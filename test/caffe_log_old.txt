I0824 23:08:36.429520 44210 caffe.cpp:217] Using GPUs 0
I0824 23:08:36.441011 44210 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0824 23:08:36.967221 44210 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc7/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0824 23:08:36.967394 44210 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/train.prototxt
I0824 23:08:36.970214 44210 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 23:08:36.970727 44210 layer_factory.hpp:77] Creating layer data
I0824 23:08:36.970749 44210 net.cpp:100] Creating Layer data
I0824 23:08:36.970759 44210 net.cpp:408] data -> data
I0824 23:08:36.970789 44210 net.cpp:408] data -> label
I0824 23:08:36.970811 44210 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt
I0824 23:08:36.973834 44210 hdf5_data_layer.cpp:93] Number of HDF5 files: 48
I0824 23:08:36.975046 44210 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0824 23:08:37.078507 44210 net.cpp:150] Setting up data
I0824 23:08:37.078536 44210 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 23:08:37.078548 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:37.078557 44210 net.cpp:165] Memory required for data: 24883200
I0824 23:08:37.078565 44210 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 23:08:37.078580 44210 net.cpp:100] Creating Layer label_data_1_split
I0824 23:08:37.078589 44210 net.cpp:434] label_data_1_split <- label
I0824 23:08:37.078606 44210 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 23:08:37.078619 44210 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 23:08:37.078662 44210 net.cpp:150] Setting up label_data_1_split
I0824 23:08:37.078670 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:37.078676 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:37.078680 44210 net.cpp:165] Memory required for data: 30412800
I0824 23:08:37.078685 44210 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 23:08:37.078706 44210 net.cpp:100] Creating Layer conv1_1_1
I0824 23:08:37.078712 44210 net.cpp:434] conv1_1_1 <- data
I0824 23:08:37.078718 44210 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 23:08:37.600358 44210 net.cpp:150] Setting up conv1_1_1
I0824 23:08:37.600399 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.600404 44210 net.cpp:165] Memory required for data: 207360000
I0824 23:08:37.600436 44210 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 23:08:37.600455 44210 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 23:08:37.600462 44210 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 23:08:37.600471 44210 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 23:08:37.600872 44210 net.cpp:150] Setting up conv1_1_1_bn
I0824 23:08:37.600883 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.600893 44210 net.cpp:165] Memory required for data: 384307200
I0824 23:08:37.600906 44210 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 23:08:37.600924 44210 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 23:08:37.600930 44210 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 23:08:37.600936 44210 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 23:08:37.600988 44210 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 23:08:37.602650 44210 net.cpp:150] Setting up conv1_1_1_scale
I0824 23:08:37.602668 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.602676 44210 net.cpp:165] Memory required for data: 561254400
I0824 23:08:37.602685 44210 layer_factory.hpp:77] Creating layer relu1_1
I0824 23:08:37.602696 44210 net.cpp:100] Creating Layer relu1_1
I0824 23:08:37.602702 44210 net.cpp:434] relu1_1 <- conv1_1_1
I0824 23:08:37.602708 44210 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 23:08:37.602941 44210 net.cpp:150] Setting up relu1_1
I0824 23:08:37.602953 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.602958 44210 net.cpp:165] Memory required for data: 738201600
I0824 23:08:37.602962 44210 layer_factory.hpp:77] Creating layer conv1_2
I0824 23:08:37.602977 44210 net.cpp:100] Creating Layer conv1_2
I0824 23:08:37.602982 44210 net.cpp:434] conv1_2 <- conv1_1_1
I0824 23:08:37.602989 44210 net.cpp:408] conv1_2 -> conv1_2
I0824 23:08:37.607216 44210 net.cpp:150] Setting up conv1_2
I0824 23:08:37.607234 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.607244 44210 net.cpp:165] Memory required for data: 915148800
I0824 23:08:37.607257 44210 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 23:08:37.607267 44210 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 23:08:37.607276 44210 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 23:08:37.607282 44210 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 23:08:37.608834 44210 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 23:08:37.608850 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.608857 44210 net.cpp:165] Memory required for data: 1092096000
I0824 23:08:37.608868 44210 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 23:08:37.608878 44210 net.cpp:100] Creating Layer conv1_2_scale
I0824 23:08:37.608885 44210 net.cpp:434] conv1_2_scale <- conv1_2
I0824 23:08:37.608891 44210 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 23:08:37.608937 44210 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 23:08:37.609313 44210 net.cpp:150] Setting up conv1_2_scale
I0824 23:08:37.609323 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.609328 44210 net.cpp:165] Memory required for data: 1269043200
I0824 23:08:37.609334 44210 layer_factory.hpp:77] Creating layer relu1_2
I0824 23:08:37.609342 44210 net.cpp:100] Creating Layer relu1_2
I0824 23:08:37.609347 44210 net.cpp:434] relu1_2 <- conv1_2
I0824 23:08:37.609352 44210 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 23:08:37.609560 44210 net.cpp:150] Setting up relu1_2
I0824 23:08:37.609570 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.609575 44210 net.cpp:165] Memory required for data: 1445990400
I0824 23:08:37.609578 44210 layer_factory.hpp:77] Creating layer pool1
I0824 23:08:37.609586 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:37.609592 44210 net.cpp:100] Creating Layer pool1
I0824 23:08:37.609597 44210 net.cpp:434] pool1 <- conv1_2
I0824 23:08:37.609603 44210 net.cpp:408] pool1 -> pool1
I0824 23:08:37.609614 44210 net.cpp:408] pool1 -> pool1_mask
I0824 23:08:37.609673 44210 net.cpp:150] Setting up pool1
I0824 23:08:37.609680 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:37.609685 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:37.609690 44210 net.cpp:165] Memory required for data: 1534464000
I0824 23:08:37.609695 44210 layer_factory.hpp:77] Creating layer conv2_1
I0824 23:08:37.609709 44210 net.cpp:100] Creating Layer conv2_1
I0824 23:08:37.609714 44210 net.cpp:434] conv2_1 <- pool1
I0824 23:08:37.609719 44210 net.cpp:408] conv2_1 -> conv2_1
I0824 23:08:37.615838 44210 net.cpp:150] Setting up conv2_1
I0824 23:08:37.615855 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.615867 44210 net.cpp:165] Memory required for data: 1622937600
I0824 23:08:37.615876 44210 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 23:08:37.615885 44210 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 23:08:37.615890 44210 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 23:08:37.615895 44210 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 23:08:37.616127 44210 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 23:08:37.616137 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.616140 44210 net.cpp:165] Memory required for data: 1711411200
I0824 23:08:37.616160 44210 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 23:08:37.616183 44210 net.cpp:100] Creating Layer conv2_1_scale
I0824 23:08:37.616188 44210 net.cpp:434] conv2_1_scale <- conv2_1
I0824 23:08:37.616194 44210 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 23:08:37.616240 44210 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 23:08:37.616417 44210 net.cpp:150] Setting up conv2_1_scale
I0824 23:08:37.616427 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.616431 44210 net.cpp:165] Memory required for data: 1799884800
I0824 23:08:37.616439 44210 layer_factory.hpp:77] Creating layer relu2_1
I0824 23:08:37.616449 44210 net.cpp:100] Creating Layer relu2_1
I0824 23:08:37.616454 44210 net.cpp:434] relu2_1 <- conv2_1
I0824 23:08:37.616461 44210 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 23:08:37.617497 44210 net.cpp:150] Setting up relu2_1
I0824 23:08:37.617513 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.617518 44210 net.cpp:165] Memory required for data: 1888358400
I0824 23:08:37.617525 44210 layer_factory.hpp:77] Creating layer conv2_2
I0824 23:08:37.617538 44210 net.cpp:100] Creating Layer conv2_2
I0824 23:08:37.617544 44210 net.cpp:434] conv2_2 <- conv2_1
I0824 23:08:37.617552 44210 net.cpp:408] conv2_2 -> conv2_2
I0824 23:08:37.624904 44210 net.cpp:150] Setting up conv2_2
I0824 23:08:37.624922 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.624930 44210 net.cpp:165] Memory required for data: 1976832000
I0824 23:08:37.624939 44210 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 23:08:37.624951 44210 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 23:08:37.624958 44210 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 23:08:37.624963 44210 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 23:08:37.625197 44210 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 23:08:37.625207 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.625211 44210 net.cpp:165] Memory required for data: 2065305600
I0824 23:08:37.625221 44210 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 23:08:37.625231 44210 net.cpp:100] Creating Layer conv2_2_scale
I0824 23:08:37.625239 44210 net.cpp:434] conv2_2_scale <- conv2_2
I0824 23:08:37.625246 44210 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 23:08:37.625288 44210 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 23:08:37.625474 44210 net.cpp:150] Setting up conv2_2_scale
I0824 23:08:37.625484 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.625488 44210 net.cpp:165] Memory required for data: 2153779200
I0824 23:08:37.625495 44210 layer_factory.hpp:77] Creating layer relu2_2
I0824 23:08:37.625502 44210 net.cpp:100] Creating Layer relu2_2
I0824 23:08:37.625507 44210 net.cpp:434] relu2_2 <- conv2_2
I0824 23:08:37.625514 44210 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 23:08:37.625711 44210 net.cpp:150] Setting up relu2_2
I0824 23:08:37.625721 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.625726 44210 net.cpp:165] Memory required for data: 2242252800
I0824 23:08:37.625732 44210 layer_factory.hpp:77] Creating layer pool2
I0824 23:08:37.625738 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:37.625744 44210 net.cpp:100] Creating Layer pool2
I0824 23:08:37.625749 44210 net.cpp:434] pool2 <- conv2_2
I0824 23:08:37.625756 44210 net.cpp:408] pool2 -> pool2
I0824 23:08:37.625764 44210 net.cpp:408] pool2 -> pool2_mask
I0824 23:08:37.625811 44210 net.cpp:150] Setting up pool2
I0824 23:08:37.625818 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:37.625823 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:37.625828 44210 net.cpp:165] Memory required for data: 2286489600
I0824 23:08:37.625831 44210 layer_factory.hpp:77] Creating layer conv3_1
I0824 23:08:37.625844 44210 net.cpp:100] Creating Layer conv3_1
I0824 23:08:37.625849 44210 net.cpp:434] conv3_1 <- pool2
I0824 23:08:37.625855 44210 net.cpp:408] conv3_1 -> conv3_1
I0824 23:08:37.637965 44210 net.cpp:150] Setting up conv3_1
I0824 23:08:37.637996 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.638007 44210 net.cpp:165] Memory required for data: 2330726400
I0824 23:08:37.638016 44210 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 23:08:37.638026 44210 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 23:08:37.638033 44210 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 23:08:37.638041 44210 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 23:08:37.638262 44210 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 23:08:37.638270 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.638279 44210 net.cpp:165] Memory required for data: 2374963200
I0824 23:08:37.638293 44210 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 23:08:37.638303 44210 net.cpp:100] Creating Layer conv3_1_scale
I0824 23:08:37.638309 44210 net.cpp:434] conv3_1_scale <- conv3_1
I0824 23:08:37.638314 44210 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 23:08:37.638357 44210 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 23:08:37.638494 44210 net.cpp:150] Setting up conv3_1_scale
I0824 23:08:37.638502 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.638509 44210 net.cpp:165] Memory required for data: 2419200000
I0824 23:08:37.638517 44210 layer_factory.hpp:77] Creating layer relu3_1
I0824 23:08:37.638526 44210 net.cpp:100] Creating Layer relu3_1
I0824 23:08:37.638531 44210 net.cpp:434] relu3_1 <- conv3_1
I0824 23:08:37.638537 44210 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 23:08:37.638736 44210 net.cpp:150] Setting up relu3_1
I0824 23:08:37.638746 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.638751 44210 net.cpp:165] Memory required for data: 2463436800
I0824 23:08:37.638756 44210 layer_factory.hpp:77] Creating layer conv3_2
I0824 23:08:37.638768 44210 net.cpp:100] Creating Layer conv3_2
I0824 23:08:37.638773 44210 net.cpp:434] conv3_2 <- conv3_1
I0824 23:08:37.638782 44210 net.cpp:408] conv3_2 -> conv3_2
I0824 23:08:37.662006 44210 net.cpp:150] Setting up conv3_2
I0824 23:08:37.662024 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.662034 44210 net.cpp:165] Memory required for data: 2507673600
I0824 23:08:37.662042 44210 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 23:08:37.662056 44210 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 23:08:37.662065 44210 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 23:08:37.662070 44210 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 23:08:37.662286 44210 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 23:08:37.662294 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.662298 44210 net.cpp:165] Memory required for data: 2551910400
I0824 23:08:37.662307 44210 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 23:08:37.662319 44210 net.cpp:100] Creating Layer conv3_2_scale
I0824 23:08:37.662324 44210 net.cpp:434] conv3_2_scale <- conv3_2
I0824 23:08:37.662330 44210 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 23:08:37.662374 44210 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 23:08:37.662513 44210 net.cpp:150] Setting up conv3_2_scale
I0824 23:08:37.662523 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.662528 44210 net.cpp:165] Memory required for data: 2596147200
I0824 23:08:37.662534 44210 layer_factory.hpp:77] Creating layer relu3_2
I0824 23:08:37.662541 44210 net.cpp:100] Creating Layer relu3_2
I0824 23:08:37.662547 44210 net.cpp:434] relu3_2 <- conv3_2
I0824 23:08:37.662552 44210 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 23:08:37.662755 44210 net.cpp:150] Setting up relu3_2
I0824 23:08:37.662765 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.662770 44210 net.cpp:165] Memory required for data: 2640384000
I0824 23:08:37.662775 44210 layer_factory.hpp:77] Creating layer conv3_3
I0824 23:08:37.662786 44210 net.cpp:100] Creating Layer conv3_3
I0824 23:08:37.662791 44210 net.cpp:434] conv3_3 <- conv3_2
I0824 23:08:37.662797 44210 net.cpp:408] conv3_3 -> conv3_3
I0824 23:08:37.686049 44210 net.cpp:150] Setting up conv3_3
I0824 23:08:37.686081 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.686090 44210 net.cpp:165] Memory required for data: 2684620800
I0824 23:08:37.686100 44210 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 23:08:37.686113 44210 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 23:08:37.686121 44210 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 23:08:37.686127 44210 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 23:08:37.686347 44210 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 23:08:37.686357 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.686360 44210 net.cpp:165] Memory required for data: 2728857600
I0824 23:08:37.686375 44210 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 23:08:37.686388 44210 net.cpp:100] Creating Layer conv3_3_scale
I0824 23:08:37.686393 44210 net.cpp:434] conv3_3_scale <- conv3_3
I0824 23:08:37.686398 44210 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 23:08:37.686444 44210 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 23:08:37.686583 44210 net.cpp:150] Setting up conv3_3_scale
I0824 23:08:37.686591 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.686596 44210 net.cpp:165] Memory required for data: 2773094400
I0824 23:08:37.686604 44210 layer_factory.hpp:77] Creating layer relu3_3
I0824 23:08:37.686611 44210 net.cpp:100] Creating Layer relu3_3
I0824 23:08:37.686616 44210 net.cpp:434] relu3_3 <- conv3_3
I0824 23:08:37.686621 44210 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 23:08:37.686827 44210 net.cpp:150] Setting up relu3_3
I0824 23:08:37.686837 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.686842 44210 net.cpp:165] Memory required for data: 2817331200
I0824 23:08:37.686846 44210 layer_factory.hpp:77] Creating layer pool3
I0824 23:08:37.686851 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:37.686861 44210 net.cpp:100] Creating Layer pool3
I0824 23:08:37.686867 44210 net.cpp:434] pool3 <- conv3_3
I0824 23:08:37.686873 44210 net.cpp:408] pool3 -> pool3
I0824 23:08:37.686882 44210 net.cpp:408] pool3 -> pool3_mask
I0824 23:08:37.686930 44210 net.cpp:150] Setting up pool3
I0824 23:08:37.686939 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:37.686944 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:37.686949 44210 net.cpp:165] Memory required for data: 2839449600
I0824 23:08:37.686951 44210 layer_factory.hpp:77] Creating layer conv4_1
I0824 23:08:37.686964 44210 net.cpp:100] Creating Layer conv4_1
I0824 23:08:37.686969 44210 net.cpp:434] conv4_1 <- pool3
I0824 23:08:37.686975 44210 net.cpp:408] conv4_1 -> conv4_1
I0824 23:08:37.733089 44210 net.cpp:150] Setting up conv4_1
I0824 23:08:37.733108 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.733119 44210 net.cpp:165] Memory required for data: 2861568000
I0824 23:08:37.733130 44210 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 23:08:37.733140 44210 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 23:08:37.733147 44210 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 23:08:37.733155 44210 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 23:08:37.733388 44210 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 23:08:37.733399 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.733403 44210 net.cpp:165] Memory required for data: 2883686400
I0824 23:08:37.733412 44210 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 23:08:37.733423 44210 net.cpp:100] Creating Layer conv4_1_scale
I0824 23:08:37.733428 44210 net.cpp:434] conv4_1_scale <- conv4_1
I0824 23:08:37.733434 44210 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 23:08:37.733479 44210 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 23:08:37.733606 44210 net.cpp:150] Setting up conv4_1_scale
I0824 23:08:37.733614 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.733618 44210 net.cpp:165] Memory required for data: 2905804800
I0824 23:08:37.733625 44210 layer_factory.hpp:77] Creating layer relu4_1
I0824 23:08:37.733649 44210 net.cpp:100] Creating Layer relu4_1
I0824 23:08:37.733654 44210 net.cpp:434] relu4_1 <- conv4_1
I0824 23:08:37.733660 44210 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 23:08:37.733873 44210 net.cpp:150] Setting up relu4_1
I0824 23:08:37.733883 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.733888 44210 net.cpp:165] Memory required for data: 2927923200
I0824 23:08:37.733892 44210 layer_factory.hpp:77] Creating layer conv4_2
I0824 23:08:37.733904 44210 net.cpp:100] Creating Layer conv4_2
I0824 23:08:37.733911 44210 net.cpp:434] conv4_2 <- conv4_1
I0824 23:08:37.733917 44210 net.cpp:408] conv4_2 -> conv4_2
I0824 23:08:37.817332 44210 net.cpp:150] Setting up conv4_2
I0824 23:08:37.817350 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.817356 44210 net.cpp:165] Memory required for data: 2950041600
I0824 23:08:37.817384 44210 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 23:08:37.817394 44210 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 23:08:37.817399 44210 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 23:08:37.817406 44210 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 23:08:37.817617 44210 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 23:08:37.817627 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.817631 44210 net.cpp:165] Memory required for data: 2972160000
I0824 23:08:37.817641 44210 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 23:08:37.817656 44210 net.cpp:100] Creating Layer conv4_2_scale
I0824 23:08:37.817663 44210 net.cpp:434] conv4_2_scale <- conv4_2
I0824 23:08:37.817668 44210 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 23:08:37.817715 44210 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 23:08:37.817842 44210 net.cpp:150] Setting up conv4_2_scale
I0824 23:08:37.817852 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.817854 44210 net.cpp:165] Memory required for data: 2994278400
I0824 23:08:37.817862 44210 layer_factory.hpp:77] Creating layer relu4_2
I0824 23:08:37.817870 44210 net.cpp:100] Creating Layer relu4_2
I0824 23:08:37.817875 44210 net.cpp:434] relu4_2 <- conv4_2
I0824 23:08:37.817881 44210 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 23:08:37.818939 44210 net.cpp:150] Setting up relu4_2
I0824 23:08:37.818955 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.818960 44210 net.cpp:165] Memory required for data: 3016396800
I0824 23:08:37.818965 44210 layer_factory.hpp:77] Creating layer conv4_3
I0824 23:08:37.818979 44210 net.cpp:100] Creating Layer conv4_3
I0824 23:08:37.818985 44210 net.cpp:434] conv4_3 <- conv4_2
I0824 23:08:37.818994 44210 net.cpp:408] conv4_3 -> conv4_3
I0824 23:08:37.902564 44210 net.cpp:150] Setting up conv4_3
I0824 23:08:37.902582 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.902587 44210 net.cpp:165] Memory required for data: 3038515200
I0824 23:08:37.902611 44210 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 23:08:37.902623 44210 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 23:08:37.902631 44210 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 23:08:37.902637 44210 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 23:08:37.902853 44210 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 23:08:37.902863 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.902871 44210 net.cpp:165] Memory required for data: 3060633600
I0824 23:08:37.902881 44210 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 23:08:37.902890 44210 net.cpp:100] Creating Layer conv4_3_scale
I0824 23:08:37.902895 44210 net.cpp:434] conv4_3_scale <- conv4_3
I0824 23:08:37.902901 44210 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 23:08:37.902945 44210 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 23:08:37.903076 44210 net.cpp:150] Setting up conv4_3_scale
I0824 23:08:37.903085 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.903090 44210 net.cpp:165] Memory required for data: 3082752000
I0824 23:08:37.903097 44210 layer_factory.hpp:77] Creating layer relu4_3
I0824 23:08:37.903120 44210 net.cpp:100] Creating Layer relu4_3
I0824 23:08:37.903126 44210 net.cpp:434] relu4_3 <- conv4_3
I0824 23:08:37.903132 44210 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 23:08:37.903338 44210 net.cpp:150] Setting up relu4_3
I0824 23:08:37.903348 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.903353 44210 net.cpp:165] Memory required for data: 3104870400
I0824 23:08:37.903357 44210 layer_factory.hpp:77] Creating layer pool4
I0824 23:08:37.903362 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:37.903370 44210 net.cpp:100] Creating Layer pool4
I0824 23:08:37.903375 44210 net.cpp:434] pool4 <- conv4_3
I0824 23:08:37.903383 44210 net.cpp:408] pool4 -> pool4
I0824 23:08:37.903393 44210 net.cpp:408] pool4 -> pool4_mask
I0824 23:08:37.903441 44210 net.cpp:150] Setting up pool4
I0824 23:08:37.903450 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.903453 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.903458 44210 net.cpp:165] Memory required for data: 3116175360
I0824 23:08:37.903463 44210 layer_factory.hpp:77] Creating layer conv5_1
I0824 23:08:37.903477 44210 net.cpp:100] Creating Layer conv5_1
I0824 23:08:37.903482 44210 net.cpp:434] conv5_1 <- pool4
I0824 23:08:37.903489 44210 net.cpp:408] conv5_1 -> conv5_1
I0824 23:08:37.987026 44210 net.cpp:150] Setting up conv5_1
I0824 23:08:37.987046 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.987057 44210 net.cpp:165] Memory required for data: 3121827840
I0824 23:08:37.987066 44210 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 23:08:37.987074 44210 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 23:08:37.987083 44210 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 23:08:37.987090 44210 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 23:08:37.987308 44210 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 23:08:37.987316 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.987320 44210 net.cpp:165] Memory required for data: 3127480320
I0824 23:08:37.987335 44210 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 23:08:37.987345 44210 net.cpp:100] Creating Layer conv5_1_scale
I0824 23:08:37.987350 44210 net.cpp:434] conv5_1_scale <- conv5_1
I0824 23:08:37.987356 44210 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 23:08:37.987404 44210 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 23:08:37.987527 44210 net.cpp:150] Setting up conv5_1_scale
I0824 23:08:37.987536 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.987540 44210 net.cpp:165] Memory required for data: 3133132800
I0824 23:08:37.987547 44210 layer_factory.hpp:77] Creating layer relu5_1
I0824 23:08:37.987557 44210 net.cpp:100] Creating Layer relu5_1
I0824 23:08:37.987563 44210 net.cpp:434] relu5_1 <- conv5_1
I0824 23:08:37.987568 44210 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 23:08:37.987772 44210 net.cpp:150] Setting up relu5_1
I0824 23:08:37.987782 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.987787 44210 net.cpp:165] Memory required for data: 3138785280
I0824 23:08:37.987793 44210 layer_factory.hpp:77] Creating layer conv5_2
I0824 23:08:37.987807 44210 net.cpp:100] Creating Layer conv5_2
I0824 23:08:37.987812 44210 net.cpp:434] conv5_2 <- conv5_1
I0824 23:08:37.987821 44210 net.cpp:408] conv5_2 -> conv5_2
I0824 23:08:38.072044 44210 net.cpp:150] Setting up conv5_2
I0824 23:08:38.072067 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.072079 44210 net.cpp:165] Memory required for data: 3144437760
I0824 23:08:38.072091 44210 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 23:08:38.072104 44210 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 23:08:38.072113 44210 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 23:08:38.072125 44210 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 23:08:38.072350 44210 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 23:08:38.072360 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.072381 44210 net.cpp:165] Memory required for data: 3150090240
I0824 23:08:38.072391 44210 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 23:08:38.072403 44210 net.cpp:100] Creating Layer conv5_2_scale
I0824 23:08:38.072408 44210 net.cpp:434] conv5_2_scale <- conv5_2
I0824 23:08:38.072414 44210 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 23:08:38.072468 44210 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 23:08:38.072599 44210 net.cpp:150] Setting up conv5_2_scale
I0824 23:08:38.072608 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.072613 44210 net.cpp:165] Memory required for data: 3155742720
I0824 23:08:38.072620 44210 layer_factory.hpp:77] Creating layer relu5_2
I0824 23:08:38.072629 44210 net.cpp:100] Creating Layer relu5_2
I0824 23:08:38.072634 44210 net.cpp:434] relu5_2 <- conv5_2
I0824 23:08:38.072640 44210 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 23:08:38.072849 44210 net.cpp:150] Setting up relu5_2
I0824 23:08:38.072860 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.072865 44210 net.cpp:165] Memory required for data: 3161395200
I0824 23:08:38.072870 44210 layer_factory.hpp:77] Creating layer conv5_3
I0824 23:08:38.072885 44210 net.cpp:100] Creating Layer conv5_3
I0824 23:08:38.072890 44210 net.cpp:434] conv5_3 <- conv5_2
I0824 23:08:38.072898 44210 net.cpp:408] conv5_3 -> conv5_3
I0824 23:08:38.156597 44210 net.cpp:150] Setting up conv5_3
I0824 23:08:38.156617 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.156626 44210 net.cpp:165] Memory required for data: 3167047680
I0824 23:08:38.156635 44210 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 23:08:38.156646 44210 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 23:08:38.156652 44210 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 23:08:38.156661 44210 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 23:08:38.156886 44210 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 23:08:38.156895 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.156898 44210 net.cpp:165] Memory required for data: 3172700160
I0824 23:08:38.156908 44210 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 23:08:38.156919 44210 net.cpp:100] Creating Layer conv5_3_scale
I0824 23:08:38.156925 44210 net.cpp:434] conv5_3_scale <- conv5_3
I0824 23:08:38.156931 44210 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 23:08:38.156981 44210 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 23:08:38.157112 44210 net.cpp:150] Setting up conv5_3_scale
I0824 23:08:38.157121 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.157124 44210 net.cpp:165] Memory required for data: 3178352640
I0824 23:08:38.157131 44210 layer_factory.hpp:77] Creating layer relu5_3
I0824 23:08:38.157140 44210 net.cpp:100] Creating Layer relu5_3
I0824 23:08:38.157145 44210 net.cpp:434] relu5_3 <- conv5_3
I0824 23:08:38.157150 44210 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 23:08:38.157358 44210 net.cpp:150] Setting up relu5_3
I0824 23:08:38.157387 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.157392 44210 net.cpp:165] Memory required for data: 3184005120
I0824 23:08:38.157397 44210 layer_factory.hpp:77] Creating layer pool5
I0824 23:08:38.157402 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:38.157410 44210 net.cpp:100] Creating Layer pool5
I0824 23:08:38.157415 44210 net.cpp:434] pool5 <- conv5_3
I0824 23:08:38.157423 44210 net.cpp:408] pool5 -> pool5
I0824 23:08:38.157433 44210 net.cpp:408] pool5 -> pool5_mask
I0824 23:08:38.157485 44210 net.cpp:150] Setting up pool5
I0824 23:08:38.157493 44210 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 23:08:38.157498 44210 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 23:08:38.157502 44210 net.cpp:165] Memory required for data: 3186954240
I0824 23:08:38.157506 44210 layer_factory.hpp:77] Creating layer upsample5
I0824 23:08:38.157521 44210 net.cpp:100] Creating Layer upsample5
I0824 23:08:38.157526 44210 net.cpp:434] upsample5 <- pool5
I0824 23:08:38.157546 44210 net.cpp:434] upsample5 <- pool5_mask
I0824 23:08:38.157554 44210 net.cpp:408] upsample5 -> pool5_D
I0824 23:08:38.157598 44210 net.cpp:150] Setting up upsample5
I0824 23:08:38.157606 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.157610 44210 net.cpp:165] Memory required for data: 3192606720
I0824 23:08:38.157613 44210 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 23:08:38.157627 44210 net.cpp:100] Creating Layer conv5_3_D
I0824 23:08:38.157634 44210 net.cpp:434] conv5_3_D <- pool5_D
I0824 23:08:38.157641 44210 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 23:08:38.242136 44210 net.cpp:150] Setting up conv5_3_D
I0824 23:08:38.242154 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.242166 44210 net.cpp:165] Memory required for data: 3198259200
I0824 23:08:38.242174 44210 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 23:08:38.242184 44210 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 23:08:38.242192 44210 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 23:08:38.242199 44210 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 23:08:38.242429 44210 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 23:08:38.242439 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.242441 44210 net.cpp:165] Memory required for data: 3203911680
I0824 23:08:38.242456 44210 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 23:08:38.242466 44210 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 23:08:38.242471 44210 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 23:08:38.242478 44210 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 23:08:38.242528 44210 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 23:08:38.242660 44210 net.cpp:150] Setting up conv5_3_D_scale
I0824 23:08:38.242668 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.242672 44210 net.cpp:165] Memory required for data: 3209564160
I0824 23:08:38.242679 44210 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 23:08:38.242686 44210 net.cpp:100] Creating Layer relu5_3_D
I0824 23:08:38.242691 44210 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 23:08:38.242698 44210 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 23:08:38.242918 44210 net.cpp:150] Setting up relu5_3_D
I0824 23:08:38.242928 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.242933 44210 net.cpp:165] Memory required for data: 3215216640
I0824 23:08:38.242936 44210 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 23:08:38.242974 44210 net.cpp:100] Creating Layer conv5_2_D
I0824 23:08:38.242980 44210 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 23:08:38.242990 44210 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 23:08:38.326680 44210 net.cpp:150] Setting up conv5_2_D
I0824 23:08:38.326699 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.326702 44210 net.cpp:165] Memory required for data: 3220869120
I0824 23:08:38.326711 44210 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 23:08:38.326720 44210 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 23:08:38.326726 44210 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 23:08:38.326733 44210 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 23:08:38.326962 44210 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 23:08:38.326972 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.326974 44210 net.cpp:165] Memory required for data: 3226521600
I0824 23:08:38.326985 44210 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 23:08:38.326995 44210 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 23:08:38.327002 44210 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 23:08:38.327008 44210 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 23:08:38.327060 44210 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 23:08:38.327193 44210 net.cpp:150] Setting up conv5_2_D_scale
I0824 23:08:38.327201 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.327205 44210 net.cpp:165] Memory required for data: 3232174080
I0824 23:08:38.327229 44210 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 23:08:38.327237 44210 net.cpp:100] Creating Layer relu5_2_D
I0824 23:08:38.327244 44210 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 23:08:38.327250 44210 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 23:08:38.328336 44210 net.cpp:150] Setting up relu5_2_D
I0824 23:08:38.328351 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.328356 44210 net.cpp:165] Memory required for data: 3237826560
I0824 23:08:38.328361 44210 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 23:08:38.328375 44210 net.cpp:100] Creating Layer conv5_1_D
I0824 23:08:38.328382 44210 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 23:08:38.328390 44210 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 23:08:38.412014 44210 net.cpp:150] Setting up conv5_1_D
I0824 23:08:38.412034 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.412045 44210 net.cpp:165] Memory required for data: 3243479040
I0824 23:08:38.412053 44210 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 23:08:38.412065 44210 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 23:08:38.412070 44210 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 23:08:38.412078 44210 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 23:08:38.412315 44210 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 23:08:38.412324 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.412333 44210 net.cpp:165] Memory required for data: 3249131520
I0824 23:08:38.412343 44210 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 23:08:38.412353 44210 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 23:08:38.412358 44210 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 23:08:38.412365 44210 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 23:08:38.412416 44210 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 23:08:38.412552 44210 net.cpp:150] Setting up conv5_1_D_scale
I0824 23:08:38.412560 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.412564 44210 net.cpp:165] Memory required for data: 3254784000
I0824 23:08:38.412571 44210 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 23:08:38.412580 44210 net.cpp:100] Creating Layer relu5_1_D
I0824 23:08:38.412585 44210 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 23:08:38.412591 44210 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 23:08:38.412801 44210 net.cpp:150] Setting up relu5_1_D
I0824 23:08:38.412811 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.412816 44210 net.cpp:165] Memory required for data: 3260436480
I0824 23:08:38.412819 44210 layer_factory.hpp:77] Creating layer upsample4
I0824 23:08:38.412828 44210 net.cpp:100] Creating Layer upsample4
I0824 23:08:38.412833 44210 net.cpp:434] upsample4 <- conv5_1_D
I0824 23:08:38.412838 44210 net.cpp:434] upsample4 <- pool4_mask
I0824 23:08:38.412847 44210 net.cpp:408] upsample4 -> pool4_D
I0824 23:08:38.412883 44210 net.cpp:150] Setting up upsample4
I0824 23:08:38.412892 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.412896 44210 net.cpp:165] Memory required for data: 3282554880
I0824 23:08:38.412900 44210 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 23:08:38.412914 44210 net.cpp:100] Creating Layer conv4_3_D
I0824 23:08:38.412919 44210 net.cpp:434] conv4_3_D <- pool4_D
I0824 23:08:38.412926 44210 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 23:08:38.496631 44210 net.cpp:150] Setting up conv4_3_D
I0824 23:08:38.496651 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.496661 44210 net.cpp:165] Memory required for data: 3304673280
I0824 23:08:38.496670 44210 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 23:08:38.496680 44210 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 23:08:38.496686 44210 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 23:08:38.496693 44210 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 23:08:38.496933 44210 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 23:08:38.496942 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.496964 44210 net.cpp:165] Memory required for data: 3326791680
I0824 23:08:38.496975 44210 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 23:08:38.496987 44210 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 23:08:38.496992 44210 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 23:08:38.496999 44210 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 23:08:38.497048 44210 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 23:08:38.497200 44210 net.cpp:150] Setting up conv4_3_D_scale
I0824 23:08:38.497210 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.497213 44210 net.cpp:165] Memory required for data: 3348910080
I0824 23:08:38.497220 44210 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 23:08:38.497229 44210 net.cpp:100] Creating Layer relu4_3_D
I0824 23:08:38.497234 44210 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 23:08:38.497241 44210 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 23:08:38.497470 44210 net.cpp:150] Setting up relu4_3_D
I0824 23:08:38.497481 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.497488 44210 net.cpp:165] Memory required for data: 3371028480
I0824 23:08:38.497491 44210 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 23:08:38.497509 44210 net.cpp:100] Creating Layer conv4_2_D
I0824 23:08:38.497514 44210 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 23:08:38.497522 44210 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 23:08:38.582813 44210 net.cpp:150] Setting up conv4_2_D
I0824 23:08:38.582834 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.582845 44210 net.cpp:165] Memory required for data: 3393146880
I0824 23:08:38.582857 44210 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 23:08:38.582871 44210 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 23:08:38.582883 44210 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 23:08:38.582895 44210 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 23:08:38.583137 44210 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 23:08:38.583145 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.583149 44210 net.cpp:165] Memory required for data: 3415265280
I0824 23:08:38.583158 44210 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 23:08:38.583171 44210 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 23:08:38.583176 44210 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 23:08:38.583183 44210 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 23:08:38.583228 44210 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 23:08:38.583379 44210 net.cpp:150] Setting up conv4_2_D_scale
I0824 23:08:38.583386 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.583390 44210 net.cpp:165] Memory required for data: 3437383680
I0824 23:08:38.583397 44210 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 23:08:38.583405 44210 net.cpp:100] Creating Layer relu4_2_D
I0824 23:08:38.583410 44210 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 23:08:38.583417 44210 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 23:08:38.583626 44210 net.cpp:150] Setting up relu4_2_D
I0824 23:08:38.583636 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.583640 44210 net.cpp:165] Memory required for data: 3459502080
I0824 23:08:38.583644 44210 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 23:08:38.583660 44210 net.cpp:100] Creating Layer conv4_1_D
I0824 23:08:38.583665 44210 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 23:08:38.583674 44210 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 23:08:38.627575 44210 net.cpp:150] Setting up conv4_1_D
I0824 23:08:38.627593 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.627604 44210 net.cpp:165] Memory required for data: 3470561280
I0824 23:08:38.627612 44210 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 23:08:38.627622 44210 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 23:08:38.627629 44210 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 23:08:38.627637 44210 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 23:08:38.627881 44210 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 23:08:38.627907 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.627915 44210 net.cpp:165] Memory required for data: 3481620480
I0824 23:08:38.627969 44210 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 23:08:38.627979 44210 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 23:08:38.627985 44210 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 23:08:38.627991 44210 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 23:08:38.628046 44210 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 23:08:38.628191 44210 net.cpp:150] Setting up conv4_1_D_scale
I0824 23:08:38.628201 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.628203 44210 net.cpp:165] Memory required for data: 3492679680
I0824 23:08:38.628211 44210 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 23:08:38.628221 44210 net.cpp:100] Creating Layer relu4_1_D
I0824 23:08:38.628226 44210 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 23:08:38.628232 44210 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 23:08:38.628454 44210 net.cpp:150] Setting up relu4_1_D
I0824 23:08:38.628464 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.628469 44210 net.cpp:165] Memory required for data: 3503738880
I0824 23:08:38.628473 44210 layer_factory.hpp:77] Creating layer upsample3
I0824 23:08:38.628484 44210 net.cpp:100] Creating Layer upsample3
I0824 23:08:38.628489 44210 net.cpp:434] upsample3 <- conv4_1_D
I0824 23:08:38.628495 44210 net.cpp:434] upsample3 <- pool3_mask
I0824 23:08:38.628504 44210 net.cpp:408] upsample3 -> pool3_D
I0824 23:08:38.628513 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:38.628547 44210 net.cpp:150] Setting up upsample3
I0824 23:08:38.628556 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.628561 44210 net.cpp:165] Memory required for data: 3547975680
I0824 23:08:38.628564 44210 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 23:08:38.628578 44210 net.cpp:100] Creating Layer conv3_3_D
I0824 23:08:38.628583 44210 net.cpp:434] conv3_3_D <- pool3_D
I0824 23:08:38.628594 44210 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 23:08:38.652086 44210 net.cpp:150] Setting up conv3_3_D
I0824 23:08:38.652103 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.652113 44210 net.cpp:165] Memory required for data: 3592212480
I0824 23:08:38.652122 44210 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 23:08:38.652133 44210 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 23:08:38.652140 44210 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 23:08:38.652148 44210 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 23:08:38.652405 44210 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 23:08:38.652413 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.652417 44210 net.cpp:165] Memory required for data: 3636449280
I0824 23:08:38.652426 44210 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 23:08:38.652438 44210 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 23:08:38.652444 44210 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 23:08:38.652451 44210 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 23:08:38.652500 44210 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 23:08:38.652664 44210 net.cpp:150] Setting up conv3_3_D_scale
I0824 23:08:38.652673 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.652678 44210 net.cpp:165] Memory required for data: 3680686080
I0824 23:08:38.652685 44210 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 23:08:38.652694 44210 net.cpp:100] Creating Layer relu3_3_D
I0824 23:08:38.652699 44210 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 23:08:38.652705 44210 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 23:08:38.652925 44210 net.cpp:150] Setting up relu3_3_D
I0824 23:08:38.652935 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.652940 44210 net.cpp:165] Memory required for data: 3724922880
I0824 23:08:38.652958 44210 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 23:08:38.652972 44210 net.cpp:100] Creating Layer conv3_2_D
I0824 23:08:38.652977 44210 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 23:08:38.652987 44210 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 23:08:38.676457 44210 net.cpp:150] Setting up conv3_2_D
I0824 23:08:38.676476 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.676489 44210 net.cpp:165] Memory required for data: 3769159680
I0824 23:08:38.676499 44210 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 23:08:38.676512 44210 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 23:08:38.676519 44210 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 23:08:38.676527 44210 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 23:08:38.676791 44210 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 23:08:38.676801 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.676810 44210 net.cpp:165] Memory required for data: 3813396480
I0824 23:08:38.676820 44210 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 23:08:38.676828 44210 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 23:08:38.676834 44210 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 23:08:38.676841 44210 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 23:08:38.676892 44210 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 23:08:38.677054 44210 net.cpp:150] Setting up conv3_2_D_scale
I0824 23:08:38.677063 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.677067 44210 net.cpp:165] Memory required for data: 3857633280
I0824 23:08:38.677074 44210 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 23:08:38.677084 44210 net.cpp:100] Creating Layer relu3_2_D
I0824 23:08:38.677089 44210 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 23:08:38.677096 44210 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 23:08:38.678210 44210 net.cpp:150] Setting up relu3_2_D
I0824 23:08:38.678226 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.678231 44210 net.cpp:165] Memory required for data: 3901870080
I0824 23:08:38.678236 44210 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 23:08:38.678251 44210 net.cpp:100] Creating Layer conv3_1_D
I0824 23:08:38.678257 44210 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 23:08:38.678267 44210 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 23:08:38.692014 44210 net.cpp:150] Setting up conv3_1_D
I0824 23:08:38.692032 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.692041 44210 net.cpp:165] Memory required for data: 3923988480
I0824 23:08:38.692050 44210 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 23:08:38.692061 44210 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 23:08:38.692068 44210 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 23:08:38.692075 44210 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 23:08:38.692338 44210 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 23:08:38.692348 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.692356 44210 net.cpp:165] Memory required for data: 3946106880
I0824 23:08:38.692366 44210 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 23:08:38.692375 44210 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 23:08:38.692380 44210 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 23:08:38.692386 44210 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 23:08:38.692437 44210 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 23:08:38.692607 44210 net.cpp:150] Setting up conv3_1_D_scale
I0824 23:08:38.692616 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.692620 44210 net.cpp:165] Memory required for data: 3968225280
I0824 23:08:38.692626 44210 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 23:08:38.692636 44210 net.cpp:100] Creating Layer relu3_1_D
I0824 23:08:38.692641 44210 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 23:08:38.692647 44210 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 23:08:38.692867 44210 net.cpp:150] Setting up relu3_1_D
I0824 23:08:38.692890 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.692896 44210 net.cpp:165] Memory required for data: 3990343680
I0824 23:08:38.692900 44210 layer_factory.hpp:77] Creating layer upsample2
I0824 23:08:38.692909 44210 net.cpp:100] Creating Layer upsample2
I0824 23:08:38.692914 44210 net.cpp:434] upsample2 <- conv3_1_D
I0824 23:08:38.692919 44210 net.cpp:434] upsample2 <- pool2_mask
I0824 23:08:38.692927 44210 net.cpp:408] upsample2 -> pool2_D
I0824 23:08:38.692936 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:38.692972 44210 net.cpp:150] Setting up upsample2
I0824 23:08:38.692981 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.692986 44210 net.cpp:165] Memory required for data: 4078817280
I0824 23:08:38.692988 44210 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 23:08:38.693001 44210 net.cpp:100] Creating Layer conv2_2_D
I0824 23:08:38.693006 44210 net.cpp:434] conv2_2_D <- pool2_D
I0824 23:08:38.693014 44210 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 23:08:38.700687 44210 net.cpp:150] Setting up conv2_2_D
I0824 23:08:38.700706 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.700713 44210 net.cpp:165] Memory required for data: 4167290880
I0824 23:08:38.700722 44210 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 23:08:38.700736 44210 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 23:08:38.700742 44210 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 23:08:38.700752 44210 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 23:08:38.701058 44210 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 23:08:38.701068 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.701078 44210 net.cpp:165] Memory required for data: 4255764480
I0824 23:08:38.701087 44210 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 23:08:38.701097 44210 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 23:08:38.701102 44210 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 23:08:38.701108 44210 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 23:08:38.701161 44210 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 23:08:38.702672 44210 net.cpp:150] Setting up conv2_2_D_scale
I0824 23:08:38.702688 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.702693 44210 net.cpp:165] Memory required for data: 4344238080
I0824 23:08:38.702702 44210 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 23:08:38.702711 44210 net.cpp:100] Creating Layer relu2_2_D
I0824 23:08:38.702718 44210 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 23:08:38.702725 44210 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 23:08:38.702961 44210 net.cpp:150] Setting up relu2_2_D
I0824 23:08:38.702971 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.702976 44210 net.cpp:165] Memory required for data: 4432711680
I0824 23:08:38.702980 44210 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 23:08:38.702993 44210 net.cpp:100] Creating Layer conv2_1_D
I0824 23:08:38.702999 44210 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 23:08:38.703008 44210 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 23:08:38.708256 44210 net.cpp:150] Setting up conv2_1_D
I0824 23:08:38.708274 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.708281 44210 net.cpp:165] Memory required for data: 4476948480
I0824 23:08:38.708290 44210 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 23:08:38.708304 44210 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 23:08:38.708312 44210 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 23:08:38.708318 44210 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 23:08:38.708621 44210 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 23:08:38.708631 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.708636 44210 net.cpp:165] Memory required for data: 4521185280
I0824 23:08:38.708645 44210 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 23:08:38.708668 44210 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 23:08:38.708673 44210 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 23:08:38.708680 44210 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 23:08:38.708739 44210 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 23:08:38.708961 44210 net.cpp:150] Setting up conv2_1_D_scale
I0824 23:08:38.708971 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.708976 44210 net.cpp:165] Memory required for data: 4565422080
I0824 23:08:38.708983 44210 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 23:08:38.708992 44210 net.cpp:100] Creating Layer relu2_1_D
I0824 23:08:38.708997 44210 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 23:08:38.709002 44210 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 23:08:38.709231 44210 net.cpp:150] Setting up relu2_1_D
I0824 23:08:38.709241 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.709246 44210 net.cpp:165] Memory required for data: 4609658880
I0824 23:08:38.709250 44210 layer_factory.hpp:77] Creating layer upsample1
I0824 23:08:38.709259 44210 net.cpp:100] Creating Layer upsample1
I0824 23:08:38.709264 44210 net.cpp:434] upsample1 <- conv2_1_D
I0824 23:08:38.709270 44210 net.cpp:434] upsample1 <- pool1_mask
I0824 23:08:38.709280 44210 net.cpp:408] upsample1 -> pool1_D
I0824 23:08:38.709288 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:38.709323 44210 net.cpp:150] Setting up upsample1
I0824 23:08:38.709331 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.709336 44210 net.cpp:165] Memory required for data: 4786606080
I0824 23:08:38.709339 44210 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 23:08:38.709352 44210 net.cpp:100] Creating Layer conv1_2_D
I0824 23:08:38.709357 44210 net.cpp:434] conv1_2_D <- pool1_D
I0824 23:08:38.709379 44210 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 23:08:38.713910 44210 net.cpp:150] Setting up conv1_2_D
I0824 23:08:38.713928 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.713938 44210 net.cpp:165] Memory required for data: 4963553280
I0824 23:08:38.713948 44210 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 23:08:38.713963 44210 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 23:08:38.713968 44210 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 23:08:38.713975 44210 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 23:08:38.714371 44210 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 23:08:38.714380 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.714385 44210 net.cpp:165] Memory required for data: 5140500480
I0824 23:08:38.714396 44210 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 23:08:38.714406 44210 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 23:08:38.714411 44210 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 23:08:38.714417 44210 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 23:08:38.714470 44210 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 23:08:38.716159 44210 net.cpp:150] Setting up conv1_2_D_scale
I0824 23:08:38.716176 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.716181 44210 net.cpp:165] Memory required for data: 5317447680
I0824 23:08:38.716189 44210 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 23:08:38.716198 44210 net.cpp:100] Creating Layer relu1_2_D
I0824 23:08:38.716204 44210 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 23:08:38.716212 44210 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 23:08:38.716446 44210 net.cpp:150] Setting up relu1_2_D
I0824 23:08:38.716457 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.716461 44210 net.cpp:165] Memory required for data: 5494394880
I0824 23:08:38.716466 44210 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 23:08:38.716478 44210 net.cpp:100] Creating Layer conv1_1_1_D
I0824 23:08:38.716485 44210 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 23:08:38.716508 44210 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 23:08:38.718585 44210 net.cpp:150] Setting up conv1_1_1_D
I0824 23:08:38.718602 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:38.718608 44210 net.cpp:165] Memory required for data: 5499924480
I0824 23:08:38.718617 44210 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:38.718626 44210 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:38.718632 44210 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 23:08:38.718641 44210 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 23:08:38.718650 44210 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 23:08:38.718708 44210 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:38.718715 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:38.718722 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:38.718725 44210 net.cpp:165] Memory required for data: 5510983680
I0824 23:08:38.718730 44210 layer_factory.hpp:77] Creating layer loss
I0824 23:08:38.718746 44210 net.cpp:100] Creating Layer loss
I0824 23:08:38.718752 44210 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 23:08:38.718757 44210 net.cpp:434] loss <- label_data_1_split_0
I0824 23:08:38.718766 44210 net.cpp:408] loss -> loss
I0824 23:08:38.718786 44210 layer_factory.hpp:77] Creating layer loss
I0824 23:08:38.722909 44210 net.cpp:150] Setting up loss
I0824 23:08:38.722925 44210 net.cpp:157] Top shape: (1)
I0824 23:08:38.722934 44210 net.cpp:160]     with loss weight 1
I0824 23:08:38.722973 44210 net.cpp:165] Memory required for data: 5510983684
I0824 23:08:38.722978 44210 layer_factory.hpp:77] Creating layer accuracy
I0824 23:08:38.722991 44210 net.cpp:100] Creating Layer accuracy
I0824 23:08:38.722996 44210 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 23:08:38.723003 44210 net.cpp:434] accuracy <- label_data_1_split_1
I0824 23:08:38.723012 44210 net.cpp:408] accuracy -> accuracy
I0824 23:08:38.723021 44210 net.cpp:408] accuracy -> per_class_accuracy
I0824 23:08:38.723080 44210 net.cpp:150] Setting up accuracy
I0824 23:08:38.723088 44210 net.cpp:157] Top shape: (1)
I0824 23:08:38.723093 44210 net.cpp:157] Top shape: 2 (2)
I0824 23:08:38.723098 44210 net.cpp:165] Memory required for data: 5510983696
I0824 23:08:38.723101 44210 net.cpp:228] accuracy does not need backward computation.
I0824 23:08:38.723105 44210 net.cpp:226] loss needs backward computation.
I0824 23:08:38.723110 44210 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 23:08:38.723114 44210 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 23:08:38.723117 44210 net.cpp:226] relu1_2_D needs backward computation.
I0824 23:08:38.723122 44210 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 23:08:38.723125 44210 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 23:08:38.723129 44210 net.cpp:226] conv1_2_D needs backward computation.
I0824 23:08:38.723131 44210 net.cpp:226] upsample1 needs backward computation.
I0824 23:08:38.723135 44210 net.cpp:226] relu2_1_D needs backward computation.
I0824 23:08:38.723140 44210 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 23:08:38.723142 44210 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 23:08:38.723145 44210 net.cpp:226] conv2_1_D needs backward computation.
I0824 23:08:38.723148 44210 net.cpp:226] relu2_2_D needs backward computation.
I0824 23:08:38.723151 44210 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 23:08:38.723155 44210 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 23:08:38.723157 44210 net.cpp:226] conv2_2_D needs backward computation.
I0824 23:08:38.723161 44210 net.cpp:226] upsample2 needs backward computation.
I0824 23:08:38.723165 44210 net.cpp:226] relu3_1_D needs backward computation.
I0824 23:08:38.723168 44210 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 23:08:38.723186 44210 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 23:08:38.723189 44210 net.cpp:226] conv3_1_D needs backward computation.
I0824 23:08:38.723193 44210 net.cpp:226] relu3_2_D needs backward computation.
I0824 23:08:38.723196 44210 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 23:08:38.723199 44210 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 23:08:38.723203 44210 net.cpp:226] conv3_2_D needs backward computation.
I0824 23:08:38.723206 44210 net.cpp:226] relu3_3_D needs backward computation.
I0824 23:08:38.723212 44210 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 23:08:38.723214 44210 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 23:08:38.723217 44210 net.cpp:226] conv3_3_D needs backward computation.
I0824 23:08:38.723220 44210 net.cpp:226] upsample3 needs backward computation.
I0824 23:08:38.723225 44210 net.cpp:226] relu4_1_D needs backward computation.
I0824 23:08:38.723228 44210 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 23:08:38.723232 44210 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 23:08:38.723234 44210 net.cpp:226] conv4_1_D needs backward computation.
I0824 23:08:38.723238 44210 net.cpp:226] relu4_2_D needs backward computation.
I0824 23:08:38.723242 44210 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 23:08:38.723244 44210 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 23:08:38.723248 44210 net.cpp:226] conv4_2_D needs backward computation.
I0824 23:08:38.723253 44210 net.cpp:226] relu4_3_D needs backward computation.
I0824 23:08:38.723258 44210 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 23:08:38.723260 44210 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 23:08:38.723264 44210 net.cpp:226] conv4_3_D needs backward computation.
I0824 23:08:38.723268 44210 net.cpp:226] upsample4 needs backward computation.
I0824 23:08:38.723274 44210 net.cpp:226] relu5_1_D needs backward computation.
I0824 23:08:38.723279 44210 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 23:08:38.723284 44210 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 23:08:38.723286 44210 net.cpp:226] conv5_1_D needs backward computation.
I0824 23:08:38.723291 44210 net.cpp:226] relu5_2_D needs backward computation.
I0824 23:08:38.723294 44210 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 23:08:38.723300 44210 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 23:08:38.723304 44210 net.cpp:226] conv5_2_D needs backward computation.
I0824 23:08:38.723309 44210 net.cpp:226] relu5_3_D needs backward computation.
I0824 23:08:38.723312 44210 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 23:08:38.723316 44210 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 23:08:38.723320 44210 net.cpp:226] conv5_3_D needs backward computation.
I0824 23:08:38.723323 44210 net.cpp:226] upsample5 needs backward computation.
I0824 23:08:38.723327 44210 net.cpp:226] pool5 needs backward computation.
I0824 23:08:38.723333 44210 net.cpp:226] relu5_3 needs backward computation.
I0824 23:08:38.723338 44210 net.cpp:226] conv5_3_scale needs backward computation.
I0824 23:08:38.723342 44210 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 23:08:38.723345 44210 net.cpp:226] conv5_3 needs backward computation.
I0824 23:08:38.723350 44210 net.cpp:226] relu5_2 needs backward computation.
I0824 23:08:38.723354 44210 net.cpp:226] conv5_2_scale needs backward computation.
I0824 23:08:38.723357 44210 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 23:08:38.723361 44210 net.cpp:226] conv5_2 needs backward computation.
I0824 23:08:38.723366 44210 net.cpp:226] relu5_1 needs backward computation.
I0824 23:08:38.723369 44210 net.cpp:226] conv5_1_scale needs backward computation.
I0824 23:08:38.723373 44210 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 23:08:38.723376 44210 net.cpp:226] conv5_1 needs backward computation.
I0824 23:08:38.723381 44210 net.cpp:226] pool4 needs backward computation.
I0824 23:08:38.723392 44210 net.cpp:226] relu4_3 needs backward computation.
I0824 23:08:38.723395 44210 net.cpp:226] conv4_3_scale needs backward computation.
I0824 23:08:38.723399 44210 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 23:08:38.723402 44210 net.cpp:226] conv4_3 needs backward computation.
I0824 23:08:38.723407 44210 net.cpp:226] relu4_2 needs backward computation.
I0824 23:08:38.723409 44210 net.cpp:226] conv4_2_scale needs backward computation.
I0824 23:08:38.723413 44210 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 23:08:38.723417 44210 net.cpp:226] conv4_2 needs backward computation.
I0824 23:08:38.723420 44210 net.cpp:226] relu4_1 needs backward computation.
I0824 23:08:38.723423 44210 net.cpp:226] conv4_1_scale needs backward computation.
I0824 23:08:38.723426 44210 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 23:08:38.723430 44210 net.cpp:226] conv4_1 needs backward computation.
I0824 23:08:38.723433 44210 net.cpp:226] pool3 needs backward computation.
I0824 23:08:38.723438 44210 net.cpp:226] relu3_3 needs backward computation.
I0824 23:08:38.723443 44210 net.cpp:226] conv3_3_scale needs backward computation.
I0824 23:08:38.723445 44210 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 23:08:38.723449 44210 net.cpp:226] conv3_3 needs backward computation.
I0824 23:08:38.723453 44210 net.cpp:226] relu3_2 needs backward computation.
I0824 23:08:38.723456 44210 net.cpp:226] conv3_2_scale needs backward computation.
I0824 23:08:38.723459 44210 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 23:08:38.723464 44210 net.cpp:226] conv3_2 needs backward computation.
I0824 23:08:38.723466 44210 net.cpp:226] relu3_1 needs backward computation.
I0824 23:08:38.723471 44210 net.cpp:226] conv3_1_scale needs backward computation.
I0824 23:08:38.723474 44210 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 23:08:38.723477 44210 net.cpp:226] conv3_1 needs backward computation.
I0824 23:08:38.723484 44210 net.cpp:226] pool2 needs backward computation.
I0824 23:08:38.723486 44210 net.cpp:226] relu2_2 needs backward computation.
I0824 23:08:38.723490 44210 net.cpp:226] conv2_2_scale needs backward computation.
I0824 23:08:38.723495 44210 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 23:08:38.723498 44210 net.cpp:226] conv2_2 needs backward computation.
I0824 23:08:38.723503 44210 net.cpp:226] relu2_1 needs backward computation.
I0824 23:08:38.723506 44210 net.cpp:226] conv2_1_scale needs backward computation.
I0824 23:08:38.723511 44210 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 23:08:38.723515 44210 net.cpp:226] conv2_1 needs backward computation.
I0824 23:08:38.723518 44210 net.cpp:226] pool1 needs backward computation.
I0824 23:08:38.723523 44210 net.cpp:226] relu1_2 needs backward computation.
I0824 23:08:38.723527 44210 net.cpp:226] conv1_2_scale needs backward computation.
I0824 23:08:38.723531 44210 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 23:08:38.723534 44210 net.cpp:226] conv1_2 needs backward computation.
I0824 23:08:38.723537 44210 net.cpp:226] relu1_1 needs backward computation.
I0824 23:08:38.723541 44210 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 23:08:38.723546 44210 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 23:08:38.723548 44210 net.cpp:226] conv1_1_1 needs backward computation.
I0824 23:08:38.723553 44210 net.cpp:228] label_data_1_split does not need backward computation.
I0824 23:08:38.723557 44210 net.cpp:228] data does not need backward computation.
I0824 23:08:38.723563 44210 net.cpp:270] This network produces output accuracy
I0824 23:08:38.723567 44210 net.cpp:270] This network produces output loss
I0824 23:08:38.723572 44210 net.cpp:270] This network produces output per_class_accuracy
I0824 23:08:38.723634 44210 net.cpp:283] Network initialization done.
I0824 23:08:38.726013 44210 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/train.prototxt
I0824 23:08:38.726707 44210 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 23:08:38.727114 44210 layer_factory.hpp:77] Creating layer data
I0824 23:08:38.727128 44210 net.cpp:100] Creating Layer data
I0824 23:08:38.727133 44210 net.cpp:408] data -> data
I0824 23:08:38.727143 44210 net.cpp:408] data -> label
I0824 23:08:38.727151 44210 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt
I0824 23:08:38.727200 44210 hdf5_data_layer.cpp:93] Number of HDF5 files: 48
I0824 23:08:38.785923 44210 net.cpp:150] Setting up data
I0824 23:08:38.785943 44210 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 23:08:38.785948 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:38.785953 44210 net.cpp:165] Memory required for data: 24883200
I0824 23:08:38.785957 44210 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 23:08:38.785967 44210 net.cpp:100] Creating Layer label_data_1_split
I0824 23:08:38.785974 44210 net.cpp:434] label_data_1_split <- label
I0824 23:08:38.785979 44210 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 23:08:38.785993 44210 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 23:08:38.786041 44210 net.cpp:150] Setting up label_data_1_split
I0824 23:08:38.786048 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:38.786054 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:38.786062 44210 net.cpp:165] Memory required for data: 30412800
I0824 23:08:38.786065 44210 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 23:08:38.786077 44210 net.cpp:100] Creating Layer conv1_1_1
I0824 23:08:38.786082 44210 net.cpp:434] conv1_1_1 <- data
I0824 23:08:38.786087 44210 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 23:08:38.789608 44210 net.cpp:150] Setting up conv1_1_1
I0824 23:08:38.789626 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.789633 44210 net.cpp:165] Memory required for data: 207360000
I0824 23:08:38.789646 44210 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 23:08:38.789655 44210 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 23:08:38.789664 44210 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 23:08:38.789670 44210 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 23:08:38.790052 44210 net.cpp:150] Setting up conv1_1_1_bn
I0824 23:08:38.790062 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.790066 44210 net.cpp:165] Memory required for data: 384307200
I0824 23:08:38.790084 44210 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 23:08:38.790093 44210 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 23:08:38.790098 44210 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 23:08:38.790104 44210 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 23:08:38.790156 44210 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 23:08:38.791860 44210 net.cpp:150] Setting up conv1_1_1_scale
I0824 23:08:38.791877 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.791882 44210 net.cpp:165] Memory required for data: 561254400
I0824 23:08:38.791891 44210 layer_factory.hpp:77] Creating layer relu1_1
I0824 23:08:38.791899 44210 net.cpp:100] Creating Layer relu1_1
I0824 23:08:38.791904 44210 net.cpp:434] relu1_1 <- conv1_1_1
I0824 23:08:38.791910 44210 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 23:08:38.792134 44210 net.cpp:150] Setting up relu1_1
I0824 23:08:38.792143 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.792148 44210 net.cpp:165] Memory required for data: 738201600
I0824 23:08:38.792152 44210 layer_factory.hpp:77] Creating layer conv1_2
I0824 23:08:38.792162 44210 net.cpp:100] Creating Layer conv1_2
I0824 23:08:38.792167 44210 net.cpp:434] conv1_2 <- conv1_1_1
I0824 23:08:38.792174 44210 net.cpp:408] conv1_2 -> conv1_2
I0824 23:08:38.796279 44210 net.cpp:150] Setting up conv1_2
I0824 23:08:38.796298 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.796309 44210 net.cpp:165] Memory required for data: 915148800
I0824 23:08:38.796339 44210 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 23:08:38.796349 44210 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 23:08:38.796353 44210 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 23:08:38.796360 44210 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 23:08:38.796741 44210 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 23:08:38.796751 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.796756 44210 net.cpp:165] Memory required for data: 1092096000
I0824 23:08:38.796766 44210 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 23:08:38.796774 44210 net.cpp:100] Creating Layer conv1_2_scale
I0824 23:08:38.796779 44210 net.cpp:434] conv1_2_scale <- conv1_2
I0824 23:08:38.796784 44210 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 23:08:38.796836 44210 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 23:08:38.798555 44210 net.cpp:150] Setting up conv1_2_scale
I0824 23:08:38.798571 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.798578 44210 net.cpp:165] Memory required for data: 1269043200
I0824 23:08:38.798585 44210 layer_factory.hpp:77] Creating layer relu1_2
I0824 23:08:38.798593 44210 net.cpp:100] Creating Layer relu1_2
I0824 23:08:38.798599 44210 net.cpp:434] relu1_2 <- conv1_2
I0824 23:08:38.798604 44210 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 23:08:38.799724 44210 net.cpp:150] Setting up relu1_2
I0824 23:08:38.799742 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.799748 44210 net.cpp:165] Memory required for data: 1445990400
I0824 23:08:38.799752 44210 layer_factory.hpp:77] Creating layer pool1
I0824 23:08:38.799759 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:38.799765 44210 net.cpp:100] Creating Layer pool1
I0824 23:08:38.799770 44210 net.cpp:434] pool1 <- conv1_2
I0824 23:08:38.799777 44210 net.cpp:408] pool1 -> pool1
I0824 23:08:38.799787 44210 net.cpp:408] pool1 -> pool1_mask
I0824 23:08:38.799847 44210 net.cpp:150] Setting up pool1
I0824 23:08:38.799856 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.799862 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.799866 44210 net.cpp:165] Memory required for data: 1534464000
I0824 23:08:38.799870 44210 layer_factory.hpp:77] Creating layer conv2_1
I0824 23:08:38.799882 44210 net.cpp:100] Creating Layer conv2_1
I0824 23:08:38.799887 44210 net.cpp:434] conv2_1 <- pool1
I0824 23:08:38.799895 44210 net.cpp:408] conv2_1 -> conv2_1
I0824 23:08:38.804253 44210 net.cpp:150] Setting up conv2_1
I0824 23:08:38.804273 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.804282 44210 net.cpp:165] Memory required for data: 1622937600
I0824 23:08:38.804291 44210 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 23:08:38.804298 44210 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 23:08:38.804307 44210 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 23:08:38.804316 44210 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 23:08:38.804633 44210 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 23:08:38.804642 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.804647 44210 net.cpp:165] Memory required for data: 1711411200
I0824 23:08:38.804661 44210 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 23:08:38.804668 44210 net.cpp:100] Creating Layer conv2_1_scale
I0824 23:08:38.804674 44210 net.cpp:434] conv2_1_scale <- conv2_1
I0824 23:08:38.804682 44210 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 23:08:38.804734 44210 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 23:08:38.804976 44210 net.cpp:150] Setting up conv2_1_scale
I0824 23:08:38.804986 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.804991 44210 net.cpp:165] Memory required for data: 1799884800
I0824 23:08:38.804997 44210 layer_factory.hpp:77] Creating layer relu2_1
I0824 23:08:38.805007 44210 net.cpp:100] Creating Layer relu2_1
I0824 23:08:38.805012 44210 net.cpp:434] relu2_1 <- conv2_1
I0824 23:08:38.805017 44210 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 23:08:38.806169 44210 net.cpp:150] Setting up relu2_1
I0824 23:08:38.806185 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.806190 44210 net.cpp:165] Memory required for data: 1888358400
I0824 23:08:38.806195 44210 layer_factory.hpp:77] Creating layer conv2_2
I0824 23:08:38.806208 44210 net.cpp:100] Creating Layer conv2_2
I0824 23:08:38.806215 44210 net.cpp:434] conv2_2 <- conv2_1
I0824 23:08:38.806222 44210 net.cpp:408] conv2_2 -> conv2_2
I0824 23:08:38.815299 44210 net.cpp:150] Setting up conv2_2
I0824 23:08:38.815316 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.815325 44210 net.cpp:165] Memory required for data: 1976832000
I0824 23:08:38.815336 44210 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 23:08:38.815354 44210 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 23:08:38.815361 44210 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 23:08:38.815366 44210 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 23:08:38.816962 44210 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 23:08:38.816977 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.816985 44210 net.cpp:165] Memory required for data: 2065305600
I0824 23:08:38.816995 44210 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 23:08:38.817004 44210 net.cpp:100] Creating Layer conv2_2_scale
I0824 23:08:38.817013 44210 net.cpp:434] conv2_2_scale <- conv2_2
I0824 23:08:38.817018 44210 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 23:08:38.817080 44210 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 23:08:38.817296 44210 net.cpp:150] Setting up conv2_2_scale
I0824 23:08:38.817304 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.817309 44210 net.cpp:165] Memory required for data: 2153779200
I0824 23:08:38.817317 44210 layer_factory.hpp:77] Creating layer relu2_2
I0824 23:08:38.817327 44210 net.cpp:100] Creating Layer relu2_2
I0824 23:08:38.817332 44210 net.cpp:434] relu2_2 <- conv2_2
I0824 23:08:38.817337 44210 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 23:08:38.817577 44210 net.cpp:150] Setting up relu2_2
I0824 23:08:38.817589 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.817596 44210 net.cpp:165] Memory required for data: 2242252800
I0824 23:08:38.817600 44210 layer_factory.hpp:77] Creating layer pool2
I0824 23:08:38.817605 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:38.817611 44210 net.cpp:100] Creating Layer pool2
I0824 23:08:38.817616 44210 net.cpp:434] pool2 <- conv2_2
I0824 23:08:38.817622 44210 net.cpp:408] pool2 -> pool2
I0824 23:08:38.817631 44210 net.cpp:408] pool2 -> pool2_mask
I0824 23:08:38.817692 44210 net.cpp:150] Setting up pool2
I0824 23:08:38.817700 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.817706 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.817709 44210 net.cpp:165] Memory required for data: 2286489600
I0824 23:08:38.817713 44210 layer_factory.hpp:77] Creating layer conv3_1
I0824 23:08:38.817724 44210 net.cpp:100] Creating Layer conv3_1
I0824 23:08:38.817729 44210 net.cpp:434] conv3_1 <- pool2
I0824 23:08:38.817739 44210 net.cpp:408] conv3_1 -> conv3_1
I0824 23:08:38.830238 44210 net.cpp:150] Setting up conv3_1
I0824 23:08:38.830255 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.830265 44210 net.cpp:165] Memory required for data: 2330726400
I0824 23:08:38.830273 44210 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 23:08:38.830284 44210 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 23:08:38.830291 44210 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 23:08:38.830299 44210 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 23:08:38.830582 44210 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 23:08:38.830591 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.830595 44210 net.cpp:165] Memory required for data: 2374963200
I0824 23:08:38.830611 44210 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 23:08:38.830634 44210 net.cpp:100] Creating Layer conv3_1_scale
I0824 23:08:38.830642 44210 net.cpp:434] conv3_1_scale <- conv3_1
I0824 23:08:38.830647 44210 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 23:08:38.830709 44210 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 23:08:38.830891 44210 net.cpp:150] Setting up conv3_1_scale
I0824 23:08:38.830900 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.830905 44210 net.cpp:165] Memory required for data: 2419200000
I0824 23:08:38.830912 44210 layer_factory.hpp:77] Creating layer relu3_1
I0824 23:08:38.830919 44210 net.cpp:100] Creating Layer relu3_1
I0824 23:08:38.830924 44210 net.cpp:434] relu3_1 <- conv3_1
I0824 23:08:38.830931 44210 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 23:08:38.831163 44210 net.cpp:150] Setting up relu3_1
I0824 23:08:38.831173 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.831178 44210 net.cpp:165] Memory required for data: 2463436800
I0824 23:08:38.831182 44210 layer_factory.hpp:77] Creating layer conv3_2
I0824 23:08:38.831194 44210 net.cpp:100] Creating Layer conv3_2
I0824 23:08:38.831200 44210 net.cpp:434] conv3_2 <- conv3_1
I0824 23:08:38.831209 44210 net.cpp:408] conv3_2 -> conv3_2
I0824 23:08:38.854835 44210 net.cpp:150] Setting up conv3_2
I0824 23:08:38.854853 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.854863 44210 net.cpp:165] Memory required for data: 2507673600
I0824 23:08:38.854872 44210 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 23:08:38.854883 44210 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 23:08:38.854889 44210 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 23:08:38.854897 44210 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 23:08:38.855186 44210 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 23:08:38.855195 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.855199 44210 net.cpp:165] Memory required for data: 2551910400
I0824 23:08:38.855211 44210 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 23:08:38.855219 44210 net.cpp:100] Creating Layer conv3_2_scale
I0824 23:08:38.855224 44210 net.cpp:434] conv3_2_scale <- conv3_2
I0824 23:08:38.855229 44210 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 23:08:38.855284 44210 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 23:08:38.855468 44210 net.cpp:150] Setting up conv3_2_scale
I0824 23:08:38.855476 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.855480 44210 net.cpp:165] Memory required for data: 2596147200
I0824 23:08:38.855487 44210 layer_factory.hpp:77] Creating layer relu3_2
I0824 23:08:38.855496 44210 net.cpp:100] Creating Layer relu3_2
I0824 23:08:38.855501 44210 net.cpp:434] relu3_2 <- conv3_2
I0824 23:08:38.855506 44210 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 23:08:38.855733 44210 net.cpp:150] Setting up relu3_2
I0824 23:08:38.855744 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.855748 44210 net.cpp:165] Memory required for data: 2640384000
I0824 23:08:38.855753 44210 layer_factory.hpp:77] Creating layer conv3_3
I0824 23:08:38.855767 44210 net.cpp:100] Creating Layer conv3_3
I0824 23:08:38.855772 44210 net.cpp:434] conv3_3 <- conv3_2
I0824 23:08:38.855779 44210 net.cpp:408] conv3_3 -> conv3_3
I0824 23:08:38.879400 44210 net.cpp:150] Setting up conv3_3
I0824 23:08:38.879417 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.879426 44210 net.cpp:165] Memory required for data: 2684620800
I0824 23:08:38.879436 44210 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 23:08:38.879446 44210 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 23:08:38.879454 44210 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 23:08:38.879461 44210 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 23:08:38.879747 44210 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 23:08:38.879757 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.879761 44210 net.cpp:165] Memory required for data: 2728857600
I0824 23:08:38.879776 44210 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 23:08:38.879797 44210 net.cpp:100] Creating Layer conv3_3_scale
I0824 23:08:38.879803 44210 net.cpp:434] conv3_3_scale <- conv3_3
I0824 23:08:38.879811 44210 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 23:08:38.879866 44210 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 23:08:38.880048 44210 net.cpp:150] Setting up conv3_3_scale
I0824 23:08:38.880058 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.880061 44210 net.cpp:165] Memory required for data: 2773094400
I0824 23:08:38.880069 44210 layer_factory.hpp:77] Creating layer relu3_3
I0824 23:08:38.880076 44210 net.cpp:100] Creating Layer relu3_3
I0824 23:08:38.880081 44210 net.cpp:434] relu3_3 <- conv3_3
I0824 23:08:38.880086 44210 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 23:08:38.880317 44210 net.cpp:150] Setting up relu3_3
I0824 23:08:38.880328 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.880332 44210 net.cpp:165] Memory required for data: 2817331200
I0824 23:08:38.880336 44210 layer_factory.hpp:77] Creating layer pool3
I0824 23:08:38.880340 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:38.880352 44210 net.cpp:100] Creating Layer pool3
I0824 23:08:38.880357 44210 net.cpp:434] pool3 <- conv3_3
I0824 23:08:38.880364 44210 net.cpp:408] pool3 -> pool3
I0824 23:08:38.880373 44210 net.cpp:408] pool3 -> pool3_mask
I0824 23:08:38.880434 44210 net.cpp:150] Setting up pool3
I0824 23:08:38.880442 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.880448 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.880452 44210 net.cpp:165] Memory required for data: 2839449600
I0824 23:08:38.880456 44210 layer_factory.hpp:77] Creating layer conv4_1
I0824 23:08:38.880467 44210 net.cpp:100] Creating Layer conv4_1
I0824 23:08:38.880472 44210 net.cpp:434] conv4_1 <- pool3
I0824 23:08:38.880482 44210 net.cpp:408] conv4_1 -> conv4_1
I0824 23:08:38.924474 44210 net.cpp:150] Setting up conv4_1
I0824 23:08:38.924492 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.924502 44210 net.cpp:165] Memory required for data: 2861568000
I0824 23:08:38.924511 44210 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 23:08:38.924523 44210 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 23:08:38.924530 44210 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 23:08:38.924535 44210 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 23:08:38.924814 44210 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 23:08:38.924823 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.924827 44210 net.cpp:165] Memory required for data: 2883686400
I0824 23:08:38.924836 44210 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 23:08:38.924849 44210 net.cpp:100] Creating Layer conv4_1_scale
I0824 23:08:38.924855 44210 net.cpp:434] conv4_1_scale <- conv4_1
I0824 23:08:38.924860 44210 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 23:08:38.924912 44210 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 23:08:38.925079 44210 net.cpp:150] Setting up conv4_1_scale
I0824 23:08:38.925088 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.925091 44210 net.cpp:165] Memory required for data: 2905804800
I0824 23:08:38.925098 44210 layer_factory.hpp:77] Creating layer relu4_1
I0824 23:08:38.925107 44210 net.cpp:100] Creating Layer relu4_1
I0824 23:08:38.925112 44210 net.cpp:434] relu4_1 <- conv4_1
I0824 23:08:38.925122 44210 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 23:08:38.926270 44210 net.cpp:150] Setting up relu4_1
I0824 23:08:38.926286 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.926291 44210 net.cpp:165] Memory required for data: 2927923200
I0824 23:08:38.926295 44210 layer_factory.hpp:77] Creating layer conv4_2
I0824 23:08:38.926311 44210 net.cpp:100] Creating Layer conv4_2
I0824 23:08:38.926317 44210 net.cpp:434] conv4_2 <- conv4_1
I0824 23:08:38.926326 44210 net.cpp:408] conv4_2 -> conv4_2
I0824 23:08:39.009132 44210 net.cpp:150] Setting up conv4_2
I0824 23:08:39.009165 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.009169 44210 net.cpp:165] Memory required for data: 2950041600
I0824 23:08:39.009178 44210 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 23:08:39.009188 44210 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 23:08:39.009196 44210 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 23:08:39.009202 44210 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 23:08:39.009488 44210 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 23:08:39.009500 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.009510 44210 net.cpp:165] Memory required for data: 2972160000
I0824 23:08:39.009519 44210 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 23:08:39.009526 44210 net.cpp:100] Creating Layer conv4_2_scale
I0824 23:08:39.009536 44210 net.cpp:434] conv4_2_scale <- conv4_2
I0824 23:08:39.009541 44210 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 23:08:39.009596 44210 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 23:08:39.009763 44210 net.cpp:150] Setting up conv4_2_scale
I0824 23:08:39.009773 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.009776 44210 net.cpp:165] Memory required for data: 2994278400
I0824 23:08:39.009783 44210 layer_factory.hpp:77] Creating layer relu4_2
I0824 23:08:39.009793 44210 net.cpp:100] Creating Layer relu4_2
I0824 23:08:39.009798 44210 net.cpp:434] relu4_2 <- conv4_2
I0824 23:08:39.009802 44210 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 23:08:39.010972 44210 net.cpp:150] Setting up relu4_2
I0824 23:08:39.010987 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.010993 44210 net.cpp:165] Memory required for data: 3016396800
I0824 23:08:39.010996 44210 layer_factory.hpp:77] Creating layer conv4_3
I0824 23:08:39.011011 44210 net.cpp:100] Creating Layer conv4_3
I0824 23:08:39.011018 44210 net.cpp:434] conv4_3 <- conv4_2
I0824 23:08:39.011027 44210 net.cpp:408] conv4_3 -> conv4_3
I0824 23:08:39.094899 44210 net.cpp:150] Setting up conv4_3
I0824 23:08:39.094918 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.094929 44210 net.cpp:165] Memory required for data: 3038515200
I0824 23:08:39.094954 44210 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 23:08:39.094965 44210 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 23:08:39.094972 44210 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 23:08:39.094980 44210 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 23:08:39.095254 44210 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 23:08:39.095263 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.095268 44210 net.cpp:165] Memory required for data: 3060633600
I0824 23:08:39.095275 44210 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 23:08:39.095284 44210 net.cpp:100] Creating Layer conv4_3_scale
I0824 23:08:39.095289 44210 net.cpp:434] conv4_3_scale <- conv4_3
I0824 23:08:39.095299 44210 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 23:08:39.095351 44210 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 23:08:39.095516 44210 net.cpp:150] Setting up conv4_3_scale
I0824 23:08:39.095525 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.095530 44210 net.cpp:165] Memory required for data: 3082752000
I0824 23:08:39.095538 44210 layer_factory.hpp:77] Creating layer relu4_3
I0824 23:08:39.095546 44210 net.cpp:100] Creating Layer relu4_3
I0824 23:08:39.095551 44210 net.cpp:434] relu4_3 <- conv4_3
I0824 23:08:39.095556 44210 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 23:08:39.095782 44210 net.cpp:150] Setting up relu4_3
I0824 23:08:39.095793 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.095798 44210 net.cpp:165] Memory required for data: 3104870400
I0824 23:08:39.095801 44210 layer_factory.hpp:77] Creating layer pool4
I0824 23:08:39.095806 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:39.095813 44210 net.cpp:100] Creating Layer pool4
I0824 23:08:39.095818 44210 net.cpp:434] pool4 <- conv4_3
I0824 23:08:39.095841 44210 net.cpp:408] pool4 -> pool4
I0824 23:08:39.095850 44210 net.cpp:408] pool4 -> pool4_mask
I0824 23:08:39.095911 44210 net.cpp:150] Setting up pool4
I0824 23:08:39.095918 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.095926 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.095928 44210 net.cpp:165] Memory required for data: 3116175360
I0824 23:08:39.095932 44210 layer_factory.hpp:77] Creating layer conv5_1
I0824 23:08:39.095945 44210 net.cpp:100] Creating Layer conv5_1
I0824 23:08:39.095950 44210 net.cpp:434] conv5_1 <- pool4
I0824 23:08:39.095957 44210 net.cpp:408] conv5_1 -> conv5_1
I0824 23:08:39.180421 44210 net.cpp:150] Setting up conv5_1
I0824 23:08:39.180449 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.180455 44210 net.cpp:165] Memory required for data: 3121827840
I0824 23:08:39.180469 44210 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 23:08:39.180480 44210 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 23:08:39.180490 44210 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 23:08:39.180505 44210 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 23:08:39.180794 44210 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 23:08:39.180804 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.180807 44210 net.cpp:165] Memory required for data: 3127480320
I0824 23:08:39.180816 44210 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 23:08:39.180824 44210 net.cpp:100] Creating Layer conv5_1_scale
I0824 23:08:39.180830 44210 net.cpp:434] conv5_1_scale <- conv5_1
I0824 23:08:39.180835 44210 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 23:08:39.180896 44210 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 23:08:39.181052 44210 net.cpp:150] Setting up conv5_1_scale
I0824 23:08:39.181061 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.181066 44210 net.cpp:165] Memory required for data: 3133132800
I0824 23:08:39.181072 44210 layer_factory.hpp:77] Creating layer relu5_1
I0824 23:08:39.181080 44210 net.cpp:100] Creating Layer relu5_1
I0824 23:08:39.181085 44210 net.cpp:434] relu5_1 <- conv5_1
I0824 23:08:39.181093 44210 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 23:08:39.181318 44210 net.cpp:150] Setting up relu5_1
I0824 23:08:39.181329 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.181332 44210 net.cpp:165] Memory required for data: 3138785280
I0824 23:08:39.181336 44210 layer_factory.hpp:77] Creating layer conv5_2
I0824 23:08:39.181349 44210 net.cpp:100] Creating Layer conv5_2
I0824 23:08:39.181354 44210 net.cpp:434] conv5_2 <- conv5_1
I0824 23:08:39.181362 44210 net.cpp:408] conv5_2 -> conv5_2
I0824 23:08:39.265224 44210 net.cpp:150] Setting up conv5_2
I0824 23:08:39.265244 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.265247 44210 net.cpp:165] Memory required for data: 3144437760
I0824 23:08:39.265255 44210 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 23:08:39.265265 44210 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 23:08:39.265277 44210 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 23:08:39.265285 44210 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 23:08:39.265568 44210 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 23:08:39.265578 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.265583 44210 net.cpp:165] Memory required for data: 3150090240
I0824 23:08:39.265591 44210 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 23:08:39.265604 44210 net.cpp:100] Creating Layer conv5_2_scale
I0824 23:08:39.265614 44210 net.cpp:434] conv5_2_scale <- conv5_2
I0824 23:08:39.265622 44210 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 23:08:39.265679 44210 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 23:08:39.265835 44210 net.cpp:150] Setting up conv5_2_scale
I0824 23:08:39.265846 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.265851 44210 net.cpp:165] Memory required for data: 3155742720
I0824 23:08:39.265857 44210 layer_factory.hpp:77] Creating layer relu5_2
I0824 23:08:39.265880 44210 net.cpp:100] Creating Layer relu5_2
I0824 23:08:39.265885 44210 net.cpp:434] relu5_2 <- conv5_2
I0824 23:08:39.265890 44210 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 23:08:39.266116 44210 net.cpp:150] Setting up relu5_2
I0824 23:08:39.266129 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.266134 44210 net.cpp:165] Memory required for data: 3161395200
I0824 23:08:39.266137 44210 layer_factory.hpp:77] Creating layer conv5_3
I0824 23:08:39.266152 44210 net.cpp:100] Creating Layer conv5_3
I0824 23:08:39.266158 44210 net.cpp:434] conv5_3 <- conv5_2
I0824 23:08:39.266165 44210 net.cpp:408] conv5_3 -> conv5_3
I0824 23:08:39.349966 44210 net.cpp:150] Setting up conv5_3
I0824 23:08:39.349983 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.349988 44210 net.cpp:165] Memory required for data: 3167047680
I0824 23:08:39.349997 44210 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 23:08:39.350006 44210 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 23:08:39.350016 44210 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 23:08:39.350024 44210 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 23:08:39.350296 44210 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 23:08:39.350306 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.350309 44210 net.cpp:165] Memory required for data: 3172700160
I0824 23:08:39.350319 44210 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 23:08:39.350329 44210 net.cpp:100] Creating Layer conv5_3_scale
I0824 23:08:39.350335 44210 net.cpp:434] conv5_3_scale <- conv5_3
I0824 23:08:39.350342 44210 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 23:08:39.350404 44210 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 23:08:39.350563 44210 net.cpp:150] Setting up conv5_3_scale
I0824 23:08:39.350570 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.350574 44210 net.cpp:165] Memory required for data: 3178352640
I0824 23:08:39.350581 44210 layer_factory.hpp:77] Creating layer relu5_3
I0824 23:08:39.350589 44210 net.cpp:100] Creating Layer relu5_3
I0824 23:08:39.350594 44210 net.cpp:434] relu5_3 <- conv5_3
I0824 23:08:39.350599 44210 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 23:08:39.350826 44210 net.cpp:150] Setting up relu5_3
I0824 23:08:39.350836 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.350841 44210 net.cpp:165] Memory required for data: 3184005120
I0824 23:08:39.350845 44210 layer_factory.hpp:77] Creating layer pool5
I0824 23:08:39.350850 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:39.350858 44210 net.cpp:100] Creating Layer pool5
I0824 23:08:39.350863 44210 net.cpp:434] pool5 <- conv5_3
I0824 23:08:39.350874 44210 net.cpp:408] pool5 -> pool5
I0824 23:08:39.350883 44210 net.cpp:408] pool5 -> pool5_mask
I0824 23:08:39.350945 44210 net.cpp:150] Setting up pool5
I0824 23:08:39.350953 44210 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 23:08:39.350958 44210 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 23:08:39.350962 44210 net.cpp:165] Memory required for data: 3186954240
I0824 23:08:39.350966 44210 layer_factory.hpp:77] Creating layer upsample5
I0824 23:08:39.350975 44210 net.cpp:100] Creating Layer upsample5
I0824 23:08:39.350980 44210 net.cpp:434] upsample5 <- pool5
I0824 23:08:39.350986 44210 net.cpp:434] upsample5 <- pool5_mask
I0824 23:08:39.350994 44210 net.cpp:408] upsample5 -> pool5_D
I0824 23:08:39.351028 44210 net.cpp:150] Setting up upsample5
I0824 23:08:39.351035 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.351038 44210 net.cpp:165] Memory required for data: 3192606720
I0824 23:08:39.351042 44210 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 23:08:39.351056 44210 net.cpp:100] Creating Layer conv5_3_D
I0824 23:08:39.351061 44210 net.cpp:434] conv5_3_D <- pool5_D
I0824 23:08:39.351068 44210 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 23:08:39.434933 44210 net.cpp:150] Setting up conv5_3_D
I0824 23:08:39.434953 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.434976 44210 net.cpp:165] Memory required for data: 3198259200
I0824 23:08:39.434985 44210 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 23:08:39.434994 44210 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 23:08:39.435003 44210 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 23:08:39.435009 44210 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 23:08:39.435297 44210 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 23:08:39.435305 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.435314 44210 net.cpp:165] Memory required for data: 3203911680
I0824 23:08:39.435323 44210 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 23:08:39.435331 44210 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 23:08:39.435336 44210 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 23:08:39.435341 44210 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 23:08:39.435405 44210 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 23:08:39.435566 44210 net.cpp:150] Setting up conv5_3_D_scale
I0824 23:08:39.435575 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.435578 44210 net.cpp:165] Memory required for data: 3209564160
I0824 23:08:39.435585 44210 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 23:08:39.435593 44210 net.cpp:100] Creating Layer relu5_3_D
I0824 23:08:39.435598 44210 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 23:08:39.435606 44210 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 23:08:39.436759 44210 net.cpp:150] Setting up relu5_3_D
I0824 23:08:39.436775 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.436780 44210 net.cpp:165] Memory required for data: 3215216640
I0824 23:08:39.436784 44210 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 23:08:39.436823 44210 net.cpp:100] Creating Layer conv5_2_D
I0824 23:08:39.436830 44210 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 23:08:39.436838 44210 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 23:08:39.520823 44210 net.cpp:150] Setting up conv5_2_D
I0824 23:08:39.520841 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.520845 44210 net.cpp:165] Memory required for data: 3220869120
I0824 23:08:39.520854 44210 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 23:08:39.520869 44210 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 23:08:39.520876 44210 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 23:08:39.520884 44210 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 23:08:39.521173 44210 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 23:08:39.521183 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.521186 44210 net.cpp:165] Memory required for data: 3226521600
I0824 23:08:39.521199 44210 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 23:08:39.521210 44210 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 23:08:39.521215 44210 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 23:08:39.521220 44210 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 23:08:39.521282 44210 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 23:08:39.521468 44210 net.cpp:150] Setting up conv5_2_D_scale
I0824 23:08:39.521479 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.521482 44210 net.cpp:165] Memory required for data: 3232174080
I0824 23:08:39.521491 44210 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 23:08:39.521498 44210 net.cpp:100] Creating Layer relu5_2_D
I0824 23:08:39.521503 44210 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 23:08:39.521510 44210 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 23:08:39.522708 44210 net.cpp:150] Setting up relu5_2_D
I0824 23:08:39.522723 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.522729 44210 net.cpp:165] Memory required for data: 3237826560
I0824 23:08:39.522733 44210 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 23:08:39.522748 44210 net.cpp:100] Creating Layer conv5_1_D
I0824 23:08:39.522754 44210 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 23:08:39.522764 44210 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 23:08:39.607126 44210 net.cpp:150] Setting up conv5_1_D
I0824 23:08:39.607162 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.607167 44210 net.cpp:165] Memory required for data: 3243479040
I0824 23:08:39.607177 44210 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 23:08:39.607193 44210 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 23:08:39.607208 44210 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 23:08:39.607221 44210 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 23:08:39.607512 44210 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 23:08:39.607522 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.607524 44210 net.cpp:165] Memory required for data: 3249131520
I0824 23:08:39.607533 44210 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 23:08:39.607543 44210 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 23:08:39.607550 44210 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 23:08:39.607556 44210 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 23:08:39.607620 44210 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 23:08:39.607780 44210 net.cpp:150] Setting up conv5_1_D_scale
I0824 23:08:39.607789 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.607791 44210 net.cpp:165] Memory required for data: 3254784000
I0824 23:08:39.607798 44210 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 23:08:39.607810 44210 net.cpp:100] Creating Layer relu5_1_D
I0824 23:08:39.607815 44210 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 23:08:39.607820 44210 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 23:08:39.608047 44210 net.cpp:150] Setting up relu5_1_D
I0824 23:08:39.608057 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.608060 44210 net.cpp:165] Memory required for data: 3260436480
I0824 23:08:39.608064 44210 layer_factory.hpp:77] Creating layer upsample4
I0824 23:08:39.608073 44210 net.cpp:100] Creating Layer upsample4
I0824 23:08:39.608078 44210 net.cpp:434] upsample4 <- conv5_1_D
I0824 23:08:39.608084 44210 net.cpp:434] upsample4 <- pool4_mask
I0824 23:08:39.608093 44210 net.cpp:408] upsample4 -> pool4_D
I0824 23:08:39.608134 44210 net.cpp:150] Setting up upsample4
I0824 23:08:39.608140 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.608144 44210 net.cpp:165] Memory required for data: 3282554880
I0824 23:08:39.608147 44210 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 23:08:39.608163 44210 net.cpp:100] Creating Layer conv4_3_D
I0824 23:08:39.608170 44210 net.cpp:434] conv4_3_D <- pool4_D
I0824 23:08:39.608176 44210 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 23:08:39.692481 44210 net.cpp:150] Setting up conv4_3_D
I0824 23:08:39.692500 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.692504 44210 net.cpp:165] Memory required for data: 3304673280
I0824 23:08:39.692512 44210 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 23:08:39.692523 44210 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 23:08:39.692530 44210 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 23:08:39.692538 44210 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 23:08:39.692824 44210 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 23:08:39.692833 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.692836 44210 net.cpp:165] Memory required for data: 3326791680
I0824 23:08:39.692845 44210 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 23:08:39.692857 44210 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 23:08:39.692867 44210 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 23:08:39.692874 44210 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 23:08:39.692929 44210 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 23:08:39.693104 44210 net.cpp:150] Setting up conv4_3_D_scale
I0824 23:08:39.693111 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.693114 44210 net.cpp:165] Memory required for data: 3348910080
I0824 23:08:39.693121 44210 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 23:08:39.693147 44210 net.cpp:100] Creating Layer relu4_3_D
I0824 23:08:39.693153 44210 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 23:08:39.693158 44210 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 23:08:39.693408 44210 net.cpp:150] Setting up relu4_3_D
I0824 23:08:39.693418 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.693423 44210 net.cpp:165] Memory required for data: 3371028480
I0824 23:08:39.693426 44210 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 23:08:39.693439 44210 net.cpp:100] Creating Layer conv4_2_D
I0824 23:08:39.693444 44210 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 23:08:39.693454 44210 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 23:08:39.777825 44210 net.cpp:150] Setting up conv4_2_D
I0824 23:08:39.777842 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.777848 44210 net.cpp:165] Memory required for data: 3393146880
I0824 23:08:39.777854 44210 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 23:08:39.777871 44210 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 23:08:39.777878 44210 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 23:08:39.777886 44210 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 23:08:39.778175 44210 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 23:08:39.778184 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.778187 44210 net.cpp:165] Memory required for data: 3415265280
I0824 23:08:39.778197 44210 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 23:08:39.778211 44210 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 23:08:39.778218 44210 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 23:08:39.778223 44210 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 23:08:39.778275 44210 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 23:08:39.778448 44210 net.cpp:150] Setting up conv4_2_D_scale
I0824 23:08:39.778456 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.778460 44210 net.cpp:165] Memory required for data: 3437383680
I0824 23:08:39.778466 44210 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 23:08:39.778475 44210 net.cpp:100] Creating Layer relu4_2_D
I0824 23:08:39.778481 44210 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 23:08:39.778487 44210 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 23:08:39.778709 44210 net.cpp:150] Setting up relu4_2_D
I0824 23:08:39.778718 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.778723 44210 net.cpp:165] Memory required for data: 3459502080
I0824 23:08:39.778725 44210 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 23:08:39.778743 44210 net.cpp:100] Creating Layer conv4_1_D
I0824 23:08:39.778748 44210 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 23:08:39.778758 44210 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 23:08:39.823861 44210 net.cpp:150] Setting up conv4_1_D
I0824 23:08:39.823879 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:39.823884 44210 net.cpp:165] Memory required for data: 3470561280
I0824 23:08:39.823891 44210 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 23:08:39.823901 44210 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 23:08:39.823909 44210 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 23:08:39.823918 44210 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 23:08:39.824213 44210 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 23:08:39.824221 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:39.824224 44210 net.cpp:165] Memory required for data: 3481620480
I0824 23:08:39.824385 44210 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 23:08:39.824398 44210 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 23:08:39.824405 44210 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 23:08:39.824411 44210 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 23:08:39.824475 44210 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 23:08:39.824648 44210 net.cpp:150] Setting up conv4_1_D_scale
I0824 23:08:39.824656 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:39.824676 44210 net.cpp:165] Memory required for data: 3492679680
I0824 23:08:39.824684 44210 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 23:08:39.824690 44210 net.cpp:100] Creating Layer relu4_1_D
I0824 23:08:39.824697 44210 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 23:08:39.824702 44210 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 23:08:39.824939 44210 net.cpp:150] Setting up relu4_1_D
I0824 23:08:39.824949 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:39.824954 44210 net.cpp:165] Memory required for data: 3503738880
I0824 23:08:39.824957 44210 layer_factory.hpp:77] Creating layer upsample3
I0824 23:08:39.824968 44210 net.cpp:100] Creating Layer upsample3
I0824 23:08:39.824973 44210 net.cpp:434] upsample3 <- conv4_1_D
I0824 23:08:39.824978 44210 net.cpp:434] upsample3 <- pool3_mask
I0824 23:08:39.824985 44210 net.cpp:408] upsample3 -> pool3_D
I0824 23:08:39.824993 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:39.825033 44210 net.cpp:150] Setting up upsample3
I0824 23:08:39.825039 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.825043 44210 net.cpp:165] Memory required for data: 3547975680
I0824 23:08:39.825047 44210 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 23:08:39.825058 44210 net.cpp:100] Creating Layer conv3_3_D
I0824 23:08:39.825064 44210 net.cpp:434] conv3_3_D <- pool3_D
I0824 23:08:39.825073 44210 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 23:08:39.851440 44210 net.cpp:150] Setting up conv3_3_D
I0824 23:08:39.851459 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.851464 44210 net.cpp:165] Memory required for data: 3592212480
I0824 23:08:39.851474 44210 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 23:08:39.851490 44210 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 23:08:39.851500 44210 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 23:08:39.851511 44210 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 23:08:39.851824 44210 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 23:08:39.851833 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.851837 44210 net.cpp:165] Memory required for data: 3636449280
I0824 23:08:39.851847 44210 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 23:08:39.851861 44210 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 23:08:39.851866 44210 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 23:08:39.851871 44210 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 23:08:39.851930 44210 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 23:08:39.852130 44210 net.cpp:150] Setting up conv3_3_D_scale
I0824 23:08:39.852138 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.852143 44210 net.cpp:165] Memory required for data: 3680686080
I0824 23:08:39.852149 44210 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 23:08:39.852159 44210 net.cpp:100] Creating Layer relu3_3_D
I0824 23:08:39.852164 44210 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 23:08:39.852169 44210 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 23:08:39.853348 44210 net.cpp:150] Setting up relu3_3_D
I0824 23:08:39.853363 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.853384 44210 net.cpp:165] Memory required for data: 3724922880
I0824 23:08:39.853389 44210 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 23:08:39.853406 44210 net.cpp:100] Creating Layer conv3_2_D
I0824 23:08:39.853411 44210 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 23:08:39.853421 44210 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 23:08:39.876401 44210 net.cpp:150] Setting up conv3_2_D
I0824 23:08:39.876417 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.876427 44210 net.cpp:165] Memory required for data: 3769159680
I0824 23:08:39.876435 44210 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 23:08:39.876453 44210 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 23:08:39.876461 44210 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 23:08:39.876482 44210 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 23:08:39.876790 44210 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 23:08:39.876797 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.876801 44210 net.cpp:165] Memory required for data: 3813396480
I0824 23:08:39.876809 44210 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 23:08:39.876821 44210 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 23:08:39.876826 44210 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 23:08:39.876833 44210 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 23:08:39.876888 44210 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 23:08:39.877082 44210 net.cpp:150] Setting up conv3_2_D_scale
I0824 23:08:39.877090 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.877094 44210 net.cpp:165] Memory required for data: 3857633280
I0824 23:08:39.877100 44210 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 23:08:39.877110 44210 net.cpp:100] Creating Layer relu3_2_D
I0824 23:08:39.877115 44210 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 23:08:39.877120 44210 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 23:08:39.878324 44210 net.cpp:150] Setting up relu3_2_D
I0824 23:08:39.878340 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.878345 44210 net.cpp:165] Memory required for data: 3901870080
I0824 23:08:39.878350 44210 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 23:08:39.878366 44210 net.cpp:100] Creating Layer conv3_1_D
I0824 23:08:39.878372 44210 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 23:08:39.878381 44210 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 23:08:39.892482 44210 net.cpp:150] Setting up conv3_1_D
I0824 23:08:39.892501 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:39.892509 44210 net.cpp:165] Memory required for data: 3923988480
I0824 23:08:39.892518 44210 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 23:08:39.892535 44210 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 23:08:39.892540 44210 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 23:08:39.892547 44210 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 23:08:39.892858 44210 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 23:08:39.892866 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:39.892869 44210 net.cpp:165] Memory required for data: 3946106880
I0824 23:08:39.892879 44210 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 23:08:39.892891 44210 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 23:08:39.892896 44210 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 23:08:39.892902 44210 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 23:08:39.892961 44210 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 23:08:39.894583 44210 net.cpp:150] Setting up conv3_1_D_scale
I0824 23:08:39.894599 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:39.894604 44210 net.cpp:165] Memory required for data: 3968225280
I0824 23:08:39.894613 44210 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 23:08:39.894623 44210 net.cpp:100] Creating Layer relu3_1_D
I0824 23:08:39.894628 44210 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 23:08:39.894635 44210 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 23:08:39.894876 44210 net.cpp:150] Setting up relu3_1_D
I0824 23:08:39.894886 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:39.894891 44210 net.cpp:165] Memory required for data: 3990343680
I0824 23:08:39.894894 44210 layer_factory.hpp:77] Creating layer upsample2
I0824 23:08:39.894903 44210 net.cpp:100] Creating Layer upsample2
I0824 23:08:39.894911 44210 net.cpp:434] upsample2 <- conv3_1_D
I0824 23:08:39.894917 44210 net.cpp:434] upsample2 <- pool2_mask
I0824 23:08:39.894924 44210 net.cpp:408] upsample2 -> pool2_D
I0824 23:08:39.894933 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:39.894973 44210 net.cpp:150] Setting up upsample2
I0824 23:08:39.894994 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:39.894999 44210 net.cpp:165] Memory required for data: 4078817280
I0824 23:08:39.895004 44210 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 23:08:39.895020 44210 net.cpp:100] Creating Layer conv2_2_D
I0824 23:08:39.895025 44210 net.cpp:434] conv2_2_D <- pool2_D
I0824 23:08:39.895031 44210 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 23:08:39.903007 44210 net.cpp:150] Setting up conv2_2_D
I0824 23:08:39.903026 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:39.903033 44210 net.cpp:165] Memory required for data: 4167290880
I0824 23:08:39.903041 44210 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 23:08:39.903051 44210 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 23:08:39.903061 44210 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 23:08:39.903069 44210 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 23:08:39.903419 44210 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 23:08:39.903427 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:39.903430 44210 net.cpp:165] Memory required for data: 4255764480
I0824 23:08:39.903439 44210 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 23:08:39.903448 44210 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 23:08:39.903456 44210 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 23:08:39.903462 44210 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 23:08:39.903524 44210 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 23:08:39.903800 44210 net.cpp:150] Setting up conv2_2_D_scale
I0824 23:08:39.903810 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:39.903812 44210 net.cpp:165] Memory required for data: 4344238080
I0824 23:08:39.903820 44210 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 23:08:39.903826 44210 net.cpp:100] Creating Layer relu2_2_D
I0824 23:08:39.903831 44210 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 23:08:39.903838 44210 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 23:08:39.904078 44210 net.cpp:150] Setting up relu2_2_D
I0824 23:08:39.904088 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:39.904093 44210 net.cpp:165] Memory required for data: 4432711680
I0824 23:08:39.904098 44210 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 23:08:39.904111 44210 net.cpp:100] Creating Layer conv2_1_D
I0824 23:08:39.904116 44210 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 23:08:39.904127 44210 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 23:08:39.909689 44210 net.cpp:150] Setting up conv2_1_D
I0824 23:08:39.909705 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:39.909714 44210 net.cpp:165] Memory required for data: 4476948480
I0824 23:08:39.909723 44210 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 23:08:39.909734 44210 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 23:08:39.909740 44210 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 23:08:39.909749 44210 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 23:08:39.910109 44210 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 23:08:39.910118 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:39.910122 44210 net.cpp:165] Memory required for data: 4521185280
I0824 23:08:39.910130 44210 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 23:08:39.910142 44210 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 23:08:39.910147 44210 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 23:08:39.910153 44210 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 23:08:39.910213 44210 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 23:08:39.910498 44210 net.cpp:150] Setting up conv2_1_D_scale
I0824 23:08:39.910507 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:39.910511 44210 net.cpp:165] Memory required for data: 4565422080
I0824 23:08:39.910517 44210 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 23:08:39.910524 44210 net.cpp:100] Creating Layer relu2_1_D
I0824 23:08:39.910529 44210 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 23:08:39.910552 44210 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 23:08:39.910786 44210 net.cpp:150] Setting up relu2_1_D
I0824 23:08:39.910796 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:39.910801 44210 net.cpp:165] Memory required for data: 4609658880
I0824 23:08:39.910805 44210 layer_factory.hpp:77] Creating layer upsample1
I0824 23:08:39.910815 44210 net.cpp:100] Creating Layer upsample1
I0824 23:08:39.910820 44210 net.cpp:434] upsample1 <- conv2_1_D
I0824 23:08:39.910825 44210 net.cpp:434] upsample1 <- pool1_mask
I0824 23:08:39.910832 44210 net.cpp:408] upsample1 -> pool1_D
I0824 23:08:39.910841 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:39.910879 44210 net.cpp:150] Setting up upsample1
I0824 23:08:39.910887 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:39.910889 44210 net.cpp:165] Memory required for data: 4786606080
I0824 23:08:39.910893 44210 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 23:08:39.910907 44210 net.cpp:100] Creating Layer conv1_2_D
I0824 23:08:39.910912 44210 net.cpp:434] conv1_2_D <- pool1_D
I0824 23:08:39.910918 44210 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 23:08:39.915745 44210 net.cpp:150] Setting up conv1_2_D
I0824 23:08:39.915761 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:39.915771 44210 net.cpp:165] Memory required for data: 4963553280
I0824 23:08:39.915778 44210 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 23:08:39.915788 44210 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 23:08:39.915794 44210 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 23:08:39.915801 44210 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 23:08:39.916241 44210 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 23:08:39.916250 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:39.916254 44210 net.cpp:165] Memory required for data: 5140500480
I0824 23:08:39.916262 44210 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 23:08:39.916272 44210 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 23:08:39.916278 44210 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 23:08:39.916285 44210 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 23:08:39.916344 44210 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 23:08:39.918238 44210 net.cpp:150] Setting up conv1_2_D_scale
I0824 23:08:39.918254 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:39.918259 44210 net.cpp:165] Memory required for data: 5317447680
I0824 23:08:39.918267 44210 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 23:08:39.918278 44210 net.cpp:100] Creating Layer relu1_2_D
I0824 23:08:39.918283 44210 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 23:08:39.918292 44210 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 23:08:39.918537 44210 net.cpp:150] Setting up relu1_2_D
I0824 23:08:39.918546 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:39.918552 44210 net.cpp:165] Memory required for data: 5494394880
I0824 23:08:39.918556 44210 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 23:08:39.918570 44210 net.cpp:100] Creating Layer conv1_1_1_D
I0824 23:08:39.918575 44210 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 23:08:39.918583 44210 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 23:08:39.920814 44210 net.cpp:150] Setting up conv1_1_1_D
I0824 23:08:39.920830 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:39.920835 44210 net.cpp:165] Memory required for data: 5499924480
I0824 23:08:39.920842 44210 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:39.920852 44210 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:39.920861 44210 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 23:08:39.920866 44210 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 23:08:39.920876 44210 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 23:08:39.920953 44210 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:39.920961 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:39.920965 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:39.920970 44210 net.cpp:165] Memory required for data: 5510983680
I0824 23:08:39.920974 44210 layer_factory.hpp:77] Creating layer loss
I0824 23:08:39.920984 44210 net.cpp:100] Creating Layer loss
I0824 23:08:39.920989 44210 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 23:08:39.920994 44210 net.cpp:434] loss <- label_data_1_split_0
I0824 23:08:39.921002 44210 net.cpp:408] loss -> loss
I0824 23:08:39.921013 44210 layer_factory.hpp:77] Creating layer loss
I0824 23:08:39.925277 44210 net.cpp:150] Setting up loss
I0824 23:08:39.925293 44210 net.cpp:157] Top shape: (1)
I0824 23:08:39.925297 44210 net.cpp:160]     with loss weight 1
I0824 23:08:39.925317 44210 net.cpp:165] Memory required for data: 5510983684
I0824 23:08:39.925320 44210 layer_factory.hpp:77] Creating layer accuracy
I0824 23:08:39.925329 44210 net.cpp:100] Creating Layer accuracy
I0824 23:08:39.925338 44210 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 23:08:39.925348 44210 net.cpp:434] accuracy <- label_data_1_split_1
I0824 23:08:39.925356 44210 net.cpp:408] accuracy -> accuracy
I0824 23:08:39.925381 44210 net.cpp:408] accuracy -> per_class_accuracy
I0824 23:08:39.925442 44210 net.cpp:150] Setting up accuracy
I0824 23:08:39.925449 44210 net.cpp:157] Top shape: (1)
I0824 23:08:39.925454 44210 net.cpp:157] Top shape: 2 (2)
I0824 23:08:39.925458 44210 net.cpp:165] Memory required for data: 5510983696
I0824 23:08:39.925462 44210 net.cpp:228] accuracy does not need backward computation.
I0824 23:08:39.925467 44210 net.cpp:226] loss needs backward computation.
I0824 23:08:39.925472 44210 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 23:08:39.925475 44210 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 23:08:39.925479 44210 net.cpp:226] relu1_2_D needs backward computation.
I0824 23:08:39.925482 44210 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 23:08:39.925485 44210 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 23:08:39.925488 44210 net.cpp:226] conv1_2_D needs backward computation.
I0824 23:08:39.925493 44210 net.cpp:226] upsample1 needs backward computation.
I0824 23:08:39.925496 44210 net.cpp:226] relu2_1_D needs backward computation.
I0824 23:08:39.925499 44210 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 23:08:39.925503 44210 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 23:08:39.925505 44210 net.cpp:226] conv2_1_D needs backward computation.
I0824 23:08:39.925509 44210 net.cpp:226] relu2_2_D needs backward computation.
I0824 23:08:39.925513 44210 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 23:08:39.925515 44210 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 23:08:39.925518 44210 net.cpp:226] conv2_2_D needs backward computation.
I0824 23:08:39.925521 44210 net.cpp:226] upsample2 needs backward computation.
I0824 23:08:39.925525 44210 net.cpp:226] relu3_1_D needs backward computation.
I0824 23:08:39.925529 44210 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 23:08:39.925531 44210 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 23:08:39.925534 44210 net.cpp:226] conv3_1_D needs backward computation.
I0824 23:08:39.925539 44210 net.cpp:226] relu3_2_D needs backward computation.
I0824 23:08:39.925541 44210 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 23:08:39.925545 44210 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 23:08:39.925550 44210 net.cpp:226] conv3_2_D needs backward computation.
I0824 23:08:39.925554 44210 net.cpp:226] relu3_3_D needs backward computation.
I0824 23:08:39.925556 44210 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 23:08:39.925559 44210 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 23:08:39.925576 44210 net.cpp:226] conv3_3_D needs backward computation.
I0824 23:08:39.925581 44210 net.cpp:226] upsample3 needs backward computation.
I0824 23:08:39.925586 44210 net.cpp:226] relu4_1_D needs backward computation.
I0824 23:08:39.925592 44210 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 23:08:39.925595 44210 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 23:08:39.925599 44210 net.cpp:226] conv4_1_D needs backward computation.
I0824 23:08:39.925604 44210 net.cpp:226] relu4_2_D needs backward computation.
I0824 23:08:39.925607 44210 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 23:08:39.925612 44210 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 23:08:39.925617 44210 net.cpp:226] conv4_2_D needs backward computation.
I0824 23:08:39.925621 44210 net.cpp:226] relu4_3_D needs backward computation.
I0824 23:08:39.925626 44210 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 23:08:39.925629 44210 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 23:08:39.925633 44210 net.cpp:226] conv4_3_D needs backward computation.
I0824 23:08:39.925637 44210 net.cpp:226] upsample4 needs backward computation.
I0824 23:08:39.925642 44210 net.cpp:226] relu5_1_D needs backward computation.
I0824 23:08:39.925647 44210 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 23:08:39.925650 44210 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 23:08:39.925655 44210 net.cpp:226] conv5_1_D needs backward computation.
I0824 23:08:39.925658 44210 net.cpp:226] relu5_2_D needs backward computation.
I0824 23:08:39.925664 44210 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 23:08:39.925668 44210 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 23:08:39.925671 44210 net.cpp:226] conv5_2_D needs backward computation.
I0824 23:08:39.925675 44210 net.cpp:226] relu5_3_D needs backward computation.
I0824 23:08:39.925679 44210 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 23:08:39.925683 44210 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 23:08:39.925685 44210 net.cpp:226] conv5_3_D needs backward computation.
I0824 23:08:39.925689 44210 net.cpp:226] upsample5 needs backward computation.
I0824 23:08:39.925694 44210 net.cpp:226] pool5 needs backward computation.
I0824 23:08:39.925699 44210 net.cpp:226] relu5_3 needs backward computation.
I0824 23:08:39.925704 44210 net.cpp:226] conv5_3_scale needs backward computation.
I0824 23:08:39.925709 44210 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 23:08:39.925712 44210 net.cpp:226] conv5_3 needs backward computation.
I0824 23:08:39.925716 44210 net.cpp:226] relu5_2 needs backward computation.
I0824 23:08:39.925719 44210 net.cpp:226] conv5_2_scale needs backward computation.
I0824 23:08:39.925724 44210 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 23:08:39.925727 44210 net.cpp:226] conv5_2 needs backward computation.
I0824 23:08:39.925731 44210 net.cpp:226] relu5_1 needs backward computation.
I0824 23:08:39.925736 44210 net.cpp:226] conv5_1_scale needs backward computation.
I0824 23:08:39.925740 44210 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 23:08:39.925743 44210 net.cpp:226] conv5_1 needs backward computation.
I0824 23:08:39.925747 44210 net.cpp:226] pool4 needs backward computation.
I0824 23:08:39.925751 44210 net.cpp:226] relu4_3 needs backward computation.
I0824 23:08:39.925755 44210 net.cpp:226] conv4_3_scale needs backward computation.
I0824 23:08:39.925758 44210 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 23:08:39.925762 44210 net.cpp:226] conv4_3 needs backward computation.
I0824 23:08:39.925767 44210 net.cpp:226] relu4_2 needs backward computation.
I0824 23:08:39.925772 44210 net.cpp:226] conv4_2_scale needs backward computation.
I0824 23:08:39.925776 44210 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 23:08:39.925786 44210 net.cpp:226] conv4_2 needs backward computation.
I0824 23:08:39.925792 44210 net.cpp:226] relu4_1 needs backward computation.
I0824 23:08:39.925806 44210 net.cpp:226] conv4_1_scale needs backward computation.
I0824 23:08:39.925809 44210 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 23:08:39.925813 44210 net.cpp:226] conv4_1 needs backward computation.
I0824 23:08:39.925817 44210 net.cpp:226] pool3 needs backward computation.
I0824 23:08:39.925820 44210 net.cpp:226] relu3_3 needs backward computation.
I0824 23:08:39.925824 44210 net.cpp:226] conv3_3_scale needs backward computation.
I0824 23:08:39.925827 44210 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 23:08:39.925837 44210 net.cpp:226] conv3_3 needs backward computation.
I0824 23:08:39.925843 44210 net.cpp:226] relu3_2 needs backward computation.
I0824 23:08:39.925845 44210 net.cpp:226] conv3_2_scale needs backward computation.
I0824 23:08:39.925849 44210 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 23:08:39.925858 44210 net.cpp:226] conv3_2 needs backward computation.
I0824 23:08:39.925863 44210 net.cpp:226] relu3_1 needs backward computation.
I0824 23:08:39.925866 44210 net.cpp:226] conv3_1_scale needs backward computation.
I0824 23:08:39.925869 44210 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 23:08:39.925873 44210 net.cpp:226] conv3_1 needs backward computation.
I0824 23:08:39.925879 44210 net.cpp:226] pool2 needs backward computation.
I0824 23:08:39.925884 44210 net.cpp:226] relu2_2 needs backward computation.
I0824 23:08:39.925887 44210 net.cpp:226] conv2_2_scale needs backward computation.
I0824 23:08:39.925894 44210 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 23:08:39.925901 44210 net.cpp:226] conv2_2 needs backward computation.
I0824 23:08:39.925906 44210 net.cpp:226] relu2_1 needs backward computation.
I0824 23:08:39.925910 44210 net.cpp:226] conv2_1_scale needs backward computation.
I0824 23:08:39.925914 44210 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 23:08:39.925917 44210 net.cpp:226] conv2_1 needs backward computation.
I0824 23:08:39.925922 44210 net.cpp:226] pool1 needs backward computation.
I0824 23:08:39.925926 44210 net.cpp:226] relu1_2 needs backward computation.
I0824 23:08:39.925931 44210 net.cpp:226] conv1_2_scale needs backward computation.
I0824 23:08:39.925937 44210 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 23:08:39.925941 44210 net.cpp:226] conv1_2 needs backward computation.
I0824 23:08:39.925951 44210 net.cpp:226] relu1_1 needs backward computation.
I0824 23:08:39.925956 44210 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 23:08:39.925958 44210 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 23:08:39.925962 44210 net.cpp:226] conv1_1_1 needs backward computation.
I0824 23:08:39.925967 44210 net.cpp:228] label_data_1_split does not need backward computation.
I0824 23:08:39.925973 44210 net.cpp:228] data does not need backward computation.
I0824 23:08:39.925976 44210 net.cpp:270] This network produces output accuracy
I0824 23:08:39.925981 44210 net.cpp:270] This network produces output loss
I0824 23:08:39.925984 44210 net.cpp:270] This network produces output per_class_accuracy
I0824 23:08:39.926048 44210 net.cpp:283] Network initialization done.
I0824 23:08:39.926533 44210 solver.cpp:60] Solver scaffolding done.
I0824 23:08:39.935967 44210 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0824 23:08:40.364194 44210 net.cpp:761] Ignoring source layer conv1_1
I0824 23:08:40.364213 44210 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 23:08:40.364276 44210 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 23:08:40.364285 44210 net.cpp:761] Ignoring source layer pool1_drop
I0824 23:08:40.364372 44210 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 23:08:40.364533 44210 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 23:08:40.364540 44210 net.cpp:761] Ignoring source layer pool2_drop
I0824 23:08:40.364830 44210 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 23:08:40.365408 44210 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 23:08:40.365983 44210 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 23:08:40.366008 44210 net.cpp:761] Ignoring source layer pool3_drop
I0824 23:08:40.367115 44210 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 23:08:40.369323 44210 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 23:08:40.371541 44210 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 23:08:40.371551 44210 net.cpp:761] Ignoring source layer pool4_drop
I0824 23:08:40.373762 44210 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 23:08:40.375985 44210 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 23:08:40.378227 44210 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 23:08:40.378235 44210 net.cpp:761] Ignoring source layer pool5_drop
I0824 23:08:40.378240 44210 net.cpp:761] Ignoring source layer upsample5_drop
I0824 23:08:40.380452 44210 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 23:08:40.382688 44210 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 23:08:40.384856 44210 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 23:08:40.384867 44210 net.cpp:761] Ignoring source layer upsample4_drop
I0824 23:08:40.386893 44210 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 23:08:40.389029 44210 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 23:08:40.390197 44210 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 23:08:40.390206 44210 net.cpp:761] Ignoring source layer upsample3_drop
I0824 23:08:40.390781 44210 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 23:08:40.391355 44210 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 23:08:40.391660 44210 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 23:08:40.391667 44210 net.cpp:761] Ignoring source layer upsample2_drop
I0824 23:08:40.391825 44210 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 23:08:40.391912 44210 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 23:08:40.391921 44210 net.cpp:761] Ignoring source layer upsample1_drop
I0824 23:08:40.391968 44210 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 23:08:40.391973 44210 net.cpp:761] Ignoring source layer conv1_1_D
I0824 23:08:40.391978 44210 net.cpp:761] Ignoring source layer prob
I0824 23:08:40.695796 44210 net.cpp:761] Ignoring source layer conv1_1
I0824 23:08:40.695823 44210 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 23:08:40.695875 44210 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 23:08:40.695881 44210 net.cpp:761] Ignoring source layer pool1_drop
I0824 23:08:40.695960 44210 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 23:08:40.696111 44210 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 23:08:40.696118 44210 net.cpp:761] Ignoring source layer pool2_drop
I0824 23:08:40.696419 44210 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 23:08:40.697006 44210 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 23:08:40.697609 44210 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 23:08:40.697616 44210 net.cpp:761] Ignoring source layer pool3_drop
I0824 23:08:40.698688 44210 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 23:08:40.700747 44210 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 23:08:40.702816 44210 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 23:08:40.702826 44210 net.cpp:761] Ignoring source layer pool4_drop
I0824 23:08:40.704890 44210 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 23:08:40.706970 44210 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 23:08:40.709046 44210 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 23:08:40.709055 44210 net.cpp:761] Ignoring source layer pool5_drop
I0824 23:08:40.709059 44210 net.cpp:761] Ignoring source layer upsample5_drop
I0824 23:08:40.711143 44210 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 23:08:40.713224 44210 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 23:08:40.715319 44210 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 23:08:40.715328 44210 net.cpp:761] Ignoring source layer upsample4_drop
I0824 23:08:40.717614 44210 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 23:08:40.719894 44210 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 23:08:40.721065 44210 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 23:08:40.721074 44210 net.cpp:761] Ignoring source layer upsample3_drop
I0824 23:08:40.721658 44210 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 23:08:40.722306 44210 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 23:08:40.722604 44210 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 23:08:40.722611 44210 net.cpp:761] Ignoring source layer upsample2_drop
I0824 23:08:40.722764 44210 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 23:08:40.722847 44210 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 23:08:40.722853 44210 net.cpp:761] Ignoring source layer upsample1_drop
I0824 23:08:40.722896 44210 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 23:08:40.722903 44210 net.cpp:761] Ignoring source layer conv1_1_D
I0824 23:08:40.722908 44210 net.cpp:761] Ignoring source layer prob
I0824 23:08:40.731330 44210 caffe.cpp:251] Starting Optimization
I0824 23:08:40.731350 44210 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0824 23:08:40.731355 44210 solver.cpp:280] Learning Rate Policy: step
I0824 23:08:41.820837 44210 solver.cpp:228] Iteration 0, loss = 0.733806
I0824 23:08:41.820881 44210 solver.cpp:244]     Train net output #0: accuracy = 0.583604
I0824 23:08:41.820894 44210 solver.cpp:244]     Train net output #1: loss = 0.733806 (* 1 = 0.733806 loss)
I0824 23:08:41.820901 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.614179
I0824 23:08:41.820905 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.430134
I0824 23:08:41.820929 44210 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0824 23:09:00.755303 44210 solver.cpp:228] Iteration 20, loss = 0.483828
I0824 23:09:00.755353 44210 solver.cpp:244]     Train net output #0: accuracy = 0.682053
I0824 23:09:00.755367 44210 solver.cpp:244]     Train net output #1: loss = 0.483828 (* 1 = 0.483828 loss)
I0824 23:09:00.755374 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.646236
I0824 23:09:00.755378 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.878325
I0824 23:09:00.755386 44210 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0824 23:09:17.379230 44210 solver.cpp:228] Iteration 40, loss = 0.485339
I0824 23:09:17.379389 44210 solver.cpp:244]     Train net output #0: accuracy = 0.636534
I0824 23:09:17.379405 44210 solver.cpp:244]     Train net output #1: loss = 0.485339 (* 1 = 0.485339 loss)
I0824 23:09:17.379410 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.632187
I0824 23:09:17.379415 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.710945
I0824 23:09:17.379423 44210 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0824 23:09:34.012181 44210 solver.cpp:228] Iteration 60, loss = 0.325711
I0824 23:09:34.012230 44210 solver.cpp:244]     Train net output #0: accuracy = 0.889521
I0824 23:09:34.012243 44210 solver.cpp:244]     Train net output #1: loss = 0.325711 (* 1 = 0.325711 loss)
I0824 23:09:34.012249 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.898684
I0824 23:09:34.012254 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.874768
I0824 23:09:34.012262 44210 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0824 23:09:50.619493 44210 solver.cpp:228] Iteration 80, loss = 0.37178
I0824 23:09:50.619645 44210 solver.cpp:244]     Train net output #0: accuracy = 0.82167
I0824 23:09:50.619666 44210 solver.cpp:244]     Train net output #1: loss = 0.37178 (* 1 = 0.37178 loss)
I0824 23:09:50.619674 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.80969
I0824 23:09:50.619679 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.858202
I0824 23:09:50.619688 44210 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0824 23:10:07.247624 44210 solver.cpp:228] Iteration 100, loss = 0.207385
I0824 23:10:07.247674 44210 solver.cpp:244]     Train net output #0: accuracy = 0.939125
I0824 23:10:07.247687 44210 solver.cpp:244]     Train net output #1: loss = 0.207385 (* 1 = 0.207385 loss)
I0824 23:10:07.247694 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.935902
I0824 23:10:07.247699 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.945559
I0824 23:10:07.247706 44210 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0824 23:10:23.878125 44210 solver.cpp:228] Iteration 120, loss = 0.186188
I0824 23:10:23.878286 44210 solver.cpp:244]     Train net output #0: accuracy = 0.923131
I0824 23:10:23.878304 44210 solver.cpp:244]     Train net output #1: loss = 0.186188 (* 1 = 0.186188 loss)
I0824 23:10:23.878311 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.911759
I0824 23:10:23.878316 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.960648
I0824 23:10:23.878329 44210 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0824 23:10:40.495554 44210 solver.cpp:228] Iteration 140, loss = 0.282919
I0824 23:10:40.495601 44210 solver.cpp:244]     Train net output #0: accuracy = 0.911353
I0824 23:10:40.495615 44210 solver.cpp:244]     Train net output #1: loss = 0.282919 (* 1 = 0.282919 loss)
I0824 23:10:40.495621 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977657
I0824 23:10:40.495626 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.817041
I0824 23:10:40.495635 44210 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0824 23:10:57.133512 44210 solver.cpp:228] Iteration 160, loss = 0.247097
I0824 23:10:57.133631 44210 solver.cpp:244]     Train net output #0: accuracy = 0.924787
I0824 23:10:57.133652 44210 solver.cpp:244]     Train net output #1: loss = 0.247097 (* 1 = 0.247097 loss)
I0824 23:10:57.133661 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990806
I0824 23:10:57.133666 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.790549
I0824 23:10:57.133672 44210 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0824 23:11:13.762153 44210 solver.cpp:228] Iteration 180, loss = 0.254152
I0824 23:11:13.762199 44210 solver.cpp:244]     Train net output #0: accuracy = 0.929916
I0824 23:11:13.762214 44210 solver.cpp:244]     Train net output #1: loss = 0.254152 (* 1 = 0.254152 loss)
I0824 23:11:13.762228 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.96941
I0824 23:11:13.762234 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.863261
I0824 23:11:13.762243 44210 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0824 23:11:30.385151 44210 solver.cpp:228] Iteration 200, loss = 0.191782
I0824 23:11:30.385267 44210 solver.cpp:244]     Train net output #0: accuracy = 0.907995
I0824 23:11:30.385282 44210 solver.cpp:244]     Train net output #1: loss = 0.191782 (* 1 = 0.191782 loss)
I0824 23:11:30.385288 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.898643
I0824 23:11:30.385293 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.952275
I0824 23:11:30.385300 44210 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0824 23:11:47.031513 44210 solver.cpp:228] Iteration 220, loss = 0.141058
I0824 23:11:47.031556 44210 solver.cpp:244]     Train net output #0: accuracy = 0.951613
I0824 23:11:47.031568 44210 solver.cpp:244]     Train net output #1: loss = 0.141058 (* 1 = 0.141058 loss)
I0824 23:11:47.031574 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.953609
I0824 23:11:47.031579 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.946737
I0824 23:11:47.031586 44210 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0824 23:12:03.663853 44210 solver.cpp:228] Iteration 240, loss = 0.0676143
I0824 23:12:03.663995 44210 solver.cpp:244]     Train net output #0: accuracy = 0.978882
I0824 23:12:03.664021 44210 solver.cpp:244]     Train net output #1: loss = 0.0676142 (* 1 = 0.0676142 loss)
I0824 23:12:03.664029 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980512
I0824 23:12:03.664033 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.974417
I0824 23:12:03.664041 44210 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0824 23:12:20.288956 44210 solver.cpp:228] Iteration 260, loss = 0.141707
I0824 23:12:20.289002 44210 solver.cpp:244]     Train net output #0: accuracy = 0.92929
I0824 23:12:20.289016 44210 solver.cpp:244]     Train net output #1: loss = 0.141707 (* 1 = 0.141707 loss)
I0824 23:12:20.289022 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.925492
I0824 23:12:20.289036 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.949118
I0824 23:12:20.289043 44210 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0824 23:12:36.914073 44210 solver.cpp:228] Iteration 280, loss = 0.0908463
I0824 23:12:36.914271 44210 solver.cpp:244]     Train net output #0: accuracy = 0.968138
I0824 23:12:36.914289 44210 solver.cpp:244]     Train net output #1: loss = 0.0908463 (* 1 = 0.0908463 loss)
I0824 23:12:36.914299 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972439
I0824 23:12:36.914304 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.957388
I0824 23:12:36.914310 44210 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0824 23:12:53.721305 44210 solver.cpp:228] Iteration 300, loss = 0.115633
I0824 23:12:53.721354 44210 solver.cpp:244]     Train net output #0: accuracy = 0.961957
I0824 23:12:53.721372 44210 solver.cpp:244]     Train net output #1: loss = 0.115633 (* 1 = 0.115633 loss)
I0824 23:12:53.721379 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.964981
I0824 23:12:53.721384 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.954348
I0824 23:12:53.721390 44210 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0824 23:13:10.342118 44210 solver.cpp:228] Iteration 320, loss = 0.0689311
I0824 23:13:10.342258 44210 solver.cpp:244]     Train net output #0: accuracy = 0.971221
I0824 23:13:10.342274 44210 solver.cpp:244]     Train net output #1: loss = 0.0689311 (* 1 = 0.0689311 loss)
I0824 23:13:10.342280 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.96663
I0824 23:13:10.342286 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982374
I0824 23:13:10.342294 44210 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0824 23:13:26.963672 44210 solver.cpp:228] Iteration 340, loss = 0.0709022
I0824 23:13:26.963719 44210 solver.cpp:244]     Train net output #0: accuracy = 0.974446
I0824 23:13:26.963734 44210 solver.cpp:244]     Train net output #1: loss = 0.0709022 (* 1 = 0.0709022 loss)
I0824 23:13:26.963740 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972717
I0824 23:13:26.963745 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.977523
I0824 23:13:26.963752 44210 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0824 23:13:43.587692 44210 solver.cpp:228] Iteration 360, loss = 0.0644762
I0824 23:13:43.587824 44210 solver.cpp:244]     Train net output #0: accuracy = 0.974207
I0824 23:13:43.587841 44210 solver.cpp:244]     Train net output #1: loss = 0.0644762 (* 1 = 0.0644762 loss)
I0824 23:13:43.587851 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.968572
I0824 23:13:43.587854 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98663
I0824 23:13:43.587862 44210 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0824 23:14:00.220765 44210 solver.cpp:228] Iteration 380, loss = 0.0845994
I0824 23:14:00.220809 44210 solver.cpp:244]     Train net output #0: accuracy = 0.971564
I0824 23:14:00.220824 44210 solver.cpp:244]     Train net output #1: loss = 0.0845993 (* 1 = 0.0845993 loss)
I0824 23:14:00.220829 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985419
I0824 23:14:00.220834 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.944256
I0824 23:14:00.220840 44210 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0824 23:14:16.837371 44210 solver.cpp:228] Iteration 400, loss = 0.106256
I0824 23:14:16.837496 44210 solver.cpp:244]     Train net output #0: accuracy = 0.955085
I0824 23:14:16.837512 44210 solver.cpp:244]     Train net output #1: loss = 0.106256 (* 1 = 0.106256 loss)
I0824 23:14:16.837517 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.948631
I0824 23:14:16.837522 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987985
I0824 23:14:16.837529 44210 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0824 23:14:33.491046 44210 solver.cpp:228] Iteration 420, loss = 0.047781
I0824 23:14:33.491091 44210 solver.cpp:244]     Train net output #0: accuracy = 0.982273
I0824 23:14:33.491103 44210 solver.cpp:244]     Train net output #1: loss = 0.047781 (* 1 = 0.047781 loss)
I0824 23:14:33.491109 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980435
I0824 23:14:33.491116 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986446
I0824 23:14:33.491122 44210 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0824 23:14:50.110047 44210 solver.cpp:228] Iteration 440, loss = 0.053097
I0824 23:14:50.110266 44210 solver.cpp:244]     Train net output #0: accuracy = 0.979554
I0824 23:14:50.110282 44210 solver.cpp:244]     Train net output #1: loss = 0.053097 (* 1 = 0.053097 loss)
I0824 23:14:50.110291 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977736
I0824 23:14:50.110296 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985131
I0824 23:14:50.110303 44210 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0824 23:15:06.729490 44210 solver.cpp:228] Iteration 460, loss = 0.0436465
I0824 23:15:06.729537 44210 solver.cpp:244]     Train net output #0: accuracy = 0.9872
I0824 23:15:06.729549 44210 solver.cpp:244]     Train net output #1: loss = 0.0436464 (* 1 = 0.0436464 loss)
I0824 23:15:06.729557 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990285
I0824 23:15:06.729562 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98079
I0824 23:15:06.729568 44210 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0824 23:15:23.331383 44210 solver.cpp:228] Iteration 480, loss = 0.0595345
I0824 23:15:23.331511 44210 solver.cpp:244]     Train net output #0: accuracy = 0.972993
I0824 23:15:23.331527 44210 solver.cpp:244]     Train net output #1: loss = 0.0595344 (* 1 = 0.0595344 loss)
I0824 23:15:23.331533 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969368
I0824 23:15:23.331538 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98517
I0824 23:15:23.331545 44210 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0824 23:15:39.955260 44210 solver.cpp:228] Iteration 500, loss = 0.0469334
I0824 23:15:39.955307 44210 solver.cpp:244]     Train net output #0: accuracy = 0.983419
I0824 23:15:39.955322 44210 solver.cpp:244]     Train net output #1: loss = 0.0469333 (* 1 = 0.0469333 loss)
I0824 23:15:39.955327 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985096
I0824 23:15:39.955332 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978556
I0824 23:15:39.955338 44210 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0824 23:15:56.567229 44210 solver.cpp:228] Iteration 520, loss = 0.0527975
I0824 23:15:56.567364 44210 solver.cpp:244]     Train net output #0: accuracy = 0.977159
I0824 23:15:56.567379 44210 solver.cpp:244]     Train net output #1: loss = 0.0527974 (* 1 = 0.0527974 loss)
I0824 23:15:56.567385 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973389
I0824 23:15:56.567390 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98746
I0824 23:15:56.567397 44210 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0824 23:16:13.187294 44210 solver.cpp:228] Iteration 540, loss = 0.0728903
I0824 23:16:13.187342 44210 solver.cpp:244]     Train net output #0: accuracy = 0.971798
I0824 23:16:13.187355 44210 solver.cpp:244]     Train net output #1: loss = 0.0728902 (* 1 = 0.0728902 loss)
I0824 23:16:13.187360 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.968405
I0824 23:16:13.187364 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979355
I0824 23:16:13.187372 44210 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0824 23:16:29.798708 44210 solver.cpp:228] Iteration 560, loss = 0.0538692
I0824 23:16:29.798895 44210 solver.cpp:244]     Train net output #0: accuracy = 0.977985
I0824 23:16:29.798918 44210 solver.cpp:244]     Train net output #1: loss = 0.0538691 (* 1 = 0.0538691 loss)
I0824 23:16:29.798924 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969747
I0824 23:16:29.798929 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992156
I0824 23:16:29.798941 44210 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0824 23:16:46.411001 44210 solver.cpp:228] Iteration 580, loss = 0.0384053
I0824 23:16:46.411044 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986318
I0824 23:16:46.411057 44210 solver.cpp:244]     Train net output #1: loss = 0.0384053 (* 1 = 0.0384053 loss)
I0824 23:16:46.411063 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987253
I0824 23:16:46.411067 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982718
I0824 23:16:46.411074 44210 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0824 23:17:03.017498 44210 solver.cpp:228] Iteration 600, loss = 0.0727702
I0824 23:17:03.017624 44210 solver.cpp:244]     Train net output #0: accuracy = 0.97526
I0824 23:17:03.017640 44210 solver.cpp:244]     Train net output #1: loss = 0.0727701 (* 1 = 0.0727701 loss)
I0824 23:17:03.017647 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980947
I0824 23:17:03.017652 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.946691
I0824 23:17:03.017662 44210 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0824 23:17:19.620561 44210 solver.cpp:228] Iteration 620, loss = 0.0343988
I0824 23:17:19.620604 44210 solver.cpp:244]     Train net output #0: accuracy = 0.987183
I0824 23:17:19.620615 44210 solver.cpp:244]     Train net output #1: loss = 0.0343987 (* 1 = 0.0343987 loss)
I0824 23:17:19.620621 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98846
I0824 23:17:19.620626 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981089
I0824 23:17:19.620635 44210 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0824 23:17:36.233618 44210 solver.cpp:228] Iteration 640, loss = 0.0420002
I0824 23:17:36.233749 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986836
I0824 23:17:36.233763 44210 solver.cpp:244]     Train net output #1: loss = 0.0420001 (* 1 = 0.0420001 loss)
I0824 23:17:36.233769 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989605
I0824 23:17:36.233774 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976527
I0824 23:17:36.233780 44210 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0824 23:17:52.846823 44210 solver.cpp:228] Iteration 660, loss = 0.040764
I0824 23:17:52.846865 44210 solver.cpp:244]     Train net output #0: accuracy = 0.982109
I0824 23:17:52.846879 44210 solver.cpp:244]     Train net output #1: loss = 0.0407639 (* 1 = 0.0407639 loss)
I0824 23:17:52.846884 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980427
I0824 23:17:52.846889 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9873
I0824 23:17:52.846896 44210 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0824 23:18:09.469231 44210 solver.cpp:228] Iteration 680, loss = 0.0369429
I0824 23:18:09.469352 44210 solver.cpp:244]     Train net output #0: accuracy = 0.985376
I0824 23:18:09.469373 44210 solver.cpp:244]     Train net output #1: loss = 0.0369429 (* 1 = 0.0369429 loss)
I0824 23:18:09.469380 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982798
I0824 23:18:09.469385 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991001
I0824 23:18:09.469393 44210 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0824 23:18:26.081450 44210 solver.cpp:228] Iteration 700, loss = 0.163663
I0824 23:18:26.081491 44210 solver.cpp:244]     Train net output #0: accuracy = 0.952934
I0824 23:18:26.081502 44210 solver.cpp:244]     Train net output #1: loss = 0.163663 (* 1 = 0.163663 loss)
I0824 23:18:26.081511 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98572
I0824 23:18:26.081516 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.857177
I0824 23:18:26.081522 44210 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0824 23:18:42.694874 44210 solver.cpp:228] Iteration 720, loss = 0.0663919
I0824 23:18:42.695031 44210 solver.cpp:244]     Train net output #0: accuracy = 0.982209
I0824 23:18:42.695049 44210 solver.cpp:244]     Train net output #1: loss = 0.0663918 (* 1 = 0.0663918 loss)
I0824 23:18:42.695055 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993472
I0824 23:18:42.695058 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.963239
I0824 23:18:42.695066 44210 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0824 23:18:59.310497 44210 solver.cpp:228] Iteration 740, loss = 0.0352414
I0824 23:18:59.310539 44210 solver.cpp:244]     Train net output #0: accuracy = 0.984783
I0824 23:18:59.310550 44210 solver.cpp:244]     Train net output #1: loss = 0.0352413 (* 1 = 0.0352413 loss)
I0824 23:18:59.310556 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98365
I0824 23:18:59.310562 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988703
I0824 23:18:59.310570 44210 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0824 23:19:15.943104 44210 solver.cpp:228] Iteration 760, loss = 0.0349238
I0824 23:19:15.943224 44210 solver.cpp:244]     Train net output #0: accuracy = 0.985651
I0824 23:19:15.943240 44210 solver.cpp:244]     Train net output #1: loss = 0.0349237 (* 1 = 0.0349237 loss)
I0824 23:19:15.943251 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982538
I0824 23:19:15.943258 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99475
I0824 23:19:15.943265 44210 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0824 23:19:32.558012 44210 solver.cpp:228] Iteration 780, loss = 0.0304722
I0824 23:19:32.558056 44210 solver.cpp:244]     Train net output #0: accuracy = 0.988695
I0824 23:19:32.558069 44210 solver.cpp:244]     Train net output #1: loss = 0.0304721 (* 1 = 0.0304721 loss)
I0824 23:19:32.558076 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988885
I0824 23:19:32.558089 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987688
I0824 23:19:32.558096 44210 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0824 23:19:49.187002 44210 solver.cpp:228] Iteration 800, loss = 0.0526581
I0824 23:19:49.187116 44210 solver.cpp:244]     Train net output #0: accuracy = 0.980606
I0824 23:19:49.187131 44210 solver.cpp:244]     Train net output #1: loss = 0.0526581 (* 1 = 0.0526581 loss)
I0824 23:19:49.187144 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980721
I0824 23:19:49.187147 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980376
I0824 23:19:49.187155 44210 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0824 23:20:05.814538 44210 solver.cpp:228] Iteration 820, loss = 0.0376138
I0824 23:20:05.814582 44210 solver.cpp:244]     Train net output #0: accuracy = 0.985372
I0824 23:20:05.814596 44210 solver.cpp:244]     Train net output #1: loss = 0.0376137 (* 1 = 0.0376137 loss)
I0824 23:20:05.814602 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9803
I0824 23:20:05.814606 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993193
I0824 23:20:05.814613 44210 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0824 23:20:22.432809 44210 solver.cpp:228] Iteration 840, loss = 0.0851661
I0824 23:20:22.432924 44210 solver.cpp:244]     Train net output #0: accuracy = 0.976231
I0824 23:20:22.432940 44210 solver.cpp:244]     Train net output #1: loss = 0.0851661 (* 1 = 0.0851661 loss)
I0824 23:20:22.432951 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975465
I0824 23:20:22.432955 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989504
I0824 23:20:22.432962 44210 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0824 23:20:39.058461 44210 solver.cpp:228] Iteration 860, loss = 0.0274111
I0824 23:20:39.058502 44210 solver.cpp:244]     Train net output #0: accuracy = 0.988536
I0824 23:20:39.058514 44210 solver.cpp:244]     Train net output #1: loss = 0.0274111 (* 1 = 0.0274111 loss)
I0824 23:20:39.058521 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987211
I0824 23:20:39.058533 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992762
I0824 23:20:39.058540 44210 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0824 23:20:55.685783 44210 solver.cpp:228] Iteration 880, loss = 0.0403005
I0824 23:20:55.685945 44210 solver.cpp:244]     Train net output #0: accuracy = 0.987124
I0824 23:20:55.685962 44210 solver.cpp:244]     Train net output #1: loss = 0.0403004 (* 1 = 0.0403004 loss)
I0824 23:20:55.685974 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986769
I0824 23:20:55.685979 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987673
I0824 23:20:55.685986 44210 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0824 23:21:12.298741 44210 solver.cpp:228] Iteration 900, loss = 0.0307094
I0824 23:21:12.298785 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989855
I0824 23:21:12.298799 44210 solver.cpp:244]     Train net output #1: loss = 0.0307093 (* 1 = 0.0307093 loss)
I0824 23:21:12.298804 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991098
I0824 23:21:12.298808 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984984
I0824 23:21:12.298815 44210 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0824 23:21:28.901779 44210 solver.cpp:228] Iteration 920, loss = 0.0236842
I0824 23:21:28.901886 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991026
I0824 23:21:28.901902 44210 solver.cpp:244]     Train net output #1: loss = 0.0236841 (* 1 = 0.0236841 loss)
I0824 23:21:28.901908 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991245
I0824 23:21:28.901913 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989928
I0824 23:21:28.901919 44210 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0824 23:21:45.507853 44210 solver.cpp:228] Iteration 940, loss = 0.0271621
I0824 23:21:45.507894 44210 solver.cpp:244]     Train net output #0: accuracy = 0.988105
I0824 23:21:45.507905 44210 solver.cpp:244]     Train net output #1: loss = 0.027162 (* 1 = 0.027162 loss)
I0824 23:21:45.507911 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98524
I0824 23:21:45.507916 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994427
I0824 23:21:45.507923 44210 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0824 23:22:02.274657 44210 solver.cpp:228] Iteration 960, loss = 0.0213186
I0824 23:22:02.274778 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992636
I0824 23:22:02.274794 44210 solver.cpp:244]     Train net output #1: loss = 0.0213185 (* 1 = 0.0213185 loss)
I0824 23:22:02.274801 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995131
I0824 23:22:02.274806 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981209
I0824 23:22:02.274812 44210 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0824 23:22:18.905177 44210 solver.cpp:228] Iteration 980, loss = 0.0252555
I0824 23:22:18.905221 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990088
I0824 23:22:18.905236 44210 solver.cpp:244]     Train net output #1: loss = 0.0252554 (* 1 = 0.0252554 loss)
I0824 23:22:18.905241 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991137
I0824 23:22:18.905246 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986621
I0824 23:22:18.905253 44210 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0824 23:22:35.514134 44210 solver.cpp:228] Iteration 1000, loss = 0.0353197
I0824 23:22:35.514261 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986723
I0824 23:22:35.514276 44210 solver.cpp:244]     Train net output #1: loss = 0.0353197 (* 1 = 0.0353197 loss)
I0824 23:22:35.514288 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985151
I0824 23:22:35.514293 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989286
I0824 23:22:35.514300 44210 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0824 23:22:52.166627 44210 solver.cpp:228] Iteration 1020, loss = 0.0337199
I0824 23:22:52.166682 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986659
I0824 23:22:52.166698 44210 solver.cpp:244]     Train net output #1: loss = 0.0337198 (* 1 = 0.0337198 loss)
I0824 23:22:52.166705 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988966
I0824 23:22:52.166712 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.97827
I0824 23:22:52.166723 44210 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0824 23:23:08.857573 44210 solver.cpp:228] Iteration 1040, loss = 0.0232015
I0824 23:23:08.857861 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990878
I0824 23:23:08.857894 44210 solver.cpp:244]     Train net output #1: loss = 0.0232015 (* 1 = 0.0232015 loss)
I0824 23:23:08.857903 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990896
I0824 23:23:08.857913 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990822
I0824 23:23:08.857919 44210 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0824 23:23:25.483193 44210 solver.cpp:228] Iteration 1060, loss = 0.0237464
I0824 23:23:25.483248 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99111
I0824 23:23:25.483269 44210 solver.cpp:244]     Train net output #1: loss = 0.0237464 (* 1 = 0.0237464 loss)
I0824 23:23:25.483288 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991712
I0824 23:23:25.483299 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989443
I0824 23:23:25.483314 44210 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0824 23:23:42.100529 44210 solver.cpp:228] Iteration 1080, loss = 0.0321298
I0824 23:23:42.100664 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986111
I0824 23:23:42.100680 44210 solver.cpp:244]     Train net output #1: loss = 0.0321297 (* 1 = 0.0321297 loss)
I0824 23:23:42.100687 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98463
I0824 23:23:42.100692 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989239
I0824 23:23:42.100698 44210 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0824 23:23:58.709820 44210 solver.cpp:228] Iteration 1100, loss = 0.0258923
I0824 23:23:58.709870 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990951
I0824 23:23:58.709884 44210 solver.cpp:244]     Train net output #1: loss = 0.0258923 (* 1 = 0.0258923 loss)
I0824 23:23:58.709892 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989723
I0824 23:23:58.709904 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993053
I0824 23:23:58.709911 44210 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0824 23:24:15.316035 44210 solver.cpp:228] Iteration 1120, loss = 0.0257613
I0824 23:24:15.316169 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990185
I0824 23:24:15.316207 44210 solver.cpp:244]     Train net output #1: loss = 0.0257612 (* 1 = 0.0257612 loss)
I0824 23:24:15.316215 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991499
I0824 23:24:15.316226 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978805
I0824 23:24:15.316236 44210 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0824 23:24:32.010740 44210 solver.cpp:228] Iteration 1140, loss = 0.027707
I0824 23:24:32.010808 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990365
I0824 23:24:32.010828 44210 solver.cpp:244]     Train net output #1: loss = 0.0277069 (* 1 = 0.0277069 loss)
I0824 23:24:32.010841 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991847
I0824 23:24:32.010852 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984402
I0824 23:24:32.010869 44210 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0824 23:24:48.705471 44210 solver.cpp:228] Iteration 1160, loss = 0.0384505
I0824 23:24:48.705672 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986927
I0824 23:24:48.705696 44210 solver.cpp:244]     Train net output #1: loss = 0.0384504 (* 1 = 0.0384504 loss)
I0824 23:24:48.705705 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988481
I0824 23:24:48.705718 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984197
I0824 23:24:48.705727 44210 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0824 23:25:05.332430 44210 solver.cpp:228] Iteration 1180, loss = 0.028131
I0824 23:25:05.332474 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989504
I0824 23:25:05.332487 44210 solver.cpp:244]     Train net output #1: loss = 0.0281309 (* 1 = 0.0281309 loss)
I0824 23:25:05.332494 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991364
I0824 23:25:05.332499 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98197
I0824 23:25:05.332509 44210 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0824 23:25:21.960239 44210 solver.cpp:228] Iteration 1200, loss = 0.0135996
I0824 23:25:21.960398 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994149
I0824 23:25:21.960422 44210 solver.cpp:244]     Train net output #1: loss = 0.0135995 (* 1 = 0.0135995 loss)
I0824 23:25:21.960434 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993713
I0824 23:25:21.960446 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995805
I0824 23:25:21.960461 44210 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0824 23:25:38.567454 44210 solver.cpp:228] Iteration 1220, loss = 0.0350264
I0824 23:25:38.567528 44210 solver.cpp:244]     Train net output #0: accuracy = 0.984537
I0824 23:25:38.567544 44210 solver.cpp:244]     Train net output #1: loss = 0.0350264 (* 1 = 0.0350264 loss)
I0824 23:25:38.567559 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982188
I0824 23:25:38.567564 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989744
I0824 23:25:38.567574 44210 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0824 23:25:55.215899 44210 solver.cpp:228] Iteration 1240, loss = 0.0319381
I0824 23:25:55.216032 44210 solver.cpp:244]     Train net output #0: accuracy = 0.988764
I0824 23:25:55.216051 44210 solver.cpp:244]     Train net output #1: loss = 0.031938 (* 1 = 0.031938 loss)
I0824 23:25:55.216060 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988283
I0824 23:25:55.216068 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989467
I0824 23:25:55.216076 44210 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0824 23:26:11.907795 44210 solver.cpp:228] Iteration 1260, loss = 0.0253499
I0824 23:26:11.907897 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990291
I0824 23:26:11.907922 44210 solver.cpp:244]     Train net output #1: loss = 0.0253499 (* 1 = 0.0253499 loss)
I0824 23:26:11.907937 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9892
I0824 23:26:11.907948 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992726
I0824 23:26:11.907964 44210 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0824 23:26:28.583065 44210 solver.cpp:228] Iteration 1280, loss = 0.0321991
I0824 23:26:28.583192 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986816
I0824 23:26:28.583217 44210 solver.cpp:244]     Train net output #1: loss = 0.032199 (* 1 = 0.032199 loss)
I0824 23:26:28.583226 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984404
I0824 23:26:28.583236 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991219
I0824 23:26:28.583245 44210 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0824 23:26:45.275967 44210 solver.cpp:228] Iteration 1300, loss = 0.026284
I0824 23:26:45.276021 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991098
I0824 23:26:45.276041 44210 solver.cpp:244]     Train net output #1: loss = 0.0262839 (* 1 = 0.0262839 loss)
I0824 23:26:45.276051 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993376
I0824 23:26:45.276057 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985405
I0824 23:26:45.276067 44210 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0824 23:27:01.929201 44210 solver.cpp:228] Iteration 1320, loss = 0.0216623
I0824 23:27:01.929378 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990758
I0824 23:27:01.929395 44210 solver.cpp:244]     Train net output #1: loss = 0.0216622 (* 1 = 0.0216622 loss)
I0824 23:27:01.929402 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989395
I0824 23:27:01.929407 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99382
I0824 23:27:01.929417 44210 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0824 23:27:18.546473 44210 solver.cpp:228] Iteration 1340, loss = 0.025499
I0824 23:27:18.546519 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991168
I0824 23:27:18.546535 44210 solver.cpp:244]     Train net output #1: loss = 0.0254989 (* 1 = 0.0254989 loss)
I0824 23:27:18.546541 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994256
I0824 23:27:18.546546 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9795
I0824 23:27:18.546555 44210 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0824 23:27:35.163913 44210 solver.cpp:228] Iteration 1360, loss = 0.0235846
I0824 23:27:35.164059 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990955
I0824 23:27:35.164077 44210 solver.cpp:244]     Train net output #1: loss = 0.0235845 (* 1 = 0.0235845 loss)
I0824 23:27:35.164084 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989768
I0824 23:27:35.164091 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99309
I0824 23:27:35.164106 44210 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0824 23:27:51.769114 44210 solver.cpp:228] Iteration 1380, loss = 0.0211887
I0824 23:27:51.769155 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990891
I0824 23:27:51.769166 44210 solver.cpp:244]     Train net output #1: loss = 0.0211886 (* 1 = 0.0211886 loss)
I0824 23:27:51.769172 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988025
I0824 23:27:51.769177 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996058
I0824 23:27:51.769184 44210 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0824 23:28:08.394165 44210 solver.cpp:228] Iteration 1400, loss = 0.0211976
I0824 23:28:08.394284 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991615
I0824 23:28:08.394299 44210 solver.cpp:244]     Train net output #1: loss = 0.0211975 (* 1 = 0.0211975 loss)
I0824 23:28:08.394305 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989973
I0824 23:28:08.394311 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994406
I0824 23:28:08.394320 44210 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0824 23:28:25.002918 44210 solver.cpp:228] Iteration 1420, loss = 0.0212734
I0824 23:28:25.002959 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991098
I0824 23:28:25.002972 44210 solver.cpp:244]     Train net output #1: loss = 0.0212733 (* 1 = 0.0212733 loss)
I0824 23:28:25.002979 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991677
I0824 23:28:25.002984 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988864
I0824 23:28:25.002990 44210 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0824 23:28:41.617089 44210 solver.cpp:228] Iteration 1440, loss = 0.0243787
I0824 23:28:41.617229 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989343
I0824 23:28:41.617269 44210 solver.cpp:244]     Train net output #1: loss = 0.0243786 (* 1 = 0.0243786 loss)
I0824 23:28:41.617278 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986209
I0824 23:28:41.617290 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995384
I0824 23:28:41.617300 44210 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0824 23:28:58.287729 44210 solver.cpp:228] Iteration 1460, loss = 0.0111283
I0824 23:28:58.287776 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995129
I0824 23:28:58.287807 44210 solver.cpp:244]     Train net output #1: loss = 0.0111282 (* 1 = 0.0111282 loss)
I0824 23:28:58.287822 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994534
I0824 23:28:58.287833 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997073
I0824 23:28:58.287840 44210 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0824 23:29:14.918570 44210 solver.cpp:228] Iteration 1480, loss = 0.0152597
I0824 23:29:14.918730 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995373
I0824 23:29:14.918748 44210 solver.cpp:244]     Train net output #1: loss = 0.0152596 (* 1 = 0.0152596 loss)
I0824 23:29:14.918759 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997268
I0824 23:29:14.918771 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986134
I0824 23:29:14.918779 44210 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0824 23:29:31.535383 44210 solver.cpp:228] Iteration 1500, loss = 0.0182475
I0824 23:29:31.535428 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993844
I0824 23:29:31.535441 44210 solver.cpp:244]     Train net output #1: loss = 0.0182474 (* 1 = 0.0182474 loss)
I0824 23:29:31.535449 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99517
I0824 23:29:31.535454 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990377
I0824 23:29:31.535460 44210 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0824 23:29:48.164643 44210 solver.cpp:228] Iteration 1520, loss = 0.0268044
I0824 23:29:48.164765 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989706
I0824 23:29:48.164783 44210 solver.cpp:244]     Train net output #1: loss = 0.0268044 (* 1 = 0.0268044 loss)
I0824 23:29:48.164790 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99119
I0824 23:29:48.164798 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984019
I0824 23:29:48.164806 44210 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0824 23:30:04.807322 44210 solver.cpp:228] Iteration 1540, loss = 0.0221507
I0824 23:30:04.807366 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993346
I0824 23:30:04.807381 44210 solver.cpp:244]     Train net output #1: loss = 0.0221506 (* 1 = 0.0221506 loss)
I0824 23:30:04.807387 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994363
I0824 23:30:04.807394 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982855
I0824 23:30:04.807401 44210 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0824 23:30:21.451104 44210 solver.cpp:228] Iteration 1560, loss = 0.0264825
I0824 23:30:21.451239 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990216
I0824 23:30:21.451257 44210 solver.cpp:244]     Train net output #1: loss = 0.0264824 (* 1 = 0.0264824 loss)
I0824 23:30:21.451267 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991451
I0824 23:30:21.451280 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98567
I0824 23:30:21.451290 44210 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0824 23:30:38.055479 44210 solver.cpp:228] Iteration 1580, loss = 0.0174983
I0824 23:30:38.055519 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993416
I0824 23:30:38.055534 44210 solver.cpp:244]     Train net output #1: loss = 0.0174983 (* 1 = 0.0174983 loss)
I0824 23:30:38.055541 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992914
I0824 23:30:38.055546 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994569
I0824 23:30:38.055553 44210 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0824 23:30:54.696007 44210 solver.cpp:228] Iteration 1600, loss = 0.0172436
I0824 23:30:54.696136 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993553
I0824 23:30:54.696151 44210 solver.cpp:244]     Train net output #1: loss = 0.0172435 (* 1 = 0.0172435 loss)
I0824 23:30:54.696163 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995178
I0824 23:30:54.696169 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98404
I0824 23:30:54.696178 44210 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0824 23:31:11.312546 44210 solver.cpp:228] Iteration 1620, loss = 0.0204264
I0824 23:31:11.312594 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991288
I0824 23:31:11.312609 44210 solver.cpp:244]     Train net output #1: loss = 0.0204263 (* 1 = 0.0204263 loss)
I0824 23:31:11.312618 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990517
I0824 23:31:11.312623 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992857
I0824 23:31:11.312631 44210 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0824 23:31:27.941830 44210 solver.cpp:228] Iteration 1640, loss = 0.0154647
I0824 23:31:27.941994 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994
I0824 23:31:27.942013 44210 solver.cpp:244]     Train net output #1: loss = 0.0154646 (* 1 = 0.0154646 loss)
I0824 23:31:27.942021 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993333
I0824 23:31:27.942026 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995812
I0824 23:31:27.942034 44210 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0824 23:31:44.572067 44210 solver.cpp:228] Iteration 1660, loss = 0.0146359
I0824 23:31:44.572114 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993721
I0824 23:31:44.572131 44210 solver.cpp:244]     Train net output #1: loss = 0.0146358 (* 1 = 0.0146358 loss)
I0824 23:31:44.572139 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993263
I0824 23:31:44.572144 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995134
I0824 23:31:44.572154 44210 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0824 23:32:01.203583 44210 solver.cpp:228] Iteration 1680, loss = 0.018441
I0824 23:32:01.203711 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992795
I0824 23:32:01.203728 44210 solver.cpp:244]     Train net output #1: loss = 0.018441 (* 1 = 0.018441 loss)
I0824 23:32:01.203735 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994373
I0824 23:32:01.203740 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986533
I0824 23:32:01.203747 44210 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0824 23:32:17.828239 44210 solver.cpp:228] Iteration 1700, loss = 0.0224454
I0824 23:32:17.828279 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991411
I0824 23:32:17.828294 44210 solver.cpp:244]     Train net output #1: loss = 0.0224453 (* 1 = 0.0224453 loss)
I0824 23:32:17.828310 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990568
I0824 23:32:17.828315 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994093
I0824 23:32:17.828322 44210 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0824 23:32:34.459281 44210 solver.cpp:228] Iteration 1720, loss = 0.0189551
I0824 23:32:34.459444 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992603
I0824 23:32:34.459486 44210 solver.cpp:244]     Train net output #1: loss = 0.0189551 (* 1 = 0.0189551 loss)
I0824 23:32:34.459496 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993352
I0824 23:32:34.459506 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990359
I0824 23:32:34.459517 44210 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0824 23:32:51.076565 44210 solver.cpp:228] Iteration 1740, loss = 0.019478
I0824 23:32:51.076613 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991969
I0824 23:32:51.076628 44210 solver.cpp:244]     Train net output #1: loss = 0.019478 (* 1 = 0.019478 loss)
I0824 23:32:51.076635 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990664
I0824 23:32:51.076642 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994926
I0824 23:32:51.076653 44210 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0824 23:33:07.710259 44210 solver.cpp:228] Iteration 1760, loss = 0.0201775
I0824 23:33:07.710455 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991039
I0824 23:33:07.710489 44210 solver.cpp:244]     Train net output #1: loss = 0.0201774 (* 1 = 0.0201774 loss)
I0824 23:33:07.710497 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988681
I0824 23:33:07.710510 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996087
I0824 23:33:07.710520 44210 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0824 23:33:24.335863 44210 solver.cpp:228] Iteration 1780, loss = 0.0168014
I0824 23:33:24.335909 44210 solver.cpp:244]     Train net output #0: accuracy = 0.9923
I0824 23:33:24.335924 44210 solver.cpp:244]     Train net output #1: loss = 0.0168013 (* 1 = 0.0168013 loss)
I0824 23:33:24.335938 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990415
I0824 23:33:24.335944 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996534
I0824 23:33:24.335953 44210 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0824 23:33:40.951401 44210 solver.cpp:228] Iteration 1800, loss = 0.0170099
I0824 23:33:40.951529 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995441
I0824 23:33:40.951546 44210 solver.cpp:244]     Train net output #1: loss = 0.0170098 (* 1 = 0.0170098 loss)
I0824 23:33:40.951555 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99663
I0824 23:33:40.951566 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981517
I0824 23:33:40.951575 44210 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0824 23:33:57.636580 44210 solver.cpp:228] Iteration 1820, loss = 0.0171111
I0824 23:33:57.636637 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992843
I0824 23:33:57.636654 44210 solver.cpp:244]     Train net output #1: loss = 0.017111 (* 1 = 0.017111 loss)
I0824 23:33:57.636662 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991285
I0824 23:33:57.636668 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995793
I0824 23:33:57.636678 44210 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0824 23:34:14.302930 44210 solver.cpp:228] Iteration 1840, loss = 0.0197009
I0824 23:34:14.303061 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989981
I0824 23:34:14.303081 44210 solver.cpp:244]     Train net output #1: loss = 0.0197008 (* 1 = 0.0197008 loss)
I0824 23:34:14.303088 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987587
I0824 23:34:14.303094 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995758
I0824 23:34:14.303104 44210 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0824 23:34:30.915393 44210 solver.cpp:228] Iteration 1860, loss = 0.218776
I0824 23:34:30.915443 44210 solver.cpp:244]     Train net output #0: accuracy = 0.960236
I0824 23:34:30.915459 44210 solver.cpp:244]     Train net output #1: loss = 0.218776 (* 1 = 0.218776 loss)
I0824 23:34:30.915472 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986042
I0824 23:34:30.915483 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.909551
I0824 23:34:30.915499 44210 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0824 23:34:47.533144 44210 solver.cpp:228] Iteration 1880, loss = 0.0441052
I0824 23:34:47.533258 44210 solver.cpp:244]     Train net output #0: accuracy = 0.978828
I0824 23:34:47.533277 44210 solver.cpp:244]     Train net output #1: loss = 0.0441052 (* 1 = 0.0441052 loss)
I0824 23:34:47.533285 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974748
I0824 23:34:47.533298 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995031
I0824 23:34:47.533308 44210 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0824 23:35:04.162652 44210 solver.cpp:228] Iteration 1900, loss = 0.031316
I0824 23:35:04.162703 44210 solver.cpp:244]     Train net output #0: accuracy = 0.984769
I0824 23:35:04.162717 44210 solver.cpp:244]     Train net output #1: loss = 0.0313159 (* 1 = 0.0313159 loss)
I0824 23:35:04.162730 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979028
I0824 23:35:04.162736 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995856
I0824 23:35:04.162744 44210 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0824 23:35:20.809658 44210 solver.cpp:228] Iteration 1920, loss = 0.0234641
I0824 23:35:20.809834 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989685
I0824 23:35:20.809857 44210 solver.cpp:244]     Train net output #1: loss = 0.0234641 (* 1 = 0.0234641 loss)
I0824 23:35:20.809865 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985321
I0824 23:35:20.809871 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996993
I0824 23:35:20.809880 44210 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0824 23:35:37.429160 44210 solver.cpp:228] Iteration 1940, loss = 0.0259383
I0824 23:35:37.429208 44210 solver.cpp:244]     Train net output #0: accuracy = 0.987593
I0824 23:35:37.429222 44210 solver.cpp:244]     Train net output #1: loss = 0.0259383 (* 1 = 0.0259383 loss)
I0824 23:35:37.429231 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983545
I0824 23:35:37.429245 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997702
I0824 23:35:37.429253 44210 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0824 23:35:54.025171 44210 solver.cpp:228] Iteration 1960, loss = 0.0167758
I0824 23:35:54.025292 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992503
I0824 23:35:54.025310 44210 solver.cpp:244]     Train net output #1: loss = 0.0167758 (* 1 = 0.0167758 loss)
I0824 23:35:54.025317 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991736
I0824 23:35:54.025323 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994954
I0824 23:35:54.025331 44210 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0824 23:36:10.665845 44210 solver.cpp:228] Iteration 1980, loss = 0.0186211
I0824 23:36:10.665908 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99226
I0824 23:36:10.665926 44210 solver.cpp:244]     Train net output #1: loss = 0.0186211 (* 1 = 0.0186211 loss)
I0824 23:36:10.665935 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989112
I0824 23:36:10.665946 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997057
I0824 23:36:10.665956 44210 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0824 23:36:27.287782 44210 solver.cpp:228] Iteration 2000, loss = 0.022923
I0824 23:36:27.287935 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993385
I0824 23:36:27.287977 44210 solver.cpp:244]     Train net output #1: loss = 0.0229229 (* 1 = 0.0229229 loss)
I0824 23:36:27.287988 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994598
I0824 23:36:27.287999 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980306
I0824 23:36:27.288009 44210 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0824 23:36:43.927870 44210 solver.cpp:228] Iteration 2020, loss = 0.0314188
I0824 23:36:43.927913 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986655
I0824 23:36:43.927928 44210 solver.cpp:244]     Train net output #1: loss = 0.0314187 (* 1 = 0.0314187 loss)
I0824 23:36:43.927935 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985883
I0824 23:36:43.927942 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989213
I0824 23:36:43.927952 44210 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0824 23:37:00.560354 44210 solver.cpp:228] Iteration 2040, loss = 0.0282555
I0824 23:37:00.560467 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989771
I0824 23:37:00.560483 44210 solver.cpp:244]     Train net output #1: loss = 0.0282555 (* 1 = 0.0282555 loss)
I0824 23:37:00.560492 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988753
I0824 23:37:00.560499 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991382
I0824 23:37:00.560508 44210 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0824 23:37:17.199318 44210 solver.cpp:228] Iteration 2060, loss = 0.0230043
I0824 23:37:17.199367 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991612
I0824 23:37:17.199381 44210 solver.cpp:244]     Train net output #1: loss = 0.0230043 (* 1 = 0.0230043 loss)
I0824 23:37:17.199389 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988768
I0824 23:37:17.199395 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995341
I0824 23:37:17.199404 44210 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0824 23:37:33.848731 44210 solver.cpp:228] Iteration 2080, loss = 0.0222064
I0824 23:37:33.848896 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0824 23:37:33.848914 44210 solver.cpp:244]     Train net output #1: loss = 0.0222064 (* 1 = 0.0222064 loss)
I0824 23:37:33.848922 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988805
I0824 23:37:33.848928 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993454
I0824 23:37:33.848937 44210 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0824 23:37:50.464208 44210 solver.cpp:228] Iteration 2100, loss = 0.0183166
I0824 23:37:50.464256 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991861
I0824 23:37:50.464270 44210 solver.cpp:244]     Train net output #1: loss = 0.0183165 (* 1 = 0.0183165 loss)
I0824 23:37:50.464278 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990105
I0824 23:37:50.464287 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99567
I0824 23:37:50.464294 44210 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0824 23:38:07.095500 44210 solver.cpp:228] Iteration 2120, loss = 0.0173663
I0824 23:38:07.095634 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994287
I0824 23:38:07.095651 44210 solver.cpp:244]     Train net output #1: loss = 0.0173662 (* 1 = 0.0173662 loss)
I0824 23:38:07.095659 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997027
I0824 23:38:07.095664 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.97668
I0824 23:38:07.095674 44210 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0824 23:38:23.742595 44210 solver.cpp:228] Iteration 2140, loss = 0.0202452
I0824 23:38:23.742642 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993355
I0824 23:38:23.742658 44210 solver.cpp:244]     Train net output #1: loss = 0.0202451 (* 1 = 0.0202451 loss)
I0824 23:38:23.742666 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994478
I0824 23:38:23.742672 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98958
I0824 23:38:23.742681 44210 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0824 23:38:40.376785 44210 solver.cpp:228] Iteration 2160, loss = 0.0182581
I0824 23:38:40.376899 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992122
I0824 23:38:40.376915 44210 solver.cpp:244]     Train net output #1: loss = 0.018258 (* 1 = 0.018258 loss)
I0824 23:38:40.376924 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989527
I0824 23:38:40.376931 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997091
I0824 23:38:40.376955 44210 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0824 23:38:56.999311 44210 solver.cpp:228] Iteration 2180, loss = 0.0204598
I0824 23:38:56.999358 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991233
I0824 23:38:56.999374 44210 solver.cpp:244]     Train net output #1: loss = 0.0204597 (* 1 = 0.0204597 loss)
I0824 23:38:56.999382 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987102
I0824 23:38:56.999388 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997507
I0824 23:38:56.999397 44210 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0824 23:39:13.633877 44210 solver.cpp:228] Iteration 2200, loss = 0.0207641
I0824 23:39:13.634040 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992111
I0824 23:39:13.634058 44210 solver.cpp:244]     Train net output #1: loss = 0.0207641 (* 1 = 0.0207641 loss)
I0824 23:39:13.634070 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992349
I0824 23:39:13.634076 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991509
I0824 23:39:13.634084 44210 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0824 23:39:30.263490 44210 solver.cpp:228] Iteration 2220, loss = 0.0187907
I0824 23:39:30.263532 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992922
I0824 23:39:30.263547 44210 solver.cpp:244]     Train net output #1: loss = 0.0187907 (* 1 = 0.0187907 loss)
I0824 23:39:30.263556 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993834
I0824 23:39:30.263566 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990478
I0824 23:39:30.263576 44210 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0824 23:39:46.897997 44210 solver.cpp:228] Iteration 2240, loss = 0.0101135
I0824 23:39:46.898125 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995407
I0824 23:39:46.898144 44210 solver.cpp:244]     Train net output #1: loss = 0.0101134 (* 1 = 0.0101134 loss)
I0824 23:39:46.898151 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994842
I0824 23:39:46.898164 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997304
I0824 23:39:46.898175 44210 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0824 23:40:03.596340 44210 solver.cpp:228] Iteration 2260, loss = 0.0182024
I0824 23:40:03.596391 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993019
I0824 23:40:03.596406 44210 solver.cpp:244]     Train net output #1: loss = 0.0182023 (* 1 = 0.0182023 loss)
I0824 23:40:03.596413 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993361
I0824 23:40:03.596424 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992099
I0824 23:40:03.596446 44210 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0824 23:40:20.224213 44210 solver.cpp:228] Iteration 2280, loss = 0.0139612
I0824 23:40:20.224328 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994414
I0824 23:40:20.224345 44210 solver.cpp:244]     Train net output #1: loss = 0.0139612 (* 1 = 0.0139612 loss)
I0824 23:40:20.224352 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993932
I0824 23:40:20.224364 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995749
I0824 23:40:20.224371 44210 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0824 23:40:36.838527 44210 solver.cpp:228] Iteration 2300, loss = 0.0169057
I0824 23:40:36.838568 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992645
I0824 23:40:36.838580 44210 solver.cpp:244]     Train net output #1: loss = 0.0169056 (* 1 = 0.0169056 loss)
I0824 23:40:36.838587 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991489
I0824 23:40:36.838594 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995146
I0824 23:40:36.838603 44210 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0824 23:40:53.455530 44210 solver.cpp:228] Iteration 2320, loss = 0.0136313
I0824 23:40:53.455673 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993876
I0824 23:40:53.455689 44210 solver.cpp:244]     Train net output #1: loss = 0.0136313 (* 1 = 0.0136313 loss)
I0824 23:40:53.455698 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99341
I0824 23:40:53.455703 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995262
I0824 23:40:53.455711 44210 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0824 23:41:10.085271 44210 solver.cpp:228] Iteration 2340, loss = 0.0191444
I0824 23:41:10.085310 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990864
I0824 23:41:10.085324 44210 solver.cpp:244]     Train net output #1: loss = 0.0191443 (* 1 = 0.0191443 loss)
I0824 23:41:10.085330 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988481
I0824 23:41:10.085336 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997396
I0824 23:41:10.085345 44210 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0824 23:41:26.700229 44210 solver.cpp:228] Iteration 2360, loss = 0.0105395
I0824 23:41:26.700423 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99547
I0824 23:41:26.700439 44210 solver.cpp:244]     Train net output #1: loss = 0.0105394 (* 1 = 0.0105394 loss)
I0824 23:41:26.700448 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995069
I0824 23:41:26.700459 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996945
I0824 23:41:26.700467 44210 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0824 23:41:43.316846 44210 solver.cpp:228] Iteration 2380, loss = 0.0137649
I0824 23:41:43.316890 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995059
I0824 23:41:43.316905 44210 solver.cpp:244]     Train net output #1: loss = 0.0137648 (* 1 = 0.0137648 loss)
I0824 23:41:43.316910 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995872
I0824 23:41:43.316916 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992601
I0824 23:41:43.316926 44210 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0824 23:41:59.914974 44210 solver.cpp:228] Iteration 2400, loss = 0.0139514
I0824 23:41:59.915112 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994559
I0824 23:41:59.915127 44210 solver.cpp:244]     Train net output #1: loss = 0.0139513 (* 1 = 0.0139513 loss)
I0824 23:41:59.915136 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993479
I0824 23:41:59.915146 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996477
I0824 23:41:59.915154 44210 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0824 23:42:16.532629 44210 solver.cpp:228] Iteration 2420, loss = 0.0156456
I0824 23:42:16.532675 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995815
I0824 23:42:16.532690 44210 solver.cpp:244]     Train net output #1: loss = 0.0156456 (* 1 = 0.0156456 loss)
I0824 23:42:16.532696 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996456
I0824 23:42:16.532701 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987213
I0824 23:42:16.532709 44210 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0824 23:42:33.139057 44210 solver.cpp:228] Iteration 2440, loss = 0.0182445
I0824 23:42:33.139219 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992701
I0824 23:42:33.139261 44210 solver.cpp:244]     Train net output #1: loss = 0.0182445 (* 1 = 0.0182445 loss)
I0824 23:42:33.139269 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991994
I0824 23:42:33.139297 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995174
I0824 23:42:33.139308 44210 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0824 23:42:49.810771 44210 solver.cpp:228] Iteration 2460, loss = 0.0164549
I0824 23:42:49.810817 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992999
I0824 23:42:49.810832 44210 solver.cpp:244]     Train net output #1: loss = 0.0164549 (* 1 = 0.0164549 loss)
I0824 23:42:49.810839 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991404
I0824 23:42:49.810845 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996342
I0824 23:42:49.810854 44210 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0824 23:43:06.438225 44210 solver.cpp:228] Iteration 2480, loss = 0.0167321
I0824 23:43:06.438374 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993954
I0824 23:43:06.438391 44210 solver.cpp:244]     Train net output #1: loss = 0.0167321 (* 1 = 0.0167321 loss)
I0824 23:43:06.438403 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994913
I0824 23:43:06.438416 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990506
I0824 23:43:06.438424 44210 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0824 23:43:23.067754 44210 solver.cpp:228] Iteration 2500, loss = 0.0161652
I0824 23:43:23.067803 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993087
I0824 23:43:23.067818 44210 solver.cpp:244]     Train net output #1: loss = 0.0161651 (* 1 = 0.0161651 loss)
I0824 23:43:23.067826 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992367
I0824 23:43:23.067832 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994901
I0824 23:43:23.067842 44210 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0824 23:43:39.742179 44210 solver.cpp:228] Iteration 2520, loss = 0.0119218
I0824 23:43:39.742393 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995381
I0824 23:43:39.742413 44210 solver.cpp:244]     Train net output #1: loss = 0.0119218 (* 1 = 0.0119218 loss)
I0824 23:43:39.742424 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994878
I0824 23:43:39.742430 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996469
I0824 23:43:39.742439 44210 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0824 23:43:56.345242 44210 solver.cpp:228] Iteration 2540, loss = 0.0187443
I0824 23:43:56.345288 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992423
I0824 23:43:56.345304 44210 solver.cpp:244]     Train net output #1: loss = 0.0187443 (* 1 = 0.0187443 loss)
I0824 23:43:56.345311 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992276
I0824 23:43:56.345317 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992787
I0824 23:43:56.345325 44210 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0824 23:44:12.966444 44210 solver.cpp:228] Iteration 2560, loss = 0.0134636
I0824 23:44:12.966601 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994109
I0824 23:44:12.966640 44210 solver.cpp:244]     Train net output #1: loss = 0.0134636 (* 1 = 0.0134636 loss)
I0824 23:44:12.966650 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992964
I0824 23:44:12.966660 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996935
I0824 23:44:12.966671 44210 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0824 23:44:29.618353 44210 solver.cpp:228] Iteration 2580, loss = 0.0165184
I0824 23:44:29.618409 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992834
I0824 23:44:29.618430 44210 solver.cpp:244]     Train net output #1: loss = 0.0165184 (* 1 = 0.0165184 loss)
I0824 23:44:29.618440 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990061
I0824 23:44:29.618453 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997316
I0824 23:44:29.618463 44210 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0824 23:44:46.244170 44210 solver.cpp:228] Iteration 2600, loss = 0.0139681
I0824 23:44:46.244302 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995178
I0824 23:44:46.244318 44210 solver.cpp:244]     Train net output #1: loss = 0.013968 (* 1 = 0.013968 loss)
I0824 23:44:46.244325 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996868
I0824 23:44:46.244331 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980809
I0824 23:44:46.244340 44210 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0824 23:45:02.869328 44210 solver.cpp:228] Iteration 2620, loss = 0.0157734
I0824 23:45:02.869400 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993225
I0824 23:45:02.869423 44210 solver.cpp:244]     Train net output #1: loss = 0.0157733 (* 1 = 0.0157733 loss)
I0824 23:45:02.869431 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991691
I0824 23:45:02.869438 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996074
I0824 23:45:02.869446 44210 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0824 23:45:19.515380 44210 solver.cpp:228] Iteration 2640, loss = 0.0130183
I0824 23:45:19.515511 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994799
I0824 23:45:19.515527 44210 solver.cpp:244]     Train net output #1: loss = 0.0130182 (* 1 = 0.0130182 loss)
I0824 23:45:19.515535 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994326
I0824 23:45:19.515542 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995705
I0824 23:45:19.515549 44210 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0824 23:45:36.132690 44210 solver.cpp:228] Iteration 2660, loss = 0.0171952
I0824 23:45:36.132740 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992497
I0824 23:45:36.132755 44210 solver.cpp:244]     Train net output #1: loss = 0.0171951 (* 1 = 0.0171951 loss)
I0824 23:45:36.132761 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990809
I0824 23:45:36.132767 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99583
I0824 23:45:36.132776 44210 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0824 23:45:52.743999 44210 solver.cpp:228] Iteration 2680, loss = 0.0130923
I0824 23:45:52.744210 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994686
I0824 23:45:52.744247 44210 solver.cpp:244]     Train net output #1: loss = 0.0130923 (* 1 = 0.0130923 loss)
I0824 23:45:52.744257 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994112
I0824 23:45:52.744268 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995847
I0824 23:45:52.744277 44210 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0824 23:46:09.367292 44210 solver.cpp:228] Iteration 2700, loss = 0.0114065
I0824 23:46:09.367337 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995336
I0824 23:46:09.367354 44210 solver.cpp:244]     Train net output #1: loss = 0.0114064 (* 1 = 0.0114064 loss)
I0824 23:46:09.367362 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99563
I0824 23:46:09.367368 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994394
I0824 23:46:09.367377 44210 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0824 23:46:26.001672 44210 solver.cpp:228] Iteration 2720, loss = 0.0124813
I0824 23:46:26.001844 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994967
I0824 23:46:26.001884 44210 solver.cpp:244]     Train net output #1: loss = 0.0124812 (* 1 = 0.0124812 loss)
I0824 23:46:26.001894 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99501
I0824 23:46:26.001904 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994871
I0824 23:46:26.001911 44210 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0824 23:46:42.637245 44210 solver.cpp:228] Iteration 2740, loss = 0.0134878
I0824 23:46:42.637295 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99468
I0824 23:46:42.637312 44210 solver.cpp:244]     Train net output #1: loss = 0.0134878 (* 1 = 0.0134878 loss)
I0824 23:46:42.637320 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995237
I0824 23:46:42.637326 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99299
I0824 23:46:42.637334 44210 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0824 23:46:59.280522 44210 solver.cpp:228] Iteration 2760, loss = 0.0139167
I0824 23:46:59.280653 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995185
I0824 23:46:59.280674 44210 solver.cpp:244]     Train net output #1: loss = 0.0139166 (* 1 = 0.0139166 loss)
I0824 23:46:59.280683 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996251
I0824 23:46:59.280694 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991517
I0824 23:46:59.280709 44210 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0824 23:47:15.898339 44210 solver.cpp:228] Iteration 2780, loss = 0.013473
I0824 23:47:15.898380 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995733
I0824 23:47:15.898392 44210 solver.cpp:244]     Train net output #1: loss = 0.013473 (* 1 = 0.013473 loss)
I0824 23:47:15.898401 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996208
I0824 23:47:15.898416 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994037
I0824 23:47:15.898423 44210 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0824 23:47:32.535254 44210 solver.cpp:228] Iteration 2800, loss = 0.0110556
I0824 23:47:32.535460 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995168
I0824 23:47:32.535496 44210 solver.cpp:244]     Train net output #1: loss = 0.0110555 (* 1 = 0.0110555 loss)
I0824 23:47:32.535509 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99504
I0824 23:47:32.535521 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995613
I0824 23:47:32.535528 44210 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0824 23:47:49.174679 44210 solver.cpp:228] Iteration 2820, loss = 0.0189417
I0824 23:47:49.174723 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992582
I0824 23:47:49.174736 44210 solver.cpp:244]     Train net output #1: loss = 0.0189416 (* 1 = 0.0189416 loss)
I0824 23:47:49.174744 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991628
I0824 23:47:49.174758 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994178
I0824 23:47:49.174767 44210 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0824 23:48:05.795286 44210 solver.cpp:228] Iteration 2840, loss = 0.0161476
I0824 23:48:05.795428 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992496
I0824 23:48:05.795445 44210 solver.cpp:244]     Train net output #1: loss = 0.0161475 (* 1 = 0.0161475 loss)
I0824 23:48:05.795454 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991694
I0824 23:48:05.795459 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994672
I0824 23:48:05.795469 44210 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0824 23:48:22.417244 44210 solver.cpp:228] Iteration 2860, loss = 0.0162191
I0824 23:48:22.417290 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993322
I0824 23:48:22.417305 44210 solver.cpp:244]     Train net output #1: loss = 0.016219 (* 1 = 0.016219 loss)
I0824 23:48:22.417311 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992381
I0824 23:48:22.417317 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995939
I0824 23:48:22.417325 44210 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0824 23:48:39.099236 44210 solver.cpp:228] Iteration 2880, loss = 0.00870753
I0824 23:48:39.099380 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996573
I0824 23:48:39.099412 44210 solver.cpp:244]     Train net output #1: loss = 0.00870747 (* 1 = 0.00870747 loss)
I0824 23:48:39.099421 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997062
I0824 23:48:39.099433 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994611
I0824 23:48:39.099440 44210 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0824 23:48:55.777693 44210 solver.cpp:228] Iteration 2900, loss = 0.0128165
I0824 23:48:55.777742 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994965
I0824 23:48:55.777756 44210 solver.cpp:244]     Train net output #1: loss = 0.0128164 (* 1 = 0.0128164 loss)
I0824 23:48:55.777765 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994093
I0824 23:48:55.777770 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997629
I0824 23:48:55.777781 44210 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0824 23:49:12.476083 44210 solver.cpp:228] Iteration 2920, loss = 0.0127674
I0824 23:49:12.476200 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995172
I0824 23:49:12.476223 44210 solver.cpp:244]     Train net output #1: loss = 0.0127673 (* 1 = 0.0127673 loss)
I0824 23:49:12.476233 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994764
I0824 23:49:12.476245 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995837
I0824 23:49:12.476256 44210 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0824 23:49:29.145076 44210 solver.cpp:228] Iteration 2940, loss = 0.0147365
I0824 23:49:29.145123 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994498
I0824 23:49:29.145138 44210 solver.cpp:244]     Train net output #1: loss = 0.0147364 (* 1 = 0.0147364 loss)
I0824 23:49:29.145145 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995581
I0824 23:49:29.145153 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989741
I0824 23:49:29.145162 44210 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0824 23:49:45.785993 44210 solver.cpp:228] Iteration 2960, loss = 0.0193045
I0824 23:49:45.786180 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992296
I0824 23:49:45.786198 44210 solver.cpp:244]     Train net output #1: loss = 0.0193044 (* 1 = 0.0193044 loss)
I0824 23:49:45.786211 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993153
I0824 23:49:45.786216 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988561
I0824 23:49:45.786226 44210 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0824 23:50:02.454741 44210 solver.cpp:228] Iteration 2980, loss = 0.00960248
I0824 23:50:02.454787 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996422
I0824 23:50:02.454802 44210 solver.cpp:244]     Train net output #1: loss = 0.00960242 (* 1 = 0.00960242 loss)
I0824 23:50:02.454808 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996491
I0824 23:50:02.454816 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99628
I0824 23:50:02.454833 44210 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0824 23:50:19.116631 44210 solver.cpp:228] Iteration 3000, loss = 0.0107485
I0824 23:50:19.116758 44210 solver.cpp:244]     Train net output #0: accuracy = 0.9958
I0824 23:50:19.116776 44210 solver.cpp:244]     Train net output #1: loss = 0.0107484 (* 1 = 0.0107484 loss)
I0824 23:50:19.116786 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996536
I0824 23:50:19.116797 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992476
I0824 23:50:19.116806 44210 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0824 23:50:35.767957 44210 solver.cpp:228] Iteration 3020, loss = 0.0130986
I0824 23:50:35.768002 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995833
I0824 23:50:35.768015 44210 solver.cpp:244]     Train net output #1: loss = 0.0130985 (* 1 = 0.0130985 loss)
I0824 23:50:35.768023 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997198
I0824 23:50:35.768029 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990985
I0824 23:50:35.768038 44210 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0824 23:50:52.385893 44210 solver.cpp:228] Iteration 3040, loss = 0.0157575
I0824 23:50:52.386093 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994271
I0824 23:50:52.386111 44210 solver.cpp:244]     Train net output #1: loss = 0.0157575 (* 1 = 0.0157575 loss)
I0824 23:50:52.386119 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994479
I0824 23:50:52.386131 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993928
I0824 23:50:52.386145 44210 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0824 23:51:09.017282 44210 solver.cpp:228] Iteration 3060, loss = 0.0141707
I0824 23:51:09.017320 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993916
I0824 23:51:09.017334 44210 solver.cpp:244]     Train net output #1: loss = 0.0141707 (* 1 = 0.0141707 loss)
I0824 23:51:09.017343 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992836
I0824 23:51:09.017359 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996133
I0824 23:51:09.017381 44210 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0824 23:51:25.672667 44210 solver.cpp:228] Iteration 3080, loss = 0.0170467
I0824 23:51:25.672788 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992894
I0824 23:51:25.672806 44210 solver.cpp:244]     Train net output #1: loss = 0.0170466 (* 1 = 0.0170466 loss)
I0824 23:51:25.672812 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992848
I0824 23:51:25.672818 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993014
I0824 23:51:25.672828 44210 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0824 23:51:42.338363 44210 solver.cpp:228] Iteration 3100, loss = 0.0134283
I0824 23:51:42.338412 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996152
I0824 23:51:42.338428 44210 solver.cpp:244]     Train net output #1: loss = 0.0134283 (* 1 = 0.0134283 loss)
I0824 23:51:42.338434 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996902
I0824 23:51:42.338440 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98329
I0824 23:51:42.338449 44210 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0824 23:51:58.963001 44210 solver.cpp:228] Iteration 3120, loss = 0.0109416
I0824 23:51:58.963172 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994792
I0824 23:51:58.963202 44210 solver.cpp:244]     Train net output #1: loss = 0.0109415 (* 1 = 0.0109415 loss)
I0824 23:51:58.963210 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993464
I0824 23:51:58.963217 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9981
I0824 23:51:58.963227 44210 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0824 23:52:15.631975 44210 solver.cpp:228] Iteration 3140, loss = 0.0126158
I0824 23:52:15.632030 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994964
I0824 23:52:15.632047 44210 solver.cpp:244]     Train net output #1: loss = 0.0126158 (* 1 = 0.0126158 loss)
I0824 23:52:15.632055 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995373
I0824 23:52:15.632068 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993216
I0824 23:52:15.632091 44210 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0824 23:52:32.322751 44210 solver.cpp:228] Iteration 3160, loss = 0.0081887
I0824 23:52:32.322882 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996804
I0824 23:52:32.322917 44210 solver.cpp:244]     Train net output #1: loss = 0.00818864 (* 1 = 0.00818864 loss)
I0824 23:52:32.322927 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99675
I0824 23:52:32.322933 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99693
I0824 23:52:32.322942 44210 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0824 23:52:49.016162 44210 solver.cpp:228] Iteration 3180, loss = 0.015018
I0824 23:52:49.016211 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994009
I0824 23:52:49.016227 44210 solver.cpp:244]     Train net output #1: loss = 0.0150179 (* 1 = 0.0150179 loss)
I0824 23:52:49.016243 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994361
I0824 23:52:49.016255 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992955
I0824 23:52:49.016269 44210 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0824 23:53:05.680248 44210 solver.cpp:228] Iteration 3200, loss = 0.00955751
I0824 23:53:05.680366 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996587
I0824 23:53:05.680383 44210 solver.cpp:244]     Train net output #1: loss = 0.00955745 (* 1 = 0.00955745 loss)
I0824 23:53:05.680394 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997548
I0824 23:53:05.680404 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993504
I0824 23:53:05.680414 44210 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0824 23:53:22.334949 44210 solver.cpp:228] Iteration 3220, loss = 0.0154608
I0824 23:53:22.334991 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994761
I0824 23:53:22.335006 44210 solver.cpp:244]     Train net output #1: loss = 0.0154607 (* 1 = 0.0154607 loss)
I0824 23:53:22.335021 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995635
I0824 23:53:22.335033 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993357
I0824 23:53:22.335048 44210 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0824 23:53:39.006803 44210 solver.cpp:228] Iteration 3240, loss = 0.0193756
I0824 23:53:39.006914 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990823
I0824 23:53:39.006932 44210 solver.cpp:244]     Train net output #1: loss = 0.0193755 (* 1 = 0.0193755 loss)
I0824 23:53:39.006942 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988974
I0824 23:53:39.006954 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99592
I0824 23:53:39.006963 44210 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0824 23:53:55.634511 44210 solver.cpp:228] Iteration 3260, loss = 0.0139765
I0824 23:53:55.634555 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994473
I0824 23:53:55.634569 44210 solver.cpp:244]     Train net output #1: loss = 0.0139764 (* 1 = 0.0139764 loss)
I0824 23:53:55.634577 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993015
I0824 23:53:55.634583 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997241
I0824 23:53:55.634593 44210 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0824 23:54:12.310577 44210 solver.cpp:228] Iteration 3280, loss = 0.011157
I0824 23:54:12.310719 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996162
I0824 23:54:12.310739 44210 solver.cpp:244]     Train net output #1: loss = 0.0111569 (* 1 = 0.0111569 loss)
I0824 23:54:12.310746 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99766
I0824 23:54:12.310752 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987002
I0824 23:54:12.310761 44210 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0824 23:54:28.978652 44210 solver.cpp:228] Iteration 3300, loss = 0.0223687
I0824 23:54:28.978703 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991539
I0824 23:54:28.978718 44210 solver.cpp:244]     Train net output #1: loss = 0.0223687 (* 1 = 0.0223687 loss)
I0824 23:54:28.978725 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992309
I0824 23:54:28.978746 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989981
I0824 23:54:28.978757 44210 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0824 23:54:45.676442 44210 solver.cpp:228] Iteration 3320, loss = 0.0131353
I0824 23:54:45.676589 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995013
I0824 23:54:45.676617 44210 solver.cpp:244]     Train net output #1: loss = 0.0131352 (* 1 = 0.0131352 loss)
I0824 23:54:45.676630 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994904
I0824 23:54:45.676637 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995414
I0824 23:54:45.676647 44210 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0824 23:55:02.362066 44210 solver.cpp:228] Iteration 3340, loss = 0.011238
I0824 23:55:02.362125 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995702
I0824 23:55:02.362145 44210 solver.cpp:244]     Train net output #1: loss = 0.0112379 (* 1 = 0.0112379 loss)
I0824 23:55:02.362155 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995128
I0824 23:55:02.362169 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996775
I0824 23:55:02.362185 44210 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0824 23:55:19.003125 44210 solver.cpp:228] Iteration 3360, loss = 0.0180335
I0824 23:55:19.003237 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993608
I0824 23:55:19.003255 44210 solver.cpp:244]     Train net output #1: loss = 0.0180335 (* 1 = 0.0180335 loss)
I0824 23:55:19.003262 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994407
I0824 23:55:19.003269 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992275
I0824 23:55:19.003279 44210 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0824 23:55:35.653348 44210 solver.cpp:228] Iteration 3380, loss = 0.0167471
I0824 23:55:35.653403 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993349
I0824 23:55:35.653419 44210 solver.cpp:244]     Train net output #1: loss = 0.016747 (* 1 = 0.016747 loss)
I0824 23:55:35.653427 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994586
I0824 23:55:35.653434 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989581
I0824 23:55:35.653443 44210 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0824 23:55:52.288391 44210 solver.cpp:228] Iteration 3400, loss = 0.0177166
I0824 23:55:52.288578 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994132
I0824 23:55:52.288616 44210 solver.cpp:244]     Train net output #1: loss = 0.0177165 (* 1 = 0.0177165 loss)
I0824 23:55:52.288624 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996385
I0824 23:55:52.288630 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984469
I0824 23:55:52.288640 44210 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0824 23:56:08.948026 44210 solver.cpp:228] Iteration 3420, loss = 0.0135599
I0824 23:56:08.948104 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993639
I0824 23:56:08.948122 44210 solver.cpp:244]     Train net output #1: loss = 0.0135599 (* 1 = 0.0135599 loss)
I0824 23:56:08.948133 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991607
I0824 23:56:08.948144 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997726
I0824 23:56:08.948154 44210 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0824 23:56:25.602674 44210 solver.cpp:228] Iteration 3440, loss = 0.0146404
I0824 23:56:25.602793 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993394
I0824 23:56:25.602811 44210 solver.cpp:244]     Train net output #1: loss = 0.0146403 (* 1 = 0.0146403 loss)
I0824 23:56:25.602820 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992126
I0824 23:56:25.602846 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99619
I0824 23:56:25.602857 44210 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0824 23:56:42.231704 44210 solver.cpp:228] Iteration 3460, loss = 0.0132811
I0824 23:56:42.231752 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994928
I0824 23:56:42.231770 44210 solver.cpp:244]     Train net output #1: loss = 0.013281 (* 1 = 0.013281 loss)
I0824 23:56:42.231778 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995858
I0824 23:56:42.231792 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989172
I0824 23:56:42.231808 44210 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0824 23:56:58.851938 44210 solver.cpp:228] Iteration 3480, loss = 0.0147309
I0824 23:56:58.852066 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994646
I0824 23:56:58.852087 44210 solver.cpp:244]     Train net output #1: loss = 0.0147309 (* 1 = 0.0147309 loss)
I0824 23:56:58.852095 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993532
I0824 23:56:58.852107 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99641
I0824 23:56:58.852116 44210 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0824 23:57:15.494138 44210 solver.cpp:228] Iteration 3500, loss = 0.0100217
I0824 23:57:15.494180 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996036
I0824 23:57:15.494195 44210 solver.cpp:244]     Train net output #1: loss = 0.0100217 (* 1 = 0.0100217 loss)
I0824 23:57:15.494209 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996735
I0824 23:57:15.494221 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993063
I0824 23:57:15.494237 44210 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0824 23:57:32.111408 44210 solver.cpp:228] Iteration 3520, loss = 0.0104255
I0824 23:57:32.111519 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995441
I0824 23:57:32.111537 44210 solver.cpp:244]     Train net output #1: loss = 0.0104254 (* 1 = 0.0104254 loss)
I0824 23:57:32.111546 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994897
I0824 23:57:32.111558 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9968
I0824 23:57:32.111569 44210 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0824 23:57:48.759994 44210 solver.cpp:228] Iteration 3540, loss = 0.0146048
I0824 23:57:48.760038 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993659
I0824 23:57:48.760053 44210 solver.cpp:244]     Train net output #1: loss = 0.0146048 (* 1 = 0.0146048 loss)
I0824 23:57:48.760066 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992142
I0824 23:57:48.760079 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996498
I0824 23:57:48.760102 44210 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0824 23:58:05.540427 44210 solver.cpp:228] Iteration 3560, loss = 0.00917226
I0824 23:58:05.540598 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996047
I0824 23:58:05.540617 44210 solver.cpp:244]     Train net output #1: loss = 0.0091722 (* 1 = 0.0091722 loss)
I0824 23:58:05.540626 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995966
I0824 23:58:05.540632 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996324
I0824 23:58:05.540648 44210 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0824 23:58:22.191563 44210 solver.cpp:228] Iteration 3580, loss = 0.0143743
I0824 23:58:22.191612 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994379
I0824 23:58:22.191627 44210 solver.cpp:244]     Train net output #1: loss = 0.0143743 (* 1 = 0.0143743 loss)
I0824 23:58:22.191635 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994131
I0824 23:58:22.191642 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995018
I0824 23:58:22.191651 44210 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0824 23:58:38.842159 44210 solver.cpp:228] Iteration 3600, loss = 0.00986229
I0824 23:58:38.842281 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996309
I0824 23:58:38.842308 44210 solver.cpp:244]     Train net output #1: loss = 0.00986223 (* 1 = 0.00986223 loss)
I0824 23:58:38.842319 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997176
I0824 23:58:38.842329 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990988
I0824 23:58:38.842345 44210 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0824 23:58:55.482363 44210 solver.cpp:228] Iteration 3620, loss = 0.0104085
I0824 23:58:55.482405 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994935
I0824 23:58:55.482420 44210 solver.cpp:244]     Train net output #1: loss = 0.0104084 (* 1 = 0.0104084 loss)
I0824 23:58:55.482427 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993185
I0824 23:58:55.482434 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999041
I0824 23:58:55.482444 44210 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0824 23:59:12.172096 44210 solver.cpp:228] Iteration 3640, loss = 0.0124777
I0824 23:59:12.172224 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994696
I0824 23:59:12.172250 44210 solver.cpp:244]     Train net output #1: loss = 0.0124777 (* 1 = 0.0124777 loss)
I0824 23:59:12.172263 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993797
I0824 23:59:12.172276 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996777
I0824 23:59:12.172291 44210 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0824 23:59:28.858438 44210 solver.cpp:228] Iteration 3660, loss = 0.0100087
I0824 23:59:28.858494 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995968
I0824 23:59:28.858516 44210 solver.cpp:244]     Train net output #1: loss = 0.0100086 (* 1 = 0.0100086 loss)
I0824 23:59:28.858526 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996551
I0824 23:59:28.858537 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993949
I0824 23:59:28.858547 44210 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0824 23:59:45.510223 44210 solver.cpp:228] Iteration 3680, loss = 0.0111126
I0824 23:59:45.510337 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995404
I0824 23:59:45.510354 44210 solver.cpp:244]     Train net output #1: loss = 0.0111125 (* 1 = 0.0111125 loss)
I0824 23:59:45.510360 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995791
I0824 23:59:45.510367 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994229
I0824 23:59:45.510375 44210 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0825 00:00:02.131686 44210 solver.cpp:228] Iteration 3700, loss = 0.0116478
I0825 00:00:02.131734 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995893
I0825 00:00:02.131747 44210 solver.cpp:244]     Train net output #1: loss = 0.0116477 (* 1 = 0.0116477 loss)
I0825 00:00:02.131755 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996265
I0825 00:00:02.131762 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995132
I0825 00:00:02.131770 44210 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0825 00:00:18.772122 44210 solver.cpp:228] Iteration 3720, loss = 0.0119031
I0825 00:00:18.772282 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995632
I0825 00:00:18.772305 44210 solver.cpp:244]     Train net output #1: loss = 0.011903 (* 1 = 0.011903 loss)
I0825 00:00:18.772315 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995919
I0825 00:00:18.772325 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99432
I0825 00:00:18.772334 44210 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0825 00:00:35.412678 44210 solver.cpp:228] Iteration 3740, loss = 0.014692
I0825 00:00:35.412731 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994359
I0825 00:00:35.412746 44210 solver.cpp:244]     Train net output #1: loss = 0.0146919 (* 1 = 0.0146919 loss)
I0825 00:00:35.412760 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992925
I0825 00:00:35.412768 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996377
I0825 00:00:35.412781 44210 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0825 00:00:52.041842 44210 solver.cpp:228] Iteration 3760, loss = 0.00825344
I0825 00:00:52.041960 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996586
I0825 00:00:52.041978 44210 solver.cpp:244]     Train net output #1: loss = 0.00825338 (* 1 = 0.00825338 loss)
I0825 00:00:52.041986 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99592
I0825 00:00:52.041992 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997908
I0825 00:00:52.042002 44210 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0825 00:01:08.715395 44210 solver.cpp:228] Iteration 3780, loss = 0.0105645
I0825 00:01:08.715448 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995108
I0825 00:01:08.715466 44210 solver.cpp:244]     Train net output #1: loss = 0.0105644 (* 1 = 0.0105644 loss)
I0825 00:01:08.715488 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994245
I0825 00:01:08.715497 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997132
I0825 00:01:08.715512 44210 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0825 00:01:25.355970 44210 solver.cpp:228] Iteration 3800, loss = 0.012873
I0825 00:01:25.356096 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993999
I0825 00:01:25.356114 44210 solver.cpp:244]     Train net output #1: loss = 0.0128729 (* 1 = 0.0128729 loss)
I0825 00:01:25.356122 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992598
I0825 00:01:25.356127 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997218
I0825 00:01:25.356135 44210 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0825 00:01:42.135231 44210 solver.cpp:228] Iteration 3820, loss = 0.0103235
I0825 00:01:42.135283 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995605
I0825 00:01:42.135313 44210 solver.cpp:244]     Train net output #1: loss = 0.0103234 (* 1 = 0.0103234 loss)
I0825 00:01:42.135323 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994243
I0825 00:01:42.135334 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998037
I0825 00:01:42.135344 44210 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0825 00:01:58.782471 44210 solver.cpp:228] Iteration 3840, loss = 0.0123186
I0825 00:01:58.782625 44210 solver.cpp:244]     Train net output #0: accuracy = 0.9951
I0825 00:01:58.782644 44210 solver.cpp:244]     Train net output #1: loss = 0.0123185 (* 1 = 0.0123185 loss)
I0825 00:01:58.782654 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99587
I0825 00:01:58.782665 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992555
I0825 00:01:58.782673 44210 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0825 00:02:15.412324 44210 solver.cpp:228] Iteration 3860, loss = 0.0114466
I0825 00:02:15.412384 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995511
I0825 00:02:15.412400 44210 solver.cpp:244]     Train net output #1: loss = 0.0114465 (* 1 = 0.0114465 loss)
I0825 00:02:15.412408 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996012
I0825 00:02:15.412420 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991485
I0825 00:02:15.412436 44210 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0825 00:02:32.081571 44210 solver.cpp:228] Iteration 3880, loss = 0.0150309
I0825 00:02:32.081814 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993407
I0825 00:02:32.081848 44210 solver.cpp:244]     Train net output #1: loss = 0.0150308 (* 1 = 0.0150308 loss)
I0825 00:02:32.081857 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992782
I0825 00:02:32.081869 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99548
I0825 00:02:32.081883 44210 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0825 00:02:48.733160 44210 solver.cpp:228] Iteration 3900, loss = 0.0117767
I0825 00:02:48.733211 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995518
I0825 00:02:48.733227 44210 solver.cpp:244]     Train net output #1: loss = 0.0117767 (* 1 = 0.0117767 loss)
I0825 00:02:48.733233 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994566
I0825 00:02:48.733243 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997027
I0825 00:02:48.733258 44210 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0825 00:03:05.363159 44210 solver.cpp:228] Iteration 3920, loss = 0.00794775
I0825 00:03:05.363308 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996995
I0825 00:03:05.363327 44210 solver.cpp:244]     Train net output #1: loss = 0.00794769 (* 1 = 0.00794769 loss)
I0825 00:03:05.363342 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99687
I0825 00:03:05.363353 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997257
I0825 00:03:05.363364 44210 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0825 00:03:22.002248 44210 solver.cpp:228] Iteration 3940, loss = 0.00931249
I0825 00:03:22.002300 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996198
I0825 00:03:22.002316 44210 solver.cpp:244]     Train net output #1: loss = 0.00931243 (* 1 = 0.00931243 loss)
I0825 00:03:22.002324 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996408
I0825 00:03:22.002331 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995433
I0825 00:03:22.002338 44210 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0825 00:03:38.637451 44210 solver.cpp:228] Iteration 3960, loss = 0.0103464
I0825 00:03:38.637627 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996379
I0825 00:03:38.637645 44210 solver.cpp:244]     Train net output #1: loss = 0.0103463 (* 1 = 0.0103463 loss)
I0825 00:03:38.637652 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996224
I0825 00:03:38.637658 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996652
I0825 00:03:38.637672 44210 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0825 00:03:55.326215 44210 solver.cpp:228] Iteration 3980, loss = 0.0148593
I0825 00:03:55.326273 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994446
I0825 00:03:55.326289 44210 solver.cpp:244]     Train net output #1: loss = 0.0148592 (* 1 = 0.0148592 loss)
I0825 00:03:55.326297 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995402
I0825 00:03:55.326303 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991185
I0825 00:03:55.326328 44210 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0825 00:04:12.023468 44210 solver.cpp:228] Iteration 4000, loss = 0.0123074
I0825 00:04:12.023695 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995363
I0825 00:04:12.023718 44210 solver.cpp:244]     Train net output #1: loss = 0.0123073 (* 1 = 0.0123073 loss)
I0825 00:04:12.023730 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995098
I0825 00:04:12.023746 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996008
I0825 00:04:12.023756 44210 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0825 00:04:28.705780 44210 solver.cpp:228] Iteration 4020, loss = 0.00854097
I0825 00:04:28.705835 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996262
I0825 00:04:28.705855 44210 solver.cpp:244]     Train net output #1: loss = 0.00854091 (* 1 = 0.00854091 loss)
I0825 00:04:28.705871 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995857
I0825 00:04:28.705881 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997501
I0825 00:04:28.705890 44210 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0825 00:04:45.394196 44210 solver.cpp:228] Iteration 4040, loss = 0.00976265
I0825 00:04:45.394342 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995655
I0825 00:04:45.394378 44210 solver.cpp:244]     Train net output #1: loss = 0.00976259 (* 1 = 0.00976259 loss)
I0825 00:04:45.394387 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995411
I0825 00:04:45.394395 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996386
I0825 00:04:45.394405 44210 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0825 00:05:02.028503 44210 solver.cpp:228] Iteration 4060, loss = 0.011938
I0825 00:05:02.028565 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995032
I0825 00:05:02.028589 44210 solver.cpp:244]     Train net output #1: loss = 0.011938 (* 1 = 0.011938 loss)
I0825 00:05:02.028597 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995713
I0825 00:05:02.028614 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992225
I0825 00:05:02.028625 44210 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0825 00:05:18.657277 44210 solver.cpp:228] Iteration 4080, loss = 0.0149611
I0825 00:05:18.657433 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994
I0825 00:05:18.657452 44210 solver.cpp:244]     Train net output #1: loss = 0.014961 (* 1 = 0.014961 loss)
I0825 00:05:18.657461 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992825
I0825 00:05:18.657471 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996717
I0825 00:05:18.657480 44210 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0825 00:05:35.286447 44210 solver.cpp:228] Iteration 4100, loss = 0.0156217
I0825 00:05:35.286512 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992494
I0825 00:05:35.286527 44210 solver.cpp:244]     Train net output #1: loss = 0.0156216 (* 1 = 0.0156216 loss)
I0825 00:05:35.286535 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989577
I0825 00:05:35.286540 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997459
I0825 00:05:35.286556 44210 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0825 00:05:51.915185 44210 solver.cpp:228] Iteration 4120, loss = 0.0137807
I0825 00:05:51.915320 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994958
I0825 00:05:51.915345 44210 solver.cpp:244]     Train net output #1: loss = 0.0137807 (* 1 = 0.0137807 loss)
I0825 00:05:51.915354 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99496
I0825 00:05:51.915364 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994946
I0825 00:05:51.915372 44210 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0825 00:06:08.548678 44210 solver.cpp:228] Iteration 4140, loss = 0.00839587
I0825 00:06:08.548722 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996803
I0825 00:06:08.548737 44210 solver.cpp:244]     Train net output #1: loss = 0.00839581 (* 1 = 0.00839581 loss)
I0825 00:06:08.548743 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997544
I0825 00:06:08.548748 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993781
I0825 00:06:08.548756 44210 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0825 00:06:25.178393 44210 solver.cpp:228] Iteration 4160, loss = 0.00753506
I0825 00:06:25.178562 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996555
I0825 00:06:25.178586 44210 solver.cpp:244]     Train net output #1: loss = 0.007535 (* 1 = 0.007535 loss)
I0825 00:06:25.178594 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995592
I0825 00:06:25.178606 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998525
I0825 00:06:25.178614 44210 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0825 00:06:41.823285 44210 solver.cpp:228] Iteration 4180, loss = 0.00705538
I0825 00:06:41.823333 44210 solver.cpp:244]     Train net output #0: accuracy = 0.997238
I0825 00:06:41.823348 44210 solver.cpp:244]     Train net output #1: loss = 0.00705532 (* 1 = 0.00705532 loss)
I0825 00:06:41.823360 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997034
I0825 00:06:41.823372 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997669
I0825 00:06:41.823386 44210 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0825 00:06:58.452567 44210 solver.cpp:228] Iteration 4200, loss = 0.012767
I0825 00:06:58.452667 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994813
I0825 00:06:58.452684 44210 solver.cpp:244]     Train net output #1: loss = 0.012767 (* 1 = 0.012767 loss)
I0825 00:06:58.452695 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994569
I0825 00:06:58.452706 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995394
I0825 00:06:58.452715 44210 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0825 00:07:15.080700 44210 solver.cpp:228] Iteration 4220, loss = 0.0102869
I0825 00:07:15.080749 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996227
I0825 00:07:15.080771 44210 solver.cpp:244]     Train net output #1: loss = 0.0102868 (* 1 = 0.0102868 loss)
I0825 00:07:15.080781 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996798
I0825 00:07:15.080791 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993585
I0825 00:07:15.080801 44210 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0825 00:07:31.722236 44210 solver.cpp:228] Iteration 4240, loss = 0.00942908
I0825 00:07:31.722340 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996425
I0825 00:07:31.722357 44210 solver.cpp:244]     Train net output #1: loss = 0.00942902 (* 1 = 0.00942902 loss)
I0825 00:07:31.722363 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996808
I0825 00:07:31.722369 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995117
I0825 00:07:31.722378 44210 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0825 00:07:48.389572 44210 solver.cpp:228] Iteration 4260, loss = 0.0152269
I0825 00:07:48.389631 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99418
I0825 00:07:48.389647 44210 solver.cpp:244]     Train net output #1: loss = 0.0152268 (* 1 = 0.0152268 loss)
I0825 00:07:48.389654 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994605
I0825 00:07:48.389660 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993342
I0825 00:07:48.389670 44210 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0825 00:08:05.058140 44210 solver.cpp:228] Iteration 4280, loss = 0.0127928
I0825 00:08:05.058267 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994637
I0825 00:08:05.058286 44210 solver.cpp:244]     Train net output #1: loss = 0.0127928 (* 1 = 0.0127928 loss)
I0825 00:08:05.058295 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994366
I0825 00:08:05.058302 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995473
I0825 00:08:05.058311 44210 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0825 00:08:21.686748 44210 solver.cpp:228] Iteration 4300, loss = 0.0127392
I0825 00:08:21.686797 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994894
I0825 00:08:21.686812 44210 solver.cpp:244]     Train net output #1: loss = 0.0127391 (* 1 = 0.0127391 loss)
I0825 00:08:21.686820 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995541
I0825 00:08:21.686825 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99033
I0825 00:08:21.686836 44210 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0825 00:08:38.324429 44210 solver.cpp:228] Iteration 4320, loss = 0.00998814
I0825 00:08:38.324599 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99583
I0825 00:08:38.324616 44210 solver.cpp:244]     Train net output #1: loss = 0.00998808 (* 1 = 0.00998808 loss)
I0825 00:08:38.324626 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994855
I0825 00:08:38.324638 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997461
I0825 00:08:38.324648 44210 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0825 00:08:54.960732 44210 solver.cpp:228] Iteration 4340, loss = 0.00740889
I0825 00:08:54.960783 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996725
I0825 00:08:54.960798 44210 solver.cpp:244]     Train net output #1: loss = 0.00740883 (* 1 = 0.00740883 loss)
I0825 00:08:54.960811 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99676
I0825 00:08:54.960824 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996568
I0825 00:08:54.960832 44210 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0825 00:09:11.588676 44210 solver.cpp:228] Iteration 4360, loss = 0.0115052
I0825 00:09:11.588791 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995537
I0825 00:09:11.588810 44210 solver.cpp:244]     Train net output #1: loss = 0.0115052 (* 1 = 0.0115052 loss)
I0825 00:09:11.588819 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99505
I0825 00:09:11.588825 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996371
I0825 00:09:11.588835 44210 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0825 00:09:28.221493 44210 solver.cpp:228] Iteration 4380, loss = 0.0100458
I0825 00:09:28.221542 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996081
I0825 00:09:28.221559 44210 solver.cpp:244]     Train net output #1: loss = 0.0100457 (* 1 = 0.0100457 loss)
I0825 00:09:28.221572 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995063
I0825 00:09:28.221578 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997606
I0825 00:09:28.221588 44210 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0825 00:09:44.862992 44210 solver.cpp:228] Iteration 4400, loss = 0.0137773
I0825 00:09:44.863097 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994089
I0825 00:09:44.863122 44210 solver.cpp:244]     Train net output #1: loss = 0.0137773 (* 1 = 0.0137773 loss)
I0825 00:09:44.863131 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993066
I0825 00:09:44.863143 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996396
I0825 00:09:44.863152 44210 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0825 00:10:01.525729 44210 solver.cpp:228] Iteration 4420, loss = 0.00753954
I0825 00:10:01.525786 44210 solver.cpp:244]     Train net output #0: accuracy = 0.9968
I0825 00:10:01.525802 44210 solver.cpp:244]     Train net output #1: loss = 0.00753948 (* 1 = 0.00753948 loss)
I0825 00:10:01.525811 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996797
I0825 00:10:01.525817 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996813
I0825 00:10:01.525827 44210 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0825 00:10:18.168720 44210 solver.cpp:228] Iteration 4440, loss = 0.00990264
I0825 00:10:18.168833 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996091
I0825 00:10:18.168851 44210 solver.cpp:244]     Train net output #1: loss = 0.00990258 (* 1 = 0.00990258 loss)
I0825 00:10:18.168864 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995828
I0825 00:10:18.168874 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996745
I0825 00:10:18.168882 44210 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0825 00:10:34.794258 44210 solver.cpp:228] Iteration 4460, loss = 0.0117779
I0825 00:10:34.794301 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996497
I0825 00:10:34.794332 44210 solver.cpp:244]     Train net output #1: loss = 0.0117779 (* 1 = 0.0117779 loss)
I0825 00:10:34.794340 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996584
I0825 00:10:34.794353 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996048
I0825 00:10:34.794363 44210 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0825 00:10:51.431442 44210 solver.cpp:228] Iteration 4480, loss = 0.0159644
I0825 00:10:51.431612 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993176
I0825 00:10:51.431637 44210 solver.cpp:244]     Train net output #1: loss = 0.0159644 (* 1 = 0.0159644 loss)
I0825 00:10:51.431645 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992227
I0825 00:10:51.431658 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994793
I0825 00:10:51.431668 44210 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0825 00:11:08.059521 44210 solver.cpp:228] Iteration 4500, loss = 0.011012
I0825 00:11:08.059563 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996118
I0825 00:11:08.059578 44210 solver.cpp:244]     Train net output #1: loss = 0.0110119 (* 1 = 0.0110119 loss)
I0825 00:11:08.059587 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997133
I0825 00:11:08.059592 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992697
I0825 00:11:08.059602 44210 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0825 00:11:24.701416 44210 solver.cpp:228] Iteration 4520, loss = 0.00930764
I0825 00:11:24.701541 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99639
I0825 00:11:24.701562 44210 solver.cpp:244]     Train net output #1: loss = 0.00930758 (* 1 = 0.00930758 loss)
I0825 00:11:24.701576 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996566
I0825 00:11:24.701584 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995562
I0825 00:11:24.701594 44210 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0825 00:11:41.355514 44210 solver.cpp:228] Iteration 4540, loss = 0.00990297
I0825 00:11:41.355557 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995932
I0825 00:11:41.355572 44210 solver.cpp:244]     Train net output #1: loss = 0.00990291 (* 1 = 0.00990291 loss)
I0825 00:11:41.355581 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995959
I0825 00:11:41.355587 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995839
I0825 00:11:41.355597 44210 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0825 00:11:57.982750 44210 solver.cpp:228] Iteration 4560, loss = 0.00764508
I0825 00:11:57.982864 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996984
I0825 00:11:57.982882 44210 solver.cpp:244]     Train net output #1: loss = 0.00764502 (* 1 = 0.00764502 loss)
I0825 00:11:57.982894 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99683
I0825 00:11:57.982906 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997283
I0825 00:11:57.982928 44210 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0825 00:12:14.628748 44210 solver.cpp:228] Iteration 4580, loss = 0.0125272
I0825 00:12:14.628799 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995537
I0825 00:12:14.628815 44210 solver.cpp:244]     Train net output #1: loss = 0.0125271 (* 1 = 0.0125271 loss)
I0825 00:12:14.628823 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995357
I0825 00:12:14.628829 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995966
I0825 00:12:14.628849 44210 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0825 00:12:31.258584 44210 solver.cpp:228] Iteration 4600, loss = 0.00664431
I0825 00:12:31.258757 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99695
I0825 00:12:31.258798 44210 solver.cpp:244]     Train net output #1: loss = 0.00664425 (* 1 = 0.00664425 loss)
I0825 00:12:31.258810 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996326
I0825 00:12:31.258821 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998475
I0825 00:12:31.258831 44210 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0825 00:12:47.883461 44210 solver.cpp:228] Iteration 4620, loss = 0.00952722
I0825 00:12:47.883524 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996497
I0825 00:12:47.883551 44210 solver.cpp:244]     Train net output #1: loss = 0.00952716 (* 1 = 0.00952716 loss)
I0825 00:12:47.883561 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995884
I0825 00:12:47.883574 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997459
I0825 00:12:47.883582 44210 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0825 00:13:04.508499 44210 solver.cpp:228] Iteration 4640, loss = 0.0123039
I0825 00:13:04.508628 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995383
I0825 00:13:04.508648 44210 solver.cpp:244]     Train net output #1: loss = 0.0123038 (* 1 = 0.0123038 loss)
I0825 00:13:04.508657 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995524
I0825 00:13:04.508668 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995131
I0825 00:13:04.508678 44210 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0825 00:13:21.141808 44210 solver.cpp:228] Iteration 4660, loss = 0.0108275
I0825 00:13:21.141855 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995385
I0825 00:13:21.141883 44210 solver.cpp:244]     Train net output #1: loss = 0.0108275 (* 1 = 0.0108275 loss)
I0825 00:13:21.141893 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995648
I0825 00:13:21.141906 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994495
I0825 00:13:21.141914 44210 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0825 00:13:37.803234 44210 solver.cpp:228] Iteration 4680, loss = 0.0121174
I0825 00:13:37.803357 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995443
I0825 00:13:37.803380 44210 solver.cpp:244]     Train net output #1: loss = 0.0121174 (* 1 = 0.0121174 loss)
I0825 00:13:37.803392 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994825
I0825 00:13:37.803400 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996796
I0825 00:13:37.803411 44210 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0825 00:13:54.459533 44210 solver.cpp:228] Iteration 4700, loss = 0.00796839
I0825 00:13:54.459584 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996646
I0825 00:13:54.459617 44210 solver.cpp:244]     Train net output #1: loss = 0.00796833 (* 1 = 0.00796833 loss)
I0825 00:13:54.459627 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996447
I0825 00:13:54.459645 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997079
I0825 00:13:54.459656 44210 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0825 00:14:11.099803 44210 solver.cpp:228] Iteration 4720, loss = 0.00871636
I0825 00:14:11.099937 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996461
I0825 00:14:11.099975 44210 solver.cpp:244]     Train net output #1: loss = 0.0087163 (* 1 = 0.0087163 loss)
I0825 00:14:11.099984 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996772
I0825 00:14:11.099995 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995023
I0825 00:14:11.100003 44210 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0825 00:14:27.795017 44210 solver.cpp:228] Iteration 4740, loss = 0.0113413
I0825 00:14:27.795058 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995007
I0825 00:14:27.795075 44210 solver.cpp:244]     Train net output #1: loss = 0.0113412 (* 1 = 0.0113412 loss)
I0825 00:14:27.795084 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994413
I0825 00:14:27.795094 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996505
I0825 00:14:27.795102 44210 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0825 00:14:44.446575 44210 solver.cpp:228] Iteration 4760, loss = 0.00795587
I0825 00:14:44.446722 44210 solver.cpp:244]     Train net output #0: accuracy = 0.997118
I0825 00:14:44.446756 44210 solver.cpp:244]     Train net output #1: loss = 0.00795581 (* 1 = 0.00795581 loss)
I0825 00:14:44.446766 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997734
I0825 00:14:44.446777 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992503
I0825 00:14:44.446786 44210 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0825 00:15:01.092177 44210 solver.cpp:228] Iteration 4780, loss = 0.00642779
I0825 00:15:01.092228 44210 solver.cpp:244]     Train net output #0: accuracy = 0.997598
I0825 00:15:01.092243 44210 solver.cpp:244]     Train net output #1: loss = 0.00642773 (* 1 = 0.00642773 loss)
I0825 00:15:01.092250 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998029
I0825 00:15:01.092257 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993946
I0825 00:15:01.092267 44210 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0825 00:15:17.757066 44210 solver.cpp:228] Iteration 4800, loss = 0.00996151
I0825 00:15:17.757197 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995955
I0825 00:15:17.757215 44210 solver.cpp:244]     Train net output #1: loss = 0.00996145 (* 1 = 0.00996145 loss)
I0825 00:15:17.757228 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995736
I0825 00:15:17.757239 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996843
I0825 00:15:17.757247 44210 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0825 00:15:34.419960 44210 solver.cpp:228] Iteration 4820, loss = 0.0116361
I0825 00:15:34.420007 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994967
I0825 00:15:34.420027 44210 solver.cpp:244]     Train net output #1: loss = 0.011636 (* 1 = 0.011636 loss)
I0825 00:15:34.420035 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993665
I0825 00:15:34.420040 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997116
I0825 00:15:34.420050 44210 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0825 00:15:51.087286 44210 solver.cpp:228] Iteration 4840, loss = 0.00689715
I0825 00:15:51.087426 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99716
I0825 00:15:51.087445 44210 solver.cpp:244]     Train net output #1: loss = 0.00689709 (* 1 = 0.00689709 loss)
I0825 00:15:51.087451 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996791
I0825 00:15:51.087457 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997971
I0825 00:15:51.087467 44210 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0825 00:16:07.752904 44210 solver.cpp:228] Iteration 4860, loss = 0.00704802
I0825 00:16:07.752955 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996963
I0825 00:16:07.752971 44210 solver.cpp:244]     Train net output #1: loss = 0.00704796 (* 1 = 0.00704796 loss)
I0825 00:16:07.752979 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996259
I0825 00:16:07.752985 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998451
I0825 00:16:07.753005 44210 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0825 00:16:24.395186 44210 solver.cpp:228] Iteration 4880, loss = 0.00805526
I0825 00:16:24.395308 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99717
I0825 00:16:24.395330 44210 solver.cpp:244]     Train net output #1: loss = 0.0080552 (* 1 = 0.0080552 loss)
I0825 00:16:24.395342 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996673
I0825 00:16:24.395354 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997886
I0825 00:16:24.395364 44210 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0825 00:16:41.072188 44210 solver.cpp:228] Iteration 4900, loss = 0.0118023
I0825 00:16:41.072249 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995764
I0825 00:16:41.072265 44210 solver.cpp:244]     Train net output #1: loss = 0.0118022 (* 1 = 0.0118022 loss)
I0825 00:16:41.072273 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995532
I0825 00:16:41.072280 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996134
I0825 00:16:41.072299 44210 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0825 00:16:57.718226 44210 solver.cpp:228] Iteration 4920, loss = 0.00741615
I0825 00:16:57.718423 44210 solver.cpp:244]     Train net output #0: accuracy = 0.997193
I0825 00:16:57.718448 44210 solver.cpp:244]     Train net output #1: loss = 0.00741609 (* 1 = 0.00741609 loss)
I0825 00:16:57.718459 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997952
I0825 00:16:57.718474 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99418
I0825 00:16:57.718489 44210 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0825 00:17:14.360810 44210 solver.cpp:228] Iteration 4940, loss = 0.00716554
I0825 00:17:14.360860 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99697
I0825 00:17:14.360883 44210 solver.cpp:244]     Train net output #1: loss = 0.00716548 (* 1 = 0.00716548 loss)
I0825 00:17:14.360891 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99704
I0825 00:17:14.360898 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996749
I0825 00:17:14.360908 44210 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0825 00:17:31.071704 44210 solver.cpp:228] Iteration 4960, loss = 0.012866
I0825 00:17:31.071871 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994991
I0825 00:17:31.071919 44210 solver.cpp:244]     Train net output #1: loss = 0.0128659 (* 1 = 0.0128659 loss)
I0825 00:17:31.071930 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994961
I0825 00:17:31.071940 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995059
I0825 00:17:31.071949 44210 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0825 00:17:47.776046 44210 solver.cpp:228] Iteration 4980, loss = 0.00913234
I0825 00:17:47.776134 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995966
I0825 00:17:47.776151 44210 solver.cpp:244]     Train net output #1: loss = 0.00913228 (* 1 = 0.00913228 loss)
I0825 00:17:47.776160 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995742
I0825 00:17:47.776172 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996634
I0825 00:17:47.776181 44210 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0825 00:18:04.096411 44210 solver.cpp:454] Snapshotting to binary proto file pocwisc7/training_iter_5000.caffemodel
I0825 00:18:05.182621 44210 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc7/training_iter_5000.solverstate
I0825 00:18:05.782177 44210 solver.cpp:317] Iteration 5000, loss = 0.00609329
I0825 00:18:05.782230 44210 solver.cpp:322] Optimization Done.
I0825 00:18:05.782244 44210 caffe.cpp:254] Optimization Done.
