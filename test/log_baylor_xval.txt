2017-09-11 23:20:02,299 log.framework MainThread  INFO       Picture selection is done from the global 'gpic_selection_file' file!
2017-09-11 23:20:02,305 log.framework MainThread  INFO       The framework runs with this configuration: 
work_area: ['pocwisc1', 'pocwisc2', 'pocwisc3', 'pocwisc4', 'pocwisc5', 'pocwisc6', 'pocwisc7']
job_type: 
input_csv: CRF_DU_v2.csv
time_interval: 0
n_split: 7
shuffle: False
random_state: None
split_method: burnarea
keep_logs: False
gpic_selection_file: /disk2/nik/Analyzer/test/pics.txt
2017-09-11 23:20:02,306 log.framework MainThread  INFO       Creating HDF5Files area
2017-09-11 23:20:05,055 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:05,055 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:05,078 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:05,078 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:05,079 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:05,083 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:05,083 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:05,083 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:05,083 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:05,381 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:05,381 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:05,401 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:05,401 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:05,401 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:05,405 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:05,405 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:05,405 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:05,405 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:05,678 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:05,679 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:05,696 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:05,696 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:05,697 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:05,701 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:05,701 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:05,701 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:05,701 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:05,967 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:05,967 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:05,982 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:05,982 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:05,982 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:05,986 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:05,986 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:05,987 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:05,987 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:06,243 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:06,243 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:06,260 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:06,260 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:06,260 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:06,264 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:06,264 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:06,264 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:06,264 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:06,547 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:06,547 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:06,564 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:06,565 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:06,565 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:06,569 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:06,569 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:06,569 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:06,569 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_11
2017-09-11 23:20:06,859 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:06,859 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:06,875 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:06,876 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:06,876 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:06,880 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:06,880 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:06,880 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:06,880 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:06,881 log.framework MainThread  INFO       Creating HDF5Files area
2017-09-11 23:20:07,177 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:07,177 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:07,196 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:07,196 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:07,196 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:07,200 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:07,200 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:07,200 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:07,200 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_3
2017-09-11 23:20:07,542 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:07,542 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:07,561 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:07,561 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:07,562 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:07,566 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:07,566 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:07,566 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:07,566 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:07,831 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:07,831 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:07,848 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:07,848 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:07,848 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:07,852 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:07,852 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:07,852 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:07,852 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:08,106 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:08,107 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:08,127 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:08,127 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:08,127 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:08,131 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:08,131 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:08,131 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:08,131 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:08,398 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:08,398 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:08,416 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:08,416 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:08,416 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:08,420 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:08,420 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:08,421 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:08,421 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_4
2017-09-11 23:20:08,687 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:08,687 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:08,707 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:08,707 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:08,707 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:08,711 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:08,711 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:08,711 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:08,712 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:08,712 log.framework MainThread  INFO       Creating HDF5Files area
2017-09-11 23:20:08,998 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:08,998 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:09,014 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:09,015 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:09,015 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:09,019 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:09,019 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:09,019 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:09,019 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_6
2017-09-11 23:20:09,357 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:09,357 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:09,373 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:09,373 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:09,373 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:09,377 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:09,377 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:09,377 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:09,377 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_1
2017-09-11 23:20:09,619 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:09,619 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:09,638 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:09,638 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:09,638 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:09,642 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:09,643 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:09,643 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:09,643 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_2
2017-09-11 23:20:09,888 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:09,888 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:09,908 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:09,908 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:09,908 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:09,912 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:09,912 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:09,912 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:09,912 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_7
2017-09-11 23:20:09,913 log.framework MainThread  INFO       Creating HDF5Files area
2017-09-11 23:20:10,174 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:10,175 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:10,193 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:10,193 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:10,193 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:10,197 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:10,197 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:10,197 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:10,197 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_5
2017-09-11 23:20:10,484 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:10,484 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:10,503 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:10,503 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:10,503 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:10,507 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:10,507 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:10,507 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:10,507 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:10,798 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:10,798 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:10,817 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:10,817 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:10,818 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:10,822 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:10,822 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:10,822 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:10,822 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:11,083 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:11,083 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:11,102 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:11,103 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:11,103 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:11,107 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:11,107 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:11,107 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:11,107 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:11,396 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:11,396 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:11,412 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:11,412 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:11,412 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:11,416 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:11,416 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:11,416 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:11,416 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_10
2017-09-11 23:20:11,662 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:11,662 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:11,678 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:11,678 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:11,678 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:11,682 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:11,682 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:11,682 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:11,682 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_11
2017-09-11 23:20:11,683 log.framework MainThread  INFO       Creating HDF5Files area
2017-09-11 23:20:11,915 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:11,915 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:11,931 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:11,931 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:11,931 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:11,935 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:11,935 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:11,935 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:11,935 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:12,163 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:12,163 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:12,180 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:12,180 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:12,180 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:12,184 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:12,184 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:12,185 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:12,185 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:12,420 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:12,421 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:12,437 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:12,437 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:12,438 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:12,442 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:12,442 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:12,442 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:12,442 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:12,680 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:12,680 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:12,700 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:12,700 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:12,700 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:12,704 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:12,704 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:12,704 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:12,704 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:12,705 log.framework MainThread  INFO       Creating HDF5Files area
2017-09-11 23:20:12,942 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:12,943 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:12,959 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:12,959 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:12,959 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:12,963 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:12,964 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:12,964 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:12,964 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:13,205 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:13,205 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:13,222 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:13,222 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:13,222 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:13,226 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:13,226 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:13,226 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:13,226 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:13,227 log.framework MainThread  INFO       Creating HDF5Files area
2017-09-11 23:20:13,465 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:13,465 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:13,484 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:13,484 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:13,484 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:13,488 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:13,488 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:13,488 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:13,489 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_6
2017-09-11 23:20:13,731 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:13,731 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:13,748 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:13,748 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:13,748 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:13,752 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:13,752 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:13,752 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:13,752 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_12
2017-09-11 23:20:13,994 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:13,994 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:14,012 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:14,012 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:14,012 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:14,016 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:14,017 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:14,017 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:14,017 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:14,254 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:14,255 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:14,272 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:14,272 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:14,272 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:14,276 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:14,276 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:14,276 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:14,276 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Leg_ImageColl_6
2017-09-11 23:20:14,277 log.framework MainThread  ERROR      HDF5Files already there
2017-09-11 23:20:14,519 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:14,519 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:14,538 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:14,538 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:14,538 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:14,542 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:14,542 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:14,542 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:14,542 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_3
2017-09-11 23:20:14,783 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:14,783 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:14,800 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:14,800 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:14,800 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:14,804 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:14,804 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:14,804 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:14,804 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:15,047 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:15,047 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:15,065 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:15,066 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:15,066 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:15,070 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:15,070 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:15,070 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:15,070 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_5
2017-09-11 23:20:15,312 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:15,312 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:15,330 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:15,331 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:15,331 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:15,335 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:15,335 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:15,335 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:15,335 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_4
2017-09-11 23:20:15,577 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:15,577 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:15,596 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:15,596 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:15,596 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:15,600 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:15,600 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:15,600 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:15,600 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:15,838 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:15,838 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:15,858 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:15,858 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:15,858 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:15,862 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:15,862 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:15,862 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:15,862 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:16,102 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:16,102 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:16,119 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:16,119 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:16,119 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:16,123 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:16,123 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:16,123 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:16,123 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:16,388 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:16,388 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:16,405 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:16,405 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:16,405 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:16,409 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:16,409 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:16,409 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:16,409 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_6
2017-09-11 23:20:16,604 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:16,605 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:16,620 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:16,621 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:16,621 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:16,625 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:16,625 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:16,625 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:16,625 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_7
2017-09-11 23:20:16,851 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:16,851 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:16,869 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:16,869 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:16,869 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:16,873 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:16,873 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:16,873 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:16,873 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:17,113 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:17,113 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:17,133 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:17,133 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:17,134 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:17,138 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:17,138 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:17,138 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:17,138 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_10
2017-09-11 23:20:17,373 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:17,373 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:17,394 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:17,394 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:17,394 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:17,398 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:17,398 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:17,398 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:17,398 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_11
2017-09-11 23:20:17,636 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:17,636 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:17,655 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:17,655 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:17,655 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:17,659 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:17,659 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:17,659 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:17,659 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_6
2017-09-11 23:20:17,899 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:17,899 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:17,918 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:17,918 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:17,918 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:17,922 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:17,922 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:17,922 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:17,923 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:18,157 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:18,157 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:18,173 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:18,173 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:18,173 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:18,177 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:18,178 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:18,178 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:18,178 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_1
2017-09-11 23:20:18,418 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:18,418 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:18,437 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:18,437 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:18,437 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:18,441 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:18,441 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:18,441 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:18,441 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_2
2017-09-11 23:20:18,673 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:18,673 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:18,690 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:18,690 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:18,690 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:18,694 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:18,694 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:18,694 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:18,695 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Leg_ImageColl_6
2017-09-11 23:20:18,934 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:18,934 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:18,954 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:18,954 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:18,954 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:18,958 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:18,958 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:18,958 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:18,958 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:19,217 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:19,217 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:19,236 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:19,236 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:19,236 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:19,240 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:19,240 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:19,240 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:19,240 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:19,486 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:19,487 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:19,507 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:19,507 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:19,507 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:19,511 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:19,512 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:19,512 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:19,512 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:19,756 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:19,756 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:19,773 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:19,773 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:19,773 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:19,777 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:19,777 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:19,777 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:19,777 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:20,015 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:20,015 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:20,031 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:20,031 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:20,031 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:20,035 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:20,036 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:20,036 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:20,036 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_12
2017-09-11 23:20:20,272 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:20,272 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:20,291 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:20,291 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:20,292 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:20,296 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:20,296 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:20,296 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:20,296 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:20,536 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:20,536 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:20,556 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:20,556 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:20,556 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:20,560 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:20,560 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:20,560 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:20,560 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:20,799 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:20,800 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:20,819 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:20,819 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:20,820 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:20,824 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:20,824 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:20,824 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:20,824 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:21,062 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:21,062 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:21,081 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:21,081 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:21,081 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:21,085 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:21,086 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:21,086 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:21,086 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:21,086 log.framework MainThread  ERROR      HDF5Files already there
2017-09-11 23:20:21,323 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:21,323 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:21,342 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:21,342 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:21,342 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:21,346 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:21,346 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:21,346 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:21,346 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_5
2017-09-11 23:20:21,585 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:21,585 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:21,604 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:21,604 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:21,604 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:21,608 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:21,608 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:21,608 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:21,608 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:21,882 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:21,883 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:21,902 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:21,903 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:21,903 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:21,907 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:21,907 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:21,907 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:21,907 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:22,104 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:22,104 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:22,120 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:22,120 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:22,120 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:22,124 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:22,124 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:22,124 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:22,124 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:22,363 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:22,363 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:22,381 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:22,381 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:22,381 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:22,385 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:22,385 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:22,385 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:22,385 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:22,628 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:22,628 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:22,645 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:22,645 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:22,645 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:22,650 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:22,650 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:22,650 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:22,650 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:22,896 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:22,896 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:22,913 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:22,913 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:22,913 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:22,917 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:22,917 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:22,917 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:22,917 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_6
2017-09-11 23:20:23,164 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:23,165 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:23,181 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:23,181 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:23,181 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:23,185 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:23,186 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:23,186 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:23,186 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_7
2017-09-11 23:20:23,428 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:23,428 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:23,445 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:23,445 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:23,445 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:23,449 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:23,449 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:23,449 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:23,449 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:23,692 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:23,692 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:23,709 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:23,709 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:23,709 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:23,713 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:23,713 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:23,713 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:23,713 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:23,956 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:23,956 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:23,972 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:23,972 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:23,973 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:23,977 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:23,977 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:23,977 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:23,977 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:24,218 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:24,218 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:24,235 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:24,235 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:24,235 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:24,239 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:24,239 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:24,239 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:24,239 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:24,485 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:24,485 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:24,501 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:24,502 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:24,502 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:24,506 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:24,506 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:24,506 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:24,506 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:24,752 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:24,752 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:24,768 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:24,768 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:24,769 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:24,773 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:24,773 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:24,773 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:24,773 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_11
2017-09-11 23:20:25,014 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:25,014 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:25,030 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:25,030 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:25,030 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:25,034 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:25,034 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:25,034 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:25,035 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_10
2017-09-11 23:20:25,273 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:25,273 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:25,290 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:25,290 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:25,290 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:25,294 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:25,294 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:25,294 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:25,294 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_11
2017-09-11 23:20:25,537 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:25,537 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:25,554 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:25,554 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:25,554 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:25,558 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:25,558 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:25,559 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:25,559 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_6
2017-09-11 23:20:25,792 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:25,793 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:25,810 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:25,810 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:25,810 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:25,814 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:25,814 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:25,814 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:25,814 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:26,055 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:26,056 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:26,074 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:26,075 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:26,075 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:26,079 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:26,079 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:26,079 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:26,079 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_1
2017-09-11 23:20:26,320 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:26,320 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:26,337 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:26,337 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:26,338 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:26,342 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:26,342 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:26,342 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:26,342 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_2
2017-09-11 23:20:26,585 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:26,585 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:26,603 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:26,603 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:26,603 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:26,608 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:26,608 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:26,608 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:26,608 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Leg_ImageColl_6
2017-09-11 23:20:26,835 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:26,835 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:26,853 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:26,853 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:26,853 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:26,857 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:26,857 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:26,857 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:26,857 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:27,096 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:27,096 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:27,115 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:27,115 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:27,116 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:27,120 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:27,120 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:27,120 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:27,120 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:27,360 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:27,360 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:27,377 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:27,378 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:27,378 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:27,382 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:27,382 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:27,382 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:27,382 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_12
2017-09-11 23:20:27,574 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:27,575 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:27,592 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:27,592 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:27,592 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:27,596 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:27,596 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:27,596 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:27,597 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:27,834 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:27,835 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:27,851 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:27,851 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:27,851 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:27,856 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:27,856 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:27,856 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:27,856 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:28,094 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:28,095 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:28,113 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:28,113 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:28,113 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:28,117 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:28,117 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:28,118 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:28,118 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:28,118 log.framework MainThread  ERROR      HDF5Files already there
2017-09-11 23:20:28,356 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:28,356 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:28,375 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:28,375 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:28,375 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:28,379 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:28,379 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:28,379 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:28,379 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_3
2017-09-11 23:20:28,619 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:28,619 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:28,638 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:28,638 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:28,638 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:28,642 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:28,643 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:28,643 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:28,643 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:28,883 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:28,883 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:28,902 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:28,902 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:28,902 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:28,906 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:28,906 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:28,906 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:28,906 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_5
2017-09-11 23:20:29,148 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:29,148 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:29,166 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:29,166 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:29,166 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:29,170 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:29,170 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:29,170 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:29,170 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:29,412 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:29,412 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:29,430 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:29,430 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:29,430 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:29,434 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:29,434 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:29,434 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:29,434 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:29,665 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:29,665 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:29,680 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:29,680 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:29,681 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:29,685 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:29,685 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:29,685 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:29,685 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:29,924 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:29,925 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:29,944 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:29,945 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:29,945 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:29,949 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:29,949 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:29,949 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:29,949 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:30,185 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:30,185 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:30,201 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:30,201 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:30,201 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:30,206 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:30,206 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:30,206 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:30,206 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:30,444 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:30,444 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:30,463 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:30,464 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:30,464 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:30,468 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:30,468 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:30,468 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:30,468 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:30,707 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:30,708 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:30,726 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:30,726 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:30,726 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:30,730 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:30,730 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:30,730 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:30,730 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:30,970 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:30,970 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:30,989 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:30,989 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:30,989 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:30,993 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:30,993 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:30,993 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:30,993 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:31,233 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:31,233 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:31,250 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:31,251 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:31,251 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:31,255 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:31,255 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:31,255 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:31,255 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_4
2017-09-11 23:20:31,496 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:31,497 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:31,515 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:31,515 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:31,515 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:31,520 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:31,520 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:31,520 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:31,520 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:31,762 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:31,762 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:31,779 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:31,779 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:31,779 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:31,783 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:31,784 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:31,784 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:31,784 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:32,026 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:32,026 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:32,044 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:32,044 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:32,044 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:32,049 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:32,049 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:32,049 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:32,049 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_11
2017-09-11 23:20:32,289 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:32,289 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:32,307 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:32,308 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:32,308 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:32,312 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:32,312 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:32,312 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:32,312 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_10
2017-09-11 23:20:32,550 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:32,550 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:32,569 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:32,569 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:32,569 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:32,573 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:32,573 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:32,573 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:32,573 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_11
2017-09-11 23:20:32,841 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:32,841 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:32,861 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:32,861 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:32,861 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:32,865 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:32,865 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:32,865 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:32,865 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_6
2017-09-11 23:20:33,059 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:33,059 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:33,074 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:33,074 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:33,074 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:33,078 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:33,078 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:33,078 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:33,078 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:33,264 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:33,264 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:33,279 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:33,279 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:33,279 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:33,284 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:33,284 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:33,284 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:33,284 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:33,470 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:33,470 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:33,486 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:33,486 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:33,486 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:33,490 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:33,490 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:33,490 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:33,490 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Leg_ImageColl_6
2017-09-11 23:20:33,678 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:33,678 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:33,694 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:33,695 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:33,695 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:33,699 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:33,699 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:33,699 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:33,699 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:33,885 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:33,885 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:33,901 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:33,901 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:33,901 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:33,905 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:33,905 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:33,905 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:33,905 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:34,081 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:34,081 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:34,098 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:34,098 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:34,098 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:34,102 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:34,102 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:34,102 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:34,102 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:34,288 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:34,288 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:34,305 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:34,305 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:34,305 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:34,309 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:34,309 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:34,309 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:34,309 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:34,495 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:34,495 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:34,511 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:34,511 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:34,511 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:34,515 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:34,515 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:34,515 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:34,516 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_12
2017-09-11 23:20:34,703 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:34,703 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:34,720 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:34,720 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:34,720 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:34,724 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:34,724 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:34,724 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:34,724 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:34,919 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:34,920 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:34,938 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:34,938 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:34,938 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:34,942 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:34,942 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:34,943 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:34,943 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:35,138 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:35,138 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:35,155 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:35,155 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:35,155 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:35,159 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:35,159 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:35,159 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:35,159 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:35,160 log.framework MainThread  ERROR      HDF5Files already there
2017-09-11 23:20:35,357 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:35,357 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:35,376 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:35,376 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:35,376 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:35,380 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:35,380 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:35,380 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:35,380 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_3
2017-09-11 23:20:35,576 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:35,576 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:35,593 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:35,593 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:35,593 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:35,597 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:35,597 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:35,597 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:35,597 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:35,795 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:35,795 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:35,813 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:35,814 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:35,814 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:35,818 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:35,818 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:35,818 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:35,818 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:36,015 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:36,015 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:36,031 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:36,032 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:36,032 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:36,036 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:36,036 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:36,036 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:36,036 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:36,234 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:36,234 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:36,253 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:36,253 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:36,253 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:36,257 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:36,257 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:36,257 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:36,257 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_6
2017-09-11 23:20:36,452 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:36,453 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:36,470 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:36,471 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:36,471 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:36,475 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:36,475 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:36,475 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:36,475 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_7
2017-09-11 23:20:36,671 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:36,672 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:36,690 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:36,690 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:36,690 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:36,694 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:36,694 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:36,695 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:36,695 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:36,883 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:36,883 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:36,902 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:36,902 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:36,902 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:36,906 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:36,906 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:36,907 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:36,907 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:37,094 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:37,094 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:37,113 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:37,113 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:37,113 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:37,117 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:37,117 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:37,117 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:37,117 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:37,311 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:37,312 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:37,330 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:37,330 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:37,330 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:37,334 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:37,334 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:37,334 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:37,334 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_4
2017-09-11 23:20:37,491 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:37,492 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:37,507 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:37,507 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:37,507 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:37,512 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:37,512 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:37,512 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:37,512 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:37,749 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:37,749 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:37,765 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:37,765 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:37,765 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:37,769 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:37,769 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:37,769 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:37,769 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:38,007 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:38,007 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:38,025 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:38,025 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:38,025 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:38,029 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:38,029 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:38,029 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:38,029 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_11
2017-09-11 23:20:38,266 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:38,266 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:38,284 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:38,284 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:38,284 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:38,288 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:38,288 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:38,289 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:38,289 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_6
2017-09-11 23:20:38,528 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:38,528 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:38,546 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:38,546 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:38,546 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:38,550 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:38,551 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:38,551 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:38,551 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:38,792 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:38,792 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:38,810 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:38,810 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:38,810 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:38,814 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:38,815 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:38,815 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:38,815 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_1
2017-09-11 23:20:39,056 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:39,056 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:39,074 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:39,074 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:39,074 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:39,078 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:39,078 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:39,078 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:39,078 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_2
2017-09-11 23:20:39,318 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:39,318 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:39,336 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:39,336 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:39,336 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:39,340 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:39,340 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:39,340 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:39,340 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Leg_ImageColl_6
2017-09-11 23:20:39,580 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:39,580 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:39,598 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:39,598 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:39,598 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:39,602 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:39,602 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:39,602 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:39,603 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:39,833 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:39,833 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:39,849 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:39,849 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:39,849 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:39,853 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:39,853 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:39,853 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:39,854 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:40,091 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:40,092 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:40,109 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:40,109 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:40,109 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:40,113 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:40,113 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:40,113 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:40,114 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:40,352 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:40,352 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:40,370 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:40,370 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:40,370 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:40,374 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:40,374 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:40,374 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:40,374 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:40,614 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:40,614 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:40,631 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:40,632 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:40,632 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:40,636 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:40,636 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:40,636 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:40,636 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_12
2017-09-11 23:20:40,874 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:40,875 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:40,893 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:40,893 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:40,893 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:40,897 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:40,897 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:40,897 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:40,897 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:41,138 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:41,139 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:41,155 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:41,156 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:41,156 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:41,160 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:41,160 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:41,160 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:41,160 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:41,391 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:41,391 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:41,406 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:41,406 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:41,407 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:41,411 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:41,411 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:41,411 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:41,411 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:41,647 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:41,647 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:41,665 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:41,665 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:41,665 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:41,669 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:41,669 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:41,669 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:41,669 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:41,670 log.framework MainThread  ERROR      HDF5Files already there
2017-09-11 23:20:41,908 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:41,908 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:41,926 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:41,926 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:41,926 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:41,930 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:41,930 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:41,931 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:41,931 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_3
2017-09-11 23:20:42,171 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:42,171 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:42,189 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:42,189 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:42,189 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:42,193 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:42,193 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:42,193 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:42,193 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:42,440 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:42,440 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:42,457 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:42,457 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:42,457 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:42,461 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:42,462 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:42,462 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:42,462 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_5
2017-09-11 23:20:42,714 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:42,714 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:42,733 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:42,733 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:42,733 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:42,738 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:42,738 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:42,738 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:42,738 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:42,928 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:42,928 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:42,943 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:42,943 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:42,943 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:42,947 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:42,947 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:42,947 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:42,947 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:43,178 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:43,178 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:43,196 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:43,196 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:43,196 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:43,200 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:43,200 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:43,200 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:43,200 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:43,439 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:43,439 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:43,457 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:43,457 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:43,457 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:43,461 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:43,461 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:43,461 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:43,461 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:43,703 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:43,703 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:43,721 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:43,722 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:43,722 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:43,726 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:43,726 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:43,726 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:43,726 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:43,969 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:43,969 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:43,985 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:43,985 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:43,985 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:43,989 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:43,989 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:43,990 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:43,990 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_6
2017-09-11 23:20:44,232 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:44,232 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:44,250 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:44,250 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:44,250 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:44,254 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:44,254 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:44,255 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:44,255 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_7
2017-09-11 23:20:44,491 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:44,491 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:44,509 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:44,510 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:44,510 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:44,514 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:44,514 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:44,514 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:44,514 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:44,754 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:44,754 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:44,772 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:44,773 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:44,773 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:44,777 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:44,777 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:44,777 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:44,777 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:45,018 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:45,019 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:45,037 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:45,037 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:45,038 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:45,042 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:45,042 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:45,042 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:45,042 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:45,282 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:45,282 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:45,300 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:45,300 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:45,300 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:45,304 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:45,304 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:45,305 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:45,305 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_4
2017-09-11 23:20:45,544 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:45,544 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:45,563 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:45,563 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:45,563 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:45,567 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:45,567 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:45,567 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:45,567 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:45,807 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:45,807 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:45,826 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:45,826 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:45,826 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:45,830 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:45,830 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:45,830 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:45,831 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:46,070 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:46,070 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:46,089 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:46,089 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:46,089 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:46,093 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:46,094 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:46,094 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:46,094 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_11
2017-09-11 23:20:46,332 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:46,332 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:46,350 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:46,350 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:46,350 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:46,354 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:46,355 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:46,355 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:46,355 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_10
2017-09-11 23:20:46,589 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:46,590 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:46,608 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:46,608 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:46,608 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:46,612 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:46,612 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:46,612 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:46,612 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_11
2017-09-11 23:20:46,850 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:46,850 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:46,868 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:46,869 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:46,869 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:46,873 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:46,873 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:46,873 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:46,873 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_6
2017-09-11 23:20:47,112 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:47,112 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:47,131 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:47,131 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:47,131 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:47,135 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:47,135 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:47,136 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:47,136 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:47,377 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:47,378 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:47,396 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:47,396 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:47,396 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:47,400 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:47,400 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:47,400 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:47,400 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_1
2017-09-11 23:20:47,637 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:47,637 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:47,656 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:47,656 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:47,656 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:47,660 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:47,660 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:47,660 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:47,660 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_2
2017-09-11 23:20:47,907 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:47,907 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:47,926 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:47,926 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:47,926 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:47,930 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:47,930 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:47,930 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:47,930 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Leg_ImageColl_6
2017-09-11 23:20:48,180 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:48,180 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:48,199 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:48,199 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:48,199 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:48,203 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:48,203 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:48,203 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:48,204 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:48,396 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:48,396 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:48,412 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:48,412 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:48,412 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:48,416 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:48,416 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:48,416 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:48,416 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:48,654 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:48,654 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:48,669 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:48,669 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:48,669 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:48,674 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:48,674 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:48,674 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:48,674 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:48,913 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:48,913 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:48,930 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:48,931 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:48,931 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:48,935 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:48,935 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:48,935 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:48,935 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_12
2017-09-11 23:20:49,171 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:49,171 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:49,188 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:49,189 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:49,189 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:49,193 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:49,193 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:49,193 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:49,193 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:49,194 log.framework MainThread  ERROR      HDF5Files already there
2017-09-11 23:20:49,431 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:49,431 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:49,449 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:49,449 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:49,449 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:49,453 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:49,453 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:49,453 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:49,453 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_3
2017-09-11 23:20:49,693 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:49,694 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:49,710 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:49,710 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:49,710 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:49,714 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:49,714 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:49,714 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:49,714 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:49,948 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:49,948 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:49,963 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:49,963 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:49,963 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:49,967 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:49,967 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:49,967 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:49,967 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_5
2017-09-11 23:20:50,206 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:50,206 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:50,222 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:50,222 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:50,222 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:50,226 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:50,226 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:50,226 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:50,226 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:50,469 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:50,469 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:50,487 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:50,487 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:50,487 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:50,491 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:50,491 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:50,491 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:50,491 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:50,731 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:50,731 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:50,749 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:50,750 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:50,750 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:50,754 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:50,754 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:50,754 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:50,754 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:50,994 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:50,994 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:51,011 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:51,012 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:51,012 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:51,016 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:51,016 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:51,016 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:51,016 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:51,255 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:51,256 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:51,272 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:51,272 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:51,272 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:51,276 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:51,276 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:51,276 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:51,276 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:51,519 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:51,520 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:51,538 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:51,538 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:51,538 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:51,542 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:51,542 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:51,542 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:51,542 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_6
2017-09-11 23:20:51,774 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:51,775 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:51,790 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:51,790 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:51,790 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:51,794 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:51,795 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:51,795 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:51,795 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_7
2017-09-11 23:20:52,034 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:52,035 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:52,052 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:52,052 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:52,052 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:52,056 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:52,056 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:52,056 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:52,056 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:52,294 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:52,294 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:52,311 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:52,312 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:52,312 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:52,316 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:52,316 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:52,316 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:52,316 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:52,549 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:52,549 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:52,564 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:52,564 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:52,564 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:52,569 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:52,569 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:52,569 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:52,569 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_4
2017-09-11 23:20:52,808 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:52,808 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:52,824 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:52,824 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:52,824 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:52,828 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:52,829 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:52,829 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:52,829 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_1
2017-09-11 23:20:53,078 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:53,078 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:53,097 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:53,097 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:53,097 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:53,101 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:53,101 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:53,101 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:53,101 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:53,350 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:53,350 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:53,366 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:53,366 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:53,366 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:53,370 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:53,370 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:53,371 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:53,371 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_11
2017-09-11 23:20:53,627 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:53,627 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:53,645 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:53,646 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:53,646 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:53,650 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:53,650 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:53,650 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:53,650 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_10
2017-09-11 23:20:53,846 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:53,846 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:53,862 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:53,862 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:53,862 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:53,866 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:53,866 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:53,866 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:53,866 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_11
2017-09-11 23:20:54,101 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:54,101 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:54,116 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:54,116 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:54,116 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:54,120 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:54,120 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:54,120 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:54,120 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_6
2017-09-11 23:20:54,357 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:54,357 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:54,375 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:54,375 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:54,375 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:54,379 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:54,379 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:54,379 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:54,379 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_1
2017-09-11 23:20:54,619 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:54,619 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:54,637 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:54,637 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:54,637 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:54,641 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:54,641 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:54,641 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:54,641 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_1
2017-09-11 23:20:54,881 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:54,881 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:54,899 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:54,899 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:54,899 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:54,903 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:54,903 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:54,903 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:54,903 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_2
2017-09-11 23:20:55,141 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:55,142 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:55,160 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:55,160 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:55,160 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:55,164 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:55,164 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:55,164 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:55,164 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Leg_ImageColl_6
2017-09-11 23:20:55,403 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:55,404 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:55,421 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:55,421 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:55,421 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:55,425 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:55,425 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:55,425 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:55,425 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:55,663 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:55,663 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:55,681 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:55,681 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:55,681 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:55,685 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:55,685 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:55,685 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:55,685 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:55,924 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:55,925 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:55,940 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:55,941 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:55,941 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:55,945 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:55,945 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:55,945 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:55,945 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:56,185 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:56,185 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:56,203 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:56,203 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:56,203 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:56,208 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:56,208 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:56,208 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:56,208 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_2
2017-09-11 23:20:56,448 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:56,448 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:56,465 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:56,465 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:56,465 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:56,469 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:56,469 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:56,469 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:56,470 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient29_Ant.R.Foot_ImageColl_12
2017-09-11 23:20:56,708 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:56,708 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:56,725 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:56,725 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:56,725 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:56,729 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:56,729 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:56,730 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:56,730 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_4
2017-09-11 23:20:56,960 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:56,961 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:56,975 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:56,976 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:56,976 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:56,980 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:56,980 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:56,980 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:56,980 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:57,219 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:57,219 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:57,237 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:57,237 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:57,237 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:57,241 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:57,242 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:57,242 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:57,242 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:57,242 log.framework MainThread  ERROR      HDF5Files already there
2017-09-11 23:20:57,480 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:57,480 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:57,496 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:57,496 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:57,496 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:57,501 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:57,501 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:57,501 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:57,501 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_3
2017-09-11 23:20:57,742 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:57,742 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:57,759 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:57,760 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:57,760 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:57,764 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:57,764 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:57,764 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:57,764 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:58,005 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:58,005 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:58,023 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:58,023 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:58,023 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:58,027 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:20:58,027 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:58,027 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:58,027 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_5
2017-09-11 23:20:58,268 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:58,268 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:58,286 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:58,286 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:58,286 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:58,290 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:58,290 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:58,290 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:58,291 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_1
2017-09-11 23:20:58,540 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:58,540 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:58,555 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:58,555 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:58,555 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:58,559 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:58,559 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:58,559 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:58,559 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Leg_ImageColl_2
2017-09-11 23:20:58,806 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:58,806 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:58,823 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:58,823 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:58,823 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:58,828 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:58,828 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:58,828 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:58,828 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_3
2017-09-11 23:20:59,082 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:59,082 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:59,098 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:59,099 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:59,099 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:59,103 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:59,103 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:59,103 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:59,103 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_2
2017-09-11 23:20:59,297 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:59,297 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:59,313 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:59,313 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:59,313 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:59,317 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:59,317 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:59,317 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:59,317 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Leg_ImageColl_1
2017-09-11 23:20:59,555 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:59,555 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:59,572 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:59,572 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:59,572 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:59,576 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:59,576 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:59,576 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:59,576 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_6
2017-09-11 23:20:59,812 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:20:59,812 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:20:59,830 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:20:59,830 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:20:59,830 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:20:59,834 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:20:59,834 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:20:59,834 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:20:59,834 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Leg_ImageColl_7
2017-09-11 23:21:00,071 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:00,072 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:00,092 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:00,092 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:00,092 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:00,096 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:00,096 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:00,097 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:00,097 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_1
2017-09-11 23:21:00,336 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:00,336 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:00,355 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:00,355 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:00,355 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:00,359 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:00,359 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:00,359 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:00,359 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_4
2017-09-11 23:21:00,596 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:00,596 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:00,616 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:00,617 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:00,617 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:00,621 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:00,621 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:00,621 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:00,621 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Leg_ImageColl_1
2017-09-11 23:21:00,869 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:00,869 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:00,888 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:00,888 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:00,888 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:00,892 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:00,892 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:00,892 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:00,893 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.L.Leg_ImageColl_4
2017-09-11 23:21:01,130 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:01,130 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:01,146 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:01,146 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:01,146 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:01,150 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:01,150 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:01,151 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:01,151 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_1
2017-09-11 23:21:01,391 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:01,392 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:01,410 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:01,410 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:01,410 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:01,414 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:01,414 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:01,414 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:01,415 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient34_Ant.L.Foot_ImageColl_2
2017-09-11 23:21:01,652 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:01,652 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:01,669 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:01,669 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:01,669 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:01,673 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:01,673 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:01,674 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:01,674 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient26_Ant.L.Foot_ImageColl_11
2017-09-11 23:21:01,912 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:01,913 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:01,930 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:01,930 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:01,930 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:01,934 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:21:01,934 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:01,934 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:01,934 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_10
2017-09-11 23:21:02,175 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:02,175 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:02,194 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:02,194 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:02,194 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:02,198 log.framework MainThread  INFO       The mask has these unique classes: [ 0.]
2017-09-11 23:21:02,198 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:02,198 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:02,198 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient30_Ant.R.Foot_ImageColl_11
2017-09-11 23:21:02,438 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:02,439 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:02,455 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:02,455 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:02,455 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:02,459 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:02,459 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:02,460 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:02,460 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_1
2017-09-11 23:21:02,700 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:02,700 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:02,718 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:02,718 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:02,718 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:02,722 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:02,722 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:02,722 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:02,723 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient37_Ant.L.Thigh_ImageColl_2
2017-09-11 23:21:02,965 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:02,965 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:02,984 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:02,984 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:02,984 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:02,988 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:02,988 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:02,988 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:02,988 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_1
2017-09-11 23:21:03,229 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:03,229 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:03,245 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:03,245 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:03,245 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:03,249 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:03,249 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:03,249 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:03,249 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_3
2017-09-11 23:21:03,497 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:03,498 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:03,515 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:03,515 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:03,515 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:03,519 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:03,520 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:03,520 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:03,520 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient25_Ant.R.Leg_ImageColl_2
2017-09-11 23:21:03,768 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:03,768 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:03,788 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:03,788 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:03,788 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:03,792 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:03,792 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:03,792 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:03,792 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_2
2017-09-11 23:21:04,042 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:04,042 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:04,058 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:04,058 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:04,058 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:04,062 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:04,062 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:04,062 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:04,062 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Foot_ImageColl_4
2017-09-11 23:21:04,325 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:04,325 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:04,343 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:04,343 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:04,343 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:04,347 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:04,347 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:04,347 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:04,347 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_2
2017-09-11 23:21:04,614 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:04,615 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:04,633 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:04,633 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:04,633 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:04,637 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:04,637 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:04,637 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:04,637 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient33_Ant.L.Leg_ImageColl_1
2017-09-11 23:21:04,831 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-09-11 23:21:04,832 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-09-11 23:21:04,847 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-09-11 23:21:04,847 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-09-11 23:21:04,847 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-09-11 23:21:04,852 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-09-11 23:21:04,852 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-09-11 23:21:04,852 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-09-11 23:21:04,852 log.framework MainThread  INFO       h5name _disk1_baylor_data_du_all__Patient36_Ant.R.Foot_ImageColl_1
2017-09-11 23:21:04,852 log.framework MainThread  INFO       train file number: 26
2017-09-11 23:21:04,852 log.framework MainThread  INFO       test file number: 7
2017-09-11 23:21:04,852 log.framework MainThread  INFO       subdirectory tree 
2017-09-11 23:21:04,853 log.framework MainThread  INFO       subdirectory tree 
2017-09-11 23:21:04,853 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-09-11 23:21:04,854 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-09-11 23:21:04,854 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-09-11 23:21:04,855 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc1/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc1/training"
solver_mode: GPU

2017-09-11 23:21:04,855 log.framework MainThread  INFO       caffe training step
2017-09-11 23:21:04,855 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc1/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-09-12 00:30:36,923 log.framework MainThread  INFO       I0911 23:21:04.884263 24730 caffe.cpp:217] Using GPUs 0
I0911 23:21:04.895797 24730 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0911 23:21:05.409358 24730 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc1/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc1/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0911 23:21:05.409531 24730 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc1/caffe/model_segnet_final/train.prototxt
I0911 23:21:05.412305 24730 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc1/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0911 23:21:05.412796 24730 layer_factory.hpp:77] Creating layer data
I0911 23:21:05.412814 24730 net.cpp:100] Creating Layer data
I0911 23:21:05.412825 24730 net.cpp:408] data -> data
I0911 23:21:05.412854 24730 net.cpp:408] data -> label
I0911 23:21:05.412875 24730 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc1/HDF5Files/train_combined.txt
I0911 23:21:05.412932 24730 hdf5_data_layer.cpp:93] Number of HDF5 files: 26
I0911 23:21:05.414106 24730 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0911 23:21:05.439462 24730 net.cpp:150] Setting up data
I0911 23:21:05.439491 24730 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0911 23:21:05.439503 24730 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0911 23:21:05.439507 24730 net.cpp:165] Memory required for data: 24883200
I0911 23:21:05.439519 24730 layer_factory.hpp:77] Creating layer label_data_1_split
I0911 23:21:05.439537 24730 net.cpp:100] Creating Layer label_data_1_split
I0911 23:21:05.439544 24730 net.cpp:434] label_data_1_split <- label
I0911 23:21:05.439558 24730 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0911 23:21:05.439570 24730 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0911 23:21:05.439612 24730 net.cpp:150] Setting up label_data_1_split
I0911 23:21:05.439620 24730 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0911 23:21:05.439626 24730 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0911 23:21:05.439630 24730 net.cpp:165] Memory required for data: 30412800
I0911 23:21:05.439633 24730 layer_factory.hpp:77] Creating layer conv1_1_1
I0911 23:21:05.439652 24730 net.cpp:100] Creating Layer conv1_1_1
I0911 23:21:05.439658 24730 net.cpp:434] conv1_1_1 <- data
I0911 23:21:05.439664 24730 net.cpp:408] conv1_1_1 -> conv1_1_1
I0911 23:21:05.978420 24730 net.cpp:150] Setting up conv1_1_1
I0911 23:21:05.978452 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:05.978457 24730 net.cpp:165] Memory required for data: 207360000
I0911 23:21:05.978482 24730 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0911 23:21:05.978498 24730 net.cpp:100] Creating Layer conv1_1_1_bn
I0911 23:21:05.978505 24730 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0911 23:21:05.978513 24730 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0911 23:21:05.978905 24730 net.cpp:150] Setting up conv1_1_1_bn
I0911 23:21:05.978914 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:05.978924 24730 net.cpp:165] Memory required for data: 384307200
I0911 23:21:05.978937 24730 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0911 23:21:05.978950 24730 net.cpp:100] Creating Layer conv1_1_1_scale
I0911 23:21:05.978955 24730 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0911 23:21:05.978960 24730 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0911 23:21:05.979009 24730 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0911 23:21:05.981086 24730 net.cpp:150] Setting up conv1_1_1_scale
I0911 23:21:05.981101 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:05.981109 24730 net.cpp:165] Memory required for data: 561254400
I0911 23:21:05.981117 24730 layer_factory.hpp:77] Creating layer relu1_1
I0911 23:21:05.981128 24730 net.cpp:100] Creating Layer relu1_1
I0911 23:21:05.981133 24730 net.cpp:434] relu1_1 <- conv1_1_1
I0911 23:21:05.981139 24730 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0911 23:21:05.981374 24730 net.cpp:150] Setting up relu1_1
I0911 23:21:05.981384 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:05.981389 24730 net.cpp:165] Memory required for data: 738201600
I0911 23:21:05.981395 24730 layer_factory.hpp:77] Creating layer conv1_2
I0911 23:21:05.981405 24730 net.cpp:100] Creating Layer conv1_2
I0911 23:21:05.981410 24730 net.cpp:434] conv1_2 <- conv1_1_1
I0911 23:21:05.981417 24730 net.cpp:408] conv1_2 -> conv1_2
I0911 23:21:05.986089 24730 net.cpp:150] Setting up conv1_2
I0911 23:21:05.986106 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:05.986115 24730 net.cpp:165] Memory required for data: 915148800
I0911 23:21:05.986126 24730 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0911 23:21:05.986138 24730 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0911 23:21:05.986147 24730 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0911 23:21:05.986152 24730 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0911 23:21:05.988138 24730 net.cpp:150] Setting up conv1_2_bn_tmp
I0911 23:21:05.988153 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:05.988162 24730 net.cpp:165] Memory required for data: 1092096000
I0911 23:21:05.988170 24730 layer_factory.hpp:77] Creating layer conv1_2_scale
I0911 23:21:05.988181 24730 net.cpp:100] Creating Layer conv1_2_scale
I0911 23:21:05.988186 24730 net.cpp:434] conv1_2_scale <- conv1_2
I0911 23:21:05.988193 24730 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0911 23:21:05.988235 24730 layer_factory.hpp:77] Creating layer conv1_2_scale
I0911 23:21:05.988605 24730 net.cpp:150] Setting up conv1_2_scale
I0911 23:21:05.988615 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:05.988618 24730 net.cpp:165] Memory required for data: 1269043200
I0911 23:21:05.988626 24730 layer_factory.hpp:77] Creating layer relu1_2
I0911 23:21:05.988633 24730 net.cpp:100] Creating Layer relu1_2
I0911 23:21:05.988638 24730 net.cpp:434] relu1_2 <- conv1_2
I0911 23:21:05.988642 24730 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0911 23:21:05.988836 24730 net.cpp:150] Setting up relu1_2
I0911 23:21:05.988845 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:05.988849 24730 net.cpp:165] Memory required for data: 1445990400
I0911 23:21:05.988853 24730 layer_factory.hpp:77] Creating layer pool1
I0911 23:21:05.988858 24730 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0911 23:21:05.988867 24730 net.cpp:100] Creating Layer pool1
I0911 23:21:05.988871 24730 net.cpp:434] pool1 <- conv1_2
I0911 23:21:05.988876 24730 net.cpp:408] pool1 -> pool1
I0911 23:21:05.988886 24730 net.cpp:408] pool1 -> pool1_mask
I0911 23:21:05.988940 24730 net.cpp:150] Setting up pool1
I0911 23:21:05.988946 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:05.988951 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:05.988955 24730 net.cpp:165] Memory required for data: 1534464000
I0911 23:21:05.988958 24730 layer_factory.hpp:77] Creating layer conv2_1
I0911 23:21:05.988967 24730 net.cpp:100] Creating Layer conv2_1
I0911 23:21:05.988972 24730 net.cpp:434] conv2_1 <- pool1
I0911 23:21:05.988978 24730 net.cpp:408] conv2_1 -> conv2_1
I0911 23:21:05.995609 24730 net.cpp:150] Setting up conv2_1
I0911 23:21:05.995626 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:05.995635 24730 net.cpp:165] Memory required for data: 1622937600
I0911 23:21:05.995642 24730 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0911 23:21:05.995651 24730 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0911 23:21:05.995661 24730 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0911 23:21:05.995666 24730 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0911 23:21:05.995887 24730 net.cpp:150] Setting up conv2_1_bn_tmp
I0911 23:21:05.995896 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:05.995899 24730 net.cpp:165] Memory required for data: 1711411200
I0911 23:21:05.995913 24730 layer_factory.hpp:77] Creating layer conv2_1_scale
I0911 23:21:05.995935 24730 net.cpp:100] Creating Layer conv2_1_scale
I0911 23:21:05.995939 24730 net.cpp:434] conv2_1_scale <- conv2_1
I0911 23:21:05.995945 24730 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0911 23:21:05.995986 24730 layer_factory.hpp:77] Creating layer conv2_1_scale
I0911 23:21:05.996156 24730 net.cpp:150] Setting up conv2_1_scale
I0911 23:21:05.996165 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:05.996170 24730 net.cpp:165] Memory required for data: 1799884800
I0911 23:21:05.996176 24730 layer_factory.hpp:77] Creating layer relu2_1
I0911 23:21:05.996184 24730 net.cpp:100] Creating Layer relu2_1
I0911 23:21:05.996189 24730 net.cpp:434] relu2_1 <- conv2_1
I0911 23:21:05.996194 24730 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0911 23:21:05.997222 24730 net.cpp:150] Setting up relu2_1
I0911 23:21:05.997236 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:05.997241 24730 net.cpp:165] Memory required for data: 1888358400
I0911 23:21:05.997246 24730 layer_factory.hpp:77] Creating layer conv2_2
I0911 23:21:05.997256 24730 net.cpp:100] Creating Layer conv2_2
I0911 23:21:05.997262 24730 net.cpp:434] conv2_2 <- conv2_1
I0911 23:21:05.997268 24730 net.cpp:408] conv2_2 -> conv2_2
I0911 23:21:06.004791 24730 net.cpp:150] Setting up conv2_2
I0911 23:21:06.004808 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:06.004818 24730 net.cpp:165] Memory required for data: 1976832000
I0911 23:21:06.004827 24730 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0911 23:21:06.004838 24730 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0911 23:21:06.004844 24730 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0911 23:21:06.004850 24730 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0911 23:21:06.005077 24730 net.cpp:150] Setting up conv2_2_bn_tmp
I0911 23:21:06.005086 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:06.005089 24730 net.cpp:165] Memory required for data: 2065305600
I0911 23:21:06.005097 24730 layer_factory.hpp:77] Creating layer conv2_2_scale
I0911 23:21:06.005105 24730 net.cpp:100] Creating Layer conv2_2_scale
I0911 23:21:06.005112 24730 net.cpp:434] conv2_2_scale <- conv2_2
I0911 23:21:06.005117 24730 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0911 23:21:06.005156 24730 layer_factory.hpp:77] Creating layer conv2_2_scale
I0911 23:21:06.005326 24730 net.cpp:150] Setting up conv2_2_scale
I0911 23:21:06.005334 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:06.005339 24730 net.cpp:165] Memory required for data: 2153779200
I0911 23:21:06.005347 24730 layer_factory.hpp:77] Creating layer relu2_2
I0911 23:21:06.005353 24730 net.cpp:100] Creating Layer relu2_2
I0911 23:21:06.005358 24730 net.cpp:434] relu2_2 <- conv2_2
I0911 23:21:06.005363 24730 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0911 23:21:06.005558 24730 net.cpp:150] Setting up relu2_2
I0911 23:21:06.005568 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:06.005573 24730 net.cpp:165] Memory required for data: 2242252800
I0911 23:21:06.005575 24730 layer_factory.hpp:77] Creating layer pool2
I0911 23:21:06.005580 24730 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0911 23:21:06.005586 24730 net.cpp:100] Creating Layer pool2
I0911 23:21:06.005591 24730 net.cpp:434] pool2 <- conv2_2
I0911 23:21:06.005596 24730 net.cpp:408] pool2 -> pool2
I0911 23:21:06.005605 24730 net.cpp:408] pool2 -> pool2_mask
I0911 23:21:06.005647 24730 net.cpp:150] Setting up pool2
I0911 23:21:06.005655 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:06.005658 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:06.005662 24730 net.cpp:165] Memory required for data: 2286489600
I0911 23:21:06.005666 24730 layer_factory.hpp:77] Creating layer conv3_1
I0911 23:21:06.005676 24730 net.cpp:100] Creating Layer conv3_1
I0911 23:21:06.005681 24730 net.cpp:434] conv3_1 <- pool2
I0911 23:21:06.005686 24730 net.cpp:408] conv3_1 -> conv3_1
I0911 23:21:06.018240 24730 net.cpp:150] Setting up conv3_1
I0911 23:21:06.018271 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.018281 24730 net.cpp:165] Memory required for data: 2330726400
I0911 23:21:06.018290 24730 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0911 23:21:06.018299 24730 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0911 23:21:06.018308 24730 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0911 23:21:06.018314 24730 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0911 23:21:06.018517 24730 net.cpp:150] Setting up conv3_1_bn_tmp
I0911 23:21:06.018527 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.018529 24730 net.cpp:165] Memory required for data: 2374963200
I0911 23:21:06.018543 24730 layer_factory.hpp:77] Creating layer conv3_1_scale
I0911 23:21:06.018551 24730 net.cpp:100] Creating Layer conv3_1_scale
I0911 23:21:06.018559 24730 net.cpp:434] conv3_1_scale <- conv3_1
I0911 23:21:06.018564 24730 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0911 23:21:06.018605 24730 layer_factory.hpp:77] Creating layer conv3_1_scale
I0911 23:21:06.018735 24730 net.cpp:150] Setting up conv3_1_scale
I0911 23:21:06.018743 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.018748 24730 net.cpp:165] Memory required for data: 2419200000
I0911 23:21:06.018755 24730 layer_factory.hpp:77] Creating layer relu3_1
I0911 23:21:06.018762 24730 net.cpp:100] Creating Layer relu3_1
I0911 23:21:06.018767 24730 net.cpp:434] relu3_1 <- conv3_1
I0911 23:21:06.018772 24730 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0911 23:21:06.018961 24730 net.cpp:150] Setting up relu3_1
I0911 23:21:06.018971 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.018976 24730 net.cpp:165] Memory required for data: 2463436800
I0911 23:21:06.018980 24730 layer_factory.hpp:77] Creating layer conv3_2
I0911 23:21:06.018990 24730 net.cpp:100] Creating Layer conv3_2
I0911 23:21:06.018996 24730 net.cpp:434] conv3_2 <- conv3_1
I0911 23:21:06.019001 24730 net.cpp:408] conv3_2 -> conv3_2
I0911 23:21:06.043429 24730 net.cpp:150] Setting up conv3_2
I0911 23:21:06.043447 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.043457 24730 net.cpp:165] Memory required for data: 2507673600
I0911 23:21:06.043464 24730 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0911 23:21:06.043474 24730 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0911 23:21:06.043483 24730 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0911 23:21:06.043488 24730 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0911 23:21:06.043694 24730 net.cpp:150] Setting up conv3_2_bn_tmp
I0911 23:21:06.043702 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.043706 24730 net.cpp:165] Memory required for data: 2551910400
I0911 23:21:06.043715 24730 layer_factory.hpp:77] Creating layer conv3_2_scale
I0911 23:21:06.043720 24730 net.cpp:100] Creating Layer conv3_2_scale
I0911 23:21:06.043728 24730 net.cpp:434] conv3_2_scale <- conv3_2
I0911 23:21:06.043733 24730 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0911 23:21:06.043772 24730 layer_factory.hpp:77] Creating layer conv3_2_scale
I0911 23:21:06.043900 24730 net.cpp:150] Setting up conv3_2_scale
I0911 23:21:06.043908 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.043912 24730 net.cpp:165] Memory required for data: 2596147200
I0911 23:21:06.043920 24730 layer_factory.hpp:77] Creating layer relu3_2
I0911 23:21:06.043927 24730 net.cpp:100] Creating Layer relu3_2
I0911 23:21:06.043932 24730 net.cpp:434] relu3_2 <- conv3_2
I0911 23:21:06.043937 24730 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0911 23:21:06.044129 24730 net.cpp:150] Setting up relu3_2
I0911 23:21:06.044138 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.044143 24730 net.cpp:165] Memory required for data: 2640384000
I0911 23:21:06.044147 24730 layer_factory.hpp:77] Creating layer conv3_3
I0911 23:21:06.044157 24730 net.cpp:100] Creating Layer conv3_3
I0911 23:21:06.044162 24730 net.cpp:434] conv3_3 <- conv3_2
I0911 23:21:06.044168 24730 net.cpp:408] conv3_3 -> conv3_3
I0911 23:21:06.068580 24730 net.cpp:150] Setting up conv3_3
I0911 23:21:06.068611 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.068620 24730 net.cpp:165] Memory required for data: 2684620800
I0911 23:21:06.068629 24730 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0911 23:21:06.068639 24730 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0911 23:21:06.068647 24730 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0911 23:21:06.068652 24730 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0911 23:21:06.068862 24730 net.cpp:150] Setting up conv3_3_bn_tmp
I0911 23:21:06.068871 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.068874 24730 net.cpp:165] Memory required for data: 2728857600
I0911 23:21:06.068882 24730 layer_factory.hpp:77] Creating layer conv3_3_scale
I0911 23:21:06.068889 24730 net.cpp:100] Creating Layer conv3_3_scale
I0911 23:21:06.068897 24730 net.cpp:434] conv3_3_scale <- conv3_3
I0911 23:21:06.068902 24730 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0911 23:21:06.068943 24730 layer_factory.hpp:77] Creating layer conv3_3_scale
I0911 23:21:06.069072 24730 net.cpp:150] Setting up conv3_3_scale
I0911 23:21:06.069080 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.069084 24730 net.cpp:165] Memory required for data: 2773094400
I0911 23:21:06.069090 24730 layer_factory.hpp:77] Creating layer relu3_3
I0911 23:21:06.069097 24730 net.cpp:100] Creating Layer relu3_3
I0911 23:21:06.069103 24730 net.cpp:434] relu3_3 <- conv3_3
I0911 23:21:06.069108 24730 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0911 23:21:06.069303 24730 net.cpp:150] Setting up relu3_3
I0911 23:21:06.069314 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:06.069319 24730 net.cpp:165] Memory required for data: 2817331200
I0911 23:21:06.069322 24730 layer_factory.hpp:77] Creating layer pool3
I0911 23:21:06.069326 24730 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0911 23:21:06.069336 24730 net.cpp:100] Creating Layer pool3
I0911 23:21:06.069341 24730 net.cpp:434] pool3 <- conv3_3
I0911 23:21:06.069347 24730 net.cpp:408] pool3 -> pool3
I0911 23:21:06.069356 24730 net.cpp:408] pool3 -> pool3_mask
I0911 23:21:06.069408 24730 net.cpp:150] Setting up pool3
I0911 23:21:06.069417 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:06.069422 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:06.069425 24730 net.cpp:165] Memory required for data: 2839449600
I0911 23:21:06.069428 24730 layer_factory.hpp:77] Creating layer conv4_1
I0911 23:21:06.069439 24730 net.cpp:100] Creating Layer conv4_1
I0911 23:21:06.069444 24730 net.cpp:434] conv4_1 <- pool3
I0911 23:21:06.069450 24730 net.cpp:408] conv4_1 -> conv4_1
I0911 23:21:06.118849 24730 net.cpp:150] Setting up conv4_1
I0911 23:21:06.118866 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.118871 24730 net.cpp:165] Memory required for data: 2861568000
I0911 23:21:06.118880 24730 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0911 23:21:06.118888 24730 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0911 23:21:06.118901 24730 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0911 23:21:06.118906 24730 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0911 23:21:06.119119 24730 net.cpp:150] Setting up conv4_1_bn_tmp
I0911 23:21:06.119128 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.119137 24730 net.cpp:165] Memory required for data: 2883686400
I0911 23:21:06.119144 24730 layer_factory.hpp:77] Creating layer conv4_1_scale
I0911 23:21:06.119154 24730 net.cpp:100] Creating Layer conv4_1_scale
I0911 23:21:06.119161 24730 net.cpp:434] conv4_1_scale <- conv4_1
I0911 23:21:06.119166 24730 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0911 23:21:06.119207 24730 layer_factory.hpp:77] Creating layer conv4_1_scale
I0911 23:21:06.119329 24730 net.cpp:150] Setting up conv4_1_scale
I0911 23:21:06.119338 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.119341 24730 net.cpp:165] Memory required for data: 2905804800
I0911 23:21:06.119349 24730 layer_factory.hpp:77] Creating layer relu4_1
I0911 23:21:06.119370 24730 net.cpp:100] Creating Layer relu4_1
I0911 23:21:06.119376 24730 net.cpp:434] relu4_1 <- conv4_1
I0911 23:21:06.119381 24730 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0911 23:21:06.119585 24730 net.cpp:150] Setting up relu4_1
I0911 23:21:06.119595 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.119599 24730 net.cpp:165] Memory required for data: 2927923200
I0911 23:21:06.119603 24730 layer_factory.hpp:77] Creating layer conv4_2
I0911 23:21:06.119614 24730 net.cpp:100] Creating Layer conv4_2
I0911 23:21:06.119619 24730 net.cpp:434] conv4_2 <- conv4_1
I0911 23:21:06.119626 24730 net.cpp:408] conv4_2 -> conv4_2
I0911 23:21:06.208027 24730 net.cpp:150] Setting up conv4_2
I0911 23:21:06.208045 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.208050 24730 net.cpp:165] Memory required for data: 2950041600
I0911 23:21:06.208056 24730 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0911 23:21:06.208065 24730 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0911 23:21:06.208068 24730 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0911 23:21:06.208075 24730 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0911 23:21:06.208276 24730 net.cpp:150] Setting up conv4_2_bn_tmp
I0911 23:21:06.208283 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.208287 24730 net.cpp:165] Memory required for data: 2972160000
I0911 23:21:06.208295 24730 layer_factory.hpp:77] Creating layer conv4_2_scale
I0911 23:21:06.208302 24730 net.cpp:100] Creating Layer conv4_2_scale
I0911 23:21:06.208309 24730 net.cpp:434] conv4_2_scale <- conv4_2
I0911 23:21:06.208314 24730 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0911 23:21:06.208358 24730 layer_factory.hpp:77] Creating layer conv4_2_scale
I0911 23:21:06.208482 24730 net.cpp:150] Setting up conv4_2_scale
I0911 23:21:06.208489 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.208492 24730 net.cpp:165] Memory required for data: 2994278400
I0911 23:21:06.208498 24730 layer_factory.hpp:77] Creating layer relu4_2
I0911 23:21:06.208509 24730 net.cpp:100] Creating Layer relu4_2
I0911 23:21:06.208514 24730 net.cpp:434] relu4_2 <- conv4_2
I0911 23:21:06.208520 24730 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0911 23:21:06.209576 24730 net.cpp:150] Setting up relu4_2
I0911 23:21:06.209591 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.209596 24730 net.cpp:165] Memory required for data: 3016396800
I0911 23:21:06.209600 24730 layer_factory.hpp:77] Creating layer conv4_3
I0911 23:21:06.209611 24730 net.cpp:100] Creating Layer conv4_3
I0911 23:21:06.209617 24730 net.cpp:434] conv4_3 <- conv4_2
I0911 23:21:06.209625 24730 net.cpp:408] conv4_3 -> conv4_3
I0911 23:21:06.298117 24730 net.cpp:150] Setting up conv4_3
I0911 23:21:06.298135 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.298138 24730 net.cpp:165] Memory required for data: 3038515200
I0911 23:21:06.298164 24730 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0911 23:21:06.298177 24730 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0911 23:21:06.298183 24730 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0911 23:21:06.298189 24730 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0911 23:21:06.298414 24730 net.cpp:150] Setting up conv4_3_bn_tmp
I0911 23:21:06.298422 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.298425 24730 net.cpp:165] Memory required for data: 3060633600
I0911 23:21:06.298439 24730 layer_factory.hpp:77] Creating layer conv4_3_scale
I0911 23:21:06.298447 24730 net.cpp:100] Creating Layer conv4_3_scale
I0911 23:21:06.298455 24730 net.cpp:434] conv4_3_scale <- conv4_3
I0911 23:21:06.298460 24730 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0911 23:21:06.298511 24730 layer_factory.hpp:77] Creating layer conv4_3_scale
I0911 23:21:06.298648 24730 net.cpp:150] Setting up conv4_3_scale
I0911 23:21:06.298656 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.298660 24730 net.cpp:165] Memory required for data: 3082752000
I0911 23:21:06.298666 24730 layer_factory.hpp:77] Creating layer relu4_3
I0911 23:21:06.298692 24730 net.cpp:100] Creating Layer relu4_3
I0911 23:21:06.298697 24730 net.cpp:434] relu4_3 <- conv4_3
I0911 23:21:06.298702 24730 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0911 23:21:06.298907 24730 net.cpp:150] Setting up relu4_3
I0911 23:21:06.298916 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.298921 24730 net.cpp:165] Memory required for data: 3104870400
I0911 23:21:06.298925 24730 layer_factory.hpp:77] Creating layer pool4
I0911 23:21:06.298929 24730 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0911 23:21:06.298939 24730 net.cpp:100] Creating Layer pool4
I0911 23:21:06.298944 24730 net.cpp:434] pool4 <- conv4_3
I0911 23:21:06.298952 24730 net.cpp:408] pool4 -> pool4
I0911 23:21:06.298961 24730 net.cpp:408] pool4 -> pool4_mask
I0911 23:21:06.299008 24730 net.cpp:150] Setting up pool4
I0911 23:21:06.299016 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.299021 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.299026 24730 net.cpp:165] Memory required for data: 3116175360
I0911 23:21:06.299028 24730 layer_factory.hpp:77] Creating layer conv5_1
I0911 23:21:06.299041 24730 net.cpp:100] Creating Layer conv5_1
I0911 23:21:06.299046 24730 net.cpp:434] conv5_1 <- pool4
I0911 23:21:06.299054 24730 net.cpp:408] conv5_1 -> conv5_1
I0911 23:21:06.389096 24730 net.cpp:150] Setting up conv5_1
I0911 23:21:06.389117 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.389122 24730 net.cpp:165] Memory required for data: 3121827840
I0911 23:21:06.389133 24730 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0911 23:21:06.389152 24730 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0911 23:21:06.389160 24730 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0911 23:21:06.389171 24730 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0911 23:21:06.389411 24730 net.cpp:150] Setting up conv5_1_bn_tmp
I0911 23:21:06.389420 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.389423 24730 net.cpp:165] Memory required for data: 3127480320
I0911 23:21:06.389431 24730 layer_factory.hpp:77] Creating layer conv5_1_scale
I0911 23:21:06.389443 24730 net.cpp:100] Creating Layer conv5_1_scale
I0911 23:21:06.389451 24730 net.cpp:434] conv5_1_scale <- conv5_1
I0911 23:21:06.389457 24730 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0911 23:21:06.389503 24730 layer_factory.hpp:77] Creating layer conv5_1_scale
I0911 23:21:06.389626 24730 net.cpp:150] Setting up conv5_1_scale
I0911 23:21:06.389637 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.389642 24730 net.cpp:165] Memory required for data: 3133132800
I0911 23:21:06.389648 24730 layer_factory.hpp:77] Creating layer relu5_1
I0911 23:21:06.389655 24730 net.cpp:100] Creating Layer relu5_1
I0911 23:21:06.389660 24730 net.cpp:434] relu5_1 <- conv5_1
I0911 23:21:06.389665 24730 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0911 23:21:06.389876 24730 net.cpp:150] Setting up relu5_1
I0911 23:21:06.389886 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.389890 24730 net.cpp:165] Memory required for data: 3138785280
I0911 23:21:06.389894 24730 layer_factory.hpp:77] Creating layer conv5_2
I0911 23:21:06.389909 24730 net.cpp:100] Creating Layer conv5_2
I0911 23:21:06.389914 24730 net.cpp:434] conv5_2 <- conv5_1
I0911 23:21:06.389922 24730 net.cpp:408] conv5_2 -> conv5_2
I0911 23:21:06.478484 24730 net.cpp:150] Setting up conv5_2
I0911 23:21:06.478502 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.478505 24730 net.cpp:165] Memory required for data: 3144437760
I0911 23:21:06.478513 24730 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0911 23:21:06.478524 24730 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0911 23:21:06.478533 24730 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0911 23:21:06.478543 24730 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0911 23:21:06.478763 24730 net.cpp:150] Setting up conv5_2_bn_tmp
I0911 23:21:06.478771 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.478793 24730 net.cpp:165] Memory required for data: 3150090240
I0911 23:21:06.478802 24730 layer_factory.hpp:77] Creating layer conv5_2_scale
I0911 23:21:06.478816 24730 net.cpp:100] Creating Layer conv5_2_scale
I0911 23:21:06.478821 24730 net.cpp:434] conv5_2_scale <- conv5_2
I0911 23:21:06.478827 24730 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0911 23:21:06.478879 24730 layer_factory.hpp:77] Creating layer conv5_2_scale
I0911 23:21:06.479008 24730 net.cpp:150] Setting up conv5_2_scale
I0911 23:21:06.479017 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.479020 24730 net.cpp:165] Memory required for data: 3155742720
I0911 23:21:06.479027 24730 layer_factory.hpp:77] Creating layer relu5_2
I0911 23:21:06.479034 24730 net.cpp:100] Creating Layer relu5_2
I0911 23:21:06.479039 24730 net.cpp:434] relu5_2 <- conv5_2
I0911 23:21:06.479044 24730 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0911 23:21:06.479254 24730 net.cpp:150] Setting up relu5_2
I0911 23:21:06.479264 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.479269 24730 net.cpp:165] Memory required for data: 3161395200
I0911 23:21:06.479272 24730 layer_factory.hpp:77] Creating layer conv5_3
I0911 23:21:06.479286 24730 net.cpp:100] Creating Layer conv5_3
I0911 23:21:06.479292 24730 net.cpp:434] conv5_3 <- conv5_2
I0911 23:21:06.479302 24730 net.cpp:408] conv5_3 -> conv5_3
I0911 23:21:06.567961 24730 net.cpp:150] Setting up conv5_3
I0911 23:21:06.567978 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.567982 24730 net.cpp:165] Memory required for data: 3167047680
I0911 23:21:06.567996 24730 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0911 23:21:06.568011 24730 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0911 23:21:06.568017 24730 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0911 23:21:06.568023 24730 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0911 23:21:06.568246 24730 net.cpp:150] Setting up conv5_3_bn_tmp
I0911 23:21:06.568254 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.568258 24730 net.cpp:165] Memory required for data: 3172700160
I0911 23:21:06.568269 24730 layer_factory.hpp:77] Creating layer conv5_3_scale
I0911 23:21:06.568280 24730 net.cpp:100] Creating Layer conv5_3_scale
I0911 23:21:06.568289 24730 net.cpp:434] conv5_3_scale <- conv5_3
I0911 23:21:06.568295 24730 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0911 23:21:06.568341 24730 layer_factory.hpp:77] Creating layer conv5_3_scale
I0911 23:21:06.568470 24730 net.cpp:150] Setting up conv5_3_scale
I0911 23:21:06.568477 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.568480 24730 net.cpp:165] Memory required for data: 3178352640
I0911 23:21:06.568487 24730 layer_factory.hpp:77] Creating layer relu5_3
I0911 23:21:06.568497 24730 net.cpp:100] Creating Layer relu5_3
I0911 23:21:06.568502 24730 net.cpp:434] relu5_3 <- conv5_3
I0911 23:21:06.568507 24730 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0911 23:21:06.568720 24730 net.cpp:150] Setting up relu5_3
I0911 23:21:06.568729 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.568734 24730 net.cpp:165] Memory required for data: 3184005120
I0911 23:21:06.568738 24730 layer_factory.hpp:77] Creating layer pool5
I0911 23:21:06.568743 24730 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0911 23:21:06.568754 24730 net.cpp:100] Creating Layer pool5
I0911 23:21:06.568759 24730 net.cpp:434] pool5 <- conv5_3
I0911 23:21:06.568769 24730 net.cpp:408] pool5 -> pool5
I0911 23:21:06.568778 24730 net.cpp:408] pool5 -> pool5_mask
I0911 23:21:06.568827 24730 net.cpp:150] Setting up pool5
I0911 23:21:06.568835 24730 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0911 23:21:06.568838 24730 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0911 23:21:06.568845 24730 net.cpp:165] Memory required for data: 3186954240
I0911 23:21:06.568848 24730 layer_factory.hpp:77] Creating layer upsample5
I0911 23:21:06.568861 24730 net.cpp:100] Creating Layer upsample5
I0911 23:21:06.568866 24730 net.cpp:434] upsample5 <- pool5
I0911 23:21:06.568886 24730 net.cpp:434] upsample5 <- pool5_mask
I0911 23:21:06.568894 24730 net.cpp:408] upsample5 -> pool5_D
I0911 23:21:06.568933 24730 net.cpp:150] Setting up upsample5
I0911 23:21:06.568940 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.568943 24730 net.cpp:165] Memory required for data: 3192606720
I0911 23:21:06.568946 24730 layer_factory.hpp:77] Creating layer conv5_3_D
I0911 23:21:06.568960 24730 net.cpp:100] Creating Layer conv5_3_D
I0911 23:21:06.568964 24730 net.cpp:434] conv5_3_D <- pool5_D
I0911 23:21:06.568974 24730 net.cpp:408] conv5_3_D -> conv5_3_D
I0911 23:21:06.658336 24730 net.cpp:150] Setting up conv5_3_D
I0911 23:21:06.658354 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.658357 24730 net.cpp:165] Memory required for data: 3198259200
I0911 23:21:06.658365 24730 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0911 23:21:06.658377 24730 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0911 23:21:06.658386 24730 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0911 23:21:06.658392 24730 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0911 23:21:06.658628 24730 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0911 23:21:06.658638 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.658640 24730 net.cpp:165] Memory required for data: 3203911680
I0911 23:21:06.658648 24730 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0911 23:21:06.658660 24730 net.cpp:100] Creating Layer conv5_3_D_scale
I0911 23:21:06.658669 24730 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0911 23:21:06.658674 24730 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0911 23:21:06.658732 24730 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0911 23:21:06.658857 24730 net.cpp:150] Setting up conv5_3_D_scale
I0911 23:21:06.658865 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.658869 24730 net.cpp:165] Memory required for data: 3209564160
I0911 23:21:06.658874 24730 layer_factory.hpp:77] Creating layer relu5_3_D
I0911 23:21:06.658885 24730 net.cpp:100] Creating Layer relu5_3_D
I0911 23:21:06.658890 24730 net.cpp:434] relu5_3_D <- conv5_3_D
I0911 23:21:06.658893 24730 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0911 23:21:06.659114 24730 net.cpp:150] Setting up relu5_3_D
I0911 23:21:06.659124 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.659129 24730 net.cpp:165] Memory required for data: 3215216640
I0911 23:21:06.659133 24730 layer_factory.hpp:77] Creating layer conv5_2_D
I0911 23:21:06.659170 24730 net.cpp:100] Creating Layer conv5_2_D
I0911 23:21:06.659176 24730 net.cpp:434] conv5_2_D <- conv5_3_D
I0911 23:21:06.659183 24730 net.cpp:408] conv5_2_D -> conv5_2_D
I0911 23:21:06.747772 24730 net.cpp:150] Setting up conv5_2_D
I0911 23:21:06.747789 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.747793 24730 net.cpp:165] Memory required for data: 3220869120
I0911 23:21:06.747802 24730 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0911 23:21:06.747812 24730 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0911 23:21:06.747822 24730 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0911 23:21:06.747830 24730 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0911 23:21:06.748059 24730 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0911 23:21:06.748066 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.748070 24730 net.cpp:165] Memory required for data: 3226521600
I0911 23:21:06.748078 24730 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0911 23:21:06.748085 24730 net.cpp:100] Creating Layer conv5_2_D_scale
I0911 23:21:06.748091 24730 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0911 23:21:06.748100 24730 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0911 23:21:06.748150 24730 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0911 23:21:06.748281 24730 net.cpp:150] Setting up conv5_2_D_scale
I0911 23:21:06.748288 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.748291 24730 net.cpp:165] Memory required for data: 3232174080
I0911 23:21:06.748317 24730 layer_factory.hpp:77] Creating layer relu5_2_D
I0911 23:21:06.748324 24730 net.cpp:100] Creating Layer relu5_2_D
I0911 23:21:06.748328 24730 net.cpp:434] relu5_2_D <- conv5_2_D
I0911 23:21:06.748333 24730 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0911 23:21:06.749426 24730 net.cpp:150] Setting up relu5_2_D
I0911 23:21:06.749441 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.749446 24730 net.cpp:165] Memory required for data: 3237826560
I0911 23:21:06.749451 24730 layer_factory.hpp:77] Creating layer conv5_1_D
I0911 23:21:06.749464 24730 net.cpp:100] Creating Layer conv5_1_D
I0911 23:21:06.749470 24730 net.cpp:434] conv5_1_D <- conv5_2_D
I0911 23:21:06.749480 24730 net.cpp:408] conv5_1_D -> conv5_1_D
I0911 23:21:06.837985 24730 net.cpp:150] Setting up conv5_1_D
I0911 23:21:06.838002 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.838006 24730 net.cpp:165] Memory required for data: 3243479040
I0911 23:21:06.838014 24730 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0911 23:21:06.838024 24730 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0911 23:21:06.838035 24730 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0911 23:21:06.838042 24730 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0911 23:21:06.838279 24730 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0911 23:21:06.838287 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.838291 24730 net.cpp:165] Memory required for data: 3249131520
I0911 23:21:06.838299 24730 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0911 23:21:06.838309 24730 net.cpp:100] Creating Layer conv5_1_D_scale
I0911 23:21:06.838313 24730 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0911 23:21:06.838320 24730 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0911 23:21:06.838369 24730 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0911 23:21:06.838498 24730 net.cpp:150] Setting up conv5_1_D_scale
I0911 23:21:06.838506 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.838510 24730 net.cpp:165] Memory required for data: 3254784000
I0911 23:21:06.838518 24730 layer_factory.hpp:77] Creating layer relu5_1_D
I0911 23:21:06.838528 24730 net.cpp:100] Creating Layer relu5_1_D
I0911 23:21:06.838533 24730 net.cpp:434] relu5_1_D <- conv5_1_D
I0911 23:21:06.838537 24730 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0911 23:21:06.838757 24730 net.cpp:150] Setting up relu5_1_D
I0911 23:21:06.838770 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:06.838775 24730 net.cpp:165] Memory required for data: 3260436480
I0911 23:21:06.838778 24730 layer_factory.hpp:77] Creating layer upsample4
I0911 23:21:06.838786 24730 net.cpp:100] Creating Layer upsample4
I0911 23:21:06.838791 24730 net.cpp:434] upsample4 <- conv5_1_D
I0911 23:21:06.838798 24730 net.cpp:434] upsample4 <- pool4_mask
I0911 23:21:06.838804 24730 net.cpp:408] upsample4 -> pool4_D
I0911 23:21:06.838840 24730 net.cpp:150] Setting up upsample4
I0911 23:21:06.838847 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.838850 24730 net.cpp:165] Memory required for data: 3282554880
I0911 23:21:06.838855 24730 layer_factory.hpp:77] Creating layer conv4_3_D
I0911 23:21:06.838868 24730 net.cpp:100] Creating Layer conv4_3_D
I0911 23:21:06.838873 24730 net.cpp:434] conv4_3_D <- pool4_D
I0911 23:21:06.838881 24730 net.cpp:408] conv4_3_D -> conv4_3_D
I0911 23:21:06.928225 24730 net.cpp:150] Setting up conv4_3_D
I0911 23:21:06.928247 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.928259 24730 net.cpp:165] Memory required for data: 3304673280
I0911 23:21:06.928273 24730 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0911 23:21:06.928287 24730 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0911 23:21:06.928295 24730 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0911 23:21:06.928308 24730 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0911 23:21:06.928550 24730 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0911 23:21:06.928557 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.928580 24730 net.cpp:165] Memory required for data: 3326791680
I0911 23:21:06.928591 24730 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0911 23:21:06.928601 24730 net.cpp:100] Creating Layer conv4_3_D_scale
I0911 23:21:06.928606 24730 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0911 23:21:06.928611 24730 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0911 23:21:06.928663 24730 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0911 23:21:06.928810 24730 net.cpp:150] Setting up conv4_3_D_scale
I0911 23:21:06.928819 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.928822 24730 net.cpp:165] Memory required for data: 3348910080
I0911 23:21:06.928828 24730 layer_factory.hpp:77] Creating layer relu4_3_D
I0911 23:21:06.928836 24730 net.cpp:100] Creating Layer relu4_3_D
I0911 23:21:06.928841 24730 net.cpp:434] relu4_3_D <- conv4_3_D
I0911 23:21:06.928850 24730 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0911 23:21:06.929055 24730 net.cpp:150] Setting up relu4_3_D
I0911 23:21:06.929064 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:06.929069 24730 net.cpp:165] Memory required for data: 3371028480
I0911 23:21:06.929074 24730 layer_factory.hpp:77] Creating layer conv4_2_D
I0911 23:21:06.929086 24730 net.cpp:100] Creating Layer conv4_2_D
I0911 23:21:06.929092 24730 net.cpp:434] conv4_2_D <- conv4_3_D
I0911 23:21:06.929102 24730 net.cpp:408] conv4_2_D -> conv4_2_D
I0911 23:21:07.017657 24730 net.cpp:150] Setting up conv4_2_D
I0911 23:21:07.017673 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.017678 24730 net.cpp:165] Memory required for data: 3393146880
I0911 23:21:07.017685 24730 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0911 23:21:07.017695 24730 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0911 23:21:07.017700 24730 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0911 23:21:07.017706 24730 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0911 23:21:07.017956 24730 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0911 23:21:07.017963 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.017967 24730 net.cpp:165] Memory required for data: 3415265280
I0911 23:21:07.017976 24730 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0911 23:21:07.017982 24730 net.cpp:100] Creating Layer conv4_2_D_scale
I0911 23:21:07.017989 24730 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0911 23:21:07.017994 24730 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0911 23:21:07.018043 24730 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0911 23:21:07.018191 24730 net.cpp:150] Setting up conv4_2_D_scale
I0911 23:21:07.018199 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.018203 24730 net.cpp:165] Memory required for data: 3437383680
I0911 23:21:07.018208 24730 layer_factory.hpp:77] Creating layer relu4_2_D
I0911 23:21:07.018223 24730 net.cpp:100] Creating Layer relu4_2_D
I0911 23:21:07.018227 24730 net.cpp:434] relu4_2_D <- conv4_2_D
I0911 23:21:07.018232 24730 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0911 23:21:07.018440 24730 net.cpp:150] Setting up relu4_2_D
I0911 23:21:07.018451 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.018455 24730 net.cpp:165] Memory required for data: 3459502080
I0911 23:21:07.018460 24730 layer_factory.hpp:77] Creating layer conv4_1_D
I0911 23:21:07.018471 24730 net.cpp:100] Creating Layer conv4_1_D
I0911 23:21:07.018477 24730 net.cpp:434] conv4_1_D <- conv4_2_D
I0911 23:21:07.018483 24730 net.cpp:408] conv4_1_D -> conv4_1_D
I0911 23:21:07.064703 24730 net.cpp:150] Setting up conv4_1_D
I0911 23:21:07.064720 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:07.064724 24730 net.cpp:165] Memory required for data: 3470561280
I0911 23:21:07.064733 24730 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0911 23:21:07.064743 24730 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0911 23:21:07.064752 24730 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0911 23:21:07.064759 24730 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0911 23:21:07.065007 24730 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0911 23:21:07.065032 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:07.065042 24730 net.cpp:165] Memory required for data: 3481620480
I0911 23:21:07.065140 24730 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0911 23:21:07.065151 24730 net.cpp:100] Creating Layer conv4_1_D_scale
I0911 23:21:07.065157 24730 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0911 23:21:07.065162 24730 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0911 23:21:07.065215 24730 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0911 23:21:07.065357 24730 net.cpp:150] Setting up conv4_1_D_scale
I0911 23:21:07.065371 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:07.065376 24730 net.cpp:165] Memory required for data: 3492679680
I0911 23:21:07.065382 24730 layer_factory.hpp:77] Creating layer relu4_1_D
I0911 23:21:07.065390 24730 net.cpp:100] Creating Layer relu4_1_D
I0911 23:21:07.065395 24730 net.cpp:434] relu4_1_D <- conv4_1_D
I0911 23:21:07.065405 24730 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0911 23:21:07.065629 24730 net.cpp:150] Setting up relu4_1_D
I0911 23:21:07.065639 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:07.065644 24730 net.cpp:165] Memory required for data: 3503738880
I0911 23:21:07.065649 24730 layer_factory.hpp:77] Creating layer upsample3
I0911 23:21:07.065655 24730 net.cpp:100] Creating Layer upsample3
I0911 23:21:07.065660 24730 net.cpp:434] upsample3 <- conv4_1_D
I0911 23:21:07.065667 24730 net.cpp:434] upsample3 <- pool3_mask
I0911 23:21:07.065677 24730 net.cpp:408] upsample3 -> pool3_D
I0911 23:21:07.065686 24730 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0911 23:21:07.065719 24730 net.cpp:150] Setting up upsample3
I0911 23:21:07.065726 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.065729 24730 net.cpp:165] Memory required for data: 3547975680
I0911 23:21:07.065733 24730 layer_factory.hpp:77] Creating layer conv3_3_D
I0911 23:21:07.065747 24730 net.cpp:100] Creating Layer conv3_3_D
I0911 23:21:07.065752 24730 net.cpp:434] conv3_3_D <- pool3_D
I0911 23:21:07.065764 24730 net.cpp:408] conv3_3_D -> conv3_3_D
I0911 23:21:07.090477 24730 net.cpp:150] Setting up conv3_3_D
I0911 23:21:07.090494 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.090505 24730 net.cpp:165] Memory required for data: 3592212480
I0911 23:21:07.090513 24730 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0911 23:21:07.090520 24730 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0911 23:21:07.090525 24730 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0911 23:21:07.090530 24730 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0911 23:21:07.090786 24730 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0911 23:21:07.090795 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.090800 24730 net.cpp:165] Memory required for data: 3636449280
I0911 23:21:07.090808 24730 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0911 23:21:07.090816 24730 net.cpp:100] Creating Layer conv3_3_D_scale
I0911 23:21:07.090826 24730 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0911 23:21:07.090831 24730 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0911 23:21:07.090886 24730 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0911 23:21:07.091056 24730 net.cpp:150] Setting up conv3_3_D_scale
I0911 23:21:07.091064 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.091068 24730 net.cpp:165] Memory required for data: 3680686080
I0911 23:21:07.091074 24730 layer_factory.hpp:77] Creating layer relu3_3_D
I0911 23:21:07.091081 24730 net.cpp:100] Creating Layer relu3_3_D
I0911 23:21:07.091086 24730 net.cpp:434] relu3_3_D <- conv3_3_D
I0911 23:21:07.091094 24730 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0911 23:21:07.091312 24730 net.cpp:150] Setting up relu3_3_D
I0911 23:21:07.091321 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.091326 24730 net.cpp:165] Memory required for data: 3724922880
I0911 23:21:07.091346 24730 layer_factory.hpp:77] Creating layer conv3_2_D
I0911 23:21:07.091361 24730 net.cpp:100] Creating Layer conv3_2_D
I0911 23:21:07.091367 24730 net.cpp:434] conv3_2_D <- conv3_3_D
I0911 23:21:07.091377 24730 net.cpp:408] conv3_2_D -> conv3_2_D
I0911 23:21:07.116037 24730 net.cpp:150] Setting up conv3_2_D
I0911 23:21:07.116055 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.116066 24730 net.cpp:165] Memory required for data: 3769159680
I0911 23:21:07.116075 24730 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0911 23:21:07.116087 24730 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0911 23:21:07.116094 24730 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0911 23:21:07.116101 24730 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0911 23:21:07.116355 24730 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0911 23:21:07.116364 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.116367 24730 net.cpp:165] Memory required for data: 3813396480
I0911 23:21:07.116376 24730 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0911 23:21:07.116386 24730 net.cpp:100] Creating Layer conv3_2_D_scale
I0911 23:21:07.116394 24730 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0911 23:21:07.116397 24730 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0911 23:21:07.116446 24730 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0911 23:21:07.116611 24730 net.cpp:150] Setting up conv3_2_D_scale
I0911 23:21:07.116618 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.116621 24730 net.cpp:165] Memory required for data: 3857633280
I0911 23:21:07.116628 24730 layer_factory.hpp:77] Creating layer relu3_2_D
I0911 23:21:07.116638 24730 net.cpp:100] Creating Layer relu3_2_D
I0911 23:21:07.116643 24730 net.cpp:434] relu3_2_D <- conv3_2_D
I0911 23:21:07.116648 24730 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0911 23:21:07.117748 24730 net.cpp:150] Setting up relu3_2_D
I0911 23:21:07.117763 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.117769 24730 net.cpp:165] Memory required for data: 3901870080
I0911 23:21:07.117772 24730 layer_factory.hpp:77] Creating layer conv3_1_D
I0911 23:21:07.117787 24730 net.cpp:100] Creating Layer conv3_1_D
I0911 23:21:07.117794 24730 net.cpp:434] conv3_1_D <- conv3_2_D
I0911 23:21:07.117805 24730 net.cpp:408] conv3_1_D -> conv3_1_D
I0911 23:21:07.132304 24730 net.cpp:150] Setting up conv3_1_D
I0911 23:21:07.132323 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:07.132330 24730 net.cpp:165] Memory required for data: 3923988480
I0911 23:21:07.132339 24730 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0911 23:21:07.132349 24730 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0911 23:21:07.132357 24730 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0911 23:21:07.132366 24730 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0911 23:21:07.132628 24730 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0911 23:21:07.132637 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:07.132640 24730 net.cpp:165] Memory required for data: 3946106880
I0911 23:21:07.132649 24730 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0911 23:21:07.132661 24730 net.cpp:100] Creating Layer conv3_1_D_scale
I0911 23:21:07.132666 24730 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0911 23:21:07.132671 24730 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0911 23:21:07.132721 24730 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0911 23:21:07.132889 24730 net.cpp:150] Setting up conv3_1_D_scale
I0911 23:21:07.132897 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:07.132900 24730 net.cpp:165] Memory required for data: 3968225280
I0911 23:21:07.132906 24730 layer_factory.hpp:77] Creating layer relu3_1_D
I0911 23:21:07.132913 24730 net.cpp:100] Creating Layer relu3_1_D
I0911 23:21:07.132918 24730 net.cpp:434] relu3_1_D <- conv3_1_D
I0911 23:21:07.132931 24730 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0911 23:21:07.133150 24730 net.cpp:150] Setting up relu3_1_D
I0911 23:21:07.133174 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:07.133180 24730 net.cpp:165] Memory required for data: 3990343680
I0911 23:21:07.133183 24730 layer_factory.hpp:77] Creating layer upsample2
I0911 23:21:07.133190 24730 net.cpp:100] Creating Layer upsample2
I0911 23:21:07.133195 24730 net.cpp:434] upsample2 <- conv3_1_D
I0911 23:21:07.133200 24730 net.cpp:434] upsample2 <- pool2_mask
I0911 23:21:07.133210 24730 net.cpp:408] upsample2 -> pool2_D
I0911 23:21:07.133219 24730 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0911 23:21:07.133251 24730 net.cpp:150] Setting up upsample2
I0911 23:21:07.133258 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.133261 24730 net.cpp:165] Memory required for data: 4078817280
I0911 23:21:07.133265 24730 layer_factory.hpp:77] Creating layer conv2_2_D
I0911 23:21:07.133280 24730 net.cpp:100] Creating Layer conv2_2_D
I0911 23:21:07.133285 24730 net.cpp:434] conv2_2_D <- pool2_D
I0911 23:21:07.133291 24730 net.cpp:408] conv2_2_D -> conv2_2_D
I0911 23:21:07.141175 24730 net.cpp:150] Setting up conv2_2_D
I0911 23:21:07.141191 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.141201 24730 net.cpp:165] Memory required for data: 4167290880
I0911 23:21:07.141213 24730 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0911 23:21:07.141225 24730 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0911 23:21:07.141233 24730 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0911 23:21:07.141239 24730 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0911 23:21:07.141556 24730 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0911 23:21:07.141569 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.141582 24730 net.cpp:165] Memory required for data: 4255764480
I0911 23:21:07.141589 24730 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0911 23:21:07.141597 24730 net.cpp:100] Creating Layer conv2_2_D_scale
I0911 23:21:07.141602 24730 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0911 23:21:07.141607 24730 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0911 23:21:07.141661 24730 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0911 23:21:07.143576 24730 net.cpp:150] Setting up conv2_2_D_scale
I0911 23:21:07.143594 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.143599 24730 net.cpp:165] Memory required for data: 4344238080
I0911 23:21:07.143607 24730 layer_factory.hpp:77] Creating layer relu2_2_D
I0911 23:21:07.143615 24730 net.cpp:100] Creating Layer relu2_2_D
I0911 23:21:07.143620 24730 net.cpp:434] relu2_2_D <- conv2_2_D
I0911 23:21:07.143625 24730 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0911 23:21:07.143862 24730 net.cpp:150] Setting up relu2_2_D
I0911 23:21:07.143870 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.143875 24730 net.cpp:165] Memory required for data: 4432711680
I0911 23:21:07.143879 24730 layer_factory.hpp:77] Creating layer conv2_1_D
I0911 23:21:07.143895 24730 net.cpp:100] Creating Layer conv2_1_D
I0911 23:21:07.143900 24730 net.cpp:434] conv2_1_D <- conv2_2_D
I0911 23:21:07.143911 24730 net.cpp:408] conv2_1_D -> conv2_1_D
I0911 23:21:07.149252 24730 net.cpp:150] Setting up conv2_1_D
I0911 23:21:07.149268 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:07.149277 24730 net.cpp:165] Memory required for data: 4476948480
I0911 23:21:07.149287 24730 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0911 23:21:07.149298 24730 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0911 23:21:07.149304 24730 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0911 23:21:07.149310 24730 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0911 23:21:07.149617 24730 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0911 23:21:07.149627 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:07.149631 24730 net.cpp:165] Memory required for data: 4521185280
I0911 23:21:07.149639 24730 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0911 23:21:07.149662 24730 net.cpp:100] Creating Layer conv2_1_D_scale
I0911 23:21:07.149667 24730 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0911 23:21:07.149672 24730 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0911 23:21:07.149729 24730 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0911 23:21:07.149948 24730 net.cpp:150] Setting up conv2_1_D_scale
I0911 23:21:07.149960 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:07.149965 24730 net.cpp:165] Memory required for data: 4565422080
I0911 23:21:07.149971 24730 layer_factory.hpp:77] Creating layer relu2_1_D
I0911 23:21:07.149979 24730 net.cpp:100] Creating Layer relu2_1_D
I0911 23:21:07.149984 24730 net.cpp:434] relu2_1_D <- conv2_1_D
I0911 23:21:07.149988 24730 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0911 23:21:07.150216 24730 net.cpp:150] Setting up relu2_1_D
I0911 23:21:07.150226 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:07.150231 24730 net.cpp:165] Memory required for data: 4609658880
I0911 23:21:07.150234 24730 layer_factory.hpp:77] Creating layer upsample1
I0911 23:21:07.150241 24730 net.cpp:100] Creating Layer upsample1
I0911 23:21:07.150246 24730 net.cpp:434] upsample1 <- conv2_1_D
I0911 23:21:07.150251 24730 net.cpp:434] upsample1 <- pool1_mask
I0911 23:21:07.150259 24730 net.cpp:408] upsample1 -> pool1_D
I0911 23:21:07.150266 24730 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0911 23:21:07.150301 24730 net.cpp:150] Setting up upsample1
I0911 23:21:07.150308 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.150311 24730 net.cpp:165] Memory required for data: 4786606080
I0911 23:21:07.150315 24730 layer_factory.hpp:77] Creating layer conv1_2_D
I0911 23:21:07.150327 24730 net.cpp:100] Creating Layer conv1_2_D
I0911 23:21:07.150332 24730 net.cpp:434] conv1_2_D <- pool1_D
I0911 23:21:07.150341 24730 net.cpp:408] conv1_2_D -> conv1_2_D
I0911 23:21:07.155313 24730 net.cpp:150] Setting up conv1_2_D
I0911 23:21:07.155328 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.155339 24730 net.cpp:165] Memory required for data: 4963553280
I0911 23:21:07.155345 24730 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0911 23:21:07.155359 24730 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0911 23:21:07.155365 24730 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0911 23:21:07.155375 24730 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0911 23:21:07.155764 24730 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0911 23:21:07.155773 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.155777 24730 net.cpp:165] Memory required for data: 5140500480
I0911 23:21:07.155786 24730 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0911 23:21:07.155796 24730 net.cpp:100] Creating Layer conv1_2_D_scale
I0911 23:21:07.155802 24730 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0911 23:21:07.155805 24730 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0911 23:21:07.155858 24730 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0911 23:21:07.157955 24730 net.cpp:150] Setting up conv1_2_D_scale
I0911 23:21:07.157970 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.157975 24730 net.cpp:165] Memory required for data: 5317447680
I0911 23:21:07.157986 24730 layer_factory.hpp:77] Creating layer relu1_2_D
I0911 23:21:07.157994 24730 net.cpp:100] Creating Layer relu1_2_D
I0911 23:21:07.158000 24730 net.cpp:434] relu1_2_D <- conv1_2_D
I0911 23:21:07.158005 24730 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0911 23:21:07.158239 24730 net.cpp:150] Setting up relu1_2_D
I0911 23:21:07.158252 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.158257 24730 net.cpp:165] Memory required for data: 5494394880
I0911 23:21:07.158262 24730 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0911 23:21:07.158277 24730 net.cpp:100] Creating Layer conv1_1_1_D
I0911 23:21:07.158282 24730 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0911 23:21:07.158304 24730 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0911 23:21:07.160382 24730 net.cpp:150] Setting up conv1_1_1_D
I0911 23:21:07.160398 24730 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0911 23:21:07.160403 24730 net.cpp:165] Memory required for data: 5499924480
I0911 23:21:07.160410 24730 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0911 23:21:07.160418 24730 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0911 23:21:07.160424 24730 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0911 23:21:07.160430 24730 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0911 23:21:07.160442 24730 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0911 23:21:07.160495 24730 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0911 23:21:07.160502 24730 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0911 23:21:07.160507 24730 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0911 23:21:07.160511 24730 net.cpp:165] Memory required for data: 5510983680
I0911 23:21:07.160516 24730 layer_factory.hpp:77] Creating layer loss
I0911 23:21:07.160532 24730 net.cpp:100] Creating Layer loss
I0911 23:21:07.160538 24730 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0911 23:21:07.160543 24730 net.cpp:434] loss <- label_data_1_split_0
I0911 23:21:07.160549 24730 net.cpp:408] loss -> loss
I0911 23:21:07.160571 24730 layer_factory.hpp:77] Creating layer loss
I0911 23:21:07.165736 24730 net.cpp:150] Setting up loss
I0911 23:21:07.165751 24730 net.cpp:157] Top shape: (1)
I0911 23:21:07.165755 24730 net.cpp:160]     with loss weight 1
I0911 23:21:07.165793 24730 net.cpp:165] Memory required for data: 5510983684
I0911 23:21:07.165798 24730 layer_factory.hpp:77] Creating layer accuracy
I0911 23:21:07.165807 24730 net.cpp:100] Creating Layer accuracy
I0911 23:21:07.165817 24730 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0911 23:21:07.165822 24730 net.cpp:434] accuracy <- label_data_1_split_1
I0911 23:21:07.165832 24730 net.cpp:408] accuracy -> accuracy
I0911 23:21:07.165844 24730 net.cpp:408] accuracy -> per_class_accuracy
I0911 23:21:07.165897 24730 net.cpp:150] Setting up accuracy
I0911 23:21:07.165905 24730 net.cpp:157] Top shape: (1)
I0911 23:21:07.165910 24730 net.cpp:157] Top shape: 2 (2)
I0911 23:21:07.165913 24730 net.cpp:165] Memory required for data: 5510983696
I0911 23:21:07.165917 24730 net.cpp:228] accuracy does not need backward computation.
I0911 23:21:07.165921 24730 net.cpp:226] loss needs backward computation.
I0911 23:21:07.165927 24730 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0911 23:21:07.165930 24730 net.cpp:226] conv1_1_1_D needs backward computation.
I0911 23:21:07.165935 24730 net.cpp:226] relu1_2_D needs backward computation.
I0911 23:21:07.165937 24730 net.cpp:226] conv1_2_D_scale needs backward computation.
I0911 23:21:07.165940 24730 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0911 23:21:07.165943 24730 net.cpp:226] conv1_2_D needs backward computation.
I0911 23:21:07.165946 24730 net.cpp:226] upsample1 needs backward computation.
I0911 23:21:07.165951 24730 net.cpp:226] relu2_1_D needs backward computation.
I0911 23:21:07.165953 24730 net.cpp:226] conv2_1_D_scale needs backward computation.
I0911 23:21:07.165956 24730 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0911 23:21:07.165959 24730 net.cpp:226] conv2_1_D needs backward computation.
I0911 23:21:07.165962 24730 net.cpp:226] relu2_2_D needs backward computation.
I0911 23:21:07.165966 24730 net.cpp:226] conv2_2_D_scale needs backward computation.
I0911 23:21:07.165968 24730 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0911 23:21:07.165971 24730 net.cpp:226] conv2_2_D needs backward computation.
I0911 23:21:07.165977 24730 net.cpp:226] upsample2 needs backward computation.
I0911 23:21:07.165982 24730 net.cpp:226] relu3_1_D needs backward computation.
I0911 23:21:07.165985 24730 net.cpp:226] conv3_1_D_scale needs backward computation.
I0911 23:21:07.166004 24730 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0911 23:21:07.166008 24730 net.cpp:226] conv3_1_D needs backward computation.
I0911 23:21:07.166012 24730 net.cpp:226] relu3_2_D needs backward computation.
I0911 23:21:07.166014 24730 net.cpp:226] conv3_2_D_scale needs backward computation.
I0911 23:21:07.166018 24730 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0911 23:21:07.166020 24730 net.cpp:226] conv3_2_D needs backward computation.
I0911 23:21:07.166024 24730 net.cpp:226] relu3_3_D needs backward computation.
I0911 23:21:07.166028 24730 net.cpp:226] conv3_3_D_scale needs backward computation.
I0911 23:21:07.166030 24730 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0911 23:21:07.166033 24730 net.cpp:226] conv3_3_D needs backward computation.
I0911 23:21:07.166036 24730 net.cpp:226] upsample3 needs backward computation.
I0911 23:21:07.166040 24730 net.cpp:226] relu4_1_D needs backward computation.
I0911 23:21:07.166043 24730 net.cpp:226] conv4_1_D_scale needs backward computation.
I0911 23:21:07.166048 24730 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0911 23:21:07.166050 24730 net.cpp:226] conv4_1_D needs backward computation.
I0911 23:21:07.166054 24730 net.cpp:226] relu4_2_D needs backward computation.
I0911 23:21:07.166056 24730 net.cpp:226] conv4_2_D_scale needs backward computation.
I0911 23:21:07.166060 24730 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0911 23:21:07.166064 24730 net.cpp:226] conv4_2_D needs backward computation.
I0911 23:21:07.166067 24730 net.cpp:226] relu4_3_D needs backward computation.
I0911 23:21:07.166071 24730 net.cpp:226] conv4_3_D_scale needs backward computation.
I0911 23:21:07.166074 24730 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0911 23:21:07.166077 24730 net.cpp:226] conv4_3_D needs backward computation.
I0911 23:21:07.166081 24730 net.cpp:226] upsample4 needs backward computation.
I0911 23:21:07.166087 24730 net.cpp:226] relu5_1_D needs backward computation.
I0911 23:21:07.166092 24730 net.cpp:226] conv5_1_D_scale needs backward computation.
I0911 23:21:07.166095 24730 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0911 23:21:07.166100 24730 net.cpp:226] conv5_1_D needs backward computation.
I0911 23:21:07.166105 24730 net.cpp:226] relu5_2_D needs backward computation.
I0911 23:21:07.166108 24730 net.cpp:226] conv5_2_D_scale needs backward computation.
I0911 23:21:07.166111 24730 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0911 23:21:07.166115 24730 net.cpp:226] conv5_2_D needs backward computation.
I0911 23:21:07.166121 24730 net.cpp:226] relu5_3_D needs backward computation.
I0911 23:21:07.166124 24730 net.cpp:226] conv5_3_D_scale needs backward computation.
I0911 23:21:07.166127 24730 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0911 23:21:07.166134 24730 net.cpp:226] conv5_3_D needs backward computation.
I0911 23:21:07.166138 24730 net.cpp:226] upsample5 needs backward computation.
I0911 23:21:07.166146 24730 net.cpp:226] pool5 needs backward computation.
I0911 23:21:07.166152 24730 net.cpp:226] relu5_3 needs backward computation.
I0911 23:21:07.166154 24730 net.cpp:226] conv5_3_scale needs backward computation.
I0911 23:21:07.166158 24730 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0911 23:21:07.166162 24730 net.cpp:226] conv5_3 needs backward computation.
I0911 23:21:07.166168 24730 net.cpp:226] relu5_2 needs backward computation.
I0911 23:21:07.166172 24730 net.cpp:226] conv5_2_scale needs backward computation.
I0911 23:21:07.166177 24730 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0911 23:21:07.166182 24730 net.cpp:226] conv5_2 needs backward computation.
I0911 23:21:07.166188 24730 net.cpp:226] relu5_1 needs backward computation.
I0911 23:21:07.166193 24730 net.cpp:226] conv5_1_scale needs backward computation.
I0911 23:21:07.166196 24730 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0911 23:21:07.166200 24730 net.cpp:226] conv5_1 needs backward computation.
I0911 23:21:07.166205 24730 net.cpp:226] pool4 needs backward computation.
I0911 23:21:07.166218 24730 net.cpp:226] relu4_3 needs backward computation.
I0911 23:21:07.166223 24730 net.cpp:226] conv4_3_scale needs backward computation.
I0911 23:21:07.166225 24730 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0911 23:21:07.166230 24730 net.cpp:226] conv4_3 needs backward computation.
I0911 23:21:07.166235 24730 net.cpp:226] relu4_2 needs backward computation.
I0911 23:21:07.166239 24730 net.cpp:226] conv4_2_scale needs backward computation.
I0911 23:21:07.166244 24730 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0911 23:21:07.166247 24730 net.cpp:226] conv4_2 needs backward computation.
I0911 23:21:07.166254 24730 net.cpp:226] relu4_1 needs backward computation.
I0911 23:21:07.166256 24730 net.cpp:226] conv4_1_scale needs backward computation.
I0911 23:21:07.166260 24730 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0911 23:21:07.166263 24730 net.cpp:226] conv4_1 needs backward computation.
I0911 23:21:07.166267 24730 net.cpp:226] pool3 needs backward computation.
I0911 23:21:07.166270 24730 net.cpp:226] relu3_3 needs backward computation.
I0911 23:21:07.166275 24730 net.cpp:226] conv3_3_scale needs backward computation.
I0911 23:21:07.166280 24730 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0911 23:21:07.166283 24730 net.cpp:226] conv3_3 needs backward computation.
I0911 23:21:07.166288 24730 net.cpp:226] relu3_2 needs backward computation.
I0911 23:21:07.166292 24730 net.cpp:226] conv3_2_scale needs backward computation.
I0911 23:21:07.166296 24730 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0911 23:21:07.166301 24730 net.cpp:226] conv3_2 needs backward computation.
I0911 23:21:07.166304 24730 net.cpp:226] relu3_1 needs backward computation.
I0911 23:21:07.166308 24730 net.cpp:226] conv3_1_scale needs backward computation.
I0911 23:21:07.166312 24730 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0911 23:21:07.166316 24730 net.cpp:226] conv3_1 needs backward computation.
I0911 23:21:07.166321 24730 net.cpp:226] pool2 needs backward computation.
I0911 23:21:07.166323 24730 net.cpp:226] relu2_2 needs backward computation.
I0911 23:21:07.166327 24730 net.cpp:226] conv2_2_scale needs backward computation.
I0911 23:21:07.166332 24730 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0911 23:21:07.166337 24730 net.cpp:226] conv2_2 needs backward computation.
I0911 23:21:07.166340 24730 net.cpp:226] relu2_1 needs backward computation.
I0911 23:21:07.166343 24730 net.cpp:226] conv2_1_scale needs backward computation.
I0911 23:21:07.166348 24730 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0911 23:21:07.166352 24730 net.cpp:226] conv2_1 needs backward computation.
I0911 23:21:07.166357 24730 net.cpp:226] pool1 needs backward computation.
I0911 23:21:07.166359 24730 net.cpp:226] relu1_2 needs backward computation.
I0911 23:21:07.166363 24730 net.cpp:226] conv1_2_scale needs backward computation.
I0911 23:21:07.166366 24730 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0911 23:21:07.166370 24730 net.cpp:226] conv1_2 needs backward computation.
I0911 23:21:07.166375 24730 net.cpp:226] relu1_1 needs backward computation.
I0911 23:21:07.166379 24730 net.cpp:226] conv1_1_1_scale needs backward computation.
I0911 23:21:07.166383 24730 net.cpp:226] conv1_1_1_bn needs backward computation.
I0911 23:21:07.166385 24730 net.cpp:226] conv1_1_1 needs backward computation.
I0911 23:21:07.166391 24730 net.cpp:228] label_data_1_split does not need backward computation.
I0911 23:21:07.166396 24730 net.cpp:228] data does not need backward computation.
I0911 23:21:07.166399 24730 net.cpp:270] This network produces output accuracy
I0911 23:21:07.166404 24730 net.cpp:270] This network produces output loss
I0911 23:21:07.166407 24730 net.cpp:270] This network produces output per_class_accuracy
I0911 23:21:07.166476 24730 net.cpp:283] Network initialization done.
I0911 23:21:07.168803 24730 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc1/caffe/model_segnet_final/train.prototxt
I0911 23:21:07.169508 24730 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc1/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0911 23:21:07.169947 24730 layer_factory.hpp:77] Creating layer data
I0911 23:21:07.169960 24730 net.cpp:100] Creating Layer data
I0911 23:21:07.169966 24730 net.cpp:408] data -> data
I0911 23:21:07.169975 24730 net.cpp:408] data -> label
I0911 23:21:07.169983 24730 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc1/HDF5Files/train_combined.txt
I0911 23:21:07.170023 24730 hdf5_data_layer.cpp:93] Number of HDF5 files: 26
I0911 23:21:07.182585 24730 net.cpp:150] Setting up data
I0911 23:21:07.182605 24730 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0911 23:21:07.182610 24730 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0911 23:21:07.182615 24730 net.cpp:165] Memory required for data: 24883200
I0911 23:21:07.182618 24730 layer_factory.hpp:77] Creating layer label_data_1_split
I0911 23:21:07.182627 24730 net.cpp:100] Creating Layer label_data_1_split
I0911 23:21:07.182631 24730 net.cpp:434] label_data_1_split <- label
I0911 23:21:07.182638 24730 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0911 23:21:07.182647 24730 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0911 23:21:07.182692 24730 net.cpp:150] Setting up label_data_1_split
I0911 23:21:07.182699 24730 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0911 23:21:07.182704 24730 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0911 23:21:07.182713 24730 net.cpp:165] Memory required for data: 30412800
I0911 23:21:07.182718 24730 layer_factory.hpp:77] Creating layer conv1_1_1
I0911 23:21:07.182727 24730 net.cpp:100] Creating Layer conv1_1_1
I0911 23:21:07.182732 24730 net.cpp:434] conv1_1_1 <- data
I0911 23:21:07.182739 24730 net.cpp:408] conv1_1_1 -> conv1_1_1
I0911 23:21:07.186676 24730 net.cpp:150] Setting up conv1_1_1
I0911 23:21:07.186693 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.186697 24730 net.cpp:165] Memory required for data: 207360000
I0911 23:21:07.186708 24730 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0911 23:21:07.186717 24730 net.cpp:100] Creating Layer conv1_1_1_bn
I0911 23:21:07.186720 24730 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0911 23:21:07.186725 24730 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0911 23:21:07.187100 24730 net.cpp:150] Setting up conv1_1_1_bn
I0911 23:21:07.187110 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.187120 24730 net.cpp:165] Memory required for data: 384307200
I0911 23:21:07.187132 24730 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0911 23:21:07.187140 24730 net.cpp:100] Creating Layer conv1_1_1_scale
I0911 23:21:07.187149 24730 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0911 23:21:07.187153 24730 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0911 23:21:07.187203 24730 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0911 23:21:07.189306 24730 net.cpp:150] Setting up conv1_1_1_scale
I0911 23:21:07.189322 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.189332 24730 net.cpp:165] Memory required for data: 561254400
I0911 23:21:07.189339 24730 layer_factory.hpp:77] Creating layer relu1_1
I0911 23:21:07.189349 24730 net.cpp:100] Creating Layer relu1_1
I0911 23:21:07.189358 24730 net.cpp:434] relu1_1 <- conv1_1_1
I0911 23:21:07.189363 24730 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0911 23:21:07.189591 24730 net.cpp:150] Setting up relu1_1
I0911 23:21:07.189602 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.189607 24730 net.cpp:165] Memory required for data: 738201600
I0911 23:21:07.189610 24730 layer_factory.hpp:77] Creating layer conv1_2
I0911 23:21:07.189620 24730 net.cpp:100] Creating Layer conv1_2
I0911 23:21:07.189625 24730 net.cpp:434] conv1_2 <- conv1_1_1
I0911 23:21:07.189631 24730 net.cpp:408] conv1_2 -> conv1_2
I0911 23:21:07.193763 24730 net.cpp:150] Setting up conv1_2
I0911 23:21:07.193778 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.193789 24730 net.cpp:165] Memory required for data: 915148800
I0911 23:21:07.193819 24730 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0911 23:21:07.193830 24730 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0911 23:21:07.193840 24730 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0911 23:21:07.193845 24730 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0911 23:21:07.194218 24730 net.cpp:150] Setting up conv1_2_bn_tmp
I0911 23:21:07.194227 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.194232 24730 net.cpp:165] Memory required for data: 1092096000
I0911 23:21:07.194241 24730 layer_factory.hpp:77] Creating layer conv1_2_scale
I0911 23:21:07.194249 24730 net.cpp:100] Creating Layer conv1_2_scale
I0911 23:21:07.194254 24730 net.cpp:434] conv1_2_scale <- conv1_2
I0911 23:21:07.194259 24730 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0911 23:21:07.194308 24730 layer_factory.hpp:77] Creating layer conv1_2_scale
I0911 23:21:07.196405 24730 net.cpp:150] Setting up conv1_2_scale
I0911 23:21:07.196420 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.196425 24730 net.cpp:165] Memory required for data: 1269043200
I0911 23:21:07.196432 24730 layer_factory.hpp:77] Creating layer relu1_2
I0911 23:21:07.196440 24730 net.cpp:100] Creating Layer relu1_2
I0911 23:21:07.196445 24730 net.cpp:434] relu1_2 <- conv1_2
I0911 23:21:07.196450 24730 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0911 23:21:07.197573 24730 net.cpp:150] Setting up relu1_2
I0911 23:21:07.197588 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:07.197593 24730 net.cpp:165] Memory required for data: 1445990400
I0911 23:21:07.197598 24730 layer_factory.hpp:77] Creating layer pool1
I0911 23:21:07.197602 24730 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0911 23:21:07.197610 24730 net.cpp:100] Creating Layer pool1
I0911 23:21:07.197615 24730 net.cpp:434] pool1 <- conv1_2
I0911 23:21:07.197621 24730 net.cpp:408] pool1 -> pool1
I0911 23:21:07.197630 24730 net.cpp:408] pool1 -> pool1_mask
I0911 23:21:07.197690 24730 net.cpp:150] Setting up pool1
I0911 23:21:07.197697 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:07.197705 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:07.197707 24730 net.cpp:165] Memory required for data: 1534464000
I0911 23:21:07.197710 24730 layer_factory.hpp:77] Creating layer conv2_1
I0911 23:21:07.197722 24730 net.cpp:100] Creating Layer conv2_1
I0911 23:21:07.197727 24730 net.cpp:434] conv2_1 <- pool1
I0911 23:21:07.197733 24730 net.cpp:408] conv2_1 -> conv2_1
I0911 23:21:07.202157 24730 net.cpp:150] Setting up conv2_1
I0911 23:21:07.202172 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.202181 24730 net.cpp:165] Memory required for data: 1622937600
I0911 23:21:07.202189 24730 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0911 23:21:07.202199 24730 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0911 23:21:07.202208 24730 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0911 23:21:07.202214 24730 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0911 23:21:07.202543 24730 net.cpp:150] Setting up conv2_1_bn_tmp
I0911 23:21:07.202551 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.202554 24730 net.cpp:165] Memory required for data: 1711411200
I0911 23:21:07.202566 24730 layer_factory.hpp:77] Creating layer conv2_1_scale
I0911 23:21:07.202574 24730 net.cpp:100] Creating Layer conv2_1_scale
I0911 23:21:07.202579 24730 net.cpp:434] conv2_1_scale <- conv2_1
I0911 23:21:07.202584 24730 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0911 23:21:07.202641 24730 layer_factory.hpp:77] Creating layer conv2_1_scale
I0911 23:21:07.202891 24730 net.cpp:150] Setting up conv2_1_scale
I0911 23:21:07.202900 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.202903 24730 net.cpp:165] Memory required for data: 1799884800
I0911 23:21:07.202910 24730 layer_factory.hpp:77] Creating layer relu2_1
I0911 23:21:07.202920 24730 net.cpp:100] Creating Layer relu2_1
I0911 23:21:07.202925 24730 net.cpp:434] relu2_1 <- conv2_1
I0911 23:21:07.202929 24730 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0911 23:21:07.204071 24730 net.cpp:150] Setting up relu2_1
I0911 23:21:07.204085 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.204090 24730 net.cpp:165] Memory required for data: 1888358400
I0911 23:21:07.204094 24730 layer_factory.hpp:77] Creating layer conv2_2
I0911 23:21:07.204110 24730 net.cpp:100] Creating Layer conv2_2
I0911 23:21:07.204115 24730 net.cpp:434] conv2_2 <- conv2_1
I0911 23:21:07.204123 24730 net.cpp:408] conv2_2 -> conv2_2
I0911 23:21:07.213733 24730 net.cpp:150] Setting up conv2_2
I0911 23:21:07.213750 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.213762 24730 net.cpp:165] Memory required for data: 1976832000
I0911 23:21:07.213773 24730 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0911 23:21:07.213785 24730 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0911 23:21:07.213791 24730 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0911 23:21:07.213796 24730 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0911 23:21:07.215776 24730 net.cpp:150] Setting up conv2_2_bn_tmp
I0911 23:21:07.215791 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.215801 24730 net.cpp:165] Memory required for data: 2065305600
I0911 23:21:07.215809 24730 layer_factory.hpp:77] Creating layer conv2_2_scale
I0911 23:21:07.215816 24730 net.cpp:100] Creating Layer conv2_2_scale
I0911 23:21:07.215821 24730 net.cpp:434] conv2_2_scale <- conv2_2
I0911 23:21:07.215826 24730 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0911 23:21:07.215883 24730 layer_factory.hpp:77] Creating layer conv2_2_scale
I0911 23:21:07.216096 24730 net.cpp:150] Setting up conv2_2_scale
I0911 23:21:07.216105 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.216109 24730 net.cpp:165] Memory required for data: 2153779200
I0911 23:21:07.216115 24730 layer_factory.hpp:77] Creating layer relu2_2
I0911 23:21:07.216128 24730 net.cpp:100] Creating Layer relu2_2
I0911 23:21:07.216133 24730 net.cpp:434] relu2_2 <- conv2_2
I0911 23:21:07.216138 24730 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0911 23:21:07.216370 24730 net.cpp:150] Setting up relu2_2
I0911 23:21:07.216380 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:07.216385 24730 net.cpp:165] Memory required for data: 2242252800
I0911 23:21:07.216389 24730 layer_factory.hpp:77] Creating layer pool2
I0911 23:21:07.216393 24730 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0911 23:21:07.216401 24730 net.cpp:100] Creating Layer pool2
I0911 23:21:07.216406 24730 net.cpp:434] pool2 <- conv2_2
I0911 23:21:07.216413 24730 net.cpp:408] pool2 -> pool2
I0911 23:21:07.216421 24730 net.cpp:408] pool2 -> pool2_mask
I0911 23:21:07.216480 24730 net.cpp:150] Setting up pool2
I0911 23:21:07.216486 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:07.216491 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:07.216495 24730 net.cpp:165] Memory required for data: 2286489600
I0911 23:21:07.216498 24730 layer_factory.hpp:77] Creating layer conv3_1
I0911 23:21:07.216511 24730 net.cpp:100] Creating Layer conv3_1
I0911 23:21:07.216516 24730 net.cpp:434] conv3_1 <- pool2
I0911 23:21:07.216524 24730 net.cpp:408] conv3_1 -> conv3_1
I0911 23:21:07.229326 24730 net.cpp:150] Setting up conv3_1
I0911 23:21:07.229342 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.229352 24730 net.cpp:165] Memory required for data: 2330726400
I0911 23:21:07.229360 24730 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0911 23:21:07.229387 24730 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0911 23:21:07.229393 24730 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0911 23:21:07.229400 24730 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0911 23:21:07.229686 24730 net.cpp:150] Setting up conv3_1_bn_tmp
I0911 23:21:07.229696 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.229699 24730 net.cpp:165] Memory required for data: 2374963200
I0911 23:21:07.229714 24730 layer_factory.hpp:77] Creating layer conv3_1_scale
I0911 23:21:07.229737 24730 net.cpp:100] Creating Layer conv3_1_scale
I0911 23:21:07.229743 24730 net.cpp:434] conv3_1_scale <- conv3_1
I0911 23:21:07.229748 24730 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0911 23:21:07.229809 24730 layer_factory.hpp:77] Creating layer conv3_1_scale
I0911 23:21:07.229990 24730 net.cpp:150] Setting up conv3_1_scale
I0911 23:21:07.230000 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.230002 24730 net.cpp:165] Memory required for data: 2419200000
I0911 23:21:07.230010 24730 layer_factory.hpp:77] Creating layer relu3_1
I0911 23:21:07.230020 24730 net.cpp:100] Creating Layer relu3_1
I0911 23:21:07.230024 24730 net.cpp:434] relu3_1 <- conv3_1
I0911 23:21:07.230031 24730 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0911 23:21:07.230262 24730 net.cpp:150] Setting up relu3_1
I0911 23:21:07.230273 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.230275 24730 net.cpp:165] Memory required for data: 2463436800
I0911 23:21:07.230279 24730 layer_factory.hpp:77] Creating layer conv3_2
I0911 23:21:07.230293 24730 net.cpp:100] Creating Layer conv3_2
I0911 23:21:07.230298 24730 net.cpp:434] conv3_2 <- conv3_1
I0911 23:21:07.230307 24730 net.cpp:408] conv3_2 -> conv3_2
I0911 23:21:07.254999 24730 net.cpp:150] Setting up conv3_2
I0911 23:21:07.255017 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.255029 24730 net.cpp:165] Memory required for data: 2507673600
I0911 23:21:07.255038 24730 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0911 23:21:07.255050 24730 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0911 23:21:07.255056 24730 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0911 23:21:07.255062 24730 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0911 23:21:07.255342 24730 net.cpp:150] Setting up conv3_2_bn_tmp
I0911 23:21:07.255352 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.255354 24730 net.cpp:165] Memory required for data: 2551910400
I0911 23:21:07.255362 24730 layer_factory.hpp:77] Creating layer conv3_2_scale
I0911 23:21:07.255373 24730 net.cpp:100] Creating Layer conv3_2_scale
I0911 23:21:07.255378 24730 net.cpp:434] conv3_2_scale <- conv3_2
I0911 23:21:07.255383 24730 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0911 23:21:07.255440 24730 layer_factory.hpp:77] Creating layer conv3_2_scale
I0911 23:21:07.255620 24730 net.cpp:150] Setting up conv3_2_scale
I0911 23:21:07.255628 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.255632 24730 net.cpp:165] Memory required for data: 2596147200
I0911 23:21:07.255638 24730 layer_factory.hpp:77] Creating layer relu3_2
I0911 23:21:07.255645 24730 net.cpp:100] Creating Layer relu3_2
I0911 23:21:07.255650 24730 net.cpp:434] relu3_2 <- conv3_2
I0911 23:21:07.255662 24730 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0911 23:21:07.255888 24730 net.cpp:150] Setting up relu3_2
I0911 23:21:07.255898 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.255903 24730 net.cpp:165] Memory required for data: 2640384000
I0911 23:21:07.255906 24730 layer_factory.hpp:77] Creating layer conv3_3
I0911 23:21:07.255921 24730 net.cpp:100] Creating Layer conv3_3
I0911 23:21:07.255928 24730 net.cpp:434] conv3_3 <- conv3_2
I0911 23:21:07.255934 24730 net.cpp:408] conv3_3 -> conv3_3
I0911 23:21:07.280586 24730 net.cpp:150] Setting up conv3_3
I0911 23:21:07.280602 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.280612 24730 net.cpp:165] Memory required for data: 2684620800
I0911 23:21:07.280620 24730 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0911 23:21:07.280634 24730 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0911 23:21:07.280640 24730 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0911 23:21:07.280647 24730 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0911 23:21:07.280931 24730 net.cpp:150] Setting up conv3_3_bn_tmp
I0911 23:21:07.280939 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.280949 24730 net.cpp:165] Memory required for data: 2728857600
I0911 23:21:07.280957 24730 layer_factory.hpp:77] Creating layer conv3_3_scale
I0911 23:21:07.280980 24730 net.cpp:100] Creating Layer conv3_3_scale
I0911 23:21:07.280985 24730 net.cpp:434] conv3_3_scale <- conv3_3
I0911 23:21:07.280994 24730 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0911 23:21:07.281047 24730 layer_factory.hpp:77] Creating layer conv3_3_scale
I0911 23:21:07.281224 24730 net.cpp:150] Setting up conv3_3_scale
I0911 23:21:07.281235 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.281240 24730 net.cpp:165] Memory required for data: 2773094400
I0911 23:21:07.281246 24730 layer_factory.hpp:77] Creating layer relu3_3
I0911 23:21:07.281255 24730 net.cpp:100] Creating Layer relu3_3
I0911 23:21:07.281258 24730 net.cpp:434] relu3_3 <- conv3_3
I0911 23:21:07.281263 24730 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0911 23:21:07.281514 24730 net.cpp:150] Setting up relu3_3
I0911 23:21:07.281527 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:07.281533 24730 net.cpp:165] Memory required for data: 2817331200
I0911 23:21:07.281536 24730 layer_factory.hpp:77] Creating layer pool3
I0911 23:21:07.281540 24730 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0911 23:21:07.281549 24730 net.cpp:100] Creating Layer pool3
I0911 23:21:07.281554 24730 net.cpp:434] pool3 <- conv3_3
I0911 23:21:07.281563 24730 net.cpp:408] pool3 -> pool3
I0911 23:21:07.281572 24730 net.cpp:408] pool3 -> pool3_mask
I0911 23:21:07.281632 24730 net.cpp:150] Setting up pool3
I0911 23:21:07.281641 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:07.281644 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:07.281648 24730 net.cpp:165] Memory required for data: 2839449600
I0911 23:21:07.281652 24730 layer_factory.hpp:77] Creating layer conv4_1
I0911 23:21:07.281664 24730 net.cpp:100] Creating Layer conv4_1
I0911 23:21:07.281669 24730 net.cpp:434] conv4_1 <- pool3
I0911 23:21:07.281679 24730 net.cpp:408] conv4_1 -> conv4_1
I0911 23:21:07.327734 24730 net.cpp:150] Setting up conv4_1
I0911 23:21:07.327751 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.327762 24730 net.cpp:165] Memory required for data: 2861568000
I0911 23:21:07.327774 24730 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0911 23:21:07.327785 24730 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0911 23:21:07.327791 24730 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0911 23:21:07.327797 24730 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0911 23:21:07.328073 24730 net.cpp:150] Setting up conv4_1_bn_tmp
I0911 23:21:07.328081 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.328085 24730 net.cpp:165] Memory required for data: 2883686400
I0911 23:21:07.328094 24730 layer_factory.hpp:77] Creating layer conv4_1_scale
I0911 23:21:07.328104 24730 net.cpp:100] Creating Layer conv4_1_scale
I0911 23:21:07.328111 24730 net.cpp:434] conv4_1_scale <- conv4_1
I0911 23:21:07.328116 24730 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0911 23:21:07.328167 24730 layer_factory.hpp:77] Creating layer conv4_1_scale
I0911 23:21:07.328335 24730 net.cpp:150] Setting up conv4_1_scale
I0911 23:21:07.328343 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.328346 24730 net.cpp:165] Memory required for data: 2905804800
I0911 23:21:07.328352 24730 layer_factory.hpp:77] Creating layer relu4_1
I0911 23:21:07.328359 24730 net.cpp:100] Creating Layer relu4_1
I0911 23:21:07.328364 24730 net.cpp:434] relu4_1 <- conv4_1
I0911 23:21:07.328373 24730 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0911 23:21:07.329532 24730 net.cpp:150] Setting up relu4_1
I0911 23:21:07.329546 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.329552 24730 net.cpp:165] Memory required for data: 2927923200
I0911 23:21:07.329556 24730 layer_factory.hpp:77] Creating layer conv4_2
I0911 23:21:07.329571 24730 net.cpp:100] Creating Layer conv4_2
I0911 23:21:07.329576 24730 net.cpp:434] conv4_2 <- conv4_1
I0911 23:21:07.329584 24730 net.cpp:408] conv4_2 -> conv4_2
I0911 23:21:07.417843 24730 net.cpp:150] Setting up conv4_2
I0911 23:21:07.417879 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.417884 24730 net.cpp:165] Memory required for data: 2950041600
I0911 23:21:07.417892 24730 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0911 23:21:07.417908 24730 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0911 23:21:07.417923 24730 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0911 23:21:07.417933 24730 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0911 23:21:07.418212 24730 net.cpp:150] Setting up conv4_2_bn_tmp
I0911 23:21:07.418222 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.418231 24730 net.cpp:165] Memory required for data: 2972160000
I0911 23:21:07.418244 24730 layer_factory.hpp:77] Creating layer conv4_2_scale
I0911 23:21:07.418254 24730 net.cpp:100] Creating Layer conv4_2_scale
I0911 23:21:07.418260 24730 net.cpp:434] conv4_2_scale <- conv4_2
I0911 23:21:07.418265 24730 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0911 23:21:07.418315 24730 layer_factory.hpp:77] Creating layer conv4_2_scale
I0911 23:21:07.418483 24730 net.cpp:150] Setting up conv4_2_scale
I0911 23:21:07.418491 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.418495 24730 net.cpp:165] Memory required for data: 2994278400
I0911 23:21:07.418501 24730 layer_factory.hpp:77] Creating layer relu4_2
I0911 23:21:07.418514 24730 net.cpp:100] Creating Layer relu4_2
I0911 23:21:07.418519 24730 net.cpp:434] relu4_2 <- conv4_2
I0911 23:21:07.418524 24730 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0911 23:21:07.419723 24730 net.cpp:150] Setting up relu4_2
I0911 23:21:07.419741 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.419746 24730 net.cpp:165] Memory required for data: 3016396800
I0911 23:21:07.419750 24730 layer_factory.hpp:77] Creating layer conv4_3
I0911 23:21:07.419766 24730 net.cpp:100] Creating Layer conv4_3
I0911 23:21:07.419772 24730 net.cpp:434] conv4_3 <- conv4_2
I0911 23:21:07.419780 24730 net.cpp:408] conv4_3 -> conv4_3
I0911 23:21:07.507843 24730 net.cpp:150] Setting up conv4_3
I0911 23:21:07.507859 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.507863 24730 net.cpp:165] Memory required for data: 3038515200
I0911 23:21:07.507891 24730 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0911 23:21:07.507905 24730 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0911 23:21:07.507910 24730 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0911 23:21:07.507918 24730 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0911 23:21:07.508190 24730 net.cpp:150] Setting up conv4_3_bn_tmp
I0911 23:21:07.508200 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.508203 24730 net.cpp:165] Memory required for data: 3060633600
I0911 23:21:07.508213 24730 layer_factory.hpp:77] Creating layer conv4_3_scale
I0911 23:21:07.508221 24730 net.cpp:100] Creating Layer conv4_3_scale
I0911 23:21:07.508229 24730 net.cpp:434] conv4_3_scale <- conv4_3
I0911 23:21:07.508237 24730 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0911 23:21:07.508287 24730 layer_factory.hpp:77] Creating layer conv4_3_scale
I0911 23:21:07.508457 24730 net.cpp:150] Setting up conv4_3_scale
I0911 23:21:07.508467 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.508471 24730 net.cpp:165] Memory required for data: 3082752000
I0911 23:21:07.508477 24730 layer_factory.hpp:77] Creating layer relu4_3
I0911 23:21:07.508486 24730 net.cpp:100] Creating Layer relu4_3
I0911 23:21:07.508491 24730 net.cpp:434] relu4_3 <- conv4_3
I0911 23:21:07.508494 24730 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0911 23:21:07.508719 24730 net.cpp:150] Setting up relu4_3
I0911 23:21:07.508729 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:07.508734 24730 net.cpp:165] Memory required for data: 3104870400
I0911 23:21:07.508738 24730 layer_factory.hpp:77] Creating layer pool4
I0911 23:21:07.508744 24730 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0911 23:21:07.508751 24730 net.cpp:100] Creating Layer pool4
I0911 23:21:07.508756 24730 net.cpp:434] pool4 <- conv4_3
I0911 23:21:07.508782 24730 net.cpp:408] pool4 -> pool4
I0911 23:21:07.508791 24730 net.cpp:408] pool4 -> pool4_mask
I0911 23:21:07.508849 24730 net.cpp:150] Setting up pool4
I0911 23:21:07.508857 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.508862 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.508867 24730 net.cpp:165] Memory required for data: 3116175360
I0911 23:21:07.508869 24730 layer_factory.hpp:77] Creating layer conv5_1
I0911 23:21:07.508886 24730 net.cpp:100] Creating Layer conv5_1
I0911 23:21:07.508891 24730 net.cpp:434] conv5_1 <- pool4
I0911 23:21:07.508898 24730 net.cpp:408] conv5_1 -> conv5_1
I0911 23:21:07.596860 24730 net.cpp:150] Setting up conv5_1
I0911 23:21:07.596877 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.596881 24730 net.cpp:165] Memory required for data: 3121827840
I0911 23:21:07.596890 24730 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0911 23:21:07.596902 24730 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0911 23:21:07.596911 24730 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0911 23:21:07.596917 24730 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0911 23:21:07.597210 24730 net.cpp:150] Setting up conv5_1_bn_tmp
I0911 23:21:07.597219 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.597223 24730 net.cpp:165] Memory required for data: 3127480320
I0911 23:21:07.597230 24730 layer_factory.hpp:77] Creating layer conv5_1_scale
I0911 23:21:07.597237 24730 net.cpp:100] Creating Layer conv5_1_scale
I0911 23:21:07.597245 24730 net.cpp:434] conv5_1_scale <- conv5_1
I0911 23:21:07.597250 24730 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0911 23:21:07.597316 24730 layer_factory.hpp:77] Creating layer conv5_1_scale
I0911 23:21:07.597491 24730 net.cpp:150] Setting up conv5_1_scale
I0911 23:21:07.597501 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.597503 24730 net.cpp:165] Memory required for data: 3133132800
I0911 23:21:07.597510 24730 layer_factory.hpp:77] Creating layer relu5_1
I0911 23:21:07.597523 24730 net.cpp:100] Creating Layer relu5_1
I0911 23:21:07.597528 24730 net.cpp:434] relu5_1 <- conv5_1
I0911 23:21:07.597532 24730 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0911 23:21:07.597754 24730 net.cpp:150] Setting up relu5_1
I0911 23:21:07.597764 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.597769 24730 net.cpp:165] Memory required for data: 3138785280
I0911 23:21:07.597772 24730 layer_factory.hpp:77] Creating layer conv5_2
I0911 23:21:07.597786 24730 net.cpp:100] Creating Layer conv5_2
I0911 23:21:07.597791 24730 net.cpp:434] conv5_2 <- conv5_1
I0911 23:21:07.597801 24730 net.cpp:408] conv5_2 -> conv5_2
I0911 23:21:07.685875 24730 net.cpp:150] Setting up conv5_2
I0911 23:21:07.685894 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.685897 24730 net.cpp:165] Memory required for data: 3144437760
I0911 23:21:07.685906 24730 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0911 23:21:07.685916 24730 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0911 23:21:07.685921 24730 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0911 23:21:07.685927 24730 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0911 23:21:07.686197 24730 net.cpp:150] Setting up conv5_2_bn_tmp
I0911 23:21:07.686208 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.686210 24730 net.cpp:165] Memory required for data: 3150090240
I0911 23:21:07.686218 24730 layer_factory.hpp:77] Creating layer conv5_2_scale
I0911 23:21:07.686228 24730 net.cpp:100] Creating Layer conv5_2_scale
I0911 23:21:07.686236 24730 net.cpp:434] conv5_2_scale <- conv5_2
I0911 23:21:07.686241 24730 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0911 23:21:07.686305 24730 layer_factory.hpp:77] Creating layer conv5_2_scale
I0911 23:21:07.686458 24730 net.cpp:150] Setting up conv5_2_scale
I0911 23:21:07.686466 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.686470 24730 net.cpp:165] Memory required for data: 3155742720
I0911 23:21:07.686476 24730 layer_factory.hpp:77] Creating layer relu5_2
I0911 23:21:07.686502 24730 net.cpp:100] Creating Layer relu5_2
I0911 23:21:07.686507 24730 net.cpp:434] relu5_2 <- conv5_2
I0911 23:21:07.686512 24730 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0911 23:21:07.686736 24730 net.cpp:150] Setting up relu5_2
I0911 23:21:07.686749 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.686753 24730 net.cpp:165] Memory required for data: 3161395200
I0911 23:21:07.686758 24730 layer_factory.hpp:77] Creating layer conv5_3
I0911 23:21:07.686774 24730 net.cpp:100] Creating Layer conv5_3
I0911 23:21:07.686779 24730 net.cpp:434] conv5_3 <- conv5_2
I0911 23:21:07.686785 24730 net.cpp:408] conv5_3 -> conv5_3
I0911 23:21:07.774828 24730 net.cpp:150] Setting up conv5_3
I0911 23:21:07.774845 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.774849 24730 net.cpp:165] Memory required for data: 3167047680
I0911 23:21:07.774857 24730 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0911 23:21:07.774868 24730 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0911 23:21:07.774873 24730 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0911 23:21:07.774878 24730 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0911 23:21:07.775152 24730 net.cpp:150] Setting up conv5_3_bn_tmp
I0911 23:21:07.775161 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.775164 24730 net.cpp:165] Memory required for data: 3172700160
I0911 23:21:07.775172 24730 layer_factory.hpp:77] Creating layer conv5_3_scale
I0911 23:21:07.775182 24730 net.cpp:100] Creating Layer conv5_3_scale
I0911 23:21:07.775192 24730 net.cpp:434] conv5_3_scale <- conv5_3
I0911 23:21:07.775199 24730 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0911 23:21:07.775257 24730 layer_factory.hpp:77] Creating layer conv5_3_scale
I0911 23:21:07.775416 24730 net.cpp:150] Setting up conv5_3_scale
I0911 23:21:07.775424 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.775427 24730 net.cpp:165] Memory required for data: 3178352640
I0911 23:21:07.775434 24730 layer_factory.hpp:77] Creating layer relu5_3
I0911 23:21:07.775440 24730 net.cpp:100] Creating Layer relu5_3
I0911 23:21:07.775445 24730 net.cpp:434] relu5_3 <- conv5_3
I0911 23:21:07.775450 24730 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0911 23:21:07.775681 24730 net.cpp:150] Setting up relu5_3
I0911 23:21:07.775691 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.775696 24730 net.cpp:165] Memory required for data: 3184005120
I0911 23:21:07.775699 24730 layer_factory.hpp:77] Creating layer pool5
I0911 23:21:07.775703 24730 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0911 23:21:07.775712 24730 net.cpp:100] Creating Layer pool5
I0911 23:21:07.775717 24730 net.cpp:434] pool5 <- conv5_3
I0911 23:21:07.775725 24730 net.cpp:408] pool5 -> pool5
I0911 23:21:07.775734 24730 net.cpp:408] pool5 -> pool5_mask
I0911 23:21:07.775794 24730 net.cpp:150] Setting up pool5
I0911 23:21:07.775801 24730 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0911 23:21:07.775805 24730 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0911 23:21:07.775809 24730 net.cpp:165] Memory required for data: 3186954240
I0911 23:21:07.775813 24730 layer_factory.hpp:77] Creating layer upsample5
I0911 23:21:07.775825 24730 net.cpp:100] Creating Layer upsample5
I0911 23:21:07.775830 24730 net.cpp:434] upsample5 <- pool5
I0911 23:21:07.775835 24730 net.cpp:434] upsample5 <- pool5_mask
I0911 23:21:07.775840 24730 net.cpp:408] upsample5 -> pool5_D
I0911 23:21:07.775873 24730 net.cpp:150] Setting up upsample5
I0911 23:21:07.775882 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.775884 24730 net.cpp:165] Memory required for data: 3192606720
I0911 23:21:07.775887 24730 layer_factory.hpp:77] Creating layer conv5_3_D
I0911 23:21:07.775902 24730 net.cpp:100] Creating Layer conv5_3_D
I0911 23:21:07.775907 24730 net.cpp:434] conv5_3_D <- pool5_D
I0911 23:21:07.775915 24730 net.cpp:408] conv5_3_D -> conv5_3_D
I0911 23:21:07.863844 24730 net.cpp:150] Setting up conv5_3_D
I0911 23:21:07.863862 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.863883 24730 net.cpp:165] Memory required for data: 3198259200
I0911 23:21:07.863893 24730 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0911 23:21:07.863904 24730 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0911 23:21:07.863910 24730 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0911 23:21:07.863916 24730 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0911 23:21:07.864202 24730 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0911 23:21:07.864210 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.864214 24730 net.cpp:165] Memory required for data: 3203911680
I0911 23:21:07.864223 24730 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0911 23:21:07.864229 24730 net.cpp:100] Creating Layer conv5_3_D_scale
I0911 23:21:07.864238 24730 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0911 23:21:07.864243 24730 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0911 23:21:07.864310 24730 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0911 23:21:07.864467 24730 net.cpp:150] Setting up conv5_3_D_scale
I0911 23:21:07.864475 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.864478 24730 net.cpp:165] Memory required for data: 3209564160
I0911 23:21:07.864486 24730 layer_factory.hpp:77] Creating layer relu5_3_D
I0911 23:21:07.864496 24730 net.cpp:100] Creating Layer relu5_3_D
I0911 23:21:07.864501 24730 net.cpp:434] relu5_3_D <- conv5_3_D
I0911 23:21:07.864506 24730 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0911 23:21:07.865680 24730 net.cpp:150] Setting up relu5_3_D
I0911 23:21:07.865695 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.865700 24730 net.cpp:165] Memory required for data: 3215216640
I0911 23:21:07.865705 24730 layer_factory.hpp:77] Creating layer conv5_2_D
I0911 23:21:07.865734 24730 net.cpp:100] Creating Layer conv5_2_D
I0911 23:21:07.865741 24730 net.cpp:434] conv5_2_D <- conv5_3_D
I0911 23:21:07.865747 24730 net.cpp:408] conv5_2_D -> conv5_2_D
I0911 23:21:07.953549 24730 net.cpp:150] Setting up conv5_2_D
I0911 23:21:07.953569 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.953577 24730 net.cpp:165] Memory required for data: 3220869120
I0911 23:21:07.953586 24730 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0911 23:21:07.953593 24730 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0911 23:21:07.953598 24730 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0911 23:21:07.953610 24730 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0911 23:21:07.953896 24730 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0911 23:21:07.953905 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.953909 24730 net.cpp:165] Memory required for data: 3226521600
I0911 23:21:07.953917 24730 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0911 23:21:07.953925 24730 net.cpp:100] Creating Layer conv5_2_D_scale
I0911 23:21:07.953934 24730 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0911 23:21:07.953939 24730 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0911 23:21:07.954004 24730 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0911 23:21:07.954167 24730 net.cpp:150] Setting up conv5_2_D_scale
I0911 23:21:07.954176 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.954180 24730 net.cpp:165] Memory required for data: 3232174080
I0911 23:21:07.954188 24730 layer_factory.hpp:77] Creating layer relu5_2_D
I0911 23:21:07.954196 24730 net.cpp:100] Creating Layer relu5_2_D
I0911 23:21:07.954201 24730 net.cpp:434] relu5_2_D <- conv5_2_D
I0911 23:21:07.954208 24730 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0911 23:21:07.955368 24730 net.cpp:150] Setting up relu5_2_D
I0911 23:21:07.955382 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:07.955387 24730 net.cpp:165] Memory required for data: 3237826560
I0911 23:21:07.955391 24730 layer_factory.hpp:77] Creating layer conv5_1_D
I0911 23:21:07.955404 24730 net.cpp:100] Creating Layer conv5_1_D
I0911 23:21:07.955410 24730 net.cpp:434] conv5_1_D <- conv5_2_D
I0911 23:21:07.955420 24730 net.cpp:408] conv5_1_D -> conv5_1_D
I0911 23:21:08.043097 24730 net.cpp:150] Setting up conv5_1_D
I0911 23:21:08.043114 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:08.043119 24730 net.cpp:165] Memory required for data: 3243479040
I0911 23:21:08.043128 24730 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0911 23:21:08.043138 24730 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0911 23:21:08.043143 24730 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0911 23:21:08.043148 24730 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0911 23:21:08.043427 24730 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0911 23:21:08.043437 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:08.043440 24730 net.cpp:165] Memory required for data: 3249131520
I0911 23:21:08.043452 24730 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0911 23:21:08.043460 24730 net.cpp:100] Creating Layer conv5_1_D_scale
I0911 23:21:08.043469 24730 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0911 23:21:08.043474 24730 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0911 23:21:08.043536 24730 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0911 23:21:08.043696 24730 net.cpp:150] Setting up conv5_1_D_scale
I0911 23:21:08.043704 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:08.043709 24730 net.cpp:165] Memory required for data: 3254784000
I0911 23:21:08.043715 24730 layer_factory.hpp:77] Creating layer relu5_1_D
I0911 23:21:08.043723 24730 net.cpp:100] Creating Layer relu5_1_D
I0911 23:21:08.043728 24730 net.cpp:434] relu5_1_D <- conv5_1_D
I0911 23:21:08.043733 24730 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0911 23:21:08.043957 24730 net.cpp:150] Setting up relu5_1_D
I0911 23:21:08.043967 24730 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0911 23:21:08.043972 24730 net.cpp:165] Memory required for data: 3260436480
I0911 23:21:08.043975 24730 layer_factory.hpp:77] Creating layer upsample4
I0911 23:21:08.043985 24730 net.cpp:100] Creating Layer upsample4
I0911 23:21:08.043990 24730 net.cpp:434] upsample4 <- conv5_1_D
I0911 23:21:08.043997 24730 net.cpp:434] upsample4 <- pool4_mask
I0911 23:21:08.044005 24730 net.cpp:408] upsample4 -> pool4_D
I0911 23:21:08.044044 24730 net.cpp:150] Setting up upsample4
I0911 23:21:08.044051 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:08.044054 24730 net.cpp:165] Memory required for data: 3282554880
I0911 23:21:08.044057 24730 layer_factory.hpp:77] Creating layer conv4_3_D
I0911 23:21:08.044076 24730 net.cpp:100] Creating Layer conv4_3_D
I0911 23:21:08.044081 24730 net.cpp:434] conv4_3_D <- pool4_D
I0911 23:21:08.044087 24730 net.cpp:408] conv4_3_D -> conv4_3_D
I0911 23:21:08.131732 24730 net.cpp:150] Setting up conv4_3_D
I0911 23:21:08.131750 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:08.131760 24730 net.cpp:165] Memory required for data: 3304673280
I0911 23:21:08.131768 24730 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0911 23:21:08.131783 24730 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0911 23:21:08.131789 24730 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0911 23:21:08.131795 24730 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0911 23:21:08.132086 24730 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0911 23:21:08.132094 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:08.132098 24730 net.cpp:165] Memory required for data: 3326791680
I0911 23:21:08.132107 24730 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0911 23:21:08.132120 24730 net.cpp:100] Creating Layer conv4_3_D_scale
I0911 23:21:08.132125 24730 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0911 23:21:08.132133 24730 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0911 23:21:08.132185 24730 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0911 23:21:08.132359 24730 net.cpp:150] Setting up conv4_3_D_scale
I0911 23:21:08.132369 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:08.132375 24730 net.cpp:165] Memory required for data: 3348910080
I0911 23:21:08.132380 24730 layer_factory.hpp:77] Creating layer relu4_3_D
I0911 23:21:08.132405 24730 net.cpp:100] Creating Layer relu4_3_D
I0911 23:21:08.132411 24730 net.cpp:434] relu4_3_D <- conv4_3_D
I0911 23:21:08.132416 24730 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0911 23:21:08.132647 24730 net.cpp:150] Setting up relu4_3_D
I0911 23:21:08.132657 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:08.132661 24730 net.cpp:165] Memory required for data: 3371028480
I0911 23:21:08.132665 24730 layer_factory.hpp:77] Creating layer conv4_2_D
I0911 23:21:08.132678 24730 net.cpp:100] Creating Layer conv4_2_D
I0911 23:21:08.132683 24730 net.cpp:434] conv4_2_D <- conv4_3_D
I0911 23:21:08.132690 24730 net.cpp:408] conv4_2_D -> conv4_2_D
I0911 23:21:08.221210 24730 net.cpp:150] Setting up conv4_2_D
I0911 23:21:08.221231 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:08.221236 24730 net.cpp:165] Memory required for data: 3393146880
I0911 23:21:08.221249 24730 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0911 23:21:08.221268 24730 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0911 23:21:08.221279 24730 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0911 23:21:08.221292 24730 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0911 23:21:08.221606 24730 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0911 23:21:08.221616 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:08.221619 24730 net.cpp:165] Memory required for data: 3415265280
I0911 23:21:08.221628 24730 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0911 23:21:08.221645 24730 net.cpp:100] Creating Layer conv4_2_D_scale
I0911 23:21:08.221652 24730 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0911 23:21:08.221657 24730 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0911 23:21:08.221709 24730 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0911 23:21:08.221885 24730 net.cpp:150] Setting up conv4_2_D_scale
I0911 23:21:08.221894 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:08.221897 24730 net.cpp:165] Memory required for data: 3437383680
I0911 23:21:08.221904 24730 layer_factory.hpp:77] Creating layer relu4_2_D
I0911 23:21:08.221911 24730 net.cpp:100] Creating Layer relu4_2_D
I0911 23:21:08.221916 24730 net.cpp:434] relu4_2_D <- conv4_2_D
I0911 23:21:08.221921 24730 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0911 23:21:08.222149 24730 net.cpp:150] Setting up relu4_2_D
I0911 23:21:08.222158 24730 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0911 23:21:08.222163 24730 net.cpp:165] Memory required for data: 3459502080
I0911 23:21:08.222167 24730 layer_factory.hpp:77] Creating layer conv4_1_D
I0911 23:21:08.222180 24730 net.cpp:100] Creating Layer conv4_1_D
I0911 23:21:08.222185 24730 net.cpp:434] conv4_1_D <- conv4_2_D
I0911 23:21:08.222195 24730 net.cpp:408] conv4_1_D -> conv4_1_D
I0911 23:21:08.268157 24730 net.cpp:150] Setting up conv4_1_D
I0911 23:21:08.268172 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:08.268183 24730 net.cpp:165] Memory required for data: 3470561280
I0911 23:21:08.268193 24730 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0911 23:21:08.268205 24730 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0911 23:21:08.268211 24730 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0911 23:21:08.268218 24730 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0911 23:21:08.268518 24730 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0911 23:21:08.268527 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:08.268530 24730 net.cpp:165] Memory required for data: 3481620480
I0911 23:21:08.268623 24730 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0911 23:21:08.268635 24730 net.cpp:100] Creating Layer conv4_1_D_scale
I0911 23:21:08.268641 24730 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0911 23:21:08.268646 24730 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0911 23:21:08.268708 24730 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0911 23:21:08.268885 24730 net.cpp:150] Setting up conv4_1_D_scale
I0911 23:21:08.268894 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:08.268914 24730 net.cpp:165] Memory required for data: 3492679680
I0911 23:21:08.268921 24730 layer_factory.hpp:77] Creating layer relu4_1_D
I0911 23:21:08.268928 24730 net.cpp:100] Creating Layer relu4_1_D
I0911 23:21:08.268932 24730 net.cpp:434] relu4_1_D <- conv4_1_D
I0911 23:21:08.268937 24730 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0911 23:21:08.269176 24730 net.cpp:150] Setting up relu4_1_D
I0911 23:21:08.269186 24730 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0911 23:21:08.269191 24730 net.cpp:165] Memory required for data: 3503738880
I0911 23:21:08.269196 24730 layer_factory.hpp:77] Creating layer upsample3
I0911 23:21:08.269207 24730 net.cpp:100] Creating Layer upsample3
I0911 23:21:08.269212 24730 net.cpp:434] upsample3 <- conv4_1_D
I0911 23:21:08.269217 24730 net.cpp:434] upsample3 <- pool3_mask
I0911 23:21:08.269224 24730 net.cpp:408] upsample3 -> pool3_D
I0911 23:21:08.269233 24730 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0911 23:21:08.269271 24730 net.cpp:150] Setting up upsample3
I0911 23:21:08.269279 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:08.269282 24730 net.cpp:165] Memory required for data: 3547975680
I0911 23:21:08.269287 24730 layer_factory.hpp:77] Creating layer conv3_3_D
I0911 23:21:08.269299 24730 net.cpp:100] Creating Layer conv3_3_D
I0911 23:21:08.269304 24730 net.cpp:434] conv3_3_D <- pool3_D
I0911 23:21:08.269316 24730 net.cpp:408] conv3_3_D -> conv3_3_D
I0911 23:21:08.294090 24730 net.cpp:150] Setting up conv3_3_D
I0911 23:21:08.294106 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:08.294116 24730 net.cpp:165] Memory required for data: 3592212480
I0911 23:21:08.294122 24730 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0911 23:21:08.294137 24730 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0911 23:21:08.294143 24730 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0911 23:21:08.294149 24730 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0911 23:21:08.294456 24730 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0911 23:21:08.294464 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:08.294468 24730 net.cpp:165] Memory required for data: 3636449280
I0911 23:21:08.294476 24730 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0911 23:21:08.294487 24730 net.cpp:100] Creating Layer conv3_3_D_scale
I0911 23:21:08.294493 24730 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0911 23:21:08.294498 24730 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0911 23:21:08.294558 24730 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0911 23:21:08.294751 24730 net.cpp:150] Setting up conv3_3_D_scale
I0911 23:21:08.294759 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:08.294762 24730 net.cpp:165] Memory required for data: 3680686080
I0911 23:21:08.294770 24730 layer_factory.hpp:77] Creating layer relu3_3_D
I0911 23:21:08.294776 24730 net.cpp:100] Creating Layer relu3_3_D
I0911 23:21:08.294781 24730 net.cpp:434] relu3_3_D <- conv3_3_D
I0911 23:21:08.294788 24730 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0911 23:21:08.295971 24730 net.cpp:150] Setting up relu3_3_D
I0911 23:21:08.295986 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:08.295991 24730 net.cpp:165] Memory required for data: 3724922880
I0911 23:21:08.295997 24730 layer_factory.hpp:77] Creating layer conv3_2_D
I0911 23:21:08.296013 24730 net.cpp:100] Creating Layer conv3_2_D
I0911 23:21:08.296018 24730 net.cpp:434] conv3_2_D <- conv3_3_D
I0911 23:21:08.296028 24730 net.cpp:408] conv3_2_D -> conv3_2_D
I0911 23:21:08.319813 24730 net.cpp:150] Setting up conv3_2_D
I0911 23:21:08.319829 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:08.319839 24730 net.cpp:165] Memory required for data: 3769159680
I0911 23:21:08.319847 24730 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0911 23:21:08.319859 24730 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0911 23:21:08.319869 24730 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0911 23:21:08.319890 24730 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0911 23:21:08.320207 24730 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0911 23:21:08.320216 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:08.320219 24730 net.cpp:165] Memory required for data: 3813396480
I0911 23:21:08.320227 24730 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0911 23:21:08.320237 24730 net.cpp:100] Creating Layer conv3_2_D_scale
I0911 23:21:08.320242 24730 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0911 23:21:08.320250 24730 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0911 23:21:08.320305 24730 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0911 23:21:08.320497 24730 net.cpp:150] Setting up conv3_2_D_scale
I0911 23:21:08.320508 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:08.320511 24730 net.cpp:165] Memory required for data: 3857633280
I0911 23:21:08.320518 24730 layer_factory.hpp:77] Creating layer relu3_2_D
I0911 23:21:08.320526 24730 net.cpp:100] Creating Layer relu3_2_D
I0911 23:21:08.320531 24730 net.cpp:434] relu3_2_D <- conv3_2_D
I0911 23:21:08.320535 24730 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0911 23:21:08.321724 24730 net.cpp:150] Setting up relu3_2_D
I0911 23:21:08.321739 24730 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0911 23:21:08.321744 24730 net.cpp:165] Memory required for data: 3901870080
I0911 23:21:08.321750 24730 layer_factory.hpp:77] Creating layer conv3_1_D
I0911 23:21:08.321768 24730 net.cpp:100] Creating Layer conv3_1_D
I0911 23:21:08.321774 24730 net.cpp:434] conv3_1_D <- conv3_2_D
I0911 23:21:08.321782 24730 net.cpp:408] conv3_1_D -> conv3_1_D
I0911 23:21:08.336380 24730 net.cpp:150] Setting up conv3_1_D
I0911 23:21:08.336397 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:08.336408 24730 net.cpp:165] Memory required for data: 3923988480
I0911 23:21:08.336419 24730 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0911 23:21:08.336431 24730 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0911 23:21:08.336439 24730 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0911 23:21:08.336444 24730 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0911 23:21:08.336751 24730 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0911 23:21:08.336761 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:08.336765 24730 net.cpp:165] Memory required for data: 3946106880
I0911 23:21:08.336772 24730 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0911 23:21:08.336784 24730 net.cpp:100] Creating Layer conv3_1_D_scale
I0911 23:21:08.336789 24730 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0911 23:21:08.336794 24730 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0911 23:21:08.336858 24730 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0911 23:21:08.338688 24730 net.cpp:150] Setting up conv3_1_D_scale
I0911 23:21:08.338703 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:08.338713 24730 net.cpp:165] Memory required for data: 3968225280
I0911 23:21:08.338724 24730 layer_factory.hpp:77] Creating layer relu3_1_D
I0911 23:21:08.338732 24730 net.cpp:100] Creating Layer relu3_1_D
I0911 23:21:08.338738 24730 net.cpp:434] relu3_1_D <- conv3_1_D
I0911 23:21:08.338747 24730 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0911 23:21:08.338994 24730 net.cpp:150] Setting up relu3_1_D
I0911 23:21:08.339004 24730 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0911 23:21:08.339007 24730 net.cpp:165] Memory required for data: 3990343680
I0911 23:21:08.339013 24730 layer_factory.hpp:77] Creating layer upsample2
I0911 23:21:08.339021 24730 net.cpp:100] Creating Layer upsample2
I0911 23:21:08.339026 24730 net.cpp:434] upsample2 <- conv3_1_D
I0911 23:21:08.339031 24730 net.cpp:434] upsample2 <- pool2_mask
I0911 23:21:08.339041 24730 net.cpp:408] upsample2 -> pool2_D
I0911 23:21:08.339051 24730 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0911 23:21:08.339088 24730 net.cpp:150] Setting up upsample2
I0911 23:21:08.339110 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:08.339115 24730 net.cpp:165] Memory required for data: 4078817280
I0911 23:21:08.339119 24730 layer_factory.hpp:77] Creating layer conv2_2_D
I0911 23:21:08.339136 24730 net.cpp:100] Creating Layer conv2_2_D
I0911 23:21:08.339143 24730 net.cpp:434] conv2_2_D <- pool2_D
I0911 23:21:08.339148 24730 net.cpp:408] conv2_2_D -> conv2_2_D
I0911 23:21:08.347268 24730 net.cpp:150] Setting up conv2_2_D
I0911 23:21:08.347285 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:08.347295 24730 net.cpp:165] Memory required for data: 4167290880
I0911 23:21:08.347306 24730 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0911 23:21:08.347321 24730 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0911 23:21:08.347328 24730 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0911 23:21:08.347334 24730 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0911 23:21:08.347698 24730 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0911 23:21:08.347707 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:08.347710 24730 net.cpp:165] Memory required for data: 4255764480
I0911 23:21:08.347718 24730 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0911 23:21:08.347728 24730 net.cpp:100] Creating Layer conv2_2_D_scale
I0911 23:21:08.347733 24730 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0911 23:21:08.347738 24730 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0911 23:21:08.347800 24730 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0911 23:21:08.348074 24730 net.cpp:150] Setting up conv2_2_D_scale
I0911 23:21:08.348083 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:08.348086 24730 net.cpp:165] Memory required for data: 4344238080
I0911 23:21:08.348093 24730 layer_factory.hpp:77] Creating layer relu2_2_D
I0911 23:21:08.348105 24730 net.cpp:100] Creating Layer relu2_2_D
I0911 23:21:08.348111 24730 net.cpp:434] relu2_2_D <- conv2_2_D
I0911 23:21:08.348119 24730 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0911 23:21:08.348356 24730 net.cpp:150] Setting up relu2_2_D
I0911 23:21:08.348366 24730 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0911 23:21:08.348371 24730 net.cpp:165] Memory required for data: 4432711680
I0911 23:21:08.348374 24730 layer_factory.hpp:77] Creating layer conv2_1_D
I0911 23:21:08.348388 24730 net.cpp:100] Creating Layer conv2_1_D
I0911 23:21:08.348394 24730 net.cpp:434] conv2_1_D <- conv2_2_D
I0911 23:21:08.348405 24730 net.cpp:408] conv2_1_D -> conv2_1_D
I0911 23:21:08.354012 24730 net.cpp:150] Setting up conv2_1_D
I0911 23:21:08.354028 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:08.354038 24730 net.cpp:165] Memory required for data: 4476948480
I0911 23:21:08.354046 24730 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0911 23:21:08.354058 24730 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0911 23:21:08.354068 24730 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0911 23:21:08.354074 24730 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0911 23:21:08.354444 24730 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0911 23:21:08.354454 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:08.354456 24730 net.cpp:165] Memory required for data: 4521185280
I0911 23:21:08.354465 24730 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0911 23:21:08.354481 24730 net.cpp:100] Creating Layer conv2_1_D_scale
I0911 23:21:08.354486 24730 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0911 23:21:08.354491 24730 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0911 23:21:08.354552 24730 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0911 23:21:08.354841 24730 net.cpp:150] Setting up conv2_1_D_scale
I0911 23:21:08.354851 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:08.354854 24730 net.cpp:165] Memory required for data: 4565422080
I0911 23:21:08.354861 24730 layer_factory.hpp:77] Creating layer relu2_1_D
I0911 23:21:08.354871 24730 net.cpp:100] Creating Layer relu2_1_D
I0911 23:21:08.354876 24730 net.cpp:434] relu2_1_D <- conv2_1_D
I0911 23:21:08.354900 24730 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0911 23:21:08.355140 24730 net.cpp:150] Setting up relu2_1_D
I0911 23:21:08.355150 24730 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0911 23:21:08.355155 24730 net.cpp:165] Memory required for data: 4609658880
I0911 23:21:08.355159 24730 layer_factory.hpp:77] Creating layer upsample1
I0911 23:21:08.355165 24730 net.cpp:100] Creating Layer upsample1
I0911 23:21:08.355170 24730 net.cpp:434] upsample1 <- conv2_1_D
I0911 23:21:08.355177 24730 net.cpp:434] upsample1 <- pool1_mask
I0911 23:21:08.355186 24730 net.cpp:408] upsample1 -> pool1_D
I0911 23:21:08.355195 24730 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0911 23:21:08.355232 24730 net.cpp:150] Setting up upsample1
I0911 23:21:08.355239 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:08.355242 24730 net.cpp:165] Memory required for data: 4786606080
I0911 23:21:08.355247 24730 layer_factory.hpp:77] Creating layer conv1_2_D
I0911 23:21:08.355262 24730 net.cpp:100] Creating Layer conv1_2_D
I0911 23:21:08.355267 24730 net.cpp:434] conv1_2_D <- pool1_D
I0911 23:21:08.355273 24730 net.cpp:408] conv1_2_D -> conv1_2_D
I0911 23:21:08.360395 24730 net.cpp:150] Setting up conv1_2_D
I0911 23:21:08.360412 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:08.360422 24730 net.cpp:165] Memory required for data: 4963553280
I0911 23:21:08.360430 24730 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0911 23:21:08.360443 24730 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0911 23:21:08.360450 24730 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0911 23:21:08.360455 24730 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0911 23:21:08.360898 24730 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0911 23:21:08.360908 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:08.360913 24730 net.cpp:165] Memory required for data: 5140500480
I0911 23:21:08.360921 24730 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0911 23:21:08.360931 24730 net.cpp:100] Creating Layer conv1_2_D_scale
I0911 23:21:08.360936 24730 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0911 23:21:08.360944 24730 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0911 23:21:08.361002 24730 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0911 23:21:08.363126 24730 net.cpp:150] Setting up conv1_2_D_scale
I0911 23:21:08.363142 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:08.363147 24730 net.cpp:165] Memory required for data: 5317447680
I0911 23:21:08.363158 24730 layer_factory.hpp:77] Creating layer relu1_2_D
I0911 23:21:08.363168 24730 net.cpp:100] Creating Layer relu1_2_D
I0911 23:21:08.363173 24730 net.cpp:434] relu1_2_D <- conv1_2_D
I0911 23:21:08.363181 24730 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0911 23:21:08.363433 24730 net.cpp:150] Setting up relu1_2_D
I0911 23:21:08.363443 24730 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0911 23:21:08.363447 24730 net.cpp:165] Memory required for data: 5494394880
I0911 23:21:08.363451 24730 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0911 23:21:08.363466 24730 net.cpp:100] Creating Layer conv1_1_1_D
I0911 23:21:08.363471 24730 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0911 23:21:08.363479 24730 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0911 23:21:08.365739 24730 net.cpp:150] Setting up conv1_1_1_D
I0911 23:21:08.365756 24730 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0911 23:21:08.365761 24730 net.cpp:165] Memory required for data: 5499924480
I0911 23:21:08.365768 24730 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0911 23:21:08.365777 24730 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0911 23:21:08.365782 24730 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0911 23:21:08.365792 24730 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0911 23:21:08.365802 24730 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0911 23:21:08.365877 24730 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0911 23:21:08.365887 24730 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0911 23:21:08.365893 24730 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0911 23:21:08.365896 24730 net.cpp:165] Memory required for data: 5510983680
I0911 23:21:08.365901 24730 layer_factory.hpp:77] Creating layer loss
I0911 23:21:08.365912 24730 net.cpp:100] Creating Layer loss
I0911 23:21:08.365917 24730 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0911 23:21:08.365922 24730 net.cpp:434] loss <- label_data_1_split_0
I0911 23:21:08.365927 24730 net.cpp:408] loss -> loss
I0911 23:21:08.365938 24730 layer_factory.hpp:77] Creating layer loss
I0911 23:21:08.370947 24730 net.cpp:150] Setting up loss
I0911 23:21:08.370962 24730 net.cpp:157] Top shape: (1)
I0911 23:21:08.370972 24730 net.cpp:160]     with loss weight 1
I0911 23:21:08.370987 24730 net.cpp:165] Memory required for data: 5510983684
I0911 23:21:08.370992 24730 layer_factory.hpp:77] Creating layer accuracy
I0911 23:21:08.371001 24730 net.cpp:100] Creating Layer accuracy
I0911 23:21:08.371009 24730 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0911 23:21:08.371014 24730 net.cpp:434] accuracy <- label_data_1_split_1
I0911 23:21:08.371021 24730 net.cpp:408] accuracy -> accuracy
I0911 23:21:08.371028 24730 net.cpp:408] accuracy -> per_class_accuracy
I0911 23:21:08.371088 24730 net.cpp:150] Setting up accuracy
I0911 23:21:08.371095 24730 net.cpp:157] Top shape: (1)
I0911 23:21:08.371099 24730 net.cpp:157] Top shape: 2 (2)
I0911 23:21:08.371104 24730 net.cpp:165] Memory required for data: 5510983696
I0911 23:21:08.371107 24730 net.cpp:228] accuracy does not need backward computation.
I0911 23:21:08.371114 24730 net.cpp:226] loss needs backward computation.
I0911 23:21:08.371117 24730 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0911 23:21:08.371120 24730 net.cpp:226] conv1_1_1_D needs backward computation.
I0911 23:21:08.371124 24730 net.cpp:226] relu1_2_D needs backward computation.
I0911 23:21:08.371127 24730 net.cpp:226] conv1_2_D_scale needs backward computation.
I0911 23:21:08.371130 24730 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0911 23:21:08.371134 24730 net.cpp:226] conv1_2_D needs backward computation.
I0911 23:21:08.371136 24730 net.cpp:226] upsample1 needs backward computation.
I0911 23:21:08.371140 24730 net.cpp:226] relu2_1_D needs backward computation.
I0911 23:21:08.371143 24730 net.cpp:226] conv2_1_D_scale needs backward computation.
I0911 23:21:08.371145 24730 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0911 23:21:08.371148 24730 net.cpp:226] conv2_1_D needs backward computation.
I0911 23:21:08.371152 24730 net.cpp:226] relu2_2_D needs backward computation.
I0911 23:21:08.371155 24730 net.cpp:226] conv2_2_D_scale needs backward computation.
I0911 23:21:08.371158 24730 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0911 23:21:08.371161 24730 net.cpp:226] conv2_2_D needs backward computation.
I0911 23:21:08.371165 24730 net.cpp:226] upsample2 needs backward computation.
I0911 23:21:08.371168 24730 net.cpp:226] relu3_1_D needs backward computation.
I0911 23:21:08.371172 24730 net.cpp:226] conv3_1_D_scale needs backward computation.
I0911 23:21:08.371176 24730 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0911 23:21:08.371178 24730 net.cpp:226] conv3_1_D needs backward computation.
I0911 23:21:08.371181 24730 net.cpp:226] relu3_2_D needs backward computation.
I0911 23:21:08.371184 24730 net.cpp:226] conv3_2_D_scale needs backward computation.
I0911 23:21:08.371187 24730 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0911 23:21:08.371191 24730 net.cpp:226] conv3_2_D needs backward computation.
I0911 23:21:08.371193 24730 net.cpp:226] relu3_3_D needs backward computation.
I0911 23:21:08.371196 24730 net.cpp:226] conv3_3_D_scale needs backward computation.
I0911 23:21:08.371199 24730 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0911 23:21:08.371217 24730 net.cpp:226] conv3_3_D needs backward computation.
I0911 23:21:08.371222 24730 net.cpp:226] upsample3 needs backward computation.
I0911 23:21:08.371225 24730 net.cpp:226] relu4_1_D needs backward computation.
I0911 23:21:08.371228 24730 net.cpp:226] conv4_1_D_scale needs backward computation.
I0911 23:21:08.371232 24730 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0911 23:21:08.371234 24730 net.cpp:226] conv4_1_D needs backward computation.
I0911 23:21:08.371237 24730 net.cpp:226] relu4_2_D needs backward computation.
I0911 23:21:08.371240 24730 net.cpp:226] conv4_2_D_scale needs backward computation.
I0911 23:21:08.371244 24730 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0911 23:21:08.371248 24730 net.cpp:226] conv4_2_D needs backward computation.
I0911 23:21:08.371250 24730 net.cpp:226] relu4_3_D needs backward computation.
I0911 23:21:08.371254 24730 net.cpp:226] conv4_3_D_scale needs backward computation.
I0911 23:21:08.371258 24730 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0911 23:21:08.371263 24730 net.cpp:226] conv4_3_D needs backward computation.
I0911 23:21:08.371268 24730 net.cpp:226] upsample4 needs backward computation.
I0911 23:21:08.371275 24730 net.cpp:226] relu5_1_D needs backward computation.
I0911 23:21:08.371279 24730 net.cpp:226] conv5_1_D_scale needs backward computation.
I0911 23:21:08.371282 24730 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0911 23:21:08.371286 24730 net.cpp:226] conv5_1_D needs backward computation.
I0911 23:21:08.371290 24730 net.cpp:226] relu5_2_D needs backward computation.
I0911 23:21:08.371295 24730 net.cpp:226] conv5_2_D_scale needs backward computation.
I0911 23:21:08.371300 24730 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0911 23:21:08.371304 24730 net.cpp:226] conv5_2_D needs backward computation.
I0911 23:21:08.371309 24730 net.cpp:226] relu5_3_D needs backward computation.
I0911 23:21:08.371312 24730 net.cpp:226] conv5_3_D_scale needs backward computation.
I0911 23:21:08.371315 24730 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0911 23:21:08.371320 24730 net.cpp:226] conv5_3_D needs backward computation.
I0911 23:21:08.371325 24730 net.cpp:226] upsample5 needs backward computation.
I0911 23:21:08.371331 24730 net.cpp:226] pool5 needs backward computation.
I0911 23:21:08.371337 24730 net.cpp:226] relu5_3 needs backward computation.
I0911 23:21:08.371341 24730 net.cpp:226] conv5_3_scale needs backward computation.
I0911 23:21:08.371345 24730 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0911 23:21:08.371351 24730 net.cpp:226] conv5_3 needs backward computation.
I0911 23:21:08.371357 24730 net.cpp:226] relu5_2 needs backward computation.
I0911 23:21:08.371361 24730 net.cpp:226] conv5_2_scale needs backward computation.
I0911 23:21:08.371364 24730 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0911 23:21:08.371368 24730 net.cpp:226] conv5_2 needs backward computation.
I0911 23:21:08.371376 24730 net.cpp:226] relu5_1 needs backward computation.
I0911 23:21:08.371378 24730 net.cpp:226] conv5_1_scale needs backward computation.
I0911 23:21:08.371382 24730 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0911 23:21:08.371387 24730 net.cpp:226] conv5_1 needs backward computation.
I0911 23:21:08.371393 24730 net.cpp:226] pool4 needs backward computation.
I0911 23:21:08.371398 24730 net.cpp:226] relu4_3 needs backward computation.
I0911 23:21:08.371402 24730 net.cpp:226] conv4_3_scale needs backward computation.
I0911 23:21:08.371407 24730 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0911 23:21:08.371409 24730 net.cpp:226] conv4_3 needs backward computation.
I0911 23:21:08.371414 24730 net.cpp:226] relu4_2 needs backward computation.
I0911 23:21:08.371419 24730 net.cpp:226] conv4_2_scale needs backward computation.
I0911 23:21:08.371423 24730 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0911 23:21:08.371428 24730 net.cpp:226] conv4_2 needs backward computation.
I0911 23:21:08.371433 24730 net.cpp:226] relu4_1 needs backward computation.
I0911 23:21:08.371444 24730 net.cpp:226] conv4_1_scale needs backward computation.
I0911 23:21:08.371448 24730 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0911 23:21:08.371451 24730 net.cpp:226] conv4_1 needs backward computation.
I0911 23:21:08.371455 24730 net.cpp:226] pool3 needs backward computation.
I0911 23:21:08.371459 24730 net.cpp:226] relu3_3 needs backward computation.
I0911 23:21:08.371464 24730 net.cpp:226] conv3_3_scale needs backward computation.
I0911 23:21:08.371467 24730 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0911 23:21:08.371472 24730 net.cpp:226] conv3_3 needs backward computation.
I0911 23:21:08.371475 24730 net.cpp:226] relu3_2 needs backward computation.
I0911 23:21:08.371481 24730 net.cpp:226] conv3_2_scale needs backward computation.
I0911 23:21:08.371484 24730 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0911 23:21:08.371490 24730 net.cpp:226] conv3_2 needs backward computation.
I0911 23:21:08.371492 24730 net.cpp:226] relu3_1 needs backward computation.
I0911 23:21:08.371497 24730 net.cpp:226] conv3_1_scale needs backward computation.
I0911 23:21:08.371500 24730 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0911 23:21:08.371505 24730 net.cpp:226] conv3_1 needs backward computation.
I0911 23:21:08.371508 24730 net.cpp:226] pool2 needs backward computation.
I0911 23:21:08.371515 24730 net.cpp:226] relu2_2 needs backward computation.
I0911 23:21:08.371517 24730 net.cpp:226] conv2_2_scale needs backward computation.
I0911 23:21:08.371520 24730 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0911 23:21:08.371526 24730 net.cpp:226] conv2_2 needs backward computation.
I0911 23:21:08.371531 24730 net.cpp:226] relu2_1 needs backward computation.
I0911 23:21:08.371533 24730 net.cpp:226] conv2_1_scale needs backward computation.
I0911 23:21:08.371537 24730 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0911 23:21:08.371542 24730 net.cpp:226] conv2_1 needs backward computation.
I0911 23:21:08.371547 24730 net.cpp:226] pool1 needs backward computation.
I0911 23:21:08.371554 24730 net.cpp:226] relu1_2 needs backward computation.
I0911 23:21:08.371557 24730 net.cpp:226] conv1_2_scale needs backward computation.
I0911 23:21:08.371562 24730 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0911 23:21:08.371567 24730 net.cpp:226] conv1_2 needs backward computation.
I0911 23:21:08.371572 24730 net.cpp:226] relu1_1 needs backward computation.
I0911 23:21:08.371577 24730 net.cpp:226] conv1_1_1_scale needs backward computation.
I0911 23:21:08.371580 24730 net.cpp:226] conv1_1_1_bn needs backward computation.
I0911 23:21:08.371583 24730 net.cpp:226] conv1_1_1 needs backward computation.
I0911 23:21:08.371588 24730 net.cpp:228] label_data_1_split does not need backward computation.
I0911 23:21:08.371595 24730 net.cpp:228] data does not need backward computation.
I0911 23:21:08.371599 24730 net.cpp:270] This network produces output accuracy
I0911 23:21:08.371603 24730 net.cpp:270] This network produces output loss
I0911 23:21:08.371608 24730 net.cpp:270] This network produces output per_class_accuracy
I0911 23:21:08.371673 24730 net.cpp:283] Network initialization done.
I0911 23:21:08.372089 24730 solver.cpp:60] Solver scaffolding done.
I0911 23:21:08.381510 24730 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0911 23:21:08.638284 24730 net.cpp:761] Ignoring source layer conv1_1
I0911 23:21:08.638309 24730 net.cpp:761] Ignoring source layer conv1_1_bn
I0911 23:21:08.638370 24730 net.cpp:761] Ignoring source layer conv1_2_bn
I0911 23:21:08.638378 24730 net.cpp:761] Ignoring source layer pool1_drop
I0911 23:21:08.638471 24730 net.cpp:761] Ignoring source layer conv2_1_bn
I0911 23:21:08.638645 24730 net.cpp:761] Ignoring source layer conv2_2_bn
I0911 23:21:08.638653 24730 net.cpp:761] Ignoring source layer pool2_drop
I0911 23:21:08.638979 24730 net.cpp:761] Ignoring source layer conv3_1_bn
I0911 23:21:08.639621 24730 net.cpp:761] Ignoring source layer conv3_2_bn
I0911 23:21:08.640260 24730 net.cpp:761] Ignoring source layer conv3_3_bn
I0911 23:21:08.640292 24730 net.cpp:761] Ignoring source layer pool3_drop
I0911 23:21:08.641578 24730 net.cpp:761] Ignoring source layer conv4_1_bn
I0911 23:21:08.643965 24730 net.cpp:761] Ignoring source layer conv4_2_bn
I0911 23:21:08.646476 24730 net.cpp:761] Ignoring source layer conv4_3_bn
I0911 23:21:08.646486 24730 net.cpp:761] Ignoring source layer pool4_drop
I0911 23:21:08.648959 24730 net.cpp:761] Ignoring source layer conv5_1_bn
I0911 23:21:08.651458 24730 net.cpp:761] Ignoring source layer conv5_2_bn
I0911 23:21:08.653951 24730 net.cpp:761] Ignoring source layer conv5_3_bn
I0911 23:21:08.653960 24730 net.cpp:761] Ignoring source layer pool5_drop
I0911 23:21:08.653966 24730 net.cpp:761] Ignoring source layer upsample5_drop
I0911 23:21:08.656440 24730 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0911 23:21:08.658933 24730 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0911 23:21:08.661428 24730 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0911 23:21:08.661439 24730 net.cpp:761] Ignoring source layer upsample4_drop
I0911 23:21:08.663903 24730 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0911 23:21:08.666395 24730 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0911 23:21:08.667654 24730 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0911 23:21:08.667662 24730 net.cpp:761] Ignoring source layer upsample3_drop
I0911 23:21:08.668296 24730 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0911 23:21:08.668946 24730 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0911 23:21:08.669275 24730 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0911 23:21:08.669281 24730 net.cpp:761] Ignoring source layer upsample2_drop
I0911 23:21:08.669462 24730 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0911 23:21:08.669559 24730 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0911 23:21:08.669567 24730 net.cpp:761] Ignoring source layer upsample1_drop
I0911 23:21:08.669623 24730 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0911 23:21:08.669631 24730 net.cpp:761] Ignoring source layer conv1_1_D
I0911 23:21:08.669636 24730 net.cpp:761] Ignoring source layer prob
I0911 23:21:08.933120 24730 net.cpp:761] Ignoring source layer conv1_1
I0911 23:21:08.933143 24730 net.cpp:761] Ignoring source layer conv1_1_bn
I0911 23:21:08.933200 24730 net.cpp:761] Ignoring source layer conv1_2_bn
I0911 23:21:08.933207 24730 net.cpp:761] Ignoring source layer pool1_drop
I0911 23:21:08.933290 24730 net.cpp:761] Ignoring source layer conv2_1_bn
I0911 23:21:08.933475 24730 net.cpp:761] Ignoring source layer conv2_2_bn
I0911 23:21:08.933480 24730 net.cpp:761] Ignoring source layer pool2_drop
I0911 23:21:08.933773 24730 net.cpp:761] Ignoring source layer conv3_1_bn
I0911 23:21:08.934414 24730 net.cpp:761] Ignoring source layer conv3_2_bn
I0911 23:21:08.935060 24730 net.cpp:761] Ignoring source layer conv3_3_bn
I0911 23:21:08.935066 24730 net.cpp:761] Ignoring source layer pool3_drop
I0911 23:21:08.936339 24730 net.cpp:761] Ignoring source layer conv4_1_bn
I0911 23:21:08.938901 24730 net.cpp:761] Ignoring source layer conv4_2_bn
I0911 23:21:08.941265 24730 net.cpp:761] Ignoring source layer conv4_3_bn
I0911 23:21:08.941273 24730 net.cpp:761] Ignoring source layer pool4_drop
I0911 23:21:08.943840 24730 net.cpp:761] Ignoring source layer conv5_1_bn
I0911 23:21:08.946405 24730 net.cpp:761] Ignoring source layer conv5_2_bn
I0911 23:21:08.948920 24730 net.cpp:761] Ignoring source layer conv5_3_bn
I0911 23:21:08.948927 24730 net.cpp:761] Ignoring source layer pool5_drop
I0911 23:21:08.948932 24730 net.cpp:761] Ignoring source layer upsample5_drop
I0911 23:21:08.951480 24730 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0911 23:21:08.954028 24730 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0911 23:21:08.956567 24730 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0911 23:21:08.956574 24730 net.cpp:761] Ignoring source layer upsample4_drop
I0911 23:21:08.959123 24730 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0911 23:21:08.961661 24730 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0911 23:21:08.962970 24730 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0911 23:21:08.962977 24730 net.cpp:761] Ignoring source layer upsample3_drop
I0911 23:21:08.963618 24730 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0911 23:21:08.964260 24730 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0911 23:21:08.964589 24730 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0911 23:21:08.964596 24730 net.cpp:761] Ignoring source layer upsample2_drop
I0911 23:21:08.964768 24730 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0911 23:21:08.964861 24730 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0911 23:21:08.964869 24730 net.cpp:761] Ignoring source layer upsample1_drop
I0911 23:21:08.964920 24730 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0911 23:21:08.964927 24730 net.cpp:761] Ignoring source layer conv1_1_D
I0911 23:21:08.964931 24730 net.cpp:761] Ignoring source layer prob
I0911 23:21:08.975450 24730 caffe.cpp:251] Starting Optimization
I0911 23:21:08.975472 24730 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0911 23:21:08.975481 24730 solver.cpp:280] Learning Rate Policy: step
I0911 23:21:09.961619 24730 solver.cpp:228] Iteration 0, loss = 0.732119
I0911 23:21:09.961655 24730 solver.cpp:244]     Train net output #0: accuracy = 0.523384
I0911 23:21:09.961670 24730 solver.cpp:244]     Train net output #1: loss = 0.732119 (* 1 = 0.732119 loss)
I0911 23:21:09.961684 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.3851
I0911 23:21:09.961689 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.715406
I0911 23:21:09.961712 24730 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0911 23:21:26.208058 24730 solver.cpp:228] Iteration 20, loss = 0.411141
I0911 23:21:26.208106 24730 solver.cpp:244]     Train net output #0: accuracy = 0.882993
I0911 23:21:26.208119 24730 solver.cpp:244]     Train net output #1: loss = 0.411141 (* 1 = 0.411141 loss)
I0911 23:21:26.208124 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.926949
I0911 23:21:26.208129 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.847996
I0911 23:21:26.208137 24730 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0911 23:21:42.860689 24730 solver.cpp:228] Iteration 40, loss = 0.302393
I0911 23:21:42.860841 24730 solver.cpp:244]     Train net output #0: accuracy = 0.80181
I0911 23:21:42.860857 24730 solver.cpp:244]     Train net output #1: loss = 0.302393 (* 1 = 0.302393 loss)
I0911 23:21:42.860865 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.753924
I0911 23:21:42.860869 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996093
I0911 23:21:42.860877 24730 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0911 23:21:59.501672 24730 solver.cpp:228] Iteration 60, loss = 0.352756
I0911 23:21:59.501718 24730 solver.cpp:244]     Train net output #0: accuracy = 0.766075
I0911 23:21:59.501731 24730 solver.cpp:244]     Train net output #1: loss = 0.352756 (* 1 = 0.352756 loss)
I0911 23:21:59.501737 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.692422
I0911 23:21:59.501742 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998521
I0911 23:21:59.501749 24730 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0911 23:22:16.148962 24730 solver.cpp:228] Iteration 80, loss = 0.123773
I0911 23:22:16.149128 24730 solver.cpp:244]     Train net output #0: accuracy = 0.968964
I0911 23:22:16.149150 24730 solver.cpp:244]     Train net output #1: loss = 0.123773 (* 1 = 0.123773 loss)
I0911 23:22:16.149158 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.958606
I0911 23:22:16.149163 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981919
I0911 23:22:16.149170 24730 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0911 23:22:32.784677 24730 solver.cpp:228] Iteration 100, loss = 0.382789
I0911 23:22:32.784736 24730 solver.cpp:244]     Train net output #0: accuracy = 0.794572
I0911 23:22:32.784752 24730 solver.cpp:244]     Train net output #1: loss = 0.382789 (* 1 = 0.382789 loss)
I0911 23:22:32.784759 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.742781
I0911 23:22:32.784765 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99506
I0911 23:22:32.784772 24730 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0911 23:22:49.438467 24730 solver.cpp:228] Iteration 120, loss = 0.162601
I0911 23:22:49.438647 24730 solver.cpp:244]     Train net output #0: accuracy = 0.961603
I0911 23:22:49.438663 24730 solver.cpp:244]     Train net output #1: loss = 0.162601 (* 1 = 0.162601 loss)
I0911 23:22:49.438675 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97471
I0911 23:22:49.438680 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.949134
I0911 23:22:49.438689 24730 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0911 23:23:06.077298 24730 solver.cpp:228] Iteration 140, loss = 0.101014
I0911 23:23:06.077338 24730 solver.cpp:244]     Train net output #0: accuracy = 0.979557
I0911 23:23:06.077350 24730 solver.cpp:244]     Train net output #1: loss = 0.101014 (* 1 = 0.101014 loss)
I0911 23:23:06.077358 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97906
I0911 23:23:06.077363 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980157
I0911 23:23:06.077375 24730 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0911 23:23:22.708290 24730 solver.cpp:228] Iteration 160, loss = 0.137358
I0911 23:23:22.708426 24730 solver.cpp:244]     Train net output #0: accuracy = 0.961878
I0911 23:23:22.708441 24730 solver.cpp:244]     Train net output #1: loss = 0.137358 (* 1 = 0.137358 loss)
I0911 23:23:22.708447 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975802
I0911 23:23:22.708452 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.938738
I0911 23:23:22.708459 24730 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0911 23:23:39.353339 24730 solver.cpp:228] Iteration 180, loss = 0.138387
I0911 23:23:39.353395 24730 solver.cpp:244]     Train net output #0: accuracy = 0.961775
I0911 23:23:39.353410 24730 solver.cpp:244]     Train net output #1: loss = 0.138387 (* 1 = 0.138387 loss)
I0911 23:23:39.353415 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983547
I0911 23:23:39.353420 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.935184
I0911 23:23:39.353427 24730 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0911 23:23:56.002339 24730 solver.cpp:228] Iteration 200, loss = 0.107919
I0911 23:23:56.002459 24730 solver.cpp:244]     Train net output #0: accuracy = 0.968811
I0911 23:23:56.002472 24730 solver.cpp:244]     Train net output #1: loss = 0.107919 (* 1 = 0.107919 loss)
I0911 23:23:56.002478 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969581
I0911 23:23:56.002482 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.967932
I0911 23:23:56.002490 24730 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0911 23:24:12.648627 24730 solver.cpp:228] Iteration 220, loss = 0.0556046
I0911 23:24:12.648664 24730 solver.cpp:244]     Train net output #0: accuracy = 0.978351
I0911 23:24:12.648677 24730 solver.cpp:244]     Train net output #1: loss = 0.0556046 (* 1 = 0.0556046 loss)
I0911 23:24:12.648684 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.961822
I0911 23:24:12.648694 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99564
I0911 23:24:12.648700 24730 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0911 23:24:29.280297 24730 solver.cpp:228] Iteration 240, loss = 0.193349
I0911 23:24:29.280428 24730 solver.cpp:244]     Train net output #0: accuracy = 0.928598
I0911 23:24:29.280465 24730 solver.cpp:244]     Train net output #1: loss = 0.193349 (* 1 = 0.193349 loss)
I0911 23:24:29.280472 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.914916
I0911 23:24:29.280479 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994089
I0911 23:24:29.280488 24730 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0911 23:24:45.939690 24730 solver.cpp:228] Iteration 260, loss = 0.0521121
I0911 23:24:45.939733 24730 solver.cpp:244]     Train net output #0: accuracy = 0.988482
I0911 23:24:45.939749 24730 solver.cpp:244]     Train net output #1: loss = 0.0521122 (* 1 = 0.0521122 loss)
I0911 23:24:45.939755 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991707
I0911 23:24:45.939759 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981152
I0911 23:24:45.939766 24730 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0911 23:25:02.607925 24730 solver.cpp:228] Iteration 280, loss = 0.170894
I0911 23:25:02.608091 24730 solver.cpp:244]     Train net output #0: accuracy = 0.926042
I0911 23:25:02.608109 24730 solver.cpp:244]     Train net output #1: loss = 0.170894 (* 1 = 0.170894 loss)
I0911 23:25:02.608115 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.916196
I0911 23:25:02.608119 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989915
I0911 23:25:02.608127 24730 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0911 23:25:19.268337 24730 solver.cpp:228] Iteration 300, loss = 0.101564
I0911 23:25:19.268380 24730 solver.cpp:244]     Train net output #0: accuracy = 0.956283
I0911 23:25:19.268393 24730 solver.cpp:244]     Train net output #1: loss = 0.101564 (* 1 = 0.101564 loss)
I0911 23:25:19.268399 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.946042
I0911 23:25:19.268404 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984404
I0911 23:25:19.268411 24730 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0911 23:25:35.926964 24730 solver.cpp:228] Iteration 320, loss = 0.0891686
I0911 23:25:35.927090 24730 solver.cpp:244]     Train net output #0: accuracy = 0.964504
I0911 23:25:35.927106 24730 solver.cpp:244]     Train net output #1: loss = 0.0891687 (* 1 = 0.0891687 loss)
I0911 23:25:35.927114 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.960131
I0911 23:25:35.927119 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.975009
I0911 23:25:35.927126 24730 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0911 23:25:52.580588 24730 solver.cpp:228] Iteration 340, loss = 0.0168279
I0911 23:25:52.580632 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996406
I0911 23:25:52.580644 24730 solver.cpp:244]     Train net output #1: loss = 0.016828 (* 1 = 0.016828 loss)
I0911 23:25:52.580651 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995317
I0911 23:25:52.580655 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998761
I0911 23:25:52.580663 24730 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0911 23:26:09.251220 24730 solver.cpp:228] Iteration 360, loss = 0.0172914
I0911 23:26:09.251334 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996319
I0911 23:26:09.251350 24730 solver.cpp:244]     Train net output #1: loss = 0.0172915 (* 1 = 0.0172915 loss)
I0911 23:26:09.251356 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996119
I0911 23:26:09.251363 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996918
I0911 23:26:09.251369 24730 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0911 23:26:25.893347 24730 solver.cpp:228] Iteration 380, loss = 0.033573
I0911 23:26:25.893395 24730 solver.cpp:244]     Train net output #0: accuracy = 0.989837
I0911 23:26:25.893410 24730 solver.cpp:244]     Train net output #1: loss = 0.0335731 (* 1 = 0.0335731 loss)
I0911 23:26:25.893416 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984739
I0911 23:26:25.893421 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994376
I0911 23:26:25.893429 24730 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0911 23:26:42.564208 24730 solver.cpp:228] Iteration 400, loss = 0.0558907
I0911 23:26:42.564321 24730 solver.cpp:244]     Train net output #0: accuracy = 0.984534
I0911 23:26:42.564340 24730 solver.cpp:244]     Train net output #1: loss = 0.0558908 (* 1 = 0.0558908 loss)
I0911 23:26:42.564347 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990605
I0911 23:26:42.564350 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.969951
I0911 23:26:42.564358 24730 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0911 23:26:59.212175 24730 solver.cpp:228] Iteration 420, loss = 0.0472819
I0911 23:26:59.212215 24730 solver.cpp:244]     Train net output #0: accuracy = 0.982221
I0911 23:26:59.212229 24730 solver.cpp:244]     Train net output #1: loss = 0.047282 (* 1 = 0.047282 loss)
I0911 23:26:59.212234 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981959
I0911 23:26:59.212239 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983163
I0911 23:26:59.212246 24730 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0911 23:27:15.841698 24730 solver.cpp:228] Iteration 440, loss = 0.0180882
I0911 23:27:15.841871 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993958
I0911 23:27:15.841888 24730 solver.cpp:244]     Train net output #1: loss = 0.0180883 (* 1 = 0.0180883 loss)
I0911 23:27:15.841902 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993782
I0911 23:27:15.841907 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994358
I0911 23:27:15.841913 24730 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0911 23:27:32.481578 24730 solver.cpp:228] Iteration 460, loss = 0.0182335
I0911 23:27:32.481618 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993249
I0911 23:27:32.481631 24730 solver.cpp:244]     Train net output #1: loss = 0.0182336 (* 1 = 0.0182336 loss)
I0911 23:27:32.481637 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990677
I0911 23:27:32.481642 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996747
I0911 23:27:32.481649 24730 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0911 23:27:49.122171 24730 solver.cpp:228] Iteration 480, loss = 0.0300928
I0911 23:27:49.122280 24730 solver.cpp:244]     Train net output #0: accuracy = 0.988479
I0911 23:27:49.122295 24730 solver.cpp:244]     Train net output #1: loss = 0.0300929 (* 1 = 0.0300929 loss)
I0911 23:27:49.122303 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98126
I0911 23:27:49.122306 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995169
I0911 23:27:49.122314 24730 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0911 23:28:05.784368 24730 solver.cpp:228] Iteration 500, loss = 0.0204767
I0911 23:28:05.784409 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99386
I0911 23:28:05.784423 24730 solver.cpp:244]     Train net output #1: loss = 0.0204768 (* 1 = 0.0204768 loss)
I0911 23:28:05.784428 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995761
I0911 23:28:05.784433 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988716
I0911 23:28:05.784440 24730 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0911 23:28:22.430564 24730 solver.cpp:228] Iteration 520, loss = 0.0312214
I0911 23:28:22.430670 24730 solver.cpp:244]     Train net output #0: accuracy = 0.991224
I0911 23:28:22.430686 24730 solver.cpp:244]     Train net output #1: loss = 0.0312215 (* 1 = 0.0312215 loss)
I0911 23:28:22.430693 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995583
I0911 23:28:22.430697 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979744
I0911 23:28:22.430704 24730 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0911 23:28:39.079352 24730 solver.cpp:228] Iteration 540, loss = 0.0269864
I0911 23:28:39.079394 24730 solver.cpp:244]     Train net output #0: accuracy = 0.990386
I0911 23:28:39.079408 24730 solver.cpp:244]     Train net output #1: loss = 0.0269865 (* 1 = 0.0269865 loss)
I0911 23:28:39.079416 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987795
I0911 23:28:39.079421 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993172
I0911 23:28:39.079427 24730 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0911 23:28:55.736894 24730 solver.cpp:228] Iteration 560, loss = 0.0338761
I0911 23:28:55.737073 24730 solver.cpp:244]     Train net output #0: accuracy = 0.987999
I0911 23:28:55.737097 24730 solver.cpp:244]     Train net output #1: loss = 0.0338762 (* 1 = 0.0338762 loss)
I0911 23:28:55.737104 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98894
I0911 23:28:55.737109 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986203
I0911 23:28:55.737118 24730 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0911 23:29:12.387779 24730 solver.cpp:228] Iteration 580, loss = 0.0135624
I0911 23:29:12.387822 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995483
I0911 23:29:12.387835 24730 solver.cpp:244]     Train net output #1: loss = 0.0135625 (* 1 = 0.0135625 loss)
I0911 23:29:12.387840 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995628
I0911 23:29:12.387845 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995164
I0911 23:29:12.387852 24730 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0911 23:29:29.046463 24730 solver.cpp:228] Iteration 600, loss = 0.0232174
I0911 23:29:29.046578 24730 solver.cpp:244]     Train net output #0: accuracy = 0.990852
I0911 23:29:29.046593 24730 solver.cpp:244]     Train net output #1: loss = 0.0232175 (* 1 = 0.0232175 loss)
I0911 23:29:29.046599 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988615
I0911 23:29:29.046605 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993908
I0911 23:29:29.046612 24730 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0911 23:29:45.687280 24730 solver.cpp:228] Iteration 620, loss = 0.017593
I0911 23:29:45.687324 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993239
I0911 23:29:45.687338 24730 solver.cpp:244]     Train net output #1: loss = 0.0175931 (* 1 = 0.0175931 loss)
I0911 23:29:45.687345 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991246
I0911 23:29:45.687351 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996833
I0911 23:29:45.687360 24730 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0911 23:30:02.331763 24730 solver.cpp:228] Iteration 640, loss = 0.0183637
I0911 23:30:02.331884 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993566
I0911 23:30:02.331902 24730 solver.cpp:244]     Train net output #1: loss = 0.0183638 (* 1 = 0.0183638 loss)
I0911 23:30:02.331907 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994295
I0911 23:30:02.331912 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992178
I0911 23:30:02.331918 24730 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0911 23:30:18.974172 24730 solver.cpp:228] Iteration 660, loss = 0.010619
I0911 23:30:18.974215 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995926
I0911 23:30:18.974228 24730 solver.cpp:244]     Train net output #1: loss = 0.0106191 (* 1 = 0.0106191 loss)
I0911 23:30:18.974234 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9932
I0911 23:30:18.974239 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99915
I0911 23:30:18.974246 24730 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0911 23:30:35.623463 24730 solver.cpp:228] Iteration 680, loss = 0.0366309
I0911 23:30:35.623587 24730 solver.cpp:244]     Train net output #0: accuracy = 0.9861
I0911 23:30:35.623602 24730 solver.cpp:244]     Train net output #1: loss = 0.036631 (* 1 = 0.036631 loss)
I0911 23:30:35.623608 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985346
I0911 23:30:35.623612 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987942
I0911 23:30:35.623620 24730 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0911 23:30:52.289047 24730 solver.cpp:228] Iteration 700, loss = 0.051683
I0911 23:30:52.289089 24730 solver.cpp:244]     Train net output #0: accuracy = 0.981842
I0911 23:30:52.289104 24730 solver.cpp:244]     Train net output #1: loss = 0.0516831 (* 1 = 0.0516831 loss)
I0911 23:30:52.289110 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984554
I0911 23:30:52.289115 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978149
I0911 23:30:52.289122 24730 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0911 23:31:08.945500 24730 solver.cpp:228] Iteration 720, loss = 0.0215046
I0911 23:31:08.945667 24730 solver.cpp:244]     Train net output #0: accuracy = 0.990405
I0911 23:31:08.945688 24730 solver.cpp:244]     Train net output #1: loss = 0.0215047 (* 1 = 0.0215047 loss)
I0911 23:31:08.945695 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982666
I0911 23:31:08.945700 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998488
I0911 23:31:08.945711 24730 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0911 23:31:25.593693 24730 solver.cpp:228] Iteration 740, loss = 0.0356653
I0911 23:31:25.593734 24730 solver.cpp:244]     Train net output #0: accuracy = 0.987614
I0911 23:31:25.593746 24730 solver.cpp:244]     Train net output #1: loss = 0.0356654 (* 1 = 0.0356654 loss)
I0911 23:31:25.593752 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987357
I0911 23:31:25.593757 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987923
I0911 23:31:25.593765 24730 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0911 23:31:42.231240 24730 solver.cpp:228] Iteration 760, loss = 0.0225986
I0911 23:31:42.231360 24730 solver.cpp:244]     Train net output #0: accuracy = 0.992863
I0911 23:31:42.231376 24730 solver.cpp:244]     Train net output #1: loss = 0.0225987 (* 1 = 0.0225987 loss)
I0911 23:31:42.231382 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990479
I0911 23:31:42.231387 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9948
I0911 23:31:42.231395 24730 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0911 23:31:58.886658 24730 solver.cpp:228] Iteration 780, loss = 0.0156968
I0911 23:31:58.886703 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994873
I0911 23:31:58.886716 24730 solver.cpp:244]     Train net output #1: loss = 0.0156969 (* 1 = 0.0156969 loss)
I0911 23:31:58.886723 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995273
I0911 23:31:58.886734 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994264
I0911 23:31:58.886741 24730 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0911 23:32:15.527264 24730 solver.cpp:228] Iteration 800, loss = 0.0127812
I0911 23:32:15.527389 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995395
I0911 23:32:15.527405 24730 solver.cpp:244]     Train net output #1: loss = 0.0127813 (* 1 = 0.0127813 loss)
I0911 23:32:15.527411 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995761
I0911 23:32:15.527416 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994517
I0911 23:32:15.527423 24730 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0911 23:32:32.175912 24730 solver.cpp:228] Iteration 820, loss = 0.0135452
I0911 23:32:32.175956 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995548
I0911 23:32:32.175968 24730 solver.cpp:244]     Train net output #1: loss = 0.0135453 (* 1 = 0.0135453 loss)
I0911 23:32:32.175974 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992978
I0911 23:32:32.175985 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997792
I0911 23:32:32.175993 24730 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0911 23:32:48.820616 24730 solver.cpp:228] Iteration 840, loss = 0.0186905
I0911 23:32:48.820725 24730 solver.cpp:244]     Train net output #0: accuracy = 0.992151
I0911 23:32:48.820741 24730 solver.cpp:244]     Train net output #1: loss = 0.0186906 (* 1 = 0.0186906 loss)
I0911 23:32:48.820749 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990312
I0911 23:32:48.820753 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996601
I0911 23:32:48.820760 24730 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0911 23:33:05.470620 24730 solver.cpp:228] Iteration 860, loss = 0.0128658
I0911 23:33:05.470664 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995541
I0911 23:33:05.470677 24730 solver.cpp:244]     Train net output #1: loss = 0.0128659 (* 1 = 0.0128659 loss)
I0911 23:33:05.470700 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995584
I0911 23:33:05.470710 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995425
I0911 23:33:05.470717 24730 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0911 23:33:22.097676 24730 solver.cpp:228] Iteration 880, loss = 0.0320111
I0911 23:33:22.097827 24730 solver.cpp:244]     Train net output #0: accuracy = 0.987406
I0911 23:33:22.097844 24730 solver.cpp:244]     Train net output #1: loss = 0.0320112 (* 1 = 0.0320112 loss)
I0911 23:33:22.097856 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980512
I0911 23:33:22.097862 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993416
I0911 23:33:22.097868 24730 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0911 23:33:38.749464 24730 solver.cpp:228] Iteration 900, loss = 0.01421
I0911 23:33:38.749505 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994167
I0911 23:33:38.749518 24730 solver.cpp:244]     Train net output #1: loss = 0.0142101 (* 1 = 0.0142101 loss)
I0911 23:33:38.749524 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989581
I0911 23:33:38.749529 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998263
I0911 23:33:38.749536 24730 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0911 23:33:55.406235 24730 solver.cpp:228] Iteration 920, loss = 0.0180884
I0911 23:33:55.406342 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993388
I0911 23:33:55.406358 24730 solver.cpp:244]     Train net output #1: loss = 0.0180886 (* 1 = 0.0180886 loss)
I0911 23:33:55.406363 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992838
I0911 23:33:55.406368 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996023
I0911 23:33:55.406375 24730 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0911 23:34:12.041540 24730 solver.cpp:228] Iteration 940, loss = 0.0111904
I0911 23:34:12.041580 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995383
I0911 23:34:12.041594 24730 solver.cpp:244]     Train net output #1: loss = 0.0111905 (* 1 = 0.0111905 loss)
I0911 23:34:12.041600 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993732
I0911 23:34:12.041610 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998062
I0911 23:34:12.041617 24730 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0911 23:34:28.687482 24730 solver.cpp:228] Iteration 960, loss = 0.00885716
I0911 23:34:28.687593 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996769
I0911 23:34:28.687609 24730 solver.cpp:244]     Train net output #1: loss = 0.00885728 (* 1 = 0.00885728 loss)
I0911 23:34:28.687623 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995857
I0911 23:34:28.687629 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997819
I0911 23:34:28.687636 24730 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0911 23:34:45.352665 24730 solver.cpp:228] Iteration 980, loss = 0.0164226
I0911 23:34:45.352705 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995291
I0911 23:34:45.352718 24730 solver.cpp:244]     Train net output #1: loss = 0.0164227 (* 1 = 0.0164227 loss)
I0911 23:34:45.352725 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997884
I0911 23:34:45.352730 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986995
I0911 23:34:45.352736 24730 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0911 23:35:01.992918 24730 solver.cpp:228] Iteration 1000, loss = 0.0192637
I0911 23:35:01.993017 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993079
I0911 23:35:01.993034 24730 solver.cpp:244]     Train net output #1: loss = 0.0192638 (* 1 = 0.0192638 loss)
I0911 23:35:01.993041 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993983
I0911 23:35:01.993046 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991461
I0911 23:35:01.993052 24730 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0911 23:35:18.633363 24730 solver.cpp:228] Iteration 1020, loss = 0.0324474
I0911 23:35:18.633411 24730 solver.cpp:244]     Train net output #0: accuracy = 0.988529
I0911 23:35:18.633422 24730 solver.cpp:244]     Train net output #1: loss = 0.0324475 (* 1 = 0.0324475 loss)
I0911 23:35:18.633430 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988098
I0911 23:35:18.633435 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989173
I0911 23:35:18.633441 24730 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0911 23:35:35.286631 24730 solver.cpp:228] Iteration 1040, loss = 0.0148592
I0911 23:35:35.286775 24730 solver.cpp:244]     Train net output #0: accuracy = 0.992879
I0911 23:35:35.286793 24730 solver.cpp:244]     Train net output #1: loss = 0.0148593 (* 1 = 0.0148593 loss)
I0911 23:35:35.286799 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990492
I0911 23:35:35.286804 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997254
I0911 23:35:35.286811 24730 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0911 23:35:51.947405 24730 solver.cpp:228] Iteration 1060, loss = 0.0192156
I0911 23:35:51.947448 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994058
I0911 23:35:51.947463 24730 solver.cpp:244]     Train net output #1: loss = 0.0192157 (* 1 = 0.0192157 loss)
I0911 23:35:51.947468 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98727
I0911 23:35:51.947481 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998179
I0911 23:35:51.947489 24730 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0911 23:36:08.595541 24730 solver.cpp:228] Iteration 1080, loss = 0.0248753
I0911 23:36:08.595646 24730 solver.cpp:244]     Train net output #0: accuracy = 0.989698
I0911 23:36:08.595662 24730 solver.cpp:244]     Train net output #1: loss = 0.0248754 (* 1 = 0.0248754 loss)
I0911 23:36:08.595669 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984459
I0911 23:36:08.595674 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996026
I0911 23:36:08.595680 24730 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0911 23:36:25.257766 24730 solver.cpp:228] Iteration 1100, loss = 0.0896423
I0911 23:36:25.257809 24730 solver.cpp:244]     Train net output #0: accuracy = 0.97963
I0911 23:36:25.257824 24730 solver.cpp:244]     Train net output #1: loss = 0.0896423 (* 1 = 0.0896423 loss)
I0911 23:36:25.257832 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993904
I0911 23:36:25.257838 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.970926
I0911 23:36:25.257848 24730 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0911 23:36:41.911269 24730 solver.cpp:228] Iteration 1120, loss = 0.0159591
I0911 23:36:41.911375 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994842
I0911 23:36:41.911392 24730 solver.cpp:244]     Train net output #1: loss = 0.0159592 (* 1 = 0.0159592 loss)
I0911 23:36:41.911399 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994737
I0911 23:36:41.911403 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995232
I0911 23:36:41.911412 24730 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0911 23:36:58.564451 24730 solver.cpp:228] Iteration 1140, loss = 0.0288511
I0911 23:36:58.564492 24730 solver.cpp:244]     Train net output #0: accuracy = 0.989246
I0911 23:36:58.564505 24730 solver.cpp:244]     Train net output #1: loss = 0.0288512 (* 1 = 0.0288512 loss)
I0911 23:36:58.564512 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984707
I0911 23:36:58.564517 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993294
I0911 23:36:58.564524 24730 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0911 23:37:15.214699 24730 solver.cpp:228] Iteration 1160, loss = 0.0192088
I0911 23:37:15.214882 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993511
I0911 23:37:15.214900 24730 solver.cpp:244]     Train net output #1: loss = 0.0192089 (* 1 = 0.0192089 loss)
I0911 23:37:15.214913 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989716
I0911 23:37:15.214918 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996502
I0911 23:37:15.214926 24730 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0911 23:37:31.860707 24730 solver.cpp:228] Iteration 1180, loss = 0.0337559
I0911 23:37:31.860746 24730 solver.cpp:244]     Train net output #0: accuracy = 0.987185
I0911 23:37:31.860760 24730 solver.cpp:244]     Train net output #1: loss = 0.033756 (* 1 = 0.033756 loss)
I0911 23:37:31.860766 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986387
I0911 23:37:31.860771 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988453
I0911 23:37:31.860779 24730 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0911 23:37:48.512605 24730 solver.cpp:228] Iteration 1200, loss = 0.0162317
I0911 23:37:48.512717 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99396
I0911 23:37:48.512732 24730 solver.cpp:244]     Train net output #1: loss = 0.0162318 (* 1 = 0.0162318 loss)
I0911 23:37:48.512738 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993614
I0911 23:37:48.512744 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994489
I0911 23:37:48.512751 24730 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0911 23:38:05.146522 24730 solver.cpp:228] Iteration 1220, loss = 0.0199116
I0911 23:38:05.146561 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993079
I0911 23:38:05.146575 24730 solver.cpp:244]     Train net output #1: loss = 0.0199116 (* 1 = 0.0199116 loss)
I0911 23:38:05.146581 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994816
I0911 23:38:05.146587 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99048
I0911 23:38:05.146595 24730 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0911 23:38:21.795953 24730 solver.cpp:228] Iteration 1240, loss = 0.0149998
I0911 23:38:21.796056 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994159
I0911 23:38:21.796069 24730 solver.cpp:244]     Train net output #1: loss = 0.0149999 (* 1 = 0.0149999 loss)
I0911 23:38:21.796075 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992459
I0911 23:38:21.796080 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996924
I0911 23:38:21.796087 24730 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0911 23:38:38.451200 24730 solver.cpp:228] Iteration 1260, loss = 0.0227499
I0911 23:38:38.451244 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993424
I0911 23:38:38.451257 24730 solver.cpp:244]     Train net output #1: loss = 0.02275 (* 1 = 0.02275 loss)
I0911 23:38:38.451263 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997602
I0911 23:38:38.451269 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986243
I0911 23:38:38.451277 24730 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0911 23:38:55.084575 24730 solver.cpp:228] Iteration 1280, loss = 0.0131353
I0911 23:38:55.084686 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995192
I0911 23:38:55.084702 24730 solver.cpp:244]     Train net output #1: loss = 0.0131354 (* 1 = 0.0131354 loss)
I0911 23:38:55.084708 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994754
I0911 23:38:55.084719 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995836
I0911 23:38:55.084727 24730 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0911 23:39:11.736814 24730 solver.cpp:228] Iteration 1300, loss = 0.0131994
I0911 23:39:11.736857 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994703
I0911 23:39:11.736871 24730 solver.cpp:244]     Train net output #1: loss = 0.0131995 (* 1 = 0.0131995 loss)
I0911 23:39:11.736876 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993185
I0911 23:39:11.736881 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997257
I0911 23:39:11.736888 24730 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0911 23:39:28.380784 24730 solver.cpp:228] Iteration 1320, loss = 0.0261522
I0911 23:39:28.381011 24730 solver.cpp:244]     Train net output #0: accuracy = 0.989116
I0911 23:39:28.381052 24730 solver.cpp:244]     Train net output #1: loss = 0.0261523 (* 1 = 0.0261523 loss)
I0911 23:39:28.381062 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982009
I0911 23:39:28.381072 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995385
I0911 23:39:28.381080 24730 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0911 23:39:45.062721 24730 solver.cpp:228] Iteration 1340, loss = 0.0243034
I0911 23:39:45.062770 24730 solver.cpp:244]     Train net output #0: accuracy = 0.990245
I0911 23:39:45.062786 24730 solver.cpp:244]     Train net output #1: loss = 0.0243035 (* 1 = 0.0243035 loss)
I0911 23:39:45.062794 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985177
I0911 23:39:45.062803 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994985
I0911 23:39:45.062813 24730 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0911 23:40:01.723482 24730 solver.cpp:228] Iteration 1360, loss = 0.0115362
I0911 23:40:01.723609 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99593
I0911 23:40:01.723625 24730 solver.cpp:244]     Train net output #1: loss = 0.0115363 (* 1 = 0.0115363 loss)
I0911 23:40:01.723637 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995873
I0911 23:40:01.723644 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996103
I0911 23:40:01.723651 24730 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0911 23:40:18.390947 24730 solver.cpp:228] Iteration 1380, loss = 0.00811974
I0911 23:40:18.390990 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996804
I0911 23:40:18.391005 24730 solver.cpp:244]     Train net output #1: loss = 0.00811983 (* 1 = 0.00811983 loss)
I0911 23:40:18.391012 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99667
I0911 23:40:18.391017 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997063
I0911 23:40:18.391026 24730 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0911 23:40:35.071394 24730 solver.cpp:228] Iteration 1400, loss = 0.0287945
I0911 23:40:35.071512 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994107
I0911 23:40:35.071528 24730 solver.cpp:244]     Train net output #1: loss = 0.0287946 (* 1 = 0.0287946 loss)
I0911 23:40:35.071537 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989223
I0911 23:40:35.071542 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996377
I0911 23:40:35.071549 24730 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0911 23:40:51.747424 24730 solver.cpp:228] Iteration 1420, loss = 0.0970623
I0911 23:40:51.747467 24730 solver.cpp:244]     Train net output #0: accuracy = 0.969715
I0911 23:40:51.747483 24730 solver.cpp:244]     Train net output #1: loss = 0.0970624 (* 1 = 0.0970624 loss)
I0911 23:40:51.747488 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973975
I0911 23:40:51.747494 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.96173
I0911 23:40:51.747503 24730 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0911 23:41:08.408823 24730 solver.cpp:228] Iteration 1440, loss = 0.0132353
I0911 23:41:08.408944 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995245
I0911 23:41:08.408963 24730 solver.cpp:244]     Train net output #1: loss = 0.0132354 (* 1 = 0.0132354 loss)
I0911 23:41:08.408977 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994821
I0911 23:41:08.408987 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996119
I0911 23:41:08.408996 24730 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0911 23:41:25.071895 24730 solver.cpp:228] Iteration 1460, loss = 0.0576573
I0911 23:41:25.071938 24730 solver.cpp:244]     Train net output #0: accuracy = 0.972895
I0911 23:41:25.071951 24730 solver.cpp:244]     Train net output #1: loss = 0.0576574 (* 1 = 0.0576574 loss)
I0911 23:41:25.071957 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.970243
I0911 23:41:25.071964 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990099
I0911 23:41:25.071972 24730 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0911 23:41:41.731045 24730 solver.cpp:228] Iteration 1480, loss = 0.0193595
I0911 23:41:41.731194 24730 solver.cpp:244]     Train net output #0: accuracy = 0.992496
I0911 23:41:41.731211 24730 solver.cpp:244]     Train net output #1: loss = 0.0193596 (* 1 = 0.0193596 loss)
I0911 23:41:41.731220 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992665
I0911 23:41:41.731225 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992096
I0911 23:41:41.731233 24730 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0911 23:41:58.408197 24730 solver.cpp:228] Iteration 1500, loss = 0.0153847
I0911 23:41:58.408243 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993984
I0911 23:41:58.408258 24730 solver.cpp:244]     Train net output #1: loss = 0.0153848 (* 1 = 0.0153848 loss)
I0911 23:41:58.408264 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993696
I0911 23:41:58.408269 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994663
I0911 23:41:58.408277 24730 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0911 23:42:15.073235 24730 solver.cpp:228] Iteration 1520, loss = 0.0131494
I0911 23:42:15.073359 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996082
I0911 23:42:15.073382 24730 solver.cpp:244]     Train net output #1: loss = 0.0131494 (* 1 = 0.0131494 loss)
I0911 23:42:15.073391 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998787
I0911 23:42:15.073405 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989842
I0911 23:42:15.073411 24730 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0911 23:42:31.739872 24730 solver.cpp:228] Iteration 1540, loss = 0.0152511
I0911 23:42:31.739918 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994918
I0911 23:42:31.739934 24730 solver.cpp:244]     Train net output #1: loss = 0.0152512 (* 1 = 0.0152512 loss)
I0911 23:42:31.739941 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996933
I0911 23:42:31.739946 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990269
I0911 23:42:31.739954 24730 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0911 23:42:48.426417 24730 solver.cpp:228] Iteration 1560, loss = 0.00983044
I0911 23:42:48.426533 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997646
I0911 23:42:48.426551 24730 solver.cpp:244]     Train net output #1: loss = 0.00983053 (* 1 = 0.00983053 loss)
I0911 23:42:48.426563 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997937
I0911 23:42:48.426568 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996376
I0911 23:42:48.426575 24730 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0911 23:43:05.107483 24730 solver.cpp:228] Iteration 1580, loss = 0.0141081
I0911 23:43:05.107528 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994831
I0911 23:43:05.107544 24730 solver.cpp:244]     Train net output #1: loss = 0.0141082 (* 1 = 0.0141082 loss)
I0911 23:43:05.107551 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995983
I0911 23:43:05.107558 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992237
I0911 23:43:05.107568 24730 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0911 23:43:21.790058 24730 solver.cpp:228] Iteration 1600, loss = 0.0133338
I0911 23:43:21.790236 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994116
I0911 23:43:21.790261 24730 solver.cpp:244]     Train net output #1: loss = 0.0133339 (* 1 = 0.0133339 loss)
I0911 23:43:21.790268 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992419
I0911 23:43:21.790276 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996686
I0911 23:43:21.790282 24730 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0911 23:43:38.491659 24730 solver.cpp:228] Iteration 1620, loss = 0.0172766
I0911 23:43:38.491703 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995375
I0911 23:43:38.491716 24730 solver.cpp:244]     Train net output #1: loss = 0.0172767 (* 1 = 0.0172767 loss)
I0911 23:43:38.491724 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993518
I0911 23:43:38.491729 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996602
I0911 23:43:38.491736 24730 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0911 23:43:55.164170 24730 solver.cpp:228] Iteration 1640, loss = 0.0132611
I0911 23:43:55.164293 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994868
I0911 23:43:55.164309 24730 solver.cpp:244]     Train net output #1: loss = 0.0132612 (* 1 = 0.0132612 loss)
I0911 23:43:55.164319 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995391
I0911 23:43:55.164324 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993409
I0911 23:43:55.164331 24730 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0911 23:44:11.837669 24730 solver.cpp:228] Iteration 1660, loss = 0.0100826
I0911 23:44:11.837710 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996095
I0911 23:44:11.837725 24730 solver.cpp:244]     Train net output #1: loss = 0.0100827 (* 1 = 0.0100827 loss)
I0911 23:44:11.837733 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994855
I0911 23:44:11.837738 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997546
I0911 23:44:11.837746 24730 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0911 23:44:28.520196 24730 solver.cpp:228] Iteration 1680, loss = 0.0092112
I0911 23:44:28.520318 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996207
I0911 23:44:28.520335 24730 solver.cpp:244]     Train net output #1: loss = 0.00921129 (* 1 = 0.00921129 loss)
I0911 23:44:28.520346 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994236
I0911 23:44:28.520359 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998375
I0911 23:44:28.520368 24730 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0911 23:44:45.394760 24730 solver.cpp:228] Iteration 1700, loss = 0.00813761
I0911 23:44:45.394804 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996425
I0911 23:44:45.394819 24730 solver.cpp:244]     Train net output #1: loss = 0.0081377 (* 1 = 0.0081377 loss)
I0911 23:44:45.394827 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9956
I0911 23:44:45.394834 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997987
I0911 23:44:45.394841 24730 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0911 23:45:02.065356 24730 solver.cpp:228] Iteration 1720, loss = 0.0143123
I0911 23:45:02.065476 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995064
I0911 23:45:02.065493 24730 solver.cpp:244]     Train net output #1: loss = 0.0143124 (* 1 = 0.0143124 loss)
I0911 23:45:02.065502 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994947
I0911 23:45:02.065508 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995191
I0911 23:45:02.065516 24730 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0911 23:45:18.727452 24730 solver.cpp:228] Iteration 1740, loss = 0.0192802
I0911 23:45:18.727497 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995304
I0911 23:45:18.727512 24730 solver.cpp:244]     Train net output #1: loss = 0.0192802 (* 1 = 0.0192802 loss)
I0911 23:45:18.727519 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991821
I0911 23:45:18.727524 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997172
I0911 23:45:18.727532 24730 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0911 23:45:35.370198 24730 solver.cpp:228] Iteration 1760, loss = 0.0249271
I0911 23:45:35.370360 24730 solver.cpp:244]     Train net output #0: accuracy = 0.992655
I0911 23:45:35.370378 24730 solver.cpp:244]     Train net output #1: loss = 0.0249272 (* 1 = 0.0249272 loss)
I0911 23:45:35.370386 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996924
I0911 23:45:35.370398 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987868
I0911 23:45:35.370405 24730 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0911 23:45:52.038347 24730 solver.cpp:228] Iteration 1780, loss = 0.018219
I0911 23:45:52.038393 24730 solver.cpp:244]     Train net output #0: accuracy = 0.991953
I0911 23:45:52.038408 24730 solver.cpp:244]     Train net output #1: loss = 0.0182191 (* 1 = 0.0182191 loss)
I0911 23:45:52.038417 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990667
I0911 23:45:52.038427 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994792
I0911 23:45:52.038441 24730 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0911 23:46:08.716789 24730 solver.cpp:228] Iteration 1800, loss = 0.0210225
I0911 23:46:08.716914 24730 solver.cpp:244]     Train net output #0: accuracy = 0.991481
I0911 23:46:08.716933 24730 solver.cpp:244]     Train net output #1: loss = 0.0210226 (* 1 = 0.0210226 loss)
I0911 23:46:08.716943 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989845
I0911 23:46:08.716948 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993866
I0911 23:46:08.716955 24730 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0911 23:46:25.376505 24730 solver.cpp:228] Iteration 1820, loss = 0.00899078
I0911 23:46:25.376551 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996094
I0911 23:46:25.376566 24730 solver.cpp:244]     Train net output #1: loss = 0.00899087 (* 1 = 0.00899087 loss)
I0911 23:46:25.376574 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994343
I0911 23:46:25.376581 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998425
I0911 23:46:25.376590 24730 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0911 23:46:42.021971 24730 solver.cpp:228] Iteration 1840, loss = 0.00838398
I0911 23:46:42.022119 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997027
I0911 23:46:42.022167 24730 solver.cpp:244]     Train net output #1: loss = 0.00838407 (* 1 = 0.00838407 loss)
I0911 23:46:42.022176 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997442
I0911 23:46:42.022186 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996183
I0911 23:46:42.022195 24730 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0911 23:46:58.673923 24730 solver.cpp:228] Iteration 1860, loss = 0.0077564
I0911 23:46:58.673965 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997159
I0911 23:46:58.673979 24730 solver.cpp:244]     Train net output #1: loss = 0.00775649 (* 1 = 0.00775649 loss)
I0911 23:46:58.673985 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997092
I0911 23:46:58.673990 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997358
I0911 23:46:58.673997 24730 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0911 23:47:15.316104 24730 solver.cpp:228] Iteration 1880, loss = 0.00721492
I0911 23:47:15.316262 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996878
I0911 23:47:15.316303 24730 solver.cpp:244]     Train net output #1: loss = 0.00721501 (* 1 = 0.00721501 loss)
I0911 23:47:15.316313 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996262
I0911 23:47:15.316323 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998902
I0911 23:47:15.316331 24730 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0911 23:47:31.985743 24730 solver.cpp:228] Iteration 1900, loss = 0.00704239
I0911 23:47:31.985785 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997384
I0911 23:47:31.985800 24730 solver.cpp:244]     Train net output #1: loss = 0.00704248 (* 1 = 0.00704248 loss)
I0911 23:47:31.985807 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996575
I0911 23:47:31.985811 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998289
I0911 23:47:31.985819 24730 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0911 23:47:48.650387 24730 solver.cpp:228] Iteration 1920, loss = 0.00949457
I0911 23:47:48.650554 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996042
I0911 23:47:48.650579 24730 solver.cpp:244]     Train net output #1: loss = 0.00949466 (* 1 = 0.00949466 loss)
I0911 23:47:48.650588 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995663
I0911 23:47:48.650599 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996762
I0911 23:47:48.650607 24730 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0911 23:48:05.292507 24730 solver.cpp:228] Iteration 1940, loss = 0.0139177
I0911 23:48:05.292548 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995516
I0911 23:48:05.292562 24730 solver.cpp:244]     Train net output #1: loss = 0.0139178 (* 1 = 0.0139178 loss)
I0911 23:48:05.292569 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991464
I0911 23:48:05.292574 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998161
I0911 23:48:05.292582 24730 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0911 23:48:21.931442 24730 solver.cpp:228] Iteration 1960, loss = 0.0136963
I0911 23:48:21.931582 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994269
I0911 23:48:21.931625 24730 solver.cpp:244]     Train net output #1: loss = 0.0136964 (* 1 = 0.0136964 loss)
I0911 23:48:21.931634 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992291
I0911 23:48:21.931644 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996487
I0911 23:48:21.931653 24730 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0911 23:48:38.649623 24730 solver.cpp:228] Iteration 1980, loss = 0.0114671
I0911 23:48:38.649672 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997975
I0911 23:48:38.649703 24730 solver.cpp:244]     Train net output #1: loss = 0.0114672 (* 1 = 0.0114672 loss)
I0911 23:48:38.649710 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998376
I0911 23:48:38.649716 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993855
I0911 23:48:38.649724 24730 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0911 23:48:55.353236 24730 solver.cpp:228] Iteration 2000, loss = 0.00665126
I0911 23:48:55.353394 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997849
I0911 23:48:55.353432 24730 solver.cpp:244]     Train net output #1: loss = 0.00665135 (* 1 = 0.00665135 loss)
I0911 23:48:55.353440 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998062
I0911 23:48:55.353451 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997122
I0911 23:48:55.353457 24730 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0911 23:49:12.007464 24730 solver.cpp:228] Iteration 2020, loss = 0.0097917
I0911 23:49:12.007511 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996201
I0911 23:49:12.007527 24730 solver.cpp:244]     Train net output #1: loss = 0.00979179 (* 1 = 0.00979179 loss)
I0911 23:49:12.007535 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993428
I0911 23:49:12.007542 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998498
I0911 23:49:12.007551 24730 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0911 23:49:28.645432 24730 solver.cpp:228] Iteration 2040, loss = 0.00737157
I0911 23:49:28.645540 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997082
I0911 23:49:28.645556 24730 solver.cpp:244]     Train net output #1: loss = 0.00737166 (* 1 = 0.00737166 loss)
I0911 23:49:28.645570 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995976
I0911 23:49:28.645581 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998257
I0911 23:49:28.645589 24730 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0911 23:49:45.313861 24730 solver.cpp:228] Iteration 2060, loss = 0.0153575
I0911 23:49:45.313907 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994554
I0911 23:49:45.313921 24730 solver.cpp:244]     Train net output #1: loss = 0.0153576 (* 1 = 0.0153576 loss)
I0911 23:49:45.313935 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99323
I0911 23:49:45.313947 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995637
I0911 23:49:45.313956 24730 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0911 23:50:01.973158 24730 solver.cpp:228] Iteration 2080, loss = 0.0117817
I0911 23:50:01.973316 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995618
I0911 23:50:01.973340 24730 solver.cpp:244]     Train net output #1: loss = 0.0117818 (* 1 = 0.0117818 loss)
I0911 23:50:01.973348 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996234
I0911 23:50:01.973353 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993541
I0911 23:50:01.973361 24730 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0911 23:50:18.626217 24730 solver.cpp:228] Iteration 2100, loss = 0.0058971
I0911 23:50:18.626262 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997446
I0911 23:50:18.626277 24730 solver.cpp:244]     Train net output #1: loss = 0.00589719 (* 1 = 0.00589719 loss)
I0911 23:50:18.626289 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996642
I0911 23:50:18.626301 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998841
I0911 23:50:18.626309 24730 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0911 23:50:35.297492 24730 solver.cpp:228] Iteration 2120, loss = 0.00541093
I0911 23:50:35.297622 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997959
I0911 23:50:35.297667 24730 solver.cpp:244]     Train net output #1: loss = 0.00541102 (* 1 = 0.00541102 loss)
I0911 23:50:35.297674 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997834
I0911 23:50:35.297680 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998401
I0911 23:50:35.297693 24730 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0911 23:50:51.954124 24730 solver.cpp:228] Iteration 2140, loss = 0.0072484
I0911 23:50:51.954164 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99753
I0911 23:50:51.954177 24730 solver.cpp:244]     Train net output #1: loss = 0.00724849 (* 1 = 0.00724849 loss)
I0911 23:50:51.954185 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998126
I0911 23:50:51.954190 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99574
I0911 23:50:51.954196 24730 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0911 23:51:08.609097 24730 solver.cpp:228] Iteration 2160, loss = 0.00765723
I0911 23:51:08.609239 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997083
I0911 23:51:08.609278 24730 solver.cpp:244]     Train net output #1: loss = 0.00765732 (* 1 = 0.00765732 loss)
I0911 23:51:08.609287 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996741
I0911 23:51:08.609292 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99755
I0911 23:51:08.609300 24730 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0911 23:51:25.273020 24730 solver.cpp:228] Iteration 2180, loss = 0.00895116
I0911 23:51:25.273063 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995945
I0911 23:51:25.273078 24730 solver.cpp:244]     Train net output #1: loss = 0.00895125 (* 1 = 0.00895125 loss)
I0911 23:51:25.273084 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993353
I0911 23:51:25.273089 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99857
I0911 23:51:25.273097 24730 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0911 23:51:41.936405 24730 solver.cpp:228] Iteration 2200, loss = 0.00799281
I0911 23:51:41.936581 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996483
I0911 23:51:41.936597 24730 solver.cpp:244]     Train net output #1: loss = 0.0079929 (* 1 = 0.0079929 loss)
I0911 23:51:41.936604 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993859
I0911 23:51:41.936610 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999052
I0911 23:51:41.936625 24730 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0911 23:51:58.593487 24730 solver.cpp:228] Iteration 2220, loss = 0.00636935
I0911 23:51:58.593528 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997594
I0911 23:51:58.593541 24730 solver.cpp:244]     Train net output #1: loss = 0.00636944 (* 1 = 0.00636944 loss)
I0911 23:51:58.593547 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997543
I0911 23:51:58.593551 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997787
I0911 23:51:58.593559 24730 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0911 23:52:15.248049 24730 solver.cpp:228] Iteration 2240, loss = 0.012278
I0911 23:52:15.248157 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995004
I0911 23:52:15.248173 24730 solver.cpp:244]     Train net output #1: loss = 0.0122781 (* 1 = 0.0122781 loss)
I0911 23:52:15.248181 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992806
I0911 23:52:15.248193 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997211
I0911 23:52:15.248201 24730 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0911 23:52:31.892693 24730 solver.cpp:228] Iteration 2260, loss = 0.00667861
I0911 23:52:31.892731 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997109
I0911 23:52:31.892746 24730 solver.cpp:244]     Train net output #1: loss = 0.0066787 (* 1 = 0.0066787 loss)
I0911 23:52:31.892757 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996532
I0911 23:52:31.892762 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998121
I0911 23:52:31.892771 24730 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0911 23:52:48.551761 24730 solver.cpp:228] Iteration 2280, loss = 0.00635823
I0911 23:52:48.551864 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997718
I0911 23:52:48.551882 24730 solver.cpp:244]     Train net output #1: loss = 0.00635832 (* 1 = 0.00635832 loss)
I0911 23:52:48.551892 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997637
I0911 23:52:48.551897 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997994
I0911 23:52:48.551903 24730 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0911 23:53:05.205245 24730 solver.cpp:228] Iteration 2300, loss = 0.00702925
I0911 23:53:05.205289 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996567
I0911 23:53:05.205302 24730 solver.cpp:244]     Train net output #1: loss = 0.00702934 (* 1 = 0.00702934 loss)
I0911 23:53:05.205317 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994818
I0911 23:53:05.205322 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999199
I0911 23:53:05.205329 24730 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0911 23:53:21.860707 24730 solver.cpp:228] Iteration 2320, loss = 0.0117014
I0911 23:53:21.860843 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996075
I0911 23:53:21.860888 24730 solver.cpp:244]     Train net output #1: loss = 0.0117015 (* 1 = 0.0117015 loss)
I0911 23:53:21.860895 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99186
I0911 23:53:21.860901 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998575
I0911 23:53:21.860910 24730 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0911 23:53:38.526080 24730 solver.cpp:228] Iteration 2340, loss = 0.00679097
I0911 23:53:38.526124 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997468
I0911 23:53:38.526139 24730 solver.cpp:244]     Train net output #1: loss = 0.00679106 (* 1 = 0.00679106 loss)
I0911 23:53:38.526146 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997503
I0911 23:53:38.526154 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997355
I0911 23:53:38.526162 24730 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0911 23:53:55.199782 24730 solver.cpp:228] Iteration 2360, loss = 0.00773804
I0911 23:53:55.199935 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996594
I0911 23:53:55.199954 24730 solver.cpp:244]     Train net output #1: loss = 0.00773814 (* 1 = 0.00773814 loss)
I0911 23:53:55.199965 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995714
I0911 23:53:55.199970 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998192
I0911 23:53:55.199976 24730 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0911 23:54:11.861500 24730 solver.cpp:228] Iteration 2380, loss = 0.0162814
I0911 23:54:11.861537 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993977
I0911 23:54:11.861552 24730 solver.cpp:244]     Train net output #1: loss = 0.0162814 (* 1 = 0.0162814 loss)
I0911 23:54:11.861557 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995179
I0911 23:54:11.861562 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990766
I0911 23:54:11.861569 24730 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0911 23:54:28.508116 24730 solver.cpp:228] Iteration 2400, loss = 0.0137113
I0911 23:54:28.508224 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996238
I0911 23:54:28.508241 24730 solver.cpp:244]     Train net output #1: loss = 0.0137114 (* 1 = 0.0137114 loss)
I0911 23:54:28.508251 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993396
I0911 23:54:28.508256 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997804
I0911 23:54:28.508263 24730 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0911 23:54:45.185284 24730 solver.cpp:228] Iteration 2420, loss = 0.00750928
I0911 23:54:45.185323 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997102
I0911 23:54:45.185338 24730 solver.cpp:244]     Train net output #1: loss = 0.00750937 (* 1 = 0.00750937 loss)
I0911 23:54:45.185344 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997082
I0911 23:54:45.185350 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997146
I0911 23:54:45.185358 24730 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0911 23:55:01.832844 24730 solver.cpp:228] Iteration 2440, loss = 0.00786125
I0911 23:55:01.832955 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996607
I0911 23:55:01.832973 24730 solver.cpp:244]     Train net output #1: loss = 0.00786134 (* 1 = 0.00786134 loss)
I0911 23:55:01.832981 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99596
I0911 23:55:01.832993 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997856
I0911 23:55:01.833001 24730 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0911 23:55:18.486923 24730 solver.cpp:228] Iteration 2460, loss = 0.00554878
I0911 23:55:18.486963 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997937
I0911 23:55:18.486977 24730 solver.cpp:244]     Train net output #1: loss = 0.00554887 (* 1 = 0.00554887 loss)
I0911 23:55:18.486982 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998023
I0911 23:55:18.486989 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997641
I0911 23:55:18.486995 24730 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0911 23:55:35.145560 24730 solver.cpp:228] Iteration 2480, loss = 0.0120184
I0911 23:55:35.145670 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994991
I0911 23:55:35.145689 24730 solver.cpp:244]     Train net output #1: loss = 0.0120185 (* 1 = 0.0120185 loss)
I0911 23:55:35.145700 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994149
I0911 23:55:35.145710 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996506
I0911 23:55:35.145718 24730 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0911 23:55:51.803234 24730 solver.cpp:228] Iteration 2500, loss = 0.0120852
I0911 23:55:51.803272 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995067
I0911 23:55:51.803285 24730 solver.cpp:244]     Train net output #1: loss = 0.0120853 (* 1 = 0.0120853 loss)
I0911 23:55:51.803292 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994594
I0911 23:55:51.803298 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995939
I0911 23:55:51.803305 24730 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0911 23:56:08.474321 24730 solver.cpp:228] Iteration 2520, loss = 0.0132507
I0911 23:56:08.474478 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99513
I0911 23:56:08.474503 24730 solver.cpp:244]     Train net output #1: loss = 0.0132508 (* 1 = 0.0132508 loss)
I0911 23:56:08.474509 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995627
I0911 23:56:08.474514 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994447
I0911 23:56:08.474522 24730 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0911 23:56:25.137488 24730 solver.cpp:228] Iteration 2540, loss = 0.0143119
I0911 23:56:25.137531 24730 solver.cpp:244]     Train net output #0: accuracy = 0.992931
I0911 23:56:25.137545 24730 solver.cpp:244]     Train net output #1: loss = 0.014312 (* 1 = 0.014312 loss)
I0911 23:56:25.137550 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986489
I0911 23:56:25.137555 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999478
I0911 23:56:25.137562 24730 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0911 23:56:41.793778 24730 solver.cpp:228] Iteration 2560, loss = 0.00595026
I0911 23:56:41.793869 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99749
I0911 23:56:41.793885 24730 solver.cpp:244]     Train net output #1: loss = 0.00595034 (* 1 = 0.00595034 loss)
I0911 23:56:41.793891 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997231
I0911 23:56:41.793896 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998247
I0911 23:56:41.793903 24730 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0911 23:56:58.441625 24730 solver.cpp:228] Iteration 2580, loss = 0.0200645
I0911 23:56:58.441669 24730 solver.cpp:244]     Train net output #0: accuracy = 0.991306
I0911 23:56:58.441684 24730 solver.cpp:244]     Train net output #1: loss = 0.0200646 (* 1 = 0.0200646 loss)
I0911 23:56:58.441697 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990271
I0911 23:56:58.441704 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993644
I0911 23:56:58.441711 24730 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0911 23:57:15.099596 24730 solver.cpp:228] Iteration 2600, loss = 0.00743256
I0911 23:57:15.099704 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996963
I0911 23:57:15.099720 24730 solver.cpp:244]     Train net output #1: loss = 0.00743265 (* 1 = 0.00743265 loss)
I0911 23:57:15.099735 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996231
I0911 23:57:15.099745 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998065
I0911 23:57:15.099753 24730 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0911 23:57:31.756120 24730 solver.cpp:228] Iteration 2620, loss = 0.00746398
I0911 23:57:31.756157 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996836
I0911 23:57:31.756171 24730 solver.cpp:244]     Train net output #1: loss = 0.00746407 (* 1 = 0.00746407 loss)
I0911 23:57:31.756178 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995994
I0911 23:57:31.756183 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998175
I0911 23:57:31.756191 24730 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0911 23:57:48.414805 24730 solver.cpp:228] Iteration 2640, loss = 0.00603906
I0911 23:57:48.414940 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997931
I0911 23:57:48.414981 24730 solver.cpp:244]     Train net output #1: loss = 0.00603915 (* 1 = 0.00603915 loss)
I0911 23:57:48.414991 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99833
I0911 23:57:48.415000 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99714
I0911 23:57:48.415010 24730 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0911 23:58:05.104710 24730 solver.cpp:228] Iteration 2660, loss = 0.0124946
I0911 23:58:05.104751 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994708
I0911 23:58:05.104766 24730 solver.cpp:244]     Train net output #1: loss = 0.0124947 (* 1 = 0.0124947 loss)
I0911 23:58:05.104773 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994341
I0911 23:58:05.104777 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995451
I0911 23:58:05.104785 24730 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0911 23:58:21.755601 24730 solver.cpp:228] Iteration 2680, loss = 0.00985799
I0911 23:58:21.755797 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995344
I0911 23:58:21.755841 24730 solver.cpp:244]     Train net output #1: loss = 0.00985808 (* 1 = 0.00985808 loss)
I0911 23:58:21.755852 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992075
I0911 23:58:21.755864 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99878
I0911 23:58:21.755875 24730 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0911 23:58:38.398442 24730 solver.cpp:228] Iteration 2700, loss = 0.00645955
I0911 23:58:38.398483 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997629
I0911 23:58:38.398496 24730 solver.cpp:244]     Train net output #1: loss = 0.00645964 (* 1 = 0.00645964 loss)
I0911 23:58:38.398504 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99644
I0911 23:58:38.398509 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998652
I0911 23:58:38.398516 24730 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0911 23:58:55.056533 24730 solver.cpp:228] Iteration 2720, loss = 0.0106899
I0911 23:58:55.056651 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995521
I0911 23:58:55.056674 24730 solver.cpp:244]     Train net output #1: loss = 0.01069 (* 1 = 0.01069 loss)
I0911 23:58:55.056682 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995174
I0911 23:58:55.056694 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996151
I0911 23:58:55.056704 24730 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0911 23:59:11.715404 24730 solver.cpp:228] Iteration 2740, loss = 0.00490081
I0911 23:59:11.715440 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998471
I0911 23:59:11.715453 24730 solver.cpp:244]     Train net output #1: loss = 0.00490091 (* 1 = 0.00490091 loss)
I0911 23:59:11.715459 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998599
I0911 23:59:11.715464 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997844
I0911 23:59:11.715471 24730 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0911 23:59:28.364847 24730 solver.cpp:228] Iteration 2760, loss = 0.00875243
I0911 23:59:28.364934 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99623
I0911 23:59:28.364950 24730 solver.cpp:244]     Train net output #1: loss = 0.00875252 (* 1 = 0.00875252 loss)
I0911 23:59:28.364964 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994496
I0911 23:59:28.364969 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99826
I0911 23:59:28.364976 24730 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0911 23:59:45.026800 24730 solver.cpp:228] Iteration 2780, loss = 0.00939127
I0911 23:59:45.026844 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996276
I0911 23:59:45.026859 24730 solver.cpp:244]     Train net output #1: loss = 0.00939136 (* 1 = 0.00939136 loss)
I0911 23:59:45.026865 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995357
I0911 23:59:45.026868 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997328
I0911 23:59:45.026876 24730 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0912 00:00:01.690024 24730 solver.cpp:228] Iteration 2800, loss = 0.00556751
I0912 00:00:01.690203 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997841
I0912 00:00:01.690248 24730 solver.cpp:244]     Train net output #1: loss = 0.0055676 (* 1 = 0.0055676 loss)
I0912 00:00:01.690255 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996776
I0912 00:00:01.690265 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998858
I0912 00:00:01.690274 24730 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0912 00:00:18.355254 24730 solver.cpp:228] Iteration 2820, loss = 0.0108303
I0912 00:00:18.355300 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996519
I0912 00:00:18.355315 24730 solver.cpp:244]     Train net output #1: loss = 0.0108304 (* 1 = 0.0108304 loss)
I0912 00:00:18.355322 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993052
I0912 00:00:18.355327 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998574
I0912 00:00:18.355335 24730 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0912 00:00:35.003244 24730 solver.cpp:228] Iteration 2840, loss = 0.00518943
I0912 00:00:35.003334 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997943
I0912 00:00:35.003351 24730 solver.cpp:244]     Train net output #1: loss = 0.00518952 (* 1 = 0.00518952 loss)
I0912 00:00:35.003362 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997119
I0912 00:00:35.003366 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998897
I0912 00:00:35.003373 24730 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0912 00:00:51.647874 24730 solver.cpp:228] Iteration 2860, loss = 0.00890362
I0912 00:00:51.647912 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996742
I0912 00:00:51.647923 24730 solver.cpp:244]     Train net output #1: loss = 0.00890371 (* 1 = 0.00890371 loss)
I0912 00:00:51.647931 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996655
I0912 00:00:51.647943 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996863
I0912 00:00:51.647951 24730 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0912 00:01:08.299484 24730 solver.cpp:228] Iteration 2880, loss = 0.0063196
I0912 00:01:08.299631 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997182
I0912 00:01:08.299674 24730 solver.cpp:244]     Train net output #1: loss = 0.00631969 (* 1 = 0.00631969 loss)
I0912 00:01:08.299682 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996682
I0912 00:01:08.299692 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998506
I0912 00:01:08.299701 24730 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0912 00:01:24.946259 24730 solver.cpp:228] Iteration 2900, loss = 0.00892247
I0912 00:01:24.946301 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996302
I0912 00:01:24.946316 24730 solver.cpp:244]     Train net output #1: loss = 0.00892256 (* 1 = 0.00892256 loss)
I0912 00:01:24.946321 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994337
I0912 00:01:24.946326 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9982
I0912 00:01:24.946333 24730 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0912 00:01:41.605528 24730 solver.cpp:228] Iteration 2920, loss = 0.00470639
I0912 00:01:41.605646 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998108
I0912 00:01:41.605662 24730 solver.cpp:244]     Train net output #1: loss = 0.00470648 (* 1 = 0.00470648 loss)
I0912 00:01:41.605674 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997987
I0912 00:01:41.605687 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998459
I0912 00:01:41.605701 24730 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0912 00:01:58.257505 24730 solver.cpp:228] Iteration 2940, loss = 0.00461582
I0912 00:01:58.257545 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998262
I0912 00:01:58.257560 24730 solver.cpp:244]     Train net output #1: loss = 0.00461591 (* 1 = 0.00461591 loss)
I0912 00:01:58.257566 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998456
I0912 00:01:58.257572 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997912
I0912 00:01:58.257578 24730 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0912 00:02:14.911061 24730 solver.cpp:228] Iteration 2960, loss = 0.00905062
I0912 00:02:14.911226 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995611
I0912 00:02:14.911244 24730 solver.cpp:244]     Train net output #1: loss = 0.0090507 (* 1 = 0.0090507 loss)
I0912 00:02:14.911253 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994446
I0912 00:02:14.911265 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998445
I0912 00:02:14.911273 24730 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0912 00:02:31.561969 24730 solver.cpp:228] Iteration 2980, loss = 0.0063437
I0912 00:02:31.562006 24730 solver.cpp:244]     Train net output #0: accuracy = 0.9974
I0912 00:02:31.562021 24730 solver.cpp:244]     Train net output #1: loss = 0.00634379 (* 1 = 0.00634379 loss)
I0912 00:02:31.562027 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996445
I0912 00:02:31.562032 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998478
I0912 00:02:31.562039 24730 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0912 00:02:48.212980 24730 solver.cpp:228] Iteration 3000, loss = 0.00794277
I0912 00:02:48.213115 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996636
I0912 00:02:48.213158 24730 solver.cpp:244]     Train net output #1: loss = 0.00794286 (* 1 = 0.00794286 loss)
I0912 00:02:48.213166 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996209
I0912 00:02:48.213177 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997508
I0912 00:02:48.213186 24730 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0912 00:03:04.867447 24730 solver.cpp:228] Iteration 3020, loss = 0.00687655
I0912 00:03:04.867492 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998594
I0912 00:03:04.867507 24730 solver.cpp:244]     Train net output #1: loss = 0.00687664 (* 1 = 0.00687664 loss)
I0912 00:03:04.867513 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99869
I0912 00:03:04.867518 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997741
I0912 00:03:04.867527 24730 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0912 00:03:21.519786 24730 solver.cpp:228] Iteration 3040, loss = 0.0119692
I0912 00:03:21.519922 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994297
I0912 00:03:21.519968 24730 solver.cpp:244]     Train net output #1: loss = 0.0119692 (* 1 = 0.0119692 loss)
I0912 00:03:21.519976 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991847
I0912 00:03:21.519982 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997807
I0912 00:03:21.519990 24730 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0912 00:03:38.224072 24730 solver.cpp:228] Iteration 3060, loss = 0.00883472
I0912 00:03:38.224118 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996529
I0912 00:03:38.224133 24730 solver.cpp:244]     Train net output #1: loss = 0.00883481 (* 1 = 0.00883481 loss)
I0912 00:03:38.224139 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99576
I0912 00:03:38.224145 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997496
I0912 00:03:38.224154 24730 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0912 00:03:54.879010 24730 solver.cpp:228] Iteration 3080, loss = 0.00693086
I0912 00:03:54.879117 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996976
I0912 00:03:54.879133 24730 solver.cpp:244]     Train net output #1: loss = 0.00693095 (* 1 = 0.00693095 loss)
I0912 00:03:54.879139 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996625
I0912 00:03:54.879149 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997785
I0912 00:03:54.879158 24730 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0912 00:04:11.525738 24730 solver.cpp:228] Iteration 3100, loss = 0.00959398
I0912 00:04:11.525774 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996684
I0912 00:04:11.525785 24730 solver.cpp:244]     Train net output #1: loss = 0.00959407 (* 1 = 0.00959407 loss)
I0912 00:04:11.525791 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99725
I0912 00:04:11.525796 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993003
I0912 00:04:11.525804 24730 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0912 00:04:28.180047 24730 solver.cpp:228] Iteration 3120, loss = 0.0108913
I0912 00:04:28.180222 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995781
I0912 00:04:28.180240 24730 solver.cpp:244]     Train net output #1: loss = 0.0108914 (* 1 = 0.0108914 loss)
I0912 00:04:28.180248 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996154
I0912 00:04:28.180253 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995148
I0912 00:04:28.180259 24730 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0912 00:04:44.884843 24730 solver.cpp:228] Iteration 3140, loss = 0.00560366
I0912 00:04:44.884884 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997565
I0912 00:04:44.884898 24730 solver.cpp:244]     Train net output #1: loss = 0.00560375 (* 1 = 0.00560375 loss)
I0912 00:04:44.884904 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996933
I0912 00:04:44.884909 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998578
I0912 00:04:44.884918 24730 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0912 00:05:01.545091 24730 solver.cpp:228] Iteration 3160, loss = 0.00636396
I0912 00:05:01.545200 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997496
I0912 00:05:01.545220 24730 solver.cpp:244]     Train net output #1: loss = 0.00636405 (* 1 = 0.00636405 loss)
I0912 00:05:01.545228 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99687
I0912 00:05:01.545239 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998452
I0912 00:05:01.545248 24730 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0912 00:05:18.210224 24730 solver.cpp:228] Iteration 3180, loss = 0.00852896
I0912 00:05:18.210265 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996309
I0912 00:05:18.210280 24730 solver.cpp:244]     Train net output #1: loss = 0.00852905 (* 1 = 0.00852905 loss)
I0912 00:05:18.210294 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993704
I0912 00:05:18.210299 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998668
I0912 00:05:18.210306 24730 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0912 00:05:34.881669 24730 solver.cpp:228] Iteration 3200, loss = 0.00810599
I0912 00:05:34.881783 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996736
I0912 00:05:34.881806 24730 solver.cpp:244]     Train net output #1: loss = 0.00810609 (* 1 = 0.00810609 loss)
I0912 00:05:34.881815 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995665
I0912 00:05:34.881826 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997895
I0912 00:05:34.881834 24730 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0912 00:05:51.545845 24730 solver.cpp:228] Iteration 3220, loss = 0.0108829
I0912 00:05:51.545881 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996289
I0912 00:05:51.545897 24730 solver.cpp:244]     Train net output #1: loss = 0.010883 (* 1 = 0.010883 loss)
I0912 00:05:51.545902 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997314
I0912 00:05:51.545913 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994462
I0912 00:05:51.545920 24730 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0912 00:06:08.197115 24730 solver.cpp:228] Iteration 3240, loss = 0.0050113
I0912 00:06:08.197276 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998071
I0912 00:06:08.197300 24730 solver.cpp:244]     Train net output #1: loss = 0.00501139 (* 1 = 0.00501139 loss)
I0912 00:06:08.197309 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99823
I0912 00:06:08.197314 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997789
I0912 00:06:08.197320 24730 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0912 00:06:24.857314 24730 solver.cpp:228] Iteration 3260, loss = 0.00464299
I0912 00:06:24.857360 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99833
I0912 00:06:24.857383 24730 solver.cpp:244]     Train net output #1: loss = 0.00464308 (* 1 = 0.00464308 loss)
I0912 00:06:24.857389 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998354
I0912 00:06:24.857396 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998227
I0912 00:06:24.857409 24730 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0912 00:06:41.513861 24730 solver.cpp:228] Iteration 3280, loss = 0.0471745
I0912 00:06:41.513972 24730 solver.cpp:244]     Train net output #0: accuracy = 0.986583
I0912 00:06:41.513988 24730 solver.cpp:244]     Train net output #1: loss = 0.0471747 (* 1 = 0.0471747 loss)
I0912 00:06:41.513994 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983473
I0912 00:06:41.513999 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994325
I0912 00:06:41.514006 24730 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0912 00:06:58.172927 24730 solver.cpp:228] Iteration 3300, loss = 0.0170613
I0912 00:06:58.172971 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994893
I0912 00:06:58.172987 24730 solver.cpp:244]     Train net output #1: loss = 0.0170614 (* 1 = 0.0170614 loss)
I0912 00:06:58.173003 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996203
I0912 00:06:58.173014 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992901
I0912 00:06:58.173022 24730 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0912 00:07:14.818469 24730 solver.cpp:228] Iteration 3320, loss = 0.00981885
I0912 00:07:14.818560 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996752
I0912 00:07:14.818578 24730 solver.cpp:244]     Train net output #1: loss = 0.00981896 (* 1 = 0.00981896 loss)
I0912 00:07:14.818583 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994526
I0912 00:07:14.818588 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998601
I0912 00:07:14.818596 24730 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0912 00:07:31.479321 24730 solver.cpp:228] Iteration 3340, loss = 0.0196943
I0912 00:07:31.479358 24730 solver.cpp:244]     Train net output #0: accuracy = 0.990176
I0912 00:07:31.479369 24730 solver.cpp:244]     Train net output #1: loss = 0.0196944 (* 1 = 0.0196944 loss)
I0912 00:07:31.479375 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982182
I0912 00:07:31.479380 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9985
I0912 00:07:31.479387 24730 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0912 00:07:48.148097 24730 solver.cpp:228] Iteration 3360, loss = 0.014457
I0912 00:07:48.148231 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994511
I0912 00:07:48.148272 24730 solver.cpp:244]     Train net output #1: loss = 0.0144571 (* 1 = 0.0144571 loss)
I0912 00:07:48.148282 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99338
I0912 00:07:48.148291 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995974
I0912 00:07:48.148301 24730 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0912 00:08:04.828187 24730 solver.cpp:228] Iteration 3380, loss = 0.00664884
I0912 00:08:04.828233 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997575
I0912 00:08:04.828249 24730 solver.cpp:244]     Train net output #1: loss = 0.00664895 (* 1 = 0.00664895 loss)
I0912 00:08:04.828255 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997857
I0912 00:08:04.828260 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99703
I0912 00:08:04.828269 24730 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0912 00:08:21.512447 24730 solver.cpp:228] Iteration 3400, loss = 0.00902279
I0912 00:08:21.512619 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99583
I0912 00:08:21.512645 24730 solver.cpp:244]     Train net output #1: loss = 0.0090229 (* 1 = 0.0090229 loss)
I0912 00:08:21.512653 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993773
I0912 00:08:21.512665 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998921
I0912 00:08:21.512673 24730 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0912 00:08:38.179702 24730 solver.cpp:228] Iteration 3420, loss = 0.0123854
I0912 00:08:38.179745 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995252
I0912 00:08:38.179760 24730 solver.cpp:244]     Train net output #1: loss = 0.0123855 (* 1 = 0.0123855 loss)
I0912 00:08:38.179767 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993385
I0912 00:08:38.179772 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997424
I0912 00:08:38.179780 24730 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0912 00:08:54.867478 24730 solver.cpp:228] Iteration 3440, loss = 0.00943242
I0912 00:08:54.867594 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995506
I0912 00:08:54.867614 24730 solver.cpp:244]     Train net output #1: loss = 0.00943253 (* 1 = 0.00943253 loss)
I0912 00:08:54.867622 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993964
I0912 00:08:54.867633 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998268
I0912 00:08:54.867643 24730 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0912 00:09:11.524230 24730 solver.cpp:228] Iteration 3460, loss = 0.0189333
I0912 00:09:11.524269 24730 solver.cpp:244]     Train net output #0: accuracy = 0.992739
I0912 00:09:11.524284 24730 solver.cpp:244]     Train net output #1: loss = 0.0189334 (* 1 = 0.0189334 loss)
I0912 00:09:11.524291 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99349
I0912 00:09:11.524296 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989968
I0912 00:09:11.524304 24730 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0912 00:09:28.183140 24730 solver.cpp:228] Iteration 3480, loss = 0.0135072
I0912 00:09:28.183280 24730 solver.cpp:244]     Train net output #0: accuracy = 0.993857
I0912 00:09:28.183321 24730 solver.cpp:244]     Train net output #1: loss = 0.0135073 (* 1 = 0.0135073 loss)
I0912 00:09:28.183329 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991385
I0912 00:09:28.183336 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997365
I0912 00:09:28.183344 24730 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0912 00:09:44.903177 24730 solver.cpp:228] Iteration 3500, loss = 0.0120197
I0912 00:09:44.903226 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994837
I0912 00:09:44.903245 24730 solver.cpp:244]     Train net output #1: loss = 0.0120199 (* 1 = 0.0120199 loss)
I0912 00:09:44.903259 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991642
I0912 00:09:44.903268 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997947
I0912 00:09:44.903278 24730 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0912 00:10:01.615629 24730 solver.cpp:228] Iteration 3520, loss = 0.0057437
I0912 00:10:01.615746 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99769
I0912 00:10:01.615761 24730 solver.cpp:244]     Train net output #1: loss = 0.0057438 (* 1 = 0.0057438 loss)
I0912 00:10:01.615768 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996568
I0912 00:10:01.615773 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998822
I0912 00:10:01.615782 24730 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0912 00:10:18.281257 24730 solver.cpp:228] Iteration 3540, loss = 0.0122128
I0912 00:10:18.281301 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995311
I0912 00:10:18.281316 24730 solver.cpp:244]     Train net output #1: loss = 0.0122129 (* 1 = 0.0122129 loss)
I0912 00:10:18.281322 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990883
I0912 00:10:18.281328 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998248
I0912 00:10:18.281337 24730 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0912 00:10:34.931320 24730 solver.cpp:228] Iteration 3560, loss = 0.00951885
I0912 00:10:34.931478 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996318
I0912 00:10:34.931500 24730 solver.cpp:244]     Train net output #1: loss = 0.00951896 (* 1 = 0.00951896 loss)
I0912 00:10:34.931509 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996301
I0912 00:10:34.931514 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996351
I0912 00:10:34.931520 24730 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0912 00:10:51.597551 24730 solver.cpp:228] Iteration 3580, loss = 0.00873441
I0912 00:10:51.597599 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99696
I0912 00:10:51.597612 24730 solver.cpp:244]     Train net output #1: loss = 0.00873451 (* 1 = 0.00873451 loss)
I0912 00:10:51.597620 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997389
I0912 00:10:51.597625 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996315
I0912 00:10:51.597635 24730 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0912 00:11:08.249004 24730 solver.cpp:228] Iteration 3600, loss = 0.00768337
I0912 00:11:08.249112 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996921
I0912 00:11:08.249127 24730 solver.cpp:244]     Train net output #1: loss = 0.00768348 (* 1 = 0.00768348 loss)
I0912 00:11:08.249140 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996945
I0912 00:11:08.249145 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996855
I0912 00:11:08.249151 24730 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0912 00:11:24.911506 24730 solver.cpp:228] Iteration 3620, loss = 0.0107444
I0912 00:11:24.911551 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996001
I0912 00:11:24.911566 24730 solver.cpp:244]     Train net output #1: loss = 0.0107445 (* 1 = 0.0107445 loss)
I0912 00:11:24.911578 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994613
I0912 00:11:24.911589 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997225
I0912 00:11:24.911597 24730 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0912 00:11:41.567859 24730 solver.cpp:228] Iteration 3640, loss = 0.0099853
I0912 00:11:41.567999 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995922
I0912 00:11:41.568040 24730 solver.cpp:244]     Train net output #1: loss = 0.00998541 (* 1 = 0.00998541 loss)
I0912 00:11:41.568048 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995742
I0912 00:11:41.568058 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996284
I0912 00:11:41.568068 24730 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0912 00:11:58.330037 24730 solver.cpp:228] Iteration 3660, loss = 0.631619
I0912 00:11:58.330080 24730 solver.cpp:244]     Train net output #0: accuracy = 0.941288
I0912 00:11:58.330092 24730 solver.cpp:244]     Train net output #1: loss = 0.631619 (* 1 = 0.631619 loss)
I0912 00:11:58.330098 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.941288
I0912 00:11:58.330104 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0
I0912 00:11:58.330112 24730 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0912 00:12:15.069833 24730 solver.cpp:228] Iteration 3680, loss = 0.007382
I0912 00:12:15.069939 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996681
I0912 00:12:15.069964 24730 solver.cpp:244]     Train net output #1: loss = 0.00738209 (* 1 = 0.00738209 loss)
I0912 00:12:15.069974 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995903
I0912 00:12:15.069984 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998539
I0912 00:12:15.069999 24730 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0912 00:12:31.777283 24730 solver.cpp:228] Iteration 3700, loss = 0.0170723
I0912 00:12:31.777324 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99377
I0912 00:12:31.777339 24730 solver.cpp:244]     Train net output #1: loss = 0.0170723 (* 1 = 0.0170723 loss)
I0912 00:12:31.777345 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987411
I0912 00:12:31.777351 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997747
I0912 00:12:31.777359 24730 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0912 00:12:48.557234 24730 solver.cpp:228] Iteration 3720, loss = 0.00541649
I0912 00:12:48.557399 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997995
I0912 00:12:48.557417 24730 solver.cpp:244]     Train net output #1: loss = 0.00541658 (* 1 = 0.00541658 loss)
I0912 00:12:48.557430 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998094
I0912 00:12:48.557435 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997832
I0912 00:12:48.557445 24730 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0912 00:13:05.215024 24730 solver.cpp:228] Iteration 3740, loss = 0.00584295
I0912 00:13:05.215070 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997996
I0912 00:13:05.215085 24730 solver.cpp:244]     Train net output #1: loss = 0.00584303 (* 1 = 0.00584303 loss)
I0912 00:13:05.215100 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997093
I0912 00:13:05.215111 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998844
I0912 00:13:05.215119 24730 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0912 00:13:21.864677 24730 solver.cpp:228] Iteration 3760, loss = 0.00531317
I0912 00:13:21.864835 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998032
I0912 00:13:21.864877 24730 solver.cpp:244]     Train net output #1: loss = 0.00531326 (* 1 = 0.00531326 loss)
I0912 00:13:21.864887 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998078
I0912 00:13:21.864899 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997846
I0912 00:13:21.864912 24730 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0912 00:13:38.530553 24730 solver.cpp:228] Iteration 3780, loss = 0.00628582
I0912 00:13:38.530596 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998459
I0912 00:13:38.530608 24730 solver.cpp:244]     Train net output #1: loss = 0.00628591 (* 1 = 0.00628591 loss)
I0912 00:13:38.530616 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998921
I0912 00:13:38.530620 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995465
I0912 00:13:38.530627 24730 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0912 00:13:55.193585 24730 solver.cpp:228] Iteration 3800, loss = 0.00950156
I0912 00:13:55.193694 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996241
I0912 00:13:55.193711 24730 solver.cpp:244]     Train net output #1: loss = 0.00950165 (* 1 = 0.00950165 loss)
I0912 00:13:55.193720 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996063
I0912 00:13:55.193732 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996538
I0912 00:13:55.193739 24730 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0912 00:14:11.853323 24730 solver.cpp:228] Iteration 3820, loss = 0.00574358
I0912 00:14:11.853363 24730 solver.cpp:244]     Train net output #0: accuracy = 0.9975
I0912 00:14:11.853385 24730 solver.cpp:244]     Train net output #1: loss = 0.00574367 (* 1 = 0.00574367 loss)
I0912 00:14:11.853391 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997251
I0912 00:14:11.853396 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998189
I0912 00:14:11.853404 24730 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0912 00:14:28.519713 24730 solver.cpp:228] Iteration 3840, loss = 0.0117043
I0912 00:14:28.519886 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995291
I0912 00:14:28.519911 24730 solver.cpp:244]     Train net output #1: loss = 0.0117044 (* 1 = 0.0117044 loss)
I0912 00:14:28.519917 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991425
I0912 00:14:28.519924 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998232
I0912 00:14:28.519937 24730 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0912 00:14:45.161963 24730 solver.cpp:228] Iteration 3860, loss = 0.00293484
I0912 00:14:45.162003 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998844
I0912 00:14:45.162017 24730 solver.cpp:244]     Train net output #1: loss = 0.00293493 (* 1 = 0.00293493 loss)
I0912 00:14:45.162024 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99879
I0912 00:14:45.162029 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998993
I0912 00:14:45.162035 24730 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0912 00:15:01.816583 24730 solver.cpp:228] Iteration 3880, loss = 0.00480096
I0912 00:15:01.816682 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998523
I0912 00:15:01.816699 24730 solver.cpp:244]     Train net output #1: loss = 0.00480105 (* 1 = 0.00480105 loss)
I0912 00:15:01.816706 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998326
I0912 00:15:01.816711 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998732
I0912 00:15:01.816720 24730 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0912 00:15:18.478269 24730 solver.cpp:228] Iteration 3900, loss = 0.00877419
I0912 00:15:18.478317 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997888
I0912 00:15:18.478332 24730 solver.cpp:244]     Train net output #1: loss = 0.00877428 (* 1 = 0.00877428 loss)
I0912 00:15:18.478345 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998294
I0912 00:15:18.478356 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99435
I0912 00:15:18.478365 24730 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0912 00:15:35.139755 24730 solver.cpp:228] Iteration 3920, loss = 0.00682977
I0912 00:15:35.139858 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997156
I0912 00:15:35.139874 24730 solver.cpp:244]     Train net output #1: loss = 0.00682986 (* 1 = 0.00682986 loss)
I0912 00:15:35.139886 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996961
I0912 00:15:35.139891 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997747
I0912 00:15:35.139899 24730 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0912 00:15:51.785262 24730 solver.cpp:228] Iteration 3940, loss = 0.0053027
I0912 00:15:51.785306 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99764
I0912 00:15:51.785322 24730 solver.cpp:244]     Train net output #1: loss = 0.00530279 (* 1 = 0.00530279 loss)
I0912 00:15:51.785329 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997245
I0912 00:15:51.785336 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998734
I0912 00:15:51.785342 24730 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0912 00:16:08.441947 24730 solver.cpp:228] Iteration 3960, loss = 0.00402683
I0912 00:16:08.442046 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998451
I0912 00:16:08.442064 24730 solver.cpp:244]     Train net output #1: loss = 0.00402692 (* 1 = 0.00402692 loss)
I0912 00:16:08.442077 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997816
I0912 00:16:08.442082 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999175
I0912 00:16:08.442090 24730 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0912 00:16:25.102823 24730 solver.cpp:228] Iteration 3980, loss = 0.0121659
I0912 00:16:25.102867 24730 solver.cpp:244]     Train net output #0: accuracy = 0.994959
I0912 00:16:25.102882 24730 solver.cpp:244]     Train net output #1: loss = 0.012166 (* 1 = 0.012166 loss)
I0912 00:16:25.102890 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991871
I0912 00:16:25.102895 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997604
I0912 00:16:25.102903 24730 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0912 00:16:41.760761 24730 solver.cpp:228] Iteration 4000, loss = 0.0101003
I0912 00:16:41.760916 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996079
I0912 00:16:41.760936 24730 solver.cpp:244]     Train net output #1: loss = 0.0101004 (* 1 = 0.0101004 loss)
I0912 00:16:41.760943 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996334
I0912 00:16:41.760948 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995098
I0912 00:16:41.760956 24730 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0912 00:16:58.403777 24730 solver.cpp:228] Iteration 4020, loss = 0.00576167
I0912 00:16:58.403821 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997749
I0912 00:16:58.403836 24730 solver.cpp:244]     Train net output #1: loss = 0.00576176 (* 1 = 0.00576176 loss)
I0912 00:16:58.403843 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99784
I0912 00:16:58.403848 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997473
I0912 00:16:58.403857 24730 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0912 00:17:15.044093 24730 solver.cpp:228] Iteration 4040, loss = 0.0103893
I0912 00:17:15.044203 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995489
I0912 00:17:15.044219 24730 solver.cpp:244]     Train net output #1: loss = 0.0103894 (* 1 = 0.0103894 loss)
I0912 00:17:15.044224 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993247
I0912 00:17:15.044229 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997854
I0912 00:17:15.044236 24730 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0912 00:17:31.703516 24730 solver.cpp:228] Iteration 4060, loss = 0.00730614
I0912 00:17:31.703560 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99697
I0912 00:17:31.703574 24730 solver.cpp:244]     Train net output #1: loss = 0.00730623 (* 1 = 0.00730623 loss)
I0912 00:17:31.703582 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995641
I0912 00:17:31.703588 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998472
I0912 00:17:31.703596 24730 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0912 00:17:48.362659 24730 solver.cpp:228] Iteration 4080, loss = 0.00418024
I0912 00:17:48.362792 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998105
I0912 00:17:48.362836 24730 solver.cpp:244]     Train net output #1: loss = 0.00418033 (* 1 = 0.00418033 loss)
I0912 00:17:48.362846 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997435
I0912 00:17:48.362856 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999223
I0912 00:17:48.362871 24730 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0912 00:18:05.027645 24730 solver.cpp:228] Iteration 4100, loss = 0.00852762
I0912 00:18:05.027688 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996547
I0912 00:18:05.027703 24730 solver.cpp:244]     Train net output #1: loss = 0.00852771 (* 1 = 0.00852771 loss)
I0912 00:18:05.027709 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995331
I0912 00:18:05.027714 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9979
I0912 00:18:05.027721 24730 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0912 00:18:21.705466 24730 solver.cpp:228] Iteration 4120, loss = 0.0084902
I0912 00:18:21.705620 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996188
I0912 00:18:21.705662 24730 solver.cpp:244]     Train net output #1: loss = 0.00849029 (* 1 = 0.00849029 loss)
I0912 00:18:21.705672 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992207
I0912 00:18:21.705682 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999308
I0912 00:18:21.705693 24730 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0912 00:18:38.368971 24730 solver.cpp:228] Iteration 4140, loss = 0.00547838
I0912 00:18:38.369012 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99731
I0912 00:18:38.369026 24730 solver.cpp:244]     Train net output #1: loss = 0.00547847 (* 1 = 0.00547847 loss)
I0912 00:18:38.369035 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99645
I0912 00:18:38.369040 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999203
I0912 00:18:38.369047 24730 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0912 00:18:55.033036 24730 solver.cpp:228] Iteration 4160, loss = 0.0092442
I0912 00:18:55.033197 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995538
I0912 00:18:55.033215 24730 solver.cpp:244]     Train net output #1: loss = 0.00924429 (* 1 = 0.00924429 loss)
I0912 00:18:55.033226 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992418
I0912 00:18:55.033237 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998936
I0912 00:18:55.033246 24730 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0912 00:19:11.700503 24730 solver.cpp:228] Iteration 4180, loss = 0.00751378
I0912 00:19:11.700544 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996568
I0912 00:19:11.700559 24730 solver.cpp:244]     Train net output #1: loss = 0.00751387 (* 1 = 0.00751387 loss)
I0912 00:19:11.700565 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99315
I0912 00:19:11.700570 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999429
I0912 00:19:11.700577 24730 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0912 00:19:28.359839 24730 solver.cpp:228] Iteration 4200, loss = 0.00576224
I0912 00:19:28.359966 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997867
I0912 00:19:28.359987 24730 solver.cpp:244]     Train net output #1: loss = 0.00576233 (* 1 = 0.00576233 loss)
I0912 00:19:28.359994 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997928
I0912 00:19:28.360007 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99778
I0912 00:19:28.360014 24730 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0912 00:19:45.015341 24730 solver.cpp:228] Iteration 4220, loss = 0.00633331
I0912 00:19:45.015381 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997169
I0912 00:19:45.015395 24730 solver.cpp:244]     Train net output #1: loss = 0.0063334 (* 1 = 0.0063334 loss)
I0912 00:19:45.015401 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996314
I0912 00:19:45.015406 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998599
I0912 00:19:45.015413 24730 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0912 00:20:01.668128 24730 solver.cpp:228] Iteration 4240, loss = 0.00557481
I0912 00:20:01.668264 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997694
I0912 00:20:01.668305 24730 solver.cpp:244]     Train net output #1: loss = 0.0055749 (* 1 = 0.0055749 loss)
I0912 00:20:01.668315 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996615
I0912 00:20:01.668325 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999013
I0912 00:20:01.668334 24730 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0912 00:20:18.365705 24730 solver.cpp:228] Iteration 4260, loss = 0.00356126
I0912 00:20:18.365756 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998524
I0912 00:20:18.365772 24730 solver.cpp:244]     Train net output #1: loss = 0.00356135 (* 1 = 0.00356135 loss)
I0912 00:20:18.365779 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998121
I0912 00:20:18.365787 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999165
I0912 00:20:18.365797 24730 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0912 00:20:35.038242 24730 solver.cpp:228] Iteration 4280, loss = 0.00624047
I0912 00:20:35.038352 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997399
I0912 00:20:35.038372 24730 solver.cpp:244]     Train net output #1: loss = 0.00624056 (* 1 = 0.00624056 loss)
I0912 00:20:35.038383 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997225
I0912 00:20:35.038393 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997778
I0912 00:20:35.038403 24730 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0912 00:20:51.685737 24730 solver.cpp:228] Iteration 4300, loss = 0.00758895
I0912 00:20:51.685783 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996646
I0912 00:20:51.685799 24730 solver.cpp:244]     Train net output #1: loss = 0.00758903 (* 1 = 0.00758903 loss)
I0912 00:20:51.685806 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994161
I0912 00:20:51.685812 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998788
I0912 00:20:51.685822 24730 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0912 00:21:08.354846 24730 solver.cpp:228] Iteration 4320, loss = 0.00554623
I0912 00:21:08.354982 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99817
I0912 00:21:08.355020 24730 solver.cpp:244]     Train net output #1: loss = 0.00554632 (* 1 = 0.00554632 loss)
I0912 00:21:08.355028 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998833
I0912 00:21:08.355033 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997084
I0912 00:21:08.355041 24730 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0912 00:21:25.033408 24730 solver.cpp:228] Iteration 4340, loss = 0.00440733
I0912 00:21:25.033455 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998349
I0912 00:21:25.033471 24730 solver.cpp:244]     Train net output #1: loss = 0.00440742 (* 1 = 0.00440742 loss)
I0912 00:21:25.033483 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998393
I0912 00:21:25.033495 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998169
I0912 00:21:25.033504 24730 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0912 00:21:41.715557 24730 solver.cpp:228] Iteration 4360, loss = 0.00677018
I0912 00:21:41.715708 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996819
I0912 00:21:41.715751 24730 solver.cpp:244]     Train net output #1: loss = 0.00677027 (* 1 = 0.00677027 loss)
I0912 00:21:41.715759 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993774
I0912 00:21:41.715770 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999517
I0912 00:21:41.715778 24730 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0912 00:21:58.438314 24730 solver.cpp:228] Iteration 4380, loss = 0.00600306
I0912 00:21:58.438361 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997769
I0912 00:21:58.438376 24730 solver.cpp:244]     Train net output #1: loss = 0.00600315 (* 1 = 0.00600315 loss)
I0912 00:21:58.438383 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998083
I0912 00:21:58.438390 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997029
I0912 00:21:58.438398 24730 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0912 00:22:15.099989 24730 solver.cpp:228] Iteration 4400, loss = 0.00808124
I0912 00:22:15.100098 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99685
I0912 00:22:15.100116 24730 solver.cpp:244]     Train net output #1: loss = 0.00808133 (* 1 = 0.00808133 loss)
I0912 00:22:15.100127 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996611
I0912 00:22:15.100133 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997195
I0912 00:22:15.100144 24730 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0912 00:22:31.742604 24730 solver.cpp:228] Iteration 4420, loss = 0.00503713
I0912 00:22:31.742646 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998112
I0912 00:22:31.742661 24730 solver.cpp:244]     Train net output #1: loss = 0.00503721 (* 1 = 0.00503721 loss)
I0912 00:22:31.742676 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998465
I0912 00:22:31.742688 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997329
I0912 00:22:31.742697 24730 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0912 00:22:48.402889 24730 solver.cpp:228] Iteration 4440, loss = 0.00448218
I0912 00:22:48.403081 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998189
I0912 00:22:48.403126 24730 solver.cpp:244]     Train net output #1: loss = 0.00448227 (* 1 = 0.00448227 loss)
I0912 00:22:48.403134 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997659
I0912 00:22:48.403144 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998797
I0912 00:22:48.403154 24730 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0912 00:23:05.071462 24730 solver.cpp:228] Iteration 4460, loss = 0.0038877
I0912 00:23:05.071503 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998446
I0912 00:23:05.071518 24730 solver.cpp:244]     Train net output #1: loss = 0.00388778 (* 1 = 0.00388778 loss)
I0912 00:23:05.071526 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997525
I0912 00:23:05.071532 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999411
I0912 00:23:05.071540 24730 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0912 00:23:21.719583 24730 solver.cpp:228] Iteration 4480, loss = 0.00437915
I0912 00:23:21.719698 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998409
I0912 00:23:21.719714 24730 solver.cpp:244]     Train net output #1: loss = 0.00437924 (* 1 = 0.00437924 loss)
I0912 00:23:21.719727 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998742
I0912 00:23:21.719739 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997294
I0912 00:23:21.719748 24730 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0912 00:23:38.376457 24730 solver.cpp:228] Iteration 4500, loss = 0.00578055
I0912 00:23:38.376497 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997896
I0912 00:23:38.376512 24730 solver.cpp:244]     Train net output #1: loss = 0.00578063 (* 1 = 0.00578063 loss)
I0912 00:23:38.376518 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998001
I0912 00:23:38.376523 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997251
I0912 00:23:38.376529 24730 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0912 00:23:55.031654 24730 solver.cpp:228] Iteration 4520, loss = 0.00240861
I0912 00:23:55.031767 24730 solver.cpp:244]     Train net output #0: accuracy = 0.999369
I0912 00:23:55.031783 24730 solver.cpp:244]     Train net output #1: loss = 0.00240869 (* 1 = 0.00240869 loss)
I0912 00:23:55.031795 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999322
I0912 00:23:55.031805 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999649
I0912 00:23:55.031814 24730 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0912 00:24:11.687340 24730 solver.cpp:228] Iteration 4540, loss = 0.00591191
I0912 00:24:11.687381 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997491
I0912 00:24:11.687396 24730 solver.cpp:244]     Train net output #1: loss = 0.00591199 (* 1 = 0.00591199 loss)
I0912 00:24:11.687402 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997125
I0912 00:24:11.687407 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998043
I0912 00:24:11.687415 24730 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0912 00:24:28.341325 24730 solver.cpp:228] Iteration 4560, loss = 0.0038117
I0912 00:24:28.341471 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99832
I0912 00:24:28.341512 24730 solver.cpp:244]     Train net output #1: loss = 0.00381179 (* 1 = 0.00381179 loss)
I0912 00:24:28.341523 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997378
I0912 00:24:28.341533 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999413
I0912 00:24:28.341544 24730 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0912 00:24:45.094765 24730 solver.cpp:228] Iteration 4580, loss = 0.00675719
I0912 00:24:45.094811 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997416
I0912 00:24:45.094827 24730 solver.cpp:244]     Train net output #1: loss = 0.00675727 (* 1 = 0.00675727 loss)
I0912 00:24:45.094833 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997726
I0912 00:24:45.094840 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996608
I0912 00:24:45.094847 24730 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0912 00:25:01.833915 24730 solver.cpp:228] Iteration 4600, loss = 0.00703016
I0912 00:25:01.834081 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996995
I0912 00:25:01.834106 24730 solver.cpp:244]     Train net output #1: loss = 0.00703025 (* 1 = 0.00703025 loss)
I0912 00:25:01.834116 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99625
I0912 00:25:01.834127 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998162
I0912 00:25:01.834136 24730 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0912 00:25:18.560174 24730 solver.cpp:228] Iteration 4620, loss = 0.0104634
I0912 00:25:18.560256 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995298
I0912 00:25:18.560286 24730 solver.cpp:244]     Train net output #1: loss = 0.0104635 (* 1 = 0.0104635 loss)
I0912 00:25:18.560300 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991419
I0912 00:25:18.560312 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998706
I0912 00:25:18.560326 24730 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0912 00:25:35.292135 24730 solver.cpp:228] Iteration 4640, loss = 0.00512109
I0912 00:25:35.292228 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998025
I0912 00:25:35.292246 24730 solver.cpp:244]     Train net output #1: loss = 0.00512117 (* 1 = 0.00512117 loss)
I0912 00:25:35.292258 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996953
I0912 00:25:35.292269 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999032
I0912 00:25:35.292284 24730 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0912 00:25:52.024541 24730 solver.cpp:228] Iteration 4660, loss = 0.00378572
I0912 00:25:52.024588 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998433
I0912 00:25:52.024606 24730 solver.cpp:244]     Train net output #1: loss = 0.00378581 (* 1 = 0.00378581 loss)
I0912 00:25:52.024616 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998349
I0912 00:25:52.024622 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998621
I0912 00:25:52.024631 24730 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0912 00:26:08.711169 24730 solver.cpp:228] Iteration 4680, loss = 0.00801537
I0912 00:26:08.711284 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996823
I0912 00:26:08.711302 24730 solver.cpp:244]     Train net output #1: loss = 0.00801545 (* 1 = 0.00801545 loss)
I0912 00:26:08.711309 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994112
I0912 00:26:08.711316 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998866
I0912 00:26:08.711324 24730 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0912 00:26:25.357435 24730 solver.cpp:228] Iteration 4700, loss = 0.00653845
I0912 00:26:25.357493 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997018
I0912 00:26:25.357513 24730 solver.cpp:244]     Train net output #1: loss = 0.00653854 (* 1 = 0.00653854 loss)
I0912 00:26:25.357519 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996011
I0912 00:26:25.357524 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998668
I0912 00:26:25.357532 24730 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0912 00:26:42.019266 24730 solver.cpp:228] Iteration 4720, loss = 0.00654246
I0912 00:26:42.019428 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997737
I0912 00:26:42.019480 24730 solver.cpp:244]     Train net output #1: loss = 0.00654255 (* 1 = 0.00654255 loss)
I0912 00:26:42.019490 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99696
I0912 00:26:42.019501 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998349
I0912 00:26:42.019511 24730 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0912 00:26:58.755347 24730 solver.cpp:228] Iteration 4740, loss = 0.00722255
I0912 00:26:58.755398 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997251
I0912 00:26:58.755424 24730 solver.cpp:244]     Train net output #1: loss = 0.00722263 (* 1 = 0.00722263 loss)
I0912 00:26:58.755434 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994256
I0912 00:26:58.755444 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999216
I0912 00:26:58.755452 24730 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0912 00:27:15.421334 24730 solver.cpp:228] Iteration 4760, loss = 0.00486103
I0912 00:27:15.421509 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998199
I0912 00:27:15.421530 24730 solver.cpp:244]     Train net output #1: loss = 0.00486112 (* 1 = 0.00486112 loss)
I0912 00:27:15.421540 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998361
I0912 00:27:15.421545 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997815
I0912 00:27:15.421556 24730 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0912 00:27:32.088208 24730 solver.cpp:228] Iteration 4780, loss = 0.0124388
I0912 00:27:32.088266 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997847
I0912 00:27:32.088292 24730 solver.cpp:244]     Train net output #1: loss = 0.0124389 (* 1 = 0.0124389 loss)
I0912 00:27:32.088305 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996097
I0912 00:27:32.088325 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998555
I0912 00:27:32.088340 24730 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0912 00:27:48.750804 24730 solver.cpp:228] Iteration 4800, loss = 0.00639019
I0912 00:27:48.750952 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997282
I0912 00:27:48.750996 24730 solver.cpp:244]     Train net output #1: loss = 0.00639028 (* 1 = 0.00639028 loss)
I0912 00:27:48.751006 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996895
I0912 00:27:48.751013 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998274
I0912 00:27:48.751024 24730 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0912 00:28:05.470638 24730 solver.cpp:228] Iteration 4820, loss = 0.00420656
I0912 00:28:05.470685 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998073
I0912 00:28:05.470708 24730 solver.cpp:244]     Train net output #1: loss = 0.00420665 (* 1 = 0.00420665 loss)
I0912 00:28:05.470723 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997242
I0912 00:28:05.470733 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999312
I0912 00:28:05.470742 24730 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0912 00:28:22.204696 24730 solver.cpp:228] Iteration 4840, loss = 0.00472786
I0912 00:28:22.204797 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998002
I0912 00:28:22.204823 24730 solver.cpp:244]     Train net output #1: loss = 0.00472794 (* 1 = 0.00472794 loss)
I0912 00:28:22.204833 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997014
I0912 00:28:22.204844 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99915
I0912 00:28:22.204859 24730 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0912 00:28:38.881361 24730 solver.cpp:228] Iteration 4860, loss = 0.00806699
I0912 00:28:38.881410 24730 solver.cpp:244]     Train net output #0: accuracy = 0.996696
I0912 00:28:38.881425 24730 solver.cpp:244]     Train net output #1: loss = 0.00806708 (* 1 = 0.00806708 loss)
I0912 00:28:38.881433 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996694
I0912 00:28:38.881438 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996698
I0912 00:28:38.881446 24730 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0912 00:28:55.550778 24730 solver.cpp:228] Iteration 4880, loss = 0.00725641
I0912 00:28:55.550956 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997117
I0912 00:28:55.550997 24730 solver.cpp:244]     Train net output #1: loss = 0.0072565 (* 1 = 0.0072565 loss)
I0912 00:28:55.551007 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997171
I0912 00:28:55.551012 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996851
I0912 00:28:55.551019 24730 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0912 00:29:12.188052 24730 solver.cpp:228] Iteration 4900, loss = 0.00497123
I0912 00:29:12.188102 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997912
I0912 00:29:12.188117 24730 solver.cpp:244]     Train net output #1: loss = 0.00497132 (* 1 = 0.00497132 loss)
I0912 00:29:12.188124 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99783
I0912 00:29:12.188130 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998081
I0912 00:29:12.188138 24730 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0912 00:29:28.847213 24730 solver.cpp:228] Iteration 4920, loss = 0.00330889
I0912 00:29:28.847327 24730 solver.cpp:244]     Train net output #0: accuracy = 0.998601
I0912 00:29:28.847345 24730 solver.cpp:244]     Train net output #1: loss = 0.00330898 (* 1 = 0.00330898 loss)
I0912 00:29:28.847357 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997902
I0912 00:29:28.847369 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999379
I0912 00:29:28.847378 24730 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0912 00:29:45.501729 24730 solver.cpp:228] Iteration 4940, loss = 0.00352186
I0912 00:29:45.501768 24730 solver.cpp:244]     Train net output #0: accuracy = 0.99861
I0912 00:29:45.501803 24730 solver.cpp:244]     Train net output #1: loss = 0.00352195 (* 1 = 0.00352195 loss)
I0912 00:29:45.501811 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998623
I0912 00:29:45.501816 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998574
I0912 00:29:45.501822 24730 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0912 00:30:02.154472 24730 solver.cpp:228] Iteration 4960, loss = 0.00598172
I0912 00:30:02.154582 24730 solver.cpp:244]     Train net output #0: accuracy = 0.997461
I0912 00:30:02.154598 24730 solver.cpp:244]     Train net output #1: loss = 0.0059818 (* 1 = 0.0059818 loss)
I0912 00:30:02.154609 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997488
I0912 00:30:02.154619 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997337
I0912 00:30:02.154628 24730 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0912 00:30:18.817554 24730 solver.cpp:228] Iteration 4980, loss = 0.0106292
I0912 00:30:18.817595 24730 solver.cpp:244]     Train net output #0: accuracy = 0.995137
I0912 00:30:18.817608 24730 solver.cpp:244]     Train net output #1: loss = 0.0106293 (* 1 = 0.0106293 loss)
I0912 00:30:18.817615 24730 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992462
I0912 00:30:18.817620 24730 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998172
I0912 00:30:18.817627 24730 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0912 00:30:35.087666 24730 solver.cpp:454] Snapshotting to binary proto file pocwisc1/training_iter_5000.caffemodel
I0912 00:30:35.899286 24730 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc1/training_iter_5000.solverstate
I0912 00:30:36.500110 24730 solver.cpp:317] Iteration 5000, loss = 0.00386075
I0912 00:30:36.500159 24730 solver.cpp:322] Optimization Done.
I0912 00:30:36.500164 24730 caffe.cpp:254] Optimization Done.

2017-09-12 00:30:36,927 log.framework MainThread  INFO       caffe models found
pocwisc1/training_iter_5000.caffemodel
2017-09-12 00:30:36,927 log.framework MainThread  INFO       Caffe model found: pocwisc1/training_iter_5000.caffemodel
2017-09-12 00:30:40,216 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 00:30:40,411 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 00:30:40,553 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 00:30:40,696 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 00:30:40,837 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 00:30:40,979 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 00:30:41,121 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 00:30:41,265 log.framework MainThread  INFO       train file number: 27
2017-09-12 00:30:41,265 log.framework MainThread  INFO       test file number: 6
2017-09-12 00:30:41,266 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 00:30:41,266 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 00:30:41,266 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-09-12 00:30:41,267 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-09-12 00:30:41,267 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-09-12 00:30:41,268 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc2/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc2/training"
solver_mode: GPU

2017-09-12 00:30:41,268 log.framework MainThread  INFO       caffe training step
2017-09-12 00:30:41,268 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc2/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-09-12 01:41:13,488 log.framework MainThread  INFO       I0912 00:30:41.366863 24948 caffe.cpp:217] Using GPUs 0
I0912 00:30:41.378370 24948 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0912 00:30:41.908648 24948 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc2/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc2/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0912 00:30:41.908809 24948 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc2/caffe/model_segnet_final/train.prototxt
I0912 00:30:41.911583 24948 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc2/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 00:30:41.912071 24948 layer_factory.hpp:77] Creating layer data
I0912 00:30:41.912091 24948 net.cpp:100] Creating Layer data
I0912 00:30:41.912101 24948 net.cpp:408] data -> data
I0912 00:30:41.912132 24948 net.cpp:408] data -> label
I0912 00:30:41.912153 24948 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc2/HDF5Files/train_combined.txt
I0912 00:30:41.912210 24948 hdf5_data_layer.cpp:93] Number of HDF5 files: 27
I0912 00:30:41.913383 24948 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0912 00:30:41.938778 24948 net.cpp:150] Setting up data
I0912 00:30:41.938807 24948 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 00:30:41.938822 24948 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 00:30:41.938832 24948 net.cpp:165] Memory required for data: 24883200
I0912 00:30:41.938839 24948 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 00:30:41.938856 24948 net.cpp:100] Creating Layer label_data_1_split
I0912 00:30:41.938863 24948 net.cpp:434] label_data_1_split <- label
I0912 00:30:41.938876 24948 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 00:30:41.938889 24948 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 00:30:41.938930 24948 net.cpp:150] Setting up label_data_1_split
I0912 00:30:41.938936 24948 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 00:30:41.938943 24948 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 00:30:41.938946 24948 net.cpp:165] Memory required for data: 30412800
I0912 00:30:41.938951 24948 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 00:30:41.938969 24948 net.cpp:100] Creating Layer conv1_1_1
I0912 00:30:41.938974 24948 net.cpp:434] conv1_1_1 <- data
I0912 00:30:41.938980 24948 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 00:30:42.533543 24948 net.cpp:150] Setting up conv1_1_1
I0912 00:30:42.533576 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:42.533581 24948 net.cpp:165] Memory required for data: 207360000
I0912 00:30:42.533607 24948 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 00:30:42.533622 24948 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 00:30:42.533629 24948 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 00:30:42.533638 24948 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 00:30:42.534026 24948 net.cpp:150] Setting up conv1_1_1_bn
I0912 00:30:42.534034 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:42.534039 24948 net.cpp:165] Memory required for data: 384307200
I0912 00:30:42.534050 24948 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 00:30:42.534065 24948 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 00:30:42.534070 24948 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 00:30:42.534075 24948 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 00:30:42.534122 24948 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 00:30:42.536033 24948 net.cpp:150] Setting up conv1_1_1_scale
I0912 00:30:42.536049 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:42.536056 24948 net.cpp:165] Memory required for data: 561254400
I0912 00:30:42.536065 24948 layer_factory.hpp:77] Creating layer relu1_1
I0912 00:30:42.536077 24948 net.cpp:100] Creating Layer relu1_1
I0912 00:30:42.536083 24948 net.cpp:434] relu1_1 <- conv1_1_1
I0912 00:30:42.536088 24948 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 00:30:42.536314 24948 net.cpp:150] Setting up relu1_1
I0912 00:30:42.536324 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:42.536329 24948 net.cpp:165] Memory required for data: 738201600
I0912 00:30:42.536334 24948 layer_factory.hpp:77] Creating layer conv1_2
I0912 00:30:42.536345 24948 net.cpp:100] Creating Layer conv1_2
I0912 00:30:42.536350 24948 net.cpp:434] conv1_2 <- conv1_1_1
I0912 00:30:42.536357 24948 net.cpp:408] conv1_2 -> conv1_2
I0912 00:30:42.540876 24948 net.cpp:150] Setting up conv1_2
I0912 00:30:42.540894 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:42.540901 24948 net.cpp:165] Memory required for data: 915148800
I0912 00:30:42.540912 24948 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 00:30:42.540922 24948 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 00:30:42.540930 24948 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 00:30:42.540935 24948 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 00:30:42.542771 24948 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 00:30:42.542788 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:42.542796 24948 net.cpp:165] Memory required for data: 1092096000
I0912 00:30:42.542806 24948 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 00:30:42.542817 24948 net.cpp:100] Creating Layer conv1_2_scale
I0912 00:30:42.542822 24948 net.cpp:434] conv1_2_scale <- conv1_2
I0912 00:30:42.542829 24948 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 00:30:42.542870 24948 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 00:30:42.543241 24948 net.cpp:150] Setting up conv1_2_scale
I0912 00:30:42.543249 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:42.543252 24948 net.cpp:165] Memory required for data: 1269043200
I0912 00:30:42.543260 24948 layer_factory.hpp:77] Creating layer relu1_2
I0912 00:30:42.543267 24948 net.cpp:100] Creating Layer relu1_2
I0912 00:30:42.543272 24948 net.cpp:434] relu1_2 <- conv1_2
I0912 00:30:42.543277 24948 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 00:30:42.543467 24948 net.cpp:150] Setting up relu1_2
I0912 00:30:42.543476 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:42.543481 24948 net.cpp:165] Memory required for data: 1445990400
I0912 00:30:42.543485 24948 layer_factory.hpp:77] Creating layer pool1
I0912 00:30:42.543489 24948 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 00:30:42.543498 24948 net.cpp:100] Creating Layer pool1
I0912 00:30:42.543503 24948 net.cpp:434] pool1 <- conv1_2
I0912 00:30:42.543507 24948 net.cpp:408] pool1 -> pool1
I0912 00:30:42.543517 24948 net.cpp:408] pool1 -> pool1_mask
I0912 00:30:42.543570 24948 net.cpp:150] Setting up pool1
I0912 00:30:42.543577 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:42.543581 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:42.543586 24948 net.cpp:165] Memory required for data: 1534464000
I0912 00:30:42.543589 24948 layer_factory.hpp:77] Creating layer conv2_1
I0912 00:30:42.543598 24948 net.cpp:100] Creating Layer conv2_1
I0912 00:30:42.543603 24948 net.cpp:434] conv2_1 <- pool1
I0912 00:30:42.543609 24948 net.cpp:408] conv2_1 -> conv2_1
I0912 00:30:42.550086 24948 net.cpp:150] Setting up conv2_1
I0912 00:30:42.550102 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:42.550112 24948 net.cpp:165] Memory required for data: 1622937600
I0912 00:30:42.550119 24948 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 00:30:42.550129 24948 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 00:30:42.550137 24948 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 00:30:42.550143 24948 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 00:30:42.550367 24948 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 00:30:42.550375 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:42.550379 24948 net.cpp:165] Memory required for data: 1711411200
I0912 00:30:42.550391 24948 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 00:30:42.550415 24948 net.cpp:100] Creating Layer conv2_1_scale
I0912 00:30:42.550418 24948 net.cpp:434] conv2_1_scale <- conv2_1
I0912 00:30:42.550424 24948 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 00:30:42.550467 24948 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 00:30:42.550635 24948 net.cpp:150] Setting up conv2_1_scale
I0912 00:30:42.550644 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:42.550649 24948 net.cpp:165] Memory required for data: 1799884800
I0912 00:30:42.550657 24948 layer_factory.hpp:77] Creating layer relu2_1
I0912 00:30:42.550663 24948 net.cpp:100] Creating Layer relu2_1
I0912 00:30:42.550668 24948 net.cpp:434] relu2_1 <- conv2_1
I0912 00:30:42.550673 24948 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 00:30:42.551686 24948 net.cpp:150] Setting up relu2_1
I0912 00:30:42.551700 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:42.551705 24948 net.cpp:165] Memory required for data: 1888358400
I0912 00:30:42.551709 24948 layer_factory.hpp:77] Creating layer conv2_2
I0912 00:30:42.551720 24948 net.cpp:100] Creating Layer conv2_2
I0912 00:30:42.551725 24948 net.cpp:434] conv2_2 <- conv2_1
I0912 00:30:42.551733 24948 net.cpp:408] conv2_2 -> conv2_2
I0912 00:30:42.559265 24948 net.cpp:150] Setting up conv2_2
I0912 00:30:42.559281 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:42.559290 24948 net.cpp:165] Memory required for data: 1976832000
I0912 00:30:42.559298 24948 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 00:30:42.559309 24948 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 00:30:42.559316 24948 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 00:30:42.559322 24948 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 00:30:42.559546 24948 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 00:30:42.559556 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:42.559558 24948 net.cpp:165] Memory required for data: 2065305600
I0912 00:30:42.559566 24948 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 00:30:42.559576 24948 net.cpp:100] Creating Layer conv2_2_scale
I0912 00:30:42.559584 24948 net.cpp:434] conv2_2_scale <- conv2_2
I0912 00:30:42.559590 24948 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 00:30:42.559628 24948 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 00:30:42.559798 24948 net.cpp:150] Setting up conv2_2_scale
I0912 00:30:42.559806 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:42.559809 24948 net.cpp:165] Memory required for data: 2153779200
I0912 00:30:42.559816 24948 layer_factory.hpp:77] Creating layer relu2_2
I0912 00:30:42.559823 24948 net.cpp:100] Creating Layer relu2_2
I0912 00:30:42.559828 24948 net.cpp:434] relu2_2 <- conv2_2
I0912 00:30:42.559834 24948 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 00:30:42.560024 24948 net.cpp:150] Setting up relu2_2
I0912 00:30:42.560034 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:42.560039 24948 net.cpp:165] Memory required for data: 2242252800
I0912 00:30:42.560042 24948 layer_factory.hpp:77] Creating layer pool2
I0912 00:30:42.560047 24948 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 00:30:42.560052 24948 net.cpp:100] Creating Layer pool2
I0912 00:30:42.560057 24948 net.cpp:434] pool2 <- conv2_2
I0912 00:30:42.560062 24948 net.cpp:408] pool2 -> pool2
I0912 00:30:42.560071 24948 net.cpp:408] pool2 -> pool2_mask
I0912 00:30:42.560113 24948 net.cpp:150] Setting up pool2
I0912 00:30:42.560120 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:42.560124 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:42.560127 24948 net.cpp:165] Memory required for data: 2286489600
I0912 00:30:42.560130 24948 layer_factory.hpp:77] Creating layer conv3_1
I0912 00:30:42.560140 24948 net.cpp:100] Creating Layer conv3_1
I0912 00:30:42.560145 24948 net.cpp:434] conv3_1 <- pool2
I0912 00:30:42.560151 24948 net.cpp:408] conv3_1 -> conv3_1
I0912 00:30:42.572710 24948 net.cpp:150] Setting up conv3_1
I0912 00:30:42.572741 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.572751 24948 net.cpp:165] Memory required for data: 2330726400
I0912 00:30:42.572758 24948 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 00:30:42.572768 24948 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 00:30:42.572777 24948 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 00:30:42.572782 24948 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 00:30:42.572988 24948 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 00:30:42.572996 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.572999 24948 net.cpp:165] Memory required for data: 2374963200
I0912 00:30:42.573012 24948 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 00:30:42.573020 24948 net.cpp:100] Creating Layer conv3_1_scale
I0912 00:30:42.573029 24948 net.cpp:434] conv3_1_scale <- conv3_1
I0912 00:30:42.573034 24948 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 00:30:42.573074 24948 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 00:30:42.573204 24948 net.cpp:150] Setting up conv3_1_scale
I0912 00:30:42.573212 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.573215 24948 net.cpp:165] Memory required for data: 2419200000
I0912 00:30:42.573222 24948 layer_factory.hpp:77] Creating layer relu3_1
I0912 00:30:42.573230 24948 net.cpp:100] Creating Layer relu3_1
I0912 00:30:42.573235 24948 net.cpp:434] relu3_1 <- conv3_1
I0912 00:30:42.573238 24948 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 00:30:42.573446 24948 net.cpp:150] Setting up relu3_1
I0912 00:30:42.573457 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.573460 24948 net.cpp:165] Memory required for data: 2463436800
I0912 00:30:42.573464 24948 layer_factory.hpp:77] Creating layer conv3_2
I0912 00:30:42.573474 24948 net.cpp:100] Creating Layer conv3_2
I0912 00:30:42.573479 24948 net.cpp:434] conv3_2 <- conv3_1
I0912 00:30:42.573485 24948 net.cpp:408] conv3_2 -> conv3_2
I0912 00:30:42.597832 24948 net.cpp:150] Setting up conv3_2
I0912 00:30:42.597849 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.597858 24948 net.cpp:165] Memory required for data: 2507673600
I0912 00:30:42.597867 24948 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 00:30:42.597877 24948 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 00:30:42.597884 24948 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 00:30:42.597890 24948 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 00:30:42.598101 24948 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 00:30:42.598109 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.598114 24948 net.cpp:165] Memory required for data: 2551910400
I0912 00:30:42.598121 24948 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 00:30:42.598134 24948 net.cpp:100] Creating Layer conv3_2_scale
I0912 00:30:42.598139 24948 net.cpp:434] conv3_2_scale <- conv3_2
I0912 00:30:42.598143 24948 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 00:30:42.598183 24948 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 00:30:42.598316 24948 net.cpp:150] Setting up conv3_2_scale
I0912 00:30:42.598325 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.598327 24948 net.cpp:165] Memory required for data: 2596147200
I0912 00:30:42.598335 24948 layer_factory.hpp:77] Creating layer relu3_2
I0912 00:30:42.598340 24948 net.cpp:100] Creating Layer relu3_2
I0912 00:30:42.598346 24948 net.cpp:434] relu3_2 <- conv3_2
I0912 00:30:42.598351 24948 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 00:30:42.598544 24948 net.cpp:150] Setting up relu3_2
I0912 00:30:42.598553 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.598559 24948 net.cpp:165] Memory required for data: 2640384000
I0912 00:30:42.598563 24948 layer_factory.hpp:77] Creating layer conv3_3
I0912 00:30:42.598573 24948 net.cpp:100] Creating Layer conv3_3
I0912 00:30:42.598578 24948 net.cpp:434] conv3_3 <- conv3_2
I0912 00:30:42.598584 24948 net.cpp:408] conv3_3 -> conv3_3
I0912 00:30:42.622905 24948 net.cpp:150] Setting up conv3_3
I0912 00:30:42.622936 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.622946 24948 net.cpp:165] Memory required for data: 2684620800
I0912 00:30:42.622953 24948 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 00:30:42.622961 24948 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 00:30:42.622968 24948 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 00:30:42.622974 24948 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 00:30:42.623183 24948 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 00:30:42.623191 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.623195 24948 net.cpp:165] Memory required for data: 2728857600
I0912 00:30:42.623203 24948 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 00:30:42.623214 24948 net.cpp:100] Creating Layer conv3_3_scale
I0912 00:30:42.623222 24948 net.cpp:434] conv3_3_scale <- conv3_3
I0912 00:30:42.623227 24948 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 00:30:42.623266 24948 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 00:30:42.623399 24948 net.cpp:150] Setting up conv3_3_scale
I0912 00:30:42.623406 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.623409 24948 net.cpp:165] Memory required for data: 2773094400
I0912 00:30:42.623416 24948 layer_factory.hpp:77] Creating layer relu3_3
I0912 00:30:42.623423 24948 net.cpp:100] Creating Layer relu3_3
I0912 00:30:42.623428 24948 net.cpp:434] relu3_3 <- conv3_3
I0912 00:30:42.623433 24948 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 00:30:42.623626 24948 net.cpp:150] Setting up relu3_3
I0912 00:30:42.623636 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:42.623641 24948 net.cpp:165] Memory required for data: 2817331200
I0912 00:30:42.623644 24948 layer_factory.hpp:77] Creating layer pool3
I0912 00:30:42.623648 24948 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 00:30:42.623658 24948 net.cpp:100] Creating Layer pool3
I0912 00:30:42.623663 24948 net.cpp:434] pool3 <- conv3_3
I0912 00:30:42.623669 24948 net.cpp:408] pool3 -> pool3
I0912 00:30:42.623678 24948 net.cpp:408] pool3 -> pool3_mask
I0912 00:30:42.623723 24948 net.cpp:150] Setting up pool3
I0912 00:30:42.623730 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:42.623735 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:42.623740 24948 net.cpp:165] Memory required for data: 2839449600
I0912 00:30:42.623744 24948 layer_factory.hpp:77] Creating layer conv4_1
I0912 00:30:42.623754 24948 net.cpp:100] Creating Layer conv4_1
I0912 00:30:42.623759 24948 net.cpp:434] conv4_1 <- pool3
I0912 00:30:42.623764 24948 net.cpp:408] conv4_1 -> conv4_1
I0912 00:30:42.672502 24948 net.cpp:150] Setting up conv4_1
I0912 00:30:42.672518 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.672523 24948 net.cpp:165] Memory required for data: 2861568000
I0912 00:30:42.672531 24948 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 00:30:42.672543 24948 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 00:30:42.672551 24948 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 00:30:42.672557 24948 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 00:30:42.672766 24948 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 00:30:42.672775 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.672778 24948 net.cpp:165] Memory required for data: 2883686400
I0912 00:30:42.672786 24948 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 00:30:42.672793 24948 net.cpp:100] Creating Layer conv4_1_scale
I0912 00:30:42.672798 24948 net.cpp:434] conv4_1_scale <- conv4_1
I0912 00:30:42.672804 24948 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 00:30:42.672842 24948 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 00:30:42.672963 24948 net.cpp:150] Setting up conv4_1_scale
I0912 00:30:42.672971 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.672974 24948 net.cpp:165] Memory required for data: 2905804800
I0912 00:30:42.672981 24948 layer_factory.hpp:77] Creating layer relu4_1
I0912 00:30:42.673002 24948 net.cpp:100] Creating Layer relu4_1
I0912 00:30:42.673008 24948 net.cpp:434] relu4_1 <- conv4_1
I0912 00:30:42.673014 24948 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 00:30:42.673219 24948 net.cpp:150] Setting up relu4_1
I0912 00:30:42.673229 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.673234 24948 net.cpp:165] Memory required for data: 2927923200
I0912 00:30:42.673238 24948 layer_factory.hpp:77] Creating layer conv4_2
I0912 00:30:42.673249 24948 net.cpp:100] Creating Layer conv4_2
I0912 00:30:42.673254 24948 net.cpp:434] conv4_2 <- conv4_1
I0912 00:30:42.673261 24948 net.cpp:408] conv4_2 -> conv4_2
I0912 00:30:42.761010 24948 net.cpp:150] Setting up conv4_2
I0912 00:30:42.761027 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.761039 24948 net.cpp:165] Memory required for data: 2950041600
I0912 00:30:42.761046 24948 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 00:30:42.761054 24948 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 00:30:42.761065 24948 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 00:30:42.761071 24948 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 00:30:42.761284 24948 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 00:30:42.761292 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.761296 24948 net.cpp:165] Memory required for data: 2972160000
I0912 00:30:42.761303 24948 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 00:30:42.761312 24948 net.cpp:100] Creating Layer conv4_2_scale
I0912 00:30:42.761320 24948 net.cpp:434] conv4_2_scale <- conv4_2
I0912 00:30:42.761327 24948 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 00:30:42.761380 24948 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 00:30:42.761512 24948 net.cpp:150] Setting up conv4_2_scale
I0912 00:30:42.761520 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.761523 24948 net.cpp:165] Memory required for data: 2994278400
I0912 00:30:42.761530 24948 layer_factory.hpp:77] Creating layer relu4_2
I0912 00:30:42.761538 24948 net.cpp:100] Creating Layer relu4_2
I0912 00:30:42.761543 24948 net.cpp:434] relu4_2 <- conv4_2
I0912 00:30:42.761548 24948 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 00:30:42.762594 24948 net.cpp:150] Setting up relu4_2
I0912 00:30:42.762609 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.762614 24948 net.cpp:165] Memory required for data: 3016396800
I0912 00:30:42.762619 24948 layer_factory.hpp:77] Creating layer conv4_3
I0912 00:30:42.762630 24948 net.cpp:100] Creating Layer conv4_3
I0912 00:30:42.762636 24948 net.cpp:434] conv4_3 <- conv4_2
I0912 00:30:42.762645 24948 net.cpp:408] conv4_3 -> conv4_3
I0912 00:30:42.850519 24948 net.cpp:150] Setting up conv4_3
I0912 00:30:42.850538 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.850541 24948 net.cpp:165] Memory required for data: 3038515200
I0912 00:30:42.850565 24948 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 00:30:42.850575 24948 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 00:30:42.850584 24948 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 00:30:42.850590 24948 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 00:30:42.850806 24948 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 00:30:42.850813 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.850817 24948 net.cpp:165] Memory required for data: 3060633600
I0912 00:30:42.850826 24948 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 00:30:42.850836 24948 net.cpp:100] Creating Layer conv4_3_scale
I0912 00:30:42.850844 24948 net.cpp:434] conv4_3_scale <- conv4_3
I0912 00:30:42.850849 24948 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 00:30:42.850895 24948 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 00:30:42.851030 24948 net.cpp:150] Setting up conv4_3_scale
I0912 00:30:42.851037 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.851042 24948 net.cpp:165] Memory required for data: 3082752000
I0912 00:30:42.851047 24948 layer_factory.hpp:77] Creating layer relu4_3
I0912 00:30:42.851071 24948 net.cpp:100] Creating Layer relu4_3
I0912 00:30:42.851078 24948 net.cpp:434] relu4_3 <- conv4_3
I0912 00:30:42.851083 24948 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 00:30:42.851284 24948 net.cpp:150] Setting up relu4_3
I0912 00:30:42.851292 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:42.851297 24948 net.cpp:165] Memory required for data: 3104870400
I0912 00:30:42.851301 24948 layer_factory.hpp:77] Creating layer pool4
I0912 00:30:42.851306 24948 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 00:30:42.851313 24948 net.cpp:100] Creating Layer pool4
I0912 00:30:42.851318 24948 net.cpp:434] pool4 <- conv4_3
I0912 00:30:42.851325 24948 net.cpp:408] pool4 -> pool4
I0912 00:30:42.851333 24948 net.cpp:408] pool4 -> pool4_mask
I0912 00:30:42.851382 24948 net.cpp:150] Setting up pool4
I0912 00:30:42.851390 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:42.851394 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:42.851399 24948 net.cpp:165] Memory required for data: 3116175360
I0912 00:30:42.851402 24948 layer_factory.hpp:77] Creating layer conv5_1
I0912 00:30:42.851413 24948 net.cpp:100] Creating Layer conv5_1
I0912 00:30:42.851418 24948 net.cpp:434] conv5_1 <- pool4
I0912 00:30:42.851426 24948 net.cpp:408] conv5_1 -> conv5_1
I0912 00:30:42.941936 24948 net.cpp:150] Setting up conv5_1
I0912 00:30:42.941958 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:42.941963 24948 net.cpp:165] Memory required for data: 3121827840
I0912 00:30:42.941974 24948 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 00:30:42.941988 24948 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 00:30:42.941998 24948 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 00:30:42.942009 24948 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 00:30:42.942234 24948 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 00:30:42.942241 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:42.942245 24948 net.cpp:165] Memory required for data: 3127480320
I0912 00:30:42.942255 24948 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 00:30:42.942266 24948 net.cpp:100] Creating Layer conv5_1_scale
I0912 00:30:42.942271 24948 net.cpp:434] conv5_1_scale <- conv5_1
I0912 00:30:42.942277 24948 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 00:30:42.942323 24948 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 00:30:42.942448 24948 net.cpp:150] Setting up conv5_1_scale
I0912 00:30:42.942456 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:42.942458 24948 net.cpp:165] Memory required for data: 3133132800
I0912 00:30:42.942466 24948 layer_factory.hpp:77] Creating layer relu5_1
I0912 00:30:42.942473 24948 net.cpp:100] Creating Layer relu5_1
I0912 00:30:42.942479 24948 net.cpp:434] relu5_1 <- conv5_1
I0912 00:30:42.942484 24948 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 00:30:42.942684 24948 net.cpp:150] Setting up relu5_1
I0912 00:30:42.942693 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:42.942698 24948 net.cpp:165] Memory required for data: 3138785280
I0912 00:30:42.942701 24948 layer_factory.hpp:77] Creating layer conv5_2
I0912 00:30:42.942715 24948 net.cpp:100] Creating Layer conv5_2
I0912 00:30:42.942720 24948 net.cpp:434] conv5_2 <- conv5_1
I0912 00:30:42.942728 24948 net.cpp:408] conv5_2 -> conv5_2
I0912 00:30:43.030544 24948 net.cpp:150] Setting up conv5_2
I0912 00:30:43.030561 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.030565 24948 net.cpp:165] Memory required for data: 3144437760
I0912 00:30:43.030573 24948 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 00:30:43.030582 24948 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 00:30:43.030587 24948 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 00:30:43.030594 24948 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 00:30:43.030808 24948 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 00:30:43.030817 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.030838 24948 net.cpp:165] Memory required for data: 3150090240
I0912 00:30:43.030850 24948 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 00:30:43.030859 24948 net.cpp:100] Creating Layer conv5_2_scale
I0912 00:30:43.030866 24948 net.cpp:434] conv5_2_scale <- conv5_2
I0912 00:30:43.030874 24948 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 00:30:43.030926 24948 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 00:30:43.031049 24948 net.cpp:150] Setting up conv5_2_scale
I0912 00:30:43.031057 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.031062 24948 net.cpp:165] Memory required for data: 3155742720
I0912 00:30:43.031069 24948 layer_factory.hpp:77] Creating layer relu5_2
I0912 00:30:43.031077 24948 net.cpp:100] Creating Layer relu5_2
I0912 00:30:43.031083 24948 net.cpp:434] relu5_2 <- conv5_2
I0912 00:30:43.031088 24948 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 00:30:43.031288 24948 net.cpp:150] Setting up relu5_2
I0912 00:30:43.031297 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.031302 24948 net.cpp:165] Memory required for data: 3161395200
I0912 00:30:43.031306 24948 layer_factory.hpp:77] Creating layer conv5_3
I0912 00:30:43.031321 24948 net.cpp:100] Creating Layer conv5_3
I0912 00:30:43.031325 24948 net.cpp:434] conv5_3 <- conv5_2
I0912 00:30:43.031333 24948 net.cpp:408] conv5_3 -> conv5_3
I0912 00:30:43.119154 24948 net.cpp:150] Setting up conv5_3
I0912 00:30:43.119171 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.119182 24948 net.cpp:165] Memory required for data: 3167047680
I0912 00:30:43.119190 24948 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 00:30:43.119200 24948 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 00:30:43.119207 24948 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 00:30:43.119215 24948 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 00:30:43.119431 24948 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 00:30:43.119439 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.119442 24948 net.cpp:165] Memory required for data: 3172700160
I0912 00:30:43.119453 24948 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 00:30:43.119462 24948 net.cpp:100] Creating Layer conv5_3_scale
I0912 00:30:43.119469 24948 net.cpp:434] conv5_3_scale <- conv5_3
I0912 00:30:43.119475 24948 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 00:30:43.119523 24948 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 00:30:43.119647 24948 net.cpp:150] Setting up conv5_3_scale
I0912 00:30:43.119655 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.119658 24948 net.cpp:165] Memory required for data: 3178352640
I0912 00:30:43.119665 24948 layer_factory.hpp:77] Creating layer relu5_3
I0912 00:30:43.119675 24948 net.cpp:100] Creating Layer relu5_3
I0912 00:30:43.119680 24948 net.cpp:434] relu5_3 <- conv5_3
I0912 00:30:43.119686 24948 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 00:30:43.119889 24948 net.cpp:150] Setting up relu5_3
I0912 00:30:43.119899 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.119904 24948 net.cpp:165] Memory required for data: 3184005120
I0912 00:30:43.119907 24948 layer_factory.hpp:77] Creating layer pool5
I0912 00:30:43.119913 24948 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 00:30:43.119922 24948 net.cpp:100] Creating Layer pool5
I0912 00:30:43.119927 24948 net.cpp:434] pool5 <- conv5_3
I0912 00:30:43.119936 24948 net.cpp:408] pool5 -> pool5
I0912 00:30:43.119946 24948 net.cpp:408] pool5 -> pool5_mask
I0912 00:30:43.119997 24948 net.cpp:150] Setting up pool5
I0912 00:30:43.120003 24948 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 00:30:43.120007 24948 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 00:30:43.120012 24948 net.cpp:165] Memory required for data: 3186954240
I0912 00:30:43.120015 24948 layer_factory.hpp:77] Creating layer upsample5
I0912 00:30:43.120028 24948 net.cpp:100] Creating Layer upsample5
I0912 00:30:43.120033 24948 net.cpp:434] upsample5 <- pool5
I0912 00:30:43.120054 24948 net.cpp:434] upsample5 <- pool5_mask
I0912 00:30:43.120064 24948 net.cpp:408] upsample5 -> pool5_D
I0912 00:30:43.120100 24948 net.cpp:150] Setting up upsample5
I0912 00:30:43.120107 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.120110 24948 net.cpp:165] Memory required for data: 3192606720
I0912 00:30:43.120115 24948 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 00:30:43.120128 24948 net.cpp:100] Creating Layer conv5_3_D
I0912 00:30:43.120133 24948 net.cpp:434] conv5_3_D <- pool5_D
I0912 00:30:43.120141 24948 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 00:30:43.208915 24948 net.cpp:150] Setting up conv5_3_D
I0912 00:30:43.208932 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.208937 24948 net.cpp:165] Memory required for data: 3198259200
I0912 00:30:43.208945 24948 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 00:30:43.208961 24948 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 00:30:43.208968 24948 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 00:30:43.208976 24948 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 00:30:43.209198 24948 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 00:30:43.209206 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.209209 24948 net.cpp:165] Memory required for data: 3203911680
I0912 00:30:43.209218 24948 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 00:30:43.209226 24948 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 00:30:43.209235 24948 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 00:30:43.209241 24948 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 00:30:43.209292 24948 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 00:30:43.209437 24948 net.cpp:150] Setting up conv5_3_D_scale
I0912 00:30:43.209446 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.209450 24948 net.cpp:165] Memory required for data: 3209564160
I0912 00:30:43.209456 24948 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 00:30:43.209465 24948 net.cpp:100] Creating Layer relu5_3_D
I0912 00:30:43.209470 24948 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 00:30:43.209475 24948 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 00:30:43.209686 24948 net.cpp:150] Setting up relu5_3_D
I0912 00:30:43.209694 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.209698 24948 net.cpp:165] Memory required for data: 3215216640
I0912 00:30:43.209704 24948 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 00:30:43.209736 24948 net.cpp:100] Creating Layer conv5_2_D
I0912 00:30:43.209743 24948 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 00:30:43.209749 24948 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 00:30:43.297500 24948 net.cpp:150] Setting up conv5_2_D
I0912 00:30:43.297518 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.297521 24948 net.cpp:165] Memory required for data: 3220869120
I0912 00:30:43.297529 24948 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 00:30:43.297545 24948 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 00:30:43.297554 24948 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 00:30:43.297560 24948 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 00:30:43.297786 24948 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 00:30:43.297794 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.297798 24948 net.cpp:165] Memory required for data: 3226521600
I0912 00:30:43.297807 24948 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 00:30:43.297816 24948 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 00:30:43.297824 24948 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 00:30:43.297830 24948 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 00:30:43.297880 24948 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 00:30:43.298004 24948 net.cpp:150] Setting up conv5_2_D_scale
I0912 00:30:43.298012 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.298015 24948 net.cpp:165] Memory required for data: 3232174080
I0912 00:30:43.298040 24948 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 00:30:43.298048 24948 net.cpp:100] Creating Layer relu5_2_D
I0912 00:30:43.298054 24948 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 00:30:43.298060 24948 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 00:30:43.299137 24948 net.cpp:150] Setting up relu5_2_D
I0912 00:30:43.299152 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.299157 24948 net.cpp:165] Memory required for data: 3237826560
I0912 00:30:43.299163 24948 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 00:30:43.299178 24948 net.cpp:100] Creating Layer conv5_1_D
I0912 00:30:43.299183 24948 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 00:30:43.299192 24948 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 00:30:43.387920 24948 net.cpp:150] Setting up conv5_1_D
I0912 00:30:43.387943 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.387953 24948 net.cpp:165] Memory required for data: 3243479040
I0912 00:30:43.387967 24948 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 00:30:43.387979 24948 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 00:30:43.387989 24948 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 00:30:43.388002 24948 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 00:30:43.388245 24948 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 00:30:43.388253 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.388257 24948 net.cpp:165] Memory required for data: 3249131520
I0912 00:30:43.388264 24948 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 00:30:43.388273 24948 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 00:30:43.388279 24948 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 00:30:43.388285 24948 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 00:30:43.388335 24948 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 00:30:43.388468 24948 net.cpp:150] Setting up conv5_1_D_scale
I0912 00:30:43.388475 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.388479 24948 net.cpp:165] Memory required for data: 3254784000
I0912 00:30:43.388485 24948 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 00:30:43.388494 24948 net.cpp:100] Creating Layer relu5_1_D
I0912 00:30:43.388499 24948 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 00:30:43.388506 24948 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 00:30:43.388710 24948 net.cpp:150] Setting up relu5_1_D
I0912 00:30:43.388720 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:43.388725 24948 net.cpp:165] Memory required for data: 3260436480
I0912 00:30:43.388730 24948 layer_factory.hpp:77] Creating layer upsample4
I0912 00:30:43.388737 24948 net.cpp:100] Creating Layer upsample4
I0912 00:30:43.388742 24948 net.cpp:434] upsample4 <- conv5_1_D
I0912 00:30:43.388751 24948 net.cpp:434] upsample4 <- pool4_mask
I0912 00:30:43.388758 24948 net.cpp:408] upsample4 -> pool4_D
I0912 00:30:43.388793 24948 net.cpp:150] Setting up upsample4
I0912 00:30:43.388800 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.388803 24948 net.cpp:165] Memory required for data: 3282554880
I0912 00:30:43.388808 24948 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 00:30:43.388823 24948 net.cpp:100] Creating Layer conv4_3_D
I0912 00:30:43.388828 24948 net.cpp:434] conv4_3_D <- pool4_D
I0912 00:30:43.388835 24948 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 00:30:43.476837 24948 net.cpp:150] Setting up conv4_3_D
I0912 00:30:43.476855 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.476866 24948 net.cpp:165] Memory required for data: 3304673280
I0912 00:30:43.476874 24948 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 00:30:43.476886 24948 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 00:30:43.476893 24948 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 00:30:43.476902 24948 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 00:30:43.477147 24948 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 00:30:43.477155 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.477177 24948 net.cpp:165] Memory required for data: 3326791680
I0912 00:30:43.477187 24948 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 00:30:43.477195 24948 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 00:30:43.477200 24948 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 00:30:43.477207 24948 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 00:30:43.477254 24948 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 00:30:43.477427 24948 net.cpp:150] Setting up conv4_3_D_scale
I0912 00:30:43.477437 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.477442 24948 net.cpp:165] Memory required for data: 3348910080
I0912 00:30:43.477449 24948 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 00:30:43.477458 24948 net.cpp:100] Creating Layer relu4_3_D
I0912 00:30:43.477464 24948 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 00:30:43.477470 24948 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 00:30:43.477675 24948 net.cpp:150] Setting up relu4_3_D
I0912 00:30:43.477685 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.477690 24948 net.cpp:165] Memory required for data: 3371028480
I0912 00:30:43.477694 24948 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 00:30:43.477706 24948 net.cpp:100] Creating Layer conv4_2_D
I0912 00:30:43.477711 24948 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 00:30:43.477720 24948 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 00:30:43.565706 24948 net.cpp:150] Setting up conv4_2_D
I0912 00:30:43.565724 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.565735 24948 net.cpp:165] Memory required for data: 3393146880
I0912 00:30:43.565743 24948 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 00:30:43.565755 24948 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 00:30:43.565762 24948 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 00:30:43.565770 24948 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 00:30:43.566011 24948 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 00:30:43.566020 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.566022 24948 net.cpp:165] Memory required for data: 3415265280
I0912 00:30:43.566030 24948 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 00:30:43.566040 24948 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 00:30:43.566045 24948 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 00:30:43.566051 24948 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 00:30:43.566097 24948 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 00:30:43.566247 24948 net.cpp:150] Setting up conv4_2_D_scale
I0912 00:30:43.566256 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.566262 24948 net.cpp:165] Memory required for data: 3437383680
I0912 00:30:43.566267 24948 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 00:30:43.566277 24948 net.cpp:100] Creating Layer relu4_2_D
I0912 00:30:43.566282 24948 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 00:30:43.566287 24948 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 00:30:43.566490 24948 net.cpp:150] Setting up relu4_2_D
I0912 00:30:43.566499 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.566504 24948 net.cpp:165] Memory required for data: 3459502080
I0912 00:30:43.566509 24948 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 00:30:43.566521 24948 net.cpp:100] Creating Layer conv4_1_D
I0912 00:30:43.566527 24948 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 00:30:43.566534 24948 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 00:30:43.612484 24948 net.cpp:150] Setting up conv4_1_D
I0912 00:30:43.612501 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:43.612514 24948 net.cpp:165] Memory required for data: 3470561280
I0912 00:30:43.612524 24948 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 00:30:43.612534 24948 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 00:30:43.612543 24948 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 00:30:43.612550 24948 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 00:30:43.612800 24948 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 00:30:43.612824 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:43.612834 24948 net.cpp:165] Memory required for data: 3481620480
I0912 00:30:43.612922 24948 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 00:30:43.612932 24948 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 00:30:43.612937 24948 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 00:30:43.612944 24948 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 00:30:43.612994 24948 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 00:30:43.613137 24948 net.cpp:150] Setting up conv4_1_D_scale
I0912 00:30:43.613145 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:43.613150 24948 net.cpp:165] Memory required for data: 3492679680
I0912 00:30:43.613157 24948 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 00:30:43.613165 24948 net.cpp:100] Creating Layer relu4_1_D
I0912 00:30:43.613169 24948 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 00:30:43.613175 24948 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 00:30:43.613414 24948 net.cpp:150] Setting up relu4_1_D
I0912 00:30:43.613426 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:43.613430 24948 net.cpp:165] Memory required for data: 3503738880
I0912 00:30:43.613433 24948 layer_factory.hpp:77] Creating layer upsample3
I0912 00:30:43.613442 24948 net.cpp:100] Creating Layer upsample3
I0912 00:30:43.613447 24948 net.cpp:434] upsample3 <- conv4_1_D
I0912 00:30:43.613452 24948 net.cpp:434] upsample3 <- pool3_mask
I0912 00:30:43.613461 24948 net.cpp:408] upsample3 -> pool3_D
I0912 00:30:43.613468 24948 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 00:30:43.613503 24948 net.cpp:150] Setting up upsample3
I0912 00:30:43.613510 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.613513 24948 net.cpp:165] Memory required for data: 3547975680
I0912 00:30:43.613518 24948 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 00:30:43.613530 24948 net.cpp:100] Creating Layer conv3_3_D
I0912 00:30:43.613535 24948 net.cpp:434] conv3_3_D <- pool3_D
I0912 00:30:43.613544 24948 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 00:30:43.638118 24948 net.cpp:150] Setting up conv3_3_D
I0912 00:30:43.638134 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.638145 24948 net.cpp:165] Memory required for data: 3592212480
I0912 00:30:43.638155 24948 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 00:30:43.638166 24948 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 00:30:43.638173 24948 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 00:30:43.638180 24948 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 00:30:43.638442 24948 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 00:30:43.638450 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.638453 24948 net.cpp:165] Memory required for data: 3636449280
I0912 00:30:43.638463 24948 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 00:30:43.638470 24948 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 00:30:43.638476 24948 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 00:30:43.638483 24948 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 00:30:43.638530 24948 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 00:30:43.638694 24948 net.cpp:150] Setting up conv3_3_D_scale
I0912 00:30:43.638701 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.638705 24948 net.cpp:165] Memory required for data: 3680686080
I0912 00:30:43.638710 24948 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 00:30:43.638720 24948 net.cpp:100] Creating Layer relu3_3_D
I0912 00:30:43.638725 24948 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 00:30:43.638731 24948 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 00:30:43.638948 24948 net.cpp:150] Setting up relu3_3_D
I0912 00:30:43.638957 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.638960 24948 net.cpp:165] Memory required for data: 3724922880
I0912 00:30:43.638979 24948 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 00:30:43.638994 24948 net.cpp:100] Creating Layer conv3_2_D
I0912 00:30:43.638999 24948 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 00:30:43.639008 24948 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 00:30:43.663547 24948 net.cpp:150] Setting up conv3_2_D
I0912 00:30:43.663563 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.663576 24948 net.cpp:165] Memory required for data: 3769159680
I0912 00:30:43.663586 24948 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 00:30:43.663595 24948 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 00:30:43.663606 24948 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 00:30:43.663614 24948 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 00:30:43.663877 24948 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 00:30:43.663887 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.663889 24948 net.cpp:165] Memory required for data: 3813396480
I0912 00:30:43.663898 24948 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 00:30:43.663910 24948 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 00:30:43.663916 24948 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 00:30:43.663923 24948 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 00:30:43.663971 24948 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 00:30:43.664139 24948 net.cpp:150] Setting up conv3_2_D_scale
I0912 00:30:43.664147 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.664150 24948 net.cpp:165] Memory required for data: 3857633280
I0912 00:30:43.664156 24948 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 00:30:43.664165 24948 net.cpp:100] Creating Layer relu3_2_D
I0912 00:30:43.664170 24948 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 00:30:43.664175 24948 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 00:30:43.665267 24948 net.cpp:150] Setting up relu3_2_D
I0912 00:30:43.665282 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.665287 24948 net.cpp:165] Memory required for data: 3901870080
I0912 00:30:43.665290 24948 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 00:30:43.665304 24948 net.cpp:100] Creating Layer conv3_1_D
I0912 00:30:43.665309 24948 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 00:30:43.665319 24948 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 00:30:43.679733 24948 net.cpp:150] Setting up conv3_1_D
I0912 00:30:43.679749 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:43.679760 24948 net.cpp:165] Memory required for data: 3923988480
I0912 00:30:43.679770 24948 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 00:30:43.679782 24948 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 00:30:43.679788 24948 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 00:30:43.679795 24948 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 00:30:43.680063 24948 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 00:30:43.680070 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:43.680073 24948 net.cpp:165] Memory required for data: 3946106880
I0912 00:30:43.680083 24948 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 00:30:43.680097 24948 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 00:30:43.680102 24948 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 00:30:43.680107 24948 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 00:30:43.680155 24948 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 00:30:43.680321 24948 net.cpp:150] Setting up conv3_1_D_scale
I0912 00:30:43.680330 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:43.680332 24948 net.cpp:165] Memory required for data: 3968225280
I0912 00:30:43.680338 24948 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 00:30:43.680347 24948 net.cpp:100] Creating Layer relu3_1_D
I0912 00:30:43.680352 24948 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 00:30:43.680357 24948 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 00:30:43.680575 24948 net.cpp:150] Setting up relu3_1_D
I0912 00:30:43.680599 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:43.680604 24948 net.cpp:165] Memory required for data: 3990343680
I0912 00:30:43.680608 24948 layer_factory.hpp:77] Creating layer upsample2
I0912 00:30:43.680618 24948 net.cpp:100] Creating Layer upsample2
I0912 00:30:43.680622 24948 net.cpp:434] upsample2 <- conv3_1_D
I0912 00:30:43.680627 24948 net.cpp:434] upsample2 <- pool2_mask
I0912 00:30:43.680636 24948 net.cpp:408] upsample2 -> pool2_D
I0912 00:30:43.680645 24948 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 00:30:43.680680 24948 net.cpp:150] Setting up upsample2
I0912 00:30:43.680686 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.680691 24948 net.cpp:165] Memory required for data: 4078817280
I0912 00:30:43.680696 24948 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 00:30:43.680707 24948 net.cpp:100] Creating Layer conv2_2_D
I0912 00:30:43.680714 24948 net.cpp:434] conv2_2_D <- pool2_D
I0912 00:30:43.680721 24948 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 00:30:43.688587 24948 net.cpp:150] Setting up conv2_2_D
I0912 00:30:43.688606 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.688613 24948 net.cpp:165] Memory required for data: 4167290880
I0912 00:30:43.688622 24948 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 00:30:43.688633 24948 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 00:30:43.688642 24948 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 00:30:43.688648 24948 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 00:30:43.688958 24948 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 00:30:43.688967 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.688971 24948 net.cpp:165] Memory required for data: 4255764480
I0912 00:30:43.688979 24948 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 00:30:43.688988 24948 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 00:30:43.688993 24948 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 00:30:43.688999 24948 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 00:30:43.689049 24948 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 00:30:43.690814 24948 net.cpp:150] Setting up conv2_2_D_scale
I0912 00:30:43.690829 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.690840 24948 net.cpp:165] Memory required for data: 4344238080
I0912 00:30:43.690848 24948 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 00:30:43.690860 24948 net.cpp:100] Creating Layer relu2_2_D
I0912 00:30:43.690865 24948 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 00:30:43.690871 24948 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 00:30:43.691102 24948 net.cpp:150] Setting up relu2_2_D
I0912 00:30:43.691110 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.691114 24948 net.cpp:165] Memory required for data: 4432711680
I0912 00:30:43.691119 24948 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 00:30:43.691133 24948 net.cpp:100] Creating Layer conv2_1_D
I0912 00:30:43.691138 24948 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 00:30:43.691146 24948 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 00:30:43.696494 24948 net.cpp:150] Setting up conv2_1_D
I0912 00:30:43.696511 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:43.696521 24948 net.cpp:165] Memory required for data: 4476948480
I0912 00:30:43.696532 24948 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 00:30:43.696540 24948 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 00:30:43.696549 24948 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 00:30:43.696558 24948 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 00:30:43.696851 24948 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 00:30:43.696862 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:43.696867 24948 net.cpp:165] Memory required for data: 4521185280
I0912 00:30:43.696876 24948 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 00:30:43.696899 24948 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 00:30:43.696904 24948 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 00:30:43.696909 24948 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 00:30:43.696964 24948 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 00:30:43.697186 24948 net.cpp:150] Setting up conv2_1_D_scale
I0912 00:30:43.697194 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:43.697198 24948 net.cpp:165] Memory required for data: 4565422080
I0912 00:30:43.697206 24948 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 00:30:43.697212 24948 net.cpp:100] Creating Layer relu2_1_D
I0912 00:30:43.697219 24948 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 00:30:43.697224 24948 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 00:30:43.697461 24948 net.cpp:150] Setting up relu2_1_D
I0912 00:30:43.697473 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:43.697475 24948 net.cpp:165] Memory required for data: 4609658880
I0912 00:30:43.697480 24948 layer_factory.hpp:77] Creating layer upsample1
I0912 00:30:43.697491 24948 net.cpp:100] Creating Layer upsample1
I0912 00:30:43.697496 24948 net.cpp:434] upsample1 <- conv2_1_D
I0912 00:30:43.697501 24948 net.cpp:434] upsample1 <- pool1_mask
I0912 00:30:43.697510 24948 net.cpp:408] upsample1 -> pool1_D
I0912 00:30:43.697518 24948 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 00:30:43.697552 24948 net.cpp:150] Setting up upsample1
I0912 00:30:43.697559 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.697562 24948 net.cpp:165] Memory required for data: 4786606080
I0912 00:30:43.697566 24948 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 00:30:43.697577 24948 net.cpp:100] Creating Layer conv1_2_D
I0912 00:30:43.697582 24948 net.cpp:434] conv1_2_D <- pool1_D
I0912 00:30:43.697592 24948 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 00:30:43.702374 24948 net.cpp:150] Setting up conv1_2_D
I0912 00:30:43.702390 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.702400 24948 net.cpp:165] Memory required for data: 4963553280
I0912 00:30:43.702407 24948 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 00:30:43.702422 24948 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 00:30:43.702430 24948 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 00:30:43.702435 24948 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 00:30:43.702829 24948 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 00:30:43.702837 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.702841 24948 net.cpp:165] Memory required for data: 5140500480
I0912 00:30:43.702852 24948 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 00:30:43.702859 24948 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 00:30:43.702864 24948 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 00:30:43.702872 24948 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 00:30:43.702921 24948 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 00:30:43.704849 24948 net.cpp:150] Setting up conv1_2_D_scale
I0912 00:30:43.704862 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.704869 24948 net.cpp:165] Memory required for data: 5317447680
I0912 00:30:43.704877 24948 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 00:30:43.704886 24948 net.cpp:100] Creating Layer relu1_2_D
I0912 00:30:43.704891 24948 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 00:30:43.704900 24948 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 00:30:43.705132 24948 net.cpp:150] Setting up relu1_2_D
I0912 00:30:43.705142 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.705147 24948 net.cpp:165] Memory required for data: 5494394880
I0912 00:30:43.705150 24948 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 00:30:43.705165 24948 net.cpp:100] Creating Layer conv1_1_1_D
I0912 00:30:43.705170 24948 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 00:30:43.705195 24948 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 00:30:43.707274 24948 net.cpp:150] Setting up conv1_1_1_D
I0912 00:30:43.707289 24948 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 00:30:43.707295 24948 net.cpp:165] Memory required for data: 5499924480
I0912 00:30:43.707304 24948 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 00:30:43.707314 24948 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 00:30:43.707320 24948 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 00:30:43.707326 24948 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 00:30:43.707335 24948 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 00:30:43.707391 24948 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 00:30:43.707398 24948 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 00:30:43.707402 24948 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 00:30:43.707406 24948 net.cpp:165] Memory required for data: 5510983680
I0912 00:30:43.707411 24948 layer_factory.hpp:77] Creating layer loss
I0912 00:30:43.707422 24948 net.cpp:100] Creating Layer loss
I0912 00:30:43.707427 24948 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 00:30:43.707432 24948 net.cpp:434] loss <- label_data_1_split_0
I0912 00:30:43.707440 24948 net.cpp:408] loss -> loss
I0912 00:30:43.707463 24948 layer_factory.hpp:77] Creating layer loss
I0912 00:30:43.712172 24948 net.cpp:150] Setting up loss
I0912 00:30:43.712188 24948 net.cpp:157] Top shape: (1)
I0912 00:30:43.712198 24948 net.cpp:160]     with loss weight 1
I0912 00:30:43.712235 24948 net.cpp:165] Memory required for data: 5510983684
I0912 00:30:43.712240 24948 layer_factory.hpp:77] Creating layer accuracy
I0912 00:30:43.712252 24948 net.cpp:100] Creating Layer accuracy
I0912 00:30:43.712258 24948 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 00:30:43.712263 24948 net.cpp:434] accuracy <- label_data_1_split_1
I0912 00:30:43.712270 24948 net.cpp:408] accuracy -> accuracy
I0912 00:30:43.712278 24948 net.cpp:408] accuracy -> per_class_accuracy
I0912 00:30:43.712337 24948 net.cpp:150] Setting up accuracy
I0912 00:30:43.712344 24948 net.cpp:157] Top shape: (1)
I0912 00:30:43.712348 24948 net.cpp:157] Top shape: 2 (2)
I0912 00:30:43.712352 24948 net.cpp:165] Memory required for data: 5510983696
I0912 00:30:43.712355 24948 net.cpp:228] accuracy does not need backward computation.
I0912 00:30:43.712360 24948 net.cpp:226] loss needs backward computation.
I0912 00:30:43.712364 24948 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 00:30:43.712368 24948 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 00:30:43.712373 24948 net.cpp:226] relu1_2_D needs backward computation.
I0912 00:30:43.712375 24948 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 00:30:43.712378 24948 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 00:30:43.712381 24948 net.cpp:226] conv1_2_D needs backward computation.
I0912 00:30:43.712384 24948 net.cpp:226] upsample1 needs backward computation.
I0912 00:30:43.712388 24948 net.cpp:226] relu2_1_D needs backward computation.
I0912 00:30:43.712391 24948 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 00:30:43.712393 24948 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 00:30:43.712396 24948 net.cpp:226] conv2_1_D needs backward computation.
I0912 00:30:43.712399 24948 net.cpp:226] relu2_2_D needs backward computation.
I0912 00:30:43.712402 24948 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 00:30:43.712405 24948 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 00:30:43.712409 24948 net.cpp:226] conv2_2_D needs backward computation.
I0912 00:30:43.712412 24948 net.cpp:226] upsample2 needs backward computation.
I0912 00:30:43.712415 24948 net.cpp:226] relu3_1_D needs backward computation.
I0912 00:30:43.712419 24948 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 00:30:43.712436 24948 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 00:30:43.712440 24948 net.cpp:226] conv3_1_D needs backward computation.
I0912 00:30:43.712442 24948 net.cpp:226] relu3_2_D needs backward computation.
I0912 00:30:43.712445 24948 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 00:30:43.712448 24948 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 00:30:43.712451 24948 net.cpp:226] conv3_2_D needs backward computation.
I0912 00:30:43.712455 24948 net.cpp:226] relu3_3_D needs backward computation.
I0912 00:30:43.712457 24948 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 00:30:43.712460 24948 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 00:30:43.712463 24948 net.cpp:226] conv3_3_D needs backward computation.
I0912 00:30:43.712467 24948 net.cpp:226] upsample3 needs backward computation.
I0912 00:30:43.712471 24948 net.cpp:226] relu4_1_D needs backward computation.
I0912 00:30:43.712474 24948 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 00:30:43.712478 24948 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 00:30:43.712481 24948 net.cpp:226] conv4_1_D needs backward computation.
I0912 00:30:43.712484 24948 net.cpp:226] relu4_2_D needs backward computation.
I0912 00:30:43.712488 24948 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 00:30:43.712491 24948 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 00:30:43.712494 24948 net.cpp:226] conv4_2_D needs backward computation.
I0912 00:30:43.712498 24948 net.cpp:226] relu4_3_D needs backward computation.
I0912 00:30:43.712502 24948 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 00:30:43.712505 24948 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 00:30:43.712508 24948 net.cpp:226] conv4_3_D needs backward computation.
I0912 00:30:43.712512 24948 net.cpp:226] upsample4 needs backward computation.
I0912 00:30:43.712517 24948 net.cpp:226] relu5_1_D needs backward computation.
I0912 00:30:43.712522 24948 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 00:30:43.712524 24948 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 00:30:43.712527 24948 net.cpp:226] conv5_1_D needs backward computation.
I0912 00:30:43.712532 24948 net.cpp:226] relu5_2_D needs backward computation.
I0912 00:30:43.712534 24948 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 00:30:43.712538 24948 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 00:30:43.712541 24948 net.cpp:226] conv5_2_D needs backward computation.
I0912 00:30:43.712544 24948 net.cpp:226] relu5_3_D needs backward computation.
I0912 00:30:43.712549 24948 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 00:30:43.712553 24948 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 00:30:43.712556 24948 net.cpp:226] conv5_3_D needs backward computation.
I0912 00:30:43.712560 24948 net.cpp:226] upsample5 needs backward computation.
I0912 00:30:43.712564 24948 net.cpp:226] pool5 needs backward computation.
I0912 00:30:43.712571 24948 net.cpp:226] relu5_3 needs backward computation.
I0912 00:30:43.712576 24948 net.cpp:226] conv5_3_scale needs backward computation.
I0912 00:30:43.712579 24948 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 00:30:43.712584 24948 net.cpp:226] conv5_3 needs backward computation.
I0912 00:30:43.712589 24948 net.cpp:226] relu5_2 needs backward computation.
I0912 00:30:43.712594 24948 net.cpp:226] conv5_2_scale needs backward computation.
I0912 00:30:43.712596 24948 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 00:30:43.712601 24948 net.cpp:226] conv5_2 needs backward computation.
I0912 00:30:43.712606 24948 net.cpp:226] relu5_1 needs backward computation.
I0912 00:30:43.712610 24948 net.cpp:226] conv5_1_scale needs backward computation.
I0912 00:30:43.712615 24948 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 00:30:43.712617 24948 net.cpp:226] conv5_1 needs backward computation.
I0912 00:30:43.712621 24948 net.cpp:226] pool4 needs backward computation.
I0912 00:30:43.712633 24948 net.cpp:226] relu4_3 needs backward computation.
I0912 00:30:43.712636 24948 net.cpp:226] conv4_3_scale needs backward computation.
I0912 00:30:43.712641 24948 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 00:30:43.712644 24948 net.cpp:226] conv4_3 needs backward computation.
I0912 00:30:43.712651 24948 net.cpp:226] relu4_2 needs backward computation.
I0912 00:30:43.712653 24948 net.cpp:226] conv4_2_scale needs backward computation.
I0912 00:30:43.712657 24948 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 00:30:43.712661 24948 net.cpp:226] conv4_2 needs backward computation.
I0912 00:30:43.712666 24948 net.cpp:226] relu4_1 needs backward computation.
I0912 00:30:43.712669 24948 net.cpp:226] conv4_1_scale needs backward computation.
I0912 00:30:43.712672 24948 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 00:30:43.712677 24948 net.cpp:226] conv4_1 needs backward computation.
I0912 00:30:43.712680 24948 net.cpp:226] pool3 needs backward computation.
I0912 00:30:43.712684 24948 net.cpp:226] relu3_3 needs backward computation.
I0912 00:30:43.712687 24948 net.cpp:226] conv3_3_scale needs backward computation.
I0912 00:30:43.712690 24948 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 00:30:43.712694 24948 net.cpp:226] conv3_3 needs backward computation.
I0912 00:30:43.712700 24948 net.cpp:226] relu3_2 needs backward computation.
I0912 00:30:43.712704 24948 net.cpp:226] conv3_2_scale needs backward computation.
I0912 00:30:43.712707 24948 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 00:30:43.712712 24948 net.cpp:226] conv3_2 needs backward computation.
I0912 00:30:43.712716 24948 net.cpp:226] relu3_1 needs backward computation.
I0912 00:30:43.712719 24948 net.cpp:226] conv3_1_scale needs backward computation.
I0912 00:30:43.712723 24948 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 00:30:43.712726 24948 net.cpp:226] conv3_1 needs backward computation.
I0912 00:30:43.712729 24948 net.cpp:226] pool2 needs backward computation.
I0912 00:30:43.712733 24948 net.cpp:226] relu2_2 needs backward computation.
I0912 00:30:43.712738 24948 net.cpp:226] conv2_2_scale needs backward computation.
I0912 00:30:43.712741 24948 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 00:30:43.712745 24948 net.cpp:226] conv2_2 needs backward computation.
I0912 00:30:43.712749 24948 net.cpp:226] relu2_1 needs backward computation.
I0912 00:30:43.712752 24948 net.cpp:226] conv2_1_scale needs backward computation.
I0912 00:30:43.712755 24948 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 00:30:43.712759 24948 net.cpp:226] conv2_1 needs backward computation.
I0912 00:30:43.712764 24948 net.cpp:226] pool1 needs backward computation.
I0912 00:30:43.712769 24948 net.cpp:226] relu1_2 needs backward computation.
I0912 00:30:43.712772 24948 net.cpp:226] conv1_2_scale needs backward computation.
I0912 00:30:43.712775 24948 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 00:30:43.712779 24948 net.cpp:226] conv1_2 needs backward computation.
I0912 00:30:43.712785 24948 net.cpp:226] relu1_1 needs backward computation.
I0912 00:30:43.712788 24948 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 00:30:43.712791 24948 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 00:30:43.712795 24948 net.cpp:226] conv1_1_1 needs backward computation.
I0912 00:30:43.712801 24948 net.cpp:228] label_data_1_split does not need backward computation.
I0912 00:30:43.712807 24948 net.cpp:228] data does not need backward computation.
I0912 00:30:43.712810 24948 net.cpp:270] This network produces output accuracy
I0912 00:30:43.712815 24948 net.cpp:270] This network produces output loss
I0912 00:30:43.712818 24948 net.cpp:270] This network produces output per_class_accuracy
I0912 00:30:43.712884 24948 net.cpp:283] Network initialization done.
I0912 00:30:43.715270 24948 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc2/caffe/model_segnet_final/train.prototxt
I0912 00:30:43.715960 24948 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc2/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 00:30:43.716387 24948 layer_factory.hpp:77] Creating layer data
I0912 00:30:43.716399 24948 net.cpp:100] Creating Layer data
I0912 00:30:43.716405 24948 net.cpp:408] data -> data
I0912 00:30:43.716414 24948 net.cpp:408] data -> label
I0912 00:30:43.716423 24948 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc2/HDF5Files/train_combined.txt
I0912 00:30:43.716464 24948 hdf5_data_layer.cpp:93] Number of HDF5 files: 27
I0912 00:30:43.727835 24948 net.cpp:150] Setting up data
I0912 00:30:43.727852 24948 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 00:30:43.727859 24948 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 00:30:43.727862 24948 net.cpp:165] Memory required for data: 24883200
I0912 00:30:43.727867 24948 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 00:30:43.727877 24948 net.cpp:100] Creating Layer label_data_1_split
I0912 00:30:43.727881 24948 net.cpp:434] label_data_1_split <- label
I0912 00:30:43.727887 24948 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 00:30:43.727896 24948 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 00:30:43.727941 24948 net.cpp:150] Setting up label_data_1_split
I0912 00:30:43.727947 24948 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 00:30:43.727952 24948 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 00:30:43.727962 24948 net.cpp:165] Memory required for data: 30412800
I0912 00:30:43.727965 24948 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 00:30:43.727975 24948 net.cpp:100] Creating Layer conv1_1_1
I0912 00:30:43.727980 24948 net.cpp:434] conv1_1_1 <- data
I0912 00:30:43.727987 24948 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 00:30:43.731762 24948 net.cpp:150] Setting up conv1_1_1
I0912 00:30:43.731781 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.731791 24948 net.cpp:165] Memory required for data: 207360000
I0912 00:30:43.731801 24948 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 00:30:43.731814 24948 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 00:30:43.731823 24948 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 00:30:43.731829 24948 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 00:30:43.732209 24948 net.cpp:150] Setting up conv1_1_1_bn
I0912 00:30:43.732218 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.732221 24948 net.cpp:165] Memory required for data: 384307200
I0912 00:30:43.732234 24948 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 00:30:43.732242 24948 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 00:30:43.732247 24948 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 00:30:43.732251 24948 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 00:30:43.732300 24948 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 00:30:43.734235 24948 net.cpp:150] Setting up conv1_1_1_scale
I0912 00:30:43.734251 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.734261 24948 net.cpp:165] Memory required for data: 561254400
I0912 00:30:43.734268 24948 layer_factory.hpp:77] Creating layer relu1_1
I0912 00:30:43.734279 24948 net.cpp:100] Creating Layer relu1_1
I0912 00:30:43.734284 24948 net.cpp:434] relu1_1 <- conv1_1_1
I0912 00:30:43.734290 24948 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 00:30:43.734524 24948 net.cpp:150] Setting up relu1_1
I0912 00:30:43.734534 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.734539 24948 net.cpp:165] Memory required for data: 738201600
I0912 00:30:43.734544 24948 layer_factory.hpp:77] Creating layer conv1_2
I0912 00:30:43.734552 24948 net.cpp:100] Creating Layer conv1_2
I0912 00:30:43.734557 24948 net.cpp:434] conv1_2 <- conv1_1_1
I0912 00:30:43.734565 24948 net.cpp:408] conv1_2 -> conv1_2
I0912 00:30:43.738732 24948 net.cpp:150] Setting up conv1_2
I0912 00:30:43.738749 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.738757 24948 net.cpp:165] Memory required for data: 915148800
I0912 00:30:43.738787 24948 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 00:30:43.738798 24948 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 00:30:43.738803 24948 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 00:30:43.738808 24948 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 00:30:43.739181 24948 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 00:30:43.739190 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.739193 24948 net.cpp:165] Memory required for data: 1092096000
I0912 00:30:43.739202 24948 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 00:30:43.739210 24948 net.cpp:100] Creating Layer conv1_2_scale
I0912 00:30:43.739215 24948 net.cpp:434] conv1_2_scale <- conv1_2
I0912 00:30:43.739220 24948 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 00:30:43.739269 24948 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 00:30:43.741192 24948 net.cpp:150] Setting up conv1_2_scale
I0912 00:30:43.741207 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.741212 24948 net.cpp:165] Memory required for data: 1269043200
I0912 00:30:43.741220 24948 layer_factory.hpp:77] Creating layer relu1_2
I0912 00:30:43.741228 24948 net.cpp:100] Creating Layer relu1_2
I0912 00:30:43.741233 24948 net.cpp:434] relu1_2 <- conv1_2
I0912 00:30:43.741238 24948 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 00:30:43.742359 24948 net.cpp:150] Setting up relu1_2
I0912 00:30:43.742374 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:43.742380 24948 net.cpp:165] Memory required for data: 1445990400
I0912 00:30:43.742384 24948 layer_factory.hpp:77] Creating layer pool1
I0912 00:30:43.742388 24948 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 00:30:43.742396 24948 net.cpp:100] Creating Layer pool1
I0912 00:30:43.742401 24948 net.cpp:434] pool1 <- conv1_2
I0912 00:30:43.742408 24948 net.cpp:408] pool1 -> pool1
I0912 00:30:43.742415 24948 net.cpp:408] pool1 -> pool1_mask
I0912 00:30:43.742476 24948 net.cpp:150] Setting up pool1
I0912 00:30:43.742485 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:43.742488 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:43.742493 24948 net.cpp:165] Memory required for data: 1534464000
I0912 00:30:43.742496 24948 layer_factory.hpp:77] Creating layer conv2_1
I0912 00:30:43.742506 24948 net.cpp:100] Creating Layer conv2_1
I0912 00:30:43.742511 24948 net.cpp:434] conv2_1 <- pool1
I0912 00:30:43.742521 24948 net.cpp:408] conv2_1 -> conv2_1
I0912 00:30:43.746953 24948 net.cpp:150] Setting up conv2_1
I0912 00:30:43.746970 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.746978 24948 net.cpp:165] Memory required for data: 1622937600
I0912 00:30:43.746986 24948 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 00:30:43.746999 24948 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 00:30:43.747006 24948 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 00:30:43.747011 24948 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 00:30:43.747324 24948 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 00:30:43.747334 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.747336 24948 net.cpp:165] Memory required for data: 1711411200
I0912 00:30:43.747351 24948 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 00:30:43.747359 24948 net.cpp:100] Creating Layer conv2_1_scale
I0912 00:30:43.747364 24948 net.cpp:434] conv2_1_scale <- conv2_1
I0912 00:30:43.747369 24948 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 00:30:43.747422 24948 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 00:30:43.747676 24948 net.cpp:150] Setting up conv2_1_scale
I0912 00:30:43.747684 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.747689 24948 net.cpp:165] Memory required for data: 1799884800
I0912 00:30:43.747694 24948 layer_factory.hpp:77] Creating layer relu2_1
I0912 00:30:43.747701 24948 net.cpp:100] Creating Layer relu2_1
I0912 00:30:43.747707 24948 net.cpp:434] relu2_1 <- conv2_1
I0912 00:30:43.747714 24948 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 00:30:43.748847 24948 net.cpp:150] Setting up relu2_1
I0912 00:30:43.748860 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.748865 24948 net.cpp:165] Memory required for data: 1888358400
I0912 00:30:43.748869 24948 layer_factory.hpp:77] Creating layer conv2_2
I0912 00:30:43.748883 24948 net.cpp:100] Creating Layer conv2_2
I0912 00:30:43.748888 24948 net.cpp:434] conv2_2 <- conv2_1
I0912 00:30:43.748898 24948 net.cpp:408] conv2_2 -> conv2_2
I0912 00:30:43.758364 24948 net.cpp:150] Setting up conv2_2
I0912 00:30:43.758380 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.758390 24948 net.cpp:165] Memory required for data: 1976832000
I0912 00:30:43.758399 24948 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 00:30:43.758412 24948 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 00:30:43.758419 24948 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 00:30:43.758427 24948 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 00:30:43.760224 24948 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 00:30:43.760238 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.760247 24948 net.cpp:165] Memory required for data: 2065305600
I0912 00:30:43.760257 24948 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 00:30:43.760267 24948 net.cpp:100] Creating Layer conv2_2_scale
I0912 00:30:43.760274 24948 net.cpp:434] conv2_2_scale <- conv2_2
I0912 00:30:43.760280 24948 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 00:30:43.760339 24948 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 00:30:43.760555 24948 net.cpp:150] Setting up conv2_2_scale
I0912 00:30:43.760563 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.760567 24948 net.cpp:165] Memory required for data: 2153779200
I0912 00:30:43.760573 24948 layer_factory.hpp:77] Creating layer relu2_2
I0912 00:30:43.760581 24948 net.cpp:100] Creating Layer relu2_2
I0912 00:30:43.760586 24948 net.cpp:434] relu2_2 <- conv2_2
I0912 00:30:43.760593 24948 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 00:30:43.760823 24948 net.cpp:150] Setting up relu2_2
I0912 00:30:43.760833 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:43.760838 24948 net.cpp:165] Memory required for data: 2242252800
I0912 00:30:43.760840 24948 layer_factory.hpp:77] Creating layer pool2
I0912 00:30:43.760846 24948 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 00:30:43.760852 24948 net.cpp:100] Creating Layer pool2
I0912 00:30:43.760859 24948 net.cpp:434] pool2 <- conv2_2
I0912 00:30:43.760865 24948 net.cpp:408] pool2 -> pool2
I0912 00:30:43.760872 24948 net.cpp:408] pool2 -> pool2_mask
I0912 00:30:43.760931 24948 net.cpp:150] Setting up pool2
I0912 00:30:43.760938 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:43.760942 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:43.760946 24948 net.cpp:165] Memory required for data: 2286489600
I0912 00:30:43.760949 24948 layer_factory.hpp:77] Creating layer conv3_1
I0912 00:30:43.760962 24948 net.cpp:100] Creating Layer conv3_1
I0912 00:30:43.760967 24948 net.cpp:434] conv3_1 <- pool2
I0912 00:30:43.760974 24948 net.cpp:408] conv3_1 -> conv3_1
I0912 00:30:43.773834 24948 net.cpp:150] Setting up conv3_1
I0912 00:30:43.773850 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.773854 24948 net.cpp:165] Memory required for data: 2330726400
I0912 00:30:43.773862 24948 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 00:30:43.773872 24948 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 00:30:43.773876 24948 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 00:30:43.773882 24948 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 00:30:43.774163 24948 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 00:30:43.774173 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.774175 24948 net.cpp:165] Memory required for data: 2374963200
I0912 00:30:43.774194 24948 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 00:30:43.774217 24948 net.cpp:100] Creating Layer conv3_1_scale
I0912 00:30:43.774225 24948 net.cpp:434] conv3_1_scale <- conv3_1
I0912 00:30:43.774230 24948 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 00:30:43.774293 24948 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 00:30:43.774473 24948 net.cpp:150] Setting up conv3_1_scale
I0912 00:30:43.774482 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.774485 24948 net.cpp:165] Memory required for data: 2419200000
I0912 00:30:43.774492 24948 layer_factory.hpp:77] Creating layer relu3_1
I0912 00:30:43.774502 24948 net.cpp:100] Creating Layer relu3_1
I0912 00:30:43.774507 24948 net.cpp:434] relu3_1 <- conv3_1
I0912 00:30:43.774511 24948 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 00:30:43.774739 24948 net.cpp:150] Setting up relu3_1
I0912 00:30:43.774749 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.774751 24948 net.cpp:165] Memory required for data: 2463436800
I0912 00:30:43.774755 24948 layer_factory.hpp:77] Creating layer conv3_2
I0912 00:30:43.774771 24948 net.cpp:100] Creating Layer conv3_2
I0912 00:30:43.774776 24948 net.cpp:434] conv3_2 <- conv3_1
I0912 00:30:43.774783 24948 net.cpp:408] conv3_2 -> conv3_2
I0912 00:30:43.799365 24948 net.cpp:150] Setting up conv3_2
I0912 00:30:43.799381 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.799391 24948 net.cpp:165] Memory required for data: 2507673600
I0912 00:30:43.799399 24948 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 00:30:43.799412 24948 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 00:30:43.799419 24948 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 00:30:43.799427 24948 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 00:30:43.799708 24948 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 00:30:43.799717 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.799721 24948 net.cpp:165] Memory required for data: 2551910400
I0912 00:30:43.799729 24948 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 00:30:43.799738 24948 net.cpp:100] Creating Layer conv3_2_scale
I0912 00:30:43.799743 24948 net.cpp:434] conv3_2_scale <- conv3_2
I0912 00:30:43.799749 24948 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 00:30:43.799806 24948 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 00:30:43.799985 24948 net.cpp:150] Setting up conv3_2_scale
I0912 00:30:43.799993 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.799996 24948 net.cpp:165] Memory required for data: 2596147200
I0912 00:30:43.800004 24948 layer_factory.hpp:77] Creating layer relu3_2
I0912 00:30:43.800010 24948 net.cpp:100] Creating Layer relu3_2
I0912 00:30:43.800015 24948 net.cpp:434] relu3_2 <- conv3_2
I0912 00:30:43.800024 24948 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 00:30:43.800246 24948 net.cpp:150] Setting up relu3_2
I0912 00:30:43.800256 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.800259 24948 net.cpp:165] Memory required for data: 2640384000
I0912 00:30:43.800263 24948 layer_factory.hpp:77] Creating layer conv3_3
I0912 00:30:43.800276 24948 net.cpp:100] Creating Layer conv3_3
I0912 00:30:43.800281 24948 net.cpp:434] conv3_3 <- conv3_2
I0912 00:30:43.800289 24948 net.cpp:408] conv3_3 -> conv3_3
I0912 00:30:43.824826 24948 net.cpp:150] Setting up conv3_3
I0912 00:30:43.824841 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.824851 24948 net.cpp:165] Memory required for data: 2684620800
I0912 00:30:43.824859 24948 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 00:30:43.824869 24948 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 00:30:43.824879 24948 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 00:30:43.824887 24948 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 00:30:43.825175 24948 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 00:30:43.825183 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.825186 24948 net.cpp:165] Memory required for data: 2728857600
I0912 00:30:43.825196 24948 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 00:30:43.825218 24948 net.cpp:100] Creating Layer conv3_3_scale
I0912 00:30:43.825223 24948 net.cpp:434] conv3_3_scale <- conv3_3
I0912 00:30:43.825228 24948 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 00:30:43.825284 24948 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 00:30:43.825480 24948 net.cpp:150] Setting up conv3_3_scale
I0912 00:30:43.825489 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.825492 24948 net.cpp:165] Memory required for data: 2773094400
I0912 00:30:43.825500 24948 layer_factory.hpp:77] Creating layer relu3_3
I0912 00:30:43.825510 24948 net.cpp:100] Creating Layer relu3_3
I0912 00:30:43.825515 24948 net.cpp:434] relu3_3 <- conv3_3
I0912 00:30:43.825520 24948 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 00:30:43.825749 24948 net.cpp:150] Setting up relu3_3
I0912 00:30:43.825759 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:43.825764 24948 net.cpp:165] Memory required for data: 2817331200
I0912 00:30:43.825768 24948 layer_factory.hpp:77] Creating layer pool3
I0912 00:30:43.825773 24948 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 00:30:43.825783 24948 net.cpp:100] Creating Layer pool3
I0912 00:30:43.825788 24948 net.cpp:434] pool3 <- conv3_3
I0912 00:30:43.825795 24948 net.cpp:408] pool3 -> pool3
I0912 00:30:43.825804 24948 net.cpp:408] pool3 -> pool3_mask
I0912 00:30:43.825863 24948 net.cpp:150] Setting up pool3
I0912 00:30:43.825870 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:43.825875 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:43.825878 24948 net.cpp:165] Memory required for data: 2839449600
I0912 00:30:43.825881 24948 layer_factory.hpp:77] Creating layer conv4_1
I0912 00:30:43.825896 24948 net.cpp:100] Creating Layer conv4_1
I0912 00:30:43.825901 24948 net.cpp:434] conv4_1 <- pool3
I0912 00:30:43.825907 24948 net.cpp:408] conv4_1 -> conv4_1
I0912 00:30:43.873636 24948 net.cpp:150] Setting up conv4_1
I0912 00:30:43.873654 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.873658 24948 net.cpp:165] Memory required for data: 2861568000
I0912 00:30:43.873668 24948 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 00:30:43.873687 24948 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 00:30:43.873695 24948 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 00:30:43.873709 24948 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 00:30:43.873993 24948 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 00:30:43.874002 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.874006 24948 net.cpp:165] Memory required for data: 2883686400
I0912 00:30:43.874013 24948 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 00:30:43.874027 24948 net.cpp:100] Creating Layer conv4_1_scale
I0912 00:30:43.874033 24948 net.cpp:434] conv4_1_scale <- conv4_1
I0912 00:30:43.874038 24948 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 00:30:43.874086 24948 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 00:30:43.874253 24948 net.cpp:150] Setting up conv4_1_scale
I0912 00:30:43.874263 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.874265 24948 net.cpp:165] Memory required for data: 2905804800
I0912 00:30:43.874271 24948 layer_factory.hpp:77] Creating layer relu4_1
I0912 00:30:43.874280 24948 net.cpp:100] Creating Layer relu4_1
I0912 00:30:43.874285 24948 net.cpp:434] relu4_1 <- conv4_1
I0912 00:30:43.874289 24948 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 00:30:43.875437 24948 net.cpp:150] Setting up relu4_1
I0912 00:30:43.875452 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.875457 24948 net.cpp:165] Memory required for data: 2927923200
I0912 00:30:43.875460 24948 layer_factory.hpp:77] Creating layer conv4_2
I0912 00:30:43.875478 24948 net.cpp:100] Creating Layer conv4_2
I0912 00:30:43.875483 24948 net.cpp:434] conv4_2 <- conv4_1
I0912 00:30:43.875491 24948 net.cpp:408] conv4_2 -> conv4_2
I0912 00:30:43.962054 24948 net.cpp:150] Setting up conv4_2
I0912 00:30:43.962086 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.962091 24948 net.cpp:165] Memory required for data: 2950041600
I0912 00:30:43.962100 24948 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 00:30:43.962116 24948 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 00:30:43.962122 24948 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 00:30:43.962128 24948 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 00:30:43.962409 24948 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 00:30:43.962417 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.962420 24948 net.cpp:165] Memory required for data: 2972160000
I0912 00:30:43.962430 24948 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 00:30:43.962440 24948 net.cpp:100] Creating Layer conv4_2_scale
I0912 00:30:43.962445 24948 net.cpp:434] conv4_2_scale <- conv4_2
I0912 00:30:43.962450 24948 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 00:30:43.962505 24948 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 00:30:43.962672 24948 net.cpp:150] Setting up conv4_2_scale
I0912 00:30:43.962679 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.962683 24948 net.cpp:165] Memory required for data: 2994278400
I0912 00:30:43.962689 24948 layer_factory.hpp:77] Creating layer relu4_2
I0912 00:30:43.962698 24948 net.cpp:100] Creating Layer relu4_2
I0912 00:30:43.962703 24948 net.cpp:434] relu4_2 <- conv4_2
I0912 00:30:43.962710 24948 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 00:30:43.963867 24948 net.cpp:150] Setting up relu4_2
I0912 00:30:43.963881 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:43.963886 24948 net.cpp:165] Memory required for data: 3016396800
I0912 00:30:43.963891 24948 layer_factory.hpp:77] Creating layer conv4_3
I0912 00:30:43.963907 24948 net.cpp:100] Creating Layer conv4_3
I0912 00:30:43.963913 24948 net.cpp:434] conv4_3 <- conv4_2
I0912 00:30:43.963922 24948 net.cpp:408] conv4_3 -> conv4_3
I0912 00:30:44.051518 24948 net.cpp:150] Setting up conv4_3
I0912 00:30:44.051535 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.051539 24948 net.cpp:165] Memory required for data: 3038515200
I0912 00:30:44.051568 24948 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 00:30:44.051580 24948 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 00:30:44.051587 24948 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 00:30:44.051594 24948 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 00:30:44.051872 24948 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 00:30:44.051880 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.051883 24948 net.cpp:165] Memory required for data: 3060633600
I0912 00:30:44.051892 24948 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 00:30:44.051899 24948 net.cpp:100] Creating Layer conv4_3_scale
I0912 00:30:44.051908 24948 net.cpp:434] conv4_3_scale <- conv4_3
I0912 00:30:44.051913 24948 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 00:30:44.051970 24948 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 00:30:44.052135 24948 net.cpp:150] Setting up conv4_3_scale
I0912 00:30:44.052144 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.052147 24948 net.cpp:165] Memory required for data: 3082752000
I0912 00:30:44.052153 24948 layer_factory.hpp:77] Creating layer relu4_3
I0912 00:30:44.052165 24948 net.cpp:100] Creating Layer relu4_3
I0912 00:30:44.052170 24948 net.cpp:434] relu4_3 <- conv4_3
I0912 00:30:44.052173 24948 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 00:30:44.052400 24948 net.cpp:150] Setting up relu4_3
I0912 00:30:44.052409 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.052417 24948 net.cpp:165] Memory required for data: 3104870400
I0912 00:30:44.052420 24948 layer_factory.hpp:77] Creating layer pool4
I0912 00:30:44.052425 24948 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 00:30:44.052431 24948 net.cpp:100] Creating Layer pool4
I0912 00:30:44.052436 24948 net.cpp:434] pool4 <- conv4_3
I0912 00:30:44.052459 24948 net.cpp:408] pool4 -> pool4
I0912 00:30:44.052467 24948 net.cpp:408] pool4 -> pool4_mask
I0912 00:30:44.052530 24948 net.cpp:150] Setting up pool4
I0912 00:30:44.052536 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.052541 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.052544 24948 net.cpp:165] Memory required for data: 3116175360
I0912 00:30:44.052548 24948 layer_factory.hpp:77] Creating layer conv5_1
I0912 00:30:44.052563 24948 net.cpp:100] Creating Layer conv5_1
I0912 00:30:44.052568 24948 net.cpp:434] conv5_1 <- pool4
I0912 00:30:44.052577 24948 net.cpp:408] conv5_1 -> conv5_1
I0912 00:30:44.140077 24948 net.cpp:150] Setting up conv5_1
I0912 00:30:44.140094 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.140099 24948 net.cpp:165] Memory required for data: 3121827840
I0912 00:30:44.140106 24948 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 00:30:44.140116 24948 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 00:30:44.140120 24948 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 00:30:44.140126 24948 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 00:30:44.140408 24948 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 00:30:44.140416 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.140420 24948 net.cpp:165] Memory required for data: 3127480320
I0912 00:30:44.140431 24948 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 00:30:44.140439 24948 net.cpp:100] Creating Layer conv5_1_scale
I0912 00:30:44.140447 24948 net.cpp:434] conv5_1_scale <- conv5_1
I0912 00:30:44.140453 24948 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 00:30:44.140516 24948 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 00:30:44.140672 24948 net.cpp:150] Setting up conv5_1_scale
I0912 00:30:44.140681 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.140683 24948 net.cpp:165] Memory required for data: 3133132800
I0912 00:30:44.140691 24948 layer_factory.hpp:77] Creating layer relu5_1
I0912 00:30:44.140702 24948 net.cpp:100] Creating Layer relu5_1
I0912 00:30:44.140707 24948 net.cpp:434] relu5_1 <- conv5_1
I0912 00:30:44.140712 24948 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 00:30:44.140930 24948 net.cpp:150] Setting up relu5_1
I0912 00:30:44.140939 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.140944 24948 net.cpp:165] Memory required for data: 3138785280
I0912 00:30:44.140947 24948 layer_factory.hpp:77] Creating layer conv5_2
I0912 00:30:44.140964 24948 net.cpp:100] Creating Layer conv5_2
I0912 00:30:44.140969 24948 net.cpp:434] conv5_2 <- conv5_1
I0912 00:30:44.140975 24948 net.cpp:408] conv5_2 -> conv5_2
I0912 00:30:44.228461 24948 net.cpp:150] Setting up conv5_2
I0912 00:30:44.228478 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.228482 24948 net.cpp:165] Memory required for data: 3144437760
I0912 00:30:44.228490 24948 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 00:30:44.228504 24948 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 00:30:44.228513 24948 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 00:30:44.228523 24948 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 00:30:44.228801 24948 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 00:30:44.228808 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.228812 24948 net.cpp:165] Memory required for data: 3150090240
I0912 00:30:44.228821 24948 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 00:30:44.228826 24948 net.cpp:100] Creating Layer conv5_2_scale
I0912 00:30:44.228837 24948 net.cpp:434] conv5_2_scale <- conv5_2
I0912 00:30:44.228842 24948 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 00:30:44.228899 24948 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 00:30:44.229053 24948 net.cpp:150] Setting up conv5_2_scale
I0912 00:30:44.229059 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.229063 24948 net.cpp:165] Memory required for data: 3155742720
I0912 00:30:44.229069 24948 layer_factory.hpp:77] Creating layer relu5_2
I0912 00:30:44.229092 24948 net.cpp:100] Creating Layer relu5_2
I0912 00:30:44.229097 24948 net.cpp:434] relu5_2 <- conv5_2
I0912 00:30:44.229105 24948 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 00:30:44.229331 24948 net.cpp:150] Setting up relu5_2
I0912 00:30:44.229341 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.229346 24948 net.cpp:165] Memory required for data: 3161395200
I0912 00:30:44.229351 24948 layer_factory.hpp:77] Creating layer conv5_3
I0912 00:30:44.229382 24948 net.cpp:100] Creating Layer conv5_3
I0912 00:30:44.229387 24948 net.cpp:434] conv5_3 <- conv5_2
I0912 00:30:44.229398 24948 net.cpp:408] conv5_3 -> conv5_3
I0912 00:30:44.316884 24948 net.cpp:150] Setting up conv5_3
I0912 00:30:44.316900 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.316905 24948 net.cpp:165] Memory required for data: 3167047680
I0912 00:30:44.316912 24948 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 00:30:44.316925 24948 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 00:30:44.316929 24948 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 00:30:44.316936 24948 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 00:30:44.317210 24948 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 00:30:44.317219 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.317222 24948 net.cpp:165] Memory required for data: 3172700160
I0912 00:30:44.317230 24948 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 00:30:44.317239 24948 net.cpp:100] Creating Layer conv5_3_scale
I0912 00:30:44.317247 24948 net.cpp:434] conv5_3_scale <- conv5_3
I0912 00:30:44.317252 24948 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 00:30:44.317314 24948 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 00:30:44.317489 24948 net.cpp:150] Setting up conv5_3_scale
I0912 00:30:44.317498 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.317502 24948 net.cpp:165] Memory required for data: 3178352640
I0912 00:30:44.317508 24948 layer_factory.hpp:77] Creating layer relu5_3
I0912 00:30:44.317519 24948 net.cpp:100] Creating Layer relu5_3
I0912 00:30:44.317524 24948 net.cpp:434] relu5_3 <- conv5_3
I0912 00:30:44.317528 24948 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 00:30:44.317751 24948 net.cpp:150] Setting up relu5_3
I0912 00:30:44.317762 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.317767 24948 net.cpp:165] Memory required for data: 3184005120
I0912 00:30:44.317772 24948 layer_factory.hpp:77] Creating layer pool5
I0912 00:30:44.317776 24948 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 00:30:44.317783 24948 net.cpp:100] Creating Layer pool5
I0912 00:30:44.317788 24948 net.cpp:434] pool5 <- conv5_3
I0912 00:30:44.317793 24948 net.cpp:408] pool5 -> pool5
I0912 00:30:44.317802 24948 net.cpp:408] pool5 -> pool5_mask
I0912 00:30:44.317864 24948 net.cpp:150] Setting up pool5
I0912 00:30:44.317872 24948 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 00:30:44.317875 24948 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 00:30:44.317878 24948 net.cpp:165] Memory required for data: 3186954240
I0912 00:30:44.317883 24948 layer_factory.hpp:77] Creating layer upsample5
I0912 00:30:44.317890 24948 net.cpp:100] Creating Layer upsample5
I0912 00:30:44.317895 24948 net.cpp:434] upsample5 <- pool5
I0912 00:30:44.317903 24948 net.cpp:434] upsample5 <- pool5_mask
I0912 00:30:44.317909 24948 net.cpp:408] upsample5 -> pool5_D
I0912 00:30:44.317942 24948 net.cpp:150] Setting up upsample5
I0912 00:30:44.317950 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.317952 24948 net.cpp:165] Memory required for data: 3192606720
I0912 00:30:44.317956 24948 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 00:30:44.317970 24948 net.cpp:100] Creating Layer conv5_3_D
I0912 00:30:44.317975 24948 net.cpp:434] conv5_3_D <- pool5_D
I0912 00:30:44.317986 24948 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 00:30:44.405495 24948 net.cpp:150] Setting up conv5_3_D
I0912 00:30:44.405511 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.405534 24948 net.cpp:165] Memory required for data: 3198259200
I0912 00:30:44.405542 24948 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 00:30:44.405552 24948 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 00:30:44.405562 24948 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 00:30:44.405570 24948 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 00:30:44.405855 24948 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 00:30:44.405864 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.405867 24948 net.cpp:165] Memory required for data: 3203911680
I0912 00:30:44.405877 24948 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 00:30:44.405889 24948 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 00:30:44.405894 24948 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 00:30:44.405900 24948 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 00:30:44.405959 24948 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 00:30:44.406117 24948 net.cpp:150] Setting up conv5_3_D_scale
I0912 00:30:44.406126 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.406128 24948 net.cpp:165] Memory required for data: 3209564160
I0912 00:30:44.406136 24948 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 00:30:44.406146 24948 net.cpp:100] Creating Layer relu5_3_D
I0912 00:30:44.406150 24948 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 00:30:44.406154 24948 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 00:30:44.407306 24948 net.cpp:150] Setting up relu5_3_D
I0912 00:30:44.407323 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.407328 24948 net.cpp:165] Memory required for data: 3215216640
I0912 00:30:44.407332 24948 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 00:30:44.407362 24948 net.cpp:100] Creating Layer conv5_2_D
I0912 00:30:44.407368 24948 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 00:30:44.407376 24948 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 00:30:44.494989 24948 net.cpp:150] Setting up conv5_2_D
I0912 00:30:44.495007 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.495010 24948 net.cpp:165] Memory required for data: 3220869120
I0912 00:30:44.495023 24948 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 00:30:44.495033 24948 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 00:30:44.495041 24948 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 00:30:44.495046 24948 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 00:30:44.495339 24948 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 00:30:44.495348 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.495352 24948 net.cpp:165] Memory required for data: 3226521600
I0912 00:30:44.495362 24948 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 00:30:44.495373 24948 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 00:30:44.495383 24948 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 00:30:44.495388 24948 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 00:30:44.495453 24948 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 00:30:44.495612 24948 net.cpp:150] Setting up conv5_2_D_scale
I0912 00:30:44.495620 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.495623 24948 net.cpp:165] Memory required for data: 3232174080
I0912 00:30:44.495630 24948 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 00:30:44.495643 24948 net.cpp:100] Creating Layer relu5_2_D
I0912 00:30:44.495649 24948 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 00:30:44.495654 24948 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 00:30:44.496817 24948 net.cpp:150] Setting up relu5_2_D
I0912 00:30:44.496832 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.496837 24948 net.cpp:165] Memory required for data: 3237826560
I0912 00:30:44.496841 24948 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 00:30:44.496857 24948 net.cpp:100] Creating Layer conv5_1_D
I0912 00:30:44.496863 24948 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 00:30:44.496872 24948 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 00:30:44.584560 24948 net.cpp:150] Setting up conv5_1_D
I0912 00:30:44.584578 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.584589 24948 net.cpp:165] Memory required for data: 3243479040
I0912 00:30:44.584595 24948 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 00:30:44.584610 24948 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 00:30:44.584617 24948 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 00:30:44.584623 24948 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 00:30:44.584903 24948 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 00:30:44.584911 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.584914 24948 net.cpp:165] Memory required for data: 3249131520
I0912 00:30:44.584923 24948 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 00:30:44.584935 24948 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 00:30:44.584941 24948 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 00:30:44.584946 24948 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 00:30:44.585009 24948 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 00:30:44.585170 24948 net.cpp:150] Setting up conv5_1_D_scale
I0912 00:30:44.585178 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.585181 24948 net.cpp:165] Memory required for data: 3254784000
I0912 00:30:44.585188 24948 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 00:30:44.585196 24948 net.cpp:100] Creating Layer relu5_1_D
I0912 00:30:44.585201 24948 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 00:30:44.585208 24948 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 00:30:44.585450 24948 net.cpp:150] Setting up relu5_1_D
I0912 00:30:44.585460 24948 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 00:30:44.585464 24948 net.cpp:165] Memory required for data: 3260436480
I0912 00:30:44.585469 24948 layer_factory.hpp:77] Creating layer upsample4
I0912 00:30:44.585479 24948 net.cpp:100] Creating Layer upsample4
I0912 00:30:44.585484 24948 net.cpp:434] upsample4 <- conv5_1_D
I0912 00:30:44.585489 24948 net.cpp:434] upsample4 <- pool4_mask
I0912 00:30:44.585496 24948 net.cpp:408] upsample4 -> pool4_D
I0912 00:30:44.585539 24948 net.cpp:150] Setting up upsample4
I0912 00:30:44.585546 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.585549 24948 net.cpp:165] Memory required for data: 3282554880
I0912 00:30:44.585552 24948 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 00:30:44.585567 24948 net.cpp:100] Creating Layer conv4_3_D
I0912 00:30:44.585573 24948 net.cpp:434] conv4_3_D <- pool4_D
I0912 00:30:44.585582 24948 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 00:30:44.673996 24948 net.cpp:150] Setting up conv4_3_D
I0912 00:30:44.674019 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.674029 24948 net.cpp:165] Memory required for data: 3304673280
I0912 00:30:44.674044 24948 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 00:30:44.674055 24948 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 00:30:44.674068 24948 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 00:30:44.674082 24948 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 00:30:44.674371 24948 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 00:30:44.674381 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.674383 24948 net.cpp:165] Memory required for data: 3326791680
I0912 00:30:44.674392 24948 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 00:30:44.674401 24948 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 00:30:44.674405 24948 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 00:30:44.674410 24948 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 00:30:44.674464 24948 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 00:30:44.674639 24948 net.cpp:150] Setting up conv4_3_D_scale
I0912 00:30:44.674648 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.674651 24948 net.cpp:165] Memory required for data: 3348910080
I0912 00:30:44.674657 24948 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 00:30:44.674685 24948 net.cpp:100] Creating Layer relu4_3_D
I0912 00:30:44.674691 24948 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 00:30:44.674696 24948 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 00:30:44.674924 24948 net.cpp:150] Setting up relu4_3_D
I0912 00:30:44.674933 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.674938 24948 net.cpp:165] Memory required for data: 3371028480
I0912 00:30:44.674943 24948 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 00:30:44.674955 24948 net.cpp:100] Creating Layer conv4_2_D
I0912 00:30:44.674960 24948 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 00:30:44.674970 24948 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 00:30:44.762558 24948 net.cpp:150] Setting up conv4_2_D
I0912 00:30:44.762575 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.762586 24948 net.cpp:165] Memory required for data: 3393146880
I0912 00:30:44.762594 24948 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 00:30:44.762607 24948 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 00:30:44.762614 24948 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 00:30:44.762620 24948 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 00:30:44.762918 24948 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 00:30:44.762928 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.762930 24948 net.cpp:165] Memory required for data: 3415265280
I0912 00:30:44.762939 24948 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 00:30:44.762948 24948 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 00:30:44.762954 24948 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 00:30:44.762962 24948 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 00:30:44.763015 24948 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 00:30:44.763188 24948 net.cpp:150] Setting up conv4_2_D_scale
I0912 00:30:44.763198 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.763203 24948 net.cpp:165] Memory required for data: 3437383680
I0912 00:30:44.763209 24948 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 00:30:44.763217 24948 net.cpp:100] Creating Layer relu4_2_D
I0912 00:30:44.763221 24948 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 00:30:44.763226 24948 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 00:30:44.763458 24948 net.cpp:150] Setting up relu4_2_D
I0912 00:30:44.763466 24948 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 00:30:44.763471 24948 net.cpp:165] Memory required for data: 3459502080
I0912 00:30:44.763476 24948 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 00:30:44.763491 24948 net.cpp:100] Creating Layer conv4_1_D
I0912 00:30:44.763496 24948 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 00:30:44.763505 24948 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 00:30:44.809463 24948 net.cpp:150] Setting up conv4_1_D
I0912 00:30:44.809479 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:44.809484 24948 net.cpp:165] Memory required for data: 3470561280
I0912 00:30:44.809492 24948 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 00:30:44.809510 24948 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 00:30:44.809517 24948 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 00:30:44.809523 24948 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 00:30:44.809824 24948 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 00:30:44.809833 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:44.809836 24948 net.cpp:165] Memory required for data: 3481620480
I0912 00:30:44.809924 24948 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 00:30:44.809933 24948 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 00:30:44.809943 24948 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 00:30:44.809952 24948 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 00:30:44.810014 24948 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 00:30:44.810195 24948 net.cpp:150] Setting up conv4_1_D_scale
I0912 00:30:44.810204 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:44.810225 24948 net.cpp:165] Memory required for data: 3492679680
I0912 00:30:44.810232 24948 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 00:30:44.810240 24948 net.cpp:100] Creating Layer relu4_1_D
I0912 00:30:44.810245 24948 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 00:30:44.810248 24948 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 00:30:44.810487 24948 net.cpp:150] Setting up relu4_1_D
I0912 00:30:44.810497 24948 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 00:30:44.810503 24948 net.cpp:165] Memory required for data: 3503738880
I0912 00:30:44.810505 24948 layer_factory.hpp:77] Creating layer upsample3
I0912 00:30:44.810514 24948 net.cpp:100] Creating Layer upsample3
I0912 00:30:44.810519 24948 net.cpp:434] upsample3 <- conv4_1_D
I0912 00:30:44.810526 24948 net.cpp:434] upsample3 <- pool3_mask
I0912 00:30:44.810536 24948 net.cpp:408] upsample3 -> pool3_D
I0912 00:30:44.810545 24948 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 00:30:44.810581 24948 net.cpp:150] Setting up upsample3
I0912 00:30:44.810588 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:44.810591 24948 net.cpp:165] Memory required for data: 3547975680
I0912 00:30:44.810595 24948 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 00:30:44.810611 24948 net.cpp:100] Creating Layer conv3_3_D
I0912 00:30:44.810616 24948 net.cpp:434] conv3_3_D <- pool3_D
I0912 00:30:44.810624 24948 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 00:30:44.835348 24948 net.cpp:150] Setting up conv3_3_D
I0912 00:30:44.835364 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:44.835374 24948 net.cpp:165] Memory required for data: 3592212480
I0912 00:30:44.835382 24948 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 00:30:44.835398 24948 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 00:30:44.835404 24948 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 00:30:44.835412 24948 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 00:30:44.835721 24948 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 00:30:44.835728 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:44.835732 24948 net.cpp:165] Memory required for data: 3636449280
I0912 00:30:44.835741 24948 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 00:30:44.835750 24948 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 00:30:44.835755 24948 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 00:30:44.835762 24948 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 00:30:44.835819 24948 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 00:30:44.836012 24948 net.cpp:150] Setting up conv3_3_D_scale
I0912 00:30:44.836019 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:44.836024 24948 net.cpp:165] Memory required for data: 3680686080
I0912 00:30:44.836030 24948 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 00:30:44.836038 24948 net.cpp:100] Creating Layer relu3_3_D
I0912 00:30:44.836043 24948 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 00:30:44.836050 24948 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 00:30:44.837215 24948 net.cpp:150] Setting up relu3_3_D
I0912 00:30:44.837229 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:44.837234 24948 net.cpp:165] Memory required for data: 3724922880
I0912 00:30:44.837239 24948 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 00:30:44.837255 24948 net.cpp:100] Creating Layer conv3_2_D
I0912 00:30:44.837260 24948 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 00:30:44.837270 24948 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 00:30:44.861111 24948 net.cpp:150] Setting up conv3_2_D
I0912 00:30:44.861129 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:44.861138 24948 net.cpp:165] Memory required for data: 3769159680
I0912 00:30:44.861146 24948 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 00:30:44.861157 24948 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 00:30:44.861166 24948 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 00:30:44.861192 24948 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 00:30:44.861523 24948 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 00:30:44.861533 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:44.861537 24948 net.cpp:165] Memory required for data: 3813396480
I0912 00:30:44.861546 24948 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 00:30:44.861553 24948 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 00:30:44.861558 24948 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 00:30:44.861564 24948 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 00:30:44.861623 24948 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 00:30:44.861814 24948 net.cpp:150] Setting up conv3_2_D_scale
I0912 00:30:44.861821 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:44.861824 24948 net.cpp:165] Memory required for data: 3857633280
I0912 00:30:44.861831 24948 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 00:30:44.861845 24948 net.cpp:100] Creating Layer relu3_2_D
I0912 00:30:44.861850 24948 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 00:30:44.861853 24948 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 00:30:44.863016 24948 net.cpp:150] Setting up relu3_2_D
I0912 00:30:44.863030 24948 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 00:30:44.863035 24948 net.cpp:165] Memory required for data: 3901870080
I0912 00:30:44.863040 24948 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 00:30:44.863056 24948 net.cpp:100] Creating Layer conv3_1_D
I0912 00:30:44.863061 24948 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 00:30:44.863072 24948 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 00:30:44.877651 24948 net.cpp:150] Setting up conv3_1_D
I0912 00:30:44.877667 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:44.877677 24948 net.cpp:165] Memory required for data: 3923988480
I0912 00:30:44.877686 24948 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 00:30:44.877697 24948 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 00:30:44.877707 24948 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 00:30:44.877717 24948 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 00:30:44.878026 24948 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 00:30:44.878034 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:44.878037 24948 net.cpp:165] Memory required for data: 3946106880
I0912 00:30:44.878046 24948 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 00:30:44.878056 24948 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 00:30:44.878063 24948 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 00:30:44.878072 24948 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 00:30:44.878126 24948 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 00:30:44.879884 24948 net.cpp:150] Setting up conv3_1_D_scale
I0912 00:30:44.879899 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:44.879907 24948 net.cpp:165] Memory required for data: 3968225280
I0912 00:30:44.879915 24948 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 00:30:44.879927 24948 net.cpp:100] Creating Layer relu3_1_D
I0912 00:30:44.879933 24948 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 00:30:44.879938 24948 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 00:30:44.880183 24948 net.cpp:150] Setting up relu3_1_D
I0912 00:30:44.880192 24948 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 00:30:44.880197 24948 net.cpp:165] Memory required for data: 3990343680
I0912 00:30:44.880203 24948 layer_factory.hpp:77] Creating layer upsample2
I0912 00:30:44.880213 24948 net.cpp:100] Creating Layer upsample2
I0912 00:30:44.880218 24948 net.cpp:434] upsample2 <- conv3_1_D
I0912 00:30:44.880223 24948 net.cpp:434] upsample2 <- pool2_mask
I0912 00:30:44.880231 24948 net.cpp:408] upsample2 -> pool2_D
I0912 00:30:44.880240 24948 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 00:30:44.880278 24948 net.cpp:150] Setting up upsample2
I0912 00:30:44.880300 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:44.880302 24948 net.cpp:165] Memory required for data: 4078817280
I0912 00:30:44.880306 24948 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 00:30:44.880321 24948 net.cpp:100] Creating Layer conv2_2_D
I0912 00:30:44.880326 24948 net.cpp:434] conv2_2_D <- pool2_D
I0912 00:30:44.880332 24948 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 00:30:44.888442 24948 net.cpp:150] Setting up conv2_2_D
I0912 00:30:44.888458 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:44.888468 24948 net.cpp:165] Memory required for data: 4167290880
I0912 00:30:44.888476 24948 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 00:30:44.888486 24948 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 00:30:44.888490 24948 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 00:30:44.888496 24948 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 00:30:44.888849 24948 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 00:30:44.888857 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:44.888861 24948 net.cpp:165] Memory required for data: 4255764480
I0912 00:30:44.888872 24948 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 00:30:44.888882 24948 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 00:30:44.888891 24948 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 00:30:44.888897 24948 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 00:30:44.888954 24948 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 00:30:44.889231 24948 net.cpp:150] Setting up conv2_2_D_scale
I0912 00:30:44.889240 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:44.889243 24948 net.cpp:165] Memory required for data: 4344238080
I0912 00:30:44.889250 24948 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 00:30:44.889264 24948 net.cpp:100] Creating Layer relu2_2_D
I0912 00:30:44.889271 24948 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 00:30:44.889274 24948 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 00:30:44.889530 24948 net.cpp:150] Setting up relu2_2_D
I0912 00:30:44.889541 24948 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 00:30:44.889545 24948 net.cpp:165] Memory required for data: 4432711680
I0912 00:30:44.889549 24948 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 00:30:44.889565 24948 net.cpp:100] Creating Layer conv2_1_D
I0912 00:30:44.889570 24948 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 00:30:44.889578 24948 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 00:30:44.895189 24948 net.cpp:150] Setting up conv2_1_D
I0912 00:30:44.895205 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:44.895215 24948 net.cpp:165] Memory required for data: 4476948480
I0912 00:30:44.895223 24948 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 00:30:44.895236 24948 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 00:30:44.895244 24948 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 00:30:44.895251 24948 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 00:30:44.895617 24948 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 00:30:44.895627 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:44.895629 24948 net.cpp:165] Memory required for data: 4521185280
I0912 00:30:44.895639 24948 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 00:30:44.895650 24948 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 00:30:44.895658 24948 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 00:30:44.895663 24948 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 00:30:44.895722 24948 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 00:30:44.896011 24948 net.cpp:150] Setting up conv2_1_D_scale
I0912 00:30:44.896020 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:44.896023 24948 net.cpp:165] Memory required for data: 4565422080
I0912 00:30:44.896029 24948 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 00:30:44.896040 24948 net.cpp:100] Creating Layer relu2_1_D
I0912 00:30:44.896044 24948 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 00:30:44.896066 24948 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 00:30:44.896306 24948 net.cpp:150] Setting up relu2_1_D
I0912 00:30:44.896315 24948 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 00:30:44.896320 24948 net.cpp:165] Memory required for data: 4609658880
I0912 00:30:44.896324 24948 layer_factory.hpp:77] Creating layer upsample1
I0912 00:30:44.896333 24948 net.cpp:100] Creating Layer upsample1
I0912 00:30:44.896338 24948 net.cpp:434] upsample1 <- conv2_1_D
I0912 00:30:44.896344 24948 net.cpp:434] upsample1 <- pool1_mask
I0912 00:30:44.896349 24948 net.cpp:408] upsample1 -> pool1_D
I0912 00:30:44.896358 24948 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 00:30:44.896399 24948 net.cpp:150] Setting up upsample1
I0912 00:30:44.896405 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:44.896409 24948 net.cpp:165] Memory required for data: 4786606080
I0912 00:30:44.896411 24948 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 00:30:44.896425 24948 net.cpp:100] Creating Layer conv1_2_D
I0912 00:30:44.896430 24948 net.cpp:434] conv1_2_D <- pool1_D
I0912 00:30:44.896437 24948 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 00:30:44.901535 24948 net.cpp:150] Setting up conv1_2_D
I0912 00:30:44.901551 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:44.901561 24948 net.cpp:165] Memory required for data: 4963553280
I0912 00:30:44.901571 24948 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 00:30:44.901581 24948 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 00:30:44.901589 24948 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 00:30:44.901598 24948 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 00:30:44.902045 24948 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 00:30:44.902053 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:44.902056 24948 net.cpp:165] Memory required for data: 5140500480
I0912 00:30:44.902065 24948 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 00:30:44.902074 24948 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 00:30:44.902079 24948 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 00:30:44.902084 24948 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 00:30:44.902145 24948 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 00:30:44.904181 24948 net.cpp:150] Setting up conv1_2_D_scale
I0912 00:30:44.904196 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:44.904201 24948 net.cpp:165] Memory required for data: 5317447680
I0912 00:30:44.904208 24948 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 00:30:44.904218 24948 net.cpp:100] Creating Layer relu1_2_D
I0912 00:30:44.904224 24948 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 00:30:44.904230 24948 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 00:30:44.904480 24948 net.cpp:150] Setting up relu1_2_D
I0912 00:30:44.904489 24948 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 00:30:44.904495 24948 net.cpp:165] Memory required for data: 5494394880
I0912 00:30:44.904498 24948 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 00:30:44.904515 24948 net.cpp:100] Creating Layer conv1_1_1_D
I0912 00:30:44.904520 24948 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 00:30:44.904527 24948 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 00:30:44.906774 24948 net.cpp:150] Setting up conv1_1_1_D
I0912 00:30:44.906790 24948 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 00:30:44.906795 24948 net.cpp:165] Memory required for data: 5499924480
I0912 00:30:44.906802 24948 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 00:30:44.906813 24948 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 00:30:44.906819 24948 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 00:30:44.906826 24948 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 00:30:44.906837 24948 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 00:30:44.906914 24948 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 00:30:44.906922 24948 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 00:30:44.906926 24948 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 00:30:44.906932 24948 net.cpp:165] Memory required for data: 5510983680
I0912 00:30:44.906937 24948 layer_factory.hpp:77] Creating layer loss
I0912 00:30:44.906951 24948 net.cpp:100] Creating Layer loss
I0912 00:30:44.906956 24948 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 00:30:44.906961 24948 net.cpp:434] loss <- label_data_1_split_0
I0912 00:30:44.906967 24948 net.cpp:408] loss -> loss
I0912 00:30:44.906978 24948 layer_factory.hpp:77] Creating layer loss
I0912 00:30:44.911801 24948 net.cpp:150] Setting up loss
I0912 00:30:44.911816 24948 net.cpp:157] Top shape: (1)
I0912 00:30:44.911826 24948 net.cpp:160]     with loss weight 1
I0912 00:30:44.911844 24948 net.cpp:165] Memory required for data: 5510983684
I0912 00:30:44.911849 24948 layer_factory.hpp:77] Creating layer accuracy
I0912 00:30:44.911862 24948 net.cpp:100] Creating Layer accuracy
I0912 00:30:44.911870 24948 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 00:30:44.911875 24948 net.cpp:434] accuracy <- label_data_1_split_1
I0912 00:30:44.911881 24948 net.cpp:408] accuracy -> accuracy
I0912 00:30:44.911890 24948 net.cpp:408] accuracy -> per_class_accuracy
I0912 00:30:44.911949 24948 net.cpp:150] Setting up accuracy
I0912 00:30:44.911957 24948 net.cpp:157] Top shape: (1)
I0912 00:30:44.911960 24948 net.cpp:157] Top shape: 2 (2)
I0912 00:30:44.911964 24948 net.cpp:165] Memory required for data: 5510983696
I0912 00:30:44.911967 24948 net.cpp:228] accuracy does not need backward computation.
I0912 00:30:44.911972 24948 net.cpp:226] loss needs backward computation.
I0912 00:30:44.911978 24948 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 00:30:44.911981 24948 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 00:30:44.911984 24948 net.cpp:226] relu1_2_D needs backward computation.
I0912 00:30:44.911988 24948 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 00:30:44.911990 24948 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 00:30:44.911993 24948 net.cpp:226] conv1_2_D needs backward computation.
I0912 00:30:44.911998 24948 net.cpp:226] upsample1 needs backward computation.
I0912 00:30:44.912001 24948 net.cpp:226] relu2_1_D needs backward computation.
I0912 00:30:44.912005 24948 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 00:30:44.912009 24948 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 00:30:44.912011 24948 net.cpp:226] conv2_1_D needs backward computation.
I0912 00:30:44.912015 24948 net.cpp:226] relu2_2_D needs backward computation.
I0912 00:30:44.912019 24948 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 00:30:44.912021 24948 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 00:30:44.912024 24948 net.cpp:226] conv2_2_D needs backward computation.
I0912 00:30:44.912027 24948 net.cpp:226] upsample2 needs backward computation.
I0912 00:30:44.912031 24948 net.cpp:226] relu3_1_D needs backward computation.
I0912 00:30:44.912034 24948 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 00:30:44.912037 24948 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 00:30:44.912040 24948 net.cpp:226] conv3_1_D needs backward computation.
I0912 00:30:44.912044 24948 net.cpp:226] relu3_2_D needs backward computation.
I0912 00:30:44.912046 24948 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 00:30:44.912050 24948 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 00:30:44.912052 24948 net.cpp:226] conv3_2_D needs backward computation.
I0912 00:30:44.912055 24948 net.cpp:226] relu3_3_D needs backward computation.
I0912 00:30:44.912058 24948 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 00:30:44.912061 24948 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 00:30:44.912080 24948 net.cpp:226] conv3_3_D needs backward computation.
I0912 00:30:44.912083 24948 net.cpp:226] upsample3 needs backward computation.
I0912 00:30:44.912087 24948 net.cpp:226] relu4_1_D needs backward computation.
I0912 00:30:44.912091 24948 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 00:30:44.912093 24948 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 00:30:44.912096 24948 net.cpp:226] conv4_1_D needs backward computation.
I0912 00:30:44.912099 24948 net.cpp:226] relu4_2_D needs backward computation.
I0912 00:30:44.912103 24948 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 00:30:44.912106 24948 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 00:30:44.912109 24948 net.cpp:226] conv4_2_D needs backward computation.
I0912 00:30:44.912116 24948 net.cpp:226] relu4_3_D needs backward computation.
I0912 00:30:44.912118 24948 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 00:30:44.912122 24948 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 00:30:44.912124 24948 net.cpp:226] conv4_3_D needs backward computation.
I0912 00:30:44.912128 24948 net.cpp:226] upsample4 needs backward computation.
I0912 00:30:44.912132 24948 net.cpp:226] relu5_1_D needs backward computation.
I0912 00:30:44.912137 24948 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 00:30:44.912140 24948 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 00:30:44.912145 24948 net.cpp:226] conv5_1_D needs backward computation.
I0912 00:30:44.912149 24948 net.cpp:226] relu5_2_D needs backward computation.
I0912 00:30:44.912153 24948 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 00:30:44.912158 24948 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 00:30:44.912161 24948 net.cpp:226] conv5_2_D needs backward computation.
I0912 00:30:44.912166 24948 net.cpp:226] relu5_3_D needs backward computation.
I0912 00:30:44.912173 24948 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 00:30:44.912175 24948 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 00:30:44.912180 24948 net.cpp:226] conv5_3_D needs backward computation.
I0912 00:30:44.912186 24948 net.cpp:226] upsample5 needs backward computation.
I0912 00:30:44.912191 24948 net.cpp:226] pool5 needs backward computation.
I0912 00:30:44.912197 24948 net.cpp:226] relu5_3 needs backward computation.
I0912 00:30:44.912201 24948 net.cpp:226] conv5_3_scale needs backward computation.
I0912 00:30:44.912206 24948 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 00:30:44.912211 24948 net.cpp:226] conv5_3 needs backward computation.
I0912 00:30:44.912217 24948 net.cpp:226] relu5_2 needs backward computation.
I0912 00:30:44.912221 24948 net.cpp:226] conv5_2_scale needs backward computation.
I0912 00:30:44.912225 24948 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 00:30:44.912228 24948 net.cpp:226] conv5_2 needs backward computation.
I0912 00:30:44.912232 24948 net.cpp:226] relu5_1 needs backward computation.
I0912 00:30:44.912238 24948 net.cpp:226] conv5_1_scale needs backward computation.
I0912 00:30:44.912242 24948 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 00:30:44.912246 24948 net.cpp:226] conv5_1 needs backward computation.
I0912 00:30:44.912253 24948 net.cpp:226] pool4 needs backward computation.
I0912 00:30:44.912257 24948 net.cpp:226] relu4_3 needs backward computation.
I0912 00:30:44.912262 24948 net.cpp:226] conv4_3_scale needs backward computation.
I0912 00:30:44.912266 24948 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 00:30:44.912269 24948 net.cpp:226] conv4_3 needs backward computation.
I0912 00:30:44.912273 24948 net.cpp:226] relu4_2 needs backward computation.
I0912 00:30:44.912278 24948 net.cpp:226] conv4_2_scale needs backward computation.
I0912 00:30:44.912281 24948 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 00:30:44.912286 24948 net.cpp:226] conv4_2 needs backward computation.
I0912 00:30:44.912289 24948 net.cpp:226] relu4_1 needs backward computation.
I0912 00:30:44.912302 24948 net.cpp:226] conv4_1_scale needs backward computation.
I0912 00:30:44.912305 24948 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 00:30:44.912308 24948 net.cpp:226] conv4_1 needs backward computation.
I0912 00:30:44.912313 24948 net.cpp:226] pool3 needs backward computation.
I0912 00:30:44.912318 24948 net.cpp:226] relu3_3 needs backward computation.
I0912 00:30:44.912322 24948 net.cpp:226] conv3_3_scale needs backward computation.
I0912 00:30:44.912325 24948 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 00:30:44.912330 24948 net.cpp:226] conv3_3 needs backward computation.
I0912 00:30:44.912334 24948 net.cpp:226] relu3_2 needs backward computation.
I0912 00:30:44.912338 24948 net.cpp:226] conv3_2_scale needs backward computation.
I0912 00:30:44.912340 24948 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 00:30:44.912345 24948 net.cpp:226] conv3_2 needs backward computation.
I0912 00:30:44.912350 24948 net.cpp:226] relu3_1 needs backward computation.
I0912 00:30:44.912353 24948 net.cpp:226] conv3_1_scale needs backward computation.
I0912 00:30:44.912356 24948 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 00:30:44.912360 24948 net.cpp:226] conv3_1 needs backward computation.
I0912 00:30:44.912364 24948 net.cpp:226] pool2 needs backward computation.
I0912 00:30:44.912369 24948 net.cpp:226] relu2_2 needs backward computation.
I0912 00:30:44.912374 24948 net.cpp:226] conv2_2_scale needs backward computation.
I0912 00:30:44.912377 24948 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 00:30:44.912384 24948 net.cpp:226] conv2_2 needs backward computation.
I0912 00:30:44.912389 24948 net.cpp:226] relu2_1 needs backward computation.
I0912 00:30:44.912391 24948 net.cpp:226] conv2_1_scale needs backward computation.
I0912 00:30:44.912395 24948 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 00:30:44.912400 24948 net.cpp:226] conv2_1 needs backward computation.
I0912 00:30:44.912405 24948 net.cpp:226] pool1 needs backward computation.
I0912 00:30:44.912410 24948 net.cpp:226] relu1_2 needs backward computation.
I0912 00:30:44.912415 24948 net.cpp:226] conv1_2_scale needs backward computation.
I0912 00:30:44.912420 24948 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 00:30:44.912423 24948 net.cpp:226] conv1_2 needs backward computation.
I0912 00:30:44.912428 24948 net.cpp:226] relu1_1 needs backward computation.
I0912 00:30:44.912433 24948 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 00:30:44.912437 24948 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 00:30:44.912441 24948 net.cpp:226] conv1_1_1 needs backward computation.
I0912 00:30:44.912446 24948 net.cpp:228] label_data_1_split does not need backward computation.
I0912 00:30:44.912451 24948 net.cpp:228] data does not need backward computation.
I0912 00:30:44.912454 24948 net.cpp:270] This network produces output accuracy
I0912 00:30:44.912457 24948 net.cpp:270] This network produces output loss
I0912 00:30:44.912461 24948 net.cpp:270] This network produces output per_class_accuracy
I0912 00:30:44.912530 24948 net.cpp:283] Network initialization done.
I0912 00:30:44.912933 24948 solver.cpp:60] Solver scaffolding done.
I0912 00:30:44.922328 24948 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0912 00:30:45.175803 24948 net.cpp:761] Ignoring source layer conv1_1
I0912 00:30:45.175828 24948 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 00:30:45.175891 24948 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 00:30:45.175899 24948 net.cpp:761] Ignoring source layer pool1_drop
I0912 00:30:45.175992 24948 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 00:30:45.176162 24948 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 00:30:45.176169 24948 net.cpp:761] Ignoring source layer pool2_drop
I0912 00:30:45.176487 24948 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 00:30:45.177114 24948 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 00:30:45.177781 24948 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 00:30:45.177819 24948 net.cpp:761] Ignoring source layer pool3_drop
I0912 00:30:45.179059 24948 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 00:30:45.181565 24948 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 00:30:45.184029 24948 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 00:30:45.184037 24948 net.cpp:761] Ignoring source layer pool4_drop
I0912 00:30:45.186372 24948 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 00:30:45.188532 24948 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 00:30:45.190749 24948 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 00:30:45.190757 24948 net.cpp:761] Ignoring source layer pool5_drop
I0912 00:30:45.190762 24948 net.cpp:761] Ignoring source layer upsample5_drop
I0912 00:30:45.193233 24948 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 00:30:45.195667 24948 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 00:30:45.197885 24948 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 00:30:45.197906 24948 net.cpp:761] Ignoring source layer upsample4_drop
I0912 00:30:45.200073 24948 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 00:30:45.202358 24948 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 00:30:45.203621 24948 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 00:30:45.203635 24948 net.cpp:761] Ignoring source layer upsample3_drop
I0912 00:30:45.204280 24948 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 00:30:45.204926 24948 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 00:30:45.205260 24948 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 00:30:45.205267 24948 net.cpp:761] Ignoring source layer upsample2_drop
I0912 00:30:45.205468 24948 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 00:30:45.205574 24948 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 00:30:45.205581 24948 net.cpp:761] Ignoring source layer upsample1_drop
I0912 00:30:45.205647 24948 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 00:30:45.205654 24948 net.cpp:761] Ignoring source layer conv1_1_D
I0912 00:30:45.205658 24948 net.cpp:761] Ignoring source layer prob
I0912 00:30:45.461009 24948 net.cpp:761] Ignoring source layer conv1_1
I0912 00:30:45.461036 24948 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 00:30:45.461093 24948 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 00:30:45.461100 24948 net.cpp:761] Ignoring source layer pool1_drop
I0912 00:30:45.461185 24948 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 00:30:45.461339 24948 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 00:30:45.461345 24948 net.cpp:761] Ignoring source layer pool2_drop
I0912 00:30:45.461663 24948 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 00:30:45.462239 24948 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 00:30:45.462805 24948 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 00:30:45.462811 24948 net.cpp:761] Ignoring source layer pool3_drop
I0912 00:30:45.463907 24948 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 00:30:45.466112 24948 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 00:30:45.468287 24948 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 00:30:45.468296 24948 net.cpp:761] Ignoring source layer pool4_drop
I0912 00:30:45.470465 24948 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 00:30:45.472630 24948 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 00:30:45.474891 24948 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 00:30:45.474900 24948 net.cpp:761] Ignoring source layer pool5_drop
I0912 00:30:45.474905 24948 net.cpp:761] Ignoring source layer upsample5_drop
I0912 00:30:45.477411 24948 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 00:30:45.479913 24948 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 00:30:45.482432 24948 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 00:30:45.482441 24948 net.cpp:761] Ignoring source layer upsample4_drop
I0912 00:30:45.484930 24948 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 00:30:45.487450 24948 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 00:30:45.488581 24948 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 00:30:45.488590 24948 net.cpp:761] Ignoring source layer upsample3_drop
I0912 00:30:45.489225 24948 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 00:30:45.489786 24948 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 00:30:45.490115 24948 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 00:30:45.490123 24948 net.cpp:761] Ignoring source layer upsample2_drop
I0912 00:30:45.490289 24948 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 00:30:45.490386 24948 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 00:30:45.490392 24948 net.cpp:761] Ignoring source layer upsample1_drop
I0912 00:30:45.490447 24948 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 00:30:45.490453 24948 net.cpp:761] Ignoring source layer conv1_1_D
I0912 00:30:45.490458 24948 net.cpp:761] Ignoring source layer prob
I0912 00:30:45.501483 24948 caffe.cpp:251] Starting Optimization
I0912 00:30:45.501503 24948 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0912 00:30:45.501509 24948 solver.cpp:280] Learning Rate Policy: step
I0912 00:30:46.509281 24948 solver.cpp:228] Iteration 0, loss = 0.772171
I0912 00:30:46.509340 24948 solver.cpp:244]     Train net output #0: accuracy = 0.474481
I0912 00:30:46.509359 24948 solver.cpp:244]     Train net output #1: loss = 0.772171 (* 1 = 0.772171 loss)
I0912 00:30:46.509373 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.190281
I0912 00:30:46.509382 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.79602
I0912 00:30:46.509418 24948 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0912 00:31:03.030143 24948 solver.cpp:228] Iteration 20, loss = 0.411695
I0912 00:31:03.030191 24948 solver.cpp:244]     Train net output #0: accuracy = 0.77849
I0912 00:31:03.030205 24948 solver.cpp:244]     Train net output #1: loss = 0.411695 (* 1 = 0.411695 loss)
I0912 00:31:03.030210 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.735589
I0912 00:31:03.030215 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.928465
I0912 00:31:03.030222 24948 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0912 00:31:19.942492 24948 solver.cpp:228] Iteration 40, loss = 0.317176
I0912 00:31:19.942637 24948 solver.cpp:244]     Train net output #0: accuracy = 0.838594
I0912 00:31:19.942652 24948 solver.cpp:244]     Train net output #1: loss = 0.317176 (* 1 = 0.317176 loss)
I0912 00:31:19.942662 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.786731
I0912 00:31:19.942667 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.962484
I0912 00:31:19.942674 24948 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0912 00:31:36.843978 24948 solver.cpp:228] Iteration 60, loss = 0.180016
I0912 00:31:36.844025 24948 solver.cpp:244]     Train net output #0: accuracy = 0.941641
I0912 00:31:36.844039 24948 solver.cpp:244]     Train net output #1: loss = 0.180016 (* 1 = 0.180016 loss)
I0912 00:31:36.844044 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.91952
I0912 00:31:36.844049 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998654
I0912 00:31:36.844056 24948 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0912 00:31:53.737362 24948 solver.cpp:228] Iteration 80, loss = 0.289734
I0912 00:31:53.737509 24948 solver.cpp:244]     Train net output #0: accuracy = 0.911406
I0912 00:31:53.737524 24948 solver.cpp:244]     Train net output #1: loss = 0.289734 (* 1 = 0.289734 loss)
I0912 00:31:53.737536 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.938953
I0912 00:31:53.737541 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.888336
I0912 00:31:53.737547 24948 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0912 00:32:10.630146 24948 solver.cpp:228] Iteration 100, loss = 0.548337
I0912 00:32:10.630189 24948 solver.cpp:244]     Train net output #0: accuracy = 0.875927
I0912 00:32:10.630203 24948 solver.cpp:244]     Train net output #1: loss = 0.548337 (* 1 = 0.548337 loss)
I0912 00:32:10.630209 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988209
I0912 00:32:10.630214 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.826328
I0912 00:32:10.630221 24948 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0912 00:32:27.531878 24948 solver.cpp:228] Iteration 120, loss = 0.284647
I0912 00:32:27.532037 24948 solver.cpp:244]     Train net output #0: accuracy = 0.908899
I0912 00:32:27.532050 24948 solver.cpp:244]     Train net output #1: loss = 0.284647 (* 1 = 0.284647 loss)
I0912 00:32:27.532057 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.905086
I0912 00:32:27.532060 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.920086
I0912 00:32:27.532066 24948 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0912 00:32:44.565589 24948 solver.cpp:228] Iteration 140, loss = 0.0916013
I0912 00:32:44.565634 24948 solver.cpp:244]     Train net output #0: accuracy = 0.977222
I0912 00:32:44.565647 24948 solver.cpp:244]     Train net output #1: loss = 0.0916012 (* 1 = 0.0916012 loss)
I0912 00:32:44.565654 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972157
I0912 00:32:44.565659 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986533
I0912 00:32:44.565666 24948 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0912 00:33:01.452949 24948 solver.cpp:228] Iteration 160, loss = 0.121409
I0912 00:33:01.453057 24948 solver.cpp:244]     Train net output #0: accuracy = 0.978346
I0912 00:33:01.453070 24948 solver.cpp:244]     Train net output #1: loss = 0.121409 (* 1 = 0.121409 loss)
I0912 00:33:01.453081 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977364
I0912 00:33:01.453086 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979042
I0912 00:33:01.453094 24948 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0912 00:33:18.341908 24948 solver.cpp:228] Iteration 180, loss = 0.0508503
I0912 00:33:18.341953 24948 solver.cpp:244]     Train net output #0: accuracy = 0.986273
I0912 00:33:18.341965 24948 solver.cpp:244]     Train net output #1: loss = 0.0508502 (* 1 = 0.0508502 loss)
I0912 00:33:18.341972 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981697
I0912 00:33:18.341979 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997437
I0912 00:33:18.341985 24948 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0912 00:33:35.227200 24948 solver.cpp:228] Iteration 200, loss = 0.055883
I0912 00:33:35.227300 24948 solver.cpp:244]     Train net output #0: accuracy = 0.98683
I0912 00:33:35.227313 24948 solver.cpp:244]     Train net output #1: loss = 0.0558829 (* 1 = 0.0558829 loss)
I0912 00:33:35.227319 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988669
I0912 00:33:35.227324 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985006
I0912 00:33:35.227330 24948 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0912 00:33:52.117838 24948 solver.cpp:228] Iteration 220, loss = 0.0591481
I0912 00:33:52.117882 24948 solver.cpp:244]     Train net output #0: accuracy = 0.9799
I0912 00:33:52.117892 24948 solver.cpp:244]     Train net output #1: loss = 0.059148 (* 1 = 0.059148 loss)
I0912 00:33:52.117898 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975718
I0912 00:33:52.117903 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992243
I0912 00:33:52.117910 24948 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0912 00:34:09.007720 24948 solver.cpp:228] Iteration 240, loss = 0.0682496
I0912 00:34:09.007827 24948 solver.cpp:244]     Train net output #0: accuracy = 0.977928
I0912 00:34:09.007843 24948 solver.cpp:244]     Train net output #1: loss = 0.0682495 (* 1 = 0.0682495 loss)
I0912 00:34:09.007848 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.968265
I0912 00:34:09.007853 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988968
I0912 00:34:09.007860 24948 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0912 00:34:25.904412 24948 solver.cpp:228] Iteration 260, loss = 0.0257601
I0912 00:34:25.904455 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994039
I0912 00:34:25.904466 24948 solver.cpp:244]     Train net output #1: loss = 0.02576 (* 1 = 0.02576 loss)
I0912 00:34:25.904474 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992559
I0912 00:34:25.904479 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995666
I0912 00:34:25.904484 24948 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0912 00:34:42.789619 24948 solver.cpp:228] Iteration 280, loss = 0.0534999
I0912 00:34:42.789786 24948 solver.cpp:244]     Train net output #0: accuracy = 0.984233
I0912 00:34:42.789801 24948 solver.cpp:244]     Train net output #1: loss = 0.0534998 (* 1 = 0.0534998 loss)
I0912 00:34:42.789808 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9873
I0912 00:34:42.789813 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979181
I0912 00:34:42.789820 24948 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0912 00:34:59.687258 24948 solver.cpp:228] Iteration 300, loss = 0.0227896
I0912 00:34:59.687301 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994687
I0912 00:34:59.687314 24948 solver.cpp:244]     Train net output #1: loss = 0.0227895 (* 1 = 0.0227895 loss)
I0912 00:34:59.687320 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996554
I0912 00:34:59.687325 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991042
I0912 00:34:59.687332 24948 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0912 00:35:16.567544 24948 solver.cpp:228] Iteration 320, loss = 0.0706401
I0912 00:35:16.567637 24948 solver.cpp:244]     Train net output #0: accuracy = 0.978232
I0912 00:35:16.567653 24948 solver.cpp:244]     Train net output #1: loss = 0.07064 (* 1 = 0.07064 loss)
I0912 00:35:16.567659 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.970029
I0912 00:35:16.567664 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985592
I0912 00:35:16.567672 24948 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0912 00:35:33.446487 24948 solver.cpp:228] Iteration 340, loss = 0.0304044
I0912 00:35:33.446527 24948 solver.cpp:244]     Train net output #0: accuracy = 0.992998
I0912 00:35:33.446542 24948 solver.cpp:244]     Train net output #1: loss = 0.0304043 (* 1 = 0.0304043 loss)
I0912 00:35:33.446547 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993855
I0912 00:35:33.446552 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991814
I0912 00:35:33.446559 24948 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0912 00:35:50.326035 24948 solver.cpp:228] Iteration 360, loss = 0.0239688
I0912 00:35:50.326129 24948 solver.cpp:244]     Train net output #0: accuracy = 0.992455
I0912 00:35:50.326143 24948 solver.cpp:244]     Train net output #1: loss = 0.0239687 (* 1 = 0.0239687 loss)
I0912 00:35:50.326148 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989257
I0912 00:35:50.326153 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997853
I0912 00:35:50.326160 24948 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0912 00:36:07.212193 24948 solver.cpp:228] Iteration 380, loss = 0.0583693
I0912 00:36:07.212237 24948 solver.cpp:244]     Train net output #0: accuracy = 0.980051
I0912 00:36:07.212250 24948 solver.cpp:244]     Train net output #1: loss = 0.0583693 (* 1 = 0.0583693 loss)
I0912 00:36:07.212256 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986579
I0912 00:36:07.212261 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.968876
I0912 00:36:07.212268 24948 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0912 00:36:24.114105 24948 solver.cpp:228] Iteration 400, loss = 0.0365058
I0912 00:36:24.114212 24948 solver.cpp:244]     Train net output #0: accuracy = 0.987156
I0912 00:36:24.114226 24948 solver.cpp:244]     Train net output #1: loss = 0.0365058 (* 1 = 0.0365058 loss)
I0912 00:36:24.114233 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977305
I0912 00:36:24.114238 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995636
I0912 00:36:24.114243 24948 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0912 00:36:41.007498 24948 solver.cpp:228] Iteration 420, loss = 0.163108
I0912 00:36:41.007544 24948 solver.cpp:244]     Train net output #0: accuracy = 0.968273
I0912 00:36:41.007555 24948 solver.cpp:244]     Train net output #1: loss = 0.163108 (* 1 = 0.163108 loss)
I0912 00:36:41.007561 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993718
I0912 00:36:41.007567 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.958112
I0912 00:36:41.007575 24948 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0912 00:36:57.908161 24948 solver.cpp:228] Iteration 440, loss = 0.0349105
I0912 00:36:57.908316 24948 solver.cpp:244]     Train net output #0: accuracy = 0.988789
I0912 00:36:57.908332 24948 solver.cpp:244]     Train net output #1: loss = 0.0349105 (* 1 = 0.0349105 loss)
I0912 00:36:57.908344 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983471
I0912 00:36:57.908349 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993188
I0912 00:36:57.908356 24948 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0912 00:37:14.822782 24948 solver.cpp:228] Iteration 460, loss = 0.0161328
I0912 00:37:14.822820 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995346
I0912 00:37:14.822831 24948 solver.cpp:244]     Train net output #1: loss = 0.0161328 (* 1 = 0.0161328 loss)
I0912 00:37:14.822837 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997041
I0912 00:37:14.822844 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992574
I0912 00:37:14.822850 24948 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0912 00:37:31.711295 24948 solver.cpp:228] Iteration 480, loss = 0.0317866
I0912 00:37:31.711387 24948 solver.cpp:244]     Train net output #0: accuracy = 0.988867
I0912 00:37:31.711402 24948 solver.cpp:244]     Train net output #1: loss = 0.0317865 (* 1 = 0.0317865 loss)
I0912 00:37:31.711414 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990859
I0912 00:37:31.711419 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98414
I0912 00:37:31.711426 24948 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0912 00:37:48.600409 24948 solver.cpp:228] Iteration 500, loss = 0.0252268
I0912 00:37:48.600451 24948 solver.cpp:244]     Train net output #0: accuracy = 0.990198
I0912 00:37:48.600462 24948 solver.cpp:244]     Train net output #1: loss = 0.0252267 (* 1 = 0.0252267 loss)
I0912 00:37:48.600468 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989506
I0912 00:37:48.600473 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991509
I0912 00:37:48.600479 24948 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0912 00:38:05.496548 24948 solver.cpp:228] Iteration 520, loss = 0.0711144
I0912 00:38:05.496650 24948 solver.cpp:244]     Train net output #0: accuracy = 0.967727
I0912 00:38:05.496664 24948 solver.cpp:244]     Train net output #1: loss = 0.0711143 (* 1 = 0.0711143 loss)
I0912 00:38:05.496670 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.959159
I0912 00:38:05.496675 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997092
I0912 00:38:05.496682 24948 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0912 00:38:22.386782 24948 solver.cpp:228] Iteration 540, loss = 0.149309
I0912 00:38:22.386822 24948 solver.cpp:244]     Train net output #0: accuracy = 0.960644
I0912 00:38:22.386835 24948 solver.cpp:244]     Train net output #1: loss = 0.149309 (* 1 = 0.149309 loss)
I0912 00:38:22.386840 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980865
I0912 00:38:22.386847 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.920777
I0912 00:38:22.386853 24948 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0912 00:38:39.282399 24948 solver.cpp:228] Iteration 560, loss = 0.0406498
I0912 00:38:39.282552 24948 solver.cpp:244]     Train net output #0: accuracy = 0.988731
I0912 00:38:39.282570 24948 solver.cpp:244]     Train net output #1: loss = 0.0406497 (* 1 = 0.0406497 loss)
I0912 00:38:39.282577 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983832
I0912 00:38:39.282582 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992257
I0912 00:38:39.282594 24948 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0912 00:38:56.171978 24948 solver.cpp:228] Iteration 580, loss = 0.0462067
I0912 00:38:56.172020 24948 solver.cpp:244]     Train net output #0: accuracy = 0.988328
I0912 00:38:56.172031 24948 solver.cpp:244]     Train net output #1: loss = 0.0462066 (* 1 = 0.0462066 loss)
I0912 00:38:56.172039 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991838
I0912 00:38:56.172042 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.974541
I0912 00:38:56.172051 24948 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0912 00:39:13.064363 24948 solver.cpp:228] Iteration 600, loss = 0.0379287
I0912 00:39:13.064461 24948 solver.cpp:244]     Train net output #0: accuracy = 0.984099
I0912 00:39:13.064477 24948 solver.cpp:244]     Train net output #1: loss = 0.0379286 (* 1 = 0.0379286 loss)
I0912 00:39:13.064486 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979289
I0912 00:39:13.064491 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993872
I0912 00:39:13.064498 24948 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0912 00:39:29.968721 24948 solver.cpp:228] Iteration 620, loss = 0.0378826
I0912 00:39:29.968766 24948 solver.cpp:244]     Train net output #0: accuracy = 0.982344
I0912 00:39:29.968780 24948 solver.cpp:244]     Train net output #1: loss = 0.0378825 (* 1 = 0.0378825 loss)
I0912 00:39:29.968785 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972444
I0912 00:39:29.968789 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997363
I0912 00:39:29.968797 24948 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0912 00:39:46.857432 24948 solver.cpp:228] Iteration 640, loss = 0.0247583
I0912 00:39:46.857560 24948 solver.cpp:244]     Train net output #0: accuracy = 0.990119
I0912 00:39:46.857601 24948 solver.cpp:244]     Train net output #1: loss = 0.0247583 (* 1 = 0.0247583 loss)
I0912 00:39:46.857610 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986713
I0912 00:39:46.857620 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995176
I0912 00:39:46.857630 24948 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0912 00:40:03.798761 24948 solver.cpp:228] Iteration 660, loss = 0.00886779
I0912 00:40:03.798810 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997057
I0912 00:40:03.798825 24948 solver.cpp:244]     Train net output #1: loss = 0.00886771 (* 1 = 0.00886771 loss)
I0912 00:40:03.798830 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997114
I0912 00:40:03.798836 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996947
I0912 00:40:03.798843 24948 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0912 00:40:20.687435 24948 solver.cpp:228] Iteration 680, loss = 0.0189806
I0912 00:40:20.687587 24948 solver.cpp:244]     Train net output #0: accuracy = 0.993887
I0912 00:40:20.687628 24948 solver.cpp:244]     Train net output #1: loss = 0.0189805 (* 1 = 0.0189805 loss)
I0912 00:40:20.687638 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988514
I0912 00:40:20.687647 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997992
I0912 00:40:20.687655 24948 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0912 00:40:37.596671 24948 solver.cpp:228] Iteration 700, loss = 0.0190532
I0912 00:40:37.596717 24948 solver.cpp:244]     Train net output #0: accuracy = 0.992266
I0912 00:40:37.596732 24948 solver.cpp:244]     Train net output #1: loss = 0.0190531 (* 1 = 0.0190531 loss)
I0912 00:40:37.596738 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988599
I0912 00:40:37.596743 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996576
I0912 00:40:37.596750 24948 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0912 00:40:54.586556 24948 solver.cpp:228] Iteration 720, loss = 0.0168023
I0912 00:40:54.586730 24948 solver.cpp:244]     Train net output #0: accuracy = 0.991943
I0912 00:40:54.586746 24948 solver.cpp:244]     Train net output #1: loss = 0.0168022 (* 1 = 0.0168022 loss)
I0912 00:40:54.586751 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986109
I0912 00:40:54.586763 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999032
I0912 00:40:54.586771 24948 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0912 00:41:11.488786 24948 solver.cpp:228] Iteration 740, loss = 0.0352306
I0912 00:41:11.488828 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994443
I0912 00:41:11.488840 24948 solver.cpp:244]     Train net output #1: loss = 0.0352305 (* 1 = 0.0352305 loss)
I0912 00:41:11.488847 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994108
I0912 00:41:11.488852 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99691
I0912 00:41:11.488859 24948 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0912 00:41:28.376864 24948 solver.cpp:228] Iteration 760, loss = 0.0171567
I0912 00:41:28.376998 24948 solver.cpp:244]     Train net output #0: accuracy = 0.993769
I0912 00:41:28.377013 24948 solver.cpp:244]     Train net output #1: loss = 0.0171566 (* 1 = 0.0171566 loss)
I0912 00:41:28.377022 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992877
I0912 00:41:28.377027 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995488
I0912 00:41:28.377035 24948 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0912 00:41:45.266851 24948 solver.cpp:228] Iteration 780, loss = 0.0163862
I0912 00:41:45.266892 24948 solver.cpp:244]     Train net output #0: accuracy = 0.993762
I0912 00:41:45.266904 24948 solver.cpp:244]     Train net output #1: loss = 0.0163862 (* 1 = 0.0163862 loss)
I0912 00:41:45.266911 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993302
I0912 00:41:45.266916 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995163
I0912 00:41:45.266923 24948 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0912 00:42:02.171217 24948 solver.cpp:228] Iteration 800, loss = 0.0134871
I0912 00:42:02.171357 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995867
I0912 00:42:02.171401 24948 solver.cpp:244]     Train net output #1: loss = 0.013487 (* 1 = 0.013487 loss)
I0912 00:42:02.171409 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996482
I0912 00:42:02.171421 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993843
I0912 00:42:02.171428 24948 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0912 00:42:19.083408 24948 solver.cpp:228] Iteration 820, loss = 0.0417082
I0912 00:42:19.083451 24948 solver.cpp:244]     Train net output #0: accuracy = 0.988433
I0912 00:42:19.083464 24948 solver.cpp:244]     Train net output #1: loss = 0.0417081 (* 1 = 0.0417081 loss)
I0912 00:42:19.083470 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989247
I0912 00:42:19.083475 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987635
I0912 00:42:19.083482 24948 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0912 00:42:35.978518 24948 solver.cpp:228] Iteration 840, loss = 0.0289886
I0912 00:42:35.978624 24948 solver.cpp:244]     Train net output #0: accuracy = 0.990379
I0912 00:42:35.978639 24948 solver.cpp:244]     Train net output #1: loss = 0.0289886 (* 1 = 0.0289886 loss)
I0912 00:42:35.978649 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988527
I0912 00:42:35.978662 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992565
I0912 00:42:35.978672 24948 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0912 00:42:52.857336 24948 solver.cpp:228] Iteration 860, loss = 0.0404741
I0912 00:42:52.857378 24948 solver.cpp:244]     Train net output #0: accuracy = 0.988352
I0912 00:42:52.857393 24948 solver.cpp:244]     Train net output #1: loss = 0.040474 (* 1 = 0.040474 loss)
I0912 00:42:52.857399 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987314
I0912 00:42:52.857404 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994434
I0912 00:42:52.857411 24948 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0912 00:43:09.757133 24948 solver.cpp:228] Iteration 880, loss = 0.0159161
I0912 00:43:09.757287 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994497
I0912 00:43:09.757303 24948 solver.cpp:244]     Train net output #1: loss = 0.015916 (* 1 = 0.015916 loss)
I0912 00:43:09.757314 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991672
I0912 00:43:09.757319 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997811
I0912 00:43:09.757326 24948 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0912 00:43:26.646914 24948 solver.cpp:228] Iteration 900, loss = 0.0281078
I0912 00:43:26.646958 24948 solver.cpp:244]     Train net output #0: accuracy = 0.988045
I0912 00:43:26.646972 24948 solver.cpp:244]     Train net output #1: loss = 0.0281077 (* 1 = 0.0281077 loss)
I0912 00:43:26.646978 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980665
I0912 00:43:26.646983 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995479
I0912 00:43:26.646991 24948 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0912 00:43:43.533277 24948 solver.cpp:228] Iteration 920, loss = 0.0162399
I0912 00:43:43.533392 24948 solver.cpp:244]     Train net output #0: accuracy = 0.993234
I0912 00:43:43.533406 24948 solver.cpp:244]     Train net output #1: loss = 0.0162398 (* 1 = 0.0162398 loss)
I0912 00:43:43.533411 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990989
I0912 00:43:43.533416 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999429
I0912 00:43:43.533423 24948 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0912 00:44:00.422271 24948 solver.cpp:228] Iteration 940, loss = 0.0292084
I0912 00:44:00.422314 24948 solver.cpp:244]     Train net output #0: accuracy = 0.98957
I0912 00:44:00.422328 24948 solver.cpp:244]     Train net output #1: loss = 0.0292083 (* 1 = 0.0292083 loss)
I0912 00:44:00.422334 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982589
I0912 00:44:00.422338 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99548
I0912 00:44:00.422346 24948 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0912 00:44:17.316905 24948 solver.cpp:228] Iteration 960, loss = 0.0170932
I0912 00:44:17.317025 24948 solver.cpp:244]     Train net output #0: accuracy = 0.993252
I0912 00:44:17.317039 24948 solver.cpp:244]     Train net output #1: loss = 0.0170931 (* 1 = 0.0170931 loss)
I0912 00:44:17.317045 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992616
I0912 00:44:17.317050 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99533
I0912 00:44:17.317057 24948 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0912 00:44:34.206532 24948 solver.cpp:228] Iteration 980, loss = 0.0132033
I0912 00:44:34.206569 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995401
I0912 00:44:34.206583 24948 solver.cpp:244]     Train net output #1: loss = 0.0132032 (* 1 = 0.0132032 loss)
I0912 00:44:34.206588 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995734
I0912 00:44:34.206593 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994602
I0912 00:44:34.206601 24948 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0912 00:44:51.096108 24948 solver.cpp:228] Iteration 1000, loss = 0.0247634
I0912 00:44:51.096225 24948 solver.cpp:244]     Train net output #0: accuracy = 0.990475
I0912 00:44:51.096240 24948 solver.cpp:244]     Train net output #1: loss = 0.0247633 (* 1 = 0.0247633 loss)
I0912 00:44:51.096251 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991959
I0912 00:44:51.096257 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986464
I0912 00:44:51.096264 24948 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0912 00:45:07.988040 24948 solver.cpp:228] Iteration 1020, loss = 0.0150985
I0912 00:45:07.988080 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994803
I0912 00:45:07.988091 24948 solver.cpp:244]     Train net output #1: loss = 0.0150984 (* 1 = 0.0150984 loss)
I0912 00:45:07.988097 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992839
I0912 00:45:07.988102 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996837
I0912 00:45:07.988108 24948 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0912 00:45:24.879513 24948 solver.cpp:228] Iteration 1040, loss = 0.0164181
I0912 00:45:24.879670 24948 solver.cpp:244]     Train net output #0: accuracy = 0.992875
I0912 00:45:24.879688 24948 solver.cpp:244]     Train net output #1: loss = 0.016418 (* 1 = 0.016418 loss)
I0912 00:45:24.879696 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989449
I0912 00:45:24.879701 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998315
I0912 00:45:24.879709 24948 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0912 00:45:41.785594 24948 solver.cpp:228] Iteration 1060, loss = 0.0354079
I0912 00:45:41.785636 24948 solver.cpp:244]     Train net output #0: accuracy = 0.989032
I0912 00:45:41.785648 24948 solver.cpp:244]     Train net output #1: loss = 0.0354078 (* 1 = 0.0354078 loss)
I0912 00:45:41.785655 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983686
I0912 00:45:41.785660 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992589
I0912 00:45:41.785666 24948 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0912 00:45:58.683944 24948 solver.cpp:228] Iteration 1080, loss = 0.0396552
I0912 00:45:58.684053 24948 solver.cpp:244]     Train net output #0: accuracy = 0.98735
I0912 00:45:58.684068 24948 solver.cpp:244]     Train net output #1: loss = 0.0396551 (* 1 = 0.0396551 loss)
I0912 00:45:58.684074 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974214
I0912 00:45:58.684079 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994866
I0912 00:45:58.684087 24948 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0912 00:46:15.571569 24948 solver.cpp:228] Iteration 1100, loss = 0.0259351
I0912 00:46:15.571614 24948 solver.cpp:244]     Train net output #0: accuracy = 0.992766
I0912 00:46:15.571626 24948 solver.cpp:244]     Train net output #1: loss = 0.0259351 (* 1 = 0.0259351 loss)
I0912 00:46:15.571632 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989765
I0912 00:46:15.571637 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994666
I0912 00:46:15.571646 24948 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0912 00:46:32.465801 24948 solver.cpp:228] Iteration 1120, loss = 0.0244815
I0912 00:46:32.465909 24948 solver.cpp:244]     Train net output #0: accuracy = 0.991633
I0912 00:46:32.465925 24948 solver.cpp:244]     Train net output #1: loss = 0.0244815 (* 1 = 0.0244815 loss)
I0912 00:46:32.465939 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992716
I0912 00:46:32.465943 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990255
I0912 00:46:32.465950 24948 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0912 00:46:49.350741 24948 solver.cpp:228] Iteration 1140, loss = 0.0217036
I0912 00:46:49.350785 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994453
I0912 00:46:49.350798 24948 solver.cpp:244]     Train net output #1: loss = 0.0217036 (* 1 = 0.0217036 loss)
I0912 00:46:49.350805 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993686
I0912 00:46:49.350810 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999651
I0912 00:46:49.350816 24948 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0912 00:47:06.245682 24948 solver.cpp:228] Iteration 1160, loss = 0.0174246
I0912 00:47:06.245852 24948 solver.cpp:244]     Train net output #0: accuracy = 0.991778
I0912 00:47:06.245867 24948 solver.cpp:244]     Train net output #1: loss = 0.0174246 (* 1 = 0.0174246 loss)
I0912 00:47:06.245873 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986613
I0912 00:47:06.245877 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998205
I0912 00:47:06.245884 24948 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0912 00:47:23.145874 24948 solver.cpp:228] Iteration 1180, loss = 0.00885756
I0912 00:47:23.145916 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996088
I0912 00:47:23.145929 24948 solver.cpp:244]     Train net output #1: loss = 0.00885747 (* 1 = 0.00885747 loss)
I0912 00:47:23.145936 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993885
I0912 00:47:23.145941 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998836
I0912 00:47:23.145947 24948 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0912 00:47:40.034657 24948 solver.cpp:228] Iteration 1200, loss = 0.0132397
I0912 00:47:40.034778 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994517
I0912 00:47:40.034793 24948 solver.cpp:244]     Train net output #1: loss = 0.0132396 (* 1 = 0.0132396 loss)
I0912 00:47:40.034806 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990782
I0912 00:47:40.034812 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998023
I0912 00:47:40.034819 24948 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0912 00:47:56.922416 24948 solver.cpp:228] Iteration 1220, loss = 0.0125956
I0912 00:47:56.922461 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994598
I0912 00:47:56.922475 24948 solver.cpp:244]     Train net output #1: loss = 0.0125955 (* 1 = 0.0125955 loss)
I0912 00:47:56.922492 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991347
I0912 00:47:56.922503 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998869
I0912 00:47:56.922510 24948 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0912 00:48:13.819167 24948 solver.cpp:228] Iteration 1240, loss = 0.0218632
I0912 00:48:13.819273 24948 solver.cpp:244]     Train net output #0: accuracy = 0.993524
I0912 00:48:13.819289 24948 solver.cpp:244]     Train net output #1: loss = 0.0218632 (* 1 = 0.0218632 loss)
I0912 00:48:13.819295 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994514
I0912 00:48:13.819299 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987962
I0912 00:48:13.819306 24948 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0912 00:48:30.732556 24948 solver.cpp:228] Iteration 1260, loss = 0.0079995
I0912 00:48:30.732597 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997215
I0912 00:48:30.732610 24948 solver.cpp:244]     Train net output #1: loss = 0.00799941 (* 1 = 0.00799941 loss)
I0912 00:48:30.732616 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997218
I0912 00:48:30.732621 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997206
I0912 00:48:30.732630 24948 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0912 00:48:47.614962 24948 solver.cpp:228] Iteration 1280, loss = 0.0129059
I0912 00:48:47.615072 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994337
I0912 00:48:47.615087 24948 solver.cpp:244]     Train net output #1: loss = 0.0129058 (* 1 = 0.0129058 loss)
I0912 00:48:47.615093 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990659
I0912 00:48:47.615097 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998306
I0912 00:48:47.615104 24948 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0912 00:49:04.509209 24948 solver.cpp:228] Iteration 1300, loss = 0.0384315
I0912 00:49:04.509249 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995528
I0912 00:49:04.509261 24948 solver.cpp:244]     Train net output #1: loss = 0.0384314 (* 1 = 0.0384314 loss)
I0912 00:49:04.509268 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995758
I0912 00:49:04.509272 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992348
I0912 00:49:04.509279 24948 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0912 00:49:21.407225 24948 solver.cpp:228] Iteration 1320, loss = 0.0163551
I0912 00:49:21.407404 24948 solver.cpp:244]     Train net output #0: accuracy = 0.992441
I0912 00:49:21.407425 24948 solver.cpp:244]     Train net output #1: loss = 0.0163551 (* 1 = 0.0163551 loss)
I0912 00:49:21.407433 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98915
I0912 00:49:21.407438 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997658
I0912 00:49:21.407444 24948 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0912 00:49:38.297396 24948 solver.cpp:228] Iteration 1340, loss = 0.0143511
I0912 00:49:38.297436 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994525
I0912 00:49:38.297448 24948 solver.cpp:244]     Train net output #1: loss = 0.014351 (* 1 = 0.014351 loss)
I0912 00:49:38.297454 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991337
I0912 00:49:38.297459 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9974
I0912 00:49:38.297467 24948 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0912 00:49:55.193948 24948 solver.cpp:228] Iteration 1360, loss = 0.0113475
I0912 00:49:55.194049 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995681
I0912 00:49:55.194064 24948 solver.cpp:244]     Train net output #1: loss = 0.0113474 (* 1 = 0.0113474 loss)
I0912 00:49:55.194077 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995538
I0912 00:49:55.194082 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995871
I0912 00:49:55.194087 24948 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0912 00:50:12.083889 24948 solver.cpp:228] Iteration 1380, loss = 0.0106101
I0912 00:50:12.083930 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996088
I0912 00:50:12.083945 24948 solver.cpp:244]     Train net output #1: loss = 0.0106101 (* 1 = 0.0106101 loss)
I0912 00:50:12.083950 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996471
I0912 00:50:12.083956 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995127
I0912 00:50:12.083963 24948 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0912 00:50:28.961326 24948 solver.cpp:228] Iteration 1400, loss = 0.0133445
I0912 00:50:28.961448 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994484
I0912 00:50:28.961463 24948 solver.cpp:244]     Train net output #1: loss = 0.0133444 (* 1 = 0.0133444 loss)
I0912 00:50:28.961477 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993809
I0912 00:50:28.961482 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995745
I0912 00:50:28.961489 24948 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0912 00:50:45.846209 24948 solver.cpp:228] Iteration 1420, loss = 0.0051938
I0912 00:50:45.846252 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998196
I0912 00:50:45.846266 24948 solver.cpp:244]     Train net output #1: loss = 0.00519371 (* 1 = 0.00519371 loss)
I0912 00:50:45.846272 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998027
I0912 00:50:45.846277 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998562
I0912 00:50:45.846284 24948 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0912 00:51:02.735103 24948 solver.cpp:228] Iteration 1440, loss = 0.0108647
I0912 00:51:02.735214 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995544
I0912 00:51:02.735229 24948 solver.cpp:244]     Train net output #1: loss = 0.0108647 (* 1 = 0.0108647 loss)
I0912 00:51:02.735244 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99218
I0912 00:51:02.735249 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998535
I0912 00:51:02.735255 24948 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0912 00:51:19.624665 24948 solver.cpp:228] Iteration 1460, loss = 0.00990677
I0912 00:51:19.624708 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996042
I0912 00:51:19.624722 24948 solver.cpp:244]     Train net output #1: loss = 0.00990668 (* 1 = 0.00990668 loss)
I0912 00:51:19.624728 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995594
I0912 00:51:19.624733 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996907
I0912 00:51:19.624742 24948 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0912 00:51:36.507278 24948 solver.cpp:228] Iteration 1480, loss = 0.00553885
I0912 00:51:36.507470 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998148
I0912 00:51:36.507494 24948 solver.cpp:244]     Train net output #1: loss = 0.00553878 (* 1 = 0.00553878 loss)
I0912 00:51:36.507503 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998396
I0912 00:51:36.507508 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997537
I0912 00:51:36.507515 24948 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0912 00:51:53.407888 24948 solver.cpp:228] Iteration 1500, loss = 0.00984986
I0912 00:51:53.407927 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997432
I0912 00:51:53.407939 24948 solver.cpp:244]     Train net output #1: loss = 0.00984979 (* 1 = 0.00984979 loss)
I0912 00:51:53.407944 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999399
I0912 00:51:53.407949 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990554
I0912 00:51:53.407956 24948 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0912 00:52:10.295753 24948 solver.cpp:228] Iteration 1520, loss = 0.0139886
I0912 00:52:10.295871 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994459
I0912 00:52:10.295886 24948 solver.cpp:244]     Train net output #1: loss = 0.0139885 (* 1 = 0.0139885 loss)
I0912 00:52:10.295898 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994121
I0912 00:52:10.295903 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995366
I0912 00:52:10.295910 24948 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0912 00:52:27.207691 24948 solver.cpp:228] Iteration 1540, loss = 0.02192
I0912 00:52:27.207733 24948 solver.cpp:244]     Train net output #0: accuracy = 0.991027
I0912 00:52:27.207746 24948 solver.cpp:244]     Train net output #1: loss = 0.02192 (* 1 = 0.02192 loss)
I0912 00:52:27.207753 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985891
I0912 00:52:27.207757 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995999
I0912 00:52:27.207765 24948 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0912 00:52:44.118814 24948 solver.cpp:228] Iteration 1560, loss = 0.00940407
I0912 00:52:44.118937 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996325
I0912 00:52:44.118953 24948 solver.cpp:244]     Train net output #1: loss = 0.009404 (* 1 = 0.009404 loss)
I0912 00:52:44.118965 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995657
I0912 00:52:44.118969 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997363
I0912 00:52:44.118976 24948 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0912 00:53:01.019783 24948 solver.cpp:228] Iteration 1580, loss = 0.0208444
I0912 00:53:01.019824 24948 solver.cpp:244]     Train net output #0: accuracy = 0.992224
I0912 00:53:01.019835 24948 solver.cpp:244]     Train net output #1: loss = 0.0208443 (* 1 = 0.0208443 loss)
I0912 00:53:01.019841 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992634
I0912 00:53:01.019846 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991107
I0912 00:53:01.019853 24948 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0912 00:53:17.937461 24948 solver.cpp:228] Iteration 1600, loss = 0.00620284
I0912 00:53:17.937623 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997577
I0912 00:53:17.937640 24948 solver.cpp:244]     Train net output #1: loss = 0.00620278 (* 1 = 0.00620278 loss)
I0912 00:53:17.937654 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997173
I0912 00:53:17.937660 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9983
I0912 00:53:17.937669 24948 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0912 00:53:34.833151 24948 solver.cpp:228] Iteration 1620, loss = 0.00758346
I0912 00:53:34.833189 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997501
I0912 00:53:34.833202 24948 solver.cpp:244]     Train net output #1: loss = 0.0075834 (* 1 = 0.0075834 loss)
I0912 00:53:34.833209 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998014
I0912 00:53:34.833214 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995775
I0912 00:53:34.833221 24948 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0912 00:53:51.741264 24948 solver.cpp:228] Iteration 1640, loss = 0.00734162
I0912 00:53:51.741391 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997403
I0912 00:53:51.741405 24948 solver.cpp:244]     Train net output #1: loss = 0.00734155 (* 1 = 0.00734155 loss)
I0912 00:53:51.741411 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997751
I0912 00:53:51.741416 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996774
I0912 00:53:51.741425 24948 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0912 00:54:08.633999 24948 solver.cpp:228] Iteration 1660, loss = 0.016133
I0912 00:54:08.634042 24948 solver.cpp:244]     Train net output #0: accuracy = 0.993273
I0912 00:54:08.634057 24948 solver.cpp:244]     Train net output #1: loss = 0.016133 (* 1 = 0.016133 loss)
I0912 00:54:08.634063 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992166
I0912 00:54:08.634076 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99522
I0912 00:54:08.634084 24948 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0912 00:54:25.540693 24948 solver.cpp:228] Iteration 1680, loss = 0.0104329
I0912 00:54:25.540814 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996697
I0912 00:54:25.540828 24948 solver.cpp:244]     Train net output #1: loss = 0.0104329 (* 1 = 0.0104329 loss)
I0912 00:54:25.540834 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997449
I0912 00:54:25.540839 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993688
I0912 00:54:25.540846 24948 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0912 00:54:42.431779 24948 solver.cpp:228] Iteration 1700, loss = 0.0073594
I0912 00:54:42.431823 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996908
I0912 00:54:42.431838 24948 solver.cpp:244]     Train net output #1: loss = 0.00735934 (* 1 = 0.00735934 loss)
I0912 00:54:42.431843 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996459
I0912 00:54:42.431849 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997916
I0912 00:54:42.431855 24948 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0912 00:54:59.334218 24948 solver.cpp:228] Iteration 1720, loss = 0.00713091
I0912 00:54:59.334326 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997034
I0912 00:54:59.334342 24948 solver.cpp:244]     Train net output #1: loss = 0.00713085 (* 1 = 0.00713085 loss)
I0912 00:54:59.334355 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996253
I0912 00:54:59.334360 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998156
I0912 00:54:59.334369 24948 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0912 00:55:16.229156 24948 solver.cpp:228] Iteration 1740, loss = 0.00574654
I0912 00:55:16.229202 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998359
I0912 00:55:16.229215 24948 solver.cpp:244]     Train net output #1: loss = 0.00574649 (* 1 = 0.00574649 loss)
I0912 00:55:16.229223 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999511
I0912 00:55:16.229228 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995865
I0912 00:55:16.229236 24948 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0912 00:55:33.124282 24948 solver.cpp:228] Iteration 1760, loss = 0.0127606
I0912 00:55:33.124460 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994321
I0912 00:55:33.124477 24948 solver.cpp:244]     Train net output #1: loss = 0.0127605 (* 1 = 0.0127605 loss)
I0912 00:55:33.124485 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99229
I0912 00:55:33.124495 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997403
I0912 00:55:33.124503 24948 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0912 00:55:50.035449 24948 solver.cpp:228] Iteration 1780, loss = 0.0128029
I0912 00:55:50.035490 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994016
I0912 00:55:50.035504 24948 solver.cpp:244]     Train net output #1: loss = 0.0128028 (* 1 = 0.0128028 loss)
I0912 00:55:50.035511 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990847
I0912 00:55:50.035516 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999079
I0912 00:55:50.035524 24948 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0912 00:56:06.940203 24948 solver.cpp:228] Iteration 1800, loss = 0.00613553
I0912 00:56:06.940327 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997902
I0912 00:56:06.940343 24948 solver.cpp:244]     Train net output #1: loss = 0.00613547 (* 1 = 0.00613547 loss)
I0912 00:56:06.940353 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998405
I0912 00:56:06.940358 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996238
I0912 00:56:06.940366 24948 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0912 00:56:23.843690 24948 solver.cpp:228] Iteration 1820, loss = 0.00811977
I0912 00:56:23.843734 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996583
I0912 00:56:23.843747 24948 solver.cpp:244]     Train net output #1: loss = 0.00811971 (* 1 = 0.00811971 loss)
I0912 00:56:23.843753 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996227
I0912 00:56:23.843758 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997264
I0912 00:56:23.843765 24948 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0912 00:56:40.738620 24948 solver.cpp:228] Iteration 1840, loss = 0.00881625
I0912 00:56:40.738734 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996408
I0912 00:56:40.738749 24948 solver.cpp:244]     Train net output #1: loss = 0.00881619 (* 1 = 0.00881619 loss)
I0912 00:56:40.738754 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993107
I0912 00:56:40.738759 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999029
I0912 00:56:40.738767 24948 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0912 00:56:57.630210 24948 solver.cpp:228] Iteration 1860, loss = 0.0075279
I0912 00:56:57.630252 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996839
I0912 00:56:57.630264 24948 solver.cpp:244]     Train net output #1: loss = 0.00752784 (* 1 = 0.00752784 loss)
I0912 00:56:57.630270 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996375
I0912 00:56:57.630281 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997626
I0912 00:56:57.630288 24948 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0912 00:57:14.520077 24948 solver.cpp:228] Iteration 1880, loss = 0.00969127
I0912 00:57:14.520195 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995665
I0912 00:57:14.520207 24948 solver.cpp:244]     Train net output #1: loss = 0.00969121 (* 1 = 0.00969121 loss)
I0912 00:57:14.520213 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994173
I0912 00:57:14.520218 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997695
I0912 00:57:14.520226 24948 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0912 00:57:31.422449 24948 solver.cpp:228] Iteration 1900, loss = 0.00956334
I0912 00:57:31.422495 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996487
I0912 00:57:31.422508 24948 solver.cpp:244]     Train net output #1: loss = 0.00956328 (* 1 = 0.00956328 loss)
I0912 00:57:31.422513 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996345
I0912 00:57:31.422518 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996673
I0912 00:57:31.422526 24948 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0912 00:57:48.336975 24948 solver.cpp:228] Iteration 1920, loss = 0.0147228
I0912 00:57:48.337144 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994021
I0912 00:57:48.337167 24948 solver.cpp:244]     Train net output #1: loss = 0.0147228 (* 1 = 0.0147228 loss)
I0912 00:57:48.337174 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992432
I0912 00:57:48.337179 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995975
I0912 00:57:48.337186 24948 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0912 00:58:05.233654 24948 solver.cpp:228] Iteration 1940, loss = 0.0141441
I0912 00:58:05.233697 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994754
I0912 00:58:05.233711 24948 solver.cpp:244]     Train net output #1: loss = 0.0141441 (* 1 = 0.0141441 loss)
I0912 00:58:05.233717 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989654
I0912 00:58:05.233721 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998165
I0912 00:58:05.233729 24948 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0912 00:58:22.126027 24948 solver.cpp:228] Iteration 1960, loss = 0.00988599
I0912 00:58:22.126142 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995952
I0912 00:58:22.126155 24948 solver.cpp:244]     Train net output #1: loss = 0.00988593 (* 1 = 0.00988593 loss)
I0912 00:58:22.126170 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994579
I0912 00:58:22.126175 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997584
I0912 00:58:22.126183 24948 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0912 00:58:39.116940 24948 solver.cpp:228] Iteration 1980, loss = 0.0124195
I0912 00:58:39.116983 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995569
I0912 00:58:39.116997 24948 solver.cpp:244]     Train net output #1: loss = 0.0124195 (* 1 = 0.0124195 loss)
I0912 00:58:39.117004 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992903
I0912 00:58:39.117010 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997586
I0912 00:58:39.117018 24948 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0912 00:58:56.013375 24948 solver.cpp:228] Iteration 2000, loss = 0.0106286
I0912 00:58:56.013481 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996607
I0912 00:58:56.013495 24948 solver.cpp:244]     Train net output #1: loss = 0.0106286 (* 1 = 0.0106286 loss)
I0912 00:58:56.013500 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997846
I0912 00:58:56.013505 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99197
I0912 00:58:56.013514 24948 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0912 00:59:12.909381 24948 solver.cpp:228] Iteration 2020, loss = 0.00713093
I0912 00:59:12.909420 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996916
I0912 00:59:12.909432 24948 solver.cpp:244]     Train net output #1: loss = 0.00713086 (* 1 = 0.00713086 loss)
I0912 00:59:12.909438 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996772
I0912 00:59:12.909443 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997253
I0912 00:59:12.909451 24948 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0912 00:59:29.818135 24948 solver.cpp:228] Iteration 2040, loss = 0.0171825
I0912 00:59:29.818233 24948 solver.cpp:244]     Train net output #0: accuracy = 0.991797
I0912 00:59:29.818246 24948 solver.cpp:244]     Train net output #1: loss = 0.0171824 (* 1 = 0.0171824 loss)
I0912 00:59:29.818259 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986621
I0912 00:59:29.818264 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998046
I0912 00:59:29.818269 24948 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0912 00:59:46.717272 24948 solver.cpp:228] Iteration 2060, loss = 0.00971873
I0912 00:59:46.717314 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996379
I0912 00:59:46.717325 24948 solver.cpp:244]     Train net output #1: loss = 0.00971867 (* 1 = 0.00971867 loss)
I0912 00:59:46.717331 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996535
I0912 00:59:46.717336 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995765
I0912 00:59:46.717344 24948 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0912 01:00:03.614754 24948 solver.cpp:228] Iteration 2080, loss = 0.00704751
I0912 01:00:03.614910 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997106
I0912 01:00:03.614928 24948 solver.cpp:244]     Train net output #1: loss = 0.00704745 (* 1 = 0.00704745 loss)
I0912 01:00:03.614935 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996563
I0912 01:00:03.614940 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998058
I0912 01:00:03.614948 24948 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0912 01:00:20.522346 24948 solver.cpp:228] Iteration 2100, loss = 0.0171839
I0912 01:00:20.522387 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994366
I0912 01:00:20.522399 24948 solver.cpp:244]     Train net output #1: loss = 0.0171839 (* 1 = 0.0171839 loss)
I0912 01:00:20.522405 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994242
I0912 01:00:20.522410 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995173
I0912 01:00:20.522418 24948 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0912 01:00:37.422194 24948 solver.cpp:228] Iteration 2120, loss = 0.00930716
I0912 01:00:37.422298 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995703
I0912 01:00:37.422314 24948 solver.cpp:244]     Train net output #1: loss = 0.0093071 (* 1 = 0.0093071 loss)
I0912 01:00:37.422322 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993427
I0912 01:00:37.422328 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998686
I0912 01:00:37.422336 24948 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0912 01:00:54.350235 24948 solver.cpp:228] Iteration 2140, loss = 0.0124415
I0912 01:00:54.350273 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995314
I0912 01:00:54.350287 24948 solver.cpp:244]     Train net output #1: loss = 0.0124414 (* 1 = 0.0124414 loss)
I0912 01:00:54.350293 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994472
I0912 01:00:54.350298 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996362
I0912 01:00:54.350306 24948 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0912 01:01:11.236873 24948 solver.cpp:228] Iteration 2160, loss = 0.0114557
I0912 01:01:11.236976 24948 solver.cpp:244]     Train net output #0: accuracy = 0.99542
I0912 01:01:11.236990 24948 solver.cpp:244]     Train net output #1: loss = 0.0114556 (* 1 = 0.0114556 loss)
I0912 01:01:11.236997 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994102
I0912 01:01:11.237001 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997086
I0912 01:01:11.237009 24948 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0912 01:01:28.132905 24948 solver.cpp:228] Iteration 2180, loss = 0.00413777
I0912 01:01:28.132951 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998466
I0912 01:01:28.132964 24948 solver.cpp:244]     Train net output #1: loss = 0.00413771 (* 1 = 0.00413771 loss)
I0912 01:01:28.132971 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998495
I0912 01:01:28.132974 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998416
I0912 01:01:28.132982 24948 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0912 01:01:45.025066 24948 solver.cpp:228] Iteration 2200, loss = 0.0117219
I0912 01:01:45.025238 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995284
I0912 01:01:45.025254 24948 solver.cpp:244]     Train net output #1: loss = 0.0117219 (* 1 = 0.0117219 loss)
I0912 01:01:45.025260 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994963
I0912 01:01:45.025265 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995929
I0912 01:01:45.025272 24948 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0912 01:02:01.918179 24948 solver.cpp:228] Iteration 2220, loss = 0.00842721
I0912 01:02:01.918223 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996911
I0912 01:02:01.918237 24948 solver.cpp:244]     Train net output #1: loss = 0.00842715 (* 1 = 0.00842715 loss)
I0912 01:02:01.918242 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994972
I0912 01:02:01.918247 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998427
I0912 01:02:01.918254 24948 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0912 01:02:18.809904 24948 solver.cpp:228] Iteration 2240, loss = 0.00890293
I0912 01:02:18.810014 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996373
I0912 01:02:18.810029 24948 solver.cpp:244]     Train net output #1: loss = 0.00890287 (* 1 = 0.00890287 loss)
I0912 01:02:18.810034 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995468
I0912 01:02:18.810039 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997692
I0912 01:02:18.810045 24948 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0912 01:02:35.703315 24948 solver.cpp:228] Iteration 2260, loss = 0.0073034
I0912 01:02:35.703361 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997364
I0912 01:02:35.703374 24948 solver.cpp:244]     Train net output #1: loss = 0.00730335 (* 1 = 0.00730335 loss)
I0912 01:02:35.703382 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997646
I0912 01:02:35.703387 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996453
I0912 01:02:35.703397 24948 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0912 01:02:52.588973 24948 solver.cpp:228] Iteration 2280, loss = 0.00613068
I0912 01:02:52.589071 24948 solver.cpp:244]     Train net output #0: accuracy = 0.9976
I0912 01:02:52.589087 24948 solver.cpp:244]     Train net output #1: loss = 0.00613062 (* 1 = 0.00613062 loss)
I0912 01:02:52.589102 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997505
I0912 01:02:52.589107 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997751
I0912 01:02:52.589113 24948 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0912 01:03:09.484531 24948 solver.cpp:228] Iteration 2300, loss = 0.0162545
I0912 01:03:09.484573 24948 solver.cpp:244]     Train net output #0: accuracy = 0.99318
I0912 01:03:09.484587 24948 solver.cpp:244]     Train net output #1: loss = 0.0162545 (* 1 = 0.0162545 loss)
I0912 01:03:09.484593 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986292
I0912 01:03:09.484598 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998287
I0912 01:03:09.484606 24948 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0912 01:03:26.377977 24948 solver.cpp:228] Iteration 2320, loss = 0.00998069
I0912 01:03:26.378074 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995438
I0912 01:03:26.378089 24948 solver.cpp:244]     Train net output #1: loss = 0.00998063 (* 1 = 0.00998063 loss)
I0912 01:03:26.378095 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993972
I0912 01:03:26.378100 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99803
I0912 01:03:26.378108 24948 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0912 01:03:43.277626 24948 solver.cpp:228] Iteration 2340, loss = 0.00942869
I0912 01:03:43.277667 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996238
I0912 01:03:43.277679 24948 solver.cpp:244]     Train net output #1: loss = 0.00942864 (* 1 = 0.00942864 loss)
I0912 01:03:43.277685 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994073
I0912 01:03:43.277690 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9982
I0912 01:03:43.277698 24948 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0912 01:04:00.167157 24948 solver.cpp:228] Iteration 2360, loss = 0.0173384
I0912 01:04:00.167309 24948 solver.cpp:244]     Train net output #0: accuracy = 0.992826
I0912 01:04:00.167331 24948 solver.cpp:244]     Train net output #1: loss = 0.0173384 (* 1 = 0.0173384 loss)
I0912 01:04:00.167340 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993122
I0912 01:04:00.167346 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992119
I0912 01:04:00.167353 24948 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0912 01:04:17.056588 24948 solver.cpp:228] Iteration 2380, loss = 0.0113984
I0912 01:04:17.056629 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995425
I0912 01:04:17.056643 24948 solver.cpp:244]     Train net output #1: loss = 0.0113983 (* 1 = 0.0113983 loss)
I0912 01:04:17.056649 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994095
I0912 01:04:17.056654 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996813
I0912 01:04:17.056661 24948 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0912 01:04:33.965802 24948 solver.cpp:228] Iteration 2400, loss = 0.01251
I0912 01:04:33.965898 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994702
I0912 01:04:33.965912 24948 solver.cpp:244]     Train net output #1: loss = 0.01251 (* 1 = 0.01251 loss)
I0912 01:04:33.965924 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994207
I0912 01:04:33.965929 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995783
I0912 01:04:33.965935 24948 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0912 01:04:50.857657 24948 solver.cpp:228] Iteration 2420, loss = 0.00823008
I0912 01:04:50.857702 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996638
I0912 01:04:50.857714 24948 solver.cpp:244]     Train net output #1: loss = 0.00823003 (* 1 = 0.00823003 loss)
I0912 01:04:50.857722 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995212
I0912 01:04:50.857728 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998145
I0912 01:04:50.857733 24948 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0912 01:05:07.751709 24948 solver.cpp:228] Iteration 2440, loss = 0.00808987
I0912 01:05:07.751807 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996568
I0912 01:05:07.751821 24948 solver.cpp:244]     Train net output #1: loss = 0.00808982 (* 1 = 0.00808982 loss)
I0912 01:05:07.751828 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994145
I0912 01:05:07.751832 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998711
I0912 01:05:07.751839 24948 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0912 01:05:24.657701 24948 solver.cpp:228] Iteration 2460, loss = 0.00809392
I0912 01:05:24.657744 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996672
I0912 01:05:24.657758 24948 solver.cpp:244]     Train net output #1: loss = 0.00809387 (* 1 = 0.00809387 loss)
I0912 01:05:24.657764 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996599
I0912 01:05:24.657769 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996876
I0912 01:05:24.657778 24948 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0912 01:05:41.560256 24948 solver.cpp:228] Iteration 2480, loss = 0.00326622
I0912 01:05:41.560350 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998754
I0912 01:05:41.560365 24948 solver.cpp:244]     Train net output #1: loss = 0.00326617 (* 1 = 0.00326617 loss)
I0912 01:05:41.560371 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998572
I0912 01:05:41.560375 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99907
I0912 01:05:41.560382 24948 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0912 01:05:58.456837 24948 solver.cpp:228] Iteration 2500, loss = 0.00710086
I0912 01:05:58.456882 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996991
I0912 01:05:58.456897 24948 solver.cpp:244]     Train net output #1: loss = 0.00710081 (* 1 = 0.00710081 loss)
I0912 01:05:58.456904 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995277
I0912 01:05:58.456910 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998759
I0912 01:05:58.456926 24948 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0912 01:06:15.346766 24948 solver.cpp:228] Iteration 2520, loss = 0.00581471
I0912 01:06:15.346920 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997399
I0912 01:06:15.346937 24948 solver.cpp:244]     Train net output #1: loss = 0.00581466 (* 1 = 0.00581466 loss)
I0912 01:06:15.346946 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99683
I0912 01:06:15.346951 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998346
I0912 01:06:15.346958 24948 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0912 01:06:32.248235 24948 solver.cpp:228] Iteration 2540, loss = 0.00890207
I0912 01:06:32.248276 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995861
I0912 01:06:32.248291 24948 solver.cpp:244]     Train net output #1: loss = 0.00890202 (* 1 = 0.00890202 loss)
I0912 01:06:32.248296 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994619
I0912 01:06:32.248301 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998122
I0912 01:06:32.248308 24948 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0912 01:06:49.144698 24948 solver.cpp:228] Iteration 2560, loss = 0.00662085
I0912 01:06:49.144850 24948 solver.cpp:244]     Train net output #0: accuracy = 0.99773
I0912 01:06:49.144894 24948 solver.cpp:244]     Train net output #1: loss = 0.0066208 (* 1 = 0.0066208 loss)
I0912 01:06:49.144902 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998192
I0912 01:06:49.144913 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995868
I0912 01:06:49.144922 24948 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0912 01:07:06.043709 24948 solver.cpp:228] Iteration 2580, loss = 0.00858779
I0912 01:07:06.043756 24948 solver.cpp:244]     Train net output #0: accuracy = 0.99626
I0912 01:07:06.043769 24948 solver.cpp:244]     Train net output #1: loss = 0.00858774 (* 1 = 0.00858774 loss)
I0912 01:07:06.043776 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995799
I0912 01:07:06.043781 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997484
I0912 01:07:06.043789 24948 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0912 01:07:22.934540 24948 solver.cpp:228] Iteration 2600, loss = 0.00709374
I0912 01:07:22.934676 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997079
I0912 01:07:22.934691 24948 solver.cpp:244]     Train net output #1: loss = 0.00709369 (* 1 = 0.00709369 loss)
I0912 01:07:22.934698 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996849
I0912 01:07:22.934702 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997487
I0912 01:07:22.934710 24948 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0912 01:07:39.846736 24948 solver.cpp:228] Iteration 2620, loss = 0.0102512
I0912 01:07:39.846777 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995087
I0912 01:07:39.846789 24948 solver.cpp:244]     Train net output #1: loss = 0.0102511 (* 1 = 0.0102511 loss)
I0912 01:07:39.846796 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992275
I0912 01:07:39.846801 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998751
I0912 01:07:39.846809 24948 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0912 01:07:56.738124 24948 solver.cpp:228] Iteration 2640, loss = 0.0088231
I0912 01:07:56.738273 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996073
I0912 01:07:56.738314 24948 solver.cpp:244]     Train net output #1: loss = 0.00882305 (* 1 = 0.00882305 loss)
I0912 01:07:56.738324 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995304
I0912 01:07:56.738335 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997719
I0912 01:07:56.738345 24948 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0912 01:08:13.691557 24948 solver.cpp:228] Iteration 2660, loss = 0.00614114
I0912 01:08:13.691598 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997494
I0912 01:08:13.691610 24948 solver.cpp:244]     Train net output #1: loss = 0.00614109 (* 1 = 0.00614109 loss)
I0912 01:08:13.691617 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997387
I0912 01:08:13.691622 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997819
I0912 01:08:13.691632 24948 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0912 01:08:30.588299 24948 solver.cpp:228] Iteration 2680, loss = 0.0113626
I0912 01:08:30.588465 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998125
I0912 01:08:30.588479 24948 solver.cpp:244]     Train net output #1: loss = 0.0113626 (* 1 = 0.0113626 loss)
I0912 01:08:30.588487 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998308
I0912 01:08:30.588500 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996219
I0912 01:08:30.588506 24948 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0912 01:08:47.494089 24948 solver.cpp:228] Iteration 2700, loss = 0.00522474
I0912 01:08:47.494132 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997692
I0912 01:08:47.494148 24948 solver.cpp:244]     Train net output #1: loss = 0.00522469 (* 1 = 0.00522469 loss)
I0912 01:08:47.494153 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996171
I0912 01:08:47.494158 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999325
I0912 01:08:47.494165 24948 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0912 01:09:04.396525 24948 solver.cpp:228] Iteration 2720, loss = 0.00552401
I0912 01:09:04.396634 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998009
I0912 01:09:04.396651 24948 solver.cpp:244]     Train net output #1: loss = 0.00552396 (* 1 = 0.00552396 loss)
I0912 01:09:04.396664 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998415
I0912 01:09:04.396669 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996571
I0912 01:09:04.396677 24948 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0912 01:09:21.283907 24948 solver.cpp:228] Iteration 2740, loss = 0.00674555
I0912 01:09:21.283953 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997491
I0912 01:09:21.283967 24948 solver.cpp:244]     Train net output #1: loss = 0.0067455 (* 1 = 0.0067455 loss)
I0912 01:09:21.283975 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99715
I0912 01:09:21.283982 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997937
I0912 01:09:21.283990 24948 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0912 01:09:38.190623 24948 solver.cpp:228] Iteration 2760, loss = 0.00487717
I0912 01:09:38.190738 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998262
I0912 01:09:38.190753 24948 solver.cpp:244]     Train net output #1: loss = 0.00487712 (* 1 = 0.00487712 loss)
I0912 01:09:38.190762 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998314
I0912 01:09:38.190765 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998196
I0912 01:09:38.190773 24948 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0912 01:09:55.093242 24948 solver.cpp:228] Iteration 2780, loss = 0.00782757
I0912 01:09:55.093281 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996826
I0912 01:09:55.093294 24948 solver.cpp:244]     Train net output #1: loss = 0.00782751 (* 1 = 0.00782751 loss)
I0912 01:09:55.093300 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996793
I0912 01:09:55.093307 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996891
I0912 01:09:55.093313 24948 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0912 01:10:12.003754 24948 solver.cpp:228] Iteration 2800, loss = 0.0102606
I0912 01:10:12.003924 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996429
I0912 01:10:12.003947 24948 solver.cpp:244]     Train net output #1: loss = 0.0102605 (* 1 = 0.0102605 loss)
I0912 01:10:12.003957 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990981
I0912 01:10:12.003968 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999386
I0912 01:10:12.003975 24948 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0912 01:10:28.906059 24948 solver.cpp:228] Iteration 2820, loss = 0.00704789
I0912 01:10:28.906100 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997263
I0912 01:10:28.906111 24948 solver.cpp:244]     Train net output #1: loss = 0.00704783 (* 1 = 0.00704783 loss)
I0912 01:10:28.906116 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997496
I0912 01:10:28.906121 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996834
I0912 01:10:28.906127 24948 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0912 01:10:45.809828 24948 solver.cpp:228] Iteration 2840, loss = 0.00695309
I0912 01:10:45.809943 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997507
I0912 01:10:45.809959 24948 solver.cpp:244]     Train net output #1: loss = 0.00695303 (* 1 = 0.00695303 loss)
I0912 01:10:45.809965 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997601
I0912 01:10:45.809970 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997388
I0912 01:10:45.809978 24948 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0912 01:11:02.707770 24948 solver.cpp:228] Iteration 2860, loss = 0.0068376
I0912 01:11:02.707811 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997277
I0912 01:11:02.707826 24948 solver.cpp:244]     Train net output #1: loss = 0.00683754 (* 1 = 0.00683754 loss)
I0912 01:11:02.707831 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997159
I0912 01:11:02.707844 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997752
I0912 01:11:02.707851 24948 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0912 01:11:19.606668 24948 solver.cpp:228] Iteration 2880, loss = 0.0105949
I0912 01:11:19.606765 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995748
I0912 01:11:19.606781 24948 solver.cpp:244]     Train net output #1: loss = 0.0105948 (* 1 = 0.0105948 loss)
I0912 01:11:19.606796 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993247
I0912 01:11:19.606808 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998232
I0912 01:11:19.606817 24948 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0912 01:11:36.501477 24948 solver.cpp:228] Iteration 2900, loss = 0.00458094
I0912 01:11:36.501519 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998063
I0912 01:11:36.501533 24948 solver.cpp:244]     Train net output #1: loss = 0.00458089 (* 1 = 0.00458089 loss)
I0912 01:11:36.501538 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997877
I0912 01:11:36.501543 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998435
I0912 01:11:36.501550 24948 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0912 01:11:53.406730 24948 solver.cpp:228] Iteration 2920, loss = 0.00516127
I0912 01:11:53.406846 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998614
I0912 01:11:53.406858 24948 solver.cpp:244]     Train net output #1: loss = 0.00516121 (* 1 = 0.00516121 loss)
I0912 01:11:53.406864 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999157
I0912 01:11:53.406869 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995961
I0912 01:11:53.406877 24948 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0912 01:12:10.314756 24948 solver.cpp:228] Iteration 2940, loss = 0.00492292
I0912 01:12:10.314801 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997927
I0912 01:12:10.314815 24948 solver.cpp:244]     Train net output #1: loss = 0.00492287 (* 1 = 0.00492287 loss)
I0912 01:12:10.314821 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997887
I0912 01:12:10.314826 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998004
I0912 01:12:10.314833 24948 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0912 01:12:27.229107 24948 solver.cpp:228] Iteration 2960, loss = 0.00943507
I0912 01:12:27.229270 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996681
I0912 01:12:27.229295 24948 solver.cpp:244]     Train net output #1: loss = 0.00943502 (* 1 = 0.00943502 loss)
I0912 01:12:27.229302 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997174
I0912 01:12:27.229306 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99598
I0912 01:12:27.229315 24948 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0912 01:12:44.140429 24948 solver.cpp:228] Iteration 2980, loss = 0.0090169
I0912 01:12:44.140473 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996437
I0912 01:12:44.140487 24948 solver.cpp:244]     Train net output #1: loss = 0.00901685 (* 1 = 0.00901685 loss)
I0912 01:12:44.140492 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996003
I0912 01:12:44.140497 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997064
I0912 01:12:44.140504 24948 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0912 01:13:01.025262 24948 solver.cpp:228] Iteration 3000, loss = 0.00340943
I0912 01:13:01.025354 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998786
I0912 01:13:01.025375 24948 solver.cpp:244]     Train net output #1: loss = 0.00340937 (* 1 = 0.00340937 loss)
I0912 01:13:01.025382 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999096
I0912 01:13:01.025388 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998043
I0912 01:13:01.025393 24948 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0912 01:13:17.926972 24948 solver.cpp:228] Iteration 3020, loss = 0.00534178
I0912 01:13:17.927016 24948 solver.cpp:244]     Train net output #0: accuracy = 0.99764
I0912 01:13:17.927031 24948 solver.cpp:244]     Train net output #1: loss = 0.00534173 (* 1 = 0.00534173 loss)
I0912 01:13:17.927038 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996102
I0912 01:13:17.927044 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999268
I0912 01:13:17.927052 24948 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0912 01:13:34.830224 24948 solver.cpp:228] Iteration 3040, loss = 0.00658739
I0912 01:13:34.830319 24948 solver.cpp:244]     Train net output #0: accuracy = 0.99741
I0912 01:13:34.830337 24948 solver.cpp:244]     Train net output #1: loss = 0.00658734 (* 1 = 0.00658734 loss)
I0912 01:13:34.830349 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997318
I0912 01:13:34.830354 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997856
I0912 01:13:34.830361 24948 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0912 01:13:51.728742 24948 solver.cpp:228] Iteration 3060, loss = 0.00526149
I0912 01:13:51.728785 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997597
I0912 01:13:51.728797 24948 solver.cpp:244]     Train net output #1: loss = 0.00526143 (* 1 = 0.00526143 loss)
I0912 01:13:51.728802 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996342
I0912 01:13:51.728807 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999205
I0912 01:13:51.728814 24948 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0912 01:14:08.619805 24948 solver.cpp:228] Iteration 3080, loss = 0.00631646
I0912 01:14:08.619910 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997433
I0912 01:14:08.619925 24948 solver.cpp:244]     Train net output #1: loss = 0.0063164 (* 1 = 0.0063164 loss)
I0912 01:14:08.619936 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996485
I0912 01:14:08.619941 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998392
I0912 01:14:08.619948 24948 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0912 01:14:25.512850 24948 solver.cpp:228] Iteration 3100, loss = 0.00510393
I0912 01:14:25.512892 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998306
I0912 01:14:25.512905 24948 solver.cpp:244]     Train net output #1: loss = 0.00510387 (* 1 = 0.00510387 loss)
I0912 01:14:25.512912 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998212
I0912 01:14:25.512917 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998399
I0912 01:14:25.512924 24948 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0912 01:14:42.419667 24948 solver.cpp:228] Iteration 3120, loss = 0.00917682
I0912 01:14:42.419826 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996247
I0912 01:14:42.419850 24948 solver.cpp:244]     Train net output #1: loss = 0.00917676 (* 1 = 0.00917676 loss)
I0912 01:14:42.419858 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995989
I0912 01:14:42.419870 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99664
I0912 01:14:42.419879 24948 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0912 01:14:59.322448 24948 solver.cpp:228] Iteration 3140, loss = 0.00557834
I0912 01:14:59.322491 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997633
I0912 01:14:59.322504 24948 solver.cpp:244]     Train net output #1: loss = 0.00557829 (* 1 = 0.00557829 loss)
I0912 01:14:59.322510 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995588
I0912 01:14:59.322523 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999333
I0912 01:14:59.322530 24948 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0912 01:15:16.231956 24948 solver.cpp:228] Iteration 3160, loss = 0.00469627
I0912 01:15:16.232100 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998336
I0912 01:15:16.232141 24948 solver.cpp:244]     Train net output #1: loss = 0.00469622 (* 1 = 0.00469622 loss)
I0912 01:15:16.232151 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998633
I0912 01:15:16.232161 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997302
I0912 01:15:16.232174 24948 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0912 01:15:33.200716 24948 solver.cpp:228] Iteration 3180, loss = 0.00531501
I0912 01:15:33.200755 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997857
I0912 01:15:33.200772 24948 solver.cpp:244]     Train net output #1: loss = 0.00531495 (* 1 = 0.00531495 loss)
I0912 01:15:33.200778 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997904
I0912 01:15:33.200783 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9977
I0912 01:15:33.200790 24948 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0912 01:15:50.102085 24948 solver.cpp:228] Iteration 3200, loss = 0.00742272
I0912 01:15:50.102206 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998521
I0912 01:15:50.102221 24948 solver.cpp:244]     Train net output #1: loss = 0.00742266 (* 1 = 0.00742266 loss)
I0912 01:15:50.102227 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998719
I0912 01:15:50.102238 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996876
I0912 01:15:50.102246 24948 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0912 01:16:07.004367 24948 solver.cpp:228] Iteration 3220, loss = 0.00744793
I0912 01:16:07.004412 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996927
I0912 01:16:07.004426 24948 solver.cpp:244]     Train net output #1: loss = 0.00744787 (* 1 = 0.00744787 loss)
I0912 01:16:07.004431 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996545
I0912 01:16:07.004437 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997748
I0912 01:16:07.004443 24948 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0912 01:16:23.903491 24948 solver.cpp:228] Iteration 3240, loss = 0.0106576
I0912 01:16:23.903656 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996034
I0912 01:16:23.903672 24948 solver.cpp:244]     Train net output #1: loss = 0.0106575 (* 1 = 0.0106575 loss)
I0912 01:16:23.903684 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995659
I0912 01:16:23.903689 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996401
I0912 01:16:23.903697 24948 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0912 01:16:40.805897 24948 solver.cpp:228] Iteration 3260, loss = 0.0308026
I0912 01:16:40.805943 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995535
I0912 01:16:40.805958 24948 solver.cpp:244]     Train net output #1: loss = 0.0308026 (* 1 = 0.0308026 loss)
I0912 01:16:40.805965 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995776
I0912 01:16:40.805971 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995458
I0912 01:16:40.805979 24948 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0912 01:16:57.709794 24948 solver.cpp:228] Iteration 3280, loss = 0.00781386
I0912 01:16:57.709928 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996785
I0912 01:16:57.709969 24948 solver.cpp:244]     Train net output #1: loss = 0.00781381 (* 1 = 0.00781381 loss)
I0912 01:16:57.709978 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994095
I0912 01:16:57.709983 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998959
I0912 01:16:57.709992 24948 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0912 01:17:14.632077 24948 solver.cpp:228] Iteration 3300, loss = 0.00608981
I0912 01:17:14.632120 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997668
I0912 01:17:14.632135 24948 solver.cpp:244]     Train net output #1: loss = 0.00608976 (* 1 = 0.00608976 loss)
I0912 01:17:14.632143 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996892
I0912 01:17:14.632148 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998408
I0912 01:17:14.632155 24948 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0912 01:17:31.530083 24948 solver.cpp:228] Iteration 3320, loss = 0.00937537
I0912 01:17:31.530200 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996068
I0912 01:17:31.530216 24948 solver.cpp:244]     Train net output #1: loss = 0.00937532 (* 1 = 0.00937532 loss)
I0912 01:17:31.530227 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995312
I0912 01:17:31.530232 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997133
I0912 01:17:31.530239 24948 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0912 01:17:48.440119 24948 solver.cpp:228] Iteration 3340, loss = 0.0031284
I0912 01:17:48.440160 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998608
I0912 01:17:48.440173 24948 solver.cpp:244]     Train net output #1: loss = 0.00312834 (* 1 = 0.00312834 loss)
I0912 01:17:48.440179 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998235
I0912 01:17:48.440184 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999433
I0912 01:17:48.440191 24948 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0912 01:18:05.338171 24948 solver.cpp:228] Iteration 3360, loss = 0.00554713
I0912 01:18:05.338311 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998006
I0912 01:18:05.338356 24948 solver.cpp:244]     Train net output #1: loss = 0.00554708 (* 1 = 0.00554708 loss)
I0912 01:18:05.338366 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998247
I0912 01:18:05.338374 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997494
I0912 01:18:05.338383 24948 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0912 01:18:22.298385 24948 solver.cpp:228] Iteration 3380, loss = 0.0123905
I0912 01:18:22.298427 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995025
I0912 01:18:22.298441 24948 solver.cpp:244]     Train net output #1: loss = 0.0123905 (* 1 = 0.0123905 loss)
I0912 01:18:22.298449 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993896
I0912 01:18:22.298452 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996169
I0912 01:18:22.298460 24948 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0912 01:18:39.207747 24948 solver.cpp:228] Iteration 3400, loss = 0.00552588
I0912 01:18:39.207912 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997637
I0912 01:18:39.207929 24948 solver.cpp:244]     Train net output #1: loss = 0.00552583 (* 1 = 0.00552583 loss)
I0912 01:18:39.207937 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996721
I0912 01:18:39.207942 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998829
I0912 01:18:39.207950 24948 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0912 01:18:56.119562 24948 solver.cpp:228] Iteration 3420, loss = 0.00498739
I0912 01:18:56.119604 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997694
I0912 01:18:56.119616 24948 solver.cpp:244]     Train net output #1: loss = 0.00498733 (* 1 = 0.00498733 loss)
I0912 01:18:56.119623 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997068
I0912 01:18:56.119628 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998851
I0912 01:18:56.119637 24948 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0912 01:19:13.017019 24948 solver.cpp:228] Iteration 3440, loss = 0.00464218
I0912 01:19:13.017125 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997892
I0912 01:19:13.017143 24948 solver.cpp:244]     Train net output #1: loss = 0.00464212 (* 1 = 0.00464212 loss)
I0912 01:19:13.017148 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997525
I0912 01:19:13.017160 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998906
I0912 01:19:13.017168 24948 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0912 01:19:29.923213 24948 solver.cpp:228] Iteration 3460, loss = 0.00409983
I0912 01:19:29.923256 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998419
I0912 01:19:29.923270 24948 solver.cpp:244]     Train net output #1: loss = 0.00409978 (* 1 = 0.00409978 loss)
I0912 01:19:29.923277 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998052
I0912 01:19:29.923282 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998926
I0912 01:19:29.923290 24948 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0912 01:19:46.821807 24948 solver.cpp:228] Iteration 3480, loss = 0.00868931
I0912 01:19:46.821923 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995846
I0912 01:19:46.821938 24948 solver.cpp:244]     Train net output #1: loss = 0.00868926 (* 1 = 0.00868926 loss)
I0912 01:19:46.821944 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993613
I0912 01:19:46.821949 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998746
I0912 01:19:46.821956 24948 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0912 01:20:03.722154 24948 solver.cpp:228] Iteration 3500, loss = 0.0103396
I0912 01:20:03.722198 24948 solver.cpp:244]     Train net output #0: accuracy = 0.995194
I0912 01:20:03.722213 24948 solver.cpp:244]     Train net output #1: loss = 0.0103395 (* 1 = 0.0103395 loss)
I0912 01:20:03.722220 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991631
I0912 01:20:03.722226 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998773
I0912 01:20:03.722235 24948 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0912 01:20:20.617022 24948 solver.cpp:228] Iteration 3520, loss = 0.00439982
I0912 01:20:20.617131 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998291
I0912 01:20:20.617146 24948 solver.cpp:244]     Train net output #1: loss = 0.00439976 (* 1 = 0.00439976 loss)
I0912 01:20:20.617151 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997936
I0912 01:20:20.617156 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998801
I0912 01:20:20.617163 24948 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0912 01:20:37.528131 24948 solver.cpp:228] Iteration 3540, loss = 0.00385276
I0912 01:20:37.528175 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998479
I0912 01:20:37.528190 24948 solver.cpp:244]     Train net output #1: loss = 0.00385271 (* 1 = 0.00385271 loss)
I0912 01:20:37.528198 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998572
I0912 01:20:37.528203 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998172
I0912 01:20:37.528213 24948 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0912 01:20:54.430644 24948 solver.cpp:228] Iteration 3560, loss = 0.00598058
I0912 01:20:54.430820 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997458
I0912 01:20:54.430837 24948 solver.cpp:244]     Train net output #1: loss = 0.00598052 (* 1 = 0.00598052 loss)
I0912 01:20:54.430845 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997242
I0912 01:20:54.430857 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998306
I0912 01:20:54.430865 24948 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0912 01:21:11.335644 24948 solver.cpp:228] Iteration 3580, loss = 0.00536373
I0912 01:21:11.335686 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997938
I0912 01:21:11.335698 24948 solver.cpp:244]     Train net output #1: loss = 0.00536367 (* 1 = 0.00536367 loss)
I0912 01:21:11.335705 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996746
I0912 01:21:11.335710 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998951
I0912 01:21:11.335716 24948 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0912 01:21:28.240118 24948 solver.cpp:228] Iteration 3600, loss = 0.0051546
I0912 01:21:28.240222 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997963
I0912 01:21:28.240238 24948 solver.cpp:244]     Train net output #1: loss = 0.00515454 (* 1 = 0.00515454 loss)
I0912 01:21:28.240244 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998003
I0912 01:21:28.240249 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997872
I0912 01:21:28.240257 24948 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0912 01:21:45.141151 24948 solver.cpp:228] Iteration 3620, loss = 0.00694791
I0912 01:21:45.141194 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996979
I0912 01:21:45.141206 24948 solver.cpp:244]     Train net output #1: loss = 0.00694785 (* 1 = 0.00694785 loss)
I0912 01:21:45.141211 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99582
I0912 01:21:45.141216 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998434
I0912 01:21:45.141223 24948 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0912 01:22:02.041945 24948 solver.cpp:228] Iteration 3640, loss = 0.00883
I0912 01:22:02.042043 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996338
I0912 01:22:02.042060 24948 solver.cpp:244]     Train net output #1: loss = 0.00882994 (* 1 = 0.00882994 loss)
I0912 01:22:02.042068 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993192
I0912 01:22:02.042073 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998648
I0912 01:22:02.042081 24948 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0912 01:22:18.953279 24948 solver.cpp:228] Iteration 3660, loss = 0.0071741
I0912 01:22:18.953321 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996937
I0912 01:22:18.953333 24948 solver.cpp:244]     Train net output #1: loss = 0.00717404 (* 1 = 0.00717404 loss)
I0912 01:22:18.953341 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995704
I0912 01:22:18.953346 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998338
I0912 01:22:18.953352 24948 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0912 01:22:35.871253 24948 solver.cpp:228] Iteration 3680, loss = 0.00602314
I0912 01:22:35.871354 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997185
I0912 01:22:35.871371 24948 solver.cpp:244]     Train net output #1: loss = 0.00602308 (* 1 = 0.00602308 loss)
I0912 01:22:35.871376 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996264
I0912 01:22:35.871383 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998925
I0912 01:22:35.871392 24948 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0912 01:22:52.770694 24948 solver.cpp:228] Iteration 3700, loss = 0.0029087
I0912 01:22:52.770731 24948 solver.cpp:244]     Train net output #0: accuracy = 0.999187
I0912 01:22:52.770746 24948 solver.cpp:244]     Train net output #1: loss = 0.00290864 (* 1 = 0.00290864 loss)
I0912 01:22:52.770752 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999394
I0912 01:22:52.770756 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998309
I0912 01:22:52.770764 24948 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0912 01:23:09.666528 24948 solver.cpp:228] Iteration 3720, loss = 0.00372604
I0912 01:23:09.666687 24948 solver.cpp:244]     Train net output #0: accuracy = 0.99921
I0912 01:23:09.666702 24948 solver.cpp:244]     Train net output #1: loss = 0.00372599 (* 1 = 0.00372599 loss)
I0912 01:23:09.666708 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999282
I0912 01:23:09.666713 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998769
I0912 01:23:09.666721 24948 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0912 01:23:26.569588 24948 solver.cpp:228] Iteration 3740, loss = 0.00385336
I0912 01:23:26.569636 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998471
I0912 01:23:26.569649 24948 solver.cpp:244]     Train net output #1: loss = 0.00385331 (* 1 = 0.00385331 loss)
I0912 01:23:26.569655 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998271
I0912 01:23:26.569660 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998819
I0912 01:23:26.569667 24948 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0912 01:23:43.466071 24948 solver.cpp:228] Iteration 3760, loss = 0.00619451
I0912 01:23:43.466189 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997428
I0912 01:23:43.466205 24948 solver.cpp:244]     Train net output #1: loss = 0.00619446 (* 1 = 0.00619446 loss)
I0912 01:23:43.466212 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997012
I0912 01:23:43.466218 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998181
I0912 01:23:43.466226 24948 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0912 01:24:00.364234 24948 solver.cpp:228] Iteration 3780, loss = 0.00734358
I0912 01:24:00.364276 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997229
I0912 01:24:00.364289 24948 solver.cpp:244]     Train net output #1: loss = 0.00734353 (* 1 = 0.00734353 loss)
I0912 01:24:00.364295 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9975
I0912 01:24:00.364300 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996573
I0912 01:24:00.364307 24948 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0912 01:24:17.277674 24948 solver.cpp:228] Iteration 3800, loss = 0.00622828
I0912 01:24:17.277787 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997668
I0912 01:24:17.277803 24948 solver.cpp:244]     Train net output #1: loss = 0.00622823 (* 1 = 0.00622823 loss)
I0912 01:24:17.277811 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996937
I0912 01:24:17.277817 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99837
I0912 01:24:17.277824 24948 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0912 01:24:34.162066 24948 solver.cpp:228] Iteration 3820, loss = 0.00362953
I0912 01:24:34.162108 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998508
I0912 01:24:34.162122 24948 solver.cpp:244]     Train net output #1: loss = 0.00362948 (* 1 = 0.00362948 loss)
I0912 01:24:34.162127 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998331
I0912 01:24:34.162132 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998884
I0912 01:24:34.162138 24948 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0912 01:24:51.059435 24948 solver.cpp:228] Iteration 3840, loss = 0.00683815
I0912 01:24:51.059602 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997044
I0912 01:24:51.059619 24948 solver.cpp:244]     Train net output #1: loss = 0.0068381 (* 1 = 0.0068381 loss)
I0912 01:24:51.059626 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9963
I0912 01:24:51.059631 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998077
I0912 01:24:51.059638 24948 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0912 01:25:07.965700 24948 solver.cpp:228] Iteration 3860, loss = 0.010369
I0912 01:25:07.965741 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997841
I0912 01:25:07.965754 24948 solver.cpp:244]     Train net output #1: loss = 0.010369 (* 1 = 0.010369 loss)
I0912 01:25:07.965759 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997909
I0912 01:25:07.965764 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997108
I0912 01:25:07.965772 24948 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0912 01:25:24.877703 24948 solver.cpp:228] Iteration 3880, loss = 0.00662327
I0912 01:25:24.877817 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997392
I0912 01:25:24.877833 24948 solver.cpp:244]     Train net output #1: loss = 0.00662322 (* 1 = 0.00662322 loss)
I0912 01:25:24.877840 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997502
I0912 01:25:24.877843 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99698
I0912 01:25:24.877851 24948 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0912 01:25:41.785295 24948 solver.cpp:228] Iteration 3900, loss = 0.00814566
I0912 01:25:41.785342 24948 solver.cpp:244]     Train net output #0: accuracy = 0.99656
I0912 01:25:41.785356 24948 solver.cpp:244]     Train net output #1: loss = 0.00814561 (* 1 = 0.00814561 loss)
I0912 01:25:41.785368 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996328
I0912 01:25:41.785375 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997018
I0912 01:25:41.785383 24948 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0912 01:25:58.685849 24948 solver.cpp:228] Iteration 3920, loss = 0.00529233
I0912 01:25:58.685957 24948 solver.cpp:244]     Train net output #0: accuracy = 0.99839
I0912 01:25:58.685972 24948 solver.cpp:244]     Train net output #1: loss = 0.00529228 (* 1 = 0.00529228 loss)
I0912 01:25:58.685978 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998613
I0912 01:25:58.685983 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997143
I0912 01:25:58.685992 24948 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0912 01:26:15.596096 24948 solver.cpp:228] Iteration 3940, loss = 0.00533933
I0912 01:26:15.596139 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997967
I0912 01:26:15.596153 24948 solver.cpp:244]     Train net output #1: loss = 0.00533928 (* 1 = 0.00533928 loss)
I0912 01:26:15.596161 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997153
I0912 01:26:15.596168 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998721
I0912 01:26:15.596182 24948 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0912 01:26:32.497258 24948 solver.cpp:228] Iteration 3960, loss = 0.00686551
I0912 01:26:32.497355 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997208
I0912 01:26:32.497373 24948 solver.cpp:244]     Train net output #1: loss = 0.00686547 (* 1 = 0.00686547 loss)
I0912 01:26:32.497381 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995394
I0912 01:26:32.497386 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998615
I0912 01:26:32.497401 24948 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0912 01:26:49.402606 24948 solver.cpp:228] Iteration 3980, loss = 0.00400343
I0912 01:26:49.402649 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998176
I0912 01:26:49.402663 24948 solver.cpp:244]     Train net output #1: loss = 0.00400338 (* 1 = 0.00400338 loss)
I0912 01:26:49.402670 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997405
I0912 01:26:49.402676 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999318
I0912 01:26:49.402684 24948 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0912 01:27:06.290442 24948 solver.cpp:228] Iteration 4000, loss = 0.00817969
I0912 01:27:06.290607 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996435
I0912 01:27:06.290626 24948 solver.cpp:244]     Train net output #1: loss = 0.00817964 (* 1 = 0.00817964 loss)
I0912 01:27:06.290632 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994518
I0912 01:27:06.290637 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998301
I0912 01:27:06.290644 24948 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0912 01:27:23.192728 24948 solver.cpp:228] Iteration 4020, loss = 0.00676203
I0912 01:27:23.192772 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997487
I0912 01:27:23.192786 24948 solver.cpp:244]     Train net output #1: loss = 0.00676198 (* 1 = 0.00676198 loss)
I0912 01:27:23.192793 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99753
I0912 01:27:23.192798 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997424
I0912 01:27:23.192806 24948 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0912 01:27:40.103735 24948 solver.cpp:228] Iteration 4040, loss = 0.00667448
I0912 01:27:40.103837 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997192
I0912 01:27:40.103850 24948 solver.cpp:244]     Train net output #1: loss = 0.00667443 (* 1 = 0.00667443 loss)
I0912 01:27:40.103857 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996073
I0912 01:27:40.103863 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998479
I0912 01:27:40.103869 24948 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0912 01:27:57.013465 24948 solver.cpp:228] Iteration 4060, loss = 0.00825602
I0912 01:27:57.013510 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996481
I0912 01:27:57.013523 24948 solver.cpp:244]     Train net output #1: loss = 0.00825597 (* 1 = 0.00825597 loss)
I0912 01:27:57.013530 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993011
I0912 01:27:57.013535 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998936
I0912 01:27:57.013542 24948 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0912 01:28:13.912722 24948 solver.cpp:228] Iteration 4080, loss = 0.00379681
I0912 01:28:13.912819 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998299
I0912 01:28:13.912835 24948 solver.cpp:244]     Train net output #1: loss = 0.00379676 (* 1 = 0.00379676 loss)
I0912 01:28:13.912842 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998035
I0912 01:28:13.912849 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999063
I0912 01:28:13.912858 24948 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0912 01:28:30.828045 24948 solver.cpp:228] Iteration 4100, loss = 0.00612559
I0912 01:28:30.828086 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997471
I0912 01:28:30.828099 24948 solver.cpp:244]     Train net output #1: loss = 0.00612554 (* 1 = 0.00612554 loss)
I0912 01:28:30.828105 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997354
I0912 01:28:30.828110 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997985
I0912 01:28:30.828117 24948 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0912 01:28:47.735551 24948 solver.cpp:228] Iteration 4120, loss = 0.0037112
I0912 01:28:47.735652 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998339
I0912 01:28:47.735668 24948 solver.cpp:244]     Train net output #1: loss = 0.00371115 (* 1 = 0.00371115 loss)
I0912 01:28:47.735677 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997803
I0912 01:28:47.735682 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99926
I0912 01:28:47.735692 24948 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0912 01:29:04.632062 24948 solver.cpp:228] Iteration 4140, loss = 0.00941467
I0912 01:29:04.632103 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996451
I0912 01:29:04.632115 24948 solver.cpp:244]     Train net output #1: loss = 0.00941462 (* 1 = 0.00941462 loss)
I0912 01:29:04.632122 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994379
I0912 01:29:04.632127 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998149
I0912 01:29:04.632134 24948 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0912 01:29:21.542196 24948 solver.cpp:228] Iteration 4160, loss = 0.00402844
I0912 01:29:21.542326 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998523
I0912 01:29:21.542361 24948 solver.cpp:244]     Train net output #1: loss = 0.00402839 (* 1 = 0.00402839 loss)
I0912 01:29:21.542368 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997441
I0912 01:29:21.542381 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999386
I0912 01:29:21.542388 24948 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0912 01:29:38.447048 24948 solver.cpp:228] Iteration 4180, loss = 0.0052826
I0912 01:29:38.447091 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997575
I0912 01:29:38.447103 24948 solver.cpp:244]     Train net output #1: loss = 0.00528255 (* 1 = 0.00528255 loss)
I0912 01:29:38.447109 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996418
I0912 01:29:38.447114 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999127
I0912 01:29:38.447121 24948 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0912 01:29:55.351244 24948 solver.cpp:228] Iteration 4200, loss = 0.00395445
I0912 01:29:55.351351 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998262
I0912 01:29:55.351366 24948 solver.cpp:244]     Train net output #1: loss = 0.0039544 (* 1 = 0.0039544 loss)
I0912 01:29:55.351373 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997624
I0912 01:29:55.351378 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999188
I0912 01:29:55.351385 24948 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0912 01:30:12.254611 24948 solver.cpp:228] Iteration 4220, loss = 0.00537236
I0912 01:30:12.254657 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997561
I0912 01:30:12.254673 24948 solver.cpp:244]     Train net output #1: loss = 0.00537231 (* 1 = 0.00537231 loss)
I0912 01:30:12.254679 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995958
I0912 01:30:12.254685 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9993
I0912 01:30:12.254693 24948 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0912 01:30:29.172813 24948 solver.cpp:228] Iteration 4240, loss = 0.00615695
I0912 01:30:29.172907 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997105
I0912 01:30:29.172922 24948 solver.cpp:244]     Train net output #1: loss = 0.00615689 (* 1 = 0.00615689 loss)
I0912 01:30:29.172929 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996506
I0912 01:30:29.172933 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998596
I0912 01:30:29.172940 24948 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0912 01:30:46.069218 24948 solver.cpp:228] Iteration 4260, loss = 0.00660105
I0912 01:30:46.069262 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997238
I0912 01:30:46.069274 24948 solver.cpp:244]     Train net output #1: loss = 0.006601 (* 1 = 0.006601 loss)
I0912 01:30:46.069280 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996683
I0912 01:30:46.069286 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998073
I0912 01:30:46.069296 24948 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0912 01:31:02.977311 24948 solver.cpp:228] Iteration 4280, loss = 0.00278007
I0912 01:31:02.977411 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998953
I0912 01:31:02.977427 24948 solver.cpp:244]     Train net output #1: loss = 0.00278002 (* 1 = 0.00278002 loss)
I0912 01:31:02.977432 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998969
I0912 01:31:02.977437 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998917
I0912 01:31:02.977444 24948 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0912 01:31:19.882359 24948 solver.cpp:228] Iteration 4300, loss = 0.0049145
I0912 01:31:19.882405 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998006
I0912 01:31:19.882418 24948 solver.cpp:244]     Train net output #1: loss = 0.00491445 (* 1 = 0.00491445 loss)
I0912 01:31:19.882426 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99764
I0912 01:31:19.882431 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998447
I0912 01:31:19.882438 24948 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0912 01:31:36.786955 24948 solver.cpp:228] Iteration 4320, loss = 0.00384096
I0912 01:31:36.787109 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998584
I0912 01:31:36.787132 24948 solver.cpp:244]     Train net output #1: loss = 0.00384091 (* 1 = 0.00384091 loss)
I0912 01:31:36.787140 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999024
I0912 01:31:36.787151 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997413
I0912 01:31:36.787159 24948 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0912 01:31:53.691304 24948 solver.cpp:228] Iteration 4340, loss = 0.00723605
I0912 01:31:53.691349 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997726
I0912 01:31:53.691362 24948 solver.cpp:244]     Train net output #1: loss = 0.00723599 (* 1 = 0.00723599 loss)
I0912 01:31:53.691370 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998652
I0912 01:31:53.691376 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996343
I0912 01:31:53.691385 24948 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0912 01:32:10.594802 24948 solver.cpp:228] Iteration 4360, loss = 0.00312247
I0912 01:32:10.594911 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998876
I0912 01:32:10.594928 24948 solver.cpp:244]     Train net output #1: loss = 0.00312242 (* 1 = 0.00312242 loss)
I0912 01:32:10.594934 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998589
I0912 01:32:10.594941 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999152
I0912 01:32:10.594950 24948 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0912 01:32:27.508826 24948 solver.cpp:228] Iteration 4380, loss = 0.00573002
I0912 01:32:27.508867 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997497
I0912 01:32:27.508879 24948 solver.cpp:244]     Train net output #1: loss = 0.00572998 (* 1 = 0.00572998 loss)
I0912 01:32:27.508885 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996406
I0912 01:32:27.508890 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999211
I0912 01:32:27.508898 24948 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0912 01:32:44.411065 24948 solver.cpp:228] Iteration 4400, loss = 0.0045244
I0912 01:32:44.411168 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998048
I0912 01:32:44.411185 24948 solver.cpp:244]     Train net output #1: loss = 0.00452436 (* 1 = 0.00452436 loss)
I0912 01:32:44.411192 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997103
I0912 01:32:44.411198 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99938
I0912 01:32:44.411206 24948 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0912 01:33:01.308655 24948 solver.cpp:228] Iteration 4420, loss = 0.00757021
I0912 01:33:01.308696 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996674
I0912 01:33:01.308709 24948 solver.cpp:244]     Train net output #1: loss = 0.00757017 (* 1 = 0.00757017 loss)
I0912 01:33:01.308715 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99476
I0912 01:33:01.308720 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999691
I0912 01:33:01.308727 24948 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0912 01:33:18.208624 24948 solver.cpp:228] Iteration 4440, loss = 0.00707649
I0912 01:33:18.208778 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996719
I0912 01:33:18.208796 24948 solver.cpp:244]     Train net output #1: loss = 0.00707645 (* 1 = 0.00707645 loss)
I0912 01:33:18.208802 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993215
I0912 01:33:18.208808 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999395
I0912 01:33:18.208817 24948 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0912 01:33:35.098714 24948 solver.cpp:228] Iteration 4460, loss = 0.00914171
I0912 01:33:35.098757 24948 solver.cpp:244]     Train net output #0: accuracy = 0.9958
I0912 01:33:35.098768 24948 solver.cpp:244]     Train net output #1: loss = 0.00914166 (* 1 = 0.00914166 loss)
I0912 01:33:35.098774 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993605
I0912 01:33:35.098779 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998317
I0912 01:33:35.098786 24948 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0912 01:33:51.995203 24948 solver.cpp:228] Iteration 4480, loss = 0.00758775
I0912 01:33:51.995306 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996764
I0912 01:33:51.995321 24948 solver.cpp:244]     Train net output #1: loss = 0.0075877 (* 1 = 0.0075877 loss)
I0912 01:33:51.995328 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996613
I0912 01:33:51.995333 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997165
I0912 01:33:51.995342 24948 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0912 01:34:08.909385 24948 solver.cpp:228] Iteration 4500, loss = 0.00367288
I0912 01:34:08.909427 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998546
I0912 01:34:08.909440 24948 solver.cpp:244]     Train net output #1: loss = 0.00367284 (* 1 = 0.00367284 loss)
I0912 01:34:08.909446 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998537
I0912 01:34:08.909451 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998568
I0912 01:34:08.909458 24948 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0912 01:34:25.809407 24948 solver.cpp:228] Iteration 4520, loss = 0.00487796
I0912 01:34:25.809509 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997815
I0912 01:34:25.809525 24948 solver.cpp:244]     Train net output #1: loss = 0.00487791 (* 1 = 0.00487791 loss)
I0912 01:34:25.809530 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997166
I0912 01:34:25.809535 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999297
I0912 01:34:25.809543 24948 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0912 01:34:42.718595 24948 solver.cpp:228] Iteration 4540, loss = 0.00358094
I0912 01:34:42.718638 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998361
I0912 01:34:42.718653 24948 solver.cpp:244]     Train net output #1: loss = 0.00358089 (* 1 = 0.00358089 loss)
I0912 01:34:42.718660 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997715
I0912 01:34:42.718667 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999506
I0912 01:34:42.718675 24948 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0912 01:34:59.612213 24948 solver.cpp:228] Iteration 4560, loss = 0.00437464
I0912 01:34:59.612306 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998417
I0912 01:34:59.612320 24948 solver.cpp:244]     Train net output #1: loss = 0.00437459 (* 1 = 0.00437459 loss)
I0912 01:34:59.612326 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997388
I0912 01:34:59.612331 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999234
I0912 01:34:59.612339 24948 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0912 01:35:16.512423 24948 solver.cpp:228] Iteration 4580, loss = 0.00877293
I0912 01:35:16.512466 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996659
I0912 01:35:16.512481 24948 solver.cpp:244]     Train net output #1: loss = 0.00877288 (* 1 = 0.00877288 loss)
I0912 01:35:16.512487 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99334
I0912 01:35:16.512493 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998828
I0912 01:35:16.512502 24948 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0912 01:35:33.419584 24948 solver.cpp:228] Iteration 4600, loss = 0.00933638
I0912 01:35:33.419739 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996032
I0912 01:35:33.419755 24948 solver.cpp:244]     Train net output #1: loss = 0.00933633 (* 1 = 0.00933633 loss)
I0912 01:35:33.419761 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995654
I0912 01:35:33.419766 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996692
I0912 01:35:33.419773 24948 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0912 01:35:50.322206 24948 solver.cpp:228] Iteration 4620, loss = 0.00703696
I0912 01:35:50.322252 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997376
I0912 01:35:50.322266 24948 solver.cpp:244]     Train net output #1: loss = 0.00703691 (* 1 = 0.00703691 loss)
I0912 01:35:50.322273 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995546
I0912 01:35:50.322278 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998773
I0912 01:35:50.322288 24948 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0912 01:36:07.214926 24948 solver.cpp:228] Iteration 4640, loss = 0.00776516
I0912 01:36:07.215024 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996778
I0912 01:36:07.215039 24948 solver.cpp:244]     Train net output #1: loss = 0.00776512 (* 1 = 0.00776512 loss)
I0912 01:36:07.215046 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996398
I0912 01:36:07.215051 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997646
I0912 01:36:07.215059 24948 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0912 01:36:24.113471 24948 solver.cpp:228] Iteration 4660, loss = 0.00830568
I0912 01:36:24.113515 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997169
I0912 01:36:24.113529 24948 solver.cpp:244]     Train net output #1: loss = 0.00830563 (* 1 = 0.00830563 loss)
I0912 01:36:24.113536 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994768
I0912 01:36:24.113543 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998594
I0912 01:36:24.113551 24948 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0912 01:36:41.020576 24948 solver.cpp:228] Iteration 4680, loss = 0.0103238
I0912 01:36:41.020678 24948 solver.cpp:244]     Train net output #0: accuracy = 0.99719
I0912 01:36:41.020694 24948 solver.cpp:244]     Train net output #1: loss = 0.0103238 (* 1 = 0.0103238 loss)
I0912 01:36:41.020700 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993633
I0912 01:36:41.020706 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998786
I0912 01:36:41.020715 24948 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0912 01:36:57.909286 24948 solver.cpp:228] Iteration 4700, loss = 0.00969611
I0912 01:36:57.909327 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996063
I0912 01:36:57.909340 24948 solver.cpp:244]     Train net output #1: loss = 0.00969606 (* 1 = 0.00969606 loss)
I0912 01:36:57.909346 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995162
I0912 01:36:57.909350 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997152
I0912 01:36:57.909358 24948 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0912 01:37:14.819429 24948 solver.cpp:228] Iteration 4720, loss = 0.00405114
I0912 01:37:14.819526 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998235
I0912 01:37:14.819542 24948 solver.cpp:244]     Train net output #1: loss = 0.00405109 (* 1 = 0.00405109 loss)
I0912 01:37:14.819550 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997071
I0912 01:37:14.819556 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999405
I0912 01:37:14.819564 24948 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0912 01:37:31.726058 24948 solver.cpp:228] Iteration 4740, loss = 0.00491541
I0912 01:37:31.726099 24948 solver.cpp:244]     Train net output #0: accuracy = 0.99819
I0912 01:37:31.726111 24948 solver.cpp:244]     Train net output #1: loss = 0.00491536 (* 1 = 0.00491536 loss)
I0912 01:37:31.726117 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998127
I0912 01:37:31.726122 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998538
I0912 01:37:31.726130 24948 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0912 01:37:48.620293 24948 solver.cpp:228] Iteration 4760, loss = 0.00308256
I0912 01:37:48.620452 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998604
I0912 01:37:48.620470 24948 solver.cpp:244]     Train net output #1: loss = 0.00308251 (* 1 = 0.00308251 loss)
I0912 01:37:48.620476 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998231
I0912 01:37:48.620483 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999304
I0912 01:37:48.620491 24948 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0912 01:38:05.534142 24948 solver.cpp:228] Iteration 4780, loss = 0.0059786
I0912 01:38:05.534184 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998581
I0912 01:38:05.534196 24948 solver.cpp:244]     Train net output #1: loss = 0.00597856 (* 1 = 0.00597856 loss)
I0912 01:38:05.534202 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998787
I0912 01:38:05.534207 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996916
I0912 01:38:05.534214 24948 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0912 01:38:22.450579 24948 solver.cpp:228] Iteration 4800, loss = 0.00710249
I0912 01:38:22.450680 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996884
I0912 01:38:22.450696 24948 solver.cpp:244]     Train net output #1: loss = 0.00710244 (* 1 = 0.00710244 loss)
I0912 01:38:22.450703 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996341
I0912 01:38:22.450709 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997931
I0912 01:38:22.450718 24948 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0912 01:38:39.360518 24948 solver.cpp:228] Iteration 4820, loss = 0.00520441
I0912 01:38:39.360560 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997865
I0912 01:38:39.360572 24948 solver.cpp:244]     Train net output #1: loss = 0.00520436 (* 1 = 0.00520436 loss)
I0912 01:38:39.360579 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996291
I0912 01:38:39.360584 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999159
I0912 01:38:39.360591 24948 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0912 01:38:56.272526 24948 solver.cpp:228] Iteration 4840, loss = 0.00496705
I0912 01:38:56.272634 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998109
I0912 01:38:56.272650 24948 solver.cpp:244]     Train net output #1: loss = 0.00496701 (* 1 = 0.00496701 loss)
I0912 01:38:56.272655 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997545
I0912 01:38:56.272660 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998765
I0912 01:38:56.272668 24948 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0912 01:39:13.177335 24948 solver.cpp:228] Iteration 4860, loss = 0.00589685
I0912 01:39:13.177388 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998743
I0912 01:39:13.177403 24948 solver.cpp:244]     Train net output #1: loss = 0.0058968 (* 1 = 0.0058968 loss)
I0912 01:39:13.177410 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998847
I0912 01:39:13.177417 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997874
I0912 01:39:13.177424 24948 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0912 01:39:30.081105 24948 solver.cpp:228] Iteration 4880, loss = 0.0133007
I0912 01:39:30.081260 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998775
I0912 01:39:30.081277 24948 solver.cpp:244]     Train net output #1: loss = 0.0133007 (* 1 = 0.0133007 loss)
I0912 01:39:30.081284 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998931
I0912 01:39:30.081290 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996007
I0912 01:39:30.081296 24948 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0912 01:39:46.986158 24948 solver.cpp:228] Iteration 4900, loss = 0.0116565
I0912 01:39:46.986203 24948 solver.cpp:244]     Train net output #0: accuracy = 0.994418
I0912 01:39:46.986217 24948 solver.cpp:244]     Train net output #1: loss = 0.0116564 (* 1 = 0.0116564 loss)
I0912 01:39:46.986224 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990813
I0912 01:39:46.986230 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99864
I0912 01:39:46.986238 24948 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0912 01:40:03.890064 24948 solver.cpp:228] Iteration 4920, loss = 0.00411523
I0912 01:40:03.890161 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998341
I0912 01:40:03.890175 24948 solver.cpp:244]     Train net output #1: loss = 0.00411518 (* 1 = 0.00411518 loss)
I0912 01:40:03.890182 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997379
I0912 01:40:03.890187 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999313
I0912 01:40:03.890193 24948 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0912 01:40:20.800731 24948 solver.cpp:228] Iteration 4940, loss = 0.00367375
I0912 01:40:20.800776 24948 solver.cpp:244]     Train net output #0: accuracy = 0.998371
I0912 01:40:20.800791 24948 solver.cpp:244]     Train net output #1: loss = 0.0036737 (* 1 = 0.0036737 loss)
I0912 01:40:20.800797 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997727
I0912 01:40:20.800803 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999427
I0912 01:40:20.800810 24948 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0912 01:40:37.713201 24948 solver.cpp:228] Iteration 4960, loss = 0.0085435
I0912 01:40:37.713299 24948 solver.cpp:244]     Train net output #0: accuracy = 0.996429
I0912 01:40:37.713315 24948 solver.cpp:244]     Train net output #1: loss = 0.00854346 (* 1 = 0.00854346 loss)
I0912 01:40:37.713320 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99647
I0912 01:40:37.713325 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996334
I0912 01:40:37.713332 24948 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0912 01:40:54.609586 24948 solver.cpp:228] Iteration 4980, loss = 0.00632415
I0912 01:40:54.609630 24948 solver.cpp:244]     Train net output #0: accuracy = 0.997418
I0912 01:40:54.609643 24948 solver.cpp:244]     Train net output #1: loss = 0.00632411 (* 1 = 0.00632411 loss)
I0912 01:40:54.609650 24948 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99754
I0912 01:40:54.609658 24948 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997082
I0912 01:40:54.609665 24948 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0912 01:41:11.136915 24948 solver.cpp:454] Snapshotting to binary proto file pocwisc2/training_iter_5000.caffemodel
I0912 01:41:12.475241 24948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc2/training_iter_5000.solverstate
I0912 01:41:13.081393 24948 solver.cpp:317] Iteration 5000, loss = 0.00319778
I0912 01:41:13.081440 24948 solver.cpp:322] Optimization Done.
I0912 01:41:13.081445 24948 caffe.cpp:254] Optimization Done.

2017-09-12 01:41:13,490 log.framework MainThread  INFO       caffe models found
pocwisc2/training_iter_5000.caffemodel
2017-09-12 01:41:13,490 log.framework MainThread  INFO       Caffe model found: pocwisc2/training_iter_5000.caffemodel
2017-09-12 01:41:15,491 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 01:41:15,633 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 01:41:15,777 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 01:41:15,916 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 01:41:16,053 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 01:41:16,190 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 01:41:16,338 log.framework MainThread  INFO       train file number: 29
2017-09-12 01:41:16,339 log.framework MainThread  INFO       test file number: 4
2017-09-12 01:41:16,339 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 01:41:16,339 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 01:41:16,340 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-09-12 01:41:16,340 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-09-12 01:41:16,340 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-09-12 01:41:16,341 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc3/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc3/training"
solver_mode: GPU

2017-09-12 01:41:16,341 log.framework MainThread  INFO       caffe training step
2017-09-12 01:41:16,341 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc3/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-09-12 02:50:41,064 log.framework MainThread  INFO       I0912 01:41:16.404207 25102 caffe.cpp:217] Using GPUs 0
I0912 01:41:16.415879 25102 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0912 01:41:17.113646 25102 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc3/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc3/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0912 01:41:17.113816 25102 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc3/caffe/model_segnet_final/train.prototxt
I0912 01:41:17.116596 25102 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc3/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 01:41:17.117092 25102 layer_factory.hpp:77] Creating layer data
I0912 01:41:17.117111 25102 net.cpp:100] Creating Layer data
I0912 01:41:17.117121 25102 net.cpp:408] data -> data
I0912 01:41:17.117151 25102 net.cpp:408] data -> label
I0912 01:41:17.117172 25102 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc3/HDF5Files/train_combined.txt
I0912 01:41:17.117231 25102 hdf5_data_layer.cpp:93] Number of HDF5 files: 29
I0912 01:41:17.118434 25102 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0912 01:41:17.143474 25102 net.cpp:150] Setting up data
I0912 01:41:17.143504 25102 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 01:41:17.143517 25102 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 01:41:17.143522 25102 net.cpp:165] Memory required for data: 24883200
I0912 01:41:17.143530 25102 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 01:41:17.143548 25102 net.cpp:100] Creating Layer label_data_1_split
I0912 01:41:17.143555 25102 net.cpp:434] label_data_1_split <- label
I0912 01:41:17.143568 25102 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 01:41:17.143581 25102 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 01:41:17.143620 25102 net.cpp:150] Setting up label_data_1_split
I0912 01:41:17.143628 25102 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 01:41:17.143633 25102 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 01:41:17.143637 25102 net.cpp:165] Memory required for data: 30412800
I0912 01:41:17.143641 25102 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 01:41:17.143661 25102 net.cpp:100] Creating Layer conv1_1_1
I0912 01:41:17.143666 25102 net.cpp:434] conv1_1_1 <- data
I0912 01:41:17.143672 25102 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 01:41:17.660538 25102 net.cpp:150] Setting up conv1_1_1
I0912 01:41:17.660573 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:17.660576 25102 net.cpp:165] Memory required for data: 207360000
I0912 01:41:17.660601 25102 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 01:41:17.660617 25102 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 01:41:17.660624 25102 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 01:41:17.660631 25102 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 01:41:17.661026 25102 net.cpp:150] Setting up conv1_1_1_bn
I0912 01:41:17.661036 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:17.661039 25102 net.cpp:165] Memory required for data: 384307200
I0912 01:41:17.661052 25102 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 01:41:17.661065 25102 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 01:41:17.661070 25102 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 01:41:17.661077 25102 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 01:41:17.661123 25102 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 01:41:17.662745 25102 net.cpp:150] Setting up conv1_1_1_scale
I0912 01:41:17.662761 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:17.662772 25102 net.cpp:165] Memory required for data: 561254400
I0912 01:41:17.662781 25102 layer_factory.hpp:77] Creating layer relu1_1
I0912 01:41:17.662796 25102 net.cpp:100] Creating Layer relu1_1
I0912 01:41:17.662801 25102 net.cpp:434] relu1_1 <- conv1_1_1
I0912 01:41:17.662806 25102 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 01:41:17.663031 25102 net.cpp:150] Setting up relu1_1
I0912 01:41:17.663043 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:17.663048 25102 net.cpp:165] Memory required for data: 738201600
I0912 01:41:17.663051 25102 layer_factory.hpp:77] Creating layer conv1_2
I0912 01:41:17.663064 25102 net.cpp:100] Creating Layer conv1_2
I0912 01:41:17.663069 25102 net.cpp:434] conv1_2 <- conv1_1_1
I0912 01:41:17.663075 25102 net.cpp:408] conv1_2 -> conv1_2
I0912 01:41:17.667251 25102 net.cpp:150] Setting up conv1_2
I0912 01:41:17.667268 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:17.667277 25102 net.cpp:165] Memory required for data: 915148800
I0912 01:41:17.667289 25102 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 01:41:17.667299 25102 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 01:41:17.667306 25102 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 01:41:17.667312 25102 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 01:41:17.668817 25102 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 01:41:17.668831 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:17.668840 25102 net.cpp:165] Memory required for data: 1092096000
I0912 01:41:17.668850 25102 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 01:41:17.668860 25102 net.cpp:100] Creating Layer conv1_2_scale
I0912 01:41:17.668865 25102 net.cpp:434] conv1_2_scale <- conv1_2
I0912 01:41:17.668871 25102 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 01:41:17.668915 25102 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 01:41:17.669287 25102 net.cpp:150] Setting up conv1_2_scale
I0912 01:41:17.669296 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:17.669301 25102 net.cpp:165] Memory required for data: 1269043200
I0912 01:41:17.669308 25102 layer_factory.hpp:77] Creating layer relu1_2
I0912 01:41:17.669315 25102 net.cpp:100] Creating Layer relu1_2
I0912 01:41:17.669322 25102 net.cpp:434] relu1_2 <- conv1_2
I0912 01:41:17.669327 25102 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 01:41:17.669543 25102 net.cpp:150] Setting up relu1_2
I0912 01:41:17.669554 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:17.669559 25102 net.cpp:165] Memory required for data: 1445990400
I0912 01:41:17.669564 25102 layer_factory.hpp:77] Creating layer pool1
I0912 01:41:17.669569 25102 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 01:41:17.669575 25102 net.cpp:100] Creating Layer pool1
I0912 01:41:17.669580 25102 net.cpp:434] pool1 <- conv1_2
I0912 01:41:17.669585 25102 net.cpp:408] pool1 -> pool1
I0912 01:41:17.669595 25102 net.cpp:408] pool1 -> pool1_mask
I0912 01:41:17.669651 25102 net.cpp:150] Setting up pool1
I0912 01:41:17.669657 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:17.669661 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:17.669665 25102 net.cpp:165] Memory required for data: 1534464000
I0912 01:41:17.669668 25102 layer_factory.hpp:77] Creating layer conv2_1
I0912 01:41:17.669677 25102 net.cpp:100] Creating Layer conv2_1
I0912 01:41:17.669682 25102 net.cpp:434] conv2_1 <- pool1
I0912 01:41:17.669688 25102 net.cpp:408] conv2_1 -> conv2_1
I0912 01:41:17.675768 25102 net.cpp:150] Setting up conv2_1
I0912 01:41:17.675786 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:17.675794 25102 net.cpp:165] Memory required for data: 1622937600
I0912 01:41:17.675803 25102 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 01:41:17.675812 25102 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 01:41:17.675822 25102 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 01:41:17.675828 25102 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 01:41:17.676054 25102 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 01:41:17.676061 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:17.676065 25102 net.cpp:165] Memory required for data: 1711411200
I0912 01:41:17.676077 25102 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 01:41:17.676100 25102 net.cpp:100] Creating Layer conv2_1_scale
I0912 01:41:17.676103 25102 net.cpp:434] conv2_1_scale <- conv2_1
I0912 01:41:17.676110 25102 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 01:41:17.676151 25102 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 01:41:17.676322 25102 net.cpp:150] Setting up conv2_1_scale
I0912 01:41:17.676331 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:17.676337 25102 net.cpp:165] Memory required for data: 1799884800
I0912 01:41:17.676342 25102 layer_factory.hpp:77] Creating layer relu2_1
I0912 01:41:17.676350 25102 net.cpp:100] Creating Layer relu2_1
I0912 01:41:17.676357 25102 net.cpp:434] relu2_1 <- conv2_1
I0912 01:41:17.676362 25102 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 01:41:17.677399 25102 net.cpp:150] Setting up relu2_1
I0912 01:41:17.677413 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:17.677418 25102 net.cpp:165] Memory required for data: 1888358400
I0912 01:41:17.677423 25102 layer_factory.hpp:77] Creating layer conv2_2
I0912 01:41:17.677435 25102 net.cpp:100] Creating Layer conv2_2
I0912 01:41:17.677441 25102 net.cpp:434] conv2_2 <- conv2_1
I0912 01:41:17.677448 25102 net.cpp:408] conv2_2 -> conv2_2
I0912 01:41:17.684787 25102 net.cpp:150] Setting up conv2_2
I0912 01:41:17.684803 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:17.684813 25102 net.cpp:165] Memory required for data: 1976832000
I0912 01:41:17.684821 25102 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 01:41:17.684834 25102 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 01:41:17.684839 25102 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 01:41:17.684845 25102 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 01:41:17.685082 25102 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 01:41:17.685091 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:17.685094 25102 net.cpp:165] Memory required for data: 2065305600
I0912 01:41:17.685103 25102 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 01:41:17.685109 25102 net.cpp:100] Creating Layer conv2_2_scale
I0912 01:41:17.685118 25102 net.cpp:434] conv2_2_scale <- conv2_2
I0912 01:41:17.685123 25102 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 01:41:17.685163 25102 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 01:41:17.685336 25102 net.cpp:150] Setting up conv2_2_scale
I0912 01:41:17.685344 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:17.685348 25102 net.cpp:165] Memory required for data: 2153779200
I0912 01:41:17.685356 25102 layer_factory.hpp:77] Creating layer relu2_2
I0912 01:41:17.685364 25102 net.cpp:100] Creating Layer relu2_2
I0912 01:41:17.685387 25102 net.cpp:434] relu2_2 <- conv2_2
I0912 01:41:17.685395 25102 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 01:41:17.685590 25102 net.cpp:150] Setting up relu2_2
I0912 01:41:17.685600 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:17.685603 25102 net.cpp:165] Memory required for data: 2242252800
I0912 01:41:17.685607 25102 layer_factory.hpp:77] Creating layer pool2
I0912 01:41:17.685611 25102 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 01:41:17.685618 25102 net.cpp:100] Creating Layer pool2
I0912 01:41:17.685622 25102 net.cpp:434] pool2 <- conv2_2
I0912 01:41:17.685628 25102 net.cpp:408] pool2 -> pool2
I0912 01:41:17.685636 25102 net.cpp:408] pool2 -> pool2_mask
I0912 01:41:17.685679 25102 net.cpp:150] Setting up pool2
I0912 01:41:17.685686 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:17.685690 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:17.685694 25102 net.cpp:165] Memory required for data: 2286489600
I0912 01:41:17.685698 25102 layer_factory.hpp:77] Creating layer conv3_1
I0912 01:41:17.685706 25102 net.cpp:100] Creating Layer conv3_1
I0912 01:41:17.685711 25102 net.cpp:434] conv3_1 <- pool2
I0912 01:41:17.685717 25102 net.cpp:408] conv3_1 -> conv3_1
I0912 01:41:17.697902 25102 net.cpp:150] Setting up conv3_1
I0912 01:41:17.697932 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.697943 25102 net.cpp:165] Memory required for data: 2330726400
I0912 01:41:17.697952 25102 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 01:41:17.697958 25102 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 01:41:17.697962 25102 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 01:41:17.697968 25102 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 01:41:17.698180 25102 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 01:41:17.698189 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.698191 25102 net.cpp:165] Memory required for data: 2374963200
I0912 01:41:17.698205 25102 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 01:41:17.698212 25102 net.cpp:100] Creating Layer conv3_1_scale
I0912 01:41:17.698222 25102 net.cpp:434] conv3_1_scale <- conv3_1
I0912 01:41:17.698227 25102 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 01:41:17.698267 25102 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 01:41:17.698400 25102 net.cpp:150] Setting up conv3_1_scale
I0912 01:41:17.698408 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.698411 25102 net.cpp:165] Memory required for data: 2419200000
I0912 01:41:17.698417 25102 layer_factory.hpp:77] Creating layer relu3_1
I0912 01:41:17.698426 25102 net.cpp:100] Creating Layer relu3_1
I0912 01:41:17.698431 25102 net.cpp:434] relu3_1 <- conv3_1
I0912 01:41:17.698434 25102 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 01:41:17.698628 25102 net.cpp:150] Setting up relu3_1
I0912 01:41:17.698638 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.698643 25102 net.cpp:165] Memory required for data: 2463436800
I0912 01:41:17.698647 25102 layer_factory.hpp:77] Creating layer conv3_2
I0912 01:41:17.698657 25102 net.cpp:100] Creating Layer conv3_2
I0912 01:41:17.698662 25102 net.cpp:434] conv3_2 <- conv3_1
I0912 01:41:17.698668 25102 net.cpp:408] conv3_2 -> conv3_2
I0912 01:41:17.721838 25102 net.cpp:150] Setting up conv3_2
I0912 01:41:17.721854 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.721864 25102 net.cpp:165] Memory required for data: 2507673600
I0912 01:41:17.721873 25102 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 01:41:17.721884 25102 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 01:41:17.721892 25102 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 01:41:17.721899 25102 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 01:41:17.722107 25102 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 01:41:17.722115 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.722118 25102 net.cpp:165] Memory required for data: 2551910400
I0912 01:41:17.722127 25102 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 01:41:17.722136 25102 net.cpp:100] Creating Layer conv3_2_scale
I0912 01:41:17.722144 25102 net.cpp:434] conv3_2_scale <- conv3_2
I0912 01:41:17.722149 25102 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 01:41:17.722189 25102 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 01:41:17.722321 25102 net.cpp:150] Setting up conv3_2_scale
I0912 01:41:17.722328 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.722332 25102 net.cpp:165] Memory required for data: 2596147200
I0912 01:41:17.722340 25102 layer_factory.hpp:77] Creating layer relu3_2
I0912 01:41:17.722347 25102 net.cpp:100] Creating Layer relu3_2
I0912 01:41:17.722353 25102 net.cpp:434] relu3_2 <- conv3_2
I0912 01:41:17.722357 25102 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 01:41:17.722553 25102 net.cpp:150] Setting up relu3_2
I0912 01:41:17.722563 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.722568 25102 net.cpp:165] Memory required for data: 2640384000
I0912 01:41:17.722573 25102 layer_factory.hpp:77] Creating layer conv3_3
I0912 01:41:17.722582 25102 net.cpp:100] Creating Layer conv3_3
I0912 01:41:17.722587 25102 net.cpp:434] conv3_3 <- conv3_2
I0912 01:41:17.722594 25102 net.cpp:408] conv3_3 -> conv3_3
I0912 01:41:17.745755 25102 net.cpp:150] Setting up conv3_3
I0912 01:41:17.745785 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.745795 25102 net.cpp:165] Memory required for data: 2684620800
I0912 01:41:17.745805 25102 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 01:41:17.745811 25102 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 01:41:17.745815 25102 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 01:41:17.745820 25102 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 01:41:17.746035 25102 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 01:41:17.746043 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.746047 25102 net.cpp:165] Memory required for data: 2728857600
I0912 01:41:17.746055 25102 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 01:41:17.746063 25102 net.cpp:100] Creating Layer conv3_3_scale
I0912 01:41:17.746073 25102 net.cpp:434] conv3_3_scale <- conv3_3
I0912 01:41:17.746078 25102 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 01:41:17.746119 25102 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 01:41:17.746253 25102 net.cpp:150] Setting up conv3_3_scale
I0912 01:41:17.746261 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.746264 25102 net.cpp:165] Memory required for data: 2773094400
I0912 01:41:17.746271 25102 layer_factory.hpp:77] Creating layer relu3_3
I0912 01:41:17.746278 25102 net.cpp:100] Creating Layer relu3_3
I0912 01:41:17.746284 25102 net.cpp:434] relu3_3 <- conv3_3
I0912 01:41:17.746289 25102 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 01:41:17.746482 25102 net.cpp:150] Setting up relu3_3
I0912 01:41:17.746492 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:17.746497 25102 net.cpp:165] Memory required for data: 2817331200
I0912 01:41:17.746501 25102 layer_factory.hpp:77] Creating layer pool3
I0912 01:41:17.746505 25102 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 01:41:17.746515 25102 net.cpp:100] Creating Layer pool3
I0912 01:41:17.746520 25102 net.cpp:434] pool3 <- conv3_3
I0912 01:41:17.746526 25102 net.cpp:408] pool3 -> pool3
I0912 01:41:17.746533 25102 net.cpp:408] pool3 -> pool3_mask
I0912 01:41:17.746578 25102 net.cpp:150] Setting up pool3
I0912 01:41:17.746585 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:17.746589 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:17.746594 25102 net.cpp:165] Memory required for data: 2839449600
I0912 01:41:17.746598 25102 layer_factory.hpp:77] Creating layer conv4_1
I0912 01:41:17.746606 25102 net.cpp:100] Creating Layer conv4_1
I0912 01:41:17.746611 25102 net.cpp:434] conv4_1 <- pool3
I0912 01:41:17.746618 25102 net.cpp:408] conv4_1 -> conv4_1
I0912 01:41:17.792479 25102 net.cpp:150] Setting up conv4_1
I0912 01:41:17.792496 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.792500 25102 net.cpp:165] Memory required for data: 2861568000
I0912 01:41:17.792508 25102 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 01:41:17.792516 25102 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 01:41:17.792520 25102 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 01:41:17.792534 25102 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 01:41:17.792747 25102 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 01:41:17.792754 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.792757 25102 net.cpp:165] Memory required for data: 2883686400
I0912 01:41:17.792773 25102 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 01:41:17.792783 25102 net.cpp:100] Creating Layer conv4_1_scale
I0912 01:41:17.792791 25102 net.cpp:434] conv4_1_scale <- conv4_1
I0912 01:41:17.792798 25102 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 01:41:17.792835 25102 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 01:41:17.792954 25102 net.cpp:150] Setting up conv4_1_scale
I0912 01:41:17.792963 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.792965 25102 net.cpp:165] Memory required for data: 2905804800
I0912 01:41:17.792973 25102 layer_factory.hpp:77] Creating layer relu4_1
I0912 01:41:17.792992 25102 net.cpp:100] Creating Layer relu4_1
I0912 01:41:17.792999 25102 net.cpp:434] relu4_1 <- conv4_1
I0912 01:41:17.793004 25102 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 01:41:17.793211 25102 net.cpp:150] Setting up relu4_1
I0912 01:41:17.793221 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.793226 25102 net.cpp:165] Memory required for data: 2927923200
I0912 01:41:17.793231 25102 layer_factory.hpp:77] Creating layer conv4_2
I0912 01:41:17.793241 25102 net.cpp:100] Creating Layer conv4_2
I0912 01:41:17.793246 25102 net.cpp:434] conv4_2 <- conv4_1
I0912 01:41:17.793253 25102 net.cpp:408] conv4_2 -> conv4_2
I0912 01:41:17.876593 25102 net.cpp:150] Setting up conv4_2
I0912 01:41:17.876611 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.876616 25102 net.cpp:165] Memory required for data: 2950041600
I0912 01:41:17.876623 25102 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 01:41:17.876631 25102 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 01:41:17.876636 25102 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 01:41:17.876649 25102 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 01:41:17.876854 25102 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 01:41:17.876863 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.876865 25102 net.cpp:165] Memory required for data: 2972160000
I0912 01:41:17.876874 25102 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 01:41:17.876880 25102 net.cpp:100] Creating Layer conv4_2_scale
I0912 01:41:17.876888 25102 net.cpp:434] conv4_2_scale <- conv4_2
I0912 01:41:17.876893 25102 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 01:41:17.876930 25102 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 01:41:17.877048 25102 net.cpp:150] Setting up conv4_2_scale
I0912 01:41:17.877055 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.877058 25102 net.cpp:165] Memory required for data: 2994278400
I0912 01:41:17.877064 25102 layer_factory.hpp:77] Creating layer relu4_2
I0912 01:41:17.877073 25102 net.cpp:100] Creating Layer relu4_2
I0912 01:41:17.877077 25102 net.cpp:434] relu4_2 <- conv4_2
I0912 01:41:17.877082 25102 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 01:41:17.878146 25102 net.cpp:150] Setting up relu4_2
I0912 01:41:17.878161 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.878166 25102 net.cpp:165] Memory required for data: 3016396800
I0912 01:41:17.878170 25102 layer_factory.hpp:77] Creating layer conv4_3
I0912 01:41:17.878183 25102 net.cpp:100] Creating Layer conv4_3
I0912 01:41:17.878190 25102 net.cpp:434] conv4_3 <- conv4_2
I0912 01:41:17.878197 25102 net.cpp:408] conv4_3 -> conv4_3
I0912 01:41:17.963807 25102 net.cpp:150] Setting up conv4_3
I0912 01:41:17.963827 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.963832 25102 net.cpp:165] Memory required for data: 3038515200
I0912 01:41:17.963858 25102 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 01:41:17.963871 25102 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 01:41:17.963882 25102 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 01:41:17.963892 25102 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 01:41:17.964112 25102 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 01:41:17.964119 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.964123 25102 net.cpp:165] Memory required for data: 3060633600
I0912 01:41:17.964131 25102 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 01:41:17.964143 25102 net.cpp:100] Creating Layer conv4_3_scale
I0912 01:41:17.964148 25102 net.cpp:434] conv4_3_scale <- conv4_3
I0912 01:41:17.964155 25102 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 01:41:17.964197 25102 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 01:41:17.964326 25102 net.cpp:150] Setting up conv4_3_scale
I0912 01:41:17.964334 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.964337 25102 net.cpp:165] Memory required for data: 3082752000
I0912 01:41:17.964344 25102 layer_factory.hpp:77] Creating layer relu4_3
I0912 01:41:17.964367 25102 net.cpp:100] Creating Layer relu4_3
I0912 01:41:17.964372 25102 net.cpp:434] relu4_3 <- conv4_3
I0912 01:41:17.964378 25102 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 01:41:17.964581 25102 net.cpp:150] Setting up relu4_3
I0912 01:41:17.964591 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:17.964596 25102 net.cpp:165] Memory required for data: 3104870400
I0912 01:41:17.964601 25102 layer_factory.hpp:77] Creating layer pool4
I0912 01:41:17.964607 25102 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 01:41:17.964614 25102 net.cpp:100] Creating Layer pool4
I0912 01:41:17.964619 25102 net.cpp:434] pool4 <- conv4_3
I0912 01:41:17.964628 25102 net.cpp:408] pool4 -> pool4
I0912 01:41:17.964637 25102 net.cpp:408] pool4 -> pool4_mask
I0912 01:41:17.964685 25102 net.cpp:150] Setting up pool4
I0912 01:41:17.964692 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:17.964696 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:17.964701 25102 net.cpp:165] Memory required for data: 3116175360
I0912 01:41:17.964704 25102 layer_factory.hpp:77] Creating layer conv5_1
I0912 01:41:17.964717 25102 net.cpp:100] Creating Layer conv5_1
I0912 01:41:17.964722 25102 net.cpp:434] conv5_1 <- pool4
I0912 01:41:17.964730 25102 net.cpp:408] conv5_1 -> conv5_1
I0912 01:41:18.048039 25102 net.cpp:150] Setting up conv5_1
I0912 01:41:18.048058 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.048063 25102 net.cpp:165] Memory required for data: 3121827840
I0912 01:41:18.048069 25102 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 01:41:18.048079 25102 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 01:41:18.048084 25102 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 01:41:18.048090 25102 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 01:41:18.048316 25102 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 01:41:18.048323 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.048327 25102 net.cpp:165] Memory required for data: 3127480320
I0912 01:41:18.048336 25102 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 01:41:18.048348 25102 net.cpp:100] Creating Layer conv5_1_scale
I0912 01:41:18.048357 25102 net.cpp:434] conv5_1_scale <- conv5_1
I0912 01:41:18.048362 25102 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 01:41:18.048406 25102 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 01:41:18.048526 25102 net.cpp:150] Setting up conv5_1_scale
I0912 01:41:18.048532 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.048535 25102 net.cpp:165] Memory required for data: 3133132800
I0912 01:41:18.048542 25102 layer_factory.hpp:77] Creating layer relu5_1
I0912 01:41:18.048550 25102 net.cpp:100] Creating Layer relu5_1
I0912 01:41:18.048555 25102 net.cpp:434] relu5_1 <- conv5_1
I0912 01:41:18.048560 25102 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 01:41:18.048754 25102 net.cpp:150] Setting up relu5_1
I0912 01:41:18.048764 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.048768 25102 net.cpp:165] Memory required for data: 3138785280
I0912 01:41:18.048773 25102 layer_factory.hpp:77] Creating layer conv5_2
I0912 01:41:18.048784 25102 net.cpp:100] Creating Layer conv5_2
I0912 01:41:18.048789 25102 net.cpp:434] conv5_2 <- conv5_1
I0912 01:41:18.048796 25102 net.cpp:408] conv5_2 -> conv5_2
I0912 01:41:18.132076 25102 net.cpp:150] Setting up conv5_2
I0912 01:41:18.132094 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.132098 25102 net.cpp:165] Memory required for data: 3144437760
I0912 01:41:18.132107 25102 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 01:41:18.132124 25102 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 01:41:18.132133 25102 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 01:41:18.132140 25102 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 01:41:18.132354 25102 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 01:41:18.132362 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.132382 25102 net.cpp:165] Memory required for data: 3150090240
I0912 01:41:18.132391 25102 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 01:41:18.132402 25102 net.cpp:100] Creating Layer conv5_2_scale
I0912 01:41:18.132407 25102 net.cpp:434] conv5_2_scale <- conv5_2
I0912 01:41:18.132414 25102 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 01:41:18.132463 25102 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 01:41:18.132585 25102 net.cpp:150] Setting up conv5_2_scale
I0912 01:41:18.132591 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.132594 25102 net.cpp:165] Memory required for data: 3155742720
I0912 01:41:18.132601 25102 layer_factory.hpp:77] Creating layer relu5_2
I0912 01:41:18.132608 25102 net.cpp:100] Creating Layer relu5_2
I0912 01:41:18.132613 25102 net.cpp:434] relu5_2 <- conv5_2
I0912 01:41:18.132618 25102 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 01:41:18.132817 25102 net.cpp:150] Setting up relu5_2
I0912 01:41:18.132827 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.132833 25102 net.cpp:165] Memory required for data: 3161395200
I0912 01:41:18.132836 25102 layer_factory.hpp:77] Creating layer conv5_3
I0912 01:41:18.132850 25102 net.cpp:100] Creating Layer conv5_3
I0912 01:41:18.132855 25102 net.cpp:434] conv5_3 <- conv5_2
I0912 01:41:18.132863 25102 net.cpp:408] conv5_3 -> conv5_3
I0912 01:41:18.216256 25102 net.cpp:150] Setting up conv5_3
I0912 01:41:18.216274 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.216277 25102 net.cpp:165] Memory required for data: 3167047680
I0912 01:41:18.216285 25102 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 01:41:18.216295 25102 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 01:41:18.216307 25102 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 01:41:18.216313 25102 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 01:41:18.216537 25102 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 01:41:18.216545 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.216548 25102 net.cpp:165] Memory required for data: 3172700160
I0912 01:41:18.216558 25102 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 01:41:18.216572 25102 net.cpp:100] Creating Layer conv5_3_scale
I0912 01:41:18.216579 25102 net.cpp:434] conv5_3_scale <- conv5_3
I0912 01:41:18.216584 25102 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 01:41:18.216631 25102 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 01:41:18.216755 25102 net.cpp:150] Setting up conv5_3_scale
I0912 01:41:18.216763 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.216765 25102 net.cpp:165] Memory required for data: 3178352640
I0912 01:41:18.216773 25102 layer_factory.hpp:77] Creating layer relu5_3
I0912 01:41:18.216780 25102 net.cpp:100] Creating Layer relu5_3
I0912 01:41:18.216785 25102 net.cpp:434] relu5_3 <- conv5_3
I0912 01:41:18.216791 25102 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 01:41:18.217000 25102 net.cpp:150] Setting up relu5_3
I0912 01:41:18.217010 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.217015 25102 net.cpp:165] Memory required for data: 3184005120
I0912 01:41:18.217018 25102 layer_factory.hpp:77] Creating layer pool5
I0912 01:41:18.217025 25102 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 01:41:18.217032 25102 net.cpp:100] Creating Layer pool5
I0912 01:41:18.217037 25102 net.cpp:434] pool5 <- conv5_3
I0912 01:41:18.217043 25102 net.cpp:408] pool5 -> pool5
I0912 01:41:18.217053 25102 net.cpp:408] pool5 -> pool5_mask
I0912 01:41:18.217103 25102 net.cpp:150] Setting up pool5
I0912 01:41:18.217110 25102 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 01:41:18.217114 25102 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 01:41:18.217118 25102 net.cpp:165] Memory required for data: 3186954240
I0912 01:41:18.217123 25102 layer_factory.hpp:77] Creating layer upsample5
I0912 01:41:18.217136 25102 net.cpp:100] Creating Layer upsample5
I0912 01:41:18.217140 25102 net.cpp:434] upsample5 <- pool5
I0912 01:41:18.217161 25102 net.cpp:434] upsample5 <- pool5_mask
I0912 01:41:18.217167 25102 net.cpp:408] upsample5 -> pool5_D
I0912 01:41:18.217205 25102 net.cpp:150] Setting up upsample5
I0912 01:41:18.217211 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.217214 25102 net.cpp:165] Memory required for data: 3192606720
I0912 01:41:18.217219 25102 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 01:41:18.217231 25102 net.cpp:100] Creating Layer conv5_3_D
I0912 01:41:18.217236 25102 net.cpp:434] conv5_3_D <- pool5_D
I0912 01:41:18.217244 25102 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 01:41:18.301554 25102 net.cpp:150] Setting up conv5_3_D
I0912 01:41:18.301571 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.301576 25102 net.cpp:165] Memory required for data: 3198259200
I0912 01:41:18.301584 25102 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 01:41:18.301595 25102 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 01:41:18.301606 25102 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 01:41:18.301612 25102 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 01:41:18.301839 25102 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 01:41:18.301847 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.301851 25102 net.cpp:165] Memory required for data: 3203911680
I0912 01:41:18.301863 25102 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 01:41:18.301872 25102 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 01:41:18.301880 25102 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 01:41:18.301885 25102 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 01:41:18.301934 25102 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 01:41:18.302060 25102 net.cpp:150] Setting up conv5_3_D_scale
I0912 01:41:18.302068 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.302072 25102 net.cpp:165] Memory required for data: 3209564160
I0912 01:41:18.302078 25102 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 01:41:18.302088 25102 net.cpp:100] Creating Layer relu5_3_D
I0912 01:41:18.302093 25102 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 01:41:18.302096 25102 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 01:41:18.302314 25102 net.cpp:150] Setting up relu5_3_D
I0912 01:41:18.302323 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.302328 25102 net.cpp:165] Memory required for data: 3215216640
I0912 01:41:18.302332 25102 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 01:41:18.302359 25102 net.cpp:100] Creating Layer conv5_2_D
I0912 01:41:18.302364 25102 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 01:41:18.302374 25102 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 01:41:18.385814 25102 net.cpp:150] Setting up conv5_2_D
I0912 01:41:18.385831 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.385835 25102 net.cpp:165] Memory required for data: 3220869120
I0912 01:41:18.385843 25102 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 01:41:18.385861 25102 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 01:41:18.385869 25102 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 01:41:18.385875 25102 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 01:41:18.386101 25102 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 01:41:18.386109 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.386112 25102 net.cpp:165] Memory required for data: 3226521600
I0912 01:41:18.386121 25102 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 01:41:18.386129 25102 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 01:41:18.386139 25102 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 01:41:18.386147 25102 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 01:41:18.386196 25102 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 01:41:18.386322 25102 net.cpp:150] Setting up conv5_2_D_scale
I0912 01:41:18.386332 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.386334 25102 net.cpp:165] Memory required for data: 3232174080
I0912 01:41:18.386356 25102 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 01:41:18.386364 25102 net.cpp:100] Creating Layer relu5_2_D
I0912 01:41:18.386369 25102 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 01:41:18.386374 25102 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 01:41:18.387454 25102 net.cpp:150] Setting up relu5_2_D
I0912 01:41:18.387468 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.387473 25102 net.cpp:165] Memory required for data: 3237826560
I0912 01:41:18.387480 25102 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 01:41:18.387495 25102 net.cpp:100] Creating Layer conv5_1_D
I0912 01:41:18.387501 25102 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 01:41:18.387509 25102 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 01:41:18.471977 25102 net.cpp:150] Setting up conv5_1_D
I0912 01:41:18.471999 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.472004 25102 net.cpp:165] Memory required for data: 3243479040
I0912 01:41:18.472017 25102 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 01:41:18.472030 25102 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 01:41:18.472041 25102 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 01:41:18.472054 25102 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 01:41:18.472293 25102 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 01:41:18.472301 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.472306 25102 net.cpp:165] Memory required for data: 3249131520
I0912 01:41:18.472313 25102 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 01:41:18.472322 25102 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 01:41:18.472327 25102 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 01:41:18.472332 25102 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 01:41:18.472383 25102 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 01:41:18.472513 25102 net.cpp:150] Setting up conv5_1_D_scale
I0912 01:41:18.472520 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.472523 25102 net.cpp:165] Memory required for data: 3254784000
I0912 01:41:18.472530 25102 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 01:41:18.472539 25102 net.cpp:100] Creating Layer relu5_1_D
I0912 01:41:18.472544 25102 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 01:41:18.472548 25102 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 01:41:18.472770 25102 net.cpp:150] Setting up relu5_1_D
I0912 01:41:18.472780 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:18.472785 25102 net.cpp:165] Memory required for data: 3260436480
I0912 01:41:18.472790 25102 layer_factory.hpp:77] Creating layer upsample4
I0912 01:41:18.472800 25102 net.cpp:100] Creating Layer upsample4
I0912 01:41:18.472805 25102 net.cpp:434] upsample4 <- conv5_1_D
I0912 01:41:18.472812 25102 net.cpp:434] upsample4 <- pool4_mask
I0912 01:41:18.472820 25102 net.cpp:408] upsample4 -> pool4_D
I0912 01:41:18.472853 25102 net.cpp:150] Setting up upsample4
I0912 01:41:18.472860 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.472863 25102 net.cpp:165] Memory required for data: 3282554880
I0912 01:41:18.472867 25102 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 01:41:18.472879 25102 net.cpp:100] Creating Layer conv4_3_D
I0912 01:41:18.472884 25102 net.cpp:434] conv4_3_D <- pool4_D
I0912 01:41:18.472892 25102 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 01:41:18.557255 25102 net.cpp:150] Setting up conv4_3_D
I0912 01:41:18.557276 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.557281 25102 net.cpp:165] Memory required for data: 3304673280
I0912 01:41:18.557288 25102 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 01:41:18.557304 25102 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 01:41:18.557312 25102 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 01:41:18.557319 25102 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 01:41:18.557585 25102 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 01:41:18.557593 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.557616 25102 net.cpp:165] Memory required for data: 3326791680
I0912 01:41:18.557626 25102 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 01:41:18.557636 25102 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 01:41:18.557641 25102 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 01:41:18.557646 25102 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 01:41:18.557689 25102 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 01:41:18.557833 25102 net.cpp:150] Setting up conv4_3_D_scale
I0912 01:41:18.557842 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.557844 25102 net.cpp:165] Memory required for data: 3348910080
I0912 01:41:18.557852 25102 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 01:41:18.557860 25102 net.cpp:100] Creating Layer relu4_3_D
I0912 01:41:18.557864 25102 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 01:41:18.557869 25102 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 01:41:18.558078 25102 net.cpp:150] Setting up relu4_3_D
I0912 01:41:18.558087 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.558091 25102 net.cpp:165] Memory required for data: 3371028480
I0912 01:41:18.558095 25102 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 01:41:18.558106 25102 net.cpp:100] Creating Layer conv4_2_D
I0912 01:41:18.558112 25102 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 01:41:18.558120 25102 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 01:41:18.642407 25102 net.cpp:150] Setting up conv4_2_D
I0912 01:41:18.642426 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.642431 25102 net.cpp:165] Memory required for data: 3393146880
I0912 01:41:18.642438 25102 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 01:41:18.642455 25102 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 01:41:18.642462 25102 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 01:41:18.642468 25102 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 01:41:18.642705 25102 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 01:41:18.642714 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.642717 25102 net.cpp:165] Memory required for data: 3415265280
I0912 01:41:18.642729 25102 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 01:41:18.642737 25102 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 01:41:18.642746 25102 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 01:41:18.642751 25102 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 01:41:18.642794 25102 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 01:41:18.642940 25102 net.cpp:150] Setting up conv4_2_D_scale
I0912 01:41:18.642948 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.642951 25102 net.cpp:165] Memory required for data: 3437383680
I0912 01:41:18.642959 25102 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 01:41:18.642969 25102 net.cpp:100] Creating Layer relu4_2_D
I0912 01:41:18.642974 25102 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 01:41:18.642979 25102 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 01:41:18.643183 25102 net.cpp:150] Setting up relu4_2_D
I0912 01:41:18.643193 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.643198 25102 net.cpp:165] Memory required for data: 3459502080
I0912 01:41:18.643203 25102 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 01:41:18.643216 25102 net.cpp:100] Creating Layer conv4_1_D
I0912 01:41:18.643221 25102 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 01:41:18.643227 25102 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 01:41:18.687376 25102 net.cpp:150] Setting up conv4_1_D
I0912 01:41:18.687393 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:18.687407 25102 net.cpp:165] Memory required for data: 3470561280
I0912 01:41:18.687415 25102 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 01:41:18.687425 25102 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 01:41:18.687432 25102 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 01:41:18.687438 25102 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 01:41:18.687681 25102 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 01:41:18.687707 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:18.687717 25102 net.cpp:165] Memory required for data: 3481620480
I0912 01:41:18.687799 25102 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 01:41:18.687811 25102 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 01:41:18.687819 25102 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 01:41:18.687824 25102 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 01:41:18.687875 25102 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 01:41:18.688019 25102 net.cpp:150] Setting up conv4_1_D_scale
I0912 01:41:18.688027 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:18.688030 25102 net.cpp:165] Memory required for data: 3492679680
I0912 01:41:18.688038 25102 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 01:41:18.688045 25102 net.cpp:100] Creating Layer relu4_1_D
I0912 01:41:18.688051 25102 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 01:41:18.688055 25102 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 01:41:18.688284 25102 net.cpp:150] Setting up relu4_1_D
I0912 01:41:18.688294 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:18.688300 25102 net.cpp:165] Memory required for data: 3503738880
I0912 01:41:18.688303 25102 layer_factory.hpp:77] Creating layer upsample3
I0912 01:41:18.688311 25102 net.cpp:100] Creating Layer upsample3
I0912 01:41:18.688316 25102 net.cpp:434] upsample3 <- conv4_1_D
I0912 01:41:18.688321 25102 net.cpp:434] upsample3 <- pool3_mask
I0912 01:41:18.688330 25102 net.cpp:408] upsample3 -> pool3_D
I0912 01:41:18.688339 25102 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 01:41:18.688370 25102 net.cpp:150] Setting up upsample3
I0912 01:41:18.688385 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.688390 25102 net.cpp:165] Memory required for data: 3547975680
I0912 01:41:18.688393 25102 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 01:41:18.688406 25102 net.cpp:100] Creating Layer conv3_3_D
I0912 01:41:18.688411 25102 net.cpp:434] conv3_3_D <- pool3_D
I0912 01:41:18.688417 25102 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 01:41:18.712329 25102 net.cpp:150] Setting up conv3_3_D
I0912 01:41:18.712347 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.712358 25102 net.cpp:165] Memory required for data: 3592212480
I0912 01:41:18.712369 25102 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 01:41:18.712381 25102 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 01:41:18.712390 25102 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 01:41:18.712396 25102 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 01:41:18.712663 25102 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 01:41:18.712672 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.712676 25102 net.cpp:165] Memory required for data: 3636449280
I0912 01:41:18.712685 25102 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 01:41:18.712693 25102 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 01:41:18.712702 25102 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 01:41:18.712707 25102 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 01:41:18.712757 25102 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 01:41:18.712921 25102 net.cpp:150] Setting up conv3_3_D_scale
I0912 01:41:18.712929 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.712932 25102 net.cpp:165] Memory required for data: 3680686080
I0912 01:41:18.712939 25102 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 01:41:18.712949 25102 net.cpp:100] Creating Layer relu3_3_D
I0912 01:41:18.712954 25102 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 01:41:18.712960 25102 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 01:41:18.713176 25102 net.cpp:150] Setting up relu3_3_D
I0912 01:41:18.713186 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.713191 25102 net.cpp:165] Memory required for data: 3724922880
I0912 01:41:18.713210 25102 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 01:41:18.713227 25102 net.cpp:100] Creating Layer conv3_2_D
I0912 01:41:18.713232 25102 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 01:41:18.713238 25102 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 01:41:18.737164 25102 net.cpp:150] Setting up conv3_2_D
I0912 01:41:18.737182 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.737191 25102 net.cpp:165] Memory required for data: 3769159680
I0912 01:41:18.737200 25102 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 01:41:18.737212 25102 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 01:41:18.737218 25102 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 01:41:18.737224 25102 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 01:41:18.737504 25102 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 01:41:18.737514 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.737517 25102 net.cpp:165] Memory required for data: 3813396480
I0912 01:41:18.737527 25102 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 01:41:18.737541 25102 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 01:41:18.737548 25102 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 01:41:18.737553 25102 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 01:41:18.737601 25102 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 01:41:18.737767 25102 net.cpp:150] Setting up conv3_2_D_scale
I0912 01:41:18.737776 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.737779 25102 net.cpp:165] Memory required for data: 3857633280
I0912 01:41:18.737785 25102 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 01:41:18.737793 25102 net.cpp:100] Creating Layer relu3_2_D
I0912 01:41:18.737798 25102 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 01:41:18.737807 25102 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 01:41:18.738903 25102 net.cpp:150] Setting up relu3_2_D
I0912 01:41:18.738917 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.738922 25102 net.cpp:165] Memory required for data: 3901870080
I0912 01:41:18.738926 25102 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 01:41:18.738946 25102 net.cpp:100] Creating Layer conv3_1_D
I0912 01:41:18.738952 25102 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 01:41:18.738961 25102 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 01:41:18.753087 25102 net.cpp:150] Setting up conv3_1_D
I0912 01:41:18.753103 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:18.753113 25102 net.cpp:165] Memory required for data: 3923988480
I0912 01:41:18.753123 25102 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 01:41:18.753136 25102 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 01:41:18.753145 25102 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 01:41:18.753151 25102 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 01:41:18.753444 25102 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 01:41:18.753454 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:18.753458 25102 net.cpp:165] Memory required for data: 3946106880
I0912 01:41:18.753468 25102 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 01:41:18.753478 25102 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 01:41:18.753485 25102 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 01:41:18.753491 25102 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 01:41:18.753542 25102 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 01:41:18.753712 25102 net.cpp:150] Setting up conv3_1_D_scale
I0912 01:41:18.753720 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:18.753723 25102 net.cpp:165] Memory required for data: 3968225280
I0912 01:41:18.753731 25102 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 01:41:18.753739 25102 net.cpp:100] Creating Layer relu3_1_D
I0912 01:41:18.753744 25102 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 01:41:18.753749 25102 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 01:41:18.753975 25102 net.cpp:150] Setting up relu3_1_D
I0912 01:41:18.754000 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:18.754005 25102 net.cpp:165] Memory required for data: 3990343680
I0912 01:41:18.754009 25102 layer_factory.hpp:77] Creating layer upsample2
I0912 01:41:18.754015 25102 net.cpp:100] Creating Layer upsample2
I0912 01:41:18.754020 25102 net.cpp:434] upsample2 <- conv3_1_D
I0912 01:41:18.754026 25102 net.cpp:434] upsample2 <- pool2_mask
I0912 01:41:18.754035 25102 net.cpp:408] upsample2 -> pool2_D
I0912 01:41:18.754045 25102 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 01:41:18.754076 25102 net.cpp:150] Setting up upsample2
I0912 01:41:18.754083 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.754088 25102 net.cpp:165] Memory required for data: 4078817280
I0912 01:41:18.754091 25102 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 01:41:18.754108 25102 net.cpp:100] Creating Layer conv2_2_D
I0912 01:41:18.754113 25102 net.cpp:434] conv2_2_D <- pool2_D
I0912 01:41:18.754119 25102 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 01:41:18.761811 25102 net.cpp:150] Setting up conv2_2_D
I0912 01:41:18.761827 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.761842 25102 net.cpp:165] Memory required for data: 4167290880
I0912 01:41:18.761850 25102 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 01:41:18.761862 25102 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 01:41:18.761871 25102 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 01:41:18.761878 25102 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 01:41:18.762186 25102 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 01:41:18.762194 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.762197 25102 net.cpp:165] Memory required for data: 4255764480
I0912 01:41:18.762205 25102 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 01:41:18.762217 25102 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 01:41:18.762221 25102 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 01:41:18.762226 25102 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 01:41:18.762284 25102 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 01:41:18.764132 25102 net.cpp:150] Setting up conv2_2_D_scale
I0912 01:41:18.764147 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.764154 25102 net.cpp:165] Memory required for data: 4344238080
I0912 01:41:18.764163 25102 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 01:41:18.764178 25102 net.cpp:100] Creating Layer relu2_2_D
I0912 01:41:18.764183 25102 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 01:41:18.764189 25102 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 01:41:18.764420 25102 net.cpp:150] Setting up relu2_2_D
I0912 01:41:18.764433 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.764438 25102 net.cpp:165] Memory required for data: 4432711680
I0912 01:41:18.764442 25102 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 01:41:18.764456 25102 net.cpp:100] Creating Layer conv2_1_D
I0912 01:41:18.764461 25102 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 01:41:18.764468 25102 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 01:41:18.769765 25102 net.cpp:150] Setting up conv2_1_D
I0912 01:41:18.769783 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:18.769794 25102 net.cpp:165] Memory required for data: 4476948480
I0912 01:41:18.769803 25102 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 01:41:18.769812 25102 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 01:41:18.769819 25102 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 01:41:18.769824 25102 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 01:41:18.770123 25102 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 01:41:18.770131 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:18.770134 25102 net.cpp:165] Memory required for data: 4521185280
I0912 01:41:18.770143 25102 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 01:41:18.770165 25102 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 01:41:18.770174 25102 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 01:41:18.770179 25102 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 01:41:18.770236 25102 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 01:41:18.770455 25102 net.cpp:150] Setting up conv2_1_D_scale
I0912 01:41:18.770463 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:18.770467 25102 net.cpp:165] Memory required for data: 4565422080
I0912 01:41:18.770473 25102 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 01:41:18.770485 25102 net.cpp:100] Creating Layer relu2_1_D
I0912 01:41:18.770490 25102 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 01:41:18.770494 25102 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 01:41:18.770727 25102 net.cpp:150] Setting up relu2_1_D
I0912 01:41:18.770740 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:18.770745 25102 net.cpp:165] Memory required for data: 4609658880
I0912 01:41:18.770748 25102 layer_factory.hpp:77] Creating layer upsample1
I0912 01:41:18.770756 25102 net.cpp:100] Creating Layer upsample1
I0912 01:41:18.770761 25102 net.cpp:434] upsample1 <- conv2_1_D
I0912 01:41:18.770766 25102 net.cpp:434] upsample1 <- pool1_mask
I0912 01:41:18.770772 25102 net.cpp:408] upsample1 -> pool1_D
I0912 01:41:18.770779 25102 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 01:41:18.770814 25102 net.cpp:150] Setting up upsample1
I0912 01:41:18.770822 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.770824 25102 net.cpp:165] Memory required for data: 4786606080
I0912 01:41:18.770829 25102 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 01:41:18.770840 25102 net.cpp:100] Creating Layer conv1_2_D
I0912 01:41:18.770845 25102 net.cpp:434] conv1_2_D <- pool1_D
I0912 01:41:18.770854 25102 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 01:41:18.775746 25102 net.cpp:150] Setting up conv1_2_D
I0912 01:41:18.775763 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.775773 25102 net.cpp:165] Memory required for data: 4963553280
I0912 01:41:18.775780 25102 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 01:41:18.775797 25102 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 01:41:18.775804 25102 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 01:41:18.775810 25102 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 01:41:18.776211 25102 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 01:41:18.776218 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.776222 25102 net.cpp:165] Memory required for data: 5140500480
I0912 01:41:18.776232 25102 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 01:41:18.776242 25102 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 01:41:18.776247 25102 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 01:41:18.776252 25102 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 01:41:18.776302 25102 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 01:41:18.778367 25102 net.cpp:150] Setting up conv1_2_D_scale
I0912 01:41:18.778381 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.778391 25102 net.cpp:165] Memory required for data: 5317447680
I0912 01:41:18.778399 25102 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 01:41:18.778412 25102 net.cpp:100] Creating Layer relu1_2_D
I0912 01:41:18.778417 25102 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 01:41:18.778424 25102 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 01:41:18.778661 25102 net.cpp:150] Setting up relu1_2_D
I0912 01:41:18.778671 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.778676 25102 net.cpp:165] Memory required for data: 5494394880
I0912 01:41:18.778681 25102 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 01:41:18.778694 25102 net.cpp:100] Creating Layer conv1_1_1_D
I0912 01:41:18.778699 25102 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 01:41:18.778724 25102 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 01:41:18.780812 25102 net.cpp:150] Setting up conv1_1_1_D
I0912 01:41:18.780833 25102 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 01:41:18.780838 25102 net.cpp:165] Memory required for data: 5499924480
I0912 01:41:18.780845 25102 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 01:41:18.780853 25102 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 01:41:18.780859 25102 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 01:41:18.780865 25102 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 01:41:18.780874 25102 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 01:41:18.780930 25102 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 01:41:18.780937 25102 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 01:41:18.780942 25102 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 01:41:18.780946 25102 net.cpp:165] Memory required for data: 5510983680
I0912 01:41:18.780951 25102 layer_factory.hpp:77] Creating layer loss
I0912 01:41:18.780967 25102 net.cpp:100] Creating Layer loss
I0912 01:41:18.780972 25102 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 01:41:18.780977 25102 net.cpp:434] loss <- label_data_1_split_0
I0912 01:41:18.780982 25102 net.cpp:408] loss -> loss
I0912 01:41:18.781004 25102 layer_factory.hpp:77] Creating layer loss
I0912 01:41:18.785912 25102 net.cpp:150] Setting up loss
I0912 01:41:18.785929 25102 net.cpp:157] Top shape: (1)
I0912 01:41:18.785933 25102 net.cpp:160]     with loss weight 1
I0912 01:41:18.785972 25102 net.cpp:165] Memory required for data: 5510983684
I0912 01:41:18.785976 25102 layer_factory.hpp:77] Creating layer accuracy
I0912 01:41:18.785986 25102 net.cpp:100] Creating Layer accuracy
I0912 01:41:18.785995 25102 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 01:41:18.786000 25102 net.cpp:434] accuracy <- label_data_1_split_1
I0912 01:41:18.786010 25102 net.cpp:408] accuracy -> accuracy
I0912 01:41:18.786017 25102 net.cpp:408] accuracy -> per_class_accuracy
I0912 01:41:18.786075 25102 net.cpp:150] Setting up accuracy
I0912 01:41:18.786082 25102 net.cpp:157] Top shape: (1)
I0912 01:41:18.786087 25102 net.cpp:157] Top shape: 2 (2)
I0912 01:41:18.786090 25102 net.cpp:165] Memory required for data: 5510983696
I0912 01:41:18.786095 25102 net.cpp:228] accuracy does not need backward computation.
I0912 01:41:18.786099 25102 net.cpp:226] loss needs backward computation.
I0912 01:41:18.786103 25102 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 01:41:18.786108 25102 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 01:41:18.786111 25102 net.cpp:226] relu1_2_D needs backward computation.
I0912 01:41:18.786116 25102 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 01:41:18.786119 25102 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 01:41:18.786123 25102 net.cpp:226] conv1_2_D needs backward computation.
I0912 01:41:18.786125 25102 net.cpp:226] upsample1 needs backward computation.
I0912 01:41:18.786129 25102 net.cpp:226] relu2_1_D needs backward computation.
I0912 01:41:18.786133 25102 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 01:41:18.786135 25102 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 01:41:18.786139 25102 net.cpp:226] conv2_1_D needs backward computation.
I0912 01:41:18.786142 25102 net.cpp:226] relu2_2_D needs backward computation.
I0912 01:41:18.786145 25102 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 01:41:18.786150 25102 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 01:41:18.786154 25102 net.cpp:226] conv2_2_D needs backward computation.
I0912 01:41:18.786157 25102 net.cpp:226] upsample2 needs backward computation.
I0912 01:41:18.786161 25102 net.cpp:226] relu3_1_D needs backward computation.
I0912 01:41:18.786164 25102 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 01:41:18.786182 25102 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 01:41:18.786186 25102 net.cpp:226] conv3_1_D needs backward computation.
I0912 01:41:18.786190 25102 net.cpp:226] relu3_2_D needs backward computation.
I0912 01:41:18.786192 25102 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 01:41:18.786195 25102 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 01:41:18.786198 25102 net.cpp:226] conv3_2_D needs backward computation.
I0912 01:41:18.786202 25102 net.cpp:226] relu3_3_D needs backward computation.
I0912 01:41:18.786206 25102 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 01:41:18.786208 25102 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 01:41:18.786212 25102 net.cpp:226] conv3_3_D needs backward computation.
I0912 01:41:18.786216 25102 net.cpp:226] upsample3 needs backward computation.
I0912 01:41:18.786221 25102 net.cpp:226] relu4_1_D needs backward computation.
I0912 01:41:18.786226 25102 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 01:41:18.786229 25102 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 01:41:18.786232 25102 net.cpp:226] conv4_1_D needs backward computation.
I0912 01:41:18.786242 25102 net.cpp:226] relu4_2_D needs backward computation.
I0912 01:41:18.786247 25102 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 01:41:18.786250 25102 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 01:41:18.786253 25102 net.cpp:226] conv4_2_D needs backward computation.
I0912 01:41:18.786257 25102 net.cpp:226] relu4_3_D needs backward computation.
I0912 01:41:18.786260 25102 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 01:41:18.786263 25102 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 01:41:18.786267 25102 net.cpp:226] conv4_3_D needs backward computation.
I0912 01:41:18.786272 25102 net.cpp:226] upsample4 needs backward computation.
I0912 01:41:18.786275 25102 net.cpp:226] relu5_1_D needs backward computation.
I0912 01:41:18.786280 25102 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 01:41:18.786284 25102 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 01:41:18.786288 25102 net.cpp:226] conv5_1_D needs backward computation.
I0912 01:41:18.786291 25102 net.cpp:226] relu5_2_D needs backward computation.
I0912 01:41:18.786294 25102 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 01:41:18.786298 25102 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 01:41:18.786303 25102 net.cpp:226] conv5_2_D needs backward computation.
I0912 01:41:18.786306 25102 net.cpp:226] relu5_3_D needs backward computation.
I0912 01:41:18.786311 25102 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 01:41:18.786314 25102 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 01:41:18.786319 25102 net.cpp:226] conv5_3_D needs backward computation.
I0912 01:41:18.786321 25102 net.cpp:226] upsample5 needs backward computation.
I0912 01:41:18.786326 25102 net.cpp:226] pool5 needs backward computation.
I0912 01:41:18.786331 25102 net.cpp:226] relu5_3 needs backward computation.
I0912 01:41:18.786335 25102 net.cpp:226] conv5_3_scale needs backward computation.
I0912 01:41:18.786339 25102 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 01:41:18.786343 25102 net.cpp:226] conv5_3 needs backward computation.
I0912 01:41:18.786348 25102 net.cpp:226] relu5_2 needs backward computation.
I0912 01:41:18.786353 25102 net.cpp:226] conv5_2_scale needs backward computation.
I0912 01:41:18.786356 25102 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 01:41:18.786360 25102 net.cpp:226] conv5_2 needs backward computation.
I0912 01:41:18.786365 25102 net.cpp:226] relu5_1 needs backward computation.
I0912 01:41:18.786368 25102 net.cpp:226] conv5_1_scale needs backward computation.
I0912 01:41:18.786373 25102 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 01:41:18.786376 25102 net.cpp:226] conv5_1 needs backward computation.
I0912 01:41:18.786381 25102 net.cpp:226] pool4 needs backward computation.
I0912 01:41:18.786391 25102 net.cpp:226] relu4_3 needs backward computation.
I0912 01:41:18.786396 25102 net.cpp:226] conv4_3_scale needs backward computation.
I0912 01:41:18.786398 25102 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 01:41:18.786403 25102 net.cpp:226] conv4_3 needs backward computation.
I0912 01:41:18.786408 25102 net.cpp:226] relu4_2 needs backward computation.
I0912 01:41:18.786412 25102 net.cpp:226] conv4_2_scale needs backward computation.
I0912 01:41:18.786415 25102 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 01:41:18.786419 25102 net.cpp:226] conv4_2 needs backward computation.
I0912 01:41:18.786423 25102 net.cpp:226] relu4_1 needs backward computation.
I0912 01:41:18.786427 25102 net.cpp:226] conv4_1_scale needs backward computation.
I0912 01:41:18.786430 25102 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 01:41:18.786433 25102 net.cpp:226] conv4_1 needs backward computation.
I0912 01:41:18.786437 25102 net.cpp:226] pool3 needs backward computation.
I0912 01:41:18.786442 25102 net.cpp:226] relu3_3 needs backward computation.
I0912 01:41:18.786447 25102 net.cpp:226] conv3_3_scale needs backward computation.
I0912 01:41:18.786450 25102 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 01:41:18.786454 25102 net.cpp:226] conv3_3 needs backward computation.
I0912 01:41:18.786458 25102 net.cpp:226] relu3_2 needs backward computation.
I0912 01:41:18.786461 25102 net.cpp:226] conv3_2_scale needs backward computation.
I0912 01:41:18.786464 25102 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 01:41:18.786469 25102 net.cpp:226] conv3_2 needs backward computation.
I0912 01:41:18.786473 25102 net.cpp:226] relu3_1 needs backward computation.
I0912 01:41:18.786478 25102 net.cpp:226] conv3_1_scale needs backward computation.
I0912 01:41:18.786483 25102 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 01:41:18.786486 25102 net.cpp:226] conv3_1 needs backward computation.
I0912 01:41:18.786490 25102 net.cpp:226] pool2 needs backward computation.
I0912 01:41:18.786495 25102 net.cpp:226] relu2_2 needs backward computation.
I0912 01:41:18.786500 25102 net.cpp:226] conv2_2_scale needs backward computation.
I0912 01:41:18.786504 25102 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 01:41:18.786509 25102 net.cpp:226] conv2_2 needs backward computation.
I0912 01:41:18.786511 25102 net.cpp:226] relu2_1 needs backward computation.
I0912 01:41:18.786515 25102 net.cpp:226] conv2_1_scale needs backward computation.
I0912 01:41:18.786520 25102 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 01:41:18.786523 25102 net.cpp:226] conv2_1 needs backward computation.
I0912 01:41:18.786527 25102 net.cpp:226] pool1 needs backward computation.
I0912 01:41:18.786531 25102 net.cpp:226] relu1_2 needs backward computation.
I0912 01:41:18.786535 25102 net.cpp:226] conv1_2_scale needs backward computation.
I0912 01:41:18.786538 25102 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 01:41:18.786542 25102 net.cpp:226] conv1_2 needs backward computation.
I0912 01:41:18.786546 25102 net.cpp:226] relu1_1 needs backward computation.
I0912 01:41:18.786550 25102 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 01:41:18.786553 25102 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 01:41:18.786557 25102 net.cpp:226] conv1_1_1 needs backward computation.
I0912 01:41:18.786564 25102 net.cpp:228] label_data_1_split does not need backward computation.
I0912 01:41:18.786569 25102 net.cpp:228] data does not need backward computation.
I0912 01:41:18.786573 25102 net.cpp:270] This network produces output accuracy
I0912 01:41:18.786577 25102 net.cpp:270] This network produces output loss
I0912 01:41:18.786581 25102 net.cpp:270] This network produces output per_class_accuracy
I0912 01:41:18.786646 25102 net.cpp:283] Network initialization done.
I0912 01:41:18.788976 25102 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc3/caffe/model_segnet_final/train.prototxt
I0912 01:41:18.789688 25102 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc3/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 01:41:18.790122 25102 layer_factory.hpp:77] Creating layer data
I0912 01:41:18.790134 25102 net.cpp:100] Creating Layer data
I0912 01:41:18.790140 25102 net.cpp:408] data -> data
I0912 01:41:18.790148 25102 net.cpp:408] data -> label
I0912 01:41:18.790158 25102 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc3/HDF5Files/train_combined.txt
I0912 01:41:18.790199 25102 hdf5_data_layer.cpp:93] Number of HDF5 files: 29
I0912 01:41:18.801353 25102 net.cpp:150] Setting up data
I0912 01:41:18.801386 25102 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 01:41:18.801394 25102 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 01:41:18.801398 25102 net.cpp:165] Memory required for data: 24883200
I0912 01:41:18.801403 25102 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 01:41:18.801411 25102 net.cpp:100] Creating Layer label_data_1_split
I0912 01:41:18.801416 25102 net.cpp:434] label_data_1_split <- label
I0912 01:41:18.801422 25102 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 01:41:18.801436 25102 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 01:41:18.801486 25102 net.cpp:150] Setting up label_data_1_split
I0912 01:41:18.801493 25102 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 01:41:18.801498 25102 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 01:41:18.801501 25102 net.cpp:165] Memory required for data: 30412800
I0912 01:41:18.801509 25102 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 01:41:18.801519 25102 net.cpp:100] Creating Layer conv1_1_1
I0912 01:41:18.801525 25102 net.cpp:434] conv1_1_1 <- data
I0912 01:41:18.801532 25102 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 01:41:18.805287 25102 net.cpp:150] Setting up conv1_1_1
I0912 01:41:18.805305 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.805312 25102 net.cpp:165] Memory required for data: 207360000
I0912 01:41:18.805325 25102 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 01:41:18.805335 25102 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 01:41:18.805343 25102 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 01:41:18.805348 25102 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 01:41:18.805752 25102 net.cpp:150] Setting up conv1_1_1_bn
I0912 01:41:18.805763 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.805766 25102 net.cpp:165] Memory required for data: 384307200
I0912 01:41:18.805778 25102 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 01:41:18.805789 25102 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 01:41:18.805794 25102 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 01:41:18.805799 25102 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 01:41:18.805850 25102 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 01:41:18.807811 25102 net.cpp:150] Setting up conv1_1_1_scale
I0912 01:41:18.807826 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.807834 25102 net.cpp:165] Memory required for data: 561254400
I0912 01:41:18.807842 25102 layer_factory.hpp:77] Creating layer relu1_1
I0912 01:41:18.807852 25102 net.cpp:100] Creating Layer relu1_1
I0912 01:41:18.807857 25102 net.cpp:434] relu1_1 <- conv1_1_1
I0912 01:41:18.807863 25102 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 01:41:18.808084 25102 net.cpp:150] Setting up relu1_1
I0912 01:41:18.808094 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.808099 25102 net.cpp:165] Memory required for data: 738201600
I0912 01:41:18.808102 25102 layer_factory.hpp:77] Creating layer conv1_2
I0912 01:41:18.808111 25102 net.cpp:100] Creating Layer conv1_2
I0912 01:41:18.808116 25102 net.cpp:434] conv1_2 <- conv1_1_1
I0912 01:41:18.808123 25102 net.cpp:408] conv1_2 -> conv1_2
I0912 01:41:18.812247 25102 net.cpp:150] Setting up conv1_2
I0912 01:41:18.812263 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.812273 25102 net.cpp:165] Memory required for data: 915148800
I0912 01:41:18.812301 25102 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 01:41:18.812314 25102 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 01:41:18.812319 25102 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 01:41:18.812325 25102 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 01:41:18.812705 25102 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 01:41:18.812714 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.812718 25102 net.cpp:165] Memory required for data: 1092096000
I0912 01:41:18.812727 25102 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 01:41:18.812736 25102 net.cpp:100] Creating Layer conv1_2_scale
I0912 01:41:18.812741 25102 net.cpp:434] conv1_2_scale <- conv1_2
I0912 01:41:18.812746 25102 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 01:41:18.812796 25102 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 01:41:18.814767 25102 net.cpp:150] Setting up conv1_2_scale
I0912 01:41:18.814784 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.814787 25102 net.cpp:165] Memory required for data: 1269043200
I0912 01:41:18.814795 25102 layer_factory.hpp:77] Creating layer relu1_2
I0912 01:41:18.814802 25102 net.cpp:100] Creating Layer relu1_2
I0912 01:41:18.814807 25102 net.cpp:434] relu1_2 <- conv1_2
I0912 01:41:18.814813 25102 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 01:41:18.815927 25102 net.cpp:150] Setting up relu1_2
I0912 01:41:18.815943 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:18.815948 25102 net.cpp:165] Memory required for data: 1445990400
I0912 01:41:18.815951 25102 layer_factory.hpp:77] Creating layer pool1
I0912 01:41:18.815955 25102 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 01:41:18.815963 25102 net.cpp:100] Creating Layer pool1
I0912 01:41:18.815968 25102 net.cpp:434] pool1 <- conv1_2
I0912 01:41:18.815974 25102 net.cpp:408] pool1 -> pool1
I0912 01:41:18.815984 25102 net.cpp:408] pool1 -> pool1_mask
I0912 01:41:18.816045 25102 net.cpp:150] Setting up pool1
I0912 01:41:18.816052 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:18.816056 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:18.816062 25102 net.cpp:165] Memory required for data: 1534464000
I0912 01:41:18.816066 25102 layer_factory.hpp:77] Creating layer conv2_1
I0912 01:41:18.816074 25102 net.cpp:100] Creating Layer conv2_1
I0912 01:41:18.816079 25102 net.cpp:434] conv2_1 <- pool1
I0912 01:41:18.816088 25102 net.cpp:408] conv2_1 -> conv2_1
I0912 01:41:18.820454 25102 net.cpp:150] Setting up conv2_1
I0912 01:41:18.820472 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.820482 25102 net.cpp:165] Memory required for data: 1622937600
I0912 01:41:18.820490 25102 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 01:41:18.820500 25102 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 01:41:18.820507 25102 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 01:41:18.820513 25102 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 01:41:18.820842 25102 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 01:41:18.820850 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.820854 25102 net.cpp:165] Memory required for data: 1711411200
I0912 01:41:18.820866 25102 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 01:41:18.820873 25102 net.cpp:100] Creating Layer conv2_1_scale
I0912 01:41:18.820879 25102 net.cpp:434] conv2_1_scale <- conv2_1
I0912 01:41:18.820884 25102 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 01:41:18.820940 25102 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 01:41:18.821192 25102 net.cpp:150] Setting up conv2_1_scale
I0912 01:41:18.821200 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.821203 25102 net.cpp:165] Memory required for data: 1799884800
I0912 01:41:18.821210 25102 layer_factory.hpp:77] Creating layer relu2_1
I0912 01:41:18.821218 25102 net.cpp:100] Creating Layer relu2_1
I0912 01:41:18.821224 25102 net.cpp:434] relu2_1 <- conv2_1
I0912 01:41:18.821229 25102 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 01:41:18.822391 25102 net.cpp:150] Setting up relu2_1
I0912 01:41:18.822407 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.822412 25102 net.cpp:165] Memory required for data: 1888358400
I0912 01:41:18.822417 25102 layer_factory.hpp:77] Creating layer conv2_2
I0912 01:41:18.822429 25102 net.cpp:100] Creating Layer conv2_2
I0912 01:41:18.822438 25102 net.cpp:434] conv2_2 <- conv2_1
I0912 01:41:18.822444 25102 net.cpp:408] conv2_2 -> conv2_2
I0912 01:41:18.831846 25102 net.cpp:150] Setting up conv2_2
I0912 01:41:18.831863 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.831873 25102 net.cpp:165] Memory required for data: 1976832000
I0912 01:41:18.831881 25102 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 01:41:18.831895 25102 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 01:41:18.831902 25102 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 01:41:18.831907 25102 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 01:41:18.833806 25102 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 01:41:18.833820 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.833829 25102 net.cpp:165] Memory required for data: 2065305600
I0912 01:41:18.833839 25102 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 01:41:18.833851 25102 net.cpp:100] Creating Layer conv2_2_scale
I0912 01:41:18.833860 25102 net.cpp:434] conv2_2_scale <- conv2_2
I0912 01:41:18.833866 25102 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 01:41:18.833925 25102 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 01:41:18.834138 25102 net.cpp:150] Setting up conv2_2_scale
I0912 01:41:18.834147 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.834151 25102 net.cpp:165] Memory required for data: 2153779200
I0912 01:41:18.834157 25102 layer_factory.hpp:77] Creating layer relu2_2
I0912 01:41:18.834164 25102 net.cpp:100] Creating Layer relu2_2
I0912 01:41:18.834172 25102 net.cpp:434] relu2_2 <- conv2_2
I0912 01:41:18.834177 25102 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 01:41:18.834411 25102 net.cpp:150] Setting up relu2_2
I0912 01:41:18.834421 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:18.834426 25102 net.cpp:165] Memory required for data: 2242252800
I0912 01:41:18.834430 25102 layer_factory.hpp:77] Creating layer pool2
I0912 01:41:18.834434 25102 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 01:41:18.834442 25102 net.cpp:100] Creating Layer pool2
I0912 01:41:18.834447 25102 net.cpp:434] pool2 <- conv2_2
I0912 01:41:18.834452 25102 net.cpp:408] pool2 -> pool2
I0912 01:41:18.834460 25102 net.cpp:408] pool2 -> pool2_mask
I0912 01:41:18.834518 25102 net.cpp:150] Setting up pool2
I0912 01:41:18.834527 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:18.834530 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:18.834535 25102 net.cpp:165] Memory required for data: 2286489600
I0912 01:41:18.834538 25102 layer_factory.hpp:77] Creating layer conv3_1
I0912 01:41:18.834552 25102 net.cpp:100] Creating Layer conv3_1
I0912 01:41:18.834556 25102 net.cpp:434] conv3_1 <- pool2
I0912 01:41:18.834564 25102 net.cpp:408] conv3_1 -> conv3_1
I0912 01:41:18.847100 25102 net.cpp:150] Setting up conv3_1
I0912 01:41:18.847116 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.847126 25102 net.cpp:165] Memory required for data: 2330726400
I0912 01:41:18.847133 25102 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 01:41:18.847143 25102 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 01:41:18.847152 25102 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 01:41:18.847160 25102 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 01:41:18.847446 25102 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 01:41:18.847455 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.847458 25102 net.cpp:165] Memory required for data: 2374963200
I0912 01:41:18.847474 25102 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 01:41:18.847496 25102 net.cpp:100] Creating Layer conv3_1_scale
I0912 01:41:18.847506 25102 net.cpp:434] conv3_1_scale <- conv3_1
I0912 01:41:18.847510 25102 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 01:41:18.847569 25102 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 01:41:18.847748 25102 net.cpp:150] Setting up conv3_1_scale
I0912 01:41:18.847755 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.847759 25102 net.cpp:165] Memory required for data: 2419200000
I0912 01:41:18.847765 25102 layer_factory.hpp:77] Creating layer relu3_1
I0912 01:41:18.847775 25102 net.cpp:100] Creating Layer relu3_1
I0912 01:41:18.847780 25102 net.cpp:434] relu3_1 <- conv3_1
I0912 01:41:18.847787 25102 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 01:41:18.848018 25102 net.cpp:150] Setting up relu3_1
I0912 01:41:18.848029 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.848034 25102 net.cpp:165] Memory required for data: 2463436800
I0912 01:41:18.848038 25102 layer_factory.hpp:77] Creating layer conv3_2
I0912 01:41:18.848050 25102 net.cpp:100] Creating Layer conv3_2
I0912 01:41:18.848055 25102 net.cpp:434] conv3_2 <- conv3_1
I0912 01:41:18.848064 25102 net.cpp:408] conv3_2 -> conv3_2
I0912 01:41:18.872072 25102 net.cpp:150] Setting up conv3_2
I0912 01:41:18.872089 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.872093 25102 net.cpp:165] Memory required for data: 2507673600
I0912 01:41:18.872102 25102 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 01:41:18.872112 25102 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 01:41:18.872118 25102 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 01:41:18.872123 25102 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 01:41:18.872421 25102 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 01:41:18.872429 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.872433 25102 net.cpp:165] Memory required for data: 2551910400
I0912 01:41:18.872442 25102 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 01:41:18.872455 25102 net.cpp:100] Creating Layer conv3_2_scale
I0912 01:41:18.872462 25102 net.cpp:434] conv3_2_scale <- conv3_2
I0912 01:41:18.872467 25102 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 01:41:18.872519 25102 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 01:41:18.872701 25102 net.cpp:150] Setting up conv3_2_scale
I0912 01:41:18.872709 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.872712 25102 net.cpp:165] Memory required for data: 2596147200
I0912 01:41:18.872719 25102 layer_factory.hpp:77] Creating layer relu3_2
I0912 01:41:18.872725 25102 net.cpp:100] Creating Layer relu3_2
I0912 01:41:18.872730 25102 net.cpp:434] relu3_2 <- conv3_2
I0912 01:41:18.872738 25102 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 01:41:18.872967 25102 net.cpp:150] Setting up relu3_2
I0912 01:41:18.872977 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.872982 25102 net.cpp:165] Memory required for data: 2640384000
I0912 01:41:18.872985 25102 layer_factory.hpp:77] Creating layer conv3_3
I0912 01:41:18.873000 25102 net.cpp:100] Creating Layer conv3_3
I0912 01:41:18.873005 25102 net.cpp:434] conv3_3 <- conv3_2
I0912 01:41:18.873013 25102 net.cpp:408] conv3_3 -> conv3_3
I0912 01:41:18.898717 25102 net.cpp:150] Setting up conv3_3
I0912 01:41:18.898736 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.898746 25102 net.cpp:165] Memory required for data: 2684620800
I0912 01:41:18.898756 25102 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 01:41:18.898771 25102 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 01:41:18.898778 25102 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 01:41:18.898789 25102 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 01:41:18.899083 25102 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 01:41:18.899091 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.899096 25102 net.cpp:165] Memory required for data: 2728857600
I0912 01:41:18.899103 25102 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 01:41:18.899130 25102 net.cpp:100] Creating Layer conv3_3_scale
I0912 01:41:18.899137 25102 net.cpp:434] conv3_3_scale <- conv3_3
I0912 01:41:18.899144 25102 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 01:41:18.899199 25102 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 01:41:18.899379 25102 net.cpp:150] Setting up conv3_3_scale
I0912 01:41:18.899389 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.899394 25102 net.cpp:165] Memory required for data: 2773094400
I0912 01:41:18.899401 25102 layer_factory.hpp:77] Creating layer relu3_3
I0912 01:41:18.899408 25102 net.cpp:100] Creating Layer relu3_3
I0912 01:41:18.899415 25102 net.cpp:434] relu3_3 <- conv3_3
I0912 01:41:18.899418 25102 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 01:41:18.899655 25102 net.cpp:150] Setting up relu3_3
I0912 01:41:18.899668 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:18.899673 25102 net.cpp:165] Memory required for data: 2817331200
I0912 01:41:18.899677 25102 layer_factory.hpp:77] Creating layer pool3
I0912 01:41:18.899684 25102 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 01:41:18.899701 25102 net.cpp:100] Creating Layer pool3
I0912 01:41:18.899706 25102 net.cpp:434] pool3 <- conv3_3
I0912 01:41:18.899714 25102 net.cpp:408] pool3 -> pool3
I0912 01:41:18.899724 25102 net.cpp:408] pool3 -> pool3_mask
I0912 01:41:18.899785 25102 net.cpp:150] Setting up pool3
I0912 01:41:18.899792 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:18.899797 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:18.899801 25102 net.cpp:165] Memory required for data: 2839449600
I0912 01:41:18.899804 25102 layer_factory.hpp:77] Creating layer conv4_1
I0912 01:41:18.899818 25102 net.cpp:100] Creating Layer conv4_1
I0912 01:41:18.899823 25102 net.cpp:434] conv4_1 <- pool3
I0912 01:41:18.899833 25102 net.cpp:408] conv4_1 -> conv4_1
I0912 01:41:18.944499 25102 net.cpp:150] Setting up conv4_1
I0912 01:41:18.944516 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.944526 25102 net.cpp:165] Memory required for data: 2861568000
I0912 01:41:18.944537 25102 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 01:41:18.944552 25102 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 01:41:18.944558 25102 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 01:41:18.944564 25102 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 01:41:18.944844 25102 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 01:41:18.944854 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.944857 25102 net.cpp:165] Memory required for data: 2883686400
I0912 01:41:18.944866 25102 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 01:41:18.944877 25102 net.cpp:100] Creating Layer conv4_1_scale
I0912 01:41:18.944882 25102 net.cpp:434] conv4_1_scale <- conv4_1
I0912 01:41:18.944888 25102 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 01:41:18.944937 25102 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 01:41:18.945104 25102 net.cpp:150] Setting up conv4_1_scale
I0912 01:41:18.945112 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.945116 25102 net.cpp:165] Memory required for data: 2905804800
I0912 01:41:18.945122 25102 layer_factory.hpp:77] Creating layer relu4_1
I0912 01:41:18.945129 25102 net.cpp:100] Creating Layer relu4_1
I0912 01:41:18.945134 25102 net.cpp:434] relu4_1 <- conv4_1
I0912 01:41:18.945143 25102 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 01:41:18.946305 25102 net.cpp:150] Setting up relu4_1
I0912 01:41:18.946321 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:18.946326 25102 net.cpp:165] Memory required for data: 2927923200
I0912 01:41:18.946331 25102 layer_factory.hpp:77] Creating layer conv4_2
I0912 01:41:18.946343 25102 net.cpp:100] Creating Layer conv4_2
I0912 01:41:18.946349 25102 net.cpp:434] conv4_2 <- conv4_1
I0912 01:41:18.946358 25102 net.cpp:408] conv4_2 -> conv4_2
I0912 01:41:19.030747 25102 net.cpp:150] Setting up conv4_2
I0912 01:41:19.030781 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.030786 25102 net.cpp:165] Memory required for data: 2950041600
I0912 01:41:19.030792 25102 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 01:41:19.030804 25102 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 01:41:19.030808 25102 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 01:41:19.030814 25102 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 01:41:19.031092 25102 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 01:41:19.031101 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.031105 25102 net.cpp:165] Memory required for data: 2972160000
I0912 01:41:19.031116 25102 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 01:41:19.031124 25102 net.cpp:100] Creating Layer conv4_2_scale
I0912 01:41:19.031132 25102 net.cpp:434] conv4_2_scale <- conv4_2
I0912 01:41:19.031137 25102 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 01:41:19.031195 25102 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 01:41:19.031363 25102 net.cpp:150] Setting up conv4_2_scale
I0912 01:41:19.031371 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.031374 25102 net.cpp:165] Memory required for data: 2994278400
I0912 01:41:19.031381 25102 layer_factory.hpp:77] Creating layer relu4_2
I0912 01:41:19.031391 25102 net.cpp:100] Creating Layer relu4_2
I0912 01:41:19.031396 25102 net.cpp:434] relu4_2 <- conv4_2
I0912 01:41:19.031400 25102 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 01:41:19.032560 25102 net.cpp:150] Setting up relu4_2
I0912 01:41:19.032577 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.032583 25102 net.cpp:165] Memory required for data: 3016396800
I0912 01:41:19.032588 25102 layer_factory.hpp:77] Creating layer conv4_3
I0912 01:41:19.032601 25102 net.cpp:100] Creating Layer conv4_3
I0912 01:41:19.032608 25102 net.cpp:434] conv4_3 <- conv4_2
I0912 01:41:19.032614 25102 net.cpp:408] conv4_3 -> conv4_3
I0912 01:41:19.117671 25102 net.cpp:150] Setting up conv4_3
I0912 01:41:19.117687 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.117698 25102 net.cpp:165] Memory required for data: 3038515200
I0912 01:41:19.117728 25102 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 01:41:19.117741 25102 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 01:41:19.117748 25102 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 01:41:19.117756 25102 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 01:41:19.118034 25102 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 01:41:19.118043 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.118046 25102 net.cpp:165] Memory required for data: 3060633600
I0912 01:41:19.118055 25102 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 01:41:19.118063 25102 net.cpp:100] Creating Layer conv4_3_scale
I0912 01:41:19.118068 25102 net.cpp:434] conv4_3_scale <- conv4_3
I0912 01:41:19.118077 25102 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 01:41:19.118124 25102 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 01:41:19.118288 25102 net.cpp:150] Setting up conv4_3_scale
I0912 01:41:19.118299 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.118301 25102 net.cpp:165] Memory required for data: 3082752000
I0912 01:41:19.118309 25102 layer_factory.hpp:77] Creating layer relu4_3
I0912 01:41:19.118316 25102 net.cpp:100] Creating Layer relu4_3
I0912 01:41:19.118321 25102 net.cpp:434] relu4_3 <- conv4_3
I0912 01:41:19.118326 25102 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 01:41:19.118551 25102 net.cpp:150] Setting up relu4_3
I0912 01:41:19.118561 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.118566 25102 net.cpp:165] Memory required for data: 3104870400
I0912 01:41:19.118568 25102 layer_factory.hpp:77] Creating layer pool4
I0912 01:41:19.118572 25102 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 01:41:19.118578 25102 net.cpp:100] Creating Layer pool4
I0912 01:41:19.118583 25102 net.cpp:434] pool4 <- conv4_3
I0912 01:41:19.118607 25102 net.cpp:408] pool4 -> pool4
I0912 01:41:19.118616 25102 net.cpp:408] pool4 -> pool4_mask
I0912 01:41:19.118676 25102 net.cpp:150] Setting up pool4
I0912 01:41:19.118683 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.118688 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.118692 25102 net.cpp:165] Memory required for data: 3116175360
I0912 01:41:19.118697 25102 layer_factory.hpp:77] Creating layer conv5_1
I0912 01:41:19.118712 25102 net.cpp:100] Creating Layer conv5_1
I0912 01:41:19.118717 25102 net.cpp:434] conv5_1 <- pool4
I0912 01:41:19.118724 25102 net.cpp:408] conv5_1 -> conv5_1
I0912 01:41:19.203784 25102 net.cpp:150] Setting up conv5_1
I0912 01:41:19.203802 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.203806 25102 net.cpp:165] Memory required for data: 3121827840
I0912 01:41:19.203814 25102 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 01:41:19.203824 25102 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 01:41:19.203832 25102 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 01:41:19.203838 25102 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 01:41:19.204121 25102 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 01:41:19.204130 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.204133 25102 net.cpp:165] Memory required for data: 3127480320
I0912 01:41:19.204141 25102 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 01:41:19.204150 25102 net.cpp:100] Creating Layer conv5_1_scale
I0912 01:41:19.204159 25102 net.cpp:434] conv5_1_scale <- conv5_1
I0912 01:41:19.204165 25102 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 01:41:19.204224 25102 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 01:41:19.204376 25102 net.cpp:150] Setting up conv5_1_scale
I0912 01:41:19.204385 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.204387 25102 net.cpp:165] Memory required for data: 3133132800
I0912 01:41:19.204393 25102 layer_factory.hpp:77] Creating layer relu5_1
I0912 01:41:19.204404 25102 net.cpp:100] Creating Layer relu5_1
I0912 01:41:19.204409 25102 net.cpp:434] relu5_1 <- conv5_1
I0912 01:41:19.204414 25102 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 01:41:19.204638 25102 net.cpp:150] Setting up relu5_1
I0912 01:41:19.204648 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.204653 25102 net.cpp:165] Memory required for data: 3138785280
I0912 01:41:19.204658 25102 layer_factory.hpp:77] Creating layer conv5_2
I0912 01:41:19.204670 25102 net.cpp:100] Creating Layer conv5_2
I0912 01:41:19.204676 25102 net.cpp:434] conv5_2 <- conv5_1
I0912 01:41:19.204689 25102 net.cpp:408] conv5_2 -> conv5_2
I0912 01:41:19.289788 25102 net.cpp:150] Setting up conv5_2
I0912 01:41:19.289805 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.289809 25102 net.cpp:165] Memory required for data: 3144437760
I0912 01:41:19.289818 25102 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 01:41:19.289834 25102 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 01:41:19.289841 25102 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 01:41:19.289847 25102 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 01:41:19.290127 25102 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 01:41:19.290134 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.290138 25102 net.cpp:165] Memory required for data: 3150090240
I0912 01:41:19.290145 25102 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 01:41:19.290156 25102 net.cpp:100] Creating Layer conv5_2_scale
I0912 01:41:19.290165 25102 net.cpp:434] conv5_2_scale <- conv5_2
I0912 01:41:19.290171 25102 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 01:41:19.290228 25102 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 01:41:19.290381 25102 net.cpp:150] Setting up conv5_2_scale
I0912 01:41:19.290388 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.290391 25102 net.cpp:165] Memory required for data: 3155742720
I0912 01:41:19.290398 25102 layer_factory.hpp:77] Creating layer relu5_2
I0912 01:41:19.290424 25102 net.cpp:100] Creating Layer relu5_2
I0912 01:41:19.290429 25102 net.cpp:434] relu5_2 <- conv5_2
I0912 01:41:19.290434 25102 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 01:41:19.290664 25102 net.cpp:150] Setting up relu5_2
I0912 01:41:19.290678 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.290683 25102 net.cpp:165] Memory required for data: 3161395200
I0912 01:41:19.290688 25102 layer_factory.hpp:77] Creating layer conv5_3
I0912 01:41:19.290701 25102 net.cpp:100] Creating Layer conv5_3
I0912 01:41:19.290706 25102 net.cpp:434] conv5_3 <- conv5_2
I0912 01:41:19.290714 25102 net.cpp:408] conv5_3 -> conv5_3
I0912 01:41:19.375824 25102 net.cpp:150] Setting up conv5_3
I0912 01:41:19.375843 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.375846 25102 net.cpp:165] Memory required for data: 3167047680
I0912 01:41:19.375854 25102 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 01:41:19.375864 25102 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 01:41:19.375874 25102 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 01:41:19.375880 25102 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 01:41:19.376157 25102 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 01:41:19.376164 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.376168 25102 net.cpp:165] Memory required for data: 3172700160
I0912 01:41:19.376176 25102 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 01:41:19.376188 25102 net.cpp:100] Creating Layer conv5_3_scale
I0912 01:41:19.376196 25102 net.cpp:434] conv5_3_scale <- conv5_3
I0912 01:41:19.376207 25102 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 01:41:19.376262 25102 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 01:41:19.376420 25102 net.cpp:150] Setting up conv5_3_scale
I0912 01:41:19.376427 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.376430 25102 net.cpp:165] Memory required for data: 3178352640
I0912 01:41:19.376437 25102 layer_factory.hpp:77] Creating layer relu5_3
I0912 01:41:19.376444 25102 net.cpp:100] Creating Layer relu5_3
I0912 01:41:19.376449 25102 net.cpp:434] relu5_3 <- conv5_3
I0912 01:41:19.376454 25102 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 01:41:19.376682 25102 net.cpp:150] Setting up relu5_3
I0912 01:41:19.376691 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.376696 25102 net.cpp:165] Memory required for data: 3184005120
I0912 01:41:19.376699 25102 layer_factory.hpp:77] Creating layer pool5
I0912 01:41:19.376705 25102 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 01:41:19.376713 25102 net.cpp:100] Creating Layer pool5
I0912 01:41:19.376718 25102 net.cpp:434] pool5 <- conv5_3
I0912 01:41:19.376726 25102 net.cpp:408] pool5 -> pool5
I0912 01:41:19.376734 25102 net.cpp:408] pool5 -> pool5_mask
I0912 01:41:19.376796 25102 net.cpp:150] Setting up pool5
I0912 01:41:19.376803 25102 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 01:41:19.376807 25102 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 01:41:19.376811 25102 net.cpp:165] Memory required for data: 3186954240
I0912 01:41:19.376816 25102 layer_factory.hpp:77] Creating layer upsample5
I0912 01:41:19.376827 25102 net.cpp:100] Creating Layer upsample5
I0912 01:41:19.376832 25102 net.cpp:434] upsample5 <- pool5
I0912 01:41:19.376837 25102 net.cpp:434] upsample5 <- pool5_mask
I0912 01:41:19.376842 25102 net.cpp:408] upsample5 -> pool5_D
I0912 01:41:19.376878 25102 net.cpp:150] Setting up upsample5
I0912 01:41:19.376884 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.376888 25102 net.cpp:165] Memory required for data: 3192606720
I0912 01:41:19.376890 25102 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 01:41:19.376902 25102 net.cpp:100] Creating Layer conv5_3_D
I0912 01:41:19.376907 25102 net.cpp:434] conv5_3_D <- pool5_D
I0912 01:41:19.376916 25102 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 01:41:19.461891 25102 net.cpp:150] Setting up conv5_3_D
I0912 01:41:19.461908 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.461933 25102 net.cpp:165] Memory required for data: 3198259200
I0912 01:41:19.461942 25102 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 01:41:19.461953 25102 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 01:41:19.461959 25102 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 01:41:19.461966 25102 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 01:41:19.462250 25102 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 01:41:19.462260 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.462263 25102 net.cpp:165] Memory required for data: 3203911680
I0912 01:41:19.462273 25102 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 01:41:19.462282 25102 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 01:41:19.462291 25102 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 01:41:19.462296 25102 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 01:41:19.462363 25102 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 01:41:19.462519 25102 net.cpp:150] Setting up conv5_3_D_scale
I0912 01:41:19.462527 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.462530 25102 net.cpp:165] Memory required for data: 3209564160
I0912 01:41:19.462537 25102 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 01:41:19.462546 25102 net.cpp:100] Creating Layer relu5_3_D
I0912 01:41:19.462551 25102 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 01:41:19.462556 25102 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 01:41:19.463704 25102 net.cpp:150] Setting up relu5_3_D
I0912 01:41:19.463719 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.463726 25102 net.cpp:165] Memory required for data: 3215216640
I0912 01:41:19.463729 25102 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 01:41:19.463757 25102 net.cpp:100] Creating Layer conv5_2_D
I0912 01:41:19.463763 25102 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 01:41:19.463770 25102 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 01:41:19.548837 25102 net.cpp:150] Setting up conv5_2_D
I0912 01:41:19.548857 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.548866 25102 net.cpp:165] Memory required for data: 3220869120
I0912 01:41:19.548874 25102 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 01:41:19.548882 25102 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 01:41:19.548888 25102 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 01:41:19.548897 25102 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 01:41:19.549185 25102 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 01:41:19.549194 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.549197 25102 net.cpp:165] Memory required for data: 3226521600
I0912 01:41:19.549207 25102 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 01:41:19.549216 25102 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 01:41:19.549224 25102 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 01:41:19.549229 25102 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 01:41:19.549288 25102 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 01:41:19.549473 25102 net.cpp:150] Setting up conv5_2_D_scale
I0912 01:41:19.549481 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.549484 25102 net.cpp:165] Memory required for data: 3232174080
I0912 01:41:19.549491 25102 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 01:41:19.549500 25102 net.cpp:100] Creating Layer relu5_2_D
I0912 01:41:19.549505 25102 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 01:41:19.549512 25102 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 01:41:19.550674 25102 net.cpp:150] Setting up relu5_2_D
I0912 01:41:19.550689 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.550694 25102 net.cpp:165] Memory required for data: 3237826560
I0912 01:41:19.550698 25102 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 01:41:19.550717 25102 net.cpp:100] Creating Layer conv5_1_D
I0912 01:41:19.550724 25102 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 01:41:19.550732 25102 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 01:41:19.635891 25102 net.cpp:150] Setting up conv5_1_D
I0912 01:41:19.635908 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.635913 25102 net.cpp:165] Memory required for data: 3243479040
I0912 01:41:19.635921 25102 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 01:41:19.635937 25102 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 01:41:19.635944 25102 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 01:41:19.635951 25102 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 01:41:19.636234 25102 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 01:41:19.636242 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.636245 25102 net.cpp:165] Memory required for data: 3249131520
I0912 01:41:19.636257 25102 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 01:41:19.636265 25102 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 01:41:19.636274 25102 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 01:41:19.636279 25102 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 01:41:19.636337 25102 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 01:41:19.636502 25102 net.cpp:150] Setting up conv5_1_D_scale
I0912 01:41:19.636509 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.636512 25102 net.cpp:165] Memory required for data: 3254784000
I0912 01:41:19.636519 25102 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 01:41:19.636529 25102 net.cpp:100] Creating Layer relu5_1_D
I0912 01:41:19.636534 25102 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 01:41:19.636538 25102 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 01:41:19.636765 25102 net.cpp:150] Setting up relu5_1_D
I0912 01:41:19.636775 25102 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 01:41:19.636780 25102 net.cpp:165] Memory required for data: 3260436480
I0912 01:41:19.636783 25102 layer_factory.hpp:77] Creating layer upsample4
I0912 01:41:19.636793 25102 net.cpp:100] Creating Layer upsample4
I0912 01:41:19.636798 25102 net.cpp:434] upsample4 <- conv5_1_D
I0912 01:41:19.636803 25102 net.cpp:434] upsample4 <- pool4_mask
I0912 01:41:19.636812 25102 net.cpp:408] upsample4 -> pool4_D
I0912 01:41:19.636852 25102 net.cpp:150] Setting up upsample4
I0912 01:41:19.636858 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.636862 25102 net.cpp:165] Memory required for data: 3282554880
I0912 01:41:19.636865 25102 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 01:41:19.636879 25102 net.cpp:100] Creating Layer conv4_3_D
I0912 01:41:19.636884 25102 net.cpp:434] conv4_3_D <- pool4_D
I0912 01:41:19.636890 25102 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 01:41:19.722103 25102 net.cpp:150] Setting up conv4_3_D
I0912 01:41:19.722121 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.722126 25102 net.cpp:165] Memory required for data: 3304673280
I0912 01:41:19.722134 25102 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 01:41:19.722146 25102 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 01:41:19.722152 25102 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 01:41:19.722158 25102 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 01:41:19.722452 25102 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 01:41:19.722461 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.722465 25102 net.cpp:165] Memory required for data: 3326791680
I0912 01:41:19.722473 25102 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 01:41:19.722484 25102 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 01:41:19.722494 25102 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 01:41:19.722501 25102 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 01:41:19.722556 25102 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 01:41:19.722728 25102 net.cpp:150] Setting up conv4_3_D_scale
I0912 01:41:19.722739 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.722743 25102 net.cpp:165] Memory required for data: 3348910080
I0912 01:41:19.722750 25102 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 01:41:19.722774 25102 net.cpp:100] Creating Layer relu4_3_D
I0912 01:41:19.722779 25102 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 01:41:19.722784 25102 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 01:41:19.723011 25102 net.cpp:150] Setting up relu4_3_D
I0912 01:41:19.723023 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.723029 25102 net.cpp:165] Memory required for data: 3371028480
I0912 01:41:19.723032 25102 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 01:41:19.723045 25102 net.cpp:100] Creating Layer conv4_2_D
I0912 01:41:19.723050 25102 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 01:41:19.723057 25102 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 01:41:19.808876 25102 net.cpp:150] Setting up conv4_2_D
I0912 01:41:19.808898 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.808902 25102 net.cpp:165] Memory required for data: 3393146880
I0912 01:41:19.808918 25102 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 01:41:19.808931 25102 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 01:41:19.808943 25102 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 01:41:19.808954 25102 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 01:41:19.809250 25102 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 01:41:19.809259 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.809262 25102 net.cpp:165] Memory required for data: 3415265280
I0912 01:41:19.809272 25102 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 01:41:19.809283 25102 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 01:41:19.809288 25102 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 01:41:19.809294 25102 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 01:41:19.809345 25102 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 01:41:19.809543 25102 net.cpp:150] Setting up conv4_2_D_scale
I0912 01:41:19.809552 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.809556 25102 net.cpp:165] Memory required for data: 3437383680
I0912 01:41:19.809562 25102 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 01:41:19.809569 25102 net.cpp:100] Creating Layer relu4_2_D
I0912 01:41:19.809573 25102 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 01:41:19.809581 25102 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 01:41:19.809810 25102 net.cpp:150] Setting up relu4_2_D
I0912 01:41:19.809820 25102 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 01:41:19.809825 25102 net.cpp:165] Memory required for data: 3459502080
I0912 01:41:19.809829 25102 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 01:41:19.809841 25102 net.cpp:100] Creating Layer conv4_1_D
I0912 01:41:19.809847 25102 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 01:41:19.809857 25102 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 01:41:19.854555 25102 net.cpp:150] Setting up conv4_1_D
I0912 01:41:19.854573 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:19.854576 25102 net.cpp:165] Memory required for data: 3470561280
I0912 01:41:19.854586 25102 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 01:41:19.854604 25102 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 01:41:19.854611 25102 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 01:41:19.854616 25102 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 01:41:19.854913 25102 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 01:41:19.854923 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:19.854925 25102 net.cpp:165] Memory required for data: 3481620480
I0912 01:41:19.855015 25102 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 01:41:19.855026 25102 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 01:41:19.855032 25102 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 01:41:19.855037 25102 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 01:41:19.855098 25102 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 01:41:19.855275 25102 net.cpp:150] Setting up conv4_1_D_scale
I0912 01:41:19.855283 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:19.855304 25102 net.cpp:165] Memory required for data: 3492679680
I0912 01:41:19.855311 25102 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 01:41:19.855317 25102 net.cpp:100] Creating Layer relu4_1_D
I0912 01:41:19.855321 25102 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 01:41:19.855325 25102 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 01:41:19.855564 25102 net.cpp:150] Setting up relu4_1_D
I0912 01:41:19.855576 25102 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 01:41:19.855581 25102 net.cpp:165] Memory required for data: 3503738880
I0912 01:41:19.855583 25102 layer_factory.hpp:77] Creating layer upsample3
I0912 01:41:19.855593 25102 net.cpp:100] Creating Layer upsample3
I0912 01:41:19.855598 25102 net.cpp:434] upsample3 <- conv4_1_D
I0912 01:41:19.855607 25102 net.cpp:434] upsample3 <- pool3_mask
I0912 01:41:19.855614 25102 net.cpp:408] upsample3 -> pool3_D
I0912 01:41:19.855623 25102 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 01:41:19.855664 25102 net.cpp:150] Setting up upsample3
I0912 01:41:19.855670 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:19.855674 25102 net.cpp:165] Memory required for data: 3547975680
I0912 01:41:19.855679 25102 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 01:41:19.855691 25102 net.cpp:100] Creating Layer conv3_3_D
I0912 01:41:19.855696 25102 net.cpp:434] conv3_3_D <- pool3_D
I0912 01:41:19.855708 25102 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 01:41:19.879817 25102 net.cpp:150] Setting up conv3_3_D
I0912 01:41:19.879834 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:19.879843 25102 net.cpp:165] Memory required for data: 3592212480
I0912 01:41:19.879853 25102 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 01:41:19.879869 25102 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 01:41:19.879875 25102 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 01:41:19.879881 25102 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 01:41:19.880193 25102 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 01:41:19.880203 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:19.880205 25102 net.cpp:165] Memory required for data: 3636449280
I0912 01:41:19.880214 25102 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 01:41:19.880225 25102 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 01:41:19.880231 25102 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 01:41:19.880236 25102 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 01:41:19.880297 25102 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 01:41:19.880491 25102 net.cpp:150] Setting up conv3_3_D_scale
I0912 01:41:19.880499 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:19.880502 25102 net.cpp:165] Memory required for data: 3680686080
I0912 01:41:19.880508 25102 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 01:41:19.880517 25102 net.cpp:100] Creating Layer relu3_3_D
I0912 01:41:19.880522 25102 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 01:41:19.880528 25102 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 01:41:19.881718 25102 net.cpp:150] Setting up relu3_3_D
I0912 01:41:19.881733 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:19.881739 25102 net.cpp:165] Memory required for data: 3724922880
I0912 01:41:19.881745 25102 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 01:41:19.881760 25102 net.cpp:100] Creating Layer conv3_2_D
I0912 01:41:19.881767 25102 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 01:41:19.881775 25102 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 01:41:19.904929 25102 net.cpp:150] Setting up conv3_2_D
I0912 01:41:19.904945 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:19.904955 25102 net.cpp:165] Memory required for data: 3769159680
I0912 01:41:19.904963 25102 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 01:41:19.904973 25102 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 01:41:19.904979 25102 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 01:41:19.905001 25102 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 01:41:19.905318 25102 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 01:41:19.905326 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:19.905329 25102 net.cpp:165] Memory required for data: 3813396480
I0912 01:41:19.905339 25102 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 01:41:19.905349 25102 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 01:41:19.905354 25102 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 01:41:19.905361 25102 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 01:41:19.905434 25102 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 01:41:19.905629 25102 net.cpp:150] Setting up conv3_2_D_scale
I0912 01:41:19.905639 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:19.905644 25102 net.cpp:165] Memory required for data: 3857633280
I0912 01:41:19.905652 25102 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 01:41:19.905659 25102 net.cpp:100] Creating Layer relu3_2_D
I0912 01:41:19.905663 25102 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 01:41:19.905668 25102 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 01:41:19.906833 25102 net.cpp:150] Setting up relu3_2_D
I0912 01:41:19.906848 25102 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 01:41:19.906853 25102 net.cpp:165] Memory required for data: 3901870080
I0912 01:41:19.906858 25102 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 01:41:19.906875 25102 net.cpp:100] Creating Layer conv3_1_D
I0912 01:41:19.906880 25102 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 01:41:19.906889 25102 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 01:41:19.921151 25102 net.cpp:150] Setting up conv3_1_D
I0912 01:41:19.921167 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:19.921176 25102 net.cpp:165] Memory required for data: 3923988480
I0912 01:41:19.921188 25102 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 01:41:19.921200 25102 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 01:41:19.921208 25102 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 01:41:19.921216 25102 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 01:41:19.921550 25102 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 01:41:19.921561 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:19.921564 25102 net.cpp:165] Memory required for data: 3946106880
I0912 01:41:19.921572 25102 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 01:41:19.921586 25102 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 01:41:19.921591 25102 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 01:41:19.921597 25102 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 01:41:19.921655 25102 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 01:41:19.923406 25102 net.cpp:150] Setting up conv3_1_D_scale
I0912 01:41:19.923421 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:19.923429 25102 net.cpp:165] Memory required for data: 3968225280
I0912 01:41:19.923439 25102 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 01:41:19.923449 25102 net.cpp:100] Creating Layer relu3_1_D
I0912 01:41:19.923454 25102 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 01:41:19.923462 25102 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 01:41:19.923705 25102 net.cpp:150] Setting up relu3_1_D
I0912 01:41:19.923715 25102 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 01:41:19.923720 25102 net.cpp:165] Memory required for data: 3990343680
I0912 01:41:19.923725 25102 layer_factory.hpp:77] Creating layer upsample2
I0912 01:41:19.923735 25102 net.cpp:100] Creating Layer upsample2
I0912 01:41:19.923740 25102 net.cpp:434] upsample2 <- conv3_1_D
I0912 01:41:19.923745 25102 net.cpp:434] upsample2 <- pool2_mask
I0912 01:41:19.923755 25102 net.cpp:408] upsample2 -> pool2_D
I0912 01:41:19.923764 25102 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 01:41:19.923804 25102 net.cpp:150] Setting up upsample2
I0912 01:41:19.923825 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:19.923830 25102 net.cpp:165] Memory required for data: 4078817280
I0912 01:41:19.923833 25102 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 01:41:19.923851 25102 net.cpp:100] Creating Layer conv2_2_D
I0912 01:41:19.923857 25102 net.cpp:434] conv2_2_D <- pool2_D
I0912 01:41:19.923863 25102 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 01:41:19.931843 25102 net.cpp:150] Setting up conv2_2_D
I0912 01:41:19.931860 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:19.931870 25102 net.cpp:165] Memory required for data: 4167290880
I0912 01:41:19.931881 25102 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 01:41:19.931893 25102 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 01:41:19.931901 25102 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 01:41:19.931907 25102 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 01:41:19.932265 25102 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 01:41:19.932274 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:19.932277 25102 net.cpp:165] Memory required for data: 4255764480
I0912 01:41:19.932286 25102 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 01:41:19.932294 25102 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 01:41:19.932303 25102 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 01:41:19.932308 25102 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 01:41:19.932368 25102 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 01:41:19.932644 25102 net.cpp:150] Setting up conv2_2_D_scale
I0912 01:41:19.932652 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:19.932657 25102 net.cpp:165] Memory required for data: 4344238080
I0912 01:41:19.932663 25102 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 01:41:19.932675 25102 net.cpp:100] Creating Layer relu2_2_D
I0912 01:41:19.932680 25102 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 01:41:19.932685 25102 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 01:41:19.932927 25102 net.cpp:150] Setting up relu2_2_D
I0912 01:41:19.932937 25102 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 01:41:19.932942 25102 net.cpp:165] Memory required for data: 4432711680
I0912 01:41:19.932946 25102 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 01:41:19.932962 25102 net.cpp:100] Creating Layer conv2_1_D
I0912 01:41:19.932967 25102 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 01:41:19.932979 25102 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 01:41:19.938531 25102 net.cpp:150] Setting up conv2_1_D
I0912 01:41:19.938547 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:19.938556 25102 net.cpp:165] Memory required for data: 4476948480
I0912 01:41:19.938565 25102 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 01:41:19.938575 25102 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 01:41:19.938583 25102 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 01:41:19.938590 25102 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 01:41:19.938966 25102 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 01:41:19.938976 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:19.938980 25102 net.cpp:165] Memory required for data: 4521185280
I0912 01:41:19.938988 25102 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 01:41:19.939002 25102 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 01:41:19.939007 25102 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 01:41:19.939012 25102 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 01:41:19.939071 25102 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 01:41:19.939360 25102 net.cpp:150] Setting up conv2_1_D_scale
I0912 01:41:19.939368 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:19.939373 25102 net.cpp:165] Memory required for data: 4565422080
I0912 01:41:19.939379 25102 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 01:41:19.939389 25102 net.cpp:100] Creating Layer relu2_1_D
I0912 01:41:19.939394 25102 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 01:41:19.939415 25102 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 01:41:19.939657 25102 net.cpp:150] Setting up relu2_1_D
I0912 01:41:19.939668 25102 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 01:41:19.939673 25102 net.cpp:165] Memory required for data: 4609658880
I0912 01:41:19.939677 25102 layer_factory.hpp:77] Creating layer upsample1
I0912 01:41:19.939683 25102 net.cpp:100] Creating Layer upsample1
I0912 01:41:19.939688 25102 net.cpp:434] upsample1 <- conv2_1_D
I0912 01:41:19.939693 25102 net.cpp:434] upsample1 <- pool1_mask
I0912 01:41:19.939702 25102 net.cpp:408] upsample1 -> pool1_D
I0912 01:41:19.939710 25102 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 01:41:19.939748 25102 net.cpp:150] Setting up upsample1
I0912 01:41:19.939754 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:19.939759 25102 net.cpp:165] Memory required for data: 4786606080
I0912 01:41:19.939764 25102 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 01:41:19.939777 25102 net.cpp:100] Creating Layer conv1_2_D
I0912 01:41:19.939784 25102 net.cpp:434] conv1_2_D <- pool1_D
I0912 01:41:19.939790 25102 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 01:41:19.944844 25102 net.cpp:150] Setting up conv1_2_D
I0912 01:41:19.944860 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:19.944869 25102 net.cpp:165] Memory required for data: 4963553280
I0912 01:41:19.944877 25102 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 01:41:19.944895 25102 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 01:41:19.944900 25102 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 01:41:19.944906 25102 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 01:41:19.945351 25102 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 01:41:19.945360 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:19.945380 25102 net.cpp:165] Memory required for data: 5140500480
I0912 01:41:19.945391 25102 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 01:41:19.945402 25102 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 01:41:19.945406 25102 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 01:41:19.945415 25102 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 01:41:19.945477 25102 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 01:41:19.947541 25102 net.cpp:150] Setting up conv1_2_D_scale
I0912 01:41:19.947556 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:19.947561 25102 net.cpp:165] Memory required for data: 5317447680
I0912 01:41:19.947571 25102 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 01:41:19.947582 25102 net.cpp:100] Creating Layer relu1_2_D
I0912 01:41:19.947587 25102 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 01:41:19.947594 25102 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 01:41:19.947847 25102 net.cpp:150] Setting up relu1_2_D
I0912 01:41:19.947857 25102 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 01:41:19.947862 25102 net.cpp:165] Memory required for data: 5494394880
I0912 01:41:19.947866 25102 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 01:41:19.947878 25102 net.cpp:100] Creating Layer conv1_1_1_D
I0912 01:41:19.947885 25102 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 01:41:19.947893 25102 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 01:41:19.950152 25102 net.cpp:150] Setting up conv1_1_1_D
I0912 01:41:19.950168 25102 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 01:41:19.950173 25102 net.cpp:165] Memory required for data: 5499924480
I0912 01:41:19.950181 25102 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 01:41:19.950191 25102 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 01:41:19.950196 25102 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 01:41:19.950209 25102 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 01:41:19.950218 25102 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 01:41:19.950294 25102 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 01:41:19.950305 25102 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 01:41:19.950311 25102 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 01:41:19.950314 25102 net.cpp:165] Memory required for data: 5510983680
I0912 01:41:19.950320 25102 layer_factory.hpp:77] Creating layer loss
I0912 01:41:19.950330 25102 net.cpp:100] Creating Layer loss
I0912 01:41:19.950335 25102 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 01:41:19.950340 25102 net.cpp:434] loss <- label_data_1_split_0
I0912 01:41:19.950346 25102 net.cpp:408] loss -> loss
I0912 01:41:19.950356 25102 layer_factory.hpp:77] Creating layer loss
I0912 01:41:19.955220 25102 net.cpp:150] Setting up loss
I0912 01:41:19.955235 25102 net.cpp:157] Top shape: (1)
I0912 01:41:19.955238 25102 net.cpp:160]     with loss weight 1
I0912 01:41:19.955256 25102 net.cpp:165] Memory required for data: 5510983684
I0912 01:41:19.955260 25102 layer_factory.hpp:77] Creating layer accuracy
I0912 01:41:19.955267 25102 net.cpp:100] Creating Layer accuracy
I0912 01:41:19.955272 25102 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 01:41:19.955277 25102 net.cpp:434] accuracy <- label_data_1_split_1
I0912 01:41:19.955287 25102 net.cpp:408] accuracy -> accuracy
I0912 01:41:19.955294 25102 net.cpp:408] accuracy -> per_class_accuracy
I0912 01:41:19.955355 25102 net.cpp:150] Setting up accuracy
I0912 01:41:19.955363 25102 net.cpp:157] Top shape: (1)
I0912 01:41:19.955368 25102 net.cpp:157] Top shape: 2 (2)
I0912 01:41:19.955370 25102 net.cpp:165] Memory required for data: 5510983696
I0912 01:41:19.955374 25102 net.cpp:228] accuracy does not need backward computation.
I0912 01:41:19.955380 25102 net.cpp:226] loss needs backward computation.
I0912 01:41:19.955384 25102 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 01:41:19.955387 25102 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 01:41:19.955391 25102 net.cpp:226] relu1_2_D needs backward computation.
I0912 01:41:19.955394 25102 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 01:41:19.955397 25102 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 01:41:19.955401 25102 net.cpp:226] conv1_2_D needs backward computation.
I0912 01:41:19.955404 25102 net.cpp:226] upsample1 needs backward computation.
I0912 01:41:19.955409 25102 net.cpp:226] relu2_1_D needs backward computation.
I0912 01:41:19.955413 25102 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 01:41:19.955416 25102 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 01:41:19.955420 25102 net.cpp:226] conv2_1_D needs backward computation.
I0912 01:41:19.955423 25102 net.cpp:226] relu2_2_D needs backward computation.
I0912 01:41:19.955426 25102 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 01:41:19.955430 25102 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 01:41:19.955432 25102 net.cpp:226] conv2_2_D needs backward computation.
I0912 01:41:19.955436 25102 net.cpp:226] upsample2 needs backward computation.
I0912 01:41:19.955440 25102 net.cpp:226] relu3_1_D needs backward computation.
I0912 01:41:19.955443 25102 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 01:41:19.955446 25102 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 01:41:19.955449 25102 net.cpp:226] conv3_1_D needs backward computation.
I0912 01:41:19.955453 25102 net.cpp:226] relu3_2_D needs backward computation.
I0912 01:41:19.955456 25102 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 01:41:19.955459 25102 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 01:41:19.955462 25102 net.cpp:226] conv3_2_D needs backward computation.
I0912 01:41:19.955466 25102 net.cpp:226] relu3_3_D needs backward computation.
I0912 01:41:19.955469 25102 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 01:41:19.955472 25102 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 01:41:19.955490 25102 net.cpp:226] conv3_3_D needs backward computation.
I0912 01:41:19.955494 25102 net.cpp:226] upsample3 needs backward computation.
I0912 01:41:19.955498 25102 net.cpp:226] relu4_1_D needs backward computation.
I0912 01:41:19.955502 25102 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 01:41:19.955505 25102 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 01:41:19.955508 25102 net.cpp:226] conv4_1_D needs backward computation.
I0912 01:41:19.955512 25102 net.cpp:226] relu4_2_D needs backward computation.
I0912 01:41:19.955515 25102 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 01:41:19.955518 25102 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 01:41:19.955523 25102 net.cpp:226] conv4_2_D needs backward computation.
I0912 01:41:19.955526 25102 net.cpp:226] relu4_3_D needs backward computation.
I0912 01:41:19.955533 25102 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 01:41:19.955536 25102 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 01:41:19.955543 25102 net.cpp:226] conv4_3_D needs backward computation.
I0912 01:41:19.955549 25102 net.cpp:226] upsample4 needs backward computation.
I0912 01:41:19.955554 25102 net.cpp:226] relu5_1_D needs backward computation.
I0912 01:41:19.955559 25102 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 01:41:19.955561 25102 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 01:41:19.955566 25102 net.cpp:226] conv5_1_D needs backward computation.
I0912 01:41:19.955570 25102 net.cpp:226] relu5_2_D needs backward computation.
I0912 01:41:19.955574 25102 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 01:41:19.955579 25102 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 01:41:19.955584 25102 net.cpp:226] conv5_2_D needs backward computation.
I0912 01:41:19.955586 25102 net.cpp:226] relu5_3_D needs backward computation.
I0912 01:41:19.955590 25102 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 01:41:19.955595 25102 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 01:41:19.955600 25102 net.cpp:226] conv5_3_D needs backward computation.
I0912 01:41:19.955605 25102 net.cpp:226] upsample5 needs backward computation.
I0912 01:41:19.955612 25102 net.cpp:226] pool5 needs backward computation.
I0912 01:41:19.955617 25102 net.cpp:226] relu5_3 needs backward computation.
I0912 01:41:19.955622 25102 net.cpp:226] conv5_3_scale needs backward computation.
I0912 01:41:19.955626 25102 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 01:41:19.955631 25102 net.cpp:226] conv5_3 needs backward computation.
I0912 01:41:19.955636 25102 net.cpp:226] relu5_2 needs backward computation.
I0912 01:41:19.955642 25102 net.cpp:226] conv5_2_scale needs backward computation.
I0912 01:41:19.955646 25102 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 01:41:19.955651 25102 net.cpp:226] conv5_2 needs backward computation.
I0912 01:41:19.955657 25102 net.cpp:226] relu5_1 needs backward computation.
I0912 01:41:19.955660 25102 net.cpp:226] conv5_1_scale needs backward computation.
I0912 01:41:19.955664 25102 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 01:41:19.955669 25102 net.cpp:226] conv5_1 needs backward computation.
I0912 01:41:19.955675 25102 net.cpp:226] pool4 needs backward computation.
I0912 01:41:19.955680 25102 net.cpp:226] relu4_3 needs backward computation.
I0912 01:41:19.955687 25102 net.cpp:226] conv4_3_scale needs backward computation.
I0912 01:41:19.955690 25102 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 01:41:19.955693 25102 net.cpp:226] conv4_3 needs backward computation.
I0912 01:41:19.955698 25102 net.cpp:226] relu4_2 needs backward computation.
I0912 01:41:19.955703 25102 net.cpp:226] conv4_2_scale needs backward computation.
I0912 01:41:19.955706 25102 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 01:41:19.955710 25102 net.cpp:226] conv4_2 needs backward computation.
I0912 01:41:19.955716 25102 net.cpp:226] relu4_1 needs backward computation.
I0912 01:41:19.955729 25102 net.cpp:226] conv4_1_scale needs backward computation.
I0912 01:41:19.955732 25102 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 01:41:19.955735 25102 net.cpp:226] conv4_1 needs backward computation.
I0912 01:41:19.955739 25102 net.cpp:226] pool3 needs backward computation.
I0912 01:41:19.955744 25102 net.cpp:226] relu3_3 needs backward computation.
I0912 01:41:19.955749 25102 net.cpp:226] conv3_3_scale needs backward computation.
I0912 01:41:19.955754 25102 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 01:41:19.955759 25102 net.cpp:226] conv3_3 needs backward computation.
I0912 01:41:19.955762 25102 net.cpp:226] relu3_2 needs backward computation.
I0912 01:41:19.955765 25102 net.cpp:226] conv3_2_scale needs backward computation.
I0912 01:41:19.955770 25102 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 01:41:19.955775 25102 net.cpp:226] conv3_2 needs backward computation.
I0912 01:41:19.955780 25102 net.cpp:226] relu3_1 needs backward computation.
I0912 01:41:19.955783 25102 net.cpp:226] conv3_1_scale needs backward computation.
I0912 01:41:19.955786 25102 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 01:41:19.955791 25102 net.cpp:226] conv3_1 needs backward computation.
I0912 01:41:19.955796 25102 net.cpp:226] pool2 needs backward computation.
I0912 01:41:19.955801 25102 net.cpp:226] relu2_2 needs backward computation.
I0912 01:41:19.955806 25102 net.cpp:226] conv2_2_scale needs backward computation.
I0912 01:41:19.955811 25102 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 01:41:19.955816 25102 net.cpp:226] conv2_2 needs backward computation.
I0912 01:41:19.955821 25102 net.cpp:226] relu2_1 needs backward computation.
I0912 01:41:19.955826 25102 net.cpp:226] conv2_1_scale needs backward computation.
I0912 01:41:19.955828 25102 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 01:41:19.955833 25102 net.cpp:226] conv2_1 needs backward computation.
I0912 01:41:19.955838 25102 net.cpp:226] pool1 needs backward computation.
I0912 01:41:19.955845 25102 net.cpp:226] relu1_2 needs backward computation.
I0912 01:41:19.955848 25102 net.cpp:226] conv1_2_scale needs backward computation.
I0912 01:41:19.955852 25102 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 01:41:19.955857 25102 net.cpp:226] conv1_2 needs backward computation.
I0912 01:41:19.955862 25102 net.cpp:226] relu1_1 needs backward computation.
I0912 01:41:19.955866 25102 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 01:41:19.955870 25102 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 01:41:19.955874 25102 net.cpp:226] conv1_1_1 needs backward computation.
I0912 01:41:19.955879 25102 net.cpp:228] label_data_1_split does not need backward computation.
I0912 01:41:19.955888 25102 net.cpp:228] data does not need backward computation.
I0912 01:41:19.955893 25102 net.cpp:270] This network produces output accuracy
I0912 01:41:19.955895 25102 net.cpp:270] This network produces output loss
I0912 01:41:19.955899 25102 net.cpp:270] This network produces output per_class_accuracy
I0912 01:41:19.955971 25102 net.cpp:283] Network initialization done.
I0912 01:41:19.956383 25102 solver.cpp:60] Solver scaffolding done.
I0912 01:41:19.965981 25102 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0912 01:41:20.280591 25102 net.cpp:761] Ignoring source layer conv1_1
I0912 01:41:20.280616 25102 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 01:41:20.280674 25102 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 01:41:20.280683 25102 net.cpp:761] Ignoring source layer pool1_drop
I0912 01:41:20.280769 25102 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 01:41:20.280935 25102 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 01:41:20.280942 25102 net.cpp:761] Ignoring source layer pool2_drop
I0912 01:41:20.281246 25102 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 01:41:20.281862 25102 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 01:41:20.282447 25102 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 01:41:20.282480 25102 net.cpp:761] Ignoring source layer pool3_drop
I0912 01:41:20.283596 25102 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 01:41:20.285838 25102 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 01:41:20.288060 25102 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 01:41:20.288067 25102 net.cpp:761] Ignoring source layer pool4_drop
I0912 01:41:20.290292 25102 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 01:41:20.292515 25102 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 01:41:20.294742 25102 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 01:41:20.294752 25102 net.cpp:761] Ignoring source layer pool5_drop
I0912 01:41:20.294756 25102 net.cpp:761] Ignoring source layer upsample5_drop
I0912 01:41:20.296979 25102 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 01:41:20.299207 25102 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 01:41:20.301457 25102 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 01:41:20.301467 25102 net.cpp:761] Ignoring source layer upsample4_drop
I0912 01:41:20.303580 25102 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 01:41:20.305835 25102 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 01:41:20.307051 25102 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 01:41:20.307060 25102 net.cpp:761] Ignoring source layer upsample3_drop
I0912 01:41:20.307710 25102 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 01:41:20.308352 25102 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 01:41:20.308684 25102 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 01:41:20.308691 25102 net.cpp:761] Ignoring source layer upsample2_drop
I0912 01:41:20.308863 25102 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 01:41:20.308960 25102 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 01:41:20.308969 25102 net.cpp:761] Ignoring source layer upsample1_drop
I0912 01:41:20.309023 25102 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 01:41:20.309031 25102 net.cpp:761] Ignoring source layer conv1_1_D
I0912 01:41:20.309034 25102 net.cpp:761] Ignoring source layer prob
I0912 01:41:20.565984 25102 net.cpp:761] Ignoring source layer conv1_1
I0912 01:41:20.566006 25102 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 01:41:20.566061 25102 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 01:41:20.566067 25102 net.cpp:761] Ignoring source layer pool1_drop
I0912 01:41:20.566151 25102 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 01:41:20.566308 25102 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 01:41:20.566314 25102 net.cpp:761] Ignoring source layer pool2_drop
I0912 01:41:20.566617 25102 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 01:41:20.567272 25102 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 01:41:20.567930 25102 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 01:41:20.567937 25102 net.cpp:761] Ignoring source layer pool3_drop
I0912 01:41:20.569232 25102 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 01:41:20.571846 25102 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 01:41:20.574424 25102 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 01:41:20.574434 25102 net.cpp:761] Ignoring source layer pool4_drop
I0912 01:41:20.576992 25102 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 01:41:20.579555 25102 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 01:41:20.582160 25102 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 01:41:20.582170 25102 net.cpp:761] Ignoring source layer pool5_drop
I0912 01:41:20.582175 25102 net.cpp:761] Ignoring source layer upsample5_drop
I0912 01:41:20.584717 25102 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 01:41:20.587260 25102 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 01:41:20.589804 25102 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 01:41:20.589813 25102 net.cpp:761] Ignoring source layer upsample4_drop
I0912 01:41:20.592348 25102 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 01:41:20.594903 25102 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 01:41:20.596246 25102 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 01:41:20.596256 25102 net.cpp:761] Ignoring source layer upsample3_drop
I0912 01:41:20.596900 25102 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 01:41:20.599056 25102 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 01:41:20.599391 25102 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 01:41:20.599400 25102 net.cpp:761] Ignoring source layer upsample2_drop
I0912 01:41:20.599570 25102 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 01:41:20.599665 25102 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 01:41:20.599673 25102 net.cpp:761] Ignoring source layer upsample1_drop
I0912 01:41:20.599726 25102 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 01:41:20.599733 25102 net.cpp:761] Ignoring source layer conv1_1_D
I0912 01:41:20.599737 25102 net.cpp:761] Ignoring source layer prob
I0912 01:41:20.608150 25102 caffe.cpp:251] Starting Optimization
I0912 01:41:20.608168 25102 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0912 01:41:20.608173 25102 solver.cpp:280] Learning Rate Policy: step
I0912 01:41:21.580693 25102 solver.cpp:228] Iteration 0, loss = 1.06205
I0912 01:41:21.580731 25102 solver.cpp:244]     Train net output #0: accuracy = 0.29747
I0912 01:41:21.580746 25102 solver.cpp:244]     Train net output #1: loss = 1.06205 (* 1 = 1.06205 loss)
I0912 01:41:21.580752 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.198306
I0912 01:41:21.580757 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.958624
I0912 01:41:21.580780 25102 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0912 01:41:37.780462 25102 solver.cpp:228] Iteration 20, loss = 0.331427
I0912 01:41:37.780505 25102 solver.cpp:244]     Train net output #0: accuracy = 0.878621
I0912 01:41:37.780515 25102 solver.cpp:244]     Train net output #1: loss = 0.331427 (* 1 = 0.331427 loss)
I0912 01:41:37.780521 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.858052
I0912 01:41:37.780526 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.904415
I0912 01:41:37.780532 25102 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0912 01:41:54.409229 25102 solver.cpp:228] Iteration 40, loss = 0.295691
I0912 01:41:54.409363 25102 solver.cpp:244]     Train net output #0: accuracy = 0.891215
I0912 01:41:54.409385 25102 solver.cpp:244]     Train net output #1: loss = 0.295691 (* 1 = 0.295691 loss)
I0912 01:41:54.409391 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.841727
I0912 01:41:54.409396 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.948519
I0912 01:41:54.409404 25102 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0912 01:42:11.031385 25102 solver.cpp:228] Iteration 60, loss = 0.306472
I0912 01:42:11.031430 25102 solver.cpp:244]     Train net output #0: accuracy = 0.908422
I0912 01:42:11.031441 25102 solver.cpp:244]     Train net output #1: loss = 0.306472 (* 1 = 0.306472 loss)
I0912 01:42:11.031447 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.958489
I0912 01:42:11.031452 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.869153
I0912 01:42:11.031460 25102 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0912 01:42:27.633302 25102 solver.cpp:228] Iteration 80, loss = 0.250776
I0912 01:42:27.633435 25102 solver.cpp:244]     Train net output #0: accuracy = 0.888281
I0912 01:42:27.633447 25102 solver.cpp:244]     Train net output #1: loss = 0.250776 (* 1 = 0.250776 loss)
I0912 01:42:27.633453 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.854503
I0912 01:42:27.633457 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984554
I0912 01:42:27.633463 25102 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0912 01:42:44.243322 25102 solver.cpp:228] Iteration 100, loss = 0.258397
I0912 01:42:44.243363 25102 solver.cpp:244]     Train net output #0: accuracy = 0.870846
I0912 01:42:44.243374 25102 solver.cpp:244]     Train net output #1: loss = 0.258397 (* 1 = 0.258397 loss)
I0912 01:42:44.243383 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.84127
I0912 01:42:44.243388 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.940716
I0912 01:42:44.243396 25102 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0912 01:43:00.863772 25102 solver.cpp:228] Iteration 120, loss = 0.0881846
I0912 01:43:00.863929 25102 solver.cpp:244]     Train net output #0: accuracy = 0.977873
I0912 01:43:00.863945 25102 solver.cpp:244]     Train net output #1: loss = 0.0881845 (* 1 = 0.0881845 loss)
I0912 01:43:00.863956 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978974
I0912 01:43:00.863966 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976277
I0912 01:43:00.863975 25102 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0912 01:43:17.491883 25102 solver.cpp:228] Iteration 140, loss = 0.105133
I0912 01:43:17.491928 25102 solver.cpp:244]     Train net output #0: accuracy = 0.955647
I0912 01:43:17.491943 25102 solver.cpp:244]     Train net output #1: loss = 0.105133 (* 1 = 0.105133 loss)
I0912 01:43:17.491950 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.943896
I0912 01:43:17.491955 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.97981
I0912 01:43:17.491963 25102 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0912 01:43:34.111289 25102 solver.cpp:228] Iteration 160, loss = 0.0741909
I0912 01:43:34.111383 25102 solver.cpp:244]     Train net output #0: accuracy = 0.988249
I0912 01:43:34.111399 25102 solver.cpp:244]     Train net output #1: loss = 0.0741909 (* 1 = 0.0741909 loss)
I0912 01:43:34.111405 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991204
I0912 01:43:34.111410 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985187
I0912 01:43:34.111419 25102 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0912 01:43:50.716953 25102 solver.cpp:228] Iteration 180, loss = 0.121576
I0912 01:43:50.716992 25102 solver.cpp:244]     Train net output #0: accuracy = 0.949413
I0912 01:43:50.717003 25102 solver.cpp:244]     Train net output #1: loss = 0.121576 (* 1 = 0.121576 loss)
I0912 01:43:50.717010 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.941292
I0912 01:43:50.717015 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.96267
I0912 01:43:50.717021 25102 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0912 01:44:07.321806 25102 solver.cpp:228] Iteration 200, loss = 0.148585
I0912 01:44:07.321899 25102 solver.cpp:244]     Train net output #0: accuracy = 0.947133
I0912 01:44:07.321915 25102 solver.cpp:244]     Train net output #1: loss = 0.148585 (* 1 = 0.148585 loss)
I0912 01:44:07.321920 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.958436
I0912 01:44:07.321925 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.929129
I0912 01:44:07.321931 25102 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0912 01:44:23.952666 25102 solver.cpp:228] Iteration 220, loss = 0.12917
I0912 01:44:23.952706 25102 solver.cpp:244]     Train net output #0: accuracy = 0.937578
I0912 01:44:23.952718 25102 solver.cpp:244]     Train net output #1: loss = 0.12917 (* 1 = 0.12917 loss)
I0912 01:44:23.952723 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.913871
I0912 01:44:23.952728 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992777
I0912 01:44:23.952735 25102 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0912 01:44:40.573029 25102 solver.cpp:228] Iteration 240, loss = 0.0851367
I0912 01:44:40.573125 25102 solver.cpp:244]     Train net output #0: accuracy = 0.97442
I0912 01:44:40.573141 25102 solver.cpp:244]     Train net output #1: loss = 0.0851367 (* 1 = 0.0851367 loss)
I0912 01:44:40.573148 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.970944
I0912 01:44:40.573153 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978849
I0912 01:44:40.573159 25102 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0912 01:44:57.206380 25102 solver.cpp:228] Iteration 260, loss = 0.0819675
I0912 01:44:57.206420 25102 solver.cpp:244]     Train net output #0: accuracy = 0.973414
I0912 01:44:57.206432 25102 solver.cpp:244]     Train net output #1: loss = 0.0819674 (* 1 = 0.0819674 loss)
I0912 01:44:57.206439 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978504
I0912 01:44:57.206444 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.966982
I0912 01:44:57.206451 25102 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0912 01:45:13.838992 25102 solver.cpp:228] Iteration 280, loss = 0.0668175
I0912 01:45:13.839138 25102 solver.cpp:244]     Train net output #0: accuracy = 0.988669
I0912 01:45:13.839157 25102 solver.cpp:244]     Train net output #1: loss = 0.0668174 (* 1 = 0.0668174 loss)
I0912 01:45:13.839165 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987225
I0912 01:45:13.839169 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999063
I0912 01:45:13.839179 25102 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0912 01:45:30.459355 25102 solver.cpp:228] Iteration 300, loss = 0.0500317
I0912 01:45:30.459393 25102 solver.cpp:244]     Train net output #0: accuracy = 0.987549
I0912 01:45:30.459406 25102 solver.cpp:244]     Train net output #1: loss = 0.0500316 (* 1 = 0.0500316 loss)
I0912 01:45:30.459412 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985424
I0912 01:45:30.459417 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998042
I0912 01:45:30.459424 25102 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0912 01:45:47.088522 25102 solver.cpp:228] Iteration 320, loss = 0.0713908
I0912 01:45:47.088618 25102 solver.cpp:244]     Train net output #0: accuracy = 0.975994
I0912 01:45:47.088634 25102 solver.cpp:244]     Train net output #1: loss = 0.0713907 (* 1 = 0.0713907 loss)
I0912 01:45:47.088640 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.976988
I0912 01:45:47.088645 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.973442
I0912 01:45:47.088652 25102 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0912 01:46:03.717375 25102 solver.cpp:228] Iteration 340, loss = 0.0384591
I0912 01:46:03.717418 25102 solver.cpp:244]     Train net output #0: accuracy = 0.985571
I0912 01:46:03.717432 25102 solver.cpp:244]     Train net output #1: loss = 0.038459 (* 1 = 0.038459 loss)
I0912 01:46:03.717438 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983253
I0912 01:46:03.717443 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991641
I0912 01:46:03.717449 25102 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0912 01:46:20.339771 25102 solver.cpp:228] Iteration 360, loss = 0.032326
I0912 01:46:20.339864 25102 solver.cpp:244]     Train net output #0: accuracy = 0.985958
I0912 01:46:20.339876 25102 solver.cpp:244]     Train net output #1: loss = 0.032326 (* 1 = 0.032326 loss)
I0912 01:46:20.339882 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980023
I0912 01:46:20.339887 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998745
I0912 01:46:20.339895 25102 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0912 01:46:36.974329 25102 solver.cpp:228] Iteration 380, loss = 0.0142821
I0912 01:46:36.974371 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99662
I0912 01:46:36.974400 25102 solver.cpp:244]     Train net output #1: loss = 0.0142821 (* 1 = 0.0142821 loss)
I0912 01:46:36.974411 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996445
I0912 01:46:36.974416 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997002
I0912 01:46:36.974424 25102 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0912 01:46:53.610312 25102 solver.cpp:228] Iteration 400, loss = 0.0407956
I0912 01:46:53.610404 25102 solver.cpp:244]     Train net output #0: accuracy = 0.985702
I0912 01:46:53.610419 25102 solver.cpp:244]     Train net output #1: loss = 0.0407956 (* 1 = 0.0407956 loss)
I0912 01:46:53.610424 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981598
I0912 01:46:53.610430 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990351
I0912 01:46:53.610436 25102 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0912 01:47:10.223799 25102 solver.cpp:228] Iteration 420, loss = 0.0401113
I0912 01:47:10.223836 25102 solver.cpp:244]     Train net output #0: accuracy = 0.988124
I0912 01:47:10.223867 25102 solver.cpp:244]     Train net output #1: loss = 0.0401113 (* 1 = 0.0401113 loss)
I0912 01:47:10.223881 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982111
I0912 01:47:10.223888 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993181
I0912 01:47:10.223894 25102 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0912 01:47:26.823170 25102 solver.cpp:228] Iteration 440, loss = 0.073035
I0912 01:47:26.823323 25102 solver.cpp:244]     Train net output #0: accuracy = 0.985016
I0912 01:47:26.823354 25102 solver.cpp:244]     Train net output #1: loss = 0.073035 (* 1 = 0.073035 loss)
I0912 01:47:26.823362 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983618
I0912 01:47:26.823367 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986111
I0912 01:47:26.823374 25102 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0912 01:47:43.422343 25102 solver.cpp:228] Iteration 460, loss = 0.0329738
I0912 01:47:43.422384 25102 solver.cpp:244]     Train net output #0: accuracy = 0.989136
I0912 01:47:43.422394 25102 solver.cpp:244]     Train net output #1: loss = 0.0329738 (* 1 = 0.0329738 loss)
I0912 01:47:43.422400 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989556
I0912 01:47:43.422405 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988648
I0912 01:47:43.422411 25102 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0912 01:48:00.017326 25102 solver.cpp:228] Iteration 480, loss = 0.0457441
I0912 01:48:00.017433 25102 solver.cpp:244]     Train net output #0: accuracy = 0.977817
I0912 01:48:00.017462 25102 solver.cpp:244]     Train net output #1: loss = 0.0457441 (* 1 = 0.0457441 loss)
I0912 01:48:00.017472 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.958525
I0912 01:48:00.017477 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998798
I0912 01:48:00.017483 25102 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0912 01:48:16.619861 25102 solver.cpp:228] Iteration 500, loss = 0.05939
I0912 01:48:16.619902 25102 solver.cpp:244]     Train net output #0: accuracy = 0.983679
I0912 01:48:16.619930 25102 solver.cpp:244]     Train net output #1: loss = 0.05939 (* 1 = 0.05939 loss)
I0912 01:48:16.619938 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9916
I0912 01:48:16.619943 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.958414
I0912 01:48:16.619951 25102 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0912 01:48:33.230204 25102 solver.cpp:228] Iteration 520, loss = 0.0252658
I0912 01:48:33.230291 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993322
I0912 01:48:33.230324 25102 solver.cpp:244]     Train net output #1: loss = 0.0252659 (* 1 = 0.0252659 loss)
I0912 01:48:33.230332 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99502
I0912 01:48:33.230339 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988039
I0912 01:48:33.230345 25102 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0912 01:48:49.838333 25102 solver.cpp:228] Iteration 540, loss = 0.0215481
I0912 01:48:49.838376 25102 solver.cpp:244]     Train net output #0: accuracy = 0.992351
I0912 01:48:49.838388 25102 solver.cpp:244]     Train net output #1: loss = 0.0215482 (* 1 = 0.0215482 loss)
I0912 01:48:49.838394 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988876
I0912 01:48:49.838399 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997372
I0912 01:48:49.838407 25102 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0912 01:49:06.421002 25102 solver.cpp:228] Iteration 560, loss = 0.057301
I0912 01:49:06.421147 25102 solver.cpp:244]     Train net output #0: accuracy = 0.974954
I0912 01:49:06.421178 25102 solver.cpp:244]     Train net output #1: loss = 0.0573011 (* 1 = 0.0573011 loss)
I0912 01:49:06.421186 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.961592
I0912 01:49:06.421192 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995299
I0912 01:49:06.421200 25102 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0912 01:49:23.034518 25102 solver.cpp:228] Iteration 580, loss = 0.018818
I0912 01:49:23.034561 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994048
I0912 01:49:23.034591 25102 solver.cpp:244]     Train net output #1: loss = 0.0188181 (* 1 = 0.0188181 loss)
I0912 01:49:23.034600 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993243
I0912 01:49:23.034605 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997442
I0912 01:49:23.034611 25102 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0912 01:49:39.646984 25102 solver.cpp:228] Iteration 600, loss = 0.0278354
I0912 01:49:39.647078 25102 solver.cpp:244]     Train net output #0: accuracy = 0.987763
I0912 01:49:39.647091 25102 solver.cpp:244]     Train net output #1: loss = 0.0278355 (* 1 = 0.0278355 loss)
I0912 01:49:39.647097 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983284
I0912 01:49:39.647101 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997015
I0912 01:49:39.647109 25102 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0912 01:49:56.258266 25102 solver.cpp:228] Iteration 620, loss = 0.0360429
I0912 01:49:56.258308 25102 solver.cpp:244]     Train net output #0: accuracy = 0.982202
I0912 01:49:56.258337 25102 solver.cpp:244]     Train net output #1: loss = 0.0360429 (* 1 = 0.0360429 loss)
I0912 01:49:56.258347 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.966913
I0912 01:49:56.258350 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999767
I0912 01:49:56.258358 25102 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0912 01:50:12.846125 25102 solver.cpp:228] Iteration 640, loss = 0.0564617
I0912 01:50:12.846218 25102 solver.cpp:244]     Train net output #0: accuracy = 0.980738
I0912 01:50:12.846231 25102 solver.cpp:244]     Train net output #1: loss = 0.0564617 (* 1 = 0.0564617 loss)
I0912 01:50:12.846237 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.971857
I0912 01:50:12.846242 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989784
I0912 01:50:12.846249 25102 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0912 01:50:29.449487 25102 solver.cpp:228] Iteration 660, loss = 0.0415143
I0912 01:50:29.449529 25102 solver.cpp:244]     Train net output #0: accuracy = 0.987468
I0912 01:50:29.449542 25102 solver.cpp:244]     Train net output #1: loss = 0.0415143 (* 1 = 0.0415143 loss)
I0912 01:50:29.449548 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99162
I0912 01:50:29.449553 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982352
I0912 01:50:29.449559 25102 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0912 01:50:46.042949 25102 solver.cpp:228] Iteration 680, loss = 0.0227971
I0912 01:50:46.043042 25102 solver.cpp:244]     Train net output #0: accuracy = 0.990674
I0912 01:50:46.043058 25102 solver.cpp:244]     Train net output #1: loss = 0.0227971 (* 1 = 0.0227971 loss)
I0912 01:50:46.043063 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983365
I0912 01:50:46.043068 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997706
I0912 01:50:46.043076 25102 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0912 01:51:02.634728 25102 solver.cpp:228] Iteration 700, loss = 0.00982387
I0912 01:51:02.634768 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997529
I0912 01:51:02.634779 25102 solver.cpp:244]     Train net output #1: loss = 0.00982392 (* 1 = 0.00982392 loss)
I0912 01:51:02.634784 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997729
I0912 01:51:02.634789 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996875
I0912 01:51:02.634796 25102 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0912 01:51:19.242871 25102 solver.cpp:228] Iteration 720, loss = 0.0292243
I0912 01:51:19.243022 25102 solver.cpp:244]     Train net output #0: accuracy = 0.988181
I0912 01:51:19.243053 25102 solver.cpp:244]     Train net output #1: loss = 0.0292243 (* 1 = 0.0292243 loss)
I0912 01:51:19.243062 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989028
I0912 01:51:19.243067 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986081
I0912 01:51:19.243073 25102 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0912 01:51:35.856681 25102 solver.cpp:228] Iteration 740, loss = 0.0494702
I0912 01:51:35.856722 25102 solver.cpp:244]     Train net output #0: accuracy = 0.978073
I0912 01:51:35.856750 25102 solver.cpp:244]     Train net output #1: loss = 0.0494702 (* 1 = 0.0494702 loss)
I0912 01:51:35.856758 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.963216
I0912 01:51:35.856763 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99968
I0912 01:51:35.856771 25102 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0912 01:51:52.475023 25102 solver.cpp:228] Iteration 760, loss = 0.125091
I0912 01:51:52.475113 25102 solver.cpp:244]     Train net output #0: accuracy = 0.943594
I0912 01:51:52.475131 25102 solver.cpp:244]     Train net output #1: loss = 0.125091 (* 1 = 0.125091 loss)
I0912 01:51:52.475136 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.914103
I0912 01:51:52.475141 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998939
I0912 01:51:52.475147 25102 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0912 01:52:09.084031 25102 solver.cpp:228] Iteration 780, loss = 0.151593
I0912 01:52:09.084072 25102 solver.cpp:244]     Train net output #0: accuracy = 0.96424
I0912 01:52:09.084100 25102 solver.cpp:244]     Train net output #1: loss = 0.151593 (* 1 = 0.151593 loss)
I0912 01:52:09.084108 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978481
I0912 01:52:09.084113 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.956805
I0912 01:52:09.084121 25102 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0912 01:52:25.699187 25102 solver.cpp:228] Iteration 800, loss = 0.0455271
I0912 01:52:25.699285 25102 solver.cpp:244]     Train net output #0: accuracy = 0.977894
I0912 01:52:25.699298 25102 solver.cpp:244]     Train net output #1: loss = 0.0455272 (* 1 = 0.0455272 loss)
I0912 01:52:25.699304 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.965032
I0912 01:52:25.699309 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99945
I0912 01:52:25.699316 25102 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0912 01:52:42.310292 25102 solver.cpp:228] Iteration 820, loss = 0.0185563
I0912 01:52:42.310333 25102 solver.cpp:244]     Train net output #0: accuracy = 0.992533
I0912 01:52:42.310344 25102 solver.cpp:244]     Train net output #1: loss = 0.0185564 (* 1 = 0.0185564 loss)
I0912 01:52:42.310350 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991308
I0912 01:52:42.310354 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995177
I0912 01:52:42.310361 25102 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0912 01:52:58.933744 25102 solver.cpp:228] Iteration 840, loss = 0.0160679
I0912 01:52:58.933835 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996458
I0912 01:52:58.933851 25102 solver.cpp:244]     Train net output #1: loss = 0.0160679 (* 1 = 0.0160679 loss)
I0912 01:52:58.933856 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996253
I0912 01:52:58.933861 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996637
I0912 01:52:58.933868 25102 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0912 01:53:15.545074 25102 solver.cpp:228] Iteration 860, loss = 0.0256846
I0912 01:53:15.545117 25102 solver.cpp:244]     Train net output #0: accuracy = 0.992293
I0912 01:53:15.545146 25102 solver.cpp:244]     Train net output #1: loss = 0.0256847 (* 1 = 0.0256847 loss)
I0912 01:53:15.545156 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996044
I0912 01:53:15.545161 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980702
I0912 01:53:15.545167 25102 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0912 01:53:32.142230 25102 solver.cpp:228] Iteration 880, loss = 0.019734
I0912 01:53:32.142374 25102 solver.cpp:244]     Train net output #0: accuracy = 0.992153
I0912 01:53:32.142392 25102 solver.cpp:244]     Train net output #1: loss = 0.019734 (* 1 = 0.019734 loss)
I0912 01:53:32.142400 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990817
I0912 01:53:32.142405 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995279
I0912 01:53:32.142411 25102 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0912 01:53:48.745205 25102 solver.cpp:228] Iteration 900, loss = 0.0225698
I0912 01:53:48.745245 25102 solver.cpp:244]     Train net output #0: accuracy = 0.990802
I0912 01:53:48.745275 25102 solver.cpp:244]     Train net output #1: loss = 0.0225699 (* 1 = 0.0225699 loss)
I0912 01:53:48.745283 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986832
I0912 01:53:48.745288 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996089
I0912 01:53:48.745296 25102 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0912 01:54:05.358674 25102 solver.cpp:228] Iteration 920, loss = 0.0305427
I0912 01:54:05.358773 25102 solver.cpp:244]     Train net output #0: accuracy = 0.986639
I0912 01:54:05.358788 25102 solver.cpp:244]     Train net output #1: loss = 0.0305427 (* 1 = 0.0305427 loss)
I0912 01:54:05.358794 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985485
I0912 01:54:05.358799 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99125
I0912 01:54:05.358806 25102 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0912 01:54:22.132721 25102 solver.cpp:228] Iteration 940, loss = 0.0218764
I0912 01:54:22.132761 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993262
I0912 01:54:22.132773 25102 solver.cpp:244]     Train net output #1: loss = 0.0218765 (* 1 = 0.0218765 loss)
I0912 01:54:22.132781 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994805
I0912 01:54:22.132786 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98605
I0912 01:54:22.132792 25102 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0912 01:54:38.740828 25102 solver.cpp:228] Iteration 960, loss = 0.0499271
I0912 01:54:38.740921 25102 solver.cpp:244]     Train net output #0: accuracy = 0.986725
I0912 01:54:38.740936 25102 solver.cpp:244]     Train net output #1: loss = 0.0499271 (* 1 = 0.0499271 loss)
I0912 01:54:38.740941 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987247
I0912 01:54:38.740947 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986336
I0912 01:54:38.740953 25102 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0912 01:54:55.341598 25102 solver.cpp:228] Iteration 980, loss = 0.0975591
I0912 01:54:55.341637 25102 solver.cpp:244]     Train net output #0: accuracy = 0.968623
I0912 01:54:55.341665 25102 solver.cpp:244]     Train net output #1: loss = 0.0975591 (* 1 = 0.0975591 loss)
I0912 01:54:55.341673 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.968106
I0912 01:54:55.341678 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.971223
I0912 01:54:55.341686 25102 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0912 01:55:11.953073 25102 solver.cpp:228] Iteration 1000, loss = 0.0316487
I0912 01:55:11.953176 25102 solver.cpp:244]     Train net output #0: accuracy = 0.988834
I0912 01:55:11.953207 25102 solver.cpp:244]     Train net output #1: loss = 0.0316486 (* 1 = 0.0316486 loss)
I0912 01:55:11.953215 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985047
I0912 01:55:11.953220 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993356
I0912 01:55:11.953227 25102 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0912 01:55:28.573570 25102 solver.cpp:228] Iteration 1020, loss = 0.0224035
I0912 01:55:28.573611 25102 solver.cpp:244]     Train net output #0: accuracy = 0.991813
I0912 01:55:28.573624 25102 solver.cpp:244]     Train net output #1: loss = 0.0224035 (* 1 = 0.0224035 loss)
I0912 01:55:28.573629 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987538
I0912 01:55:28.573634 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998089
I0912 01:55:28.573642 25102 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0912 01:55:45.247848 25102 solver.cpp:228] Iteration 1040, loss = 0.0400731
I0912 01:55:45.248018 25102 solver.cpp:244]     Train net output #0: accuracy = 0.986576
I0912 01:55:45.248034 25102 solver.cpp:244]     Train net output #1: loss = 0.040073 (* 1 = 0.040073 loss)
I0912 01:55:45.248039 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97416
I0912 01:55:45.248044 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995244
I0912 01:55:45.248050 25102 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0912 01:56:01.846710 25102 solver.cpp:228] Iteration 1060, loss = 0.0427452
I0912 01:56:01.846753 25102 solver.cpp:244]     Train net output #0: accuracy = 0.980966
I0912 01:56:01.846767 25102 solver.cpp:244]     Train net output #1: loss = 0.0427451 (* 1 = 0.0427451 loss)
I0912 01:56:01.846789 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.968503
I0912 01:56:01.846796 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996373
I0912 01:56:01.846803 25102 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0912 01:56:18.460628 25102 solver.cpp:228] Iteration 1080, loss = 0.0413685
I0912 01:56:18.460749 25102 solver.cpp:244]     Train net output #0: accuracy = 0.983207
I0912 01:56:18.460762 25102 solver.cpp:244]     Train net output #1: loss = 0.0413685 (* 1 = 0.0413685 loss)
I0912 01:56:18.460768 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973355
I0912 01:56:18.460773 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99409
I0912 01:56:18.460779 25102 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0912 01:56:35.047544 25102 solver.cpp:228] Iteration 1100, loss = 0.022709
I0912 01:56:35.047586 25102 solver.cpp:244]     Train net output #0: accuracy = 0.989729
I0912 01:56:35.047600 25102 solver.cpp:244]     Train net output #1: loss = 0.0227089 (* 1 = 0.0227089 loss)
I0912 01:56:35.047624 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984465
I0912 01:56:35.047632 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997287
I0912 01:56:35.047641 25102 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0912 01:56:51.634857 25102 solver.cpp:228] Iteration 1120, loss = 0.0147734
I0912 01:56:51.635036 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994463
I0912 01:56:51.635072 25102 solver.cpp:244]     Train net output #1: loss = 0.0147734 (* 1 = 0.0147734 loss)
I0912 01:56:51.635080 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994137
I0912 01:56:51.635085 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995097
I0912 01:56:51.635094 25102 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0912 01:57:08.365281 25102 solver.cpp:228] Iteration 1140, loss = 0.00762995
I0912 01:57:08.365326 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99703
I0912 01:57:08.365340 25102 solver.cpp:244]     Train net output #1: loss = 0.0076299 (* 1 = 0.0076299 loss)
I0912 01:57:08.365346 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996282
I0912 01:57:08.365351 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998557
I0912 01:57:08.365360 25102 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0912 01:57:25.063930 25102 solver.cpp:228] Iteration 1160, loss = 0.015419
I0912 01:57:25.064070 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994407
I0912 01:57:25.064100 25102 solver.cpp:244]     Train net output #1: loss = 0.015419 (* 1 = 0.015419 loss)
I0912 01:57:25.064108 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993214
I0912 01:57:25.064113 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995833
I0912 01:57:25.064122 25102 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0912 01:57:41.760573 25102 solver.cpp:228] Iteration 1180, loss = 0.0100169
I0912 01:57:41.760622 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996619
I0912 01:57:41.760633 25102 solver.cpp:244]     Train net output #1: loss = 0.0100168 (* 1 = 0.0100168 loss)
I0912 01:57:41.760639 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996041
I0912 01:57:41.760644 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997283
I0912 01:57:41.760653 25102 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0912 01:57:58.463898 25102 solver.cpp:228] Iteration 1200, loss = 0.0182672
I0912 01:57:58.464036 25102 solver.cpp:244]     Train net output #0: accuracy = 0.992867
I0912 01:57:58.464061 25102 solver.cpp:244]     Train net output #1: loss = 0.0182672 (* 1 = 0.0182672 loss)
I0912 01:57:58.464077 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991602
I0912 01:57:58.464084 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994652
I0912 01:57:58.464092 25102 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0912 01:58:15.091821 25102 solver.cpp:228] Iteration 1220, loss = 0.017099
I0912 01:58:15.091863 25102 solver.cpp:244]     Train net output #0: accuracy = 0.992235
I0912 01:58:15.091876 25102 solver.cpp:244]     Train net output #1: loss = 0.0170989 (* 1 = 0.0170989 loss)
I0912 01:58:15.091882 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989393
I0912 01:58:15.091887 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997155
I0912 01:58:15.091895 25102 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0912 01:58:31.708580 25102 solver.cpp:228] Iteration 1240, loss = 0.0168908
I0912 01:58:31.708694 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993304
I0912 01:58:31.708710 25102 solver.cpp:244]     Train net output #1: loss = 0.0168908 (* 1 = 0.0168908 loss)
I0912 01:58:31.708717 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992848
I0912 01:58:31.708722 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995033
I0912 01:58:31.708729 25102 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0912 01:58:48.323479 25102 solver.cpp:228] Iteration 1260, loss = 0.0132625
I0912 01:58:48.323519 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995582
I0912 01:58:48.323531 25102 solver.cpp:244]     Train net output #1: loss = 0.0132625 (* 1 = 0.0132625 loss)
I0912 01:58:48.323537 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995559
I0912 01:58:48.323541 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995614
I0912 01:58:48.323549 25102 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0912 01:59:04.960573 25102 solver.cpp:228] Iteration 1280, loss = 0.0169267
I0912 01:59:04.960688 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993728
I0912 01:59:04.960713 25102 solver.cpp:244]     Train net output #1: loss = 0.0169266 (* 1 = 0.0169266 loss)
I0912 01:59:04.960721 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992592
I0912 01:59:04.960726 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995134
I0912 01:59:04.960733 25102 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0912 01:59:21.554318 25102 solver.cpp:228] Iteration 1300, loss = 0.0200874
I0912 01:59:21.554363 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994427
I0912 01:59:21.554378 25102 solver.cpp:244]     Train net output #1: loss = 0.0200873 (* 1 = 0.0200873 loss)
I0912 01:59:21.554384 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994044
I0912 01:59:21.554390 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994757
I0912 01:59:21.554399 25102 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0912 01:59:38.146169 25102 solver.cpp:228] Iteration 1320, loss = 0.0106781
I0912 01:59:38.146334 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996589
I0912 01:59:38.146349 25102 solver.cpp:244]     Train net output #1: loss = 0.0106781 (* 1 = 0.0106781 loss)
I0912 01:59:38.146355 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997945
I0912 01:59:38.146360 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993439
I0912 01:59:38.146368 25102 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0912 01:59:54.752656 25102 solver.cpp:228] Iteration 1340, loss = 0.0183683
I0912 01:59:54.752697 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99296
I0912 01:59:54.752712 25102 solver.cpp:244]     Train net output #1: loss = 0.0183683 (* 1 = 0.0183683 loss)
I0912 01:59:54.752717 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993167
I0912 01:59:54.752722 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992604
I0912 01:59:54.752728 25102 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0912 02:00:11.365942 25102 solver.cpp:228] Iteration 1360, loss = 0.0129014
I0912 02:00:11.366068 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994446
I0912 02:00:11.366081 25102 solver.cpp:244]     Train net output #1: loss = 0.0129014 (* 1 = 0.0129014 loss)
I0912 02:00:11.366087 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991699
I0912 02:00:11.366101 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997693
I0912 02:00:11.366108 25102 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0912 02:00:27.972929 25102 solver.cpp:228] Iteration 1380, loss = 0.00610959
I0912 02:00:27.972970 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997857
I0912 02:00:27.972985 25102 solver.cpp:244]     Train net output #1: loss = 0.00610953 (* 1 = 0.00610953 loss)
I0912 02:00:27.972990 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997704
I0912 02:00:27.972995 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998382
I0912 02:00:27.973002 25102 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0912 02:00:44.567916 25102 solver.cpp:228] Iteration 1400, loss = 0.0191914
I0912 02:00:44.568004 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993874
I0912 02:00:44.568017 25102 solver.cpp:244]     Train net output #1: loss = 0.0191913 (* 1 = 0.0191913 loss)
I0912 02:00:44.568022 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990111
I0912 02:00:44.568027 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99668
I0912 02:00:44.568034 25102 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0912 02:01:01.187750 25102 solver.cpp:228] Iteration 1420, loss = 0.0137779
I0912 02:01:01.187791 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993443
I0912 02:01:01.187819 25102 solver.cpp:244]     Train net output #1: loss = 0.0137778 (* 1 = 0.0137778 loss)
I0912 02:01:01.187830 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990249
I0912 02:01:01.187835 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99813
I0912 02:01:01.187842 25102 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0912 02:01:17.797127 25102 solver.cpp:228] Iteration 1440, loss = 0.00952676
I0912 02:01:17.797214 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99753
I0912 02:01:17.797228 25102 solver.cpp:244]     Train net output #1: loss = 0.0095267 (* 1 = 0.0095267 loss)
I0912 02:01:17.797235 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996974
I0912 02:01:17.797240 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997979
I0912 02:01:17.797246 25102 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0912 02:01:34.403156 25102 solver.cpp:228] Iteration 1460, loss = 0.0135502
I0912 02:01:34.403192 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994563
I0912 02:01:34.403221 25102 solver.cpp:244]     Train net output #1: loss = 0.0135501 (* 1 = 0.0135501 loss)
I0912 02:01:34.403231 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994403
I0912 02:01:34.403236 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995192
I0912 02:01:34.403244 25102 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0912 02:01:51.025521 25102 solver.cpp:228] Iteration 1480, loss = 0.00943961
I0912 02:01:51.025677 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996606
I0912 02:01:51.025707 25102 solver.cpp:244]     Train net output #1: loss = 0.00943956 (* 1 = 0.00943956 loss)
I0912 02:01:51.025715 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996128
I0912 02:01:51.025720 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997175
I0912 02:01:51.025727 25102 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0912 02:02:07.617012 25102 solver.cpp:228] Iteration 1500, loss = 0.00823279
I0912 02:02:07.617053 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997352
I0912 02:02:07.617080 25102 solver.cpp:244]     Train net output #1: loss = 0.00823274 (* 1 = 0.00823274 loss)
I0912 02:02:07.617092 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997694
I0912 02:02:07.617097 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996921
I0912 02:02:07.617105 25102 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0912 02:02:24.237649 25102 solver.cpp:228] Iteration 1520, loss = 0.00716078
I0912 02:02:24.237749 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997853
I0912 02:02:24.237764 25102 solver.cpp:244]     Train net output #1: loss = 0.00716072 (* 1 = 0.00716072 loss)
I0912 02:02:24.237771 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99827
I0912 02:02:24.237776 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996449
I0912 02:02:24.237782 25102 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0912 02:02:40.861017 25102 solver.cpp:228] Iteration 1540, loss = 0.013941
I0912 02:02:40.861057 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995315
I0912 02:02:40.861070 25102 solver.cpp:244]     Train net output #1: loss = 0.0139409 (* 1 = 0.0139409 loss)
I0912 02:02:40.861076 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996982
I0912 02:02:40.861080 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990726
I0912 02:02:40.861088 25102 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0912 02:02:57.473996 25102 solver.cpp:228] Iteration 1560, loss = 0.0127631
I0912 02:02:57.474082 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995313
I0912 02:02:57.474097 25102 solver.cpp:244]     Train net output #1: loss = 0.012763 (* 1 = 0.012763 loss)
I0912 02:02:57.474104 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995168
I0912 02:02:57.474109 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995501
I0912 02:02:57.474117 25102 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0912 02:03:14.082322 25102 solver.cpp:228] Iteration 1580, loss = 0.00600108
I0912 02:03:14.082360 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997956
I0912 02:03:14.082373 25102 solver.cpp:244]     Train net output #1: loss = 0.00600102 (* 1 = 0.00600102 loss)
I0912 02:03:14.082379 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997679
I0912 02:03:14.082384 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998869
I0912 02:03:14.082391 25102 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0912 02:03:30.676198 25102 solver.cpp:228] Iteration 1600, loss = 0.00823331
I0912 02:03:30.676363 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996214
I0912 02:03:30.676404 25102 solver.cpp:244]     Train net output #1: loss = 0.00823326 (* 1 = 0.00823326 loss)
I0912 02:03:30.676412 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995104
I0912 02:03:30.676419 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998375
I0912 02:03:30.676427 25102 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0912 02:03:47.359158 25102 solver.cpp:228] Iteration 1620, loss = 0.0132422
I0912 02:03:47.359208 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994748
I0912 02:03:47.359238 25102 solver.cpp:244]     Train net output #1: loss = 0.0132421 (* 1 = 0.0132421 loss)
I0912 02:03:47.359247 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993949
I0912 02:03:47.359252 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995807
I0912 02:03:47.359266 25102 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0912 02:04:04.044244 25102 solver.cpp:228] Iteration 1640, loss = 0.0169901
I0912 02:04:04.044364 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993219
I0912 02:04:04.044380 25102 solver.cpp:244]     Train net output #1: loss = 0.0169901 (* 1 = 0.0169901 loss)
I0912 02:04:04.044386 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993581
I0912 02:04:04.044392 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991912
I0912 02:04:04.044405 25102 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0912 02:04:20.704953 25102 solver.cpp:228] Iteration 1660, loss = 0.00582674
I0912 02:04:20.704998 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997924
I0912 02:04:20.705029 25102 solver.cpp:244]     Train net output #1: loss = 0.00582669 (* 1 = 0.00582669 loss)
I0912 02:04:20.705044 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99812
I0912 02:04:20.705058 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997355
I0912 02:04:20.705066 25102 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0912 02:04:37.317461 25102 solver.cpp:228] Iteration 1680, loss = 0.00765243
I0912 02:04:37.317584 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996943
I0912 02:04:37.317611 25102 solver.cpp:244]     Train net output #1: loss = 0.00765238 (* 1 = 0.00765238 loss)
I0912 02:04:37.317620 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996523
I0912 02:04:37.317625 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997607
I0912 02:04:37.317632 25102 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0912 02:04:53.936568 25102 solver.cpp:228] Iteration 1700, loss = 0.00649314
I0912 02:04:53.936610 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997993
I0912 02:04:53.936640 25102 solver.cpp:244]     Train net output #1: loss = 0.00649309 (* 1 = 0.00649309 loss)
I0912 02:04:53.936648 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99854
I0912 02:04:53.936661 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995924
I0912 02:04:53.936671 25102 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0912 02:05:10.551290 25102 solver.cpp:228] Iteration 1720, loss = 0.0108188
I0912 02:05:10.551401 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995336
I0912 02:05:10.551416 25102 solver.cpp:244]     Train net output #1: loss = 0.0108188 (* 1 = 0.0108188 loss)
I0912 02:05:10.551422 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993607
I0912 02:05:10.551427 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998574
I0912 02:05:10.551435 25102 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0912 02:05:27.172111 25102 solver.cpp:228] Iteration 1740, loss = 0.0115091
I0912 02:05:27.172155 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995833
I0912 02:05:27.172186 25102 solver.cpp:244]     Train net output #1: loss = 0.0115091 (* 1 = 0.0115091 loss)
I0912 02:05:27.172199 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997022
I0912 02:05:27.172207 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993203
I0912 02:05:27.172215 25102 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0912 02:05:43.782652 25102 solver.cpp:228] Iteration 1760, loss = 0.307081
I0912 02:05:43.782796 25102 solver.cpp:244]     Train net output #0: accuracy = 0.920566
I0912 02:05:43.782814 25102 solver.cpp:244]     Train net output #1: loss = 0.307081 (* 1 = 0.307081 loss)
I0912 02:05:43.782822 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.919432
I0912 02:05:43.782827 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.923383
I0912 02:05:43.782835 25102 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0912 02:06:00.402849 25102 solver.cpp:228] Iteration 1780, loss = 0.0247628
I0912 02:06:00.402889 25102 solver.cpp:244]     Train net output #0: accuracy = 0.991471
I0912 02:06:00.402901 25102 solver.cpp:244]     Train net output #1: loss = 0.0247628 (* 1 = 0.0247628 loss)
I0912 02:06:00.402923 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987298
I0912 02:06:00.402930 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996636
I0912 02:06:00.402937 25102 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0912 02:06:17.010460 25102 solver.cpp:228] Iteration 1800, loss = 0.0288144
I0912 02:06:17.010573 25102 solver.cpp:244]     Train net output #0: accuracy = 0.988643
I0912 02:06:17.010588 25102 solver.cpp:244]     Train net output #1: loss = 0.0288144 (* 1 = 0.0288144 loss)
I0912 02:06:17.010601 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985644
I0912 02:06:17.010604 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994637
I0912 02:06:17.010617 25102 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0912 02:06:33.610349 25102 solver.cpp:228] Iteration 1820, loss = 0.0172891
I0912 02:06:33.610390 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993854
I0912 02:06:33.610401 25102 solver.cpp:244]     Train net output #1: loss = 0.0172891 (* 1 = 0.0172891 loss)
I0912 02:06:33.610407 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988929
I0912 02:06:33.610412 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997651
I0912 02:06:33.610419 25102 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0912 02:06:50.209976 25102 solver.cpp:228] Iteration 1840, loss = 0.0113678
I0912 02:06:50.210080 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995676
I0912 02:06:50.210113 25102 solver.cpp:244]     Train net output #1: loss = 0.0113678 (* 1 = 0.0113678 loss)
I0912 02:06:50.210121 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994881
I0912 02:06:50.210134 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998996
I0912 02:06:50.210141 25102 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0912 02:07:06.802947 25102 solver.cpp:228] Iteration 1860, loss = 0.0199988
I0912 02:07:06.802986 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995343
I0912 02:07:06.803014 25102 solver.cpp:244]     Train net output #1: loss = 0.0199988 (* 1 = 0.0199988 loss)
I0912 02:07:06.803022 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99258
I0912 02:07:06.803027 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996947
I0912 02:07:06.803035 25102 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0912 02:07:23.407915 25102 solver.cpp:228] Iteration 1880, loss = 0.0190887
I0912 02:07:23.408022 25102 solver.cpp:244]     Train net output #0: accuracy = 0.992402
I0912 02:07:23.408037 25102 solver.cpp:244]     Train net output #1: loss = 0.0190886 (* 1 = 0.0190886 loss)
I0912 02:07:23.408043 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991266
I0912 02:07:23.408048 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994065
I0912 02:07:23.408054 25102 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0912 02:07:40.012832 25102 solver.cpp:228] Iteration 1900, loss = 0.0190212
I0912 02:07:40.012876 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994253
I0912 02:07:40.012888 25102 solver.cpp:244]     Train net output #1: loss = 0.0190211 (* 1 = 0.0190211 loss)
I0912 02:07:40.012893 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994535
I0912 02:07:40.012900 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994023
I0912 02:07:40.012907 25102 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0912 02:07:56.616169 25102 solver.cpp:228] Iteration 1920, loss = 0.0250942
I0912 02:07:56.616304 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99036
I0912 02:07:56.616336 25102 solver.cpp:244]     Train net output #1: loss = 0.0250941 (* 1 = 0.0250941 loss)
I0912 02:07:56.616343 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99112
I0912 02:07:56.616348 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98723
I0912 02:07:56.616355 25102 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0912 02:08:13.214413 25102 solver.cpp:228] Iteration 1940, loss = 0.01421
I0912 02:08:13.214455 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995006
I0912 02:08:13.214485 25102 solver.cpp:244]     Train net output #1: loss = 0.01421 (* 1 = 0.01421 loss)
I0912 02:08:13.214493 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995956
I0912 02:08:13.214498 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991656
I0912 02:08:13.214504 25102 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0912 02:08:29.824702 25102 solver.cpp:228] Iteration 1960, loss = 0.00675578
I0912 02:08:29.824796 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997697
I0912 02:08:29.824826 25102 solver.cpp:244]     Train net output #1: loss = 0.00675574 (* 1 = 0.00675574 loss)
I0912 02:08:29.824833 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997385
I0912 02:08:29.824839 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999021
I0912 02:08:29.824846 25102 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0912 02:08:46.421164 25102 solver.cpp:228] Iteration 1980, loss = 0.0129414
I0912 02:08:46.421206 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994863
I0912 02:08:46.421236 25102 solver.cpp:244]     Train net output #1: loss = 0.0129413 (* 1 = 0.0129413 loss)
I0912 02:08:46.421245 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994992
I0912 02:08:46.421257 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994593
I0912 02:08:46.421264 25102 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0912 02:09:03.029635 25102 solver.cpp:228] Iteration 2000, loss = 0.0112094
I0912 02:09:03.029729 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995383
I0912 02:09:03.029745 25102 solver.cpp:244]     Train net output #1: loss = 0.0112094 (* 1 = 0.0112094 loss)
I0912 02:09:03.029750 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995162
I0912 02:09:03.029755 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995973
I0912 02:09:03.029763 25102 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0912 02:09:19.642647 25102 solver.cpp:228] Iteration 2020, loss = 0.0114671
I0912 02:09:19.642686 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996716
I0912 02:09:19.642698 25102 solver.cpp:244]     Train net output #1: loss = 0.011467 (* 1 = 0.011467 loss)
I0912 02:09:19.642704 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995778
I0912 02:09:19.642709 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997475
I0912 02:09:19.642715 25102 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0912 02:09:36.248741 25102 solver.cpp:228] Iteration 2040, loss = 0.00906633
I0912 02:09:36.248837 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996458
I0912 02:09:36.248852 25102 solver.cpp:244]     Train net output #1: loss = 0.00906629 (* 1 = 0.00906629 loss)
I0912 02:09:36.248858 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996242
I0912 02:09:36.248863 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99748
I0912 02:09:36.248870 25102 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0912 02:09:52.844410 25102 solver.cpp:228] Iteration 2060, loss = 0.0133214
I0912 02:09:52.844449 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994523
I0912 02:09:52.844461 25102 solver.cpp:244]     Train net output #1: loss = 0.0133214 (* 1 = 0.0133214 loss)
I0912 02:09:52.844483 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991364
I0912 02:09:52.844491 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997684
I0912 02:09:52.844498 25102 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0912 02:10:09.439342 25102 solver.cpp:228] Iteration 2080, loss = 0.0122703
I0912 02:10:09.439492 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996195
I0912 02:10:09.439510 25102 solver.cpp:244]     Train net output #1: loss = 0.0122702 (* 1 = 0.0122702 loss)
I0912 02:10:09.439519 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994327
I0912 02:10:09.439532 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99762
I0912 02:10:09.439539 25102 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0912 02:10:26.023980 25102 solver.cpp:228] Iteration 2100, loss = 0.0133518
I0912 02:10:26.024021 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99409
I0912 02:10:26.024034 25102 solver.cpp:244]     Train net output #1: loss = 0.0133518 (* 1 = 0.0133518 loss)
I0912 02:10:26.024040 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991284
I0912 02:10:26.024045 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997516
I0912 02:10:26.024052 25102 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0912 02:10:42.636781 25102 solver.cpp:228] Iteration 2120, loss = 0.0135698
I0912 02:10:42.636883 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994416
I0912 02:10:42.636898 25102 solver.cpp:244]     Train net output #1: loss = 0.0135698 (* 1 = 0.0135698 loss)
I0912 02:10:42.636904 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990622
I0912 02:10:42.636909 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998019
I0912 02:10:42.636916 25102 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0912 02:10:59.235363 25102 solver.cpp:228] Iteration 2140, loss = 0.0109145
I0912 02:10:59.235405 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995195
I0912 02:10:59.235419 25102 solver.cpp:244]     Train net output #1: loss = 0.0109144 (* 1 = 0.0109144 loss)
I0912 02:10:59.235424 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994961
I0912 02:10:59.235429 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995947
I0912 02:10:59.235435 25102 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0912 02:11:15.838739 25102 solver.cpp:228] Iteration 2160, loss = 0.0107226
I0912 02:11:15.838829 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995475
I0912 02:11:15.838843 25102 solver.cpp:244]     Train net output #1: loss = 0.0107226 (* 1 = 0.0107226 loss)
I0912 02:11:15.838848 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993636
I0912 02:11:15.838853 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997748
I0912 02:11:15.838860 25102 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0912 02:11:32.453698 25102 solver.cpp:228] Iteration 2180, loss = 0.0143542
I0912 02:11:32.453740 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99466
I0912 02:11:32.453754 25102 solver.cpp:244]     Train net output #1: loss = 0.0143542 (* 1 = 0.0143542 loss)
I0912 02:11:32.453768 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990766
I0912 02:11:32.453773 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997711
I0912 02:11:32.453781 25102 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0912 02:11:49.056149 25102 solver.cpp:228] Iteration 2200, loss = 0.010814
I0912 02:11:49.056294 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996302
I0912 02:11:49.056309 25102 solver.cpp:244]     Train net output #1: loss = 0.0108139 (* 1 = 0.0108139 loss)
I0912 02:11:49.056315 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997706
I0912 02:11:49.056320 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992863
I0912 02:11:49.056332 25102 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0912 02:12:05.771126 25102 solver.cpp:228] Iteration 2220, loss = 0.00861096
I0912 02:12:05.771168 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996502
I0912 02:12:05.771181 25102 solver.cpp:244]     Train net output #1: loss = 0.00861093 (* 1 = 0.00861093 loss)
I0912 02:12:05.771189 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995945
I0912 02:12:05.771194 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997378
I0912 02:12:05.771203 25102 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0912 02:12:22.380009 25102 solver.cpp:228] Iteration 2240, loss = 0.0174467
I0912 02:12:22.380115 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993416
I0912 02:12:22.380131 25102 solver.cpp:244]     Train net output #1: loss = 0.0174466 (* 1 = 0.0174466 loss)
I0912 02:12:22.380141 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994082
I0912 02:12:22.380146 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992205
I0912 02:12:22.380153 25102 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0912 02:12:39.003214 25102 solver.cpp:228] Iteration 2260, loss = 0.00789257
I0912 02:12:39.003253 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996487
I0912 02:12:39.003265 25102 solver.cpp:244]     Train net output #1: loss = 0.00789254 (* 1 = 0.00789254 loss)
I0912 02:12:39.003288 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994831
I0912 02:12:39.003294 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998613
I0912 02:12:39.003304 25102 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0912 02:12:55.602489 25102 solver.cpp:228] Iteration 2280, loss = 0.007285
I0912 02:12:55.602625 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996806
I0912 02:12:55.602669 25102 solver.cpp:244]     Train net output #1: loss = 0.00728496 (* 1 = 0.00728496 loss)
I0912 02:12:55.602677 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995768
I0912 02:12:55.602684 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998348
I0912 02:12:55.602692 25102 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0912 02:13:12.316421 25102 solver.cpp:228] Iteration 2300, loss = 0.0120103
I0912 02:13:12.316468 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994621
I0912 02:13:12.316481 25102 solver.cpp:244]     Train net output #1: loss = 0.0120102 (* 1 = 0.0120102 loss)
I0912 02:13:12.316488 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992822
I0912 02:13:12.316493 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997088
I0912 02:13:12.316500 25102 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0912 02:13:29.010970 25102 solver.cpp:228] Iteration 2320, loss = 0.00768757
I0912 02:13:29.011085 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996875
I0912 02:13:29.011116 25102 solver.cpp:244]     Train net output #1: loss = 0.00768753 (* 1 = 0.00768753 loss)
I0912 02:13:29.011126 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995995
I0912 02:13:29.011137 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997988
I0912 02:13:29.011147 25102 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0912 02:13:45.718883 25102 solver.cpp:228] Iteration 2340, loss = 0.00584454
I0912 02:13:45.718932 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998076
I0912 02:13:45.718945 25102 solver.cpp:244]     Train net output #1: loss = 0.00584451 (* 1 = 0.00584451 loss)
I0912 02:13:45.718951 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997639
I0912 02:13:45.718956 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998506
I0912 02:13:45.718964 25102 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0912 02:14:02.394505 25102 solver.cpp:228] Iteration 2360, loss = 0.00869347
I0912 02:14:02.394644 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997092
I0912 02:14:02.394675 25102 solver.cpp:244]     Train net output #1: loss = 0.00869344 (* 1 = 0.00869344 loss)
I0912 02:14:02.394683 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997482
I0912 02:14:02.394688 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995102
I0912 02:14:02.394696 25102 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0912 02:14:19.099781 25102 solver.cpp:228] Iteration 2380, loss = 0.0121379
I0912 02:14:19.099846 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99587
I0912 02:14:19.099869 25102 solver.cpp:244]     Train net output #1: loss = 0.0121379 (* 1 = 0.0121379 loss)
I0912 02:14:19.099877 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996634
I0912 02:14:19.099882 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994793
I0912 02:14:19.099890 25102 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0912 02:14:35.784409 25102 solver.cpp:228] Iteration 2400, loss = 0.0117036
I0912 02:14:35.784534 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995094
I0912 02:14:35.784550 25102 solver.cpp:244]     Train net output #1: loss = 0.0117035 (* 1 = 0.0117035 loss)
I0912 02:14:35.784556 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993917
I0912 02:14:35.784561 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996717
I0912 02:14:35.784569 25102 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0912 02:14:52.495389 25102 solver.cpp:228] Iteration 2420, loss = 0.00594102
I0912 02:14:52.495434 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997898
I0912 02:14:52.495460 25102 solver.cpp:244]     Train net output #1: loss = 0.00594098 (* 1 = 0.00594098 loss)
I0912 02:14:52.495468 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997797
I0912 02:14:52.495473 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998347
I0912 02:14:52.495486 25102 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0912 02:15:09.196462 25102 solver.cpp:228] Iteration 2440, loss = 0.00555766
I0912 02:15:09.196589 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997639
I0912 02:15:09.196619 25102 solver.cpp:244]     Train net output #1: loss = 0.00555762 (* 1 = 0.00555762 loss)
I0912 02:15:09.196630 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997435
I0912 02:15:09.196638 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998189
I0912 02:15:09.196646 25102 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0912 02:15:25.902325 25102 solver.cpp:228] Iteration 2460, loss = 0.00961832
I0912 02:15:25.902372 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99565
I0912 02:15:25.902397 25102 solver.cpp:244]     Train net output #1: loss = 0.00961828 (* 1 = 0.00961828 loss)
I0912 02:15:25.902405 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99395
I0912 02:15:25.902410 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997856
I0912 02:15:25.902417 25102 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0912 02:15:42.580340 25102 solver.cpp:228] Iteration 2480, loss = 0.0252658
I0912 02:15:42.580446 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994999
I0912 02:15:42.580464 25102 solver.cpp:244]     Train net output #1: loss = 0.0252657 (* 1 = 0.0252657 loss)
I0912 02:15:42.580471 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99558
I0912 02:15:42.580476 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994724
I0912 02:15:42.580483 25102 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0912 02:15:59.232426 25102 solver.cpp:228] Iteration 2500, loss = 0.0116783
I0912 02:15:59.232472 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995512
I0912 02:15:59.232486 25102 solver.cpp:244]     Train net output #1: loss = 0.0116783 (* 1 = 0.0116783 loss)
I0912 02:15:59.232493 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995886
I0912 02:15:59.232499 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994748
I0912 02:15:59.232506 25102 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0912 02:16:15.855976 25102 solver.cpp:228] Iteration 2520, loss = 0.0135533
I0912 02:16:15.856144 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99419
I0912 02:16:15.856166 25102 solver.cpp:244]     Train net output #1: loss = 0.0135533 (* 1 = 0.0135533 loss)
I0912 02:16:15.856174 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991485
I0912 02:16:15.856179 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997268
I0912 02:16:15.856189 25102 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0912 02:16:32.496829 25102 solver.cpp:228] Iteration 2540, loss = 0.00748249
I0912 02:16:32.496891 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996406
I0912 02:16:32.496906 25102 solver.cpp:244]     Train net output #1: loss = 0.00748245 (* 1 = 0.00748245 loss)
I0912 02:16:32.496913 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995666
I0912 02:16:32.496918 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998676
I0912 02:16:32.496927 25102 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0912 02:16:49.135371 25102 solver.cpp:228] Iteration 2560, loss = 0.0933835
I0912 02:16:49.135499 25102 solver.cpp:244]     Train net output #0: accuracy = 0.986225
I0912 02:16:49.135520 25102 solver.cpp:244]     Train net output #1: loss = 0.0933835 (* 1 = 0.0933835 loss)
I0912 02:16:49.135529 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995165
I0912 02:16:49.135540 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981478
I0912 02:16:49.135555 25102 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0912 02:17:05.802201 25102 solver.cpp:228] Iteration 2580, loss = 0.0121693
I0912 02:17:05.802251 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995246
I0912 02:17:05.802268 25102 solver.cpp:244]     Train net output #1: loss = 0.0121692 (* 1 = 0.0121692 loss)
I0912 02:17:05.802274 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992797
I0912 02:17:05.802280 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997529
I0912 02:17:05.802291 25102 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0912 02:17:22.454159 25102 solver.cpp:228] Iteration 2600, loss = 0.0126973
I0912 02:17:22.454315 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994321
I0912 02:17:22.454332 25102 solver.cpp:244]     Train net output #1: loss = 0.0126972 (* 1 = 0.0126972 loss)
I0912 02:17:22.454341 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992045
I0912 02:17:22.454354 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997524
I0912 02:17:22.454361 25102 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0912 02:17:39.080976 25102 solver.cpp:228] Iteration 2620, loss = 0.00978087
I0912 02:17:39.081022 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996149
I0912 02:17:39.081048 25102 solver.cpp:244]     Train net output #1: loss = 0.00978083 (* 1 = 0.00978083 loss)
I0912 02:17:39.081056 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995001
I0912 02:17:39.081061 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997517
I0912 02:17:39.081068 25102 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0912 02:17:55.738497 25102 solver.cpp:228] Iteration 2640, loss = 0.00731795
I0912 02:17:55.738608 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997073
I0912 02:17:55.738626 25102 solver.cpp:244]     Train net output #1: loss = 0.00731791 (* 1 = 0.00731791 loss)
I0912 02:17:55.738637 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997061
I0912 02:17:55.738642 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997097
I0912 02:17:55.738651 25102 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0912 02:18:12.364158 25102 solver.cpp:228] Iteration 2660, loss = 0.0185101
I0912 02:18:12.364204 25102 solver.cpp:244]     Train net output #0: accuracy = 0.992802
I0912 02:18:12.364236 25102 solver.cpp:244]     Train net output #1: loss = 0.01851 (* 1 = 0.01851 loss)
I0912 02:18:12.364246 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992355
I0912 02:18:12.364253 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99374
I0912 02:18:12.364261 25102 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0912 02:18:29.009240 25102 solver.cpp:228] Iteration 2680, loss = 0.00974609
I0912 02:18:29.009414 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995589
I0912 02:18:29.009444 25102 solver.cpp:244]     Train net output #1: loss = 0.00974605 (* 1 = 0.00974605 loss)
I0912 02:18:29.009454 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994288
I0912 02:18:29.009459 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997818
I0912 02:18:29.009467 25102 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0912 02:18:45.633755 25102 solver.cpp:228] Iteration 2700, loss = 0.00907001
I0912 02:18:45.633802 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996308
I0912 02:18:45.633817 25102 solver.cpp:244]     Train net output #1: loss = 0.00906997 (* 1 = 0.00906997 loss)
I0912 02:18:45.633824 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995745
I0912 02:18:45.633831 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997182
I0912 02:18:45.633838 25102 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0912 02:19:02.269636 25102 solver.cpp:228] Iteration 2720, loss = 0.0189235
I0912 02:19:02.269731 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99661
I0912 02:19:02.269747 25102 solver.cpp:244]     Train net output #1: loss = 0.0189234 (* 1 = 0.0189234 loss)
I0912 02:19:02.269755 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993696
I0912 02:19:02.269762 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997957
I0912 02:19:02.269769 25102 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0912 02:19:18.906860 25102 solver.cpp:228] Iteration 2740, loss = 0.0102616
I0912 02:19:18.906901 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996004
I0912 02:19:18.906916 25102 solver.cpp:244]     Train net output #1: loss = 0.0102615 (* 1 = 0.0102615 loss)
I0912 02:19:18.906924 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996292
I0912 02:19:18.906929 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995291
I0912 02:19:18.906936 25102 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0912 02:19:35.555737 25102 solver.cpp:228] Iteration 2760, loss = 0.00454495
I0912 02:19:35.555843 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99839
I0912 02:19:35.555860 25102 solver.cpp:244]     Train net output #1: loss = 0.0045449 (* 1 = 0.0045449 loss)
I0912 02:19:35.555868 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998548
I0912 02:19:35.555874 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997777
I0912 02:19:35.555881 25102 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0912 02:19:52.200474 25102 solver.cpp:228] Iteration 2780, loss = 0.0117783
I0912 02:19:52.200516 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995331
I0912 02:19:52.200531 25102 solver.cpp:244]     Train net output #1: loss = 0.0117783 (* 1 = 0.0117783 loss)
I0912 02:19:52.200537 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995635
I0912 02:19:52.200543 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994692
I0912 02:19:52.200551 25102 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0912 02:20:08.842717 25102 solver.cpp:228] Iteration 2800, loss = 0.0109013
I0912 02:20:08.842886 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994865
I0912 02:20:08.842921 25102 solver.cpp:244]     Train net output #1: loss = 0.0109013 (* 1 = 0.0109013 loss)
I0912 02:20:08.842929 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992813
I0912 02:20:08.842936 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998243
I0912 02:20:08.842943 25102 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0912 02:20:25.474252 25102 solver.cpp:228] Iteration 2820, loss = 0.00872087
I0912 02:20:25.474298 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995932
I0912 02:20:25.474311 25102 solver.cpp:244]     Train net output #1: loss = 0.00872082 (* 1 = 0.00872082 loss)
I0912 02:20:25.474318 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993795
I0912 02:20:25.474323 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998521
I0912 02:20:25.474330 25102 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0912 02:20:42.104938 25102 solver.cpp:228] Iteration 2840, loss = 0.00802841
I0912 02:20:42.105034 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99708
I0912 02:20:42.105052 25102 solver.cpp:244]     Train net output #1: loss = 0.00802836 (* 1 = 0.00802836 loss)
I0912 02:20:42.105059 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99771
I0912 02:20:42.105065 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994734
I0912 02:20:42.105075 25102 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0912 02:20:58.742151 25102 solver.cpp:228] Iteration 2860, loss = 0.0083894
I0912 02:20:58.742189 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996444
I0912 02:20:58.742205 25102 solver.cpp:244]     Train net output #1: loss = 0.00838935 (* 1 = 0.00838935 loss)
I0912 02:20:58.742211 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995986
I0912 02:20:58.742216 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997287
I0912 02:20:58.742224 25102 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0912 02:21:15.385165 25102 solver.cpp:228] Iteration 2880, loss = 0.00920306
I0912 02:21:15.385262 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995676
I0912 02:21:15.385278 25102 solver.cpp:244]     Train net output #1: loss = 0.00920301 (* 1 = 0.00920301 loss)
I0912 02:21:15.385293 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993771
I0912 02:21:15.385298 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998356
I0912 02:21:15.385305 25102 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0912 02:21:32.022895 25102 solver.cpp:228] Iteration 2900, loss = 0.0071367
I0912 02:21:32.022941 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997203
I0912 02:21:32.022956 25102 solver.cpp:244]     Train net output #1: loss = 0.00713665 (* 1 = 0.00713665 loss)
I0912 02:21:32.022964 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997419
I0912 02:21:32.022970 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996369
I0912 02:21:32.022979 25102 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0912 02:21:48.659332 25102 solver.cpp:228] Iteration 2920, loss = 0.0062553
I0912 02:21:48.659432 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997568
I0912 02:21:48.659447 25102 solver.cpp:244]     Train net output #1: loss = 0.00625526 (* 1 = 0.00625526 loss)
I0912 02:21:48.659461 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997029
I0912 02:21:48.659466 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998291
I0912 02:21:48.659472 25102 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0912 02:22:05.284590 25102 solver.cpp:228] Iteration 2940, loss = 0.00977033
I0912 02:22:05.284634 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995933
I0912 02:22:05.284648 25102 solver.cpp:244]     Train net output #1: loss = 0.00977029 (* 1 = 0.00977029 loss)
I0912 02:22:05.284657 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995836
I0912 02:22:05.284662 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996141
I0912 02:22:05.284670 25102 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0912 02:22:21.929525 25102 solver.cpp:228] Iteration 2960, loss = 0.00572655
I0912 02:22:21.929687 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998056
I0912 02:22:21.929710 25102 solver.cpp:244]     Train net output #1: loss = 0.00572651 (* 1 = 0.00572651 loss)
I0912 02:22:21.929718 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99807
I0912 02:22:21.929724 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997983
I0912 02:22:21.929733 25102 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0912 02:22:38.572587 25102 solver.cpp:228] Iteration 2980, loss = 0.0111267
I0912 02:22:38.572628 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995509
I0912 02:22:38.572641 25102 solver.cpp:244]     Train net output #1: loss = 0.0111266 (* 1 = 0.0111266 loss)
I0912 02:22:38.572648 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995128
I0912 02:22:38.572654 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996223
I0912 02:22:38.572660 25102 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0912 02:22:55.225653 25102 solver.cpp:228] Iteration 3000, loss = 0.0122791
I0912 02:22:55.225755 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994484
I0912 02:22:55.225772 25102 solver.cpp:244]     Train net output #1: loss = 0.012279 (* 1 = 0.012279 loss)
I0912 02:22:55.225783 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992153
I0912 02:22:55.225788 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997482
I0912 02:22:55.225796 25102 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0912 02:23:11.853271 25102 solver.cpp:228] Iteration 3020, loss = 0.00742068
I0912 02:23:11.853314 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996994
I0912 02:23:11.853329 25102 solver.cpp:244]     Train net output #1: loss = 0.00742064 (* 1 = 0.00742064 loss)
I0912 02:23:11.853335 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996561
I0912 02:23:11.853341 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997778
I0912 02:23:11.853348 25102 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0912 02:23:28.487267 25102 solver.cpp:228] Iteration 3040, loss = 0.0098873
I0912 02:23:28.487370 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996014
I0912 02:23:28.487387 25102 solver.cpp:244]     Train net output #1: loss = 0.00988726 (* 1 = 0.00988726 loss)
I0912 02:23:28.487402 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993409
I0912 02:23:28.487414 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998374
I0912 02:23:28.487422 25102 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0912 02:23:45.121752 25102 solver.cpp:228] Iteration 3060, loss = 0.00516042
I0912 02:23:45.121794 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998487
I0912 02:23:45.121809 25102 solver.cpp:244]     Train net output #1: loss = 0.00516038 (* 1 = 0.00516038 loss)
I0912 02:23:45.121814 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998656
I0912 02:23:45.121819 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997579
I0912 02:23:45.121827 25102 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0912 02:24:01.759111 25102 solver.cpp:228] Iteration 3080, loss = 0.00833193
I0912 02:24:01.759207 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996696
I0912 02:24:01.759225 25102 solver.cpp:244]     Train net output #1: loss = 0.00833189 (* 1 = 0.00833189 loss)
I0912 02:24:01.759240 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996132
I0912 02:24:01.759245 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997472
I0912 02:24:01.759253 25102 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0912 02:24:18.387732 25102 solver.cpp:228] Iteration 3100, loss = 0.00374563
I0912 02:24:18.387775 25102 solver.cpp:244]     Train net output #0: accuracy = 0.999051
I0912 02:24:18.387790 25102 solver.cpp:244]     Train net output #1: loss = 0.00374559 (* 1 = 0.00374559 loss)
I0912 02:24:18.387797 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999024
I0912 02:24:18.387802 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999214
I0912 02:24:18.387817 25102 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0912 02:24:35.027410 25102 solver.cpp:228] Iteration 3120, loss = 0.00542696
I0912 02:24:35.027557 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997799
I0912 02:24:35.027581 25102 solver.cpp:244]     Train net output #1: loss = 0.00542691 (* 1 = 0.00542691 loss)
I0912 02:24:35.027590 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997702
I0912 02:24:35.027595 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998073
I0912 02:24:35.027602 25102 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0912 02:24:51.660563 25102 solver.cpp:228] Iteration 3140, loss = 0.0085142
I0912 02:24:51.660609 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996994
I0912 02:24:51.660625 25102 solver.cpp:244]     Train net output #1: loss = 0.00851415 (* 1 = 0.00851415 loss)
I0912 02:24:51.660640 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997569
I0912 02:24:51.660651 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994137
I0912 02:24:51.660660 25102 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0912 02:25:08.301146 25102 solver.cpp:228] Iteration 3160, loss = 0.0077201
I0912 02:25:08.301246 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997216
I0912 02:25:08.301262 25102 solver.cpp:244]     Train net output #1: loss = 0.00772006 (* 1 = 0.00772006 loss)
I0912 02:25:08.301268 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997387
I0912 02:25:08.301273 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99701
I0912 02:25:08.301281 25102 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0912 02:25:24.947489 25102 solver.cpp:228] Iteration 3180, loss = 0.00945904
I0912 02:25:24.947535 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995479
I0912 02:25:24.947551 25102 solver.cpp:244]     Train net output #1: loss = 0.009459 (* 1 = 0.009459 loss)
I0912 02:25:24.947558 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993851
I0912 02:25:24.947564 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998482
I0912 02:25:24.947573 25102 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0912 02:25:41.593392 25102 solver.cpp:228] Iteration 3200, loss = 0.00775001
I0912 02:25:41.593485 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997454
I0912 02:25:41.593502 25102 solver.cpp:244]     Train net output #1: loss = 0.00774996 (* 1 = 0.00774996 loss)
I0912 02:25:41.593508 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99573
I0912 02:25:41.593513 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998685
I0912 02:25:41.593521 25102 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0912 02:25:58.242136 25102 solver.cpp:228] Iteration 3220, loss = 0.0061115
I0912 02:25:58.242179 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997542
I0912 02:25:58.242192 25102 solver.cpp:244]     Train net output #1: loss = 0.00611146 (* 1 = 0.00611146 loss)
I0912 02:25:58.242198 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99698
I0912 02:25:58.242204 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998311
I0912 02:25:58.242211 25102 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0912 02:26:14.897945 25102 solver.cpp:228] Iteration 3240, loss = 0.00630171
I0912 02:26:14.898046 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99727
I0912 02:26:14.898063 25102 solver.cpp:244]     Train net output #1: loss = 0.00630167 (* 1 = 0.00630167 loss)
I0912 02:26:14.898069 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996564
I0912 02:26:14.898075 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998305
I0912 02:26:14.898082 25102 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0912 02:26:31.558899 25102 solver.cpp:228] Iteration 3260, loss = 0.0106901
I0912 02:26:31.558943 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995723
I0912 02:26:31.558955 25102 solver.cpp:244]     Train net output #1: loss = 0.0106901 (* 1 = 0.0106901 loss)
I0912 02:26:31.558961 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993784
I0912 02:26:31.558969 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997581
I0912 02:26:31.558975 25102 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0912 02:26:48.174165 25102 solver.cpp:228] Iteration 3280, loss = 0.00691431
I0912 02:26:48.174314 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997098
I0912 02:26:48.174338 25102 solver.cpp:244]     Train net output #1: loss = 0.00691426 (* 1 = 0.00691426 loss)
I0912 02:26:48.174346 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99645
I0912 02:26:48.174353 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998109
I0912 02:26:48.174362 25102 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0912 02:27:04.786245 25102 solver.cpp:228] Iteration 3300, loss = 0.00413329
I0912 02:27:04.786289 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998286
I0912 02:27:04.786303 25102 solver.cpp:244]     Train net output #1: loss = 0.00413324 (* 1 = 0.00413324 loss)
I0912 02:27:04.786309 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997717
I0912 02:27:04.786315 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999152
I0912 02:27:04.786324 25102 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0912 02:27:21.434126 25102 solver.cpp:228] Iteration 3320, loss = 0.0118368
I0912 02:27:21.434211 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996386
I0912 02:27:21.434227 25102 solver.cpp:244]     Train net output #1: loss = 0.0118367 (* 1 = 0.0118367 loss)
I0912 02:27:21.434234 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992949
I0912 02:27:21.434239 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998417
I0912 02:27:21.434247 25102 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0912 02:27:38.069270 25102 solver.cpp:228] Iteration 3340, loss = 0.00808754
I0912 02:27:38.069315 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996671
I0912 02:27:38.069330 25102 solver.cpp:244]     Train net output #1: loss = 0.0080875 (* 1 = 0.0080875 loss)
I0912 02:27:38.069346 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996705
I0912 02:27:38.069358 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99651
I0912 02:27:38.069371 25102 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0912 02:27:54.716930 25102 solver.cpp:228] Iteration 3360, loss = 0.00956131
I0912 02:27:54.717023 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996127
I0912 02:27:54.717038 25102 solver.cpp:244]     Train net output #1: loss = 0.00956126 (* 1 = 0.00956126 loss)
I0912 02:27:54.717051 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993926
I0912 02:27:54.717056 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998097
I0912 02:27:54.717064 25102 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0912 02:28:11.365634 25102 solver.cpp:228] Iteration 3380, loss = 0.00871742
I0912 02:28:11.365680 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99603
I0912 02:28:11.365695 25102 solver.cpp:244]     Train net output #1: loss = 0.00871738 (* 1 = 0.00871738 loss)
I0912 02:28:11.365703 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993695
I0912 02:28:11.365710 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998827
I0912 02:28:11.365717 25102 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0912 02:28:27.985350 25102 solver.cpp:228] Iteration 3400, loss = 0.0113879
I0912 02:28:27.985505 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995301
I0912 02:28:27.985530 25102 solver.cpp:244]     Train net output #1: loss = 0.0113879 (* 1 = 0.0113879 loss)
I0912 02:28:27.985538 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993048
I0912 02:28:27.985543 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997583
I0912 02:28:27.985550 25102 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0912 02:28:44.609079 25102 solver.cpp:228] Iteration 3420, loss = 0.00659258
I0912 02:28:44.609127 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997633
I0912 02:28:44.609141 25102 solver.cpp:244]     Train net output #1: loss = 0.00659254 (* 1 = 0.00659254 loss)
I0912 02:28:44.609149 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997629
I0912 02:28:44.609156 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997638
I0912 02:28:44.609165 25102 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0912 02:29:01.247828 25102 solver.cpp:228] Iteration 3440, loss = 0.0031578
I0912 02:29:01.247915 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998815
I0912 02:29:01.247931 25102 solver.cpp:244]     Train net output #1: loss = 0.00315776 (* 1 = 0.00315776 loss)
I0912 02:29:01.247937 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998866
I0912 02:29:01.247942 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998704
I0912 02:29:01.247951 25102 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0912 02:29:17.872149 25102 solver.cpp:228] Iteration 3460, loss = 0.0088525
I0912 02:29:17.872192 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996466
I0912 02:29:17.872205 25102 solver.cpp:244]     Train net output #1: loss = 0.00885246 (* 1 = 0.00885246 loss)
I0912 02:29:17.872212 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995861
I0912 02:29:17.872217 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997282
I0912 02:29:17.872225 25102 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0912 02:29:34.499645 25102 solver.cpp:228] Iteration 3480, loss = 0.0051297
I0912 02:29:34.499778 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997782
I0912 02:29:34.499819 25102 solver.cpp:244]     Train net output #1: loss = 0.00512965 (* 1 = 0.00512965 loss)
I0912 02:29:34.499830 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997565
I0912 02:29:34.499841 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998605
I0912 02:29:34.499855 25102 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0912 02:29:51.209241 25102 solver.cpp:228] Iteration 3500, loss = 0.00910826
I0912 02:29:51.209286 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996348
I0912 02:29:51.209300 25102 solver.cpp:244]     Train net output #1: loss = 0.00910821 (* 1 = 0.00910821 loss)
I0912 02:29:51.209306 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996518
I0912 02:29:51.209311 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995962
I0912 02:29:51.209319 25102 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0912 02:30:07.902644 25102 solver.cpp:228] Iteration 3520, loss = 0.00507442
I0912 02:30:07.902752 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998051
I0912 02:30:07.902783 25102 solver.cpp:244]     Train net output #1: loss = 0.00507437 (* 1 = 0.00507437 loss)
I0912 02:30:07.902793 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996883
I0912 02:30:07.902804 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999121
I0912 02:30:07.902813 25102 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0912 02:30:24.577600 25102 solver.cpp:228] Iteration 3540, loss = 0.00734114
I0912 02:30:24.577646 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997125
I0912 02:30:24.577661 25102 solver.cpp:244]     Train net output #1: loss = 0.0073411 (* 1 = 0.0073411 loss)
I0912 02:30:24.577667 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99756
I0912 02:30:24.577672 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996131
I0912 02:30:24.577680 25102 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0912 02:30:41.212680 25102 solver.cpp:228] Iteration 3560, loss = 0.00507482
I0912 02:30:41.212821 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997755
I0912 02:30:41.212841 25102 solver.cpp:244]     Train net output #1: loss = 0.00507477 (* 1 = 0.00507477 loss)
I0912 02:30:41.212849 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997175
I0912 02:30:41.212854 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998825
I0912 02:30:41.212862 25102 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0912 02:30:57.858969 25102 solver.cpp:228] Iteration 3580, loss = 0.00774015
I0912 02:30:57.859014 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996298
I0912 02:30:57.859030 25102 solver.cpp:244]     Train net output #1: loss = 0.0077401 (* 1 = 0.0077401 loss)
I0912 02:30:57.859035 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995523
I0912 02:30:57.859040 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998329
I0912 02:30:57.859048 25102 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0912 02:31:14.485739 25102 solver.cpp:228] Iteration 3600, loss = 0.0035063
I0912 02:31:14.485877 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998511
I0912 02:31:14.485919 25102 solver.cpp:244]     Train net output #1: loss = 0.00350626 (* 1 = 0.00350626 loss)
I0912 02:31:14.485927 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998306
I0912 02:31:14.485934 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998899
I0912 02:31:14.485942 25102 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0912 02:31:31.173840 25102 solver.cpp:228] Iteration 3620, loss = 0.00495881
I0912 02:31:31.173888 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997753
I0912 02:31:31.173914 25102 solver.cpp:244]     Train net output #1: loss = 0.00495876 (* 1 = 0.00495876 loss)
I0912 02:31:31.173925 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996694
I0912 02:31:31.173936 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999039
I0912 02:31:31.173945 25102 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0912 02:31:47.837188 25102 solver.cpp:228] Iteration 3640, loss = 0.00600392
I0912 02:31:47.837304 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997692
I0912 02:31:47.837321 25102 solver.cpp:244]     Train net output #1: loss = 0.00600388 (* 1 = 0.00600388 loss)
I0912 02:31:47.837327 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997791
I0912 02:31:47.837332 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997436
I0912 02:31:47.837338 25102 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0912 02:32:04.474649 25102 solver.cpp:228] Iteration 3660, loss = 0.00732757
I0912 02:32:04.474694 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997245
I0912 02:32:04.474709 25102 solver.cpp:244]     Train net output #1: loss = 0.00732752 (* 1 = 0.00732752 loss)
I0912 02:32:04.474715 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99727
I0912 02:32:04.474721 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997111
I0912 02:32:04.474730 25102 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0912 02:32:21.090054 25102 solver.cpp:228] Iteration 3680, loss = 0.00800279
I0912 02:32:21.090163 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996373
I0912 02:32:21.090179 25102 solver.cpp:244]     Train net output #1: loss = 0.00800274 (* 1 = 0.00800274 loss)
I0912 02:32:21.090185 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994843
I0912 02:32:21.090190 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998461
I0912 02:32:21.090198 25102 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0912 02:32:37.721650 25102 solver.cpp:228] Iteration 3700, loss = 0.0108766
I0912 02:32:37.721695 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997828
I0912 02:32:37.721709 25102 solver.cpp:244]     Train net output #1: loss = 0.0108766 (* 1 = 0.0108766 loss)
I0912 02:32:37.721717 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997931
I0912 02:32:37.721722 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996416
I0912 02:32:37.721731 25102 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0912 02:32:54.353898 25102 solver.cpp:228] Iteration 3720, loss = 0.00420061
I0912 02:32:54.354053 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998552
I0912 02:32:54.354069 25102 solver.cpp:244]     Train net output #1: loss = 0.00420056 (* 1 = 0.00420056 loss)
I0912 02:32:54.354075 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999063
I0912 02:32:54.354079 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99727
I0912 02:32:54.354086 25102 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0912 02:33:10.970502 25102 solver.cpp:228] Iteration 3740, loss = 0.0158581
I0912 02:33:10.970544 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997718
I0912 02:33:10.970559 25102 solver.cpp:244]     Train net output #1: loss = 0.015858 (* 1 = 0.015858 loss)
I0912 02:33:10.970566 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996192
I0912 02:33:10.970573 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998343
I0912 02:33:10.970582 25102 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0912 02:33:27.612097 25102 solver.cpp:228] Iteration 3760, loss = 0.0028529
I0912 02:33:27.612196 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998611
I0912 02:33:27.612211 25102 solver.cpp:244]     Train net output #1: loss = 0.00285285 (* 1 = 0.00285285 loss)
I0912 02:33:27.612223 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9982
I0912 02:33:27.612228 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999744
I0912 02:33:27.612236 25102 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0912 02:33:44.217546 25102 solver.cpp:228] Iteration 3780, loss = 0.00946064
I0912 02:33:44.217588 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996273
I0912 02:33:44.217602 25102 solver.cpp:244]     Train net output #1: loss = 0.0094606 (* 1 = 0.0094606 loss)
I0912 02:33:44.217608 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996878
I0912 02:33:44.217614 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994369
I0912 02:33:44.217623 25102 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0912 02:34:00.851377 25102 solver.cpp:228] Iteration 3800, loss = 0.00747569
I0912 02:34:00.851485 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99696
I0912 02:34:00.851500 25102 solver.cpp:244]     Train net output #1: loss = 0.00747564 (* 1 = 0.00747564 loss)
I0912 02:34:00.851513 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997082
I0912 02:34:00.851518 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996549
I0912 02:34:00.851526 25102 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0912 02:34:17.487884 25102 solver.cpp:228] Iteration 3820, loss = 0.0170671
I0912 02:34:17.487927 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996374
I0912 02:34:17.487941 25102 solver.cpp:244]     Train net output #1: loss = 0.017067 (* 1 = 0.017067 loss)
I0912 02:34:17.487948 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996449
I0912 02:34:17.487953 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996337
I0912 02:34:17.487962 25102 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0912 02:34:34.108357 25102 solver.cpp:228] Iteration 3840, loss = 0.00896066
I0912 02:34:34.108516 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995765
I0912 02:34:34.108532 25102 solver.cpp:244]     Train net output #1: loss = 0.00896062 (* 1 = 0.00896062 loss)
I0912 02:34:34.108538 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990914
I0912 02:34:34.108543 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99953
I0912 02:34:34.108551 25102 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0912 02:34:50.743701 25102 solver.cpp:228] Iteration 3860, loss = 0.00615337
I0912 02:34:50.743743 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997789
I0912 02:34:50.743757 25102 solver.cpp:244]     Train net output #1: loss = 0.00615333 (* 1 = 0.00615333 loss)
I0912 02:34:50.743764 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997834
I0912 02:34:50.743770 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997732
I0912 02:34:50.743778 25102 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0912 02:35:07.387320 25102 solver.cpp:228] Iteration 3880, loss = 0.0106825
I0912 02:35:07.387420 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995969
I0912 02:35:07.387436 25102 solver.cpp:244]     Train net output #1: loss = 0.0106824 (* 1 = 0.0106824 loss)
I0912 02:35:07.387450 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996127
I0912 02:35:07.387455 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995715
I0912 02:35:07.387465 25102 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0912 02:35:24.027535 25102 solver.cpp:228] Iteration 3900, loss = 0.00655499
I0912 02:35:24.027576 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996902
I0912 02:35:24.027590 25102 solver.cpp:244]     Train net output #1: loss = 0.00655494 (* 1 = 0.00655494 loss)
I0912 02:35:24.027595 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993963
I0912 02:35:24.027601 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999582
I0912 02:35:24.027607 25102 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0912 02:35:40.647552 25102 solver.cpp:228] Iteration 3920, loss = 0.00903759
I0912 02:35:40.647652 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99658
I0912 02:35:40.647668 25102 solver.cpp:244]     Train net output #1: loss = 0.00903755 (* 1 = 0.00903755 loss)
I0912 02:35:40.647681 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995694
I0912 02:35:40.647692 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997536
I0912 02:35:40.647701 25102 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0912 02:35:57.281975 25102 solver.cpp:228] Iteration 3940, loss = 0.00544854
I0912 02:35:57.282016 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997666
I0912 02:35:57.282028 25102 solver.cpp:244]     Train net output #1: loss = 0.0054485 (* 1 = 0.0054485 loss)
I0912 02:35:57.282035 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99696
I0912 02:35:57.282039 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998884
I0912 02:35:57.282047 25102 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0912 02:36:13.890405 25102 solver.cpp:228] Iteration 3960, loss = 0.00650412
I0912 02:36:13.890502 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998176
I0912 02:36:13.890519 25102 solver.cpp:244]     Train net output #1: loss = 0.00650407 (* 1 = 0.00650407 loss)
I0912 02:36:13.890530 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998763
I0912 02:36:13.890537 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99407
I0912 02:36:13.890544 25102 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0912 02:36:30.522466 25102 solver.cpp:228] Iteration 3980, loss = 0.00582144
I0912 02:36:30.522505 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997694
I0912 02:36:30.522518 25102 solver.cpp:244]     Train net output #1: loss = 0.0058214 (* 1 = 0.0058214 loss)
I0912 02:36:30.522524 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997922
I0912 02:36:30.522529 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996876
I0912 02:36:30.522536 25102 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0912 02:36:47.161319 25102 solver.cpp:228] Iteration 4000, loss = 0.00851853
I0912 02:36:47.161470 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996442
I0912 02:36:47.161489 25102 solver.cpp:244]     Train net output #1: loss = 0.00851849 (* 1 = 0.00851849 loss)
I0912 02:36:47.161496 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996517
I0912 02:36:47.161504 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996179
I0912 02:36:47.161510 25102 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0912 02:37:03.786516 25102 solver.cpp:228] Iteration 4020, loss = 0.00795443
I0912 02:37:03.786556 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996748
I0912 02:37:03.786569 25102 solver.cpp:244]     Train net output #1: loss = 0.00795439 (* 1 = 0.00795439 loss)
I0912 02:37:03.786574 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997125
I0912 02:37:03.786579 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995028
I0912 02:37:03.786586 25102 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0912 02:37:20.412189 25102 solver.cpp:228] Iteration 4040, loss = 0.00397104
I0912 02:37:20.412286 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998519
I0912 02:37:20.412300 25102 solver.cpp:244]     Train net output #1: loss = 0.003971 (* 1 = 0.003971 loss)
I0912 02:37:20.412312 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997743
I0912 02:37:20.412317 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999233
I0912 02:37:20.412330 25102 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0912 02:37:37.045357 25102 solver.cpp:228] Iteration 4060, loss = 0.00957071
I0912 02:37:37.045408 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995864
I0912 02:37:37.045421 25102 solver.cpp:244]     Train net output #1: loss = 0.00957067 (* 1 = 0.00957067 loss)
I0912 02:37:37.045428 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995476
I0912 02:37:37.045434 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996686
I0912 02:37:37.045444 25102 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0912 02:37:53.673431 25102 solver.cpp:228] Iteration 4080, loss = 0.00828529
I0912 02:37:53.673513 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996777
I0912 02:37:53.673527 25102 solver.cpp:244]     Train net output #1: loss = 0.00828525 (* 1 = 0.00828525 loss)
I0912 02:37:53.673532 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995845
I0912 02:37:53.673537 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997792
I0912 02:37:53.673544 25102 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0912 02:38:10.296540 25102 solver.cpp:228] Iteration 4100, loss = 0.00949686
I0912 02:38:10.296584 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995651
I0912 02:38:10.296597 25102 solver.cpp:244]     Train net output #1: loss = 0.00949681 (* 1 = 0.00949681 loss)
I0912 02:38:10.296604 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994838
I0912 02:38:10.296609 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997449
I0912 02:38:10.296617 25102 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0912 02:38:26.915880 25102 solver.cpp:228] Iteration 4120, loss = 0.00853468
I0912 02:38:26.915973 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997882
I0912 02:38:26.915987 25102 solver.cpp:244]     Train net output #1: loss = 0.00853464 (* 1 = 0.00853464 loss)
I0912 02:38:26.916000 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996287
I0912 02:38:26.916005 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998754
I0912 02:38:26.916013 25102 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0912 02:38:43.524262 25102 solver.cpp:228] Iteration 4140, loss = 0.00671854
I0912 02:38:43.524307 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997179
I0912 02:38:43.524322 25102 solver.cpp:244]     Train net output #1: loss = 0.0067185 (* 1 = 0.0067185 loss)
I0912 02:38:43.524329 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995787
I0912 02:38:43.524335 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99873
I0912 02:38:43.524343 25102 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0912 02:39:00.158185 25102 solver.cpp:228] Iteration 4160, loss = 0.00271943
I0912 02:39:00.158340 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998993
I0912 02:39:00.158356 25102 solver.cpp:244]     Train net output #1: loss = 0.00271939 (* 1 = 0.00271939 loss)
I0912 02:39:00.158365 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999124
I0912 02:39:00.158370 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998564
I0912 02:39:00.158376 25102 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0912 02:39:16.790722 25102 solver.cpp:228] Iteration 4180, loss = 0.0057359
I0912 02:39:16.790766 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997805
I0912 02:39:16.790781 25102 solver.cpp:244]     Train net output #1: loss = 0.00573586 (* 1 = 0.00573586 loss)
I0912 02:39:16.790787 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997112
I0912 02:39:16.790793 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998486
I0912 02:39:16.790801 25102 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0912 02:39:33.415354 25102 solver.cpp:228] Iteration 4200, loss = 0.00808069
I0912 02:39:33.415446 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996464
I0912 02:39:33.415460 25102 solver.cpp:244]     Train net output #1: loss = 0.00808065 (* 1 = 0.00808065 loss)
I0912 02:39:33.415467 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993636
I0912 02:39:33.415472 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998957
I0912 02:39:33.415478 25102 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0912 02:39:50.036623 25102 solver.cpp:228] Iteration 4220, loss = 0.00639051
I0912 02:39:50.036665 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997562
I0912 02:39:50.036680 25102 solver.cpp:244]     Train net output #1: loss = 0.00639047 (* 1 = 0.00639047 loss)
I0912 02:39:50.036686 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997823
I0912 02:39:50.036692 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997062
I0912 02:39:50.036700 25102 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0912 02:40:06.669284 25102 solver.cpp:228] Iteration 4240, loss = 0.00526695
I0912 02:40:06.669374 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997617
I0912 02:40:06.669389 25102 solver.cpp:244]     Train net output #1: loss = 0.00526691 (* 1 = 0.00526691 loss)
I0912 02:40:06.669395 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996943
I0912 02:40:06.669400 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998757
I0912 02:40:06.669407 25102 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0912 02:40:23.291596 25102 solver.cpp:228] Iteration 4260, loss = 0.00459771
I0912 02:40:23.291641 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998239
I0912 02:40:23.291654 25102 solver.cpp:244]     Train net output #1: loss = 0.00459767 (* 1 = 0.00459767 loss)
I0912 02:40:23.291661 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998389
I0912 02:40:23.291666 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997681
I0912 02:40:23.291672 25102 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0912 02:40:39.936219 25102 solver.cpp:228] Iteration 4280, loss = 0.00967493
I0912 02:40:39.936313 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996884
I0912 02:40:39.936329 25102 solver.cpp:244]     Train net output #1: loss = 0.00967489 (* 1 = 0.00967489 loss)
I0912 02:40:39.936337 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994153
I0912 02:40:39.936343 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998497
I0912 02:40:39.936350 25102 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0912 02:40:56.556358 25102 solver.cpp:228] Iteration 4300, loss = 0.00684818
I0912 02:40:56.556398 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99685
I0912 02:40:56.556411 25102 solver.cpp:244]     Train net output #1: loss = 0.00684814 (* 1 = 0.00684814 loss)
I0912 02:40:56.556419 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996132
I0912 02:40:56.556424 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998423
I0912 02:40:56.556432 25102 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0912 02:41:13.177125 25102 solver.cpp:228] Iteration 4320, loss = 0.00894727
I0912 02:41:13.177260 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996181
I0912 02:41:13.177296 25102 solver.cpp:244]     Train net output #1: loss = 0.00894723 (* 1 = 0.00894723 loss)
I0912 02:41:13.177304 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995311
I0912 02:41:13.177310 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997458
I0912 02:41:13.177317 25102 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0912 02:41:29.816026 25102 solver.cpp:228] Iteration 4340, loss = 0.00807784
I0912 02:41:29.816066 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996729
I0912 02:41:29.816081 25102 solver.cpp:244]     Train net output #1: loss = 0.0080778 (* 1 = 0.0080778 loss)
I0912 02:41:29.816085 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995226
I0912 02:41:29.816090 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998175
I0912 02:41:29.816098 25102 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0912 02:41:46.447012 25102 solver.cpp:228] Iteration 4360, loss = 0.00647033
I0912 02:41:46.447113 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997153
I0912 02:41:46.447129 25102 solver.cpp:244]     Train net output #1: loss = 0.00647029 (* 1 = 0.00647029 loss)
I0912 02:41:46.447135 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996814
I0912 02:41:46.447141 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998336
I0912 02:41:46.447149 25102 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0912 02:42:03.069766 25102 solver.cpp:228] Iteration 4380, loss = 0.00502762
I0912 02:42:03.069805 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997608
I0912 02:42:03.069818 25102 solver.cpp:244]     Train net output #1: loss = 0.00502758 (* 1 = 0.00502758 loss)
I0912 02:42:03.069824 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997151
I0912 02:42:03.069829 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999379
I0912 02:42:03.069836 25102 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0912 02:42:19.688438 25102 solver.cpp:228] Iteration 4400, loss = 0.00648004
I0912 02:42:19.688567 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997127
I0912 02:42:19.688609 25102 solver.cpp:244]     Train net output #1: loss = 0.00648 (* 1 = 0.00648 loss)
I0912 02:42:19.688618 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996276
I0912 02:42:19.688629 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998536
I0912 02:42:19.688638 25102 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0912 02:42:36.336699 25102 solver.cpp:228] Iteration 4420, loss = 0.008165
I0912 02:42:36.336742 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996497
I0912 02:42:36.336755 25102 solver.cpp:244]     Train net output #1: loss = 0.00816496 (* 1 = 0.00816496 loss)
I0912 02:42:36.336761 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996062
I0912 02:42:36.336766 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997464
I0912 02:42:36.336772 25102 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0912 02:42:52.957221 25102 solver.cpp:228] Iteration 4440, loss = 0.00572126
I0912 02:42:52.957408 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997975
I0912 02:42:52.957427 25102 solver.cpp:244]     Train net output #1: loss = 0.00572122 (* 1 = 0.00572122 loss)
I0912 02:42:52.957448 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99763
I0912 02:42:52.957456 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998294
I0912 02:42:52.957464 25102 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0912 02:43:09.555670 25102 solver.cpp:228] Iteration 4460, loss = 0.0076665
I0912 02:43:09.555713 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996855
I0912 02:43:09.555728 25102 solver.cpp:244]     Train net output #1: loss = 0.00766646 (* 1 = 0.00766646 loss)
I0912 02:43:09.555743 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996837
I0912 02:43:09.555749 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996891
I0912 02:43:09.555757 25102 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0912 02:43:26.188264 25102 solver.cpp:228] Iteration 4480, loss = 0.00653249
I0912 02:43:26.188379 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99719
I0912 02:43:26.188393 25102 solver.cpp:244]     Train net output #1: loss = 0.00653245 (* 1 = 0.00653245 loss)
I0912 02:43:26.188400 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996924
I0912 02:43:26.188403 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997797
I0912 02:43:26.188410 25102 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0912 02:43:42.799101 25102 solver.cpp:228] Iteration 4500, loss = 0.00941503
I0912 02:43:42.799145 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996095
I0912 02:43:42.799160 25102 solver.cpp:244]     Train net output #1: loss = 0.009415 (* 1 = 0.009415 loss)
I0912 02:43:42.799175 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996153
I0912 02:43:42.799186 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995862
I0912 02:43:42.799193 25102 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0912 02:43:59.403435 25102 solver.cpp:228] Iteration 4520, loss = 0.00447617
I0912 02:43:59.403538 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998151
I0912 02:43:59.403553 25102 solver.cpp:244]     Train net output #1: loss = 0.00447614 (* 1 = 0.00447614 loss)
I0912 02:43:59.403558 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997786
I0912 02:43:59.403563 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998667
I0912 02:43:59.403569 25102 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0912 02:44:16.013756 25102 solver.cpp:228] Iteration 4540, loss = 0.00584861
I0912 02:44:16.013799 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997507
I0912 02:44:16.013814 25102 solver.cpp:244]     Train net output #1: loss = 0.00584857 (* 1 = 0.00584857 loss)
I0912 02:44:16.013823 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997286
I0912 02:44:16.013828 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998033
I0912 02:44:16.013835 25102 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0912 02:44:32.631100 25102 solver.cpp:228] Iteration 4560, loss = 0.00785325
I0912 02:44:32.631229 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996833
I0912 02:44:32.631271 25102 solver.cpp:244]     Train net output #1: loss = 0.00785321 (* 1 = 0.00785321 loss)
I0912 02:44:32.631279 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996059
I0912 02:44:32.631289 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997883
I0912 02:44:32.631299 25102 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0912 02:44:49.256032 25102 solver.cpp:228] Iteration 4580, loss = 0.0201684
I0912 02:44:49.256078 25102 solver.cpp:244]     Train net output #0: accuracy = 0.991126
I0912 02:44:49.256093 25102 solver.cpp:244]     Train net output #1: loss = 0.0201683 (* 1 = 0.0201683 loss)
I0912 02:44:49.256099 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983778
I0912 02:44:49.256106 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999736
I0912 02:44:49.256114 25102 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0912 02:45:05.885191 25102 solver.cpp:228] Iteration 4600, loss = 0.0691937
I0912 02:45:05.885360 25102 solver.cpp:244]     Train net output #0: accuracy = 0.978909
I0912 02:45:05.885382 25102 solver.cpp:244]     Train net output #1: loss = 0.0691937 (* 1 = 0.0691937 loss)
I0912 02:45:05.885397 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984141
I0912 02:45:05.885402 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.958774
I0912 02:45:05.885409 25102 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0912 02:45:22.512645 25102 solver.cpp:228] Iteration 4620, loss = 0.0367086
I0912 02:45:22.512692 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99024
I0912 02:45:22.512706 25102 solver.cpp:244]     Train net output #1: loss = 0.0367086 (* 1 = 0.0367086 loss)
I0912 02:45:22.512713 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987466
I0912 02:45:22.512718 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99674
I0912 02:45:22.512737 25102 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0912 02:45:39.138331 25102 solver.cpp:228] Iteration 4640, loss = 0.0471633
I0912 02:45:39.138442 25102 solver.cpp:244]     Train net output #0: accuracy = 0.984854
I0912 02:45:39.138458 25102 solver.cpp:244]     Train net output #1: loss = 0.0471634 (* 1 = 0.0471634 loss)
I0912 02:45:39.138473 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978728
I0912 02:45:39.138479 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992794
I0912 02:45:39.138487 25102 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0912 02:45:55.757959 25102 solver.cpp:228] Iteration 4660, loss = 0.0228187
I0912 02:45:55.758000 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993132
I0912 02:45:55.758014 25102 solver.cpp:244]     Train net output #1: loss = 0.0228187 (* 1 = 0.0228187 loss)
I0912 02:45:55.758019 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990765
I0912 02:45:55.758024 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995355
I0912 02:45:55.758031 25102 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0912 02:46:12.389889 25102 solver.cpp:228] Iteration 4680, loss = 0.0161184
I0912 02:46:12.389997 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994418
I0912 02:46:12.390013 25102 solver.cpp:244]     Train net output #1: loss = 0.0161184 (* 1 = 0.0161184 loss)
I0912 02:46:12.390020 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994922
I0912 02:46:12.390027 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99312
I0912 02:46:12.390035 25102 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0912 02:46:29.014377 25102 solver.cpp:228] Iteration 4700, loss = 0.0171169
I0912 02:46:29.014416 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994531
I0912 02:46:29.014428 25102 solver.cpp:244]     Train net output #1: loss = 0.0171169 (* 1 = 0.0171169 loss)
I0912 02:46:29.014434 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995138
I0912 02:46:29.014439 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993749
I0912 02:46:29.014446 25102 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0912 02:46:45.656652 25102 solver.cpp:228] Iteration 4720, loss = 0.0249143
I0912 02:46:45.656796 25102 solver.cpp:244]     Train net output #0: accuracy = 0.989481
I0912 02:46:45.656836 25102 solver.cpp:244]     Train net output #1: loss = 0.0249143 (* 1 = 0.0249143 loss)
I0912 02:46:45.656847 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988749
I0912 02:46:45.656857 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992318
I0912 02:46:45.656867 25102 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0912 02:47:02.302613 25102 solver.cpp:228] Iteration 4740, loss = 0.00499891
I0912 02:47:02.302654 25102 solver.cpp:244]     Train net output #0: accuracy = 0.998048
I0912 02:47:02.302667 25102 solver.cpp:244]     Train net output #1: loss = 0.00499889 (* 1 = 0.00499889 loss)
I0912 02:47:02.302673 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997542
I0912 02:47:02.302678 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999112
I0912 02:47:02.302685 25102 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0912 02:47:18.929692 25102 solver.cpp:228] Iteration 4760, loss = 0.0141717
I0912 02:47:18.929862 25102 solver.cpp:244]     Train net output #0: accuracy = 0.995268
I0912 02:47:18.929885 25102 solver.cpp:244]     Train net output #1: loss = 0.0141717 (* 1 = 0.0141717 loss)
I0912 02:47:18.929893 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995882
I0912 02:47:18.929900 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99452
I0912 02:47:18.929908 25102 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0912 02:47:35.553494 25102 solver.cpp:228] Iteration 4780, loss = 0.00730943
I0912 02:47:35.553534 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997413
I0912 02:47:35.553546 25102 solver.cpp:244]     Train net output #1: loss = 0.0073094 (* 1 = 0.0073094 loss)
I0912 02:47:35.553553 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997777
I0912 02:47:35.553558 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996496
I0912 02:47:35.553565 25102 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0912 02:47:52.177983 25102 solver.cpp:228] Iteration 4800, loss = 0.00909275
I0912 02:47:52.178105 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996726
I0912 02:47:52.178122 25102 solver.cpp:244]     Train net output #1: loss = 0.00909272 (* 1 = 0.00909272 loss)
I0912 02:47:52.178136 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997082
I0912 02:47:52.178144 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996095
I0912 02:47:52.178153 25102 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0912 02:48:08.801589 25102 solver.cpp:228] Iteration 4820, loss = 0.0168826
I0912 02:48:08.801631 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994446
I0912 02:48:08.801645 25102 solver.cpp:244]     Train net output #1: loss = 0.0168826 (* 1 = 0.0168826 loss)
I0912 02:48:08.801652 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987596
I0912 02:48:08.801658 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998694
I0912 02:48:08.801666 25102 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0912 02:48:25.417369 25102 solver.cpp:228] Iteration 4840, loss = 0.0131427
I0912 02:48:25.417474 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993569
I0912 02:48:25.417490 25102 solver.cpp:244]     Train net output #1: loss = 0.0131427 (* 1 = 0.0131427 loss)
I0912 02:48:25.417497 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990357
I0912 02:48:25.417505 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998298
I0912 02:48:25.417511 25102 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0912 02:48:42.044183 25102 solver.cpp:228] Iteration 4860, loss = 0.00577828
I0912 02:48:42.044225 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997752
I0912 02:48:42.044239 25102 solver.cpp:244]     Train net output #1: loss = 0.00577825 (* 1 = 0.00577825 loss)
I0912 02:48:42.044246 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997454
I0912 02:48:42.044251 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998231
I0912 02:48:42.044260 25102 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0912 02:48:58.671211 25102 solver.cpp:228] Iteration 4880, loss = 0.00765319
I0912 02:48:58.671324 25102 solver.cpp:244]     Train net output #0: accuracy = 0.996801
I0912 02:48:58.671339 25102 solver.cpp:244]     Train net output #1: loss = 0.00765316 (* 1 = 0.00765316 loss)
I0912 02:48:58.671344 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996408
I0912 02:48:58.671350 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997597
I0912 02:48:58.671356 25102 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0912 02:49:15.293541 25102 solver.cpp:228] Iteration 4900, loss = 0.0071317
I0912 02:49:15.293583 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997108
I0912 02:49:15.293598 25102 solver.cpp:244]     Train net output #1: loss = 0.00713167 (* 1 = 0.00713167 loss)
I0912 02:49:15.293606 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996283
I0912 02:49:15.293611 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998367
I0912 02:49:15.293618 25102 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0912 02:49:31.915585 25102 solver.cpp:228] Iteration 4920, loss = 0.0152311
I0912 02:49:31.915740 25102 solver.cpp:244]     Train net output #0: accuracy = 0.993056
I0912 02:49:31.915755 25102 solver.cpp:244]     Train net output #1: loss = 0.0152311 (* 1 = 0.0152311 loss)
I0912 02:49:31.915760 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992025
I0912 02:49:31.915766 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995243
I0912 02:49:31.915772 25102 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0912 02:49:48.566617 25102 solver.cpp:228] Iteration 4940, loss = 0.0127108
I0912 02:49:48.566660 25102 solver.cpp:244]     Train net output #0: accuracy = 0.994628
I0912 02:49:48.566675 25102 solver.cpp:244]     Train net output #1: loss = 0.0127108 (* 1 = 0.0127108 loss)
I0912 02:49:48.566682 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994655
I0912 02:49:48.566689 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994536
I0912 02:49:48.566696 25102 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0912 02:50:05.194723 25102 solver.cpp:228] Iteration 4960, loss = 0.00619216
I0912 02:50:05.194844 25102 solver.cpp:244]     Train net output #0: accuracy = 0.997423
I0912 02:50:05.194859 25102 solver.cpp:244]     Train net output #1: loss = 0.00619214 (* 1 = 0.00619214 loss)
I0912 02:50:05.194865 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997068
I0912 02:50:05.194870 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998351
I0912 02:50:05.194877 25102 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0912 02:50:21.823233 25102 solver.cpp:228] Iteration 4980, loss = 0.0072372
I0912 02:50:21.823276 25102 solver.cpp:244]     Train net output #0: accuracy = 0.99717
I0912 02:50:21.823290 25102 solver.cpp:244]     Train net output #1: loss = 0.00723718 (* 1 = 0.00723718 loss)
I0912 02:50:21.823297 25102 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997013
I0912 02:50:21.823303 25102 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998048
I0912 02:50:21.823312 25102 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0912 02:50:38.088030 25102 solver.cpp:454] Snapshotting to binary proto file pocwisc3/training_iter_5000.caffemodel
I0912 02:50:40.062135 25102 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc3/training_iter_5000.solverstate
I0912 02:50:40.659754 25102 solver.cpp:317] Iteration 5000, loss = 0.00702714
I0912 02:50:40.659801 25102 solver.cpp:322] Optimization Done.
I0912 02:50:40.659807 25102 caffe.cpp:254] Optimization Done.

2017-09-12 02:50:41,065 log.framework MainThread  INFO       caffe models found
pocwisc3/training_iter_5000.caffemodel
2017-09-12 02:50:41,066 log.framework MainThread  INFO       Caffe model found: pocwisc3/training_iter_5000.caffemodel
2017-09-12 02:50:42,664 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 02:50:42,804 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 02:50:42,943 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 02:50:43,081 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 02:50:43,231 log.framework MainThread  INFO       train file number: 27
2017-09-12 02:50:43,231 log.framework MainThread  INFO       test file number: 6
2017-09-12 02:50:43,231 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 02:50:43,231 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 02:50:43,232 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-09-12 02:50:43,232 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-09-12 02:50:43,232 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-09-12 02:50:43,233 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc4/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc4/training"
solver_mode: GPU

2017-09-12 02:50:43,234 log.framework MainThread  INFO       caffe training step
2017-09-12 02:50:43,234 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc4/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-09-12 04:00:02,922 log.framework MainThread  INFO       I0912 02:50:43.272858 25179 caffe.cpp:217] Using GPUs 0
I0912 02:50:43.285312 25179 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0912 02:50:44.369638 25179 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc4/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc4/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0912 02:50:44.369814 25179 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc4/caffe/model_segnet_final/train.prototxt
I0912 02:50:44.372615 25179 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc4/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 02:50:44.373121 25179 layer_factory.hpp:77] Creating layer data
I0912 02:50:44.373142 25179 net.cpp:100] Creating Layer data
I0912 02:50:44.373152 25179 net.cpp:408] data -> data
I0912 02:50:44.373183 25179 net.cpp:408] data -> label
I0912 02:50:44.373204 25179 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc4/HDF5Files/train_combined.txt
I0912 02:50:44.373260 25179 hdf5_data_layer.cpp:93] Number of HDF5 files: 27
I0912 02:50:44.374474 25179 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0912 02:50:44.399624 25179 net.cpp:150] Setting up data
I0912 02:50:44.399653 25179 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 02:50:44.399667 25179 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 02:50:44.399677 25179 net.cpp:165] Memory required for data: 24883200
I0912 02:50:44.399685 25179 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 02:50:44.399701 25179 net.cpp:100] Creating Layer label_data_1_split
I0912 02:50:44.399709 25179 net.cpp:434] label_data_1_split <- label
I0912 02:50:44.399727 25179 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 02:50:44.399740 25179 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 02:50:44.399783 25179 net.cpp:150] Setting up label_data_1_split
I0912 02:50:44.399791 25179 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 02:50:44.399798 25179 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 02:50:44.399801 25179 net.cpp:165] Memory required for data: 30412800
I0912 02:50:44.399806 25179 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 02:50:44.399827 25179 net.cpp:100] Creating Layer conv1_1_1
I0912 02:50:44.399833 25179 net.cpp:434] conv1_1_1 <- data
I0912 02:50:44.399839 25179 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 02:50:44.917948 25179 net.cpp:150] Setting up conv1_1_1
I0912 02:50:44.917986 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:44.917991 25179 net.cpp:165] Memory required for data: 207360000
I0912 02:50:44.918018 25179 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 02:50:44.918035 25179 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 02:50:44.918041 25179 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 02:50:44.918050 25179 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 02:50:44.918448 25179 net.cpp:150] Setting up conv1_1_1_bn
I0912 02:50:44.918458 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:44.918468 25179 net.cpp:165] Memory required for data: 384307200
I0912 02:50:44.918481 25179 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 02:50:44.918494 25179 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 02:50:44.918500 25179 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 02:50:44.918505 25179 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 02:50:44.918556 25179 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 02:50:44.920145 25179 net.cpp:150] Setting up conv1_1_1_scale
I0912 02:50:44.920161 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:44.920168 25179 net.cpp:165] Memory required for data: 561254400
I0912 02:50:44.920177 25179 layer_factory.hpp:77] Creating layer relu1_1
I0912 02:50:44.920188 25179 net.cpp:100] Creating Layer relu1_1
I0912 02:50:44.920194 25179 net.cpp:434] relu1_1 <- conv1_1_1
I0912 02:50:44.920200 25179 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 02:50:44.920430 25179 net.cpp:150] Setting up relu1_1
I0912 02:50:44.920440 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:44.920445 25179 net.cpp:165] Memory required for data: 738201600
I0912 02:50:44.920449 25179 layer_factory.hpp:77] Creating layer conv1_2
I0912 02:50:44.920462 25179 net.cpp:100] Creating Layer conv1_2
I0912 02:50:44.920467 25179 net.cpp:434] conv1_2 <- conv1_1_1
I0912 02:50:44.920475 25179 net.cpp:408] conv1_2 -> conv1_2
I0912 02:50:44.924654 25179 net.cpp:150] Setting up conv1_2
I0912 02:50:44.924671 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:44.924679 25179 net.cpp:165] Memory required for data: 915148800
I0912 02:50:44.924691 25179 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 02:50:44.924700 25179 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 02:50:44.924708 25179 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 02:50:44.924713 25179 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 02:50:44.926226 25179 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 02:50:44.926244 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:44.926251 25179 net.cpp:165] Memory required for data: 1092096000
I0912 02:50:44.926261 25179 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 02:50:44.926273 25179 net.cpp:100] Creating Layer conv1_2_scale
I0912 02:50:44.926278 25179 net.cpp:434] conv1_2_scale <- conv1_2
I0912 02:50:44.926285 25179 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 02:50:44.926329 25179 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 02:50:44.926705 25179 net.cpp:150] Setting up conv1_2_scale
I0912 02:50:44.926715 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:44.926720 25179 net.cpp:165] Memory required for data: 1269043200
I0912 02:50:44.926728 25179 layer_factory.hpp:77] Creating layer relu1_2
I0912 02:50:44.926735 25179 net.cpp:100] Creating Layer relu1_2
I0912 02:50:44.926740 25179 net.cpp:434] relu1_2 <- conv1_2
I0912 02:50:44.926746 25179 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 02:50:44.926944 25179 net.cpp:150] Setting up relu1_2
I0912 02:50:44.926955 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:44.926960 25179 net.cpp:165] Memory required for data: 1445990400
I0912 02:50:44.926964 25179 layer_factory.hpp:77] Creating layer pool1
I0912 02:50:44.926968 25179 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 02:50:44.926976 25179 net.cpp:100] Creating Layer pool1
I0912 02:50:44.926981 25179 net.cpp:434] pool1 <- conv1_2
I0912 02:50:44.926987 25179 net.cpp:408] pool1 -> pool1
I0912 02:50:44.926998 25179 net.cpp:408] pool1 -> pool1_mask
I0912 02:50:44.927054 25179 net.cpp:150] Setting up pool1
I0912 02:50:44.927063 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:44.927067 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:44.927073 25179 net.cpp:165] Memory required for data: 1534464000
I0912 02:50:44.927076 25179 layer_factory.hpp:77] Creating layer conv2_1
I0912 02:50:44.927086 25179 net.cpp:100] Creating Layer conv2_1
I0912 02:50:44.927091 25179 net.cpp:434] conv2_1 <- pool1
I0912 02:50:44.927098 25179 net.cpp:408] conv2_1 -> conv2_1
I0912 02:50:44.933157 25179 net.cpp:150] Setting up conv2_1
I0912 02:50:44.933176 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:44.933185 25179 net.cpp:165] Memory required for data: 1622937600
I0912 02:50:44.933194 25179 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 02:50:44.933203 25179 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 02:50:44.933212 25179 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 02:50:44.933218 25179 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 02:50:44.933450 25179 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 02:50:44.933460 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:44.933465 25179 net.cpp:165] Memory required for data: 1711411200
I0912 02:50:44.933476 25179 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 02:50:44.933501 25179 net.cpp:100] Creating Layer conv2_1_scale
I0912 02:50:44.933506 25179 net.cpp:434] conv2_1_scale <- conv2_1
I0912 02:50:44.933511 25179 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 02:50:44.933555 25179 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 02:50:44.933730 25179 net.cpp:150] Setting up conv2_1_scale
I0912 02:50:44.933740 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:44.933745 25179 net.cpp:165] Memory required for data: 1799884800
I0912 02:50:44.933753 25179 layer_factory.hpp:77] Creating layer relu2_1
I0912 02:50:44.933760 25179 net.cpp:100] Creating Layer relu2_1
I0912 02:50:44.933765 25179 net.cpp:434] relu2_1 <- conv2_1
I0912 02:50:44.933771 25179 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 02:50:44.934794 25179 net.cpp:150] Setting up relu2_1
I0912 02:50:44.934809 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:44.934815 25179 net.cpp:165] Memory required for data: 1888358400
I0912 02:50:44.934819 25179 layer_factory.hpp:77] Creating layer conv2_2
I0912 02:50:44.934833 25179 net.cpp:100] Creating Layer conv2_2
I0912 02:50:44.934837 25179 net.cpp:434] conv2_2 <- conv2_1
I0912 02:50:44.934844 25179 net.cpp:408] conv2_2 -> conv2_2
I0912 02:50:44.942191 25179 net.cpp:150] Setting up conv2_2
I0912 02:50:44.942209 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:44.942224 25179 net.cpp:165] Memory required for data: 1976832000
I0912 02:50:44.942232 25179 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 02:50:44.942245 25179 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 02:50:44.942250 25179 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 02:50:44.942257 25179 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 02:50:44.942484 25179 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 02:50:44.942493 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:44.942503 25179 net.cpp:165] Memory required for data: 2065305600
I0912 02:50:44.942512 25179 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 02:50:44.942522 25179 net.cpp:100] Creating Layer conv2_2_scale
I0912 02:50:44.942526 25179 net.cpp:434] conv2_2_scale <- conv2_2
I0912 02:50:44.942533 25179 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 02:50:44.942574 25179 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 02:50:44.942749 25179 net.cpp:150] Setting up conv2_2_scale
I0912 02:50:44.942759 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:44.942764 25179 net.cpp:165] Memory required for data: 2153779200
I0912 02:50:44.942771 25179 layer_factory.hpp:77] Creating layer relu2_2
I0912 02:50:44.942780 25179 net.cpp:100] Creating Layer relu2_2
I0912 02:50:44.942785 25179 net.cpp:434] relu2_2 <- conv2_2
I0912 02:50:44.942790 25179 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 02:50:44.942983 25179 net.cpp:150] Setting up relu2_2
I0912 02:50:44.942994 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:44.942999 25179 net.cpp:165] Memory required for data: 2242252800
I0912 02:50:44.943003 25179 layer_factory.hpp:77] Creating layer pool2
I0912 02:50:44.943008 25179 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 02:50:44.943015 25179 net.cpp:100] Creating Layer pool2
I0912 02:50:44.943018 25179 net.cpp:434] pool2 <- conv2_2
I0912 02:50:44.943024 25179 net.cpp:408] pool2 -> pool2
I0912 02:50:44.943033 25179 net.cpp:408] pool2 -> pool2_mask
I0912 02:50:44.943078 25179 net.cpp:150] Setting up pool2
I0912 02:50:44.943085 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:44.943089 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:44.943094 25179 net.cpp:165] Memory required for data: 2286489600
I0912 02:50:44.943099 25179 layer_factory.hpp:77] Creating layer conv3_1
I0912 02:50:44.943107 25179 net.cpp:100] Creating Layer conv3_1
I0912 02:50:44.943112 25179 net.cpp:434] conv3_1 <- pool2
I0912 02:50:44.943120 25179 net.cpp:408] conv3_1 -> conv3_1
I0912 02:50:44.955265 25179 net.cpp:150] Setting up conv3_1
I0912 02:50:44.955296 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:44.955307 25179 net.cpp:165] Memory required for data: 2330726400
I0912 02:50:44.955314 25179 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 02:50:44.955324 25179 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 02:50:44.955333 25179 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 02:50:44.955339 25179 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 02:50:44.955552 25179 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 02:50:44.955561 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:44.955565 25179 net.cpp:165] Memory required for data: 2374963200
I0912 02:50:44.955579 25179 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 02:50:44.955587 25179 net.cpp:100] Creating Layer conv3_1_scale
I0912 02:50:44.955593 25179 net.cpp:434] conv3_1_scale <- conv3_1
I0912 02:50:44.955598 25179 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 02:50:44.955641 25179 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 02:50:44.955775 25179 net.cpp:150] Setting up conv3_1_scale
I0912 02:50:44.955783 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:44.955787 25179 net.cpp:165] Memory required for data: 2419200000
I0912 02:50:44.955795 25179 layer_factory.hpp:77] Creating layer relu3_1
I0912 02:50:44.955802 25179 net.cpp:100] Creating Layer relu3_1
I0912 02:50:44.955807 25179 net.cpp:434] relu3_1 <- conv3_1
I0912 02:50:44.955812 25179 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 02:50:44.956012 25179 net.cpp:150] Setting up relu3_1
I0912 02:50:44.956022 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:44.956027 25179 net.cpp:165] Memory required for data: 2463436800
I0912 02:50:44.956030 25179 layer_factory.hpp:77] Creating layer conv3_2
I0912 02:50:44.956041 25179 net.cpp:100] Creating Layer conv3_2
I0912 02:50:44.956046 25179 net.cpp:434] conv3_2 <- conv3_1
I0912 02:50:44.956053 25179 net.cpp:408] conv3_2 -> conv3_2
I0912 02:50:44.979101 25179 net.cpp:150] Setting up conv3_2
I0912 02:50:44.979120 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:44.979133 25179 net.cpp:165] Memory required for data: 2507673600
I0912 02:50:44.979142 25179 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 02:50:44.979151 25179 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 02:50:44.979157 25179 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 02:50:44.979163 25179 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 02:50:44.979375 25179 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 02:50:44.979384 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:44.979388 25179 net.cpp:165] Memory required for data: 2551910400
I0912 02:50:44.979396 25179 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 02:50:44.979410 25179 net.cpp:100] Creating Layer conv3_2_scale
I0912 02:50:44.979420 25179 net.cpp:434] conv3_2_scale <- conv3_2
I0912 02:50:44.979425 25179 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 02:50:44.979468 25179 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 02:50:44.979604 25179 net.cpp:150] Setting up conv3_2_scale
I0912 02:50:44.979612 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:44.979615 25179 net.cpp:165] Memory required for data: 2596147200
I0912 02:50:44.979622 25179 layer_factory.hpp:77] Creating layer relu3_2
I0912 02:50:44.979630 25179 net.cpp:100] Creating Layer relu3_2
I0912 02:50:44.979635 25179 net.cpp:434] relu3_2 <- conv3_2
I0912 02:50:44.979640 25179 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 02:50:44.979840 25179 net.cpp:150] Setting up relu3_2
I0912 02:50:44.979851 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:44.979856 25179 net.cpp:165] Memory required for data: 2640384000
I0912 02:50:44.979861 25179 layer_factory.hpp:77] Creating layer conv3_3
I0912 02:50:44.979871 25179 net.cpp:100] Creating Layer conv3_3
I0912 02:50:44.979876 25179 net.cpp:434] conv3_3 <- conv3_2
I0912 02:50:44.979883 25179 net.cpp:408] conv3_3 -> conv3_3
I0912 02:50:45.003034 25179 net.cpp:150] Setting up conv3_3
I0912 02:50:45.003067 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.003077 25179 net.cpp:165] Memory required for data: 2684620800
I0912 02:50:45.003085 25179 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 02:50:45.003095 25179 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 02:50:45.003103 25179 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 02:50:45.003109 25179 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 02:50:45.003324 25179 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 02:50:45.003334 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.003343 25179 net.cpp:165] Memory required for data: 2728857600
I0912 02:50:45.003352 25179 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 02:50:45.003361 25179 net.cpp:100] Creating Layer conv3_3_scale
I0912 02:50:45.003366 25179 net.cpp:434] conv3_3_scale <- conv3_3
I0912 02:50:45.003372 25179 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 02:50:45.003415 25179 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 02:50:45.003554 25179 net.cpp:150] Setting up conv3_3_scale
I0912 02:50:45.003564 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.003569 25179 net.cpp:165] Memory required for data: 2773094400
I0912 02:50:45.003576 25179 layer_factory.hpp:77] Creating layer relu3_3
I0912 02:50:45.003583 25179 net.cpp:100] Creating Layer relu3_3
I0912 02:50:45.003589 25179 net.cpp:434] relu3_3 <- conv3_3
I0912 02:50:45.003594 25179 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 02:50:45.003794 25179 net.cpp:150] Setting up relu3_3
I0912 02:50:45.003804 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.003809 25179 net.cpp:165] Memory required for data: 2817331200
I0912 02:50:45.003813 25179 layer_factory.hpp:77] Creating layer pool3
I0912 02:50:45.003818 25179 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 02:50:45.003829 25179 net.cpp:100] Creating Layer pool3
I0912 02:50:45.003834 25179 net.cpp:434] pool3 <- conv3_3
I0912 02:50:45.003839 25179 net.cpp:408] pool3 -> pool3
I0912 02:50:45.003849 25179 net.cpp:408] pool3 -> pool3_mask
I0912 02:50:45.003896 25179 net.cpp:150] Setting up pool3
I0912 02:50:45.003904 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:45.003912 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:45.003916 25179 net.cpp:165] Memory required for data: 2839449600
I0912 02:50:45.003921 25179 layer_factory.hpp:77] Creating layer conv4_1
I0912 02:50:45.003931 25179 net.cpp:100] Creating Layer conv4_1
I0912 02:50:45.003937 25179 net.cpp:434] conv4_1 <- pool3
I0912 02:50:45.003942 25179 net.cpp:408] conv4_1 -> conv4_1
I0912 02:50:45.049819 25179 net.cpp:150] Setting up conv4_1
I0912 02:50:45.049839 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.049849 25179 net.cpp:165] Memory required for data: 2861568000
I0912 02:50:45.049859 25179 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 02:50:45.049868 25179 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 02:50:45.049876 25179 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 02:50:45.049882 25179 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 02:50:45.050096 25179 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 02:50:45.050106 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.050109 25179 net.cpp:165] Memory required for data: 2883686400
I0912 02:50:45.050118 25179 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 02:50:45.050130 25179 net.cpp:100] Creating Layer conv4_1_scale
I0912 02:50:45.050135 25179 net.cpp:434] conv4_1_scale <- conv4_1
I0912 02:50:45.050140 25179 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 02:50:45.050181 25179 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 02:50:45.050305 25179 net.cpp:150] Setting up conv4_1_scale
I0912 02:50:45.050314 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.050318 25179 net.cpp:165] Memory required for data: 2905804800
I0912 02:50:45.050324 25179 layer_factory.hpp:77] Creating layer relu4_1
I0912 02:50:45.050346 25179 net.cpp:100] Creating Layer relu4_1
I0912 02:50:45.050351 25179 net.cpp:434] relu4_1 <- conv4_1
I0912 02:50:45.050357 25179 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 02:50:45.050565 25179 net.cpp:150] Setting up relu4_1
I0912 02:50:45.050575 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.050580 25179 net.cpp:165] Memory required for data: 2927923200
I0912 02:50:45.050583 25179 layer_factory.hpp:77] Creating layer conv4_2
I0912 02:50:45.050595 25179 net.cpp:100] Creating Layer conv4_2
I0912 02:50:45.050601 25179 net.cpp:434] conv4_2 <- conv4_1
I0912 02:50:45.050607 25179 net.cpp:408] conv4_2 -> conv4_2
I0912 02:50:45.133922 25179 net.cpp:150] Setting up conv4_2
I0912 02:50:45.133940 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.133945 25179 net.cpp:165] Memory required for data: 2950041600
I0912 02:50:45.133954 25179 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 02:50:45.133961 25179 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 02:50:45.133965 25179 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 02:50:45.133972 25179 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 02:50:45.134174 25179 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 02:50:45.134184 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.134187 25179 net.cpp:165] Memory required for data: 2972160000
I0912 02:50:45.134196 25179 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 02:50:45.134204 25179 net.cpp:100] Creating Layer conv4_2_scale
I0912 02:50:45.134213 25179 net.cpp:434] conv4_2_scale <- conv4_2
I0912 02:50:45.134219 25179 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 02:50:45.134258 25179 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 02:50:45.134380 25179 net.cpp:150] Setting up conv4_2_scale
I0912 02:50:45.134388 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.134392 25179 net.cpp:165] Memory required for data: 2994278400
I0912 02:50:45.134398 25179 layer_factory.hpp:77] Creating layer relu4_2
I0912 02:50:45.134410 25179 net.cpp:100] Creating Layer relu4_2
I0912 02:50:45.134416 25179 net.cpp:434] relu4_2 <- conv4_2
I0912 02:50:45.134421 25179 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 02:50:45.135473 25179 net.cpp:150] Setting up relu4_2
I0912 02:50:45.135488 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.135493 25179 net.cpp:165] Memory required for data: 3016396800
I0912 02:50:45.135498 25179 layer_factory.hpp:77] Creating layer conv4_3
I0912 02:50:45.135509 25179 net.cpp:100] Creating Layer conv4_3
I0912 02:50:45.135514 25179 net.cpp:434] conv4_3 <- conv4_2
I0912 02:50:45.135524 25179 net.cpp:408] conv4_3 -> conv4_3
I0912 02:50:45.218921 25179 net.cpp:150] Setting up conv4_3
I0912 02:50:45.218940 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.218945 25179 net.cpp:165] Memory required for data: 3038515200
I0912 02:50:45.218968 25179 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 02:50:45.218981 25179 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 02:50:45.218988 25179 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 02:50:45.218994 25179 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 02:50:45.219215 25179 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 02:50:45.219224 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.219228 25179 net.cpp:165] Memory required for data: 3060633600
I0912 02:50:45.219236 25179 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 02:50:45.219247 25179 net.cpp:100] Creating Layer conv4_3_scale
I0912 02:50:45.219255 25179 net.cpp:434] conv4_3_scale <- conv4_3
I0912 02:50:45.219260 25179 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 02:50:45.219305 25179 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 02:50:45.219441 25179 net.cpp:150] Setting up conv4_3_scale
I0912 02:50:45.219450 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.219455 25179 net.cpp:165] Memory required for data: 3082752000
I0912 02:50:45.219460 25179 layer_factory.hpp:77] Creating layer relu4_3
I0912 02:50:45.219485 25179 net.cpp:100] Creating Layer relu4_3
I0912 02:50:45.219491 25179 net.cpp:434] relu4_3 <- conv4_3
I0912 02:50:45.219496 25179 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 02:50:45.219704 25179 net.cpp:150] Setting up relu4_3
I0912 02:50:45.219714 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.219719 25179 net.cpp:165] Memory required for data: 3104870400
I0912 02:50:45.219723 25179 layer_factory.hpp:77] Creating layer pool4
I0912 02:50:45.219727 25179 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 02:50:45.219735 25179 net.cpp:100] Creating Layer pool4
I0912 02:50:45.219740 25179 net.cpp:434] pool4 <- conv4_3
I0912 02:50:45.219746 25179 net.cpp:408] pool4 -> pool4
I0912 02:50:45.219758 25179 net.cpp:408] pool4 -> pool4_mask
I0912 02:50:45.219807 25179 net.cpp:150] Setting up pool4
I0912 02:50:45.219815 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.219820 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.219825 25179 net.cpp:165] Memory required for data: 3116175360
I0912 02:50:45.219827 25179 layer_factory.hpp:77] Creating layer conv5_1
I0912 02:50:45.219838 25179 net.cpp:100] Creating Layer conv5_1
I0912 02:50:45.219844 25179 net.cpp:434] conv5_1 <- pool4
I0912 02:50:45.219852 25179 net.cpp:408] conv5_1 -> conv5_1
I0912 02:50:45.305333 25179 net.cpp:150] Setting up conv5_1
I0912 02:50:45.305356 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.305361 25179 net.cpp:165] Memory required for data: 3121827840
I0912 02:50:45.305392 25179 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 02:50:45.305408 25179 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 02:50:45.305418 25179 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 02:50:45.305433 25179 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 02:50:45.305663 25179 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 02:50:45.305672 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.305676 25179 net.cpp:165] Memory required for data: 3127480320
I0912 02:50:45.305685 25179 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 02:50:45.305696 25179 net.cpp:100] Creating Layer conv5_1_scale
I0912 02:50:45.305701 25179 net.cpp:434] conv5_1_scale <- conv5_1
I0912 02:50:45.305709 25179 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 02:50:45.305755 25179 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 02:50:45.305881 25179 net.cpp:150] Setting up conv5_1_scale
I0912 02:50:45.305891 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.305896 25179 net.cpp:165] Memory required for data: 3133132800
I0912 02:50:45.305902 25179 layer_factory.hpp:77] Creating layer relu5_1
I0912 02:50:45.305912 25179 net.cpp:100] Creating Layer relu5_1
I0912 02:50:45.305917 25179 net.cpp:434] relu5_1 <- conv5_1
I0912 02:50:45.305920 25179 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 02:50:45.306129 25179 net.cpp:150] Setting up relu5_1
I0912 02:50:45.306141 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.306146 25179 net.cpp:165] Memory required for data: 3138785280
I0912 02:50:45.306151 25179 layer_factory.hpp:77] Creating layer conv5_2
I0912 02:50:45.306166 25179 net.cpp:100] Creating Layer conv5_2
I0912 02:50:45.306171 25179 net.cpp:434] conv5_2 <- conv5_1
I0912 02:50:45.306179 25179 net.cpp:408] conv5_2 -> conv5_2
I0912 02:50:45.389580 25179 net.cpp:150] Setting up conv5_2
I0912 02:50:45.389598 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.389602 25179 net.cpp:165] Memory required for data: 3144437760
I0912 02:50:45.389611 25179 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 02:50:45.389621 25179 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 02:50:45.389631 25179 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 02:50:45.389641 25179 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 02:50:45.389861 25179 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 02:50:45.389870 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.389891 25179 net.cpp:165] Memory required for data: 3150090240
I0912 02:50:45.389901 25179 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 02:50:45.389912 25179 net.cpp:100] Creating Layer conv5_2_scale
I0912 02:50:45.389920 25179 net.cpp:434] conv5_2_scale <- conv5_2
I0912 02:50:45.389930 25179 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 02:50:45.389981 25179 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 02:50:45.390108 25179 net.cpp:150] Setting up conv5_2_scale
I0912 02:50:45.390117 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.390120 25179 net.cpp:165] Memory required for data: 3155742720
I0912 02:50:45.390127 25179 layer_factory.hpp:77] Creating layer relu5_2
I0912 02:50:45.390135 25179 net.cpp:100] Creating Layer relu5_2
I0912 02:50:45.390141 25179 net.cpp:434] relu5_2 <- conv5_2
I0912 02:50:45.390144 25179 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 02:50:45.390352 25179 net.cpp:150] Setting up relu5_2
I0912 02:50:45.390362 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.390367 25179 net.cpp:165] Memory required for data: 3161395200
I0912 02:50:45.390372 25179 layer_factory.hpp:77] Creating layer conv5_3
I0912 02:50:45.390386 25179 net.cpp:100] Creating Layer conv5_3
I0912 02:50:45.390391 25179 net.cpp:434] conv5_3 <- conv5_2
I0912 02:50:45.390403 25179 net.cpp:408] conv5_3 -> conv5_3
I0912 02:50:45.473798 25179 net.cpp:150] Setting up conv5_3
I0912 02:50:45.473817 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.473821 25179 net.cpp:165] Memory required for data: 3167047680
I0912 02:50:45.473829 25179 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 02:50:45.473845 25179 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 02:50:45.473853 25179 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 02:50:45.473860 25179 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 02:50:45.474086 25179 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 02:50:45.474094 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.474097 25179 net.cpp:165] Memory required for data: 3172700160
I0912 02:50:45.474112 25179 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 02:50:45.474124 25179 net.cpp:100] Creating Layer conv5_3_scale
I0912 02:50:45.474129 25179 net.cpp:434] conv5_3_scale <- conv5_3
I0912 02:50:45.474134 25179 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 02:50:45.474182 25179 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 02:50:45.474309 25179 net.cpp:150] Setting up conv5_3_scale
I0912 02:50:45.474318 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.474323 25179 net.cpp:165] Memory required for data: 3178352640
I0912 02:50:45.474330 25179 layer_factory.hpp:77] Creating layer relu5_3
I0912 02:50:45.474340 25179 net.cpp:100] Creating Layer relu5_3
I0912 02:50:45.474345 25179 net.cpp:434] relu5_3 <- conv5_3
I0912 02:50:45.474350 25179 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 02:50:45.474563 25179 net.cpp:150] Setting up relu5_3
I0912 02:50:45.474573 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.474578 25179 net.cpp:165] Memory required for data: 3184005120
I0912 02:50:45.474583 25179 layer_factory.hpp:77] Creating layer pool5
I0912 02:50:45.474589 25179 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 02:50:45.474599 25179 net.cpp:100] Creating Layer pool5
I0912 02:50:45.474604 25179 net.cpp:434] pool5 <- conv5_3
I0912 02:50:45.474614 25179 net.cpp:408] pool5 -> pool5
I0912 02:50:45.474623 25179 net.cpp:408] pool5 -> pool5_mask
I0912 02:50:45.474674 25179 net.cpp:150] Setting up pool5
I0912 02:50:45.474683 25179 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 02:50:45.474687 25179 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 02:50:45.474690 25179 net.cpp:165] Memory required for data: 3186954240
I0912 02:50:45.474695 25179 layer_factory.hpp:77] Creating layer upsample5
I0912 02:50:45.474710 25179 net.cpp:100] Creating Layer upsample5
I0912 02:50:45.474715 25179 net.cpp:434] upsample5 <- pool5
I0912 02:50:45.474736 25179 net.cpp:434] upsample5 <- pool5_mask
I0912 02:50:45.474745 25179 net.cpp:408] upsample5 -> pool5_D
I0912 02:50:45.474786 25179 net.cpp:150] Setting up upsample5
I0912 02:50:45.474793 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.474798 25179 net.cpp:165] Memory required for data: 3192606720
I0912 02:50:45.474802 25179 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 02:50:45.474813 25179 net.cpp:100] Creating Layer conv5_3_D
I0912 02:50:45.474818 25179 net.cpp:434] conv5_3_D <- pool5_D
I0912 02:50:45.474826 25179 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 02:50:45.559126 25179 net.cpp:150] Setting up conv5_3_D
I0912 02:50:45.559145 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.559150 25179 net.cpp:165] Memory required for data: 3198259200
I0912 02:50:45.559159 25179 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 02:50:45.559168 25179 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 02:50:45.559172 25179 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 02:50:45.559180 25179 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 02:50:45.559406 25179 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 02:50:45.559415 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.559418 25179 net.cpp:165] Memory required for data: 3203911680
I0912 02:50:45.559432 25179 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 02:50:45.559440 25179 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 02:50:45.559449 25179 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 02:50:45.559455 25179 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 02:50:45.559509 25179 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 02:50:45.559638 25179 net.cpp:150] Setting up conv5_3_D_scale
I0912 02:50:45.559646 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.559649 25179 net.cpp:165] Memory required for data: 3209564160
I0912 02:50:45.559656 25179 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 02:50:45.559665 25179 net.cpp:100] Creating Layer relu5_3_D
I0912 02:50:45.559670 25179 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 02:50:45.559675 25179 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 02:50:45.559891 25179 net.cpp:150] Setting up relu5_3_D
I0912 02:50:45.559902 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.559907 25179 net.cpp:165] Memory required for data: 3215216640
I0912 02:50:45.559911 25179 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 02:50:45.559942 25179 net.cpp:100] Creating Layer conv5_2_D
I0912 02:50:45.559948 25179 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 02:50:45.559957 25179 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 02:50:45.643400 25179 net.cpp:150] Setting up conv5_2_D
I0912 02:50:45.643419 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.643424 25179 net.cpp:165] Memory required for data: 3220869120
I0912 02:50:45.643432 25179 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 02:50:45.643442 25179 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 02:50:45.643446 25179 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 02:50:45.643452 25179 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 02:50:45.643681 25179 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 02:50:45.643690 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.643694 25179 net.cpp:165] Memory required for data: 3226521600
I0912 02:50:45.643704 25179 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 02:50:45.643714 25179 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 02:50:45.643723 25179 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 02:50:45.643730 25179 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 02:50:45.643780 25179 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 02:50:45.643909 25179 net.cpp:150] Setting up conv5_2_D_scale
I0912 02:50:45.643918 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.643921 25179 net.cpp:165] Memory required for data: 3232174080
I0912 02:50:45.643946 25179 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 02:50:45.643956 25179 net.cpp:100] Creating Layer relu5_2_D
I0912 02:50:45.643961 25179 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 02:50:45.643966 25179 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 02:50:45.645046 25179 net.cpp:150] Setting up relu5_2_D
I0912 02:50:45.645062 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.645067 25179 net.cpp:165] Memory required for data: 3237826560
I0912 02:50:45.645071 25179 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 02:50:45.645089 25179 net.cpp:100] Creating Layer conv5_1_D
I0912 02:50:45.645095 25179 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 02:50:45.645102 25179 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 02:50:45.728545 25179 net.cpp:150] Setting up conv5_1_D
I0912 02:50:45.728564 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.728569 25179 net.cpp:165] Memory required for data: 3243479040
I0912 02:50:45.728576 25179 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 02:50:45.728585 25179 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 02:50:45.728593 25179 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 02:50:45.728602 25179 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 02:50:45.728840 25179 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 02:50:45.728849 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.728852 25179 net.cpp:165] Memory required for data: 3249131520
I0912 02:50:45.728863 25179 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 02:50:45.728873 25179 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 02:50:45.728880 25179 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 02:50:45.728886 25179 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 02:50:45.728940 25179 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 02:50:45.729073 25179 net.cpp:150] Setting up conv5_1_D_scale
I0912 02:50:45.729081 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.729085 25179 net.cpp:165] Memory required for data: 3254784000
I0912 02:50:45.729091 25179 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 02:50:45.729102 25179 net.cpp:100] Creating Layer relu5_1_D
I0912 02:50:45.729107 25179 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 02:50:45.729112 25179 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 02:50:45.729337 25179 net.cpp:150] Setting up relu5_1_D
I0912 02:50:45.729348 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:45.729353 25179 net.cpp:165] Memory required for data: 3260436480
I0912 02:50:45.729357 25179 layer_factory.hpp:77] Creating layer upsample4
I0912 02:50:45.729387 25179 net.cpp:100] Creating Layer upsample4
I0912 02:50:45.729393 25179 net.cpp:434] upsample4 <- conv5_1_D
I0912 02:50:45.729399 25179 net.cpp:434] upsample4 <- pool4_mask
I0912 02:50:45.729405 25179 net.cpp:408] upsample4 -> pool4_D
I0912 02:50:45.729444 25179 net.cpp:150] Setting up upsample4
I0912 02:50:45.729451 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.729455 25179 net.cpp:165] Memory required for data: 3282554880
I0912 02:50:45.729461 25179 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 02:50:45.729473 25179 net.cpp:100] Creating Layer conv4_3_D
I0912 02:50:45.729480 25179 net.cpp:434] conv4_3_D <- pool4_D
I0912 02:50:45.729487 25179 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 02:50:45.812939 25179 net.cpp:150] Setting up conv4_3_D
I0912 02:50:45.812959 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.812963 25179 net.cpp:165] Memory required for data: 3304673280
I0912 02:50:45.812973 25179 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 02:50:45.812989 25179 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 02:50:45.812996 25179 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 02:50:45.813004 25179 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 02:50:45.813242 25179 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 02:50:45.813251 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.813275 25179 net.cpp:165] Memory required for data: 3326791680
I0912 02:50:45.813285 25179 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 02:50:45.813300 25179 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 02:50:45.813305 25179 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 02:50:45.813311 25179 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 02:50:45.813359 25179 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 02:50:45.813525 25179 net.cpp:150] Setting up conv4_3_D_scale
I0912 02:50:45.813537 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.813541 25179 net.cpp:165] Memory required for data: 3348910080
I0912 02:50:45.813549 25179 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 02:50:45.813556 25179 net.cpp:100] Creating Layer relu4_3_D
I0912 02:50:45.813561 25179 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 02:50:45.813571 25179 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 02:50:45.813779 25179 net.cpp:150] Setting up relu4_3_D
I0912 02:50:45.813789 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.813794 25179 net.cpp:165] Memory required for data: 3371028480
I0912 02:50:45.813798 25179 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 02:50:45.813813 25179 net.cpp:100] Creating Layer conv4_2_D
I0912 02:50:45.813818 25179 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 02:50:45.813827 25179 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 02:50:45.897301 25179 net.cpp:150] Setting up conv4_2_D
I0912 02:50:45.897320 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.897323 25179 net.cpp:165] Memory required for data: 3393146880
I0912 02:50:45.897331 25179 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 02:50:45.897343 25179 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 02:50:45.897348 25179 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 02:50:45.897354 25179 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 02:50:45.897613 25179 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 02:50:45.897624 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.897629 25179 net.cpp:165] Memory required for data: 3415265280
I0912 02:50:45.897639 25179 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 02:50:45.897650 25179 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 02:50:45.897658 25179 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 02:50:45.897663 25179 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 02:50:45.897713 25179 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 02:50:45.897861 25179 net.cpp:150] Setting up conv4_2_D_scale
I0912 02:50:45.897871 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.897873 25179 net.cpp:165] Memory required for data: 3437383680
I0912 02:50:45.897881 25179 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 02:50:45.897891 25179 net.cpp:100] Creating Layer relu4_2_D
I0912 02:50:45.897895 25179 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 02:50:45.897900 25179 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 02:50:45.898109 25179 net.cpp:150] Setting up relu4_2_D
I0912 02:50:45.898119 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:45.898124 25179 net.cpp:165] Memory required for data: 3459502080
I0912 02:50:45.898128 25179 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 02:50:45.898146 25179 net.cpp:100] Creating Layer conv4_1_D
I0912 02:50:45.898151 25179 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 02:50:45.898159 25179 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 02:50:45.941889 25179 net.cpp:150] Setting up conv4_1_D
I0912 02:50:45.941906 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:45.941917 25179 net.cpp:165] Memory required for data: 3470561280
I0912 02:50:45.941926 25179 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 02:50:45.941937 25179 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 02:50:45.941946 25179 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 02:50:45.941951 25179 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 02:50:45.942190 25179 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 02:50:45.942215 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:45.942224 25179 net.cpp:165] Memory required for data: 3481620480
I0912 02:50:45.942260 25179 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 02:50:45.942270 25179 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 02:50:45.942276 25179 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 02:50:45.942282 25179 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 02:50:45.942337 25179 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 02:50:45.942477 25179 net.cpp:150] Setting up conv4_1_D_scale
I0912 02:50:45.942487 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:45.942490 25179 net.cpp:165] Memory required for data: 3492679680
I0912 02:50:45.942497 25179 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 02:50:45.942507 25179 net.cpp:100] Creating Layer relu4_1_D
I0912 02:50:45.942512 25179 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 02:50:45.942517 25179 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 02:50:45.942739 25179 net.cpp:150] Setting up relu4_1_D
I0912 02:50:45.942750 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:45.942755 25179 net.cpp:165] Memory required for data: 3503738880
I0912 02:50:45.942759 25179 layer_factory.hpp:77] Creating layer upsample3
I0912 02:50:45.942766 25179 net.cpp:100] Creating Layer upsample3
I0912 02:50:45.942771 25179 net.cpp:434] upsample3 <- conv4_1_D
I0912 02:50:45.942777 25179 net.cpp:434] upsample3 <- pool3_mask
I0912 02:50:45.942786 25179 net.cpp:408] upsample3 -> pool3_D
I0912 02:50:45.942796 25179 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 02:50:45.942827 25179 net.cpp:150] Setting up upsample3
I0912 02:50:45.942837 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.942842 25179 net.cpp:165] Memory required for data: 3547975680
I0912 02:50:45.942847 25179 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 02:50:45.942860 25179 net.cpp:100] Creating Layer conv3_3_D
I0912 02:50:45.942865 25179 net.cpp:434] conv3_3_D <- pool3_D
I0912 02:50:45.942873 25179 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 02:50:45.966306 25179 net.cpp:150] Setting up conv3_3_D
I0912 02:50:45.966325 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.966334 25179 net.cpp:165] Memory required for data: 3592212480
I0912 02:50:45.966346 25179 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 02:50:45.966356 25179 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 02:50:45.966364 25179 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 02:50:45.966372 25179 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 02:50:45.966631 25179 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 02:50:45.966640 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.966650 25179 net.cpp:165] Memory required for data: 3636449280
I0912 02:50:45.966660 25179 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 02:50:45.966670 25179 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 02:50:45.966675 25179 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 02:50:45.966681 25179 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 02:50:45.966730 25179 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 02:50:45.966897 25179 net.cpp:150] Setting up conv3_3_D_scale
I0912 02:50:45.966905 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.966909 25179 net.cpp:165] Memory required for data: 3680686080
I0912 02:50:45.966915 25179 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 02:50:45.966925 25179 net.cpp:100] Creating Layer relu3_3_D
I0912 02:50:45.966930 25179 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 02:50:45.966935 25179 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 02:50:45.967151 25179 net.cpp:150] Setting up relu3_3_D
I0912 02:50:45.967162 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.967166 25179 net.cpp:165] Memory required for data: 3724922880
I0912 02:50:45.967186 25179 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 02:50:45.967201 25179 net.cpp:100] Creating Layer conv3_2_D
I0912 02:50:45.967207 25179 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 02:50:45.967213 25179 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 02:50:45.990675 25179 net.cpp:150] Setting up conv3_2_D
I0912 02:50:45.990694 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.990706 25179 net.cpp:165] Memory required for data: 3769159680
I0912 02:50:45.990715 25179 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 02:50:45.990726 25179 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 02:50:45.990736 25179 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 02:50:45.990742 25179 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 02:50:45.991001 25179 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 02:50:45.991010 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.991014 25179 net.cpp:165] Memory required for data: 3813396480
I0912 02:50:45.991022 25179 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 02:50:45.991034 25179 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 02:50:45.991040 25179 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 02:50:45.991046 25179 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 02:50:45.991096 25179 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 02:50:45.991261 25179 net.cpp:150] Setting up conv3_2_D_scale
I0912 02:50:45.991271 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.991274 25179 net.cpp:165] Memory required for data: 3857633280
I0912 02:50:45.991281 25179 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 02:50:45.991289 25179 net.cpp:100] Creating Layer relu3_2_D
I0912 02:50:45.991294 25179 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 02:50:45.991302 25179 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 02:50:45.992401 25179 net.cpp:150] Setting up relu3_2_D
I0912 02:50:45.992416 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:45.992421 25179 net.cpp:165] Memory required for data: 3901870080
I0912 02:50:45.992426 25179 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 02:50:45.992442 25179 net.cpp:100] Creating Layer conv3_1_D
I0912 02:50:45.992449 25179 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 02:50:45.992457 25179 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 02:50:46.006171 25179 net.cpp:150] Setting up conv3_1_D
I0912 02:50:46.006189 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:46.006201 25179 net.cpp:165] Memory required for data: 3923988480
I0912 02:50:46.006209 25179 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 02:50:46.006218 25179 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 02:50:46.006227 25179 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 02:50:46.006233 25179 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 02:50:46.006495 25179 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 02:50:46.006505 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:46.006508 25179 net.cpp:165] Memory required for data: 3946106880
I0912 02:50:46.006517 25179 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 02:50:46.006531 25179 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 02:50:46.006536 25179 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 02:50:46.006541 25179 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 02:50:46.006592 25179 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 02:50:46.006760 25179 net.cpp:150] Setting up conv3_1_D_scale
I0912 02:50:46.006770 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:46.006773 25179 net.cpp:165] Memory required for data: 3968225280
I0912 02:50:46.006780 25179 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 02:50:46.006790 25179 net.cpp:100] Creating Layer relu3_1_D
I0912 02:50:46.006795 25179 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 02:50:46.006803 25179 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 02:50:46.007030 25179 net.cpp:150] Setting up relu3_1_D
I0912 02:50:46.007053 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:46.007058 25179 net.cpp:165] Memory required for data: 3990343680
I0912 02:50:46.007062 25179 layer_factory.hpp:77] Creating layer upsample2
I0912 02:50:46.007069 25179 net.cpp:100] Creating Layer upsample2
I0912 02:50:46.007074 25179 net.cpp:434] upsample2 <- conv3_1_D
I0912 02:50:46.007081 25179 net.cpp:434] upsample2 <- pool2_mask
I0912 02:50:46.007089 25179 net.cpp:408] upsample2 -> pool2_D
I0912 02:50:46.007099 25179 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 02:50:46.007133 25179 net.cpp:150] Setting up upsample2
I0912 02:50:46.007140 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.007144 25179 net.cpp:165] Memory required for data: 4078817280
I0912 02:50:46.007149 25179 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 02:50:46.007164 25179 net.cpp:100] Creating Layer conv2_2_D
I0912 02:50:46.007169 25179 net.cpp:434] conv2_2_D <- pool2_D
I0912 02:50:46.007174 25179 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 02:50:46.014837 25179 net.cpp:150] Setting up conv2_2_D
I0912 02:50:46.014856 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.014865 25179 net.cpp:165] Memory required for data: 4167290880
I0912 02:50:46.014874 25179 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 02:50:46.014888 25179 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 02:50:46.014894 25179 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 02:50:46.014899 25179 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 02:50:46.015200 25179 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 02:50:46.015210 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.015214 25179 net.cpp:165] Memory required for data: 4255764480
I0912 02:50:46.015224 25179 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 02:50:46.015235 25179 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 02:50:46.015240 25179 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 02:50:46.015245 25179 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 02:50:46.015297 25179 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 02:50:46.016726 25179 net.cpp:150] Setting up conv2_2_D_scale
I0912 02:50:46.016742 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.016747 25179 net.cpp:165] Memory required for data: 4344238080
I0912 02:50:46.016758 25179 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 02:50:46.016767 25179 net.cpp:100] Creating Layer relu2_2_D
I0912 02:50:46.016773 25179 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 02:50:46.016778 25179 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 02:50:46.017009 25179 net.cpp:150] Setting up relu2_2_D
I0912 02:50:46.017021 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.017026 25179 net.cpp:165] Memory required for data: 4432711680
I0912 02:50:46.017030 25179 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 02:50:46.017043 25179 net.cpp:100] Creating Layer conv2_1_D
I0912 02:50:46.017048 25179 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 02:50:46.017055 25179 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 02:50:46.022325 25179 net.cpp:150] Setting up conv2_1_D
I0912 02:50:46.022342 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:46.022351 25179 net.cpp:165] Memory required for data: 4476948480
I0912 02:50:46.022359 25179 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 02:50:46.022373 25179 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 02:50:46.022379 25179 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 02:50:46.022385 25179 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 02:50:46.022683 25179 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 02:50:46.022692 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:46.022697 25179 net.cpp:165] Memory required for data: 4521185280
I0912 02:50:46.022707 25179 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 02:50:46.022729 25179 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 02:50:46.022735 25179 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 02:50:46.022740 25179 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 02:50:46.022799 25179 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 02:50:46.023017 25179 net.cpp:150] Setting up conv2_1_D_scale
I0912 02:50:46.023030 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:46.023035 25179 net.cpp:165] Memory required for data: 4565422080
I0912 02:50:46.023041 25179 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 02:50:46.023049 25179 net.cpp:100] Creating Layer relu2_1_D
I0912 02:50:46.023054 25179 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 02:50:46.023059 25179 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 02:50:46.023286 25179 net.cpp:150] Setting up relu2_1_D
I0912 02:50:46.023299 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:46.023304 25179 net.cpp:165] Memory required for data: 4609658880
I0912 02:50:46.023308 25179 layer_factory.hpp:77] Creating layer upsample1
I0912 02:50:46.023317 25179 net.cpp:100] Creating Layer upsample1
I0912 02:50:46.023322 25179 net.cpp:434] upsample1 <- conv2_1_D
I0912 02:50:46.023326 25179 net.cpp:434] upsample1 <- pool1_mask
I0912 02:50:46.023332 25179 net.cpp:408] upsample1 -> pool1_D
I0912 02:50:46.023341 25179 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 02:50:46.023375 25179 net.cpp:150] Setting up upsample1
I0912 02:50:46.023383 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.023386 25179 net.cpp:165] Memory required for data: 4786606080
I0912 02:50:46.023391 25179 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 02:50:46.023402 25179 net.cpp:100] Creating Layer conv1_2_D
I0912 02:50:46.023408 25179 net.cpp:434] conv1_2_D <- pool1_D
I0912 02:50:46.023416 25179 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 02:50:46.027895 25179 net.cpp:150] Setting up conv1_2_D
I0912 02:50:46.027914 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.027926 25179 net.cpp:165] Memory required for data: 4963553280
I0912 02:50:46.027936 25179 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 02:50:46.027948 25179 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 02:50:46.027953 25179 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 02:50:46.027962 25179 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 02:50:46.028352 25179 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 02:50:46.028362 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.028367 25179 net.cpp:165] Memory required for data: 5140500480
I0912 02:50:46.028376 25179 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 02:50:46.028388 25179 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 02:50:46.028393 25179 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 02:50:46.028398 25179 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 02:50:46.028450 25179 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 02:50:46.030109 25179 net.cpp:150] Setting up conv1_2_D_scale
I0912 02:50:46.030127 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.030131 25179 net.cpp:165] Memory required for data: 5317447680
I0912 02:50:46.030140 25179 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 02:50:46.030150 25179 net.cpp:100] Creating Layer relu1_2_D
I0912 02:50:46.030156 25179 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 02:50:46.030161 25179 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 02:50:46.030397 25179 net.cpp:150] Setting up relu1_2_D
I0912 02:50:46.030408 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.030413 25179 net.cpp:165] Memory required for data: 5494394880
I0912 02:50:46.030417 25179 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 02:50:46.030431 25179 net.cpp:100] Creating Layer conv1_1_1_D
I0912 02:50:46.030436 25179 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 02:50:46.030459 25179 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 02:50:46.032518 25179 net.cpp:150] Setting up conv1_1_1_D
I0912 02:50:46.032538 25179 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 02:50:46.032544 25179 net.cpp:165] Memory required for data: 5499924480
I0912 02:50:46.032552 25179 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 02:50:46.032562 25179 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 02:50:46.032567 25179 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 02:50:46.032573 25179 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 02:50:46.032582 25179 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 02:50:46.032639 25179 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 02:50:46.032647 25179 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 02:50:46.032651 25179 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 02:50:46.032655 25179 net.cpp:165] Memory required for data: 5510983680
I0912 02:50:46.032662 25179 layer_factory.hpp:77] Creating layer loss
I0912 02:50:46.032681 25179 net.cpp:100] Creating Layer loss
I0912 02:50:46.032687 25179 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 02:50:46.032692 25179 net.cpp:434] loss <- label_data_1_split_0
I0912 02:50:46.032699 25179 net.cpp:408] loss -> loss
I0912 02:50:46.032718 25179 layer_factory.hpp:77] Creating layer loss
I0912 02:50:46.036715 25179 net.cpp:150] Setting up loss
I0912 02:50:46.036731 25179 net.cpp:157] Top shape: (1)
I0912 02:50:46.036736 25179 net.cpp:160]     with loss weight 1
I0912 02:50:46.036767 25179 net.cpp:165] Memory required for data: 5510983684
I0912 02:50:46.036773 25179 layer_factory.hpp:77] Creating layer accuracy
I0912 02:50:46.036790 25179 net.cpp:100] Creating Layer accuracy
I0912 02:50:46.036795 25179 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 02:50:46.036801 25179 net.cpp:434] accuracy <- label_data_1_split_1
I0912 02:50:46.036808 25179 net.cpp:408] accuracy -> accuracy
I0912 02:50:46.036818 25179 net.cpp:408] accuracy -> per_class_accuracy
I0912 02:50:46.036872 25179 net.cpp:150] Setting up accuracy
I0912 02:50:46.036880 25179 net.cpp:157] Top shape: (1)
I0912 02:50:46.036885 25179 net.cpp:157] Top shape: 2 (2)
I0912 02:50:46.036888 25179 net.cpp:165] Memory required for data: 5510983696
I0912 02:50:46.036892 25179 net.cpp:228] accuracy does not need backward computation.
I0912 02:50:46.036898 25179 net.cpp:226] loss needs backward computation.
I0912 02:50:46.036902 25179 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 02:50:46.036906 25179 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 02:50:46.036911 25179 net.cpp:226] relu1_2_D needs backward computation.
I0912 02:50:46.036913 25179 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 02:50:46.036916 25179 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 02:50:46.036919 25179 net.cpp:226] conv1_2_D needs backward computation.
I0912 02:50:46.036922 25179 net.cpp:226] upsample1 needs backward computation.
I0912 02:50:46.036926 25179 net.cpp:226] relu2_1_D needs backward computation.
I0912 02:50:46.036929 25179 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 02:50:46.036932 25179 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 02:50:46.036936 25179 net.cpp:226] conv2_1_D needs backward computation.
I0912 02:50:46.036938 25179 net.cpp:226] relu2_2_D needs backward computation.
I0912 02:50:46.036942 25179 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 02:50:46.036944 25179 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 02:50:46.036947 25179 net.cpp:226] conv2_2_D needs backward computation.
I0912 02:50:46.036950 25179 net.cpp:226] upsample2 needs backward computation.
I0912 02:50:46.036954 25179 net.cpp:226] relu3_1_D needs backward computation.
I0912 02:50:46.036959 25179 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 02:50:46.036978 25179 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 02:50:46.036980 25179 net.cpp:226] conv3_1_D needs backward computation.
I0912 02:50:46.036983 25179 net.cpp:226] relu3_2_D needs backward computation.
I0912 02:50:46.036986 25179 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 02:50:46.036989 25179 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 02:50:46.036993 25179 net.cpp:226] conv3_2_D needs backward computation.
I0912 02:50:46.036995 25179 net.cpp:226] relu3_3_D needs backward computation.
I0912 02:50:46.036998 25179 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 02:50:46.037001 25179 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 02:50:46.037004 25179 net.cpp:226] conv3_3_D needs backward computation.
I0912 02:50:46.037010 25179 net.cpp:226] upsample3 needs backward computation.
I0912 02:50:46.037014 25179 net.cpp:226] relu4_1_D needs backward computation.
I0912 02:50:46.037016 25179 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 02:50:46.037019 25179 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 02:50:46.037022 25179 net.cpp:226] conv4_1_D needs backward computation.
I0912 02:50:46.037026 25179 net.cpp:226] relu4_2_D needs backward computation.
I0912 02:50:46.037029 25179 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 02:50:46.037032 25179 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 02:50:46.037035 25179 net.cpp:226] conv4_2_D needs backward computation.
I0912 02:50:46.037039 25179 net.cpp:226] relu4_3_D needs backward computation.
I0912 02:50:46.037041 25179 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 02:50:46.037045 25179 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 02:50:46.037048 25179 net.cpp:226] conv4_3_D needs backward computation.
I0912 02:50:46.037051 25179 net.cpp:226] upsample4 needs backward computation.
I0912 02:50:46.037055 25179 net.cpp:226] relu5_1_D needs backward computation.
I0912 02:50:46.037058 25179 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 02:50:46.037061 25179 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 02:50:46.037067 25179 net.cpp:226] conv5_1_D needs backward computation.
I0912 02:50:46.037070 25179 net.cpp:226] relu5_2_D needs backward computation.
I0912 02:50:46.037075 25179 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 02:50:46.037077 25179 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 02:50:46.037081 25179 net.cpp:226] conv5_2_D needs backward computation.
I0912 02:50:46.037084 25179 net.cpp:226] relu5_3_D needs backward computation.
I0912 02:50:46.037088 25179 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 02:50:46.037093 25179 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 02:50:46.037096 25179 net.cpp:226] conv5_3_D needs backward computation.
I0912 02:50:46.037101 25179 net.cpp:226] upsample5 needs backward computation.
I0912 02:50:46.037104 25179 net.cpp:226] pool5 needs backward computation.
I0912 02:50:46.037111 25179 net.cpp:226] relu5_3 needs backward computation.
I0912 02:50:46.037113 25179 net.cpp:226] conv5_3_scale needs backward computation.
I0912 02:50:46.037117 25179 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 02:50:46.037120 25179 net.cpp:226] conv5_3 needs backward computation.
I0912 02:50:46.037124 25179 net.cpp:226] relu5_2 needs backward computation.
I0912 02:50:46.037127 25179 net.cpp:226] conv5_2_scale needs backward computation.
I0912 02:50:46.037132 25179 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 02:50:46.037134 25179 net.cpp:226] conv5_2 needs backward computation.
I0912 02:50:46.037138 25179 net.cpp:226] relu5_1 needs backward computation.
I0912 02:50:46.037142 25179 net.cpp:226] conv5_1_scale needs backward computation.
I0912 02:50:46.037144 25179 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 02:50:46.037148 25179 net.cpp:226] conv5_1 needs backward computation.
I0912 02:50:46.037151 25179 net.cpp:226] pool4 needs backward computation.
I0912 02:50:46.037163 25179 net.cpp:226] relu4_3 needs backward computation.
I0912 02:50:46.037166 25179 net.cpp:226] conv4_3_scale needs backward computation.
I0912 02:50:46.037170 25179 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 02:50:46.037173 25179 net.cpp:226] conv4_3 needs backward computation.
I0912 02:50:46.037176 25179 net.cpp:226] relu4_2 needs backward computation.
I0912 02:50:46.037180 25179 net.cpp:226] conv4_2_scale needs backward computation.
I0912 02:50:46.037184 25179 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 02:50:46.037187 25179 net.cpp:226] conv4_2 needs backward computation.
I0912 02:50:46.037190 25179 net.cpp:226] relu4_1 needs backward computation.
I0912 02:50:46.037194 25179 net.cpp:226] conv4_1_scale needs backward computation.
I0912 02:50:46.037197 25179 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 02:50:46.037200 25179 net.cpp:226] conv4_1 needs backward computation.
I0912 02:50:46.037204 25179 net.cpp:226] pool3 needs backward computation.
I0912 02:50:46.037207 25179 net.cpp:226] relu3_3 needs backward computation.
I0912 02:50:46.037211 25179 net.cpp:226] conv3_3_scale needs backward computation.
I0912 02:50:46.037214 25179 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 02:50:46.037217 25179 net.cpp:226] conv3_3 needs backward computation.
I0912 02:50:46.037220 25179 net.cpp:226] relu3_2 needs backward computation.
I0912 02:50:46.037225 25179 net.cpp:226] conv3_2_scale needs backward computation.
I0912 02:50:46.037227 25179 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 02:50:46.037230 25179 net.cpp:226] conv3_2 needs backward computation.
I0912 02:50:46.037235 25179 net.cpp:226] relu3_1 needs backward computation.
I0912 02:50:46.037237 25179 net.cpp:226] conv3_1_scale needs backward computation.
I0912 02:50:46.037240 25179 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 02:50:46.037245 25179 net.cpp:226] conv3_1 needs backward computation.
I0912 02:50:46.037247 25179 net.cpp:226] pool2 needs backward computation.
I0912 02:50:46.037250 25179 net.cpp:226] relu2_2 needs backward computation.
I0912 02:50:46.037256 25179 net.cpp:226] conv2_2_scale needs backward computation.
I0912 02:50:46.037259 25179 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 02:50:46.037262 25179 net.cpp:226] conv2_2 needs backward computation.
I0912 02:50:46.037266 25179 net.cpp:226] relu2_1 needs backward computation.
I0912 02:50:46.037269 25179 net.cpp:226] conv2_1_scale needs backward computation.
I0912 02:50:46.037272 25179 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 02:50:46.037276 25179 net.cpp:226] conv2_1 needs backward computation.
I0912 02:50:46.037279 25179 net.cpp:226] pool1 needs backward computation.
I0912 02:50:46.037283 25179 net.cpp:226] relu1_2 needs backward computation.
I0912 02:50:46.037288 25179 net.cpp:226] conv1_2_scale needs backward computation.
I0912 02:50:46.037292 25179 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 02:50:46.037294 25179 net.cpp:226] conv1_2 needs backward computation.
I0912 02:50:46.037298 25179 net.cpp:226] relu1_1 needs backward computation.
I0912 02:50:46.037302 25179 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 02:50:46.037305 25179 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 02:50:46.037310 25179 net.cpp:226] conv1_1_1 needs backward computation.
I0912 02:50:46.037315 25179 net.cpp:228] label_data_1_split does not need backward computation.
I0912 02:50:46.037320 25179 net.cpp:228] data does not need backward computation.
I0912 02:50:46.037324 25179 net.cpp:270] This network produces output accuracy
I0912 02:50:46.037328 25179 net.cpp:270] This network produces output loss
I0912 02:50:46.037333 25179 net.cpp:270] This network produces output per_class_accuracy
I0912 02:50:46.037416 25179 net.cpp:283] Network initialization done.
I0912 02:50:46.039765 25179 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc4/caffe/model_segnet_final/train.prototxt
I0912 02:50:46.040455 25179 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc4/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 02:50:46.040868 25179 layer_factory.hpp:77] Creating layer data
I0912 02:50:46.040881 25179 net.cpp:100] Creating Layer data
I0912 02:50:46.040889 25179 net.cpp:408] data -> data
I0912 02:50:46.040897 25179 net.cpp:408] data -> label
I0912 02:50:46.040906 25179 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc4/HDF5Files/train_combined.txt
I0912 02:50:46.040946 25179 hdf5_data_layer.cpp:93] Number of HDF5 files: 27
I0912 02:50:46.051118 25179 net.cpp:150] Setting up data
I0912 02:50:46.051138 25179 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 02:50:46.051144 25179 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 02:50:46.051148 25179 net.cpp:165] Memory required for data: 24883200
I0912 02:50:46.051153 25179 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 02:50:46.051168 25179 net.cpp:100] Creating Layer label_data_1_split
I0912 02:50:46.051175 25179 net.cpp:434] label_data_1_split <- label
I0912 02:50:46.051182 25179 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 02:50:46.051190 25179 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 02:50:46.051240 25179 net.cpp:150] Setting up label_data_1_split
I0912 02:50:46.051249 25179 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 02:50:46.051254 25179 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 02:50:46.051262 25179 net.cpp:165] Memory required for data: 30412800
I0912 02:50:46.051266 25179 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 02:50:46.051276 25179 net.cpp:100] Creating Layer conv1_1_1
I0912 02:50:46.051282 25179 net.cpp:434] conv1_1_1 <- data
I0912 02:50:46.051288 25179 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 02:50:46.054708 25179 net.cpp:150] Setting up conv1_1_1
I0912 02:50:46.054726 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.054735 25179 net.cpp:165] Memory required for data: 207360000
I0912 02:50:46.054749 25179 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 02:50:46.054757 25179 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 02:50:46.054765 25179 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 02:50:46.054771 25179 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 02:50:46.055151 25179 net.cpp:150] Setting up conv1_1_1_bn
I0912 02:50:46.055161 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.055166 25179 net.cpp:165] Memory required for data: 384307200
I0912 02:50:46.055184 25179 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 02:50:46.055193 25179 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 02:50:46.055198 25179 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 02:50:46.055203 25179 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 02:50:46.055254 25179 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 02:50:46.056902 25179 net.cpp:150] Setting up conv1_1_1_scale
I0912 02:50:46.056918 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.056923 25179 net.cpp:165] Memory required for data: 561254400
I0912 02:50:46.056932 25179 layer_factory.hpp:77] Creating layer relu1_1
I0912 02:50:46.056941 25179 net.cpp:100] Creating Layer relu1_1
I0912 02:50:46.056946 25179 net.cpp:434] relu1_1 <- conv1_1_1
I0912 02:50:46.056951 25179 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 02:50:46.057171 25179 net.cpp:150] Setting up relu1_1
I0912 02:50:46.057181 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.057186 25179 net.cpp:165] Memory required for data: 738201600
I0912 02:50:46.057190 25179 layer_factory.hpp:77] Creating layer conv1_2
I0912 02:50:46.057200 25179 net.cpp:100] Creating Layer conv1_2
I0912 02:50:46.057205 25179 net.cpp:434] conv1_2 <- conv1_1_1
I0912 02:50:46.057211 25179 net.cpp:408] conv1_2 -> conv1_2
I0912 02:50:46.061319 25179 net.cpp:150] Setting up conv1_2
I0912 02:50:46.061337 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.061345 25179 net.cpp:165] Memory required for data: 915148800
I0912 02:50:46.061393 25179 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 02:50:46.061403 25179 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 02:50:46.061408 25179 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 02:50:46.061414 25179 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 02:50:46.061794 25179 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 02:50:46.061805 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.061810 25179 net.cpp:165] Memory required for data: 1092096000
I0912 02:50:46.061818 25179 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 02:50:46.061828 25179 net.cpp:100] Creating Layer conv1_2_scale
I0912 02:50:46.061833 25179 net.cpp:434] conv1_2_scale <- conv1_2
I0912 02:50:46.061838 25179 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 02:50:46.061888 25179 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 02:50:46.063541 25179 net.cpp:150] Setting up conv1_2_scale
I0912 02:50:46.063557 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.063563 25179 net.cpp:165] Memory required for data: 1269043200
I0912 02:50:46.063571 25179 layer_factory.hpp:77] Creating layer relu1_2
I0912 02:50:46.063580 25179 net.cpp:100] Creating Layer relu1_2
I0912 02:50:46.063585 25179 net.cpp:434] relu1_2 <- conv1_2
I0912 02:50:46.063590 25179 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 02:50:46.064707 25179 net.cpp:150] Setting up relu1_2
I0912 02:50:46.064723 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:46.064728 25179 net.cpp:165] Memory required for data: 1445990400
I0912 02:50:46.064733 25179 layer_factory.hpp:77] Creating layer pool1
I0912 02:50:46.064739 25179 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 02:50:46.064745 25179 net.cpp:100] Creating Layer pool1
I0912 02:50:46.064750 25179 net.cpp:434] pool1 <- conv1_2
I0912 02:50:46.064756 25179 net.cpp:408] pool1 -> pool1
I0912 02:50:46.064764 25179 net.cpp:408] pool1 -> pool1_mask
I0912 02:50:46.064826 25179 net.cpp:150] Setting up pool1
I0912 02:50:46.064833 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:46.064838 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:46.064843 25179 net.cpp:165] Memory required for data: 1534464000
I0912 02:50:46.064847 25179 layer_factory.hpp:77] Creating layer conv2_1
I0912 02:50:46.064857 25179 net.cpp:100] Creating Layer conv2_1
I0912 02:50:46.064862 25179 net.cpp:434] conv2_1 <- pool1
I0912 02:50:46.064870 25179 net.cpp:408] conv2_1 -> conv2_1
I0912 02:50:46.069213 25179 net.cpp:150] Setting up conv2_1
I0912 02:50:46.069231 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.069239 25179 net.cpp:165] Memory required for data: 1622937600
I0912 02:50:46.069247 25179 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 02:50:46.069258 25179 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 02:50:46.069264 25179 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 02:50:46.069270 25179 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 02:50:46.069599 25179 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 02:50:46.069612 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.069614 25179 net.cpp:165] Memory required for data: 1711411200
I0912 02:50:46.069629 25179 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 02:50:46.069638 25179 net.cpp:100] Creating Layer conv2_1_scale
I0912 02:50:46.069643 25179 net.cpp:434] conv2_1_scale <- conv2_1
I0912 02:50:46.069649 25179 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 02:50:46.069706 25179 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 02:50:46.069939 25179 net.cpp:150] Setting up conv2_1_scale
I0912 02:50:46.069949 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.069955 25179 net.cpp:165] Memory required for data: 1799884800
I0912 02:50:46.069962 25179 layer_factory.hpp:77] Creating layer relu2_1
I0912 02:50:46.069969 25179 net.cpp:100] Creating Layer relu2_1
I0912 02:50:46.069974 25179 net.cpp:434] relu2_1 <- conv2_1
I0912 02:50:46.069981 25179 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 02:50:46.071118 25179 net.cpp:150] Setting up relu2_1
I0912 02:50:46.071133 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.071140 25179 net.cpp:165] Memory required for data: 1888358400
I0912 02:50:46.071143 25179 layer_factory.hpp:77] Creating layer conv2_2
I0912 02:50:46.071158 25179 net.cpp:100] Creating Layer conv2_2
I0912 02:50:46.071163 25179 net.cpp:434] conv2_2 <- conv2_1
I0912 02:50:46.071172 25179 net.cpp:408] conv2_2 -> conv2_2
I0912 02:50:46.080185 25179 net.cpp:150] Setting up conv2_2
I0912 02:50:46.080204 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.080214 25179 net.cpp:165] Memory required for data: 1976832000
I0912 02:50:46.080222 25179 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 02:50:46.080236 25179 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 02:50:46.080242 25179 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 02:50:46.080248 25179 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 02:50:46.081809 25179 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 02:50:46.081826 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.081835 25179 net.cpp:165] Memory required for data: 2065305600
I0912 02:50:46.081845 25179 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 02:50:46.081853 25179 net.cpp:100] Creating Layer conv2_2_scale
I0912 02:50:46.081861 25179 net.cpp:434] conv2_2_scale <- conv2_2
I0912 02:50:46.081867 25179 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 02:50:46.081931 25179 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 02:50:46.082145 25179 net.cpp:150] Setting up conv2_2_scale
I0912 02:50:46.082155 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.082160 25179 net.cpp:165] Memory required for data: 2153779200
I0912 02:50:46.082167 25179 layer_factory.hpp:77] Creating layer relu2_2
I0912 02:50:46.082175 25179 net.cpp:100] Creating Layer relu2_2
I0912 02:50:46.082180 25179 net.cpp:434] relu2_2 <- conv2_2
I0912 02:50:46.082187 25179 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 02:50:46.082417 25179 net.cpp:150] Setting up relu2_2
I0912 02:50:46.082428 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:46.082433 25179 net.cpp:165] Memory required for data: 2242252800
I0912 02:50:46.082437 25179 layer_factory.hpp:77] Creating layer pool2
I0912 02:50:46.082442 25179 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 02:50:46.082450 25179 net.cpp:100] Creating Layer pool2
I0912 02:50:46.082455 25179 net.cpp:434] pool2 <- conv2_2
I0912 02:50:46.082461 25179 net.cpp:408] pool2 -> pool2
I0912 02:50:46.082469 25179 net.cpp:408] pool2 -> pool2_mask
I0912 02:50:46.082528 25179 net.cpp:150] Setting up pool2
I0912 02:50:46.082536 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:46.082541 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:46.082545 25179 net.cpp:165] Memory required for data: 2286489600
I0912 02:50:46.082550 25179 layer_factory.hpp:77] Creating layer conv3_1
I0912 02:50:46.082561 25179 net.cpp:100] Creating Layer conv3_1
I0912 02:50:46.082566 25179 net.cpp:434] conv3_1 <- pool2
I0912 02:50:46.082574 25179 net.cpp:408] conv3_1 -> conv3_1
I0912 02:50:46.095124 25179 net.cpp:150] Setting up conv3_1
I0912 02:50:46.095142 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.095151 25179 net.cpp:165] Memory required for data: 2330726400
I0912 02:50:46.095160 25179 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 02:50:46.095171 25179 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 02:50:46.095178 25179 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 02:50:46.095185 25179 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 02:50:46.095466 25179 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 02:50:46.095475 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.095479 25179 net.cpp:165] Memory required for data: 2374963200
I0912 02:50:46.095495 25179 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 02:50:46.095520 25179 net.cpp:100] Creating Layer conv3_1_scale
I0912 02:50:46.095525 25179 net.cpp:434] conv3_1_scale <- conv3_1
I0912 02:50:46.095530 25179 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 02:50:46.095588 25179 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 02:50:46.095769 25179 net.cpp:150] Setting up conv3_1_scale
I0912 02:50:46.095778 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.095784 25179 net.cpp:165] Memory required for data: 2419200000
I0912 02:50:46.095791 25179 layer_factory.hpp:77] Creating layer relu3_1
I0912 02:50:46.095800 25179 net.cpp:100] Creating Layer relu3_1
I0912 02:50:46.095805 25179 net.cpp:434] relu3_1 <- conv3_1
I0912 02:50:46.095810 25179 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 02:50:46.096037 25179 net.cpp:150] Setting up relu3_1
I0912 02:50:46.096047 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.096052 25179 net.cpp:165] Memory required for data: 2463436800
I0912 02:50:46.096056 25179 layer_factory.hpp:77] Creating layer conv3_2
I0912 02:50:46.096071 25179 net.cpp:100] Creating Layer conv3_2
I0912 02:50:46.096076 25179 net.cpp:434] conv3_2 <- conv3_1
I0912 02:50:46.096082 25179 net.cpp:408] conv3_2 -> conv3_2
I0912 02:50:46.119683 25179 net.cpp:150] Setting up conv3_2
I0912 02:50:46.119700 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.119704 25179 net.cpp:165] Memory required for data: 2507673600
I0912 02:50:46.119715 25179 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 02:50:46.119729 25179 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 02:50:46.119736 25179 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 02:50:46.119742 25179 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 02:50:46.120025 25179 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 02:50:46.120035 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.120039 25179 net.cpp:165] Memory required for data: 2551910400
I0912 02:50:46.120048 25179 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 02:50:46.120064 25179 net.cpp:100] Creating Layer conv3_2_scale
I0912 02:50:46.120070 25179 net.cpp:434] conv3_2_scale <- conv3_2
I0912 02:50:46.120076 25179 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 02:50:46.120131 25179 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 02:50:46.120311 25179 net.cpp:150] Setting up conv3_2_scale
I0912 02:50:46.120321 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.120323 25179 net.cpp:165] Memory required for data: 2596147200
I0912 02:50:46.120331 25179 layer_factory.hpp:77] Creating layer relu3_2
I0912 02:50:46.120338 25179 net.cpp:100] Creating Layer relu3_2
I0912 02:50:46.120343 25179 net.cpp:434] relu3_2 <- conv3_2
I0912 02:50:46.120350 25179 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 02:50:46.120576 25179 net.cpp:150] Setting up relu3_2
I0912 02:50:46.120586 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.120591 25179 net.cpp:165] Memory required for data: 2640384000
I0912 02:50:46.120595 25179 layer_factory.hpp:77] Creating layer conv3_3
I0912 02:50:46.120607 25179 net.cpp:100] Creating Layer conv3_3
I0912 02:50:46.120613 25179 net.cpp:434] conv3_3 <- conv3_2
I0912 02:50:46.120621 25179 net.cpp:408] conv3_3 -> conv3_3
I0912 02:50:46.144215 25179 net.cpp:150] Setting up conv3_3
I0912 02:50:46.144234 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.144249 25179 net.cpp:165] Memory required for data: 2684620800
I0912 02:50:46.144258 25179 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 02:50:46.144269 25179 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 02:50:46.144276 25179 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 02:50:46.144282 25179 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 02:50:46.144564 25179 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 02:50:46.144573 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.144577 25179 net.cpp:165] Memory required for data: 2728857600
I0912 02:50:46.144587 25179 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 02:50:46.144608 25179 net.cpp:100] Creating Layer conv3_3_scale
I0912 02:50:46.144616 25179 net.cpp:434] conv3_3_scale <- conv3_3
I0912 02:50:46.144623 25179 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 02:50:46.144680 25179 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 02:50:46.144860 25179 net.cpp:150] Setting up conv3_3_scale
I0912 02:50:46.144870 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.144872 25179 net.cpp:165] Memory required for data: 2773094400
I0912 02:50:46.144879 25179 layer_factory.hpp:77] Creating layer relu3_3
I0912 02:50:46.144889 25179 net.cpp:100] Creating Layer relu3_3
I0912 02:50:46.144894 25179 net.cpp:434] relu3_3 <- conv3_3
I0912 02:50:46.144899 25179 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 02:50:46.145133 25179 net.cpp:150] Setting up relu3_3
I0912 02:50:46.145143 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:46.145150 25179 net.cpp:165] Memory required for data: 2817331200
I0912 02:50:46.145154 25179 layer_factory.hpp:77] Creating layer pool3
I0912 02:50:46.145159 25179 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 02:50:46.145169 25179 net.cpp:100] Creating Layer pool3
I0912 02:50:46.145174 25179 net.cpp:434] pool3 <- conv3_3
I0912 02:50:46.145182 25179 net.cpp:408] pool3 -> pool3
I0912 02:50:46.145190 25179 net.cpp:408] pool3 -> pool3_mask
I0912 02:50:46.145251 25179 net.cpp:150] Setting up pool3
I0912 02:50:46.145259 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:46.145267 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:46.145272 25179 net.cpp:165] Memory required for data: 2839449600
I0912 02:50:46.145275 25179 layer_factory.hpp:77] Creating layer conv4_1
I0912 02:50:46.145287 25179 net.cpp:100] Creating Layer conv4_1
I0912 02:50:46.145292 25179 net.cpp:434] conv4_1 <- pool3
I0912 02:50:46.145298 25179 net.cpp:408] conv4_1 -> conv4_1
I0912 02:50:46.189211 25179 net.cpp:150] Setting up conv4_1
I0912 02:50:46.189230 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.189244 25179 net.cpp:165] Memory required for data: 2861568000
I0912 02:50:46.189252 25179 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 02:50:46.189265 25179 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 02:50:46.189271 25179 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 02:50:46.189278 25179 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 02:50:46.189579 25179 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 02:50:46.189589 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.189594 25179 net.cpp:165] Memory required for data: 2883686400
I0912 02:50:46.189602 25179 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 02:50:46.189617 25179 net.cpp:100] Creating Layer conv4_1_scale
I0912 02:50:46.189622 25179 net.cpp:434] conv4_1_scale <- conv4_1
I0912 02:50:46.189628 25179 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 02:50:46.189678 25179 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 02:50:46.189846 25179 net.cpp:150] Setting up conv4_1_scale
I0912 02:50:46.189855 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.189860 25179 net.cpp:165] Memory required for data: 2905804800
I0912 02:50:46.189867 25179 layer_factory.hpp:77] Creating layer relu4_1
I0912 02:50:46.189874 25179 net.cpp:100] Creating Layer relu4_1
I0912 02:50:46.189879 25179 net.cpp:434] relu4_1 <- conv4_1
I0912 02:50:46.189889 25179 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 02:50:46.191038 25179 net.cpp:150] Setting up relu4_1
I0912 02:50:46.191053 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.191059 25179 net.cpp:165] Memory required for data: 2927923200
I0912 02:50:46.191063 25179 layer_factory.hpp:77] Creating layer conv4_2
I0912 02:50:46.191078 25179 net.cpp:100] Creating Layer conv4_2
I0912 02:50:46.191084 25179 net.cpp:434] conv4_2 <- conv4_1
I0912 02:50:46.191093 25179 net.cpp:408] conv4_2 -> conv4_2
I0912 02:50:46.274466 25179 net.cpp:150] Setting up conv4_2
I0912 02:50:46.274502 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.274516 25179 net.cpp:165] Memory required for data: 2950041600
I0912 02:50:46.274531 25179 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 02:50:46.274544 25179 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 02:50:46.274552 25179 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 02:50:46.274564 25179 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 02:50:46.274843 25179 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 02:50:46.274852 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.274857 25179 net.cpp:165] Memory required for data: 2972160000
I0912 02:50:46.274864 25179 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 02:50:46.274875 25179 net.cpp:100] Creating Layer conv4_2_scale
I0912 02:50:46.274880 25179 net.cpp:434] conv4_2_scale <- conv4_2
I0912 02:50:46.274885 25179 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 02:50:46.274937 25179 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 02:50:46.275104 25179 net.cpp:150] Setting up conv4_2_scale
I0912 02:50:46.275112 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.275117 25179 net.cpp:165] Memory required for data: 2994278400
I0912 02:50:46.275125 25179 layer_factory.hpp:77] Creating layer relu4_2
I0912 02:50:46.275132 25179 net.cpp:100] Creating Layer relu4_2
I0912 02:50:46.275136 25179 net.cpp:434] relu4_2 <- conv4_2
I0912 02:50:46.275143 25179 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 02:50:46.276315 25179 net.cpp:150] Setting up relu4_2
I0912 02:50:46.276335 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.276340 25179 net.cpp:165] Memory required for data: 3016396800
I0912 02:50:46.276345 25179 layer_factory.hpp:77] Creating layer conv4_3
I0912 02:50:46.276357 25179 net.cpp:100] Creating Layer conv4_3
I0912 02:50:46.276363 25179 net.cpp:434] conv4_3 <- conv4_2
I0912 02:50:46.276371 25179 net.cpp:408] conv4_3 -> conv4_3
I0912 02:50:46.359992 25179 net.cpp:150] Setting up conv4_3
I0912 02:50:46.360011 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.360015 25179 net.cpp:165] Memory required for data: 3038515200
I0912 02:50:46.360056 25179 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 02:50:46.360069 25179 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 02:50:46.360075 25179 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 02:50:46.360081 25179 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 02:50:46.360357 25179 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 02:50:46.360366 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.360376 25179 net.cpp:165] Memory required for data: 3060633600
I0912 02:50:46.360385 25179 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 02:50:46.360395 25179 net.cpp:100] Creating Layer conv4_3_scale
I0912 02:50:46.360404 25179 net.cpp:434] conv4_3_scale <- conv4_3
I0912 02:50:46.360412 25179 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 02:50:46.360463 25179 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 02:50:46.360630 25179 net.cpp:150] Setting up conv4_3_scale
I0912 02:50:46.360638 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.360641 25179 net.cpp:165] Memory required for data: 3082752000
I0912 02:50:46.360649 25179 layer_factory.hpp:77] Creating layer relu4_3
I0912 02:50:46.360659 25179 net.cpp:100] Creating Layer relu4_3
I0912 02:50:46.360664 25179 net.cpp:434] relu4_3 <- conv4_3
I0912 02:50:46.360669 25179 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 02:50:46.360888 25179 net.cpp:150] Setting up relu4_3
I0912 02:50:46.360901 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.360906 25179 net.cpp:165] Memory required for data: 3104870400
I0912 02:50:46.360910 25179 layer_factory.hpp:77] Creating layer pool4
I0912 02:50:46.360914 25179 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 02:50:46.360921 25179 net.cpp:100] Creating Layer pool4
I0912 02:50:46.360926 25179 net.cpp:434] pool4 <- conv4_3
I0912 02:50:46.360950 25179 net.cpp:408] pool4 -> pool4
I0912 02:50:46.360961 25179 net.cpp:408] pool4 -> pool4_mask
I0912 02:50:46.361022 25179 net.cpp:150] Setting up pool4
I0912 02:50:46.361030 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.361035 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.361040 25179 net.cpp:165] Memory required for data: 3116175360
I0912 02:50:46.361044 25179 layer_factory.hpp:77] Creating layer conv5_1
I0912 02:50:46.361059 25179 net.cpp:100] Creating Layer conv5_1
I0912 02:50:46.361064 25179 net.cpp:434] conv5_1 <- pool4
I0912 02:50:46.361071 25179 net.cpp:408] conv5_1 -> conv5_1
I0912 02:50:46.444682 25179 net.cpp:150] Setting up conv5_1
I0912 02:50:46.444700 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.444705 25179 net.cpp:165] Memory required for data: 3121827840
I0912 02:50:46.444713 25179 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 02:50:46.444723 25179 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 02:50:46.444727 25179 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 02:50:46.444733 25179 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 02:50:46.445019 25179 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 02:50:46.445029 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.445032 25179 net.cpp:165] Memory required for data: 3127480320
I0912 02:50:46.445044 25179 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 02:50:46.445051 25179 net.cpp:100] Creating Layer conv5_1_scale
I0912 02:50:46.445060 25179 net.cpp:434] conv5_1_scale <- conv5_1
I0912 02:50:46.445065 25179 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 02:50:46.445128 25179 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 02:50:46.445283 25179 net.cpp:150] Setting up conv5_1_scale
I0912 02:50:46.445292 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.445297 25179 net.cpp:165] Memory required for data: 3133132800
I0912 02:50:46.445302 25179 layer_factory.hpp:77] Creating layer relu5_1
I0912 02:50:46.445313 25179 net.cpp:100] Creating Layer relu5_1
I0912 02:50:46.445318 25179 net.cpp:434] relu5_1 <- conv5_1
I0912 02:50:46.445323 25179 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 02:50:46.445564 25179 net.cpp:150] Setting up relu5_1
I0912 02:50:46.445575 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.445580 25179 net.cpp:165] Memory required for data: 3138785280
I0912 02:50:46.445585 25179 layer_factory.hpp:77] Creating layer conv5_2
I0912 02:50:46.445598 25179 net.cpp:100] Creating Layer conv5_2
I0912 02:50:46.445603 25179 net.cpp:434] conv5_2 <- conv5_1
I0912 02:50:46.445611 25179 net.cpp:408] conv5_2 -> conv5_2
I0912 02:50:46.529300 25179 net.cpp:150] Setting up conv5_2
I0912 02:50:46.529320 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.529323 25179 net.cpp:165] Memory required for data: 3144437760
I0912 02:50:46.529331 25179 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 02:50:46.529340 25179 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 02:50:46.529343 25179 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 02:50:46.529351 25179 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 02:50:46.529641 25179 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 02:50:46.529652 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.529656 25179 net.cpp:165] Memory required for data: 3150090240
I0912 02:50:46.529664 25179 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 02:50:46.529672 25179 net.cpp:100] Creating Layer conv5_2_scale
I0912 02:50:46.529680 25179 net.cpp:434] conv5_2_scale <- conv5_2
I0912 02:50:46.529685 25179 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 02:50:46.529743 25179 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 02:50:46.529901 25179 net.cpp:150] Setting up conv5_2_scale
I0912 02:50:46.529911 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.529914 25179 net.cpp:165] Memory required for data: 3155742720
I0912 02:50:46.529922 25179 layer_factory.hpp:77] Creating layer relu5_2
I0912 02:50:46.529942 25179 net.cpp:100] Creating Layer relu5_2
I0912 02:50:46.529952 25179 net.cpp:434] relu5_2 <- conv5_2
I0912 02:50:46.529956 25179 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 02:50:46.530184 25179 net.cpp:150] Setting up relu5_2
I0912 02:50:46.530195 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.530200 25179 net.cpp:165] Memory required for data: 3161395200
I0912 02:50:46.530205 25179 layer_factory.hpp:77] Creating layer conv5_3
I0912 02:50:46.530216 25179 net.cpp:100] Creating Layer conv5_3
I0912 02:50:46.530221 25179 net.cpp:434] conv5_3 <- conv5_2
I0912 02:50:46.530231 25179 net.cpp:408] conv5_3 -> conv5_3
I0912 02:50:46.613976 25179 net.cpp:150] Setting up conv5_3
I0912 02:50:46.613993 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.613997 25179 net.cpp:165] Memory required for data: 3167047680
I0912 02:50:46.614006 25179 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 02:50:46.614015 25179 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 02:50:46.614024 25179 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 02:50:46.614032 25179 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 02:50:46.614307 25179 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 02:50:46.614317 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.614320 25179 net.cpp:165] Memory required for data: 3172700160
I0912 02:50:46.614329 25179 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 02:50:46.614338 25179 net.cpp:100] Creating Layer conv5_3_scale
I0912 02:50:46.614346 25179 net.cpp:434] conv5_3_scale <- conv5_3
I0912 02:50:46.614354 25179 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 02:50:46.614413 25179 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 02:50:46.614570 25179 net.cpp:150] Setting up conv5_3_scale
I0912 02:50:46.614581 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.614585 25179 net.cpp:165] Memory required for data: 3178352640
I0912 02:50:46.614593 25179 layer_factory.hpp:77] Creating layer relu5_3
I0912 02:50:46.614600 25179 net.cpp:100] Creating Layer relu5_3
I0912 02:50:46.614605 25179 net.cpp:434] relu5_3 <- conv5_3
I0912 02:50:46.614610 25179 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 02:50:46.614837 25179 net.cpp:150] Setting up relu5_3
I0912 02:50:46.614850 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.614855 25179 net.cpp:165] Memory required for data: 3184005120
I0912 02:50:46.614858 25179 layer_factory.hpp:77] Creating layer pool5
I0912 02:50:46.614862 25179 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 02:50:46.614871 25179 net.cpp:100] Creating Layer pool5
I0912 02:50:46.614876 25179 net.cpp:434] pool5 <- conv5_3
I0912 02:50:46.614881 25179 net.cpp:408] pool5 -> pool5
I0912 02:50:46.614892 25179 net.cpp:408] pool5 -> pool5_mask
I0912 02:50:46.614954 25179 net.cpp:150] Setting up pool5
I0912 02:50:46.614962 25179 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 02:50:46.614966 25179 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 02:50:46.614971 25179 net.cpp:165] Memory required for data: 3186954240
I0912 02:50:46.614975 25179 layer_factory.hpp:77] Creating layer upsample5
I0912 02:50:46.614985 25179 net.cpp:100] Creating Layer upsample5
I0912 02:50:46.614990 25179 net.cpp:434] upsample5 <- pool5
I0912 02:50:46.614995 25179 net.cpp:434] upsample5 <- pool5_mask
I0912 02:50:46.615001 25179 net.cpp:408] upsample5 -> pool5_D
I0912 02:50:46.615036 25179 net.cpp:150] Setting up upsample5
I0912 02:50:46.615044 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.615047 25179 net.cpp:165] Memory required for data: 3192606720
I0912 02:50:46.615051 25179 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 02:50:46.615064 25179 net.cpp:100] Creating Layer conv5_3_D
I0912 02:50:46.615069 25179 net.cpp:434] conv5_3_D <- pool5_D
I0912 02:50:46.615078 25179 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 02:50:46.698783 25179 net.cpp:150] Setting up conv5_3_D
I0912 02:50:46.698802 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.698823 25179 net.cpp:165] Memory required for data: 3198259200
I0912 02:50:46.698832 25179 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 02:50:46.698848 25179 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 02:50:46.698854 25179 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 02:50:46.698863 25179 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 02:50:46.699144 25179 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 02:50:46.699154 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.699164 25179 net.cpp:165] Memory required for data: 3203911680
I0912 02:50:46.699174 25179 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 02:50:46.699183 25179 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 02:50:46.699188 25179 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 02:50:46.699193 25179 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 02:50:46.699254 25179 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 02:50:46.699412 25179 net.cpp:150] Setting up conv5_3_D_scale
I0912 02:50:46.699421 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.699424 25179 net.cpp:165] Memory required for data: 3209564160
I0912 02:50:46.699431 25179 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 02:50:46.699441 25179 net.cpp:100] Creating Layer relu5_3_D
I0912 02:50:46.699446 25179 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 02:50:46.699451 25179 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 02:50:46.700604 25179 net.cpp:150] Setting up relu5_3_D
I0912 02:50:46.700623 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.700628 25179 net.cpp:165] Memory required for data: 3215216640
I0912 02:50:46.700631 25179 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 02:50:46.700664 25179 net.cpp:100] Creating Layer conv5_2_D
I0912 02:50:46.700670 25179 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 02:50:46.700678 25179 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 02:50:46.784368 25179 net.cpp:150] Setting up conv5_2_D
I0912 02:50:46.784385 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.784396 25179 net.cpp:165] Memory required for data: 3220869120
I0912 02:50:46.784407 25179 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 02:50:46.784417 25179 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 02:50:46.784426 25179 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 02:50:46.784432 25179 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 02:50:46.784725 25179 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 02:50:46.784734 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.784739 25179 net.cpp:165] Memory required for data: 3226521600
I0912 02:50:46.784747 25179 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 02:50:46.784759 25179 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 02:50:46.784765 25179 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 02:50:46.784770 25179 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 02:50:46.784832 25179 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 02:50:46.784992 25179 net.cpp:150] Setting up conv5_2_D_scale
I0912 02:50:46.785001 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.785004 25179 net.cpp:165] Memory required for data: 3232174080
I0912 02:50:46.785012 25179 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 02:50:46.785023 25179 net.cpp:100] Creating Layer relu5_2_D
I0912 02:50:46.785029 25179 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 02:50:46.785037 25179 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 02:50:46.786223 25179 net.cpp:150] Setting up relu5_2_D
I0912 02:50:46.786239 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.786245 25179 net.cpp:165] Memory required for data: 3237826560
I0912 02:50:46.786249 25179 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 02:50:46.786264 25179 net.cpp:100] Creating Layer conv5_1_D
I0912 02:50:46.786270 25179 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 02:50:46.786279 25179 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 02:50:46.869982 25179 net.cpp:150] Setting up conv5_1_D
I0912 02:50:46.870000 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.870004 25179 net.cpp:165] Memory required for data: 3243479040
I0912 02:50:46.870012 25179 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 02:50:46.870023 25179 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 02:50:46.870028 25179 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 02:50:46.870033 25179 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 02:50:46.870312 25179 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 02:50:46.870322 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.870333 25179 net.cpp:165] Memory required for data: 3249131520
I0912 02:50:46.870342 25179 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 02:50:46.870355 25179 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 02:50:46.870360 25179 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 02:50:46.870367 25179 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 02:50:46.870430 25179 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 02:50:46.870591 25179 net.cpp:150] Setting up conv5_1_D_scale
I0912 02:50:46.870599 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.870605 25179 net.cpp:165] Memory required for data: 3254784000
I0912 02:50:46.870611 25179 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 02:50:46.870621 25179 net.cpp:100] Creating Layer relu5_1_D
I0912 02:50:46.870626 25179 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 02:50:46.870631 25179 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 02:50:46.870898 25179 net.cpp:150] Setting up relu5_1_D
I0912 02:50:46.870909 25179 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 02:50:46.870914 25179 net.cpp:165] Memory required for data: 3260436480
I0912 02:50:46.870918 25179 layer_factory.hpp:77] Creating layer upsample4
I0912 02:50:46.870929 25179 net.cpp:100] Creating Layer upsample4
I0912 02:50:46.870934 25179 net.cpp:434] upsample4 <- conv5_1_D
I0912 02:50:46.870939 25179 net.cpp:434] upsample4 <- pool4_mask
I0912 02:50:46.870945 25179 net.cpp:408] upsample4 -> pool4_D
I0912 02:50:46.870988 25179 net.cpp:150] Setting up upsample4
I0912 02:50:46.870996 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.871001 25179 net.cpp:165] Memory required for data: 3282554880
I0912 02:50:46.871006 25179 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 02:50:46.871017 25179 net.cpp:100] Creating Layer conv4_3_D
I0912 02:50:46.871022 25179 net.cpp:434] conv4_3_D <- pool4_D
I0912 02:50:46.871031 25179 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 02:50:46.954766 25179 net.cpp:150] Setting up conv4_3_D
I0912 02:50:46.954784 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.954798 25179 net.cpp:165] Memory required for data: 3304673280
I0912 02:50:46.954807 25179 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 02:50:46.954819 25179 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 02:50:46.954826 25179 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 02:50:46.954833 25179 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 02:50:46.955119 25179 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 02:50:46.955128 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.955132 25179 net.cpp:165] Memory required for data: 3326791680
I0912 02:50:46.955142 25179 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 02:50:46.955150 25179 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 02:50:46.955159 25179 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 02:50:46.955165 25179 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 02:50:46.955219 25179 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 02:50:46.955392 25179 net.cpp:150] Setting up conv4_3_D_scale
I0912 02:50:46.955401 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.955404 25179 net.cpp:165] Memory required for data: 3348910080
I0912 02:50:46.955411 25179 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 02:50:46.955436 25179 net.cpp:100] Creating Layer relu4_3_D
I0912 02:50:46.955442 25179 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 02:50:46.955447 25179 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 02:50:46.955673 25179 net.cpp:150] Setting up relu4_3_D
I0912 02:50:46.955685 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:46.955690 25179 net.cpp:165] Memory required for data: 3371028480
I0912 02:50:46.955694 25179 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 02:50:46.955706 25179 net.cpp:100] Creating Layer conv4_2_D
I0912 02:50:46.955713 25179 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 02:50:46.955718 25179 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 02:50:47.039410 25179 net.cpp:150] Setting up conv4_2_D
I0912 02:50:47.039428 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:47.039433 25179 net.cpp:165] Memory required for data: 3393146880
I0912 02:50:47.039441 25179 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 02:50:47.039459 25179 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 02:50:47.039466 25179 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 02:50:47.039474 25179 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 02:50:47.039769 25179 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 02:50:47.039778 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:47.039783 25179 net.cpp:165] Memory required for data: 3415265280
I0912 02:50:47.039791 25179 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 02:50:47.039798 25179 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 02:50:47.039808 25179 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 02:50:47.039814 25179 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 02:50:47.039870 25179 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 02:50:47.040043 25179 net.cpp:150] Setting up conv4_2_D_scale
I0912 02:50:47.040052 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:47.040055 25179 net.cpp:165] Memory required for data: 3437383680
I0912 02:50:47.040063 25179 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 02:50:47.040071 25179 net.cpp:100] Creating Layer relu4_2_D
I0912 02:50:47.040076 25179 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 02:50:47.040081 25179 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 02:50:47.040310 25179 net.cpp:150] Setting up relu4_2_D
I0912 02:50:47.040320 25179 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 02:50:47.040325 25179 net.cpp:165] Memory required for data: 3459502080
I0912 02:50:47.040329 25179 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 02:50:47.040343 25179 net.cpp:100] Creating Layer conv4_1_D
I0912 02:50:47.040349 25179 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 02:50:47.040359 25179 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 02:50:47.084389 25179 net.cpp:150] Setting up conv4_1_D
I0912 02:50:47.084408 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:47.084419 25179 net.cpp:165] Memory required for data: 3470561280
I0912 02:50:47.084427 25179 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 02:50:47.084439 25179 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 02:50:47.084446 25179 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 02:50:47.084452 25179 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 02:50:47.084748 25179 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 02:50:47.084758 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:47.084767 25179 net.cpp:165] Memory required for data: 3481620480
I0912 02:50:47.084800 25179 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 02:50:47.084810 25179 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 02:50:47.084816 25179 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 02:50:47.084825 25179 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 02:50:47.084887 25179 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 02:50:47.085067 25179 net.cpp:150] Setting up conv4_1_D_scale
I0912 02:50:47.085075 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:47.085094 25179 net.cpp:165] Memory required for data: 3492679680
I0912 02:50:47.085103 25179 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 02:50:47.085109 25179 net.cpp:100] Creating Layer relu4_1_D
I0912 02:50:47.085114 25179 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 02:50:47.085119 25179 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 02:50:47.085361 25179 net.cpp:150] Setting up relu4_1_D
I0912 02:50:47.085389 25179 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 02:50:47.085394 25179 net.cpp:165] Memory required for data: 3503738880
I0912 02:50:47.085398 25179 layer_factory.hpp:77] Creating layer upsample3
I0912 02:50:47.085407 25179 net.cpp:100] Creating Layer upsample3
I0912 02:50:47.085412 25179 net.cpp:434] upsample3 <- conv4_1_D
I0912 02:50:47.085420 25179 net.cpp:434] upsample3 <- pool3_mask
I0912 02:50:47.085428 25179 net.cpp:408] upsample3 -> pool3_D
I0912 02:50:47.085438 25179 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 02:50:47.085477 25179 net.cpp:150] Setting up upsample3
I0912 02:50:47.085485 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:47.085489 25179 net.cpp:165] Memory required for data: 3547975680
I0912 02:50:47.085492 25179 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 02:50:47.085507 25179 net.cpp:100] Creating Layer conv3_3_D
I0912 02:50:47.085512 25179 net.cpp:434] conv3_3_D <- pool3_D
I0912 02:50:47.085520 25179 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 02:50:47.109295 25179 net.cpp:150] Setting up conv3_3_D
I0912 02:50:47.109313 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:47.109323 25179 net.cpp:165] Memory required for data: 3592212480
I0912 02:50:47.109334 25179 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 02:50:47.109347 25179 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 02:50:47.109354 25179 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 02:50:47.109359 25179 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 02:50:47.109691 25179 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 02:50:47.109704 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:47.109707 25179 net.cpp:165] Memory required for data: 3636449280
I0912 02:50:47.109715 25179 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 02:50:47.109725 25179 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 02:50:47.109732 25179 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 02:50:47.109737 25179 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 02:50:47.109798 25179 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 02:50:47.109995 25179 net.cpp:150] Setting up conv3_3_D_scale
I0912 02:50:47.110005 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:47.110009 25179 net.cpp:165] Memory required for data: 3680686080
I0912 02:50:47.110016 25179 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 02:50:47.110023 25179 net.cpp:100] Creating Layer relu3_3_D
I0912 02:50:47.110029 25179 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 02:50:47.110036 25179 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 02:50:47.111215 25179 net.cpp:150] Setting up relu3_3_D
I0912 02:50:47.111232 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:47.111238 25179 net.cpp:165] Memory required for data: 3724922880
I0912 02:50:47.111241 25179 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 02:50:47.111256 25179 net.cpp:100] Creating Layer conv3_2_D
I0912 02:50:47.111263 25179 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 02:50:47.111271 25179 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 02:50:47.134110 25179 net.cpp:150] Setting up conv3_2_D
I0912 02:50:47.134129 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:47.134137 25179 net.cpp:165] Memory required for data: 3769159680
I0912 02:50:47.134146 25179 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 02:50:47.134160 25179 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 02:50:47.134166 25179 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 02:50:47.134186 25179 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 02:50:47.134498 25179 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 02:50:47.134508 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:47.134512 25179 net.cpp:165] Memory required for data: 3813396480
I0912 02:50:47.134521 25179 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 02:50:47.134531 25179 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 02:50:47.134536 25179 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 02:50:47.134541 25179 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 02:50:47.134599 25179 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 02:50:47.134793 25179 net.cpp:150] Setting up conv3_2_D_scale
I0912 02:50:47.134802 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:47.134809 25179 net.cpp:165] Memory required for data: 3857633280
I0912 02:50:47.134815 25179 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 02:50:47.134825 25179 net.cpp:100] Creating Layer relu3_2_D
I0912 02:50:47.134830 25179 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 02:50:47.134835 25179 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 02:50:47.136005 25179 net.cpp:150] Setting up relu3_2_D
I0912 02:50:47.136021 25179 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 02:50:47.136026 25179 net.cpp:165] Memory required for data: 3901870080
I0912 02:50:47.136030 25179 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 02:50:47.136044 25179 net.cpp:100] Creating Layer conv3_1_D
I0912 02:50:47.136049 25179 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 02:50:47.136059 25179 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 02:50:47.150051 25179 net.cpp:150] Setting up conv3_1_D
I0912 02:50:47.150069 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:47.150079 25179 net.cpp:165] Memory required for data: 3923988480
I0912 02:50:47.150089 25179 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 02:50:47.150101 25179 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 02:50:47.150107 25179 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 02:50:47.150115 25179 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 02:50:47.150434 25179 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 02:50:47.150444 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:47.150454 25179 net.cpp:165] Memory required for data: 3946106880
I0912 02:50:47.150462 25179 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 02:50:47.150475 25179 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 02:50:47.150480 25179 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 02:50:47.150485 25179 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 02:50:47.150545 25179 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 02:50:47.151996 25179 net.cpp:150] Setting up conv3_1_D_scale
I0912 02:50:47.152012 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:47.152019 25179 net.cpp:165] Memory required for data: 3968225280
I0912 02:50:47.152026 25179 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 02:50:47.152036 25179 net.cpp:100] Creating Layer relu3_1_D
I0912 02:50:47.152042 25179 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 02:50:47.152048 25179 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 02:50:47.152295 25179 net.cpp:150] Setting up relu3_1_D
I0912 02:50:47.152307 25179 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 02:50:47.152312 25179 net.cpp:165] Memory required for data: 3990343680
I0912 02:50:47.152315 25179 layer_factory.hpp:77] Creating layer upsample2
I0912 02:50:47.152324 25179 net.cpp:100] Creating Layer upsample2
I0912 02:50:47.152329 25179 net.cpp:434] upsample2 <- conv3_1_D
I0912 02:50:47.152335 25179 net.cpp:434] upsample2 <- pool2_mask
I0912 02:50:47.152344 25179 net.cpp:408] upsample2 -> pool2_D
I0912 02:50:47.152354 25179 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 02:50:47.152393 25179 net.cpp:150] Setting up upsample2
I0912 02:50:47.152415 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:47.152420 25179 net.cpp:165] Memory required for data: 4078817280
I0912 02:50:47.152423 25179 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 02:50:47.152437 25179 net.cpp:100] Creating Layer conv2_2_D
I0912 02:50:47.152443 25179 net.cpp:434] conv2_2_D <- pool2_D
I0912 02:50:47.152451 25179 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 02:50:47.160388 25179 net.cpp:150] Setting up conv2_2_D
I0912 02:50:47.160406 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:47.160415 25179 net.cpp:165] Memory required for data: 4167290880
I0912 02:50:47.160424 25179 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 02:50:47.160434 25179 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 02:50:47.160439 25179 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 02:50:47.160445 25179 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 02:50:47.160789 25179 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 02:50:47.160799 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:47.160804 25179 net.cpp:165] Memory required for data: 4255764480
I0912 02:50:47.160814 25179 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 02:50:47.160822 25179 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 02:50:47.160831 25179 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 02:50:47.160837 25179 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 02:50:47.160900 25179 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 02:50:47.161164 25179 net.cpp:150] Setting up conv2_2_D_scale
I0912 02:50:47.161173 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:47.161177 25179 net.cpp:165] Memory required for data: 4344238080
I0912 02:50:47.161185 25179 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 02:50:47.161195 25179 net.cpp:100] Creating Layer relu2_2_D
I0912 02:50:47.161201 25179 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 02:50:47.161206 25179 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 02:50:47.161465 25179 net.cpp:150] Setting up relu2_2_D
I0912 02:50:47.161478 25179 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 02:50:47.161483 25179 net.cpp:165] Memory required for data: 4432711680
I0912 02:50:47.161486 25179 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 02:50:47.161501 25179 net.cpp:100] Creating Layer conv2_1_D
I0912 02:50:47.161507 25179 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 02:50:47.161514 25179 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 02:50:47.167017 25179 net.cpp:150] Setting up conv2_1_D
I0912 02:50:47.167035 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:47.167044 25179 net.cpp:165] Memory required for data: 4476948480
I0912 02:50:47.167052 25179 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 02:50:47.167065 25179 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 02:50:47.167071 25179 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 02:50:47.167078 25179 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 02:50:47.167440 25179 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 02:50:47.167450 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:47.167454 25179 net.cpp:165] Memory required for data: 4521185280
I0912 02:50:47.167464 25179 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 02:50:47.167475 25179 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 02:50:47.167480 25179 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 02:50:47.167485 25179 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 02:50:47.167547 25179 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 02:50:47.167820 25179 net.cpp:150] Setting up conv2_1_D_scale
I0912 02:50:47.167830 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:47.167834 25179 net.cpp:165] Memory required for data: 4565422080
I0912 02:50:47.167840 25179 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 02:50:47.167850 25179 net.cpp:100] Creating Layer relu2_1_D
I0912 02:50:47.167855 25179 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 02:50:47.167876 25179 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 02:50:47.168115 25179 net.cpp:150] Setting up relu2_1_D
I0912 02:50:47.168126 25179 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 02:50:47.168131 25179 net.cpp:165] Memory required for data: 4609658880
I0912 02:50:47.168135 25179 layer_factory.hpp:77] Creating layer upsample1
I0912 02:50:47.168146 25179 net.cpp:100] Creating Layer upsample1
I0912 02:50:47.168151 25179 net.cpp:434] upsample1 <- conv2_1_D
I0912 02:50:47.168156 25179 net.cpp:434] upsample1 <- pool1_mask
I0912 02:50:47.168165 25179 net.cpp:408] upsample1 -> pool1_D
I0912 02:50:47.168174 25179 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 02:50:47.168212 25179 net.cpp:150] Setting up upsample1
I0912 02:50:47.168220 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:47.168223 25179 net.cpp:165] Memory required for data: 4786606080
I0912 02:50:47.168227 25179 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 02:50:47.168241 25179 net.cpp:100] Creating Layer conv1_2_D
I0912 02:50:47.168246 25179 net.cpp:434] conv1_2_D <- pool1_D
I0912 02:50:47.168252 25179 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 02:50:47.172940 25179 net.cpp:150] Setting up conv1_2_D
I0912 02:50:47.172958 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:47.172967 25179 net.cpp:165] Memory required for data: 4963553280
I0912 02:50:47.172976 25179 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 02:50:47.172986 25179 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 02:50:47.172991 25179 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 02:50:47.173001 25179 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 02:50:47.173461 25179 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 02:50:47.173472 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:47.173476 25179 net.cpp:165] Memory required for data: 5140500480
I0912 02:50:47.173485 25179 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 02:50:47.173494 25179 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 02:50:47.173501 25179 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 02:50:47.173507 25179 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 02:50:47.173568 25179 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 02:50:47.175297 25179 net.cpp:150] Setting up conv1_2_D_scale
I0912 02:50:47.175312 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:47.175318 25179 net.cpp:165] Memory required for data: 5317447680
I0912 02:50:47.175326 25179 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 02:50:47.175338 25179 net.cpp:100] Creating Layer relu1_2_D
I0912 02:50:47.175343 25179 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 02:50:47.175348 25179 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 02:50:47.175598 25179 net.cpp:150] Setting up relu1_2_D
I0912 02:50:47.175608 25179 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 02:50:47.175613 25179 net.cpp:165] Memory required for data: 5494394880
I0912 02:50:47.175617 25179 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 02:50:47.175632 25179 net.cpp:100] Creating Layer conv1_1_1_D
I0912 02:50:47.175638 25179 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 02:50:47.175644 25179 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 02:50:47.177891 25179 net.cpp:150] Setting up conv1_1_1_D
I0912 02:50:47.177908 25179 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 02:50:47.177914 25179 net.cpp:165] Memory required for data: 5499924480
I0912 02:50:47.177922 25179 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 02:50:47.177933 25179 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 02:50:47.177939 25179 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 02:50:47.177947 25179 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 02:50:47.177958 25179 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 02:50:47.178035 25179 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 02:50:47.178043 25179 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 02:50:47.178050 25179 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 02:50:47.178053 25179 net.cpp:165] Memory required for data: 5510983680
I0912 02:50:47.178057 25179 layer_factory.hpp:77] Creating layer loss
I0912 02:50:47.178068 25179 net.cpp:100] Creating Layer loss
I0912 02:50:47.178073 25179 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 02:50:47.178078 25179 net.cpp:434] loss <- label_data_1_split_0
I0912 02:50:47.178086 25179 net.cpp:408] loss -> loss
I0912 02:50:47.178097 25179 layer_factory.hpp:77] Creating layer loss
I0912 02:50:47.182147 25179 net.cpp:150] Setting up loss
I0912 02:50:47.182163 25179 net.cpp:157] Top shape: (1)
I0912 02:50:47.182173 25179 net.cpp:160]     with loss weight 1
I0912 02:50:47.182189 25179 net.cpp:165] Memory required for data: 5510983684
I0912 02:50:47.182193 25179 layer_factory.hpp:77] Creating layer accuracy
I0912 02:50:47.182207 25179 net.cpp:100] Creating Layer accuracy
I0912 02:50:47.182214 25179 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 02:50:47.182219 25179 net.cpp:434] accuracy <- label_data_1_split_1
I0912 02:50:47.182225 25179 net.cpp:408] accuracy -> accuracy
I0912 02:50:47.182235 25179 net.cpp:408] accuracy -> per_class_accuracy
I0912 02:50:47.182292 25179 net.cpp:150] Setting up accuracy
I0912 02:50:47.182301 25179 net.cpp:157] Top shape: (1)
I0912 02:50:47.182305 25179 net.cpp:157] Top shape: 2 (2)
I0912 02:50:47.182310 25179 net.cpp:165] Memory required for data: 5510983696
I0912 02:50:47.182314 25179 net.cpp:228] accuracy does not need backward computation.
I0912 02:50:47.182318 25179 net.cpp:226] loss needs backward computation.
I0912 02:50:47.182322 25179 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 02:50:47.182325 25179 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 02:50:47.182329 25179 net.cpp:226] relu1_2_D needs backward computation.
I0912 02:50:47.182333 25179 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 02:50:47.182337 25179 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 02:50:47.182339 25179 net.cpp:226] conv1_2_D needs backward computation.
I0912 02:50:47.182343 25179 net.cpp:226] upsample1 needs backward computation.
I0912 02:50:47.182346 25179 net.cpp:226] relu2_1_D needs backward computation.
I0912 02:50:47.182349 25179 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 02:50:47.182353 25179 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 02:50:47.182355 25179 net.cpp:226] conv2_1_D needs backward computation.
I0912 02:50:47.182359 25179 net.cpp:226] relu2_2_D needs backward computation.
I0912 02:50:47.182363 25179 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 02:50:47.182364 25179 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 02:50:47.182368 25179 net.cpp:226] conv2_2_D needs backward computation.
I0912 02:50:47.182371 25179 net.cpp:226] upsample2 needs backward computation.
I0912 02:50:47.182375 25179 net.cpp:226] relu3_1_D needs backward computation.
I0912 02:50:47.182379 25179 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 02:50:47.182382 25179 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 02:50:47.182385 25179 net.cpp:226] conv3_1_D needs backward computation.
I0912 02:50:47.182389 25179 net.cpp:226] relu3_2_D needs backward computation.
I0912 02:50:47.182391 25179 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 02:50:47.182394 25179 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 02:50:47.182397 25179 net.cpp:226] conv3_2_D needs backward computation.
I0912 02:50:47.182401 25179 net.cpp:226] relu3_3_D needs backward computation.
I0912 02:50:47.182404 25179 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 02:50:47.182406 25179 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 02:50:47.182423 25179 net.cpp:226] conv3_3_D needs backward computation.
I0912 02:50:47.182427 25179 net.cpp:226] upsample3 needs backward computation.
I0912 02:50:47.182431 25179 net.cpp:226] relu4_1_D needs backward computation.
I0912 02:50:47.182435 25179 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 02:50:47.182437 25179 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 02:50:47.182440 25179 net.cpp:226] conv4_1_D needs backward computation.
I0912 02:50:47.182445 25179 net.cpp:226] relu4_2_D needs backward computation.
I0912 02:50:47.182447 25179 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 02:50:47.182451 25179 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 02:50:47.182453 25179 net.cpp:226] conv4_2_D needs backward computation.
I0912 02:50:47.182456 25179 net.cpp:226] relu4_3_D needs backward computation.
I0912 02:50:47.182461 25179 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 02:50:47.182466 25179 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 02:50:47.182468 25179 net.cpp:226] conv4_3_D needs backward computation.
I0912 02:50:47.182472 25179 net.cpp:226] upsample4 needs backward computation.
I0912 02:50:47.182476 25179 net.cpp:226] relu5_1_D needs backward computation.
I0912 02:50:47.182481 25179 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 02:50:47.182483 25179 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 02:50:47.182487 25179 net.cpp:226] conv5_1_D needs backward computation.
I0912 02:50:47.182490 25179 net.cpp:226] relu5_2_D needs backward computation.
I0912 02:50:47.182493 25179 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 02:50:47.182497 25179 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 02:50:47.182499 25179 net.cpp:226] conv5_2_D needs backward computation.
I0912 02:50:47.182503 25179 net.cpp:226] relu5_3_D needs backward computation.
I0912 02:50:47.182507 25179 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 02:50:47.182509 25179 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 02:50:47.182512 25179 net.cpp:226] conv5_3_D needs backward computation.
I0912 02:50:47.182516 25179 net.cpp:226] upsample5 needs backward computation.
I0912 02:50:47.182520 25179 net.cpp:226] pool5 needs backward computation.
I0912 02:50:47.182526 25179 net.cpp:226] relu5_3 needs backward computation.
I0912 02:50:47.182529 25179 net.cpp:226] conv5_3_scale needs backward computation.
I0912 02:50:47.182533 25179 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 02:50:47.182535 25179 net.cpp:226] conv5_3 needs backward computation.
I0912 02:50:47.182539 25179 net.cpp:226] relu5_2 needs backward computation.
I0912 02:50:47.182543 25179 net.cpp:226] conv5_2_scale needs backward computation.
I0912 02:50:47.182548 25179 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 02:50:47.182551 25179 net.cpp:226] conv5_2 needs backward computation.
I0912 02:50:47.182554 25179 net.cpp:226] relu5_1 needs backward computation.
I0912 02:50:47.182559 25179 net.cpp:226] conv5_1_scale needs backward computation.
I0912 02:50:47.182561 25179 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 02:50:47.182564 25179 net.cpp:226] conv5_1 needs backward computation.
I0912 02:50:47.182569 25179 net.cpp:226] pool4 needs backward computation.
I0912 02:50:47.182572 25179 net.cpp:226] relu4_3 needs backward computation.
I0912 02:50:47.182575 25179 net.cpp:226] conv4_3_scale needs backward computation.
I0912 02:50:47.182579 25179 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 02:50:47.182581 25179 net.cpp:226] conv4_3 needs backward computation.
I0912 02:50:47.182587 25179 net.cpp:226] relu4_2 needs backward computation.
I0912 02:50:47.182590 25179 net.cpp:226] conv4_2_scale needs backward computation.
I0912 02:50:47.182593 25179 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 02:50:47.182596 25179 net.cpp:226] conv4_2 needs backward computation.
I0912 02:50:47.182600 25179 net.cpp:226] relu4_1 needs backward computation.
I0912 02:50:47.182611 25179 net.cpp:226] conv4_1_scale needs backward computation.
I0912 02:50:47.182615 25179 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 02:50:47.182617 25179 net.cpp:226] conv4_1 needs backward computation.
I0912 02:50:47.182622 25179 net.cpp:226] pool3 needs backward computation.
I0912 02:50:47.182626 25179 net.cpp:226] relu3_3 needs backward computation.
I0912 02:50:47.182628 25179 net.cpp:226] conv3_3_scale needs backward computation.
I0912 02:50:47.182632 25179 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 02:50:47.182636 25179 net.cpp:226] conv3_3 needs backward computation.
I0912 02:50:47.182639 25179 net.cpp:226] relu3_2 needs backward computation.
I0912 02:50:47.182642 25179 net.cpp:226] conv3_2_scale needs backward computation.
I0912 02:50:47.182647 25179 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 02:50:47.182652 25179 net.cpp:226] conv3_2 needs backward computation.
I0912 02:50:47.182656 25179 net.cpp:226] relu3_1 needs backward computation.
I0912 02:50:47.182658 25179 net.cpp:226] conv3_1_scale needs backward computation.
I0912 02:50:47.182662 25179 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 02:50:47.182665 25179 net.cpp:226] conv3_1 needs backward computation.
I0912 02:50:47.182669 25179 net.cpp:226] pool2 needs backward computation.
I0912 02:50:47.182675 25179 net.cpp:226] relu2_2 needs backward computation.
I0912 02:50:47.182678 25179 net.cpp:226] conv2_2_scale needs backward computation.
I0912 02:50:47.182682 25179 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 02:50:47.182684 25179 net.cpp:226] conv2_2 needs backward computation.
I0912 02:50:47.182688 25179 net.cpp:226] relu2_1 needs backward computation.
I0912 02:50:47.182693 25179 net.cpp:226] conv2_1_scale needs backward computation.
I0912 02:50:47.182695 25179 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 02:50:47.182698 25179 net.cpp:226] conv2_1 needs backward computation.
I0912 02:50:47.182703 25179 net.cpp:226] pool1 needs backward computation.
I0912 02:50:47.182708 25179 net.cpp:226] relu1_2 needs backward computation.
I0912 02:50:47.182711 25179 net.cpp:226] conv1_2_scale needs backward computation.
I0912 02:50:47.182716 25179 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 02:50:47.182719 25179 net.cpp:226] conv1_2 needs backward computation.
I0912 02:50:47.182724 25179 net.cpp:226] relu1_1 needs backward computation.
I0912 02:50:47.182729 25179 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 02:50:47.182734 25179 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 02:50:47.182736 25179 net.cpp:226] conv1_1_1 needs backward computation.
I0912 02:50:47.182740 25179 net.cpp:228] label_data_1_split does not need backward computation.
I0912 02:50:47.182745 25179 net.cpp:228] data does not need backward computation.
I0912 02:50:47.182749 25179 net.cpp:270] This network produces output accuracy
I0912 02:50:47.182751 25179 net.cpp:270] This network produces output loss
I0912 02:50:47.182755 25179 net.cpp:270] This network produces output per_class_accuracy
I0912 02:50:47.182821 25179 net.cpp:283] Network initialization done.
I0912 02:50:47.183195 25179 solver.cpp:60] Solver scaffolding done.
I0912 02:50:47.192519 25179 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0912 02:50:47.436187 25179 net.cpp:761] Ignoring source layer conv1_1
I0912 02:50:47.436216 25179 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 02:50:47.436270 25179 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 02:50:47.436278 25179 net.cpp:761] Ignoring source layer pool1_drop
I0912 02:50:47.436357 25179 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 02:50:47.436504 25179 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 02:50:47.436511 25179 net.cpp:761] Ignoring source layer pool2_drop
I0912 02:50:47.436784 25179 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 02:50:47.437284 25179 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 02:50:47.437822 25179 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 02:50:47.437855 25179 net.cpp:761] Ignoring source layer pool3_drop
I0912 02:50:47.438863 25179 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 02:50:47.440861 25179 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 02:50:47.442883 25179 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 02:50:47.442893 25179 net.cpp:761] Ignoring source layer pool4_drop
I0912 02:50:47.444900 25179 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 02:50:47.446902 25179 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 02:50:47.448904 25179 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 02:50:47.448911 25179 net.cpp:761] Ignoring source layer pool5_drop
I0912 02:50:47.448916 25179 net.cpp:761] Ignoring source layer upsample5_drop
I0912 02:50:47.450929 25179 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 02:50:47.452934 25179 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 02:50:47.454952 25179 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 02:50:47.454963 25179 net.cpp:761] Ignoring source layer upsample4_drop
I0912 02:50:47.456969 25179 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 02:50:47.459039 25179 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 02:50:47.460047 25179 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 02:50:47.460054 25179 net.cpp:761] Ignoring source layer upsample3_drop
I0912 02:50:47.460556 25179 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 02:50:47.461128 25179 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 02:50:47.461398 25179 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 02:50:47.461405 25179 net.cpp:761] Ignoring source layer upsample2_drop
I0912 02:50:47.461540 25179 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 02:50:47.461617 25179 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 02:50:47.461624 25179 net.cpp:761] Ignoring source layer upsample1_drop
I0912 02:50:47.461666 25179 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 02:50:47.461674 25179 net.cpp:761] Ignoring source layer conv1_1_D
I0912 02:50:47.461678 25179 net.cpp:761] Ignoring source layer prob
I0912 02:50:47.709282 25179 net.cpp:761] Ignoring source layer conv1_1
I0912 02:50:47.709308 25179 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 02:50:47.709354 25179 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 02:50:47.709362 25179 net.cpp:761] Ignoring source layer pool1_drop
I0912 02:50:47.709463 25179 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 02:50:47.709611 25179 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 02:50:47.709617 25179 net.cpp:761] Ignoring source layer pool2_drop
I0912 02:50:47.709893 25179 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 02:50:47.710413 25179 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 02:50:47.710913 25179 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 02:50:47.710919 25179 net.cpp:761] Ignoring source layer pool3_drop
I0912 02:50:47.711916 25179 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 02:50:47.713944 25179 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 02:50:47.715952 25179 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 02:50:47.715960 25179 net.cpp:761] Ignoring source layer pool4_drop
I0912 02:50:47.717988 25179 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 02:50:47.719982 25179 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 02:50:47.721976 25179 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 02:50:47.721987 25179 net.cpp:761] Ignoring source layer pool5_drop
I0912 02:50:47.721992 25179 net.cpp:761] Ignoring source layer upsample5_drop
I0912 02:50:47.723980 25179 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 02:50:47.725989 25179 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 02:50:47.727978 25179 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 02:50:47.727988 25179 net.cpp:761] Ignoring source layer upsample4_drop
I0912 02:50:47.729992 25179 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 02:50:47.732110 25179 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 02:50:47.733148 25179 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 02:50:47.733156 25179 net.cpp:761] Ignoring source layer upsample3_drop
I0912 02:50:47.733675 25179 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 02:50:47.734179 25179 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 02:50:47.734437 25179 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 02:50:47.734443 25179 net.cpp:761] Ignoring source layer upsample2_drop
I0912 02:50:47.734580 25179 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 02:50:47.734654 25179 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 02:50:47.734661 25179 net.cpp:761] Ignoring source layer upsample1_drop
I0912 02:50:47.734704 25179 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 02:50:47.734711 25179 net.cpp:761] Ignoring source layer conv1_1_D
I0912 02:50:47.734714 25179 net.cpp:761] Ignoring source layer prob
I0912 02:50:47.743747 25179 caffe.cpp:251] Starting Optimization
I0912 02:50:47.743770 25179 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0912 02:50:47.743775 25179 solver.cpp:280] Learning Rate Policy: step
I0912 02:50:48.728404 25179 solver.cpp:228] Iteration 0, loss = 1.24212
I0912 02:50:48.728442 25179 solver.cpp:244]     Train net output #0: accuracy = 0.435579
I0912 02:50:48.728458 25179 solver.cpp:244]     Train net output #1: loss = 1.24212 (* 1 = 1.24212 loss)
I0912 02:50:48.728469 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.665072
I0912 02:50:48.728476 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.266422
I0912 02:50:48.728498 25179 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0912 02:51:04.937252 25179 solver.cpp:228] Iteration 20, loss = 0.594805
I0912 02:51:04.937307 25179 solver.cpp:244]     Train net output #0: accuracy = 0.68183
I0912 02:51:04.937320 25179 solver.cpp:244]     Train net output #1: loss = 0.594805 (* 1 = 0.594805 loss)
I0912 02:51:04.937327 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.618718
I0912 02:51:04.937333 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.966398
I0912 02:51:04.937340 25179 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0912 02:51:21.530930 25179 solver.cpp:228] Iteration 40, loss = 0.273909
I0912 02:51:21.531067 25179 solver.cpp:244]     Train net output #0: accuracy = 0.881651
I0912 02:51:21.531082 25179 solver.cpp:244]     Train net output #1: loss = 0.273909 (* 1 = 0.273909 loss)
I0912 02:51:21.531088 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.818912
I0912 02:51:21.531093 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983332
I0912 02:51:21.531101 25179 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0912 02:51:38.155652 25179 solver.cpp:228] Iteration 60, loss = 0.335185
I0912 02:51:38.155700 25179 solver.cpp:244]     Train net output #0: accuracy = 0.829582
I0912 02:51:38.155714 25179 solver.cpp:244]     Train net output #1: loss = 0.335185 (* 1 = 0.335185 loss)
I0912 02:51:38.155721 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.747598
I0912 02:51:38.155726 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995374
I0912 02:51:38.155735 25179 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0912 02:51:54.773691 25179 solver.cpp:228] Iteration 80, loss = 0.382262
I0912 02:51:54.773826 25179 solver.cpp:244]     Train net output #0: accuracy = 0.887734
I0912 02:51:54.773843 25179 solver.cpp:244]     Train net output #1: loss = 0.382262 (* 1 = 0.382262 loss)
I0912 02:51:54.773854 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.953635
I0912 02:51:54.773859 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.83521
I0912 02:51:54.773869 25179 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0912 02:52:11.389917 25179 solver.cpp:228] Iteration 100, loss = 0.162062
I0912 02:52:11.389958 25179 solver.cpp:244]     Train net output #0: accuracy = 0.95114
I0912 02:52:11.389971 25179 solver.cpp:244]     Train net output #1: loss = 0.162062 (* 1 = 0.162062 loss)
I0912 02:52:11.389977 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.944722
I0912 02:52:11.389981 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.957366
I0912 02:52:11.389989 25179 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0912 02:52:28.002893 25179 solver.cpp:228] Iteration 120, loss = 0.511099
I0912 02:52:28.003067 25179 solver.cpp:244]     Train net output #0: accuracy = 0.823594
I0912 02:52:28.003105 25179 solver.cpp:244]     Train net output #1: loss = 0.511098 (* 1 = 0.511098 loss)
I0912 02:52:28.003113 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.812136
I0912 02:52:28.003118 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.865854
I0912 02:52:28.003127 25179 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0912 02:52:44.621093 25179 solver.cpp:228] Iteration 140, loss = 0.172829
I0912 02:52:44.621140 25179 solver.cpp:244]     Train net output #0: accuracy = 0.960192
I0912 02:52:44.621155 25179 solver.cpp:244]     Train net output #1: loss = 0.172829 (* 1 = 0.172829 loss)
I0912 02:52:44.621161 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977905
I0912 02:52:44.621166 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.944522
I0912 02:52:44.621173 25179 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0912 02:53:01.238734 25179 solver.cpp:228] Iteration 160, loss = 0.164145
I0912 02:53:01.238871 25179 solver.cpp:244]     Train net output #0: accuracy = 0.96105
I0912 02:53:01.238886 25179 solver.cpp:244]     Train net output #1: loss = 0.164145 (* 1 = 0.164145 loss)
I0912 02:53:01.238893 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983953
I0912 02:53:01.238898 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.931841
I0912 02:53:01.238904 25179 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0912 02:53:17.859060 25179 solver.cpp:228] Iteration 180, loss = 0.096959
I0912 02:53:17.859103 25179 solver.cpp:244]     Train net output #0: accuracy = 0.961043
I0912 02:53:17.859117 25179 solver.cpp:244]     Train net output #1: loss = 0.0969589 (* 1 = 0.0969589 loss)
I0912 02:53:17.859122 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.948798
I0912 02:53:17.859127 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982756
I0912 02:53:17.859134 25179 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0912 02:53:34.461544 25179 solver.cpp:228] Iteration 200, loss = 0.08739
I0912 02:53:34.461664 25179 solver.cpp:244]     Train net output #0: accuracy = 0.963984
I0912 02:53:34.461680 25179 solver.cpp:244]     Train net output #1: loss = 0.0873899 (* 1 = 0.0873899 loss)
I0912 02:53:34.461686 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.951271
I0912 02:53:34.461691 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982446
I0912 02:53:34.461699 25179 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0912 02:53:51.070003 25179 solver.cpp:228] Iteration 220, loss = 0.208447
I0912 02:53:51.070040 25179 solver.cpp:244]     Train net output #0: accuracy = 0.936623
I0912 02:53:51.070052 25179 solver.cpp:244]     Train net output #1: loss = 0.208447 (* 1 = 0.208447 loss)
I0912 02:53:51.070060 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.925777
I0912 02:53:51.070065 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.947414
I0912 02:53:51.070071 25179 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0912 02:54:07.686532 25179 solver.cpp:228] Iteration 240, loss = 0.198849
I0912 02:54:07.686658 25179 solver.cpp:244]     Train net output #0: accuracy = 0.941986
I0912 02:54:07.686673 25179 solver.cpp:244]     Train net output #1: loss = 0.198849 (* 1 = 0.198849 loss)
I0912 02:54:07.686679 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.965645
I0912 02:54:07.686684 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.91557
I0912 02:54:07.686692 25179 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0912 02:54:24.311821 25179 solver.cpp:228] Iteration 260, loss = 0.0871782
I0912 02:54:24.311866 25179 solver.cpp:244]     Train net output #0: accuracy = 0.977337
I0912 02:54:24.311879 25179 solver.cpp:244]     Train net output #1: loss = 0.0871781 (* 1 = 0.0871781 loss)
I0912 02:54:24.311885 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972925
I0912 02:54:24.311890 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981308
I0912 02:54:24.311897 25179 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0912 02:54:40.920202 25179 solver.cpp:228] Iteration 280, loss = 0.0347729
I0912 02:54:40.920393 25179 solver.cpp:244]     Train net output #0: accuracy = 0.989654
I0912 02:54:40.920413 25179 solver.cpp:244]     Train net output #1: loss = 0.0347728 (* 1 = 0.0347728 loss)
I0912 02:54:40.920419 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986262
I0912 02:54:40.920424 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99384
I0912 02:54:40.920433 25179 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0912 02:54:57.518573 25179 solver.cpp:228] Iteration 300, loss = 0.0402767
I0912 02:54:57.518616 25179 solver.cpp:244]     Train net output #0: accuracy = 0.988197
I0912 02:54:57.518628 25179 solver.cpp:244]     Train net output #1: loss = 0.0402766 (* 1 = 0.0402766 loss)
I0912 02:54:57.518635 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985094
I0912 02:54:57.518640 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991522
I0912 02:54:57.518647 25179 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0912 02:55:14.139883 25179 solver.cpp:228] Iteration 320, loss = 0.142287
I0912 02:55:14.140012 25179 solver.cpp:244]     Train net output #0: accuracy = 0.965806
I0912 02:55:14.140029 25179 solver.cpp:244]     Train net output #1: loss = 0.142287 (* 1 = 0.142287 loss)
I0912 02:55:14.140036 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990389
I0912 02:55:14.140049 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.949897
I0912 02:55:14.140058 25179 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0912 02:55:30.748706 25179 solver.cpp:228] Iteration 340, loss = 0.052473
I0912 02:55:30.748747 25179 solver.cpp:244]     Train net output #0: accuracy = 0.990932
I0912 02:55:30.748764 25179 solver.cpp:244]     Train net output #1: loss = 0.0524729 (* 1 = 0.0524729 loss)
I0912 02:55:30.748770 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987075
I0912 02:55:30.748775 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99352
I0912 02:55:30.748783 25179 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0912 02:55:47.350618 25179 solver.cpp:228] Iteration 360, loss = 0.0353966
I0912 02:55:47.350745 25179 solver.cpp:244]     Train net output #0: accuracy = 0.988546
I0912 02:55:47.350760 25179 solver.cpp:244]     Train net output #1: loss = 0.0353965 (* 1 = 0.0353965 loss)
I0912 02:55:47.350766 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985861
I0912 02:55:47.350777 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992135
I0912 02:55:47.350785 25179 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0912 02:56:03.974203 25179 solver.cpp:228] Iteration 380, loss = 0.104016
I0912 02:56:03.974246 25179 solver.cpp:244]     Train net output #0: accuracy = 0.949008
I0912 02:56:03.974261 25179 solver.cpp:244]     Train net output #1: loss = 0.104016 (* 1 = 0.104016 loss)
I0912 02:56:03.974268 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.92973
I0912 02:56:03.974273 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992584
I0912 02:56:03.974282 25179 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0912 02:56:20.604481 25179 solver.cpp:228] Iteration 400, loss = 0.0347494
I0912 02:56:20.604610 25179 solver.cpp:244]     Train net output #0: accuracy = 0.986461
I0912 02:56:20.604625 25179 solver.cpp:244]     Train net output #1: loss = 0.0347494 (* 1 = 0.0347494 loss)
I0912 02:56:20.604635 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977901
I0912 02:56:20.604640 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995747
I0912 02:56:20.604647 25179 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0912 02:56:37.220981 25179 solver.cpp:228] Iteration 420, loss = 0.0720553
I0912 02:56:37.221025 25179 solver.cpp:244]     Train net output #0: accuracy = 0.985896
I0912 02:56:37.221040 25179 solver.cpp:244]     Train net output #1: loss = 0.0720552 (* 1 = 0.0720552 loss)
I0912 02:56:37.221046 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986928
I0912 02:56:37.221051 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985348
I0912 02:56:37.221060 25179 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0912 02:56:53.831142 25179 solver.cpp:228] Iteration 440, loss = 0.0453117
I0912 02:56:53.831331 25179 solver.cpp:244]     Train net output #0: accuracy = 0.980349
I0912 02:56:53.831348 25179 solver.cpp:244]     Train net output #1: loss = 0.0453116 (* 1 = 0.0453116 loss)
I0912 02:56:53.831362 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969528
I0912 02:56:53.831367 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993604
I0912 02:56:53.831374 25179 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0912 02:57:10.454129 25179 solver.cpp:228] Iteration 460, loss = 0.020905
I0912 02:57:10.454170 25179 solver.cpp:244]     Train net output #0: accuracy = 0.991994
I0912 02:57:10.454186 25179 solver.cpp:244]     Train net output #1: loss = 0.0209049 (* 1 = 0.0209049 loss)
I0912 02:57:10.454193 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986202
I0912 02:57:10.454198 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998631
I0912 02:57:10.454206 25179 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0912 02:57:27.057924 25179 solver.cpp:228] Iteration 480, loss = 0.0352394
I0912 02:57:27.058044 25179 solver.cpp:244]     Train net output #0: accuracy = 0.987549
I0912 02:57:27.058061 25179 solver.cpp:244]     Train net output #1: loss = 0.0352393 (* 1 = 0.0352393 loss)
I0912 02:57:27.058068 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988382
I0912 02:57:27.058073 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985123
I0912 02:57:27.058082 25179 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0912 02:57:43.680318 25179 solver.cpp:228] Iteration 500, loss = 0.0270575
I0912 02:57:43.680361 25179 solver.cpp:244]     Train net output #0: accuracy = 0.991123
I0912 02:57:43.680375 25179 solver.cpp:244]     Train net output #1: loss = 0.0270575 (* 1 = 0.0270575 loss)
I0912 02:57:43.680380 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99298
I0912 02:57:43.680387 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987604
I0912 02:57:43.680394 25179 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0912 02:58:00.276748 25179 solver.cpp:228] Iteration 520, loss = 0.0275868
I0912 02:58:00.276865 25179 solver.cpp:244]     Train net output #0: accuracy = 0.990444
I0912 02:58:00.276883 25179 solver.cpp:244]     Train net output #1: loss = 0.0275867 (* 1 = 0.0275867 loss)
I0912 02:58:00.276895 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991681
I0912 02:58:00.276901 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98729
I0912 02:58:00.276908 25179 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0912 02:58:16.919085 25179 solver.cpp:228] Iteration 540, loss = 0.0363855
I0912 02:58:16.919127 25179 solver.cpp:244]     Train net output #0: accuracy = 0.986823
I0912 02:58:16.919140 25179 solver.cpp:244]     Train net output #1: loss = 0.0363855 (* 1 = 0.0363855 loss)
I0912 02:58:16.919147 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987044
I0912 02:58:16.919152 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986386
I0912 02:58:16.919159 25179 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0912 02:58:33.529842 25179 solver.cpp:228] Iteration 560, loss = 0.0442572
I0912 02:58:33.530037 25179 solver.cpp:244]     Train net output #0: accuracy = 0.988821
I0912 02:58:33.530056 25179 solver.cpp:244]     Train net output #1: loss = 0.0442572 (* 1 = 0.0442572 loss)
I0912 02:58:33.530069 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992504
I0912 02:58:33.530081 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986101
I0912 02:58:33.530087 25179 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0912 02:58:50.138469 25179 solver.cpp:228] Iteration 580, loss = 0.0276938
I0912 02:58:50.138512 25179 solver.cpp:244]     Train net output #0: accuracy = 0.989518
I0912 02:58:50.138526 25179 solver.cpp:244]     Train net output #1: loss = 0.0276937 (* 1 = 0.0276937 loss)
I0912 02:58:50.138532 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988149
I0912 02:58:50.138537 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992629
I0912 02:58:50.138545 25179 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0912 02:59:06.749511 25179 solver.cpp:228] Iteration 600, loss = 0.0157827
I0912 02:59:06.749642 25179 solver.cpp:244]     Train net output #0: accuracy = 0.993659
I0912 02:59:06.749658 25179 solver.cpp:244]     Train net output #1: loss = 0.0157827 (* 1 = 0.0157827 loss)
I0912 02:59:06.749670 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992417
I0912 02:59:06.749676 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996668
I0912 02:59:06.749685 25179 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0912 02:59:23.371456 25179 solver.cpp:228] Iteration 620, loss = 0.0283772
I0912 02:59:23.371503 25179 solver.cpp:244]     Train net output #0: accuracy = 0.987804
I0912 02:59:23.371518 25179 solver.cpp:244]     Train net output #1: loss = 0.0283772 (* 1 = 0.0283772 loss)
I0912 02:59:23.371525 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982228
I0912 02:59:23.371529 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995307
I0912 02:59:23.371537 25179 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0912 02:59:39.998654 25179 solver.cpp:228] Iteration 640, loss = 0.0286845
I0912 02:59:39.998783 25179 solver.cpp:244]     Train net output #0: accuracy = 0.988398
I0912 02:59:39.998798 25179 solver.cpp:244]     Train net output #1: loss = 0.0286844 (* 1 = 0.0286844 loss)
I0912 02:59:39.998805 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985561
I0912 02:59:39.998814 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993894
I0912 02:59:39.998822 25179 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0912 02:59:56.619791 25179 solver.cpp:228] Iteration 660, loss = 0.0202951
I0912 02:59:56.619835 25179 solver.cpp:244]     Train net output #0: accuracy = 0.991243
I0912 02:59:56.619850 25179 solver.cpp:244]     Train net output #1: loss = 0.020295 (* 1 = 0.020295 loss)
I0912 02:59:56.619856 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986498
I0912 02:59:56.619861 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997801
I0912 02:59:56.619869 25179 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0912 03:00:13.237515 25179 solver.cpp:228] Iteration 680, loss = 0.0201709
I0912 03:00:13.237642 25179 solver.cpp:244]     Train net output #0: accuracy = 0.992377
I0912 03:00:13.237658 25179 solver.cpp:244]     Train net output #1: loss = 0.0201708 (* 1 = 0.0201708 loss)
I0912 03:00:13.237664 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988337
I0912 03:00:13.237670 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996428
I0912 03:00:13.237678 25179 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0912 03:00:29.834154 25179 solver.cpp:228] Iteration 700, loss = 0.0206161
I0912 03:00:29.834192 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99123
I0912 03:00:29.834208 25179 solver.cpp:244]     Train net output #1: loss = 0.0206161 (* 1 = 0.0206161 loss)
I0912 03:00:29.834213 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98748
I0912 03:00:29.834219 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996808
I0912 03:00:29.834226 25179 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0912 03:00:46.432274 25179 solver.cpp:228] Iteration 720, loss = 0.0250043
I0912 03:00:46.432432 25179 solver.cpp:244]     Train net output #0: accuracy = 0.990411
I0912 03:00:46.432451 25179 solver.cpp:244]     Train net output #1: loss = 0.0250042 (* 1 = 0.0250042 loss)
I0912 03:00:46.432456 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9894
I0912 03:00:46.432462 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99212
I0912 03:00:46.432471 25179 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0912 03:01:03.031687 25179 solver.cpp:228] Iteration 740, loss = 0.0340298
I0912 03:01:03.031731 25179 solver.cpp:244]     Train net output #0: accuracy = 0.987347
I0912 03:01:03.031746 25179 solver.cpp:244]     Train net output #1: loss = 0.0340297 (* 1 = 0.0340297 loss)
I0912 03:01:03.031752 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984704
I0912 03:01:03.031757 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99657
I0912 03:01:03.031766 25179 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0912 03:01:19.647137 25179 solver.cpp:228] Iteration 760, loss = 0.201122
I0912 03:01:19.647261 25179 solver.cpp:244]     Train net output #0: accuracy = 0.919058
I0912 03:01:19.647279 25179 solver.cpp:244]     Train net output #1: loss = 0.201122 (* 1 = 0.201122 loss)
I0912 03:01:19.647290 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.879948
I0912 03:01:19.647295 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993689
I0912 03:01:19.647303 25179 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0912 03:01:36.277855 25179 solver.cpp:228] Iteration 780, loss = 0.0777791
I0912 03:01:36.277896 25179 solver.cpp:244]     Train net output #0: accuracy = 0.967108
I0912 03:01:36.277910 25179 solver.cpp:244]     Train net output #1: loss = 0.077779 (* 1 = 0.077779 loss)
I0912 03:01:36.277917 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.959319
I0912 03:01:36.277922 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987525
I0912 03:01:36.277930 25179 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0912 03:01:52.896225 25179 solver.cpp:228] Iteration 800, loss = 0.061914
I0912 03:01:52.896353 25179 solver.cpp:244]     Train net output #0: accuracy = 0.975887
I0912 03:01:52.896371 25179 solver.cpp:244]     Train net output #1: loss = 0.0619139 (* 1 = 0.0619139 loss)
I0912 03:01:52.896384 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974997
I0912 03:01:52.896389 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979671
I0912 03:01:52.896399 25179 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0912 03:02:09.492138 25179 solver.cpp:228] Iteration 820, loss = 0.0529548
I0912 03:02:09.492177 25179 solver.cpp:244]     Train net output #0: accuracy = 0.975567
I0912 03:02:09.492192 25179 solver.cpp:244]     Train net output #1: loss = 0.0529548 (* 1 = 0.0529548 loss)
I0912 03:02:09.492199 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.964527
I0912 03:02:09.492204 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99414
I0912 03:02:09.492213 25179 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0912 03:02:26.090690 25179 solver.cpp:228] Iteration 840, loss = 0.104061
I0912 03:02:26.090814 25179 solver.cpp:244]     Train net output #0: accuracy = 0.972865
I0912 03:02:26.090831 25179 solver.cpp:244]     Train net output #1: loss = 0.104061 (* 1 = 0.104061 loss)
I0912 03:02:26.090837 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974818
I0912 03:02:26.090842 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.971577
I0912 03:02:26.090850 25179 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0912 03:02:42.716084 25179 solver.cpp:228] Iteration 860, loss = 0.0426827
I0912 03:02:42.716130 25179 solver.cpp:244]     Train net output #0: accuracy = 0.986753
I0912 03:02:42.716145 25179 solver.cpp:244]     Train net output #1: loss = 0.0426827 (* 1 = 0.0426827 loss)
I0912 03:02:42.716151 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988425
I0912 03:02:42.716156 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979945
I0912 03:02:42.716164 25179 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0912 03:02:59.331475 25179 solver.cpp:228] Iteration 880, loss = 0.0457664
I0912 03:02:59.331661 25179 solver.cpp:244]     Train net output #0: accuracy = 0.97753
I0912 03:02:59.331677 25179 solver.cpp:244]     Train net output #1: loss = 0.0457664 (* 1 = 0.0457664 loss)
I0912 03:02:59.331686 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.966914
I0912 03:02:59.331692 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99698
I0912 03:02:59.331701 25179 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0912 03:03:15.933442 25179 solver.cpp:228] Iteration 900, loss = 0.0533186
I0912 03:03:15.933490 25179 solver.cpp:244]     Train net output #0: accuracy = 0.97924
I0912 03:03:15.933504 25179 solver.cpp:244]     Train net output #1: loss = 0.0533186 (* 1 = 0.0533186 loss)
I0912 03:03:15.933511 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972326
I0912 03:03:15.933517 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988846
I0912 03:03:15.933527 25179 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0912 03:03:32.546211 25179 solver.cpp:228] Iteration 920, loss = 0.0386678
I0912 03:03:32.546329 25179 solver.cpp:244]     Train net output #0: accuracy = 0.986819
I0912 03:03:32.546345 25179 solver.cpp:244]     Train net output #1: loss = 0.0386677 (* 1 = 0.0386677 loss)
I0912 03:03:32.546351 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987725
I0912 03:03:32.546356 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98381
I0912 03:03:32.546365 25179 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0912 03:03:49.170579 25179 solver.cpp:228] Iteration 940, loss = 0.0347822
I0912 03:03:49.170619 25179 solver.cpp:244]     Train net output #0: accuracy = 0.983997
I0912 03:03:49.170635 25179 solver.cpp:244]     Train net output #1: loss = 0.0347822 (* 1 = 0.0347822 loss)
I0912 03:03:49.170641 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979603
I0912 03:03:49.170647 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995262
I0912 03:03:49.170655 25179 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0912 03:04:05.789041 25179 solver.cpp:228] Iteration 960, loss = 0.0258251
I0912 03:04:05.789192 25179 solver.cpp:244]     Train net output #0: accuracy = 0.989505
I0912 03:04:05.789233 25179 solver.cpp:244]     Train net output #1: loss = 0.0258251 (* 1 = 0.0258251 loss)
I0912 03:04:05.789242 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988213
I0912 03:04:05.789247 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992341
I0912 03:04:05.789257 25179 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0912 03:04:22.493497 25179 solver.cpp:228] Iteration 980, loss = 0.0142491
I0912 03:04:22.493541 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994716
I0912 03:04:22.493553 25179 solver.cpp:244]     Train net output #1: loss = 0.014249 (* 1 = 0.014249 loss)
I0912 03:04:22.493559 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99363
I0912 03:04:22.493564 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996128
I0912 03:04:22.493572 25179 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0912 03:04:39.089133 25179 solver.cpp:228] Iteration 1000, loss = 0.0246431
I0912 03:04:39.089257 25179 solver.cpp:244]     Train net output #0: accuracy = 0.990828
I0912 03:04:39.089273 25179 solver.cpp:244]     Train net output #1: loss = 0.0246431 (* 1 = 0.0246431 loss)
I0912 03:04:39.089285 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990656
I0912 03:04:39.089290 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99129
I0912 03:04:39.089298 25179 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0912 03:04:55.694442 25179 solver.cpp:228] Iteration 1020, loss = 0.023971
I0912 03:04:55.694483 25179 solver.cpp:244]     Train net output #0: accuracy = 0.992951
I0912 03:04:55.694496 25179 solver.cpp:244]     Train net output #1: loss = 0.0239709 (* 1 = 0.0239709 loss)
I0912 03:04:55.694502 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992526
I0912 03:04:55.694507 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993284
I0912 03:04:55.694514 25179 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0912 03:05:12.296653 25179 solver.cpp:228] Iteration 1040, loss = 0.071455
I0912 03:05:12.296823 25179 solver.cpp:244]     Train net output #0: accuracy = 0.98155
I0912 03:05:12.296841 25179 solver.cpp:244]     Train net output #1: loss = 0.071455 (* 1 = 0.071455 loss)
I0912 03:05:12.296849 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996333
I0912 03:05:12.296855 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.940481
I0912 03:05:12.296864 25179 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0912 03:05:28.895586 25179 solver.cpp:228] Iteration 1060, loss = 0.0319791
I0912 03:05:28.895622 25179 solver.cpp:244]     Train net output #0: accuracy = 0.988333
I0912 03:05:28.895638 25179 solver.cpp:244]     Train net output #1: loss = 0.0319791 (* 1 = 0.0319791 loss)
I0912 03:05:28.895651 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977543
I0912 03:05:28.895656 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995618
I0912 03:05:28.895663 25179 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0912 03:05:45.513556 25179 solver.cpp:228] Iteration 1080, loss = 0.0279879
I0912 03:05:45.513690 25179 solver.cpp:244]     Train net output #0: accuracy = 0.98816
I0912 03:05:45.513705 25179 solver.cpp:244]     Train net output #1: loss = 0.0279879 (* 1 = 0.0279879 loss)
I0912 03:05:45.513711 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980787
I0912 03:05:45.513716 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995829
I0912 03:05:45.513723 25179 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0912 03:06:02.091055 25179 solver.cpp:228] Iteration 1100, loss = 0.0224666
I0912 03:06:02.091097 25179 solver.cpp:244]     Train net output #0: accuracy = 0.992092
I0912 03:06:02.091111 25179 solver.cpp:244]     Train net output #1: loss = 0.0224666 (* 1 = 0.0224666 loss)
I0912 03:06:02.091117 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991211
I0912 03:06:02.091122 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9931
I0912 03:06:02.091130 25179 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0912 03:06:18.699800 25179 solver.cpp:228] Iteration 1120, loss = 0.023307
I0912 03:06:18.699918 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99102
I0912 03:06:18.699934 25179 solver.cpp:244]     Train net output #1: loss = 0.023307 (* 1 = 0.023307 loss)
I0912 03:06:18.699940 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989993
I0912 03:06:18.699944 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992566
I0912 03:06:18.699952 25179 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0912 03:06:35.291316 25179 solver.cpp:228] Iteration 1140, loss = 0.00907928
I0912 03:06:35.291360 25179 solver.cpp:244]     Train net output #0: accuracy = 0.9965
I0912 03:06:35.291375 25179 solver.cpp:244]     Train net output #1: loss = 0.00907927 (* 1 = 0.00907927 loss)
I0912 03:06:35.291383 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99601
I0912 03:06:35.291388 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997379
I0912 03:06:35.291396 25179 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0912 03:06:51.876210 25179 solver.cpp:228] Iteration 1160, loss = 0.0225566
I0912 03:06:51.876389 25179 solver.cpp:244]     Train net output #0: accuracy = 0.990369
I0912 03:06:51.876406 25179 solver.cpp:244]     Train net output #1: loss = 0.0225566 (* 1 = 0.0225566 loss)
I0912 03:06:51.876416 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985267
I0912 03:06:51.876421 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996499
I0912 03:06:51.876430 25179 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0912 03:07:08.473897 25179 solver.cpp:228] Iteration 1180, loss = 0.0203925
I0912 03:07:08.473937 25179 solver.cpp:244]     Train net output #0: accuracy = 0.991008
I0912 03:07:08.473951 25179 solver.cpp:244]     Train net output #1: loss = 0.0203925 (* 1 = 0.0203925 loss)
I0912 03:07:08.473958 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982759
I0912 03:07:08.473963 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998579
I0912 03:07:08.473969 25179 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0912 03:07:25.075474 25179 solver.cpp:228] Iteration 1200, loss = 0.0186805
I0912 03:07:25.075600 25179 solver.cpp:244]     Train net output #0: accuracy = 0.992797
I0912 03:07:25.075616 25179 solver.cpp:244]     Train net output #1: loss = 0.0186805 (* 1 = 0.0186805 loss)
I0912 03:07:25.075628 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991164
I0912 03:07:25.075634 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994806
I0912 03:07:25.075641 25179 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0912 03:07:41.678783 25179 solver.cpp:228] Iteration 1220, loss = 0.00944522
I0912 03:07:41.678825 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995852
I0912 03:07:41.678838 25179 solver.cpp:244]     Train net output #1: loss = 0.00944522 (* 1 = 0.00944522 loss)
I0912 03:07:41.678845 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994485
I0912 03:07:41.678850 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998586
I0912 03:07:41.678858 25179 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0912 03:07:58.276062 25179 solver.cpp:228] Iteration 1240, loss = 0.0201688
I0912 03:07:58.276185 25179 solver.cpp:244]     Train net output #0: accuracy = 0.992546
I0912 03:07:58.276201 25179 solver.cpp:244]     Train net output #1: loss = 0.0201688 (* 1 = 0.0201688 loss)
I0912 03:07:58.276216 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993265
I0912 03:07:58.276227 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990899
I0912 03:07:58.276235 25179 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0912 03:08:14.872213 25179 solver.cpp:228] Iteration 1260, loss = 0.00933039
I0912 03:08:14.872256 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996071
I0912 03:08:14.872268 25179 solver.cpp:244]     Train net output #1: loss = 0.00933038 (* 1 = 0.00933038 loss)
I0912 03:08:14.872274 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994861
I0912 03:08:14.872279 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998104
I0912 03:08:14.872287 25179 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0912 03:08:31.474385 25179 solver.cpp:228] Iteration 1280, loss = 0.0183516
I0912 03:08:31.474516 25179 solver.cpp:244]     Train net output #0: accuracy = 0.993339
I0912 03:08:31.474532 25179 solver.cpp:244]     Train net output #1: loss = 0.0183516 (* 1 = 0.0183516 loss)
I0912 03:08:31.474539 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994192
I0912 03:08:31.474545 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991768
I0912 03:08:31.474555 25179 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0912 03:08:48.071087 25179 solver.cpp:228] Iteration 1300, loss = 0.0131393
I0912 03:08:48.071125 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995683
I0912 03:08:48.071138 25179 solver.cpp:244]     Train net output #1: loss = 0.0131393 (* 1 = 0.0131393 loss)
I0912 03:08:48.071146 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996954
I0912 03:08:48.071151 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992675
I0912 03:08:48.071157 25179 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0912 03:09:04.657112 25179 solver.cpp:228] Iteration 1320, loss = 0.0405577
I0912 03:09:04.657304 25179 solver.cpp:244]     Train net output #0: accuracy = 0.981418
I0912 03:09:04.657320 25179 solver.cpp:244]     Train net output #1: loss = 0.0405577 (* 1 = 0.0405577 loss)
I0912 03:09:04.657326 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.976998
I0912 03:09:04.657331 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993984
I0912 03:09:04.657340 25179 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0912 03:09:21.254845 25179 solver.cpp:228] Iteration 1340, loss = 0.0138539
I0912 03:09:21.254889 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994588
I0912 03:09:21.254904 25179 solver.cpp:244]     Train net output #1: loss = 0.0138539 (* 1 = 0.0138539 loss)
I0912 03:09:21.254909 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993403
I0912 03:09:21.254914 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996334
I0912 03:09:21.254921 25179 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0912 03:09:37.866856 25179 solver.cpp:228] Iteration 1360, loss = 0.0161315
I0912 03:09:37.866986 25179 solver.cpp:244]     Train net output #0: accuracy = 0.993137
I0912 03:09:37.867002 25179 solver.cpp:244]     Train net output #1: loss = 0.0161315 (* 1 = 0.0161315 loss)
I0912 03:09:37.867007 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991438
I0912 03:09:37.867012 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996395
I0912 03:09:37.867019 25179 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0912 03:09:54.468233 25179 solver.cpp:228] Iteration 1380, loss = 0.0209708
I0912 03:09:54.468277 25179 solver.cpp:244]     Train net output #0: accuracy = 0.990932
I0912 03:09:54.468292 25179 solver.cpp:244]     Train net output #1: loss = 0.0209707 (* 1 = 0.0209707 loss)
I0912 03:09:54.468299 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988066
I0912 03:09:54.468305 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995152
I0912 03:09:54.468313 25179 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0912 03:10:11.049206 25179 solver.cpp:228] Iteration 1400, loss = 0.0200793
I0912 03:10:11.049314 25179 solver.cpp:244]     Train net output #0: accuracy = 0.991292
I0912 03:10:11.049330 25179 solver.cpp:244]     Train net output #1: loss = 0.0200793 (* 1 = 0.0200793 loss)
I0912 03:10:11.049340 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984251
I0912 03:10:11.049345 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997715
I0912 03:10:11.049352 25179 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0912 03:10:27.641206 25179 solver.cpp:228] Iteration 1420, loss = 0.00581427
I0912 03:10:27.641249 25179 solver.cpp:244]     Train net output #0: accuracy = 0.998001
I0912 03:10:27.641263 25179 solver.cpp:244]     Train net output #1: loss = 0.00581425 (* 1 = 0.00581425 loss)
I0912 03:10:27.641268 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997942
I0912 03:10:27.641273 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998127
I0912 03:10:27.641280 25179 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0912 03:10:44.224084 25179 solver.cpp:228] Iteration 1440, loss = 0.0244244
I0912 03:10:44.224196 25179 solver.cpp:244]     Train net output #0: accuracy = 0.988352
I0912 03:10:44.224212 25179 solver.cpp:244]     Train net output #1: loss = 0.0244243 (* 1 = 0.0244243 loss)
I0912 03:10:44.224218 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981258
I0912 03:10:44.224225 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997349
I0912 03:10:44.224231 25179 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0912 03:11:00.822690 25179 solver.cpp:228] Iteration 1460, loss = 0.0152884
I0912 03:11:00.822731 25179 solver.cpp:244]     Train net output #0: accuracy = 0.993099
I0912 03:11:00.822743 25179 solver.cpp:244]     Train net output #1: loss = 0.0152883 (* 1 = 0.0152883 loss)
I0912 03:11:00.822751 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98914
I0912 03:11:00.822755 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998122
I0912 03:11:00.822762 25179 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0912 03:11:17.406983 25179 solver.cpp:228] Iteration 1480, loss = 0.0200159
I0912 03:11:17.407151 25179 solver.cpp:244]     Train net output #0: accuracy = 0.991649
I0912 03:11:17.407168 25179 solver.cpp:244]     Train net output #1: loss = 0.0200159 (* 1 = 0.0200159 loss)
I0912 03:11:17.407182 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985913
I0912 03:11:17.407188 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997004
I0912 03:11:17.407196 25179 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0912 03:11:33.997561 25179 solver.cpp:228] Iteration 1500, loss = 0.0147958
I0912 03:11:33.997602 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994293
I0912 03:11:33.997614 25179 solver.cpp:244]     Train net output #1: loss = 0.0147958 (* 1 = 0.0147958 loss)
I0912 03:11:33.997620 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993314
I0912 03:11:33.997625 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997604
I0912 03:11:33.997632 25179 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0912 03:11:50.588050 25179 solver.cpp:228] Iteration 1520, loss = 0.0191699
I0912 03:11:50.588157 25179 solver.cpp:244]     Train net output #0: accuracy = 0.993284
I0912 03:11:50.588174 25179 solver.cpp:244]     Train net output #1: loss = 0.0191699 (* 1 = 0.0191699 loss)
I0912 03:11:50.588184 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994934
I0912 03:11:50.588189 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989039
I0912 03:11:50.588196 25179 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0912 03:12:07.179072 25179 solver.cpp:228] Iteration 1540, loss = 0.0143224
I0912 03:12:07.179116 25179 solver.cpp:244]     Train net output #0: accuracy = 0.993438
I0912 03:12:07.179131 25179 solver.cpp:244]     Train net output #1: loss = 0.0143223 (* 1 = 0.0143223 loss)
I0912 03:12:07.179136 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991154
I0912 03:12:07.179141 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997224
I0912 03:12:07.179148 25179 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0912 03:12:23.784236 25179 solver.cpp:228] Iteration 1560, loss = 0.0179072
I0912 03:12:23.784343 25179 solver.cpp:244]     Train net output #0: accuracy = 0.993416
I0912 03:12:23.784359 25179 solver.cpp:244]     Train net output #1: loss = 0.0179072 (* 1 = 0.0179072 loss)
I0912 03:12:23.784365 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993549
I0912 03:12:23.784369 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992912
I0912 03:12:23.784377 25179 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0912 03:12:40.389737 25179 solver.cpp:228] Iteration 1580, loss = 0.0176995
I0912 03:12:40.389780 25179 solver.cpp:244]     Train net output #0: accuracy = 0.992033
I0912 03:12:40.389796 25179 solver.cpp:244]     Train net output #1: loss = 0.0176994 (* 1 = 0.0176994 loss)
I0912 03:12:40.389803 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990379
I0912 03:12:40.389809 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995872
I0912 03:12:40.389818 25179 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0912 03:12:56.994938 25179 solver.cpp:228] Iteration 1600, loss = 0.0166538
I0912 03:12:56.995100 25179 solver.cpp:244]     Train net output #0: accuracy = 0.993487
I0912 03:12:56.995116 25179 solver.cpp:244]     Train net output #1: loss = 0.0166537 (* 1 = 0.0166537 loss)
I0912 03:12:56.995122 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991646
I0912 03:12:56.995127 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995497
I0912 03:12:56.995134 25179 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0912 03:13:13.585943 25179 solver.cpp:228] Iteration 1620, loss = 0.0068513
I0912 03:13:13.585988 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997096
I0912 03:13:13.586001 25179 solver.cpp:244]     Train net output #1: loss = 0.00685128 (* 1 = 0.00685128 loss)
I0912 03:13:13.586009 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995972
I0912 03:13:13.586015 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998732
I0912 03:13:13.586024 25179 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0912 03:13:30.175024 25179 solver.cpp:228] Iteration 1640, loss = 0.00829075
I0912 03:13:30.175133 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996678
I0912 03:13:30.175148 25179 solver.cpp:244]     Train net output #1: loss = 0.00829073 (* 1 = 0.00829073 loss)
I0912 03:13:30.175154 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996266
I0912 03:13:30.175159 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997435
I0912 03:13:30.175166 25179 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0912 03:13:46.753090 25179 solver.cpp:228] Iteration 1660, loss = 0.0155087
I0912 03:13:46.753132 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99394
I0912 03:13:46.753145 25179 solver.cpp:244]     Train net output #1: loss = 0.0155087 (* 1 = 0.0155087 loss)
I0912 03:13:46.753152 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994166
I0912 03:13:46.753157 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993462
I0912 03:13:46.753165 25179 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0912 03:14:03.367646 25179 solver.cpp:228] Iteration 1680, loss = 0.00955374
I0912 03:14:03.367766 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996217
I0912 03:14:03.367784 25179 solver.cpp:244]     Train net output #1: loss = 0.00955372 (* 1 = 0.00955372 loss)
I0912 03:14:03.367794 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995684
I0912 03:14:03.367805 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997233
I0912 03:14:03.367812 25179 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0912 03:14:19.944267 25179 solver.cpp:228] Iteration 1700, loss = 0.0146157
I0912 03:14:19.944309 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994006
I0912 03:14:19.944322 25179 solver.cpp:244]     Train net output #1: loss = 0.0146157 (* 1 = 0.0146157 loss)
I0912 03:14:19.944329 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993441
I0912 03:14:19.944334 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995019
I0912 03:14:19.944341 25179 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0912 03:14:36.532327 25179 solver.cpp:228] Iteration 1720, loss = 0.00764593
I0912 03:14:36.532441 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99716
I0912 03:14:36.532459 25179 solver.cpp:244]     Train net output #1: loss = 0.00764591 (* 1 = 0.00764591 loss)
I0912 03:14:36.532469 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996959
I0912 03:14:36.532480 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99754
I0912 03:14:36.532490 25179 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0912 03:14:53.124840 25179 solver.cpp:228] Iteration 1740, loss = 0.0137451
I0912 03:14:53.124881 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996095
I0912 03:14:53.124892 25179 solver.cpp:244]     Train net output #1: loss = 0.0137451 (* 1 = 0.0137451 loss)
I0912 03:14:53.124900 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991966
I0912 03:14:53.124904 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998434
I0912 03:14:53.124912 25179 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0912 03:15:09.710675 25179 solver.cpp:228] Iteration 1760, loss = 0.0132178
I0912 03:15:09.710844 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994297
I0912 03:15:09.710860 25179 solver.cpp:244]     Train net output #1: loss = 0.0132178 (* 1 = 0.0132178 loss)
I0912 03:15:09.710867 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992192
I0912 03:15:09.710873 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997129
I0912 03:15:09.710880 25179 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0912 03:15:26.298687 25179 solver.cpp:228] Iteration 1780, loss = 0.0108927
I0912 03:15:26.298730 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99578
I0912 03:15:26.298745 25179 solver.cpp:244]     Train net output #1: loss = 0.0108927 (* 1 = 0.0108927 loss)
I0912 03:15:26.298759 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995649
I0912 03:15:26.298764 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995974
I0912 03:15:26.298771 25179 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0912 03:15:42.901329 25179 solver.cpp:228] Iteration 1800, loss = 0.020239
I0912 03:15:42.901439 25179 solver.cpp:244]     Train net output #0: accuracy = 0.992047
I0912 03:15:42.901454 25179 solver.cpp:244]     Train net output #1: loss = 0.020239 (* 1 = 0.020239 loss)
I0912 03:15:42.901464 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991194
I0912 03:15:42.901469 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995706
I0912 03:15:42.901476 25179 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0912 03:15:59.495430 25179 solver.cpp:228] Iteration 1820, loss = 0.00958066
I0912 03:15:59.495476 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995503
I0912 03:15:59.495491 25179 solver.cpp:244]     Train net output #1: loss = 0.00958064 (* 1 = 0.00958064 loss)
I0912 03:15:59.495498 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993455
I0912 03:15:59.495504 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998414
I0912 03:15:59.495512 25179 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0912 03:16:16.086515 25179 solver.cpp:228] Iteration 1840, loss = 0.0184366
I0912 03:16:16.086657 25179 solver.cpp:244]     Train net output #0: accuracy = 0.991904
I0912 03:16:16.086694 25179 solver.cpp:244]     Train net output #1: loss = 0.0184365 (* 1 = 0.0184365 loss)
I0912 03:16:16.086704 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987598
I0912 03:16:16.086712 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996796
I0912 03:16:16.086721 25179 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0912 03:16:32.696321 25179 solver.cpp:228] Iteration 1860, loss = 0.0114778
I0912 03:16:32.696367 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994773
I0912 03:16:32.696382 25179 solver.cpp:244]     Train net output #1: loss = 0.0114778 (* 1 = 0.0114778 loss)
I0912 03:16:32.696388 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991133
I0912 03:16:32.696394 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998642
I0912 03:16:32.696403 25179 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0912 03:16:49.298794 25179 solver.cpp:228] Iteration 1880, loss = 0.0132397
I0912 03:16:49.298930 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994272
I0912 03:16:49.298976 25179 solver.cpp:244]     Train net output #1: loss = 0.0132397 (* 1 = 0.0132397 loss)
I0912 03:16:49.298985 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98941
I0912 03:16:49.298995 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998342
I0912 03:16:49.299005 25179 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0912 03:17:05.970926 25179 solver.cpp:228] Iteration 1900, loss = 0.0093146
I0912 03:17:05.970979 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995796
I0912 03:17:05.970993 25179 solver.cpp:244]     Train net output #1: loss = 0.00931458 (* 1 = 0.00931458 loss)
I0912 03:17:05.970999 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993627
I0912 03:17:05.971005 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998623
I0912 03:17:05.971014 25179 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0912 03:17:22.592573 25179 solver.cpp:228] Iteration 1920, loss = 0.0181993
I0912 03:17:22.592841 25179 solver.cpp:244]     Train net output #0: accuracy = 0.992493
I0912 03:17:22.592890 25179 solver.cpp:244]     Train net output #1: loss = 0.0181992 (* 1 = 0.0181992 loss)
I0912 03:17:22.592900 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990007
I0912 03:17:22.592911 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995214
I0912 03:17:22.592924 25179 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0912 03:17:39.242776 25179 solver.cpp:228] Iteration 1940, loss = 0.0162686
I0912 03:17:39.242825 25179 solver.cpp:244]     Train net output #0: accuracy = 0.992457
I0912 03:17:39.242841 25179 solver.cpp:244]     Train net output #1: loss = 0.0162686 (* 1 = 0.0162686 loss)
I0912 03:17:39.242847 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988026
I0912 03:17:39.242854 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997644
I0912 03:17:39.242862 25179 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0912 03:17:55.853507 25179 solver.cpp:228] Iteration 1960, loss = 0.00821033
I0912 03:17:55.853663 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997329
I0912 03:17:55.853703 25179 solver.cpp:244]     Train net output #1: loss = 0.00821031 (* 1 = 0.00821031 loss)
I0912 03:17:55.853713 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998255
I0912 03:17:55.853719 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995696
I0912 03:17:55.853729 25179 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0912 03:18:12.501849 25179 solver.cpp:228] Iteration 1980, loss = 0.0130607
I0912 03:18:12.501896 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994018
I0912 03:18:12.501912 25179 solver.cpp:244]     Train net output #1: loss = 0.0130607 (* 1 = 0.0130607 loss)
I0912 03:18:12.501920 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989106
I0912 03:18:12.501926 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998707
I0912 03:18:12.501935 25179 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0912 03:18:29.122053 25179 solver.cpp:228] Iteration 2000, loss = 0.0169429
I0912 03:18:29.122182 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994417
I0912 03:18:29.122200 25179 solver.cpp:244]     Train net output #1: loss = 0.0169428 (* 1 = 0.0169428 loss)
I0912 03:18:29.122211 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996002
I0912 03:18:29.122217 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988777
I0912 03:18:29.122226 25179 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0912 03:18:45.723598 25179 solver.cpp:228] Iteration 2020, loss = 0.0105252
I0912 03:18:45.723639 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996003
I0912 03:18:45.723652 25179 solver.cpp:244]     Train net output #1: loss = 0.0105252 (* 1 = 0.0105252 loss)
I0912 03:18:45.723659 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995345
I0912 03:18:45.723664 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99683
I0912 03:18:45.723670 25179 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0912 03:19:02.321416 25179 solver.cpp:228] Iteration 2040, loss = 0.0110229
I0912 03:19:02.321537 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99477
I0912 03:19:02.321553 25179 solver.cpp:244]     Train net output #1: loss = 0.0110229 (* 1 = 0.0110229 loss)
I0912 03:19:02.321564 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992193
I0912 03:19:02.321571 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998451
I0912 03:19:02.321579 25179 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0912 03:19:18.918704 25179 solver.cpp:228] Iteration 2060, loss = 0.0100746
I0912 03:19:18.918742 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996227
I0912 03:19:18.918756 25179 solver.cpp:244]     Train net output #1: loss = 0.0100746 (* 1 = 0.0100746 loss)
I0912 03:19:18.918762 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995783
I0912 03:19:18.918767 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996766
I0912 03:19:18.918776 25179 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0912 03:19:35.524103 25179 solver.cpp:228] Iteration 2080, loss = 0.010702
I0912 03:19:35.524265 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996338
I0912 03:19:35.524281 25179 solver.cpp:244]     Train net output #1: loss = 0.010702 (* 1 = 0.010702 loss)
I0912 03:19:35.524291 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997495
I0912 03:19:35.524296 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994362
I0912 03:19:35.524303 25179 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0912 03:19:52.120329 25179 solver.cpp:228] Iteration 2100, loss = 0.0114149
I0912 03:19:52.120374 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995543
I0912 03:19:52.120389 25179 solver.cpp:244]     Train net output #1: loss = 0.0114148 (* 1 = 0.0114148 loss)
I0912 03:19:52.120396 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995857
I0912 03:19:52.120402 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994723
I0912 03:19:52.120410 25179 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0912 03:20:08.720896 25179 solver.cpp:228] Iteration 2120, loss = 0.012138
I0912 03:20:08.721017 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994664
I0912 03:20:08.721032 25179 solver.cpp:244]     Train net output #1: loss = 0.012138 (* 1 = 0.012138 loss)
I0912 03:20:08.721037 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99302
I0912 03:20:08.721042 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997125
I0912 03:20:08.721050 25179 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0912 03:20:25.319190 25179 solver.cpp:228] Iteration 2140, loss = 0.00830238
I0912 03:20:25.319234 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996761
I0912 03:20:25.319248 25179 solver.cpp:244]     Train net output #1: loss = 0.00830236 (* 1 = 0.00830236 loss)
I0912 03:20:25.319262 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996396
I0912 03:20:25.319272 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99729
I0912 03:20:25.319281 25179 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0912 03:20:41.934474 25179 solver.cpp:228] Iteration 2160, loss = 0.0114562
I0912 03:20:41.934613 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995035
I0912 03:20:41.934654 25179 solver.cpp:244]     Train net output #1: loss = 0.0114562 (* 1 = 0.0114562 loss)
I0912 03:20:41.934664 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993539
I0912 03:20:41.934669 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997273
I0912 03:20:41.934679 25179 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0912 03:20:58.575114 25179 solver.cpp:228] Iteration 2180, loss = 0.00700779
I0912 03:20:58.575152 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997826
I0912 03:20:58.575168 25179 solver.cpp:244]     Train net output #1: loss = 0.00700777 (* 1 = 0.00700777 loss)
I0912 03:20:58.575175 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997426
I0912 03:20:58.575179 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998171
I0912 03:20:58.575186 25179 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0912 03:21:15.195332 25179 solver.cpp:228] Iteration 2200, loss = 0.0165122
I0912 03:21:15.195488 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994026
I0912 03:21:15.195505 25179 solver.cpp:244]     Train net output #1: loss = 0.0165122 (* 1 = 0.0165122 loss)
I0912 03:21:15.195511 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995014
I0912 03:21:15.195516 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992114
I0912 03:21:15.195524 25179 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0912 03:21:31.810971 25179 solver.cpp:228] Iteration 2220, loss = 0.0124608
I0912 03:21:31.811013 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994782
I0912 03:21:31.811027 25179 solver.cpp:244]     Train net output #1: loss = 0.0124608 (* 1 = 0.0124608 loss)
I0912 03:21:31.811033 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992414
I0912 03:21:31.811038 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997355
I0912 03:21:31.811045 25179 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0912 03:21:48.418849 25179 solver.cpp:228] Iteration 2240, loss = 0.0102358
I0912 03:21:48.418969 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995804
I0912 03:21:48.418987 25179 solver.cpp:244]     Train net output #1: loss = 0.0102358 (* 1 = 0.0102358 loss)
I0912 03:21:48.418993 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994321
I0912 03:21:48.418998 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997456
I0912 03:21:48.419008 25179 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0912 03:22:05.035425 25179 solver.cpp:228] Iteration 2260, loss = 0.00722619
I0912 03:22:05.035466 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997367
I0912 03:22:05.035480 25179 solver.cpp:244]     Train net output #1: loss = 0.00722617 (* 1 = 0.00722617 loss)
I0912 03:22:05.035486 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997497
I0912 03:22:05.035490 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997183
I0912 03:22:05.035500 25179 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0912 03:22:21.632643 25179 solver.cpp:228] Iteration 2280, loss = 0.018319
I0912 03:22:21.632767 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994831
I0912 03:22:21.632783 25179 solver.cpp:244]     Train net output #1: loss = 0.018319 (* 1 = 0.018319 loss)
I0912 03:22:21.632798 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994784
I0912 03:22:21.632810 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994858
I0912 03:22:21.632819 25179 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0912 03:22:38.249713 25179 solver.cpp:228] Iteration 2300, loss = 0.00860783
I0912 03:22:38.249752 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996393
I0912 03:22:38.249766 25179 solver.cpp:244]     Train net output #1: loss = 0.00860781 (* 1 = 0.00860781 loss)
I0912 03:22:38.249773 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995174
I0912 03:22:38.249778 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997893
I0912 03:22:38.249785 25179 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0912 03:22:54.853530 25179 solver.cpp:228] Iteration 2320, loss = 0.0134529
I0912 03:22:54.853673 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994142
I0912 03:22:54.853713 25179 solver.cpp:244]     Train net output #1: loss = 0.0134529 (* 1 = 0.0134529 loss)
I0912 03:22:54.853723 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993288
I0912 03:22:54.853732 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996082
I0912 03:22:54.853741 25179 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0912 03:23:11.517212 25179 solver.cpp:228] Iteration 2340, loss = 0.00957503
I0912 03:23:11.517261 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995862
I0912 03:23:11.517290 25179 solver.cpp:244]     Train net output #1: loss = 0.00957501 (* 1 = 0.00957501 loss)
I0912 03:23:11.517300 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993384
I0912 03:23:11.517313 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998505
I0912 03:23:11.517325 25179 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0912 03:23:28.154705 25179 solver.cpp:228] Iteration 2360, loss = 0.0174228
I0912 03:23:28.154886 25179 solver.cpp:244]     Train net output #0: accuracy = 0.993462
I0912 03:23:28.154903 25179 solver.cpp:244]     Train net output #1: loss = 0.0174228 (* 1 = 0.0174228 loss)
I0912 03:23:28.154909 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995028
I0912 03:23:28.154914 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988874
I0912 03:23:28.154922 25179 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0912 03:23:44.779804 25179 solver.cpp:228] Iteration 2380, loss = 0.0121263
I0912 03:23:44.779850 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995232
I0912 03:23:44.779865 25179 solver.cpp:244]     Train net output #1: loss = 0.0121263 (* 1 = 0.0121263 loss)
I0912 03:23:44.779872 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994004
I0912 03:23:44.779880 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996512
I0912 03:23:44.779887 25179 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0912 03:24:01.397709 25179 solver.cpp:228] Iteration 2400, loss = 0.0134467
I0912 03:24:01.397840 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995188
I0912 03:24:01.397857 25179 solver.cpp:244]     Train net output #1: loss = 0.0134467 (* 1 = 0.0134467 loss)
I0912 03:24:01.397863 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996418
I0912 03:24:01.397868 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991914
I0912 03:24:01.397876 25179 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0912 03:24:18.020841 25179 solver.cpp:228] Iteration 2420, loss = 0.0126645
I0912 03:24:18.020879 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994498
I0912 03:24:18.020895 25179 solver.cpp:244]     Train net output #1: loss = 0.0126645 (* 1 = 0.0126645 loss)
I0912 03:24:18.020900 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99162
I0912 03:24:18.020913 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998011
I0912 03:24:18.020920 25179 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0912 03:24:34.652339 25179 solver.cpp:228] Iteration 2440, loss = 0.0102267
I0912 03:24:34.652493 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99553
I0912 03:24:34.652534 25179 solver.cpp:244]     Train net output #1: loss = 0.0102267 (* 1 = 0.0102267 loss)
I0912 03:24:34.652544 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993727
I0912 03:24:34.652554 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997856
I0912 03:24:34.652564 25179 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0912 03:24:51.297811 25179 solver.cpp:228] Iteration 2460, loss = 0.00841783
I0912 03:24:51.297852 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996558
I0912 03:24:51.297866 25179 solver.cpp:244]     Train net output #1: loss = 0.0084178 (* 1 = 0.0084178 loss)
I0912 03:24:51.297871 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996365
I0912 03:24:51.297876 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997094
I0912 03:24:51.297883 25179 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0912 03:25:07.883061 25179 solver.cpp:228] Iteration 2480, loss = 0.00802639
I0912 03:25:07.883193 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996068
I0912 03:25:07.883208 25179 solver.cpp:244]     Train net output #1: loss = 0.00802637 (* 1 = 0.00802637 loss)
I0912 03:25:07.883218 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993782
I0912 03:25:07.883229 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999283
I0912 03:25:07.883237 25179 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0912 03:25:24.501358 25179 solver.cpp:228] Iteration 2500, loss = 0.0120339
I0912 03:25:24.501405 25179 solver.cpp:244]     Train net output #0: accuracy = 0.9949
I0912 03:25:24.501418 25179 solver.cpp:244]     Train net output #1: loss = 0.0120339 (* 1 = 0.0120339 loss)
I0912 03:25:24.501425 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991381
I0912 03:25:24.501430 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998382
I0912 03:25:24.501437 25179 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0912 03:25:41.092767 25179 solver.cpp:228] Iteration 2520, loss = 0.0108543
I0912 03:25:41.092954 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995781
I0912 03:25:41.092973 25179 solver.cpp:244]     Train net output #1: loss = 0.0108543 (* 1 = 0.0108543 loss)
I0912 03:25:41.092981 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995752
I0912 03:25:41.092995 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995845
I0912 03:25:41.093003 25179 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0912 03:25:57.706008 25179 solver.cpp:228] Iteration 2540, loss = 0.0100211
I0912 03:25:57.706046 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99634
I0912 03:25:57.706060 25179 solver.cpp:244]     Train net output #1: loss = 0.0100211 (* 1 = 0.0100211 loss)
I0912 03:25:57.706068 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996835
I0912 03:25:57.706073 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9953
I0912 03:25:57.706081 25179 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0912 03:26:14.317900 25179 solver.cpp:228] Iteration 2560, loss = 0.00732666
I0912 03:26:14.318027 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997211
I0912 03:26:14.318042 25179 solver.cpp:244]     Train net output #1: loss = 0.00732663 (* 1 = 0.00732663 loss)
I0912 03:26:14.318048 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997424
I0912 03:26:14.318053 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996795
I0912 03:26:14.318059 25179 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0912 03:26:30.934700 25179 solver.cpp:228] Iteration 2580, loss = 0.0130276
I0912 03:26:30.934744 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994706
I0912 03:26:30.934761 25179 solver.cpp:244]     Train net output #1: loss = 0.0130276 (* 1 = 0.0130276 loss)
I0912 03:26:30.934773 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994509
I0912 03:26:30.934779 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995092
I0912 03:26:30.934787 25179 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0912 03:26:47.547950 25179 solver.cpp:228] Iteration 2600, loss = 0.00998753
I0912 03:26:47.548063 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995431
I0912 03:26:47.548079 25179 solver.cpp:244]     Train net output #1: loss = 0.00998751 (* 1 = 0.00998751 loss)
I0912 03:26:47.548084 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994066
I0912 03:26:47.548089 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998058
I0912 03:26:47.548097 25179 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0912 03:27:04.140522 25179 solver.cpp:228] Iteration 2620, loss = 0.0129356
I0912 03:27:04.140568 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994952
I0912 03:27:04.140583 25179 solver.cpp:244]     Train net output #1: loss = 0.0129356 (* 1 = 0.0129356 loss)
I0912 03:27:04.140588 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994892
I0912 03:27:04.140594 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995066
I0912 03:27:04.140604 25179 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0912 03:27:20.759460 25179 solver.cpp:228] Iteration 2640, loss = 0.0194395
I0912 03:27:20.759573 25179 solver.cpp:244]     Train net output #0: accuracy = 0.992567
I0912 03:27:20.759589 25179 solver.cpp:244]     Train net output #1: loss = 0.0194395 (* 1 = 0.0194395 loss)
I0912 03:27:20.759594 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992356
I0912 03:27:20.759599 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993296
I0912 03:27:20.759608 25179 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0912 03:27:37.365644 25179 solver.cpp:228] Iteration 2660, loss = 0.00730069
I0912 03:27:37.365684 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996858
I0912 03:27:37.365697 25179 solver.cpp:244]     Train net output #1: loss = 0.00730066 (* 1 = 0.00730066 loss)
I0912 03:27:37.365705 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99549
I0912 03:27:37.365716 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998702
I0912 03:27:37.365723 25179 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0912 03:27:53.977869 25179 solver.cpp:228] Iteration 2680, loss = 0.00963382
I0912 03:27:53.978054 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996276
I0912 03:27:53.978072 25179 solver.cpp:244]     Train net output #1: loss = 0.00963379 (* 1 = 0.00963379 loss)
I0912 03:27:53.978082 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99615
I0912 03:27:53.978088 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996451
I0912 03:27:53.978097 25179 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0912 03:28:10.544500 25179 solver.cpp:228] Iteration 2700, loss = 0.0108932
I0912 03:28:10.544540 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996302
I0912 03:28:10.544554 25179 solver.cpp:244]     Train net output #1: loss = 0.0108932 (* 1 = 0.0108932 loss)
I0912 03:28:10.544561 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993747
I0912 03:28:10.544566 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997985
I0912 03:28:10.544574 25179 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0912 03:28:27.131074 25179 solver.cpp:228] Iteration 2720, loss = 0.0101433
I0912 03:28:27.131186 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995851
I0912 03:28:27.131203 25179 solver.cpp:244]     Train net output #1: loss = 0.0101433 (* 1 = 0.0101433 loss)
I0912 03:28:27.131217 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994427
I0912 03:28:27.131222 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997645
I0912 03:28:27.131230 25179 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0912 03:28:43.729763 25179 solver.cpp:228] Iteration 2740, loss = 0.0119665
I0912 03:28:43.729804 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995256
I0912 03:28:43.729818 25179 solver.cpp:244]     Train net output #1: loss = 0.0119664 (* 1 = 0.0119664 loss)
I0912 03:28:43.729823 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995492
I0912 03:28:43.729828 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994675
I0912 03:28:43.729836 25179 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0912 03:29:00.337371 25179 solver.cpp:228] Iteration 2760, loss = 0.0108226
I0912 03:29:00.337489 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99591
I0912 03:29:00.337507 25179 solver.cpp:244]     Train net output #1: loss = 0.0108226 (* 1 = 0.0108226 loss)
I0912 03:29:00.337513 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993374
I0912 03:29:00.337520 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99784
I0912 03:29:00.337535 25179 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0912 03:29:16.932649 25179 solver.cpp:228] Iteration 2780, loss = 0.00857794
I0912 03:29:16.932689 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996771
I0912 03:29:16.932703 25179 solver.cpp:244]     Train net output #1: loss = 0.00857791 (* 1 = 0.00857791 loss)
I0912 03:29:16.932710 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99677
I0912 03:29:16.932721 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996772
I0912 03:29:16.932729 25179 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0912 03:29:33.547489 25179 solver.cpp:228] Iteration 2800, loss = 0.00929544
I0912 03:29:33.547659 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996422
I0912 03:29:33.547677 25179 solver.cpp:244]     Train net output #1: loss = 0.00929541 (* 1 = 0.00929541 loss)
I0912 03:29:33.547682 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992871
I0912 03:29:33.547688 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998921
I0912 03:29:33.547694 25179 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0912 03:29:50.156987 25179 solver.cpp:228] Iteration 2820, loss = 0.0101682
I0912 03:29:50.157032 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995679
I0912 03:29:50.157047 25179 solver.cpp:244]     Train net output #1: loss = 0.0101682 (* 1 = 0.0101682 loss)
I0912 03:29:50.157053 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993642
I0912 03:29:50.157059 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997744
I0912 03:29:50.157068 25179 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0912 03:30:06.759907 25179 solver.cpp:228] Iteration 2840, loss = 0.0102074
I0912 03:30:06.760026 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996243
I0912 03:30:06.760041 25179 solver.cpp:244]     Train net output #1: loss = 0.0102074 (* 1 = 0.0102074 loss)
I0912 03:30:06.760051 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993562
I0912 03:30:06.760056 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99822
I0912 03:30:06.760063 25179 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0912 03:30:23.348614 25179 solver.cpp:228] Iteration 2860, loss = 0.00885434
I0912 03:30:23.348660 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996416
I0912 03:30:23.348675 25179 solver.cpp:244]     Train net output #1: loss = 0.00885431 (* 1 = 0.00885431 loss)
I0912 03:30:23.348687 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99603
I0912 03:30:23.348697 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997721
I0912 03:30:23.348706 25179 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0912 03:30:39.955162 25179 solver.cpp:228] Iteration 2880, loss = 0.010333
I0912 03:30:39.955273 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995415
I0912 03:30:39.955287 25179 solver.cpp:244]     Train net output #1: loss = 0.0103329 (* 1 = 0.0103329 loss)
I0912 03:30:39.955302 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992
I0912 03:30:39.955313 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998693
I0912 03:30:39.955322 25179 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0912 03:30:56.561513 25179 solver.cpp:228] Iteration 2900, loss = 0.00619736
I0912 03:30:56.561550 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997675
I0912 03:30:56.561564 25179 solver.cpp:244]     Train net output #1: loss = 0.00619733 (* 1 = 0.00619733 loss)
I0912 03:30:56.561569 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998016
I0912 03:30:56.561575 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996777
I0912 03:30:56.561583 25179 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0912 03:31:13.160984 25179 solver.cpp:228] Iteration 2920, loss = 0.00753821
I0912 03:31:13.161104 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997569
I0912 03:31:13.161121 25179 solver.cpp:244]     Train net output #1: loss = 0.00753818 (* 1 = 0.00753818 loss)
I0912 03:31:13.161131 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998091
I0912 03:31:13.161142 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997031
I0912 03:31:13.161150 25179 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0912 03:31:29.782924 25179 solver.cpp:228] Iteration 2940, loss = 0.0073057
I0912 03:31:29.782965 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996836
I0912 03:31:29.782979 25179 solver.cpp:244]     Train net output #1: loss = 0.00730567 (* 1 = 0.00730567 loss)
I0912 03:31:29.782984 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99459
I0912 03:31:29.782989 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998936
I0912 03:31:29.782996 25179 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0912 03:31:46.396076 25179 solver.cpp:228] Iteration 2960, loss = 0.0116384
I0912 03:31:46.396250 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995178
I0912 03:31:46.396271 25179 solver.cpp:244]     Train net output #1: loss = 0.0116383 (* 1 = 0.0116383 loss)
I0912 03:31:46.396278 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99374
I0912 03:31:46.396291 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997153
I0912 03:31:46.396298 25179 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0912 03:32:03.010592 25179 solver.cpp:228] Iteration 2980, loss = 0.00879781
I0912 03:32:03.010633 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996406
I0912 03:32:03.010646 25179 solver.cpp:244]     Train net output #1: loss = 0.00879778 (* 1 = 0.00879778 loss)
I0912 03:32:03.010653 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995756
I0912 03:32:03.010658 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997469
I0912 03:32:03.010664 25179 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0912 03:32:19.600332 25179 solver.cpp:228] Iteration 3000, loss = 0.0055276
I0912 03:32:19.600450 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99803
I0912 03:32:19.600467 25179 solver.cpp:244]     Train net output #1: loss = 0.00552758 (* 1 = 0.00552758 loss)
I0912 03:32:19.600476 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998224
I0912 03:32:19.600481 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997669
I0912 03:32:19.600492 25179 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0912 03:32:36.219081 25179 solver.cpp:228] Iteration 3020, loss = 0.00810789
I0912 03:32:36.219120 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996205
I0912 03:32:36.219133 25179 solver.cpp:244]     Train net output #1: loss = 0.00810786 (* 1 = 0.00810786 loss)
I0912 03:32:36.219141 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992933
I0912 03:32:36.219146 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999246
I0912 03:32:36.219154 25179 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0912 03:32:52.830266 25179 solver.cpp:228] Iteration 3040, loss = 0.00874805
I0912 03:32:52.830392 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996824
I0912 03:32:52.830407 25179 solver.cpp:244]     Train net output #1: loss = 0.00874802 (* 1 = 0.00874802 loss)
I0912 03:32:52.830420 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996834
I0912 03:32:52.830425 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996785
I0912 03:32:52.830431 25179 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0912 03:33:09.445897 25179 solver.cpp:228] Iteration 3060, loss = 0.0101013
I0912 03:33:09.445942 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995922
I0912 03:33:09.445957 25179 solver.cpp:244]     Train net output #1: loss = 0.0101013 (* 1 = 0.0101013 loss)
I0912 03:33:09.445964 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992791
I0912 03:33:09.445969 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998384
I0912 03:33:09.445977 25179 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0912 03:33:26.041756 25179 solver.cpp:228] Iteration 3080, loss = 0.00720635
I0912 03:33:26.041877 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996803
I0912 03:33:26.041893 25179 solver.cpp:244]     Train net output #1: loss = 0.00720632 (* 1 = 0.00720632 loss)
I0912 03:33:26.041905 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995179
I0912 03:33:26.041910 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998957
I0912 03:33:26.041918 25179 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0912 03:33:42.664527 25179 solver.cpp:228] Iteration 3100, loss = 0.015129
I0912 03:33:42.664571 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995707
I0912 03:33:42.664585 25179 solver.cpp:244]     Train net output #1: loss = 0.015129 (* 1 = 0.015129 loss)
I0912 03:33:42.664592 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991539
I0912 03:33:42.664597 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997687
I0912 03:33:42.664607 25179 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0912 03:33:59.268299 25179 solver.cpp:228] Iteration 3120, loss = 0.00685839
I0912 03:33:59.268473 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997363
I0912 03:33:59.268496 25179 solver.cpp:244]     Train net output #1: loss = 0.00685836 (* 1 = 0.00685836 loss)
I0912 03:33:59.268504 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997175
I0912 03:33:59.268515 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997698
I0912 03:33:59.268524 25179 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0912 03:34:15.883594 25179 solver.cpp:228] Iteration 3140, loss = 0.0067902
I0912 03:34:15.883636 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99683
I0912 03:34:15.883649 25179 solver.cpp:244]     Train net output #1: loss = 0.00679018 (* 1 = 0.00679018 loss)
I0912 03:34:15.883656 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995811
I0912 03:34:15.883659 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998842
I0912 03:34:15.883667 25179 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0912 03:34:32.472458 25179 solver.cpp:228] Iteration 3160, loss = 0.00633974
I0912 03:34:32.472589 25179 solver.cpp:244]     Train net output #0: accuracy = 0.9975
I0912 03:34:32.472606 25179 solver.cpp:244]     Train net output #1: loss = 0.00633971 (* 1 = 0.00633971 loss)
I0912 03:34:32.472617 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997358
I0912 03:34:32.472625 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99797
I0912 03:34:32.472632 25179 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0912 03:34:49.069674 25179 solver.cpp:228] Iteration 3180, loss = 0.0088944
I0912 03:34:49.069715 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996409
I0912 03:34:49.069727 25179 solver.cpp:244]     Train net output #1: loss = 0.00889437 (* 1 = 0.00889437 loss)
I0912 03:34:49.069733 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995966
I0912 03:34:49.069738 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99721
I0912 03:34:49.069746 25179 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0912 03:35:05.665468 25179 solver.cpp:228] Iteration 3200, loss = 0.00453964
I0912 03:35:05.665582 25179 solver.cpp:244]     Train net output #0: accuracy = 0.998416
I0912 03:35:05.665598 25179 solver.cpp:244]     Train net output #1: loss = 0.00453961 (* 1 = 0.00453961 loss)
I0912 03:35:05.665609 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998462
I0912 03:35:05.665621 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998272
I0912 03:35:05.665630 25179 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0912 03:35:22.271047 25179 solver.cpp:228] Iteration 3220, loss = 0.0107847
I0912 03:35:22.271087 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996004
I0912 03:35:22.271101 25179 solver.cpp:244]     Train net output #1: loss = 0.0107847 (* 1 = 0.0107847 loss)
I0912 03:35:22.271106 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996717
I0912 03:35:22.271111 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993707
I0912 03:35:22.271119 25179 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0912 03:35:38.882817 25179 solver.cpp:228] Iteration 3240, loss = 0.0119921
I0912 03:35:38.882927 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994598
I0912 03:35:38.882944 25179 solver.cpp:244]     Train net output #1: loss = 0.0119921 (* 1 = 0.0119921 loss)
I0912 03:35:38.882953 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993015
I0912 03:35:38.882957 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997282
I0912 03:35:38.882966 25179 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0912 03:35:55.500672 25179 solver.cpp:228] Iteration 3260, loss = 0.0110833
I0912 03:35:55.500716 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995302
I0912 03:35:55.500731 25179 solver.cpp:244]     Train net output #1: loss = 0.0110833 (* 1 = 0.0110833 loss)
I0912 03:35:55.500746 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989286
I0912 03:35:55.500756 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999215
I0912 03:35:55.500764 25179 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0912 03:36:12.102674 25179 solver.cpp:228] Iteration 3280, loss = 0.0093033
I0912 03:36:12.102857 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996211
I0912 03:36:12.102874 25179 solver.cpp:244]     Train net output #1: loss = 0.00930328 (* 1 = 0.00930328 loss)
I0912 03:36:12.102885 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995449
I0912 03:36:12.102890 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997261
I0912 03:36:12.102897 25179 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0912 03:36:28.719346 25179 solver.cpp:228] Iteration 3300, loss = 0.00725848
I0912 03:36:28.719388 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996655
I0912 03:36:28.719404 25179 solver.cpp:244]     Train net output #1: loss = 0.00725846 (* 1 = 0.00725846 loss)
I0912 03:36:28.719410 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99526
I0912 03:36:28.719421 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998555
I0912 03:36:28.719429 25179 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0912 03:36:45.311872 25179 solver.cpp:228] Iteration 3320, loss = 0.0068227
I0912 03:36:45.311985 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997254
I0912 03:36:45.312000 25179 solver.cpp:244]     Train net output #1: loss = 0.00682267 (* 1 = 0.00682267 loss)
I0912 03:36:45.312005 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996572
I0912 03:36:45.312016 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998097
I0912 03:36:45.312023 25179 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0912 03:37:01.918674 25179 solver.cpp:228] Iteration 3340, loss = 0.00429452
I0912 03:37:01.918720 25179 solver.cpp:244]     Train net output #0: accuracy = 0.998432
I0912 03:37:01.918735 25179 solver.cpp:244]     Train net output #1: loss = 0.00429449 (* 1 = 0.00429449 loss)
I0912 03:37:01.918742 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997962
I0912 03:37:01.918748 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998993
I0912 03:37:01.918757 25179 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0912 03:37:18.502756 25179 solver.cpp:228] Iteration 3360, loss = 0.00678538
I0912 03:37:18.502863 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997148
I0912 03:37:18.502879 25179 solver.cpp:244]     Train net output #1: loss = 0.00678535 (* 1 = 0.00678535 loss)
I0912 03:37:18.502892 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996688
I0912 03:37:18.502897 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997931
I0912 03:37:18.502904 25179 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0912 03:37:35.111372 25179 solver.cpp:228] Iteration 3380, loss = 0.0146687
I0912 03:37:35.111413 25179 solver.cpp:244]     Train net output #0: accuracy = 0.993728
I0912 03:37:35.111426 25179 solver.cpp:244]     Train net output #1: loss = 0.0146686 (* 1 = 0.0146686 loss)
I0912 03:37:35.111433 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992771
I0912 03:37:35.111438 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995602
I0912 03:37:35.111445 25179 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0912 03:37:51.711730 25179 solver.cpp:228] Iteration 3400, loss = 0.00839368
I0912 03:37:51.711907 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996819
I0912 03:37:51.711930 25179 solver.cpp:244]     Train net output #1: loss = 0.00839365 (* 1 = 0.00839365 loss)
I0912 03:37:51.711937 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996617
I0912 03:37:51.711949 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997148
I0912 03:37:51.711963 25179 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0912 03:38:08.301223 25179 solver.cpp:228] Iteration 3420, loss = 0.00901291
I0912 03:38:08.301265 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996251
I0912 03:38:08.301278 25179 solver.cpp:244]     Train net output #1: loss = 0.00901288 (* 1 = 0.00901288 loss)
I0912 03:38:08.301290 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994783
I0912 03:38:08.301295 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997736
I0912 03:38:08.301303 25179 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0912 03:38:25.049293 25179 solver.cpp:228] Iteration 3440, loss = 0.0131076
I0912 03:38:25.049439 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995383
I0912 03:38:25.049461 25179 solver.cpp:244]     Train net output #1: loss = 0.0131076 (* 1 = 0.0131076 loss)
I0912 03:38:25.049469 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996626
I0912 03:38:25.049475 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991262
I0912 03:38:25.049489 25179 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0912 03:38:41.652917 25179 solver.cpp:228] Iteration 3460, loss = 0.00420637
I0912 03:38:41.652959 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99841
I0912 03:38:41.652974 25179 solver.cpp:244]     Train net output #1: loss = 0.00420635 (* 1 = 0.00420635 loss)
I0912 03:38:41.652986 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997942
I0912 03:38:41.652997 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999056
I0912 03:38:41.653005 25179 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0912 03:38:58.272588 25179 solver.cpp:228] Iteration 3480, loss = 0.0075014
I0912 03:38:58.272708 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996891
I0912 03:38:58.272725 25179 solver.cpp:244]     Train net output #1: loss = 0.00750138 (* 1 = 0.00750138 loss)
I0912 03:38:58.272735 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996786
I0912 03:38:58.272740 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997136
I0912 03:38:58.272748 25179 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0912 03:39:14.894680 25179 solver.cpp:228] Iteration 3500, loss = 0.0101487
I0912 03:39:14.894722 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995694
I0912 03:39:14.894738 25179 solver.cpp:244]     Train net output #1: loss = 0.0101487 (* 1 = 0.0101487 loss)
I0912 03:39:14.894747 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993646
I0912 03:39:14.894753 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997752
I0912 03:39:14.894762 25179 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0912 03:39:31.479905 25179 solver.cpp:228] Iteration 3520, loss = 0.00502334
I0912 03:39:31.480036 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997669
I0912 03:39:31.480051 25179 solver.cpp:244]     Train net output #1: loss = 0.00502331 (* 1 = 0.00502331 loss)
I0912 03:39:31.480057 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996808
I0912 03:39:31.480062 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999294
I0912 03:39:31.480072 25179 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0912 03:39:48.101637 25179 solver.cpp:228] Iteration 3540, loss = 0.0116106
I0912 03:39:48.101682 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995178
I0912 03:39:48.101697 25179 solver.cpp:244]     Train net output #1: loss = 0.0116106 (* 1 = 0.0116106 loss)
I0912 03:39:48.101708 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994923
I0912 03:39:48.101714 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996273
I0912 03:39:48.101723 25179 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0912 03:40:04.707568 25179 solver.cpp:228] Iteration 3560, loss = 0.00681511
I0912 03:40:04.707751 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997381
I0912 03:40:04.707768 25179 solver.cpp:244]     Train net output #1: loss = 0.00681509 (* 1 = 0.00681509 loss)
I0912 03:40:04.707777 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996941
I0912 03:40:04.707782 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997996
I0912 03:40:04.707788 25179 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0912 03:40:21.318156 25179 solver.cpp:228] Iteration 3580, loss = 0.0060252
I0912 03:40:21.318198 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997745
I0912 03:40:21.318213 25179 solver.cpp:244]     Train net output #1: loss = 0.00602517 (* 1 = 0.00602517 loss)
I0912 03:40:21.318229 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997418
I0912 03:40:21.318235 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998139
I0912 03:40:21.318244 25179 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0912 03:40:37.927191 25179 solver.cpp:228] Iteration 3600, loss = 0.00691147
I0912 03:40:37.927304 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997258
I0912 03:40:37.927320 25179 solver.cpp:244]     Train net output #1: loss = 0.00691145 (* 1 = 0.00691145 loss)
I0912 03:40:37.927332 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996912
I0912 03:40:37.927345 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997753
I0912 03:40:37.927353 25179 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0912 03:40:54.534045 25179 solver.cpp:228] Iteration 3620, loss = 0.00937473
I0912 03:40:54.534086 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995796
I0912 03:40:54.534099 25179 solver.cpp:244]     Train net output #1: loss = 0.00937471 (* 1 = 0.00937471 loss)
I0912 03:40:54.534106 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994498
I0912 03:40:54.534109 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998663
I0912 03:40:54.534117 25179 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0912 03:41:11.141647 25179 solver.cpp:228] Iteration 3640, loss = 0.0140837
I0912 03:41:11.141820 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994891
I0912 03:41:11.141860 25179 solver.cpp:244]     Train net output #1: loss = 0.0140837 (* 1 = 0.0140837 loss)
I0912 03:41:11.141871 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995807
I0912 03:41:11.141881 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993033
I0912 03:41:11.141891 25179 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0912 03:41:27.810552 25179 solver.cpp:228] Iteration 3660, loss = 0.0102443
I0912 03:41:27.810597 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995378
I0912 03:41:27.810611 25179 solver.cpp:244]     Train net output #1: loss = 0.0102443 (* 1 = 0.0102443 loss)
I0912 03:41:27.810617 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993746
I0912 03:41:27.810623 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997582
I0912 03:41:27.810631 25179 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0912 03:41:44.484238 25179 solver.cpp:228] Iteration 3680, loss = 0.00630395
I0912 03:41:44.484372 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997365
I0912 03:41:44.484400 25179 solver.cpp:244]     Train net output #1: loss = 0.00630393 (* 1 = 0.00630393 loss)
I0912 03:41:44.484413 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995964
I0912 03:41:44.484424 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998863
I0912 03:41:44.484441 25179 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0912 03:42:01.161073 25179 solver.cpp:228] Iteration 3700, loss = 0.00747154
I0912 03:42:01.161118 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997459
I0912 03:42:01.161131 25179 solver.cpp:244]     Train net output #1: loss = 0.00747152 (* 1 = 0.00747152 loss)
I0912 03:42:01.161137 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998102
I0912 03:42:01.161142 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996132
I0912 03:42:01.161150 25179 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0912 03:42:17.761466 25179 solver.cpp:228] Iteration 3720, loss = 0.00515624
I0912 03:42:17.761662 25179 solver.cpp:244]     Train net output #0: accuracy = 0.998089
I0912 03:42:17.761682 25179 solver.cpp:244]     Train net output #1: loss = 0.00515622 (* 1 = 0.00515622 loss)
I0912 03:42:17.761690 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997868
I0912 03:42:17.761701 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999015
I0912 03:42:17.761709 25179 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0912 03:42:34.385453 25179 solver.cpp:228] Iteration 3740, loss = 0.00920568
I0912 03:42:34.385506 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995846
I0912 03:42:34.385526 25179 solver.cpp:244]     Train net output #1: loss = 0.00920566 (* 1 = 0.00920566 loss)
I0912 03:42:34.385540 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992616
I0912 03:42:34.385551 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998812
I0912 03:42:34.385566 25179 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0912 03:42:50.994056 25179 solver.cpp:228] Iteration 3760, loss = 0.00708383
I0912 03:42:50.994186 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996832
I0912 03:42:50.994204 25179 solver.cpp:244]     Train net output #1: loss = 0.00708381 (* 1 = 0.00708381 loss)
I0912 03:42:50.994213 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996254
I0912 03:42:50.994220 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998193
I0912 03:42:50.994228 25179 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0912 03:43:07.604426 25179 solver.cpp:228] Iteration 3780, loss = 0.00881166
I0912 03:43:07.604471 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996622
I0912 03:43:07.604486 25179 solver.cpp:244]     Train net output #1: loss = 0.00881164 (* 1 = 0.00881164 loss)
I0912 03:43:07.604499 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996695
I0912 03:43:07.604511 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996483
I0912 03:43:07.604519 25179 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0912 03:43:24.223740 25179 solver.cpp:228] Iteration 3800, loss = 0.00593147
I0912 03:43:24.223875 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997798
I0912 03:43:24.223891 25179 solver.cpp:244]     Train net output #1: loss = 0.00593145 (* 1 = 0.00593145 loss)
I0912 03:43:24.223896 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996966
I0912 03:43:24.223901 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998596
I0912 03:43:24.223909 25179 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0912 03:43:40.818318 25179 solver.cpp:228] Iteration 3820, loss = 0.00812263
I0912 03:43:40.818362 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996393
I0912 03:43:40.818377 25179 solver.cpp:244]     Train net output #1: loss = 0.00812261 (* 1 = 0.00812261 loss)
I0912 03:43:40.818392 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995199
I0912 03:43:40.818403 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998368
I0912 03:43:40.818411 25179 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0912 03:43:57.423630 25179 solver.cpp:228] Iteration 3840, loss = 0.00692239
I0912 03:43:57.423808 25179 solver.cpp:244]     Train net output #0: accuracy = 0.9965
I0912 03:43:57.423825 25179 solver.cpp:244]     Train net output #1: loss = 0.00692237 (* 1 = 0.00692237 loss)
I0912 03:43:57.423837 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994552
I0912 03:43:57.423842 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999202
I0912 03:43:57.423851 25179 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0912 03:44:14.017568 25179 solver.cpp:228] Iteration 3860, loss = 0.0036061
I0912 03:44:14.017616 25179 solver.cpp:244]     Train net output #0: accuracy = 0.998503
I0912 03:44:14.017630 25179 solver.cpp:244]     Train net output #1: loss = 0.00360608 (* 1 = 0.00360608 loss)
I0912 03:44:14.017637 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998247
I0912 03:44:14.017643 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999172
I0912 03:44:14.017652 25179 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0912 03:44:30.626376 25179 solver.cpp:228] Iteration 3880, loss = 0.00940783
I0912 03:44:30.626509 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996668
I0912 03:44:30.626526 25179 solver.cpp:244]     Train net output #1: loss = 0.00940781 (* 1 = 0.00940781 loss)
I0912 03:44:30.626535 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997495
I0912 03:44:30.626541 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993748
I0912 03:44:30.626550 25179 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0912 03:44:47.234125 25179 solver.cpp:228] Iteration 3900, loss = 0.012288
I0912 03:44:47.234166 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994935
I0912 03:44:47.234181 25179 solver.cpp:244]     Train net output #1: loss = 0.012288 (* 1 = 0.012288 loss)
I0912 03:44:47.234194 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993926
I0912 03:44:47.234205 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996385
I0912 03:44:47.234218 25179 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0912 03:45:03.841243 25179 solver.cpp:228] Iteration 3920, loss = 0.00413212
I0912 03:45:03.841377 25179 solver.cpp:244]     Train net output #0: accuracy = 0.998247
I0912 03:45:03.841403 25179 solver.cpp:244]     Train net output #1: loss = 0.0041321 (* 1 = 0.0041321 loss)
I0912 03:45:03.841410 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997877
I0912 03:45:03.841421 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998997
I0912 03:45:03.841430 25179 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0912 03:45:20.456809 25179 solver.cpp:228] Iteration 3940, loss = 0.006433
I0912 03:45:20.456851 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99718
I0912 03:45:20.456863 25179 solver.cpp:244]     Train net output #1: loss = 0.00643298 (* 1 = 0.00643298 loss)
I0912 03:45:20.456871 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996177
I0912 03:45:20.456876 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998524
I0912 03:45:20.456884 25179 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0912 03:45:37.070366 25179 solver.cpp:228] Iteration 3960, loss = 0.00724777
I0912 03:45:37.070505 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997361
I0912 03:45:37.070523 25179 solver.cpp:244]     Train net output #1: loss = 0.00724775 (* 1 = 0.00724775 loss)
I0912 03:45:37.070533 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99575
I0912 03:45:37.070540 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99863
I0912 03:45:37.070549 25179 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0912 03:45:53.695341 25179 solver.cpp:228] Iteration 3980, loss = 0.00864118
I0912 03:45:53.695384 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996415
I0912 03:45:53.695397 25179 solver.cpp:244]     Train net output #1: loss = 0.00864116 (* 1 = 0.00864116 loss)
I0912 03:45:53.695405 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996083
I0912 03:45:53.695410 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997439
I0912 03:45:53.695418 25179 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0912 03:46:10.282917 25179 solver.cpp:228] Iteration 4000, loss = 0.00782057
I0912 03:46:10.283112 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996429
I0912 03:46:10.283134 25179 solver.cpp:244]     Train net output #1: loss = 0.00782055 (* 1 = 0.00782055 loss)
I0912 03:46:10.283143 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994759
I0912 03:46:10.283154 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998752
I0912 03:46:10.283161 25179 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0912 03:46:26.885053 25179 solver.cpp:228] Iteration 4020, loss = 0.00806633
I0912 03:46:26.885097 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996561
I0912 03:46:26.885108 25179 solver.cpp:244]     Train net output #1: loss = 0.0080663 (* 1 = 0.0080663 loss)
I0912 03:46:26.885115 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996285
I0912 03:46:26.885119 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997154
I0912 03:46:26.885128 25179 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0912 03:46:43.495769 25179 solver.cpp:228] Iteration 4040, loss = 0.00685014
I0912 03:46:43.495900 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997169
I0912 03:46:43.495918 25179 solver.cpp:244]     Train net output #1: loss = 0.00685012 (* 1 = 0.00685012 loss)
I0912 03:46:43.495925 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996592
I0912 03:46:43.495931 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998008
I0912 03:46:43.495940 25179 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0912 03:47:00.103004 25179 solver.cpp:228] Iteration 4060, loss = 0.00885226
I0912 03:47:00.103050 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996204
I0912 03:47:00.103065 25179 solver.cpp:244]     Train net output #1: loss = 0.00885224 (* 1 = 0.00885224 loss)
I0912 03:47:00.103077 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99377
I0912 03:47:00.103083 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998378
I0912 03:47:00.103093 25179 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0912 03:47:16.701485 25179 solver.cpp:228] Iteration 4080, loss = 0.00669601
I0912 03:47:16.701598 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997286
I0912 03:47:16.701614 25179 solver.cpp:244]     Train net output #1: loss = 0.00669599 (* 1 = 0.00669599 loss)
I0912 03:47:16.701627 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996508
I0912 03:47:16.701638 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998263
I0912 03:47:16.701647 25179 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0912 03:47:33.315768 25179 solver.cpp:228] Iteration 4100, loss = 0.00738621
I0912 03:47:33.315812 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99752
I0912 03:47:33.315829 25179 solver.cpp:244]     Train net output #1: loss = 0.00738619 (* 1 = 0.00738619 loss)
I0912 03:47:33.315842 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997152
I0912 03:47:33.315855 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999647
I0912 03:47:33.315862 25179 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0912 03:47:49.900066 25179 solver.cpp:228] Iteration 4120, loss = 0.00638864
I0912 03:47:49.900187 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997338
I0912 03:47:49.900202 25179 solver.cpp:244]     Train net output #1: loss = 0.00638862 (* 1 = 0.00638862 loss)
I0912 03:47:49.900213 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995824
I0912 03:47:49.900224 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998782
I0912 03:47:49.900233 25179 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0912 03:48:06.488978 25179 solver.cpp:228] Iteration 4140, loss = 0.00702896
I0912 03:48:06.489023 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997051
I0912 03:48:06.489039 25179 solver.cpp:244]     Train net output #1: loss = 0.00702894 (* 1 = 0.00702894 loss)
I0912 03:48:06.489048 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995351
I0912 03:48:06.489053 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998717
I0912 03:48:06.489061 25179 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0912 03:48:23.072249 25179 solver.cpp:228] Iteration 4160, loss = 0.00560631
I0912 03:48:23.072427 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997698
I0912 03:48:23.072445 25179 solver.cpp:244]     Train net output #1: loss = 0.00560629 (* 1 = 0.00560629 loss)
I0912 03:48:23.072453 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996793
I0912 03:48:23.072463 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998633
I0912 03:48:23.072471 25179 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0912 03:48:39.701414 25179 solver.cpp:228] Iteration 4180, loss = 0.00833089
I0912 03:48:39.701458 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99667
I0912 03:48:39.701473 25179 solver.cpp:244]     Train net output #1: loss = 0.00833087 (* 1 = 0.00833087 loss)
I0912 03:48:39.701488 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996432
I0912 03:48:39.701493 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99707
I0912 03:48:39.701501 25179 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0912 03:48:56.302803 25179 solver.cpp:228] Iteration 4200, loss = 0.00694426
I0912 03:48:56.302913 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997109
I0912 03:48:56.302927 25179 solver.cpp:244]     Train net output #1: loss = 0.00694424 (* 1 = 0.00694424 loss)
I0912 03:48:56.302935 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996687
I0912 03:48:56.302940 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998032
I0912 03:48:56.302947 25179 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0912 03:49:12.916030 25179 solver.cpp:228] Iteration 4220, loss = 0.00797238
I0912 03:49:12.916075 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996047
I0912 03:49:12.916090 25179 solver.cpp:244]     Train net output #1: loss = 0.00797236 (* 1 = 0.00797236 loss)
I0912 03:49:12.916103 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993424
I0912 03:49:12.916115 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999156
I0912 03:49:12.916123 25179 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0912 03:49:29.527422 25179 solver.cpp:228] Iteration 4240, loss = 0.00683314
I0912 03:49:29.527554 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997488
I0912 03:49:29.527571 25179 solver.cpp:244]     Train net output #1: loss = 0.00683312 (* 1 = 0.00683312 loss)
I0912 03:49:29.527581 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997667
I0912 03:49:29.527593 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996864
I0912 03:49:29.527601 25179 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0912 03:49:46.128329 25179 solver.cpp:228] Iteration 4260, loss = 0.00747552
I0912 03:49:46.128371 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996881
I0912 03:49:46.128384 25179 solver.cpp:244]     Train net output #1: loss = 0.0074755 (* 1 = 0.0074755 loss)
I0912 03:49:46.128391 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995609
I0912 03:49:46.128402 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99832
I0912 03:49:46.128412 25179 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0912 03:50:02.728322 25179 solver.cpp:228] Iteration 4280, loss = 0.00446256
I0912 03:50:02.728435 25179 solver.cpp:244]     Train net output #0: accuracy = 0.998387
I0912 03:50:02.728452 25179 solver.cpp:244]     Train net output #1: loss = 0.00446254 (* 1 = 0.00446254 loss)
I0912 03:50:02.728462 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998507
I0912 03:50:02.728473 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998242
I0912 03:50:02.728482 25179 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0912 03:50:19.347282 25179 solver.cpp:228] Iteration 4300, loss = 0.00832877
I0912 03:50:19.347323 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996409
I0912 03:50:19.347338 25179 solver.cpp:244]     Train net output #1: loss = 0.00832875 (* 1 = 0.00832875 loss)
I0912 03:50:19.347344 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993844
I0912 03:50:19.347350 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998663
I0912 03:50:19.347359 25179 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0912 03:50:35.941254 25179 solver.cpp:228] Iteration 4320, loss = 0.00602181
I0912 03:50:35.941444 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997899
I0912 03:50:35.941465 25179 solver.cpp:244]     Train net output #1: loss = 0.00602179 (* 1 = 0.00602179 loss)
I0912 03:50:35.941473 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998008
I0912 03:50:35.941485 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997422
I0912 03:50:35.941493 25179 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0912 03:50:52.547498 25179 solver.cpp:228] Iteration 4340, loss = 0.00795019
I0912 03:50:52.547540 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997451
I0912 03:50:52.547554 25179 solver.cpp:244]     Train net output #1: loss = 0.00795017 (* 1 = 0.00795017 loss)
I0912 03:50:52.547561 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998517
I0912 03:50:52.547574 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995915
I0912 03:50:52.547581 25179 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0912 03:51:09.156709 25179 solver.cpp:228] Iteration 4360, loss = 0.00577917
I0912 03:51:09.156836 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997775
I0912 03:51:09.156852 25179 solver.cpp:244]     Train net output #1: loss = 0.00577915 (* 1 = 0.00577915 loss)
I0912 03:51:09.156862 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997796
I0912 03:51:09.156872 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997737
I0912 03:51:09.156880 25179 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0912 03:51:25.765261 25179 solver.cpp:228] Iteration 4380, loss = 0.00521993
I0912 03:51:25.765303 25179 solver.cpp:244]     Train net output #0: accuracy = 0.998051
I0912 03:51:25.765317 25179 solver.cpp:244]     Train net output #1: loss = 0.00521991 (* 1 = 0.00521991 loss)
I0912 03:51:25.765332 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998535
I0912 03:51:25.765342 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996925
I0912 03:51:25.765352 25179 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0912 03:51:42.375931 25179 solver.cpp:228] Iteration 4400, loss = 0.00635701
I0912 03:51:42.376058 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997159
I0912 03:51:42.376075 25179 solver.cpp:244]     Train net output #1: loss = 0.00635699 (* 1 = 0.00635699 loss)
I0912 03:51:42.376083 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996409
I0912 03:51:42.376096 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998492
I0912 03:51:42.376103 25179 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0912 03:51:58.986491 25179 solver.cpp:228] Iteration 4420, loss = 0.00904604
I0912 03:51:58.986538 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996114
I0912 03:51:58.986554 25179 solver.cpp:244]     Train net output #1: loss = 0.00904602 (* 1 = 0.00904602 loss)
I0912 03:51:58.986563 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994851
I0912 03:51:58.986574 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997734
I0912 03:51:58.986583 25179 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0912 03:52:15.581989 25179 solver.cpp:228] Iteration 4440, loss = 0.00738349
I0912 03:52:15.582181 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996914
I0912 03:52:15.582201 25179 solver.cpp:244]     Train net output #1: loss = 0.00738347 (* 1 = 0.00738347 loss)
I0912 03:52:15.582208 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995209
I0912 03:52:15.582219 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998624
I0912 03:52:15.582227 25179 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0912 03:52:32.152942 25179 solver.cpp:228] Iteration 4460, loss = 0.00719681
I0912 03:52:32.152987 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996685
I0912 03:52:32.153003 25179 solver.cpp:244]     Train net output #1: loss = 0.0071968 (* 1 = 0.0071968 loss)
I0912 03:52:32.153010 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995588
I0912 03:52:32.153017 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998602
I0912 03:52:32.153033 25179 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0912 03:52:48.775010 25179 solver.cpp:228] Iteration 4480, loss = 0.0103522
I0912 03:52:48.775164 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995974
I0912 03:52:48.775204 25179 solver.cpp:244]     Train net output #1: loss = 0.0103522 (* 1 = 0.0103522 loss)
I0912 03:52:48.775213 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99651
I0912 03:52:48.775224 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994511
I0912 03:52:48.775234 25179 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0912 03:53:05.473438 25179 solver.cpp:228] Iteration 4500, loss = 0.00628891
I0912 03:53:05.473486 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997183
I0912 03:53:05.473516 25179 solver.cpp:244]     Train net output #1: loss = 0.00628889 (* 1 = 0.00628889 loss)
I0912 03:53:05.473526 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994759
I0912 03:53:05.473537 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999353
I0912 03:53:05.473546 25179 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0912 03:53:22.095911 25179 solver.cpp:228] Iteration 4520, loss = 0.00496151
I0912 03:53:22.096108 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997879
I0912 03:53:22.096148 25179 solver.cpp:244]     Train net output #1: loss = 0.00496149 (* 1 = 0.00496149 loss)
I0912 03:53:22.096161 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997243
I0912 03:53:22.096174 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998682
I0912 03:53:22.096189 25179 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0912 03:53:38.723299 25179 solver.cpp:228] Iteration 4540, loss = 0.00753295
I0912 03:53:38.723343 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997234
I0912 03:53:38.723358 25179 solver.cpp:244]     Train net output #1: loss = 0.00753293 (* 1 = 0.00753293 loss)
I0912 03:53:38.723366 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995982
I0912 03:53:38.723371 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998284
I0912 03:53:38.723379 25179 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0912 03:53:55.328788 25179 solver.cpp:228] Iteration 4560, loss = 0.00938392
I0912 03:53:55.328919 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99717
I0912 03:53:55.328935 25179 solver.cpp:244]     Train net output #1: loss = 0.0093839 (* 1 = 0.0093839 loss)
I0912 03:53:55.328948 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99506
I0912 03:53:55.328959 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99832
I0912 03:53:55.328969 25179 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0912 03:54:11.956513 25179 solver.cpp:228] Iteration 4580, loss = 0.00573034
I0912 03:54:11.956558 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997247
I0912 03:54:11.956573 25179 solver.cpp:244]     Train net output #1: loss = 0.00573032 (* 1 = 0.00573032 loss)
I0912 03:54:11.956580 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994978
I0912 03:54:11.956585 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999429
I0912 03:54:11.956594 25179 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0912 03:54:28.544107 25179 solver.cpp:228] Iteration 4600, loss = 0.0124429
I0912 03:54:28.544275 25179 solver.cpp:244]     Train net output #0: accuracy = 0.994884
I0912 03:54:28.544294 25179 solver.cpp:244]     Train net output #1: loss = 0.0124429 (* 1 = 0.0124429 loss)
I0912 03:54:28.544302 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994744
I0912 03:54:28.544313 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995326
I0912 03:54:28.544323 25179 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0912 03:54:45.166859 25179 solver.cpp:228] Iteration 4620, loss = 0.0100713
I0912 03:54:45.166903 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995946
I0912 03:54:45.166915 25179 solver.cpp:244]     Train net output #1: loss = 0.0100712 (* 1 = 0.0100712 loss)
I0912 03:54:45.166923 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996061
I0912 03:54:45.166929 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995749
I0912 03:54:45.166936 25179 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0912 03:55:01.763149 25179 solver.cpp:228] Iteration 4640, loss = 0.00566304
I0912 03:55:01.763276 25179 solver.cpp:244]     Train net output #0: accuracy = 0.998057
I0912 03:55:01.763293 25179 solver.cpp:244]     Train net output #1: loss = 0.00566302 (* 1 = 0.00566302 loss)
I0912 03:55:01.763300 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998181
I0912 03:55:01.763306 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997486
I0912 03:55:01.763314 25179 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0912 03:55:18.357962 25179 solver.cpp:228] Iteration 4660, loss = 0.00684163
I0912 03:55:18.358006 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997345
I0912 03:55:18.358021 25179 solver.cpp:244]     Train net output #1: loss = 0.00684162 (* 1 = 0.00684162 loss)
I0912 03:55:18.358027 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995658
I0912 03:55:18.358034 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998619
I0912 03:55:18.358042 25179 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0912 03:55:34.983618 25179 solver.cpp:228] Iteration 4680, loss = 0.00757251
I0912 03:55:34.983734 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997166
I0912 03:55:34.983752 25179 solver.cpp:244]     Train net output #1: loss = 0.0075725 (* 1 = 0.0075725 loss)
I0912 03:55:34.983762 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993415
I0912 03:55:34.983767 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999344
I0912 03:55:34.983777 25179 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0912 03:55:51.594046 25179 solver.cpp:228] Iteration 4700, loss = 0.00583276
I0912 03:55:51.594087 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997423
I0912 03:55:51.594101 25179 solver.cpp:244]     Train net output #1: loss = 0.00583274 (* 1 = 0.00583274 loss)
I0912 03:55:51.594116 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996416
I0912 03:55:51.594128 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998862
I0912 03:55:51.594137 25179 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0912 03:56:08.216547 25179 solver.cpp:228] Iteration 4720, loss = 0.00543825
I0912 03:56:08.216709 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99775
I0912 03:56:08.216749 25179 solver.cpp:244]     Train net output #1: loss = 0.00543824 (* 1 = 0.00543824 loss)
I0912 03:56:08.216758 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996804
I0912 03:56:08.216769 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998853
I0912 03:56:08.216778 25179 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0912 03:56:24.904731 25179 solver.cpp:228] Iteration 4740, loss = 0.00947799
I0912 03:56:24.904778 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996691
I0912 03:56:24.904793 25179 solver.cpp:244]     Train net output #1: loss = 0.00947797 (* 1 = 0.00947797 loss)
I0912 03:56:24.904800 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997297
I0912 03:56:24.904806 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993787
I0912 03:56:24.904815 25179 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0912 03:56:41.557524 25179 solver.cpp:228] Iteration 4760, loss = 0.0059125
I0912 03:56:41.557711 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99792
I0912 03:56:41.557731 25179 solver.cpp:244]     Train net output #1: loss = 0.00591249 (* 1 = 0.00591249 loss)
I0912 03:56:41.557744 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998439
I0912 03:56:41.557755 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996497
I0912 03:56:41.557765 25179 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0912 03:56:58.167297 25179 solver.cpp:228] Iteration 4780, loss = 0.00876219
I0912 03:56:58.167346 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996995
I0912 03:56:58.167361 25179 solver.cpp:244]     Train net output #1: loss = 0.00876217 (* 1 = 0.00876217 loss)
I0912 03:56:58.167367 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997671
I0912 03:56:58.167374 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99409
I0912 03:56:58.167384 25179 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0912 03:57:14.807739 25179 solver.cpp:228] Iteration 4800, loss = 0.00798618
I0912 03:57:14.807898 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996427
I0912 03:57:14.807938 25179 solver.cpp:244]     Train net output #1: loss = 0.00798617 (* 1 = 0.00798617 loss)
I0912 03:57:14.807948 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995103
I0912 03:57:14.807960 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998322
I0912 03:57:14.807968 25179 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0912 03:57:31.440917 25179 solver.cpp:228] Iteration 4820, loss = 0.00641537
I0912 03:57:31.440963 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997473
I0912 03:57:31.440979 25179 solver.cpp:244]     Train net output #1: loss = 0.00641535 (* 1 = 0.00641535 loss)
I0912 03:57:31.440985 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996945
I0912 03:57:31.440991 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998106
I0912 03:57:31.441000 25179 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0912 03:57:48.039258 25179 solver.cpp:228] Iteration 4840, loss = 0.00928687
I0912 03:57:48.039386 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996325
I0912 03:57:48.039402 25179 solver.cpp:244]     Train net output #1: loss = 0.00928685 (* 1 = 0.00928685 loss)
I0912 03:57:48.039408 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995661
I0912 03:57:48.039414 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997157
I0912 03:57:48.039423 25179 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0912 03:58:04.668305 25179 solver.cpp:228] Iteration 4860, loss = 0.00489486
I0912 03:58:04.668350 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997889
I0912 03:58:04.668365 25179 solver.cpp:244]     Train net output #1: loss = 0.00489484 (* 1 = 0.00489484 loss)
I0912 03:58:04.668372 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997564
I0912 03:58:04.668377 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99867
I0912 03:58:04.668386 25179 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0912 03:58:21.277649 25179 solver.cpp:228] Iteration 4880, loss = 0.00386398
I0912 03:58:21.277770 25179 solver.cpp:244]     Train net output #0: accuracy = 0.998654
I0912 03:58:21.277786 25179 solver.cpp:244]     Train net output #1: loss = 0.00386397 (* 1 = 0.00386397 loss)
I0912 03:58:21.277796 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99881
I0912 03:58:21.277802 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998141
I0912 03:58:21.277812 25179 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0912 03:58:37.908152 25179 solver.cpp:228] Iteration 4900, loss = 0.0172504
I0912 03:58:37.908197 25179 solver.cpp:244]     Train net output #0: accuracy = 0.992946
I0912 03:58:37.908212 25179 solver.cpp:244]     Train net output #1: loss = 0.0172504 (* 1 = 0.0172504 loss)
I0912 03:58:37.908221 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992883
I0912 03:58:37.908226 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993109
I0912 03:58:37.908234 25179 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0912 03:58:54.536762 25179 solver.cpp:228] Iteration 4920, loss = 0.00691857
I0912 03:58:54.536931 25179 solver.cpp:244]     Train net output #0: accuracy = 0.996691
I0912 03:58:54.536948 25179 solver.cpp:244]     Train net output #1: loss = 0.00691856 (* 1 = 0.00691856 loss)
I0912 03:58:54.536958 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993306
I0912 03:58:54.536964 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999542
I0912 03:58:54.536972 25179 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0912 03:59:11.150090 25179 solver.cpp:228] Iteration 4940, loss = 0.00510989
I0912 03:59:11.150136 25179 solver.cpp:244]     Train net output #0: accuracy = 0.99806
I0912 03:59:11.150151 25179 solver.cpp:244]     Train net output #1: loss = 0.00510987 (* 1 = 0.00510987 loss)
I0912 03:59:11.150158 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997689
I0912 03:59:11.150173 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998551
I0912 03:59:11.150182 25179 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0912 03:59:27.766474 25179 solver.cpp:228] Iteration 4960, loss = 0.00985594
I0912 03:59:27.766599 25179 solver.cpp:244]     Train net output #0: accuracy = 0.995901
I0912 03:59:27.766615 25179 solver.cpp:244]     Train net output #1: loss = 0.00985592 (* 1 = 0.00985592 loss)
I0912 03:59:27.766628 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995829
I0912 03:59:27.766639 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996069
I0912 03:59:27.766647 25179 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0912 03:59:44.370810 25179 solver.cpp:228] Iteration 4980, loss = 0.00577602
I0912 03:59:44.370860 25179 solver.cpp:244]     Train net output #0: accuracy = 0.997676
I0912 03:59:44.370875 25179 solver.cpp:244]     Train net output #1: loss = 0.005776 (* 1 = 0.005776 loss)
I0912 03:59:44.370883 25179 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997224
I0912 03:59:44.370890 25179 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998411
I0912 03:59:44.370898 25179 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0912 04:00:00.605533 25179 solver.cpp:454] Snapshotting to binary proto file pocwisc4/training_iter_5000.caffemodel
I0912 04:00:01.921811 25179 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc4/training_iter_5000.solverstate
I0912 04:00:02.526304 25179 solver.cpp:317] Iteration 5000, loss = 0.0062248
I0912 04:00:02.526350 25179 solver.cpp:322] Optimization Done.
I0912 04:00:02.526355 25179 caffe.cpp:254] Optimization Done.

2017-09-12 04:00:02,923 log.framework MainThread  INFO       caffe models found
pocwisc4/training_iter_5000.caffemodel
2017-09-12 04:00:02,923 log.framework MainThread  INFO       Caffe model found: pocwisc4/training_iter_5000.caffemodel
2017-09-12 04:00:04,521 log.framework MainThread  INFO       uniques of label [0]
2017-09-12 04:00:04,524 log.framework MainThread  INFO       Image_0 has only one class - no confusion matrix is calculate!
2017-09-12 04:00:04,609 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 04:00:04,749 log.framework MainThread  INFO       uniques of label [0]
2017-09-12 04:00:04,751 log.framework MainThread  INFO       Image_2 has only one class - no confusion matrix is calculate!
2017-09-12 04:00:04,836 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 04:00:04,974 log.framework MainThread  INFO       uniques of label [0]
2017-09-12 04:00:04,977 log.framework MainThread  INFO       Image_4 has only one class - no confusion matrix is calculate!
2017-09-12 04:00:05,063 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 04:00:05,212 log.framework MainThread  INFO       train file number: 29
2017-09-12 04:00:05,212 log.framework MainThread  INFO       test file number: 4
2017-09-12 04:00:05,213 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 04:00:05,213 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 04:00:05,213 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-09-12 04:00:05,236 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-09-12 04:00:05,236 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-09-12 04:00:05,237 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc5/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc5/training"
solver_mode: GPU

2017-09-12 04:00:05,237 log.framework MainThread  INFO       caffe training step
2017-09-12 04:00:05,237 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc5/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-09-12 05:09:27,484 log.framework MainThread  INFO       I0912 04:00:05.305673 26285 caffe.cpp:217] Using GPUs 0
I0912 04:00:05.317234 26285 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0912 04:00:06.077590 26285 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc5/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc5/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0912 04:00:06.077772 26285 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc5/caffe/model_segnet_final/train.prototxt
I0912 04:00:06.080559 26285 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc5/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 04:00:06.081089 26285 layer_factory.hpp:77] Creating layer data
I0912 04:00:06.081113 26285 net.cpp:100] Creating Layer data
I0912 04:00:06.081130 26285 net.cpp:408] data -> data
I0912 04:00:06.081168 26285 net.cpp:408] data -> label
I0912 04:00:06.081194 26285 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc5/HDF5Files/train_combined.txt
I0912 04:00:06.081259 26285 hdf5_data_layer.cpp:93] Number of HDF5 files: 29
I0912 04:00:06.082458 26285 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0912 04:00:06.107061 26285 net.cpp:150] Setting up data
I0912 04:00:06.107091 26285 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 04:00:06.107101 26285 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 04:00:06.107107 26285 net.cpp:165] Memory required for data: 24883200
I0912 04:00:06.107120 26285 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 04:00:06.107151 26285 net.cpp:100] Creating Layer label_data_1_split
I0912 04:00:06.107162 26285 net.cpp:434] label_data_1_split <- label
I0912 04:00:06.107187 26285 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 04:00:06.107204 26285 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 04:00:06.107256 26285 net.cpp:150] Setting up label_data_1_split
I0912 04:00:06.107267 26285 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 04:00:06.107277 26285 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 04:00:06.107285 26285 net.cpp:165] Memory required for data: 30412800
I0912 04:00:06.107290 26285 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 04:00:06.107316 26285 net.cpp:100] Creating Layer conv1_1_1
I0912 04:00:06.107321 26285 net.cpp:434] conv1_1_1 <- data
I0912 04:00:06.107331 26285 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 04:00:06.629088 26285 net.cpp:150] Setting up conv1_1_1
I0912 04:00:06.629125 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:06.629132 26285 net.cpp:165] Memory required for data: 207360000
I0912 04:00:06.629166 26285 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 04:00:06.629194 26285 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 04:00:06.629204 26285 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 04:00:06.629223 26285 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 04:00:06.629647 26285 net.cpp:150] Setting up conv1_1_1_bn
I0912 04:00:06.629659 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:06.629665 26285 net.cpp:165] Memory required for data: 384307200
I0912 04:00:06.629686 26285 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 04:00:06.629703 26285 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 04:00:06.629710 26285 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 04:00:06.629719 26285 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 04:00:06.629776 26285 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 04:00:06.631394 26285 net.cpp:150] Setting up conv1_1_1_scale
I0912 04:00:06.631412 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:06.631418 26285 net.cpp:165] Memory required for data: 561254400
I0912 04:00:06.631431 26285 layer_factory.hpp:77] Creating layer relu1_1
I0912 04:00:06.631453 26285 net.cpp:100] Creating Layer relu1_1
I0912 04:00:06.631460 26285 net.cpp:434] relu1_1 <- conv1_1_1
I0912 04:00:06.631469 26285 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 04:00:06.631707 26285 net.cpp:150] Setting up relu1_1
I0912 04:00:06.631719 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:06.631726 26285 net.cpp:165] Memory required for data: 738201600
I0912 04:00:06.631732 26285 layer_factory.hpp:77] Creating layer conv1_2
I0912 04:00:06.631750 26285 net.cpp:100] Creating Layer conv1_2
I0912 04:00:06.631757 26285 net.cpp:434] conv1_2 <- conv1_1_1
I0912 04:00:06.631767 26285 net.cpp:408] conv1_2 -> conv1_2
I0912 04:00:06.635957 26285 net.cpp:150] Setting up conv1_2
I0912 04:00:06.635975 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:06.635982 26285 net.cpp:165] Memory required for data: 915148800
I0912 04:00:06.635999 26285 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 04:00:06.636013 26285 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 04:00:06.636026 26285 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 04:00:06.636044 26285 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 04:00:06.637568 26285 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 04:00:06.637585 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:06.637591 26285 net.cpp:165] Memory required for data: 1092096000
I0912 04:00:06.637607 26285 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 04:00:06.637625 26285 net.cpp:100] Creating Layer conv1_2_scale
I0912 04:00:06.637632 26285 net.cpp:434] conv1_2_scale <- conv1_2
I0912 04:00:06.637641 26285 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 04:00:06.637691 26285 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 04:00:06.638073 26285 net.cpp:150] Setting up conv1_2_scale
I0912 04:00:06.638085 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:06.638092 26285 net.cpp:165] Memory required for data: 1269043200
I0912 04:00:06.638103 26285 layer_factory.hpp:77] Creating layer relu1_2
I0912 04:00:06.638111 26285 net.cpp:100] Creating Layer relu1_2
I0912 04:00:06.638118 26285 net.cpp:434] relu1_2 <- conv1_2
I0912 04:00:06.638126 26285 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 04:00:06.638332 26285 net.cpp:150] Setting up relu1_2
I0912 04:00:06.638345 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:06.638350 26285 net.cpp:165] Memory required for data: 1445990400
I0912 04:00:06.638356 26285 layer_factory.hpp:77] Creating layer pool1
I0912 04:00:06.638365 26285 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 04:00:06.638376 26285 net.cpp:100] Creating Layer pool1
I0912 04:00:06.638383 26285 net.cpp:434] pool1 <- conv1_2
I0912 04:00:06.638392 26285 net.cpp:408] pool1 -> pool1
I0912 04:00:06.638406 26285 net.cpp:408] pool1 -> pool1_mask
I0912 04:00:06.638465 26285 net.cpp:150] Setting up pool1
I0912 04:00:06.638475 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:06.638484 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:06.638490 26285 net.cpp:165] Memory required for data: 1534464000
I0912 04:00:06.638495 26285 layer_factory.hpp:77] Creating layer conv2_1
I0912 04:00:06.638511 26285 net.cpp:100] Creating Layer conv2_1
I0912 04:00:06.638517 26285 net.cpp:434] conv2_1 <- pool1
I0912 04:00:06.638527 26285 net.cpp:408] conv2_1 -> conv2_1
I0912 04:00:06.644609 26285 net.cpp:150] Setting up conv2_1
I0912 04:00:06.644629 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:06.644636 26285 net.cpp:165] Memory required for data: 1622937600
I0912 04:00:06.644649 26285 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 04:00:06.644667 26285 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 04:00:06.644681 26285 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 04:00:06.644700 26285 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 04:00:06.644943 26285 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 04:00:06.644954 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:06.644960 26285 net.cpp:165] Memory required for data: 1711411200
I0912 04:00:06.644979 26285 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 04:00:06.645002 26285 net.cpp:100] Creating Layer conv2_1_scale
I0912 04:00:06.645010 26285 net.cpp:434] conv2_1_scale <- conv2_1
I0912 04:00:06.645018 26285 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 04:00:06.645068 26285 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 04:00:06.645254 26285 net.cpp:150] Setting up conv2_1_scale
I0912 04:00:06.645267 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:06.645274 26285 net.cpp:165] Memory required for data: 1799884800
I0912 04:00:06.645285 26285 layer_factory.hpp:77] Creating layer relu2_1
I0912 04:00:06.645294 26285 net.cpp:100] Creating Layer relu2_1
I0912 04:00:06.645301 26285 net.cpp:434] relu2_1 <- conv2_1
I0912 04:00:06.645310 26285 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 04:00:06.646348 26285 net.cpp:150] Setting up relu2_1
I0912 04:00:06.646366 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:06.646373 26285 net.cpp:165] Memory required for data: 1888358400
I0912 04:00:06.646379 26285 layer_factory.hpp:77] Creating layer conv2_2
I0912 04:00:06.646394 26285 net.cpp:100] Creating Layer conv2_2
I0912 04:00:06.646402 26285 net.cpp:434] conv2_2 <- conv2_1
I0912 04:00:06.646412 26285 net.cpp:408] conv2_2 -> conv2_2
I0912 04:00:06.653784 26285 net.cpp:150] Setting up conv2_2
I0912 04:00:06.653803 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:06.653810 26285 net.cpp:165] Memory required for data: 1976832000
I0912 04:00:06.653823 26285 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 04:00:06.653836 26285 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 04:00:06.653856 26285 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 04:00:06.653864 26285 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 04:00:06.654109 26285 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 04:00:06.654121 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:06.654127 26285 net.cpp:165] Memory required for data: 2065305600
I0912 04:00:06.654152 26285 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 04:00:06.654163 26285 net.cpp:100] Creating Layer conv2_2_scale
I0912 04:00:06.654176 26285 net.cpp:434] conv2_2_scale <- conv2_2
I0912 04:00:06.654193 26285 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 04:00:06.654242 26285 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 04:00:06.654428 26285 net.cpp:150] Setting up conv2_2_scale
I0912 04:00:06.654439 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:06.654445 26285 net.cpp:165] Memory required for data: 2153779200
I0912 04:00:06.654456 26285 layer_factory.hpp:77] Creating layer relu2_2
I0912 04:00:06.654466 26285 net.cpp:100] Creating Layer relu2_2
I0912 04:00:06.654474 26285 net.cpp:434] relu2_2 <- conv2_2
I0912 04:00:06.654482 26285 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 04:00:06.654685 26285 net.cpp:150] Setting up relu2_2
I0912 04:00:06.654697 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:06.654702 26285 net.cpp:165] Memory required for data: 2242252800
I0912 04:00:06.654708 26285 layer_factory.hpp:77] Creating layer pool2
I0912 04:00:06.654717 26285 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 04:00:06.654726 26285 net.cpp:100] Creating Layer pool2
I0912 04:00:06.654732 26285 net.cpp:434] pool2 <- conv2_2
I0912 04:00:06.654742 26285 net.cpp:408] pool2 -> pool2
I0912 04:00:06.654754 26285 net.cpp:408] pool2 -> pool2_mask
I0912 04:00:06.654803 26285 net.cpp:150] Setting up pool2
I0912 04:00:06.654814 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:06.654824 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:06.654829 26285 net.cpp:165] Memory required for data: 2286489600
I0912 04:00:06.654835 26285 layer_factory.hpp:77] Creating layer conv3_1
I0912 04:00:06.654850 26285 net.cpp:100] Creating Layer conv3_1
I0912 04:00:06.654857 26285 net.cpp:434] conv3_1 <- pool2
I0912 04:00:06.654866 26285 net.cpp:408] conv3_1 -> conv3_1
I0912 04:00:06.667074 26285 net.cpp:150] Setting up conv3_1
I0912 04:00:06.667106 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.667114 26285 net.cpp:165] Memory required for data: 2330726400
I0912 04:00:06.667126 26285 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 04:00:06.667150 26285 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 04:00:06.667165 26285 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 04:00:06.667173 26285 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 04:00:06.667407 26285 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 04:00:06.667419 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.667425 26285 net.cpp:165] Memory required for data: 2374963200
I0912 04:00:06.667455 26285 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 04:00:06.667465 26285 net.cpp:100] Creating Layer conv3_1_scale
I0912 04:00:06.667472 26285 net.cpp:434] conv3_1_scale <- conv3_1
I0912 04:00:06.667481 26285 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 04:00:06.667532 26285 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 04:00:06.667677 26285 net.cpp:150] Setting up conv3_1_scale
I0912 04:00:06.667688 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.667695 26285 net.cpp:165] Memory required for data: 2419200000
I0912 04:00:06.667704 26285 layer_factory.hpp:77] Creating layer relu3_1
I0912 04:00:06.667714 26285 net.cpp:100] Creating Layer relu3_1
I0912 04:00:06.667722 26285 net.cpp:434] relu3_1 <- conv3_1
I0912 04:00:06.667731 26285 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 04:00:06.667937 26285 net.cpp:150] Setting up relu3_1
I0912 04:00:06.667949 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.667955 26285 net.cpp:165] Memory required for data: 2463436800
I0912 04:00:06.667961 26285 layer_factory.hpp:77] Creating layer conv3_2
I0912 04:00:06.667975 26285 net.cpp:100] Creating Layer conv3_2
I0912 04:00:06.667981 26285 net.cpp:434] conv3_2 <- conv3_1
I0912 04:00:06.667992 26285 net.cpp:408] conv3_2 -> conv3_2
I0912 04:00:06.691150 26285 net.cpp:150] Setting up conv3_2
I0912 04:00:06.691169 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.691176 26285 net.cpp:165] Memory required for data: 2507673600
I0912 04:00:06.691190 26285 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 04:00:06.691208 26285 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 04:00:06.691222 26285 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 04:00:06.691241 26285 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 04:00:06.691468 26285 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 04:00:06.691479 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.691484 26285 net.cpp:165] Memory required for data: 2551910400
I0912 04:00:06.691498 26285 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 04:00:06.691510 26285 net.cpp:100] Creating Layer conv3_2_scale
I0912 04:00:06.691517 26285 net.cpp:434] conv3_2_scale <- conv3_2
I0912 04:00:06.691526 26285 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 04:00:06.691576 26285 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 04:00:06.691718 26285 net.cpp:150] Setting up conv3_2_scale
I0912 04:00:06.691730 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.691735 26285 net.cpp:165] Memory required for data: 2596147200
I0912 04:00:06.691746 26285 layer_factory.hpp:77] Creating layer relu3_2
I0912 04:00:06.691756 26285 net.cpp:100] Creating Layer relu3_2
I0912 04:00:06.691763 26285 net.cpp:434] relu3_2 <- conv3_2
I0912 04:00:06.691771 26285 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 04:00:06.691982 26285 net.cpp:150] Setting up relu3_2
I0912 04:00:06.691993 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.691999 26285 net.cpp:165] Memory required for data: 2640384000
I0912 04:00:06.692005 26285 layer_factory.hpp:77] Creating layer conv3_3
I0912 04:00:06.692019 26285 net.cpp:100] Creating Layer conv3_3
I0912 04:00:06.692025 26285 net.cpp:434] conv3_3 <- conv3_2
I0912 04:00:06.692037 26285 net.cpp:408] conv3_3 -> conv3_3
I0912 04:00:06.715180 26285 net.cpp:150] Setting up conv3_3
I0912 04:00:06.715212 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.715220 26285 net.cpp:165] Memory required for data: 2684620800
I0912 04:00:06.715232 26285 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 04:00:06.715257 26285 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 04:00:06.715270 26285 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 04:00:06.715281 26285 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 04:00:06.715512 26285 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 04:00:06.715524 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.715530 26285 net.cpp:165] Memory required for data: 2728857600
I0912 04:00:06.715553 26285 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 04:00:06.715565 26285 net.cpp:100] Creating Layer conv3_3_scale
I0912 04:00:06.715572 26285 net.cpp:434] conv3_3_scale <- conv3_3
I0912 04:00:06.715580 26285 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 04:00:06.715629 26285 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 04:00:06.715776 26285 net.cpp:150] Setting up conv3_3_scale
I0912 04:00:06.715787 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.715793 26285 net.cpp:165] Memory required for data: 2773094400
I0912 04:00:06.715806 26285 layer_factory.hpp:77] Creating layer relu3_3
I0912 04:00:06.715816 26285 net.cpp:100] Creating Layer relu3_3
I0912 04:00:06.715823 26285 net.cpp:434] relu3_3 <- conv3_3
I0912 04:00:06.715831 26285 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 04:00:06.716042 26285 net.cpp:150] Setting up relu3_3
I0912 04:00:06.716053 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:06.716059 26285 net.cpp:165] Memory required for data: 2817331200
I0912 04:00:06.716065 26285 layer_factory.hpp:77] Creating layer pool3
I0912 04:00:06.716073 26285 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 04:00:06.716086 26285 net.cpp:100] Creating Layer pool3
I0912 04:00:06.716092 26285 net.cpp:434] pool3 <- conv3_3
I0912 04:00:06.716101 26285 net.cpp:408] pool3 -> pool3
I0912 04:00:06.716114 26285 net.cpp:408] pool3 -> pool3_mask
I0912 04:00:06.716167 26285 net.cpp:150] Setting up pool3
I0912 04:00:06.716177 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:06.716187 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:06.716193 26285 net.cpp:165] Memory required for data: 2839449600
I0912 04:00:06.716199 26285 layer_factory.hpp:77] Creating layer conv4_1
I0912 04:00:06.716213 26285 net.cpp:100] Creating Layer conv4_1
I0912 04:00:06.716219 26285 net.cpp:434] conv4_1 <- pool3
I0912 04:00:06.716229 26285 net.cpp:408] conv4_1 -> conv4_1
I0912 04:00:06.762110 26285 net.cpp:150] Setting up conv4_1
I0912 04:00:06.762130 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.762136 26285 net.cpp:165] Memory required for data: 2861568000
I0912 04:00:06.762150 26285 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 04:00:06.762169 26285 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 04:00:06.762183 26285 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 04:00:06.762202 26285 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 04:00:06.762423 26285 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 04:00:06.762434 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.762440 26285 net.cpp:165] Memory required for data: 2883686400
I0912 04:00:06.762454 26285 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 04:00:06.762466 26285 net.cpp:100] Creating Layer conv4_1_scale
I0912 04:00:06.762473 26285 net.cpp:434] conv4_1_scale <- conv4_1
I0912 04:00:06.762482 26285 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 04:00:06.762529 26285 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 04:00:06.762663 26285 net.cpp:150] Setting up conv4_1_scale
I0912 04:00:06.762676 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.762682 26285 net.cpp:165] Memory required for data: 2905804800
I0912 04:00:06.762693 26285 layer_factory.hpp:77] Creating layer relu4_1
I0912 04:00:06.762715 26285 net.cpp:100] Creating Layer relu4_1
I0912 04:00:06.762723 26285 net.cpp:434] relu4_1 <- conv4_1
I0912 04:00:06.762732 26285 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 04:00:06.762948 26285 net.cpp:150] Setting up relu4_1
I0912 04:00:06.762960 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.762966 26285 net.cpp:165] Memory required for data: 2927923200
I0912 04:00:06.762974 26285 layer_factory.hpp:77] Creating layer conv4_2
I0912 04:00:06.762989 26285 net.cpp:100] Creating Layer conv4_2
I0912 04:00:06.762995 26285 net.cpp:434] conv4_2 <- conv4_1
I0912 04:00:06.763006 26285 net.cpp:408] conv4_2 -> conv4_2
I0912 04:00:06.848026 26285 net.cpp:150] Setting up conv4_2
I0912 04:00:06.848050 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.848057 26285 net.cpp:165] Memory required for data: 2950041600
I0912 04:00:06.848075 26285 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 04:00:06.848094 26285 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 04:00:06.848109 26285 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 04:00:06.848124 26285 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 04:00:06.848350 26285 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 04:00:06.848361 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.848367 26285 net.cpp:165] Memory required for data: 2972160000
I0912 04:00:06.848389 26285 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 04:00:06.848404 26285 net.cpp:100] Creating Layer conv4_2_scale
I0912 04:00:06.848410 26285 net.cpp:434] conv4_2_scale <- conv4_2
I0912 04:00:06.848419 26285 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 04:00:06.848467 26285 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 04:00:06.848603 26285 net.cpp:150] Setting up conv4_2_scale
I0912 04:00:06.848613 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.848621 26285 net.cpp:165] Memory required for data: 2994278400
I0912 04:00:06.848634 26285 layer_factory.hpp:77] Creating layer relu4_2
I0912 04:00:06.848644 26285 net.cpp:100] Creating Layer relu4_2
I0912 04:00:06.848650 26285 net.cpp:434] relu4_2 <- conv4_2
I0912 04:00:06.848659 26285 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 04:00:06.849728 26285 net.cpp:150] Setting up relu4_2
I0912 04:00:06.849746 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.849752 26285 net.cpp:165] Memory required for data: 3016396800
I0912 04:00:06.849759 26285 layer_factory.hpp:77] Creating layer conv4_3
I0912 04:00:06.849779 26285 net.cpp:100] Creating Layer conv4_3
I0912 04:00:06.849786 26285 net.cpp:434] conv4_3 <- conv4_2
I0912 04:00:06.849798 26285 net.cpp:408] conv4_3 -> conv4_3
I0912 04:00:06.933095 26285 net.cpp:150] Setting up conv4_3
I0912 04:00:06.933115 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.933121 26285 net.cpp:165] Memory required for data: 3038515200
I0912 04:00:06.933149 26285 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 04:00:06.933162 26285 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 04:00:06.933176 26285 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 04:00:06.933185 26285 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 04:00:06.933425 26285 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 04:00:06.933437 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.933444 26285 net.cpp:165] Memory required for data: 3060633600
I0912 04:00:06.933457 26285 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 04:00:06.933471 26285 net.cpp:100] Creating Layer conv4_3_scale
I0912 04:00:06.933485 26285 net.cpp:434] conv4_3_scale <- conv4_3
I0912 04:00:06.933496 26285 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 04:00:06.933547 26285 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 04:00:06.933686 26285 net.cpp:150] Setting up conv4_3_scale
I0912 04:00:06.933696 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.933701 26285 net.cpp:165] Memory required for data: 3082752000
I0912 04:00:06.933717 26285 layer_factory.hpp:77] Creating layer relu4_3
I0912 04:00:06.933743 26285 net.cpp:100] Creating Layer relu4_3
I0912 04:00:06.933751 26285 net.cpp:434] relu4_3 <- conv4_3
I0912 04:00:06.933760 26285 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 04:00:06.933971 26285 net.cpp:150] Setting up relu4_3
I0912 04:00:06.933984 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:06.933990 26285 net.cpp:165] Memory required for data: 3104870400
I0912 04:00:06.933995 26285 layer_factory.hpp:77] Creating layer pool4
I0912 04:00:06.934005 26285 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 04:00:06.934016 26285 net.cpp:100] Creating Layer pool4
I0912 04:00:06.934023 26285 net.cpp:434] pool4 <- conv4_3
I0912 04:00:06.934036 26285 net.cpp:408] pool4 -> pool4
I0912 04:00:06.934048 26285 net.cpp:408] pool4 -> pool4_mask
I0912 04:00:06.934103 26285 net.cpp:150] Setting up pool4
I0912 04:00:06.934113 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:06.934123 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:06.934128 26285 net.cpp:165] Memory required for data: 3116175360
I0912 04:00:06.934134 26285 layer_factory.hpp:77] Creating layer conv5_1
I0912 04:00:06.934150 26285 net.cpp:100] Creating Layer conv5_1
I0912 04:00:06.934156 26285 net.cpp:434] conv5_1 <- pool4
I0912 04:00:06.934168 26285 net.cpp:408] conv5_1 -> conv5_1
I0912 04:00:07.017467 26285 net.cpp:150] Setting up conv5_1
I0912 04:00:07.017487 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.017493 26285 net.cpp:165] Memory required for data: 3121827840
I0912 04:00:07.017506 26285 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 04:00:07.017526 26285 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 04:00:07.017540 26285 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 04:00:07.017560 26285 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 04:00:07.017796 26285 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 04:00:07.017807 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.017812 26285 net.cpp:165] Memory required for data: 3127480320
I0912 04:00:07.017837 26285 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 04:00:07.017848 26285 net.cpp:100] Creating Layer conv5_1_scale
I0912 04:00:07.017854 26285 net.cpp:434] conv5_1_scale <- conv5_1
I0912 04:00:07.017863 26285 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 04:00:07.017920 26285 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 04:00:07.018051 26285 net.cpp:150] Setting up conv5_1_scale
I0912 04:00:07.018062 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.018069 26285 net.cpp:165] Memory required for data: 3133132800
I0912 04:00:07.018081 26285 layer_factory.hpp:77] Creating layer relu5_1
I0912 04:00:07.018091 26285 net.cpp:100] Creating Layer relu5_1
I0912 04:00:07.018098 26285 net.cpp:434] relu5_1 <- conv5_1
I0912 04:00:07.018107 26285 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 04:00:07.018317 26285 net.cpp:150] Setting up relu5_1
I0912 04:00:07.018329 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.018337 26285 net.cpp:165] Memory required for data: 3138785280
I0912 04:00:07.018342 26285 layer_factory.hpp:77] Creating layer conv5_2
I0912 04:00:07.018360 26285 net.cpp:100] Creating Layer conv5_2
I0912 04:00:07.018366 26285 net.cpp:434] conv5_2 <- conv5_1
I0912 04:00:07.018378 26285 net.cpp:408] conv5_2 -> conv5_2
I0912 04:00:07.101730 26285 net.cpp:150] Setting up conv5_2
I0912 04:00:07.101750 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.101758 26285 net.cpp:165] Memory required for data: 3144437760
I0912 04:00:07.101769 26285 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 04:00:07.101789 26285 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 04:00:07.101801 26285 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 04:00:07.101820 26285 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 04:00:07.102049 26285 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 04:00:07.102061 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.102087 26285 net.cpp:165] Memory required for data: 3150090240
I0912 04:00:07.102104 26285 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 04:00:07.102115 26285 net.cpp:100] Creating Layer conv5_2_scale
I0912 04:00:07.102123 26285 net.cpp:434] conv5_2_scale <- conv5_2
I0912 04:00:07.102133 26285 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 04:00:07.102190 26285 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 04:00:07.102324 26285 net.cpp:150] Setting up conv5_2_scale
I0912 04:00:07.102335 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.102340 26285 net.cpp:165] Memory required for data: 3155742720
I0912 04:00:07.102354 26285 layer_factory.hpp:77] Creating layer relu5_2
I0912 04:00:07.102363 26285 net.cpp:100] Creating Layer relu5_2
I0912 04:00:07.102371 26285 net.cpp:434] relu5_2 <- conv5_2
I0912 04:00:07.102380 26285 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 04:00:07.102591 26285 net.cpp:150] Setting up relu5_2
I0912 04:00:07.102604 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.102609 26285 net.cpp:165] Memory required for data: 3161395200
I0912 04:00:07.102615 26285 layer_factory.hpp:77] Creating layer conv5_3
I0912 04:00:07.102633 26285 net.cpp:100] Creating Layer conv5_3
I0912 04:00:07.102640 26285 net.cpp:434] conv5_3 <- conv5_2
I0912 04:00:07.102653 26285 net.cpp:408] conv5_3 -> conv5_3
I0912 04:00:07.185979 26285 net.cpp:150] Setting up conv5_3
I0912 04:00:07.185999 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.186007 26285 net.cpp:165] Memory required for data: 3167047680
I0912 04:00:07.186018 26285 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 04:00:07.186044 26285 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 04:00:07.186058 26285 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 04:00:07.186076 26285 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 04:00:07.186308 26285 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 04:00:07.186319 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.186326 26285 net.cpp:165] Memory required for data: 3172700160
I0912 04:00:07.186349 26285 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 04:00:07.186359 26285 net.cpp:100] Creating Layer conv5_3_scale
I0912 04:00:07.186367 26285 net.cpp:434] conv5_3_scale <- conv5_3
I0912 04:00:07.186375 26285 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 04:00:07.186431 26285 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 04:00:07.186563 26285 net.cpp:150] Setting up conv5_3_scale
I0912 04:00:07.186574 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.186583 26285 net.cpp:165] Memory required for data: 3178352640
I0912 04:00:07.186594 26285 layer_factory.hpp:77] Creating layer relu5_3
I0912 04:00:07.186605 26285 net.cpp:100] Creating Layer relu5_3
I0912 04:00:07.186614 26285 net.cpp:434] relu5_3 <- conv5_3
I0912 04:00:07.186622 26285 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 04:00:07.186838 26285 net.cpp:150] Setting up relu5_3
I0912 04:00:07.186851 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.186856 26285 net.cpp:165] Memory required for data: 3184005120
I0912 04:00:07.186864 26285 layer_factory.hpp:77] Creating layer pool5
I0912 04:00:07.186872 26285 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 04:00:07.186884 26285 net.cpp:100] Creating Layer pool5
I0912 04:00:07.186890 26285 net.cpp:434] pool5 <- conv5_3
I0912 04:00:07.186900 26285 net.cpp:408] pool5 -> pool5
I0912 04:00:07.186913 26285 net.cpp:408] pool5 -> pool5_mask
I0912 04:00:07.186969 26285 net.cpp:150] Setting up pool5
I0912 04:00:07.186978 26285 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 04:00:07.186988 26285 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 04:00:07.186995 26285 net.cpp:165] Memory required for data: 3186954240
I0912 04:00:07.187000 26285 layer_factory.hpp:77] Creating layer upsample5
I0912 04:00:07.187017 26285 net.cpp:100] Creating Layer upsample5
I0912 04:00:07.187023 26285 net.cpp:434] upsample5 <- pool5
I0912 04:00:07.187046 26285 net.cpp:434] upsample5 <- pool5_mask
I0912 04:00:07.187057 26285 net.cpp:408] upsample5 -> pool5_D
I0912 04:00:07.187100 26285 net.cpp:150] Setting up upsample5
I0912 04:00:07.187110 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.187119 26285 net.cpp:165] Memory required for data: 3192606720
I0912 04:00:07.187125 26285 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 04:00:07.187144 26285 net.cpp:100] Creating Layer conv5_3_D
I0912 04:00:07.187150 26285 net.cpp:434] conv5_3_D <- pool5_D
I0912 04:00:07.187160 26285 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 04:00:07.271361 26285 net.cpp:150] Setting up conv5_3_D
I0912 04:00:07.271381 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.271389 26285 net.cpp:165] Memory required for data: 3198259200
I0912 04:00:07.271401 26285 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 04:00:07.271423 26285 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 04:00:07.271437 26285 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 04:00:07.271456 26285 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 04:00:07.271692 26285 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 04:00:07.271703 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.271708 26285 net.cpp:165] Memory required for data: 3203911680
I0912 04:00:07.271721 26285 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 04:00:07.271733 26285 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 04:00:07.271741 26285 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 04:00:07.271750 26285 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 04:00:07.271806 26285 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 04:00:07.271939 26285 net.cpp:150] Setting up conv5_3_D_scale
I0912 04:00:07.271950 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.271956 26285 net.cpp:165] Memory required for data: 3209564160
I0912 04:00:07.271970 26285 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 04:00:07.271983 26285 net.cpp:100] Creating Layer relu5_3_D
I0912 04:00:07.271989 26285 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 04:00:07.271998 26285 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 04:00:07.272219 26285 net.cpp:150] Setting up relu5_3_D
I0912 04:00:07.272231 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.272236 26285 net.cpp:165] Memory required for data: 3215216640
I0912 04:00:07.272245 26285 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 04:00:07.272279 26285 net.cpp:100] Creating Layer conv5_2_D
I0912 04:00:07.272284 26285 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 04:00:07.272296 26285 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 04:00:07.356140 26285 net.cpp:150] Setting up conv5_2_D
I0912 04:00:07.356164 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.356171 26285 net.cpp:165] Memory required for data: 3220869120
I0912 04:00:07.356189 26285 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 04:00:07.356206 26285 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 04:00:07.356222 26285 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 04:00:07.356238 26285 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 04:00:07.356482 26285 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 04:00:07.356492 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.356498 26285 net.cpp:165] Memory required for data: 3226521600
I0912 04:00:07.356523 26285 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 04:00:07.356535 26285 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 04:00:07.356542 26285 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 04:00:07.356552 26285 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 04:00:07.356611 26285 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 04:00:07.356748 26285 net.cpp:150] Setting up conv5_2_D_scale
I0912 04:00:07.356760 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.356765 26285 net.cpp:165] Memory required for data: 3232174080
I0912 04:00:07.356796 26285 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 04:00:07.356808 26285 net.cpp:100] Creating Layer relu5_2_D
I0912 04:00:07.356817 26285 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 04:00:07.356827 26285 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 04:00:07.357935 26285 net.cpp:150] Setting up relu5_2_D
I0912 04:00:07.357952 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.357959 26285 net.cpp:165] Memory required for data: 3237826560
I0912 04:00:07.357965 26285 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 04:00:07.357985 26285 net.cpp:100] Creating Layer conv5_1_D
I0912 04:00:07.357991 26285 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 04:00:07.358006 26285 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 04:00:07.441391 26285 net.cpp:150] Setting up conv5_1_D
I0912 04:00:07.441411 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.441417 26285 net.cpp:165] Memory required for data: 3243479040
I0912 04:00:07.441429 26285 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 04:00:07.441452 26285 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 04:00:07.441464 26285 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 04:00:07.441475 26285 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 04:00:07.441727 26285 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 04:00:07.441740 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.441745 26285 net.cpp:165] Memory required for data: 3249131520
I0912 04:00:07.441769 26285 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 04:00:07.441782 26285 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 04:00:07.441789 26285 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 04:00:07.441800 26285 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 04:00:07.441857 26285 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 04:00:07.442001 26285 net.cpp:150] Setting up conv5_1_D_scale
I0912 04:00:07.442013 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.442020 26285 net.cpp:165] Memory required for data: 3254784000
I0912 04:00:07.442031 26285 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 04:00:07.442042 26285 net.cpp:100] Creating Layer relu5_1_D
I0912 04:00:07.442050 26285 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 04:00:07.442059 26285 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 04:00:07.442281 26285 net.cpp:150] Setting up relu5_1_D
I0912 04:00:07.442294 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:07.442301 26285 net.cpp:165] Memory required for data: 3260436480
I0912 04:00:07.442309 26285 layer_factory.hpp:77] Creating layer upsample4
I0912 04:00:07.442322 26285 net.cpp:100] Creating Layer upsample4
I0912 04:00:07.442327 26285 net.cpp:434] upsample4 <- conv5_1_D
I0912 04:00:07.442339 26285 net.cpp:434] upsample4 <- pool4_mask
I0912 04:00:07.442348 26285 net.cpp:408] upsample4 -> pool4_D
I0912 04:00:07.442390 26285 net.cpp:150] Setting up upsample4
I0912 04:00:07.442400 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.442407 26285 net.cpp:165] Memory required for data: 3282554880
I0912 04:00:07.442414 26285 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 04:00:07.442430 26285 net.cpp:100] Creating Layer conv4_3_D
I0912 04:00:07.442436 26285 net.cpp:434] conv4_3_D <- pool4_D
I0912 04:00:07.442448 26285 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 04:00:07.525836 26285 net.cpp:150] Setting up conv4_3_D
I0912 04:00:07.525857 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.525863 26285 net.cpp:165] Memory required for data: 3304673280
I0912 04:00:07.525876 26285 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 04:00:07.525899 26285 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 04:00:07.525912 26285 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 04:00:07.525930 26285 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 04:00:07.526188 26285 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 04:00:07.526201 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.526224 26285 net.cpp:165] Memory required for data: 3326791680
I0912 04:00:07.526239 26285 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 04:00:07.526253 26285 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 04:00:07.526260 26285 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 04:00:07.526270 26285 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 04:00:07.526322 26285 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 04:00:07.526482 26285 net.cpp:150] Setting up conv4_3_D_scale
I0912 04:00:07.526494 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.526499 26285 net.cpp:165] Memory required for data: 3348910080
I0912 04:00:07.526510 26285 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 04:00:07.526520 26285 net.cpp:100] Creating Layer relu4_3_D
I0912 04:00:07.526527 26285 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 04:00:07.526536 26285 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 04:00:07.526757 26285 net.cpp:150] Setting up relu4_3_D
I0912 04:00:07.526768 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.526773 26285 net.cpp:165] Memory required for data: 3371028480
I0912 04:00:07.526779 26285 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 04:00:07.526795 26285 net.cpp:100] Creating Layer conv4_2_D
I0912 04:00:07.526801 26285 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 04:00:07.526813 26285 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 04:00:07.610152 26285 net.cpp:150] Setting up conv4_2_D
I0912 04:00:07.610172 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.610178 26285 net.cpp:165] Memory required for data: 3393146880
I0912 04:00:07.610190 26285 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 04:00:07.610213 26285 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 04:00:07.610224 26285 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 04:00:07.610241 26285 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 04:00:07.610496 26285 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 04:00:07.610507 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.610513 26285 net.cpp:165] Memory required for data: 3415265280
I0912 04:00:07.610528 26285 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 04:00:07.610543 26285 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 04:00:07.610549 26285 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 04:00:07.610558 26285 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 04:00:07.610610 26285 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 04:00:07.610769 26285 net.cpp:150] Setting up conv4_2_D_scale
I0912 04:00:07.610780 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.610785 26285 net.cpp:165] Memory required for data: 3437383680
I0912 04:00:07.610796 26285 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 04:00:07.610805 26285 net.cpp:100] Creating Layer relu4_2_D
I0912 04:00:07.610813 26285 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 04:00:07.610823 26285 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 04:00:07.611045 26285 net.cpp:150] Setting up relu4_2_D
I0912 04:00:07.611057 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.611063 26285 net.cpp:165] Memory required for data: 3459502080
I0912 04:00:07.611068 26285 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 04:00:07.611084 26285 net.cpp:100] Creating Layer conv4_1_D
I0912 04:00:07.611091 26285 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 04:00:07.611102 26285 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 04:00:07.654749 26285 net.cpp:150] Setting up conv4_1_D
I0912 04:00:07.654768 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:07.654775 26285 net.cpp:165] Memory required for data: 3470561280
I0912 04:00:07.654789 26285 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 04:00:07.654810 26285 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 04:00:07.654822 26285 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 04:00:07.654842 26285 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 04:00:07.655105 26285 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 04:00:07.655130 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:07.655138 26285 net.cpp:165] Memory required for data: 3481620480
I0912 04:00:07.655220 26285 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 04:00:07.655232 26285 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 04:00:07.655241 26285 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 04:00:07.655251 26285 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 04:00:07.655309 26285 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 04:00:07.655460 26285 net.cpp:150] Setting up conv4_1_D_scale
I0912 04:00:07.655472 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:07.655477 26285 net.cpp:165] Memory required for data: 3492679680
I0912 04:00:07.655488 26285 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 04:00:07.655498 26285 net.cpp:100] Creating Layer relu4_1_D
I0912 04:00:07.655504 26285 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 04:00:07.655514 26285 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 04:00:07.655753 26285 net.cpp:150] Setting up relu4_1_D
I0912 04:00:07.655766 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:07.655771 26285 net.cpp:165] Memory required for data: 3503738880
I0912 04:00:07.655776 26285 layer_factory.hpp:77] Creating layer upsample3
I0912 04:00:07.655787 26285 net.cpp:100] Creating Layer upsample3
I0912 04:00:07.655794 26285 net.cpp:434] upsample3 <- conv4_1_D
I0912 04:00:07.655802 26285 net.cpp:434] upsample3 <- pool3_mask
I0912 04:00:07.655812 26285 net.cpp:408] upsample3 -> pool3_D
I0912 04:00:07.655825 26285 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 04:00:07.655864 26285 net.cpp:150] Setting up upsample3
I0912 04:00:07.655874 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.655881 26285 net.cpp:165] Memory required for data: 3547975680
I0912 04:00:07.655886 26285 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 04:00:07.655903 26285 net.cpp:100] Creating Layer conv3_3_D
I0912 04:00:07.655910 26285 net.cpp:434] conv3_3_D <- pool3_D
I0912 04:00:07.655921 26285 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 04:00:07.679339 26285 net.cpp:150] Setting up conv3_3_D
I0912 04:00:07.679358 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.679364 26285 net.cpp:165] Memory required for data: 3592212480
I0912 04:00:07.679379 26285 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 04:00:07.679402 26285 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 04:00:07.679414 26285 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 04:00:07.679425 26285 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 04:00:07.679702 26285 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 04:00:07.679714 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.679719 26285 net.cpp:165] Memory required for data: 3636449280
I0912 04:00:07.679733 26285 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 04:00:07.679746 26285 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 04:00:07.679757 26285 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 04:00:07.679767 26285 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 04:00:07.679824 26285 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 04:00:07.680001 26285 net.cpp:150] Setting up conv3_3_D_scale
I0912 04:00:07.680011 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.680017 26285 net.cpp:165] Memory required for data: 3680686080
I0912 04:00:07.680027 26285 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 04:00:07.680039 26285 net.cpp:100] Creating Layer relu3_3_D
I0912 04:00:07.680047 26285 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 04:00:07.680054 26285 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 04:00:07.680289 26285 net.cpp:150] Setting up relu3_3_D
I0912 04:00:07.680301 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.680307 26285 net.cpp:165] Memory required for data: 3724922880
I0912 04:00:07.680326 26285 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 04:00:07.680346 26285 net.cpp:100] Creating Layer conv3_2_D
I0912 04:00:07.680352 26285 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 04:00:07.680363 26285 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 04:00:07.703742 26285 net.cpp:150] Setting up conv3_2_D
I0912 04:00:07.703763 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.703768 26285 net.cpp:165] Memory required for data: 3769159680
I0912 04:00:07.703783 26285 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 04:00:07.703804 26285 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 04:00:07.703815 26285 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 04:00:07.703826 26285 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 04:00:07.704108 26285 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 04:00:07.704120 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.704126 26285 net.cpp:165] Memory required for data: 3813396480
I0912 04:00:07.704139 26285 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 04:00:07.704154 26285 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 04:00:07.704164 26285 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 04:00:07.704172 26285 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 04:00:07.704229 26285 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 04:00:07.704406 26285 net.cpp:150] Setting up conv3_2_D_scale
I0912 04:00:07.704417 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.704422 26285 net.cpp:165] Memory required for data: 3857633280
I0912 04:00:07.704433 26285 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 04:00:07.704443 26285 net.cpp:100] Creating Layer relu3_2_D
I0912 04:00:07.704450 26285 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 04:00:07.704460 26285 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 04:00:07.705574 26285 net.cpp:150] Setting up relu3_2_D
I0912 04:00:07.705592 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.705598 26285 net.cpp:165] Memory required for data: 3901870080
I0912 04:00:07.705605 26285 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 04:00:07.705624 26285 net.cpp:100] Creating Layer conv3_1_D
I0912 04:00:07.705631 26285 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 04:00:07.705644 26285 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 04:00:07.719324 26285 net.cpp:150] Setting up conv3_1_D
I0912 04:00:07.719344 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:07.719350 26285 net.cpp:165] Memory required for data: 3923988480
I0912 04:00:07.719364 26285 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 04:00:07.719385 26285 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 04:00:07.719398 26285 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 04:00:07.719408 26285 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 04:00:07.719692 26285 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 04:00:07.719704 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:07.719710 26285 net.cpp:165] Memory required for data: 3946106880
I0912 04:00:07.719725 26285 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 04:00:07.719738 26285 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 04:00:07.719750 26285 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 04:00:07.719760 26285 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 04:00:07.719817 26285 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 04:00:07.719997 26285 net.cpp:150] Setting up conv3_1_D_scale
I0912 04:00:07.720008 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:07.720015 26285 net.cpp:165] Memory required for data: 3968225280
I0912 04:00:07.720024 26285 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 04:00:07.720036 26285 net.cpp:100] Creating Layer relu3_1_D
I0912 04:00:07.720042 26285 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 04:00:07.720051 26285 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 04:00:07.720290 26285 net.cpp:150] Setting up relu3_1_D
I0912 04:00:07.720314 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:07.720320 26285 net.cpp:165] Memory required for data: 3990343680
I0912 04:00:07.720329 26285 layer_factory.hpp:77] Creating layer upsample2
I0912 04:00:07.720341 26285 net.cpp:100] Creating Layer upsample2
I0912 04:00:07.720346 26285 net.cpp:434] upsample2 <- conv3_1_D
I0912 04:00:07.720355 26285 net.cpp:434] upsample2 <- pool2_mask
I0912 04:00:07.720366 26285 net.cpp:408] upsample2 -> pool2_D
I0912 04:00:07.720378 26285 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 04:00:07.720415 26285 net.cpp:150] Setting up upsample2
I0912 04:00:07.720425 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.720432 26285 net.cpp:165] Memory required for data: 4078817280
I0912 04:00:07.720439 26285 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 04:00:07.720458 26285 net.cpp:100] Creating Layer conv2_2_D
I0912 04:00:07.720464 26285 net.cpp:434] conv2_2_D <- pool2_D
I0912 04:00:07.720475 26285 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 04:00:07.728157 26285 net.cpp:150] Setting up conv2_2_D
I0912 04:00:07.728176 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.728183 26285 net.cpp:165] Memory required for data: 4167290880
I0912 04:00:07.728195 26285 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 04:00:07.728215 26285 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 04:00:07.728227 26285 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 04:00:07.728237 26285 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 04:00:07.728565 26285 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 04:00:07.728577 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.728583 26285 net.cpp:165] Memory required for data: 4255764480
I0912 04:00:07.728597 26285 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 04:00:07.728610 26285 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 04:00:07.728621 26285 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 04:00:07.728631 26285 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 04:00:07.728691 26285 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 04:00:07.730161 26285 net.cpp:150] Setting up conv2_2_D_scale
I0912 04:00:07.730180 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.730185 26285 net.cpp:165] Memory required for data: 4344238080
I0912 04:00:07.730198 26285 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 04:00:07.730217 26285 net.cpp:100] Creating Layer relu2_2_D
I0912 04:00:07.730224 26285 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 04:00:07.730234 26285 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 04:00:07.730480 26285 net.cpp:150] Setting up relu2_2_D
I0912 04:00:07.730492 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.730499 26285 net.cpp:165] Memory required for data: 4432711680
I0912 04:00:07.730505 26285 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 04:00:07.730522 26285 net.cpp:100] Creating Layer conv2_1_D
I0912 04:00:07.730530 26285 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 04:00:07.730541 26285 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 04:00:07.735808 26285 net.cpp:150] Setting up conv2_1_D
I0912 04:00:07.735826 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:07.735833 26285 net.cpp:165] Memory required for data: 4476948480
I0912 04:00:07.735846 26285 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 04:00:07.735872 26285 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 04:00:07.735883 26285 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 04:00:07.735894 26285 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 04:00:07.736208 26285 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 04:00:07.736222 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:07.736227 26285 net.cpp:165] Memory required for data: 4521185280
I0912 04:00:07.736251 26285 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 04:00:07.736275 26285 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 04:00:07.736282 26285 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 04:00:07.736292 26285 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 04:00:07.736356 26285 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 04:00:07.736589 26285 net.cpp:150] Setting up conv2_1_D_scale
I0912 04:00:07.736600 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:07.736606 26285 net.cpp:165] Memory required for data: 4565422080
I0912 04:00:07.736616 26285 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 04:00:07.736629 26285 net.cpp:100] Creating Layer relu2_1_D
I0912 04:00:07.736635 26285 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 04:00:07.736644 26285 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 04:00:07.736884 26285 net.cpp:150] Setting up relu2_1_D
I0912 04:00:07.736896 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:07.736901 26285 net.cpp:165] Memory required for data: 4609658880
I0912 04:00:07.736908 26285 layer_factory.hpp:77] Creating layer upsample1
I0912 04:00:07.736920 26285 net.cpp:100] Creating Layer upsample1
I0912 04:00:07.736927 26285 net.cpp:434] upsample1 <- conv2_1_D
I0912 04:00:07.736935 26285 net.cpp:434] upsample1 <- pool1_mask
I0912 04:00:07.736945 26285 net.cpp:408] upsample1 -> pool1_D
I0912 04:00:07.736958 26285 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 04:00:07.736997 26285 net.cpp:150] Setting up upsample1
I0912 04:00:07.737007 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.737015 26285 net.cpp:165] Memory required for data: 4786606080
I0912 04:00:07.737020 26285 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 04:00:07.737035 26285 net.cpp:100] Creating Layer conv1_2_D
I0912 04:00:07.737040 26285 net.cpp:434] conv1_2_D <- pool1_D
I0912 04:00:07.737052 26285 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 04:00:07.741555 26285 net.cpp:150] Setting up conv1_2_D
I0912 04:00:07.741575 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.741580 26285 net.cpp:165] Memory required for data: 4963553280
I0912 04:00:07.741592 26285 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 04:00:07.741614 26285 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 04:00:07.741626 26285 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 04:00:07.741636 26285 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 04:00:07.742060 26285 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 04:00:07.742072 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.742079 26285 net.cpp:165] Memory required for data: 5140500480
I0912 04:00:07.742091 26285 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 04:00:07.742100 26285 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 04:00:07.742107 26285 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 04:00:07.742120 26285 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 04:00:07.742177 26285 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 04:00:07.743829 26285 net.cpp:150] Setting up conv1_2_D_scale
I0912 04:00:07.743845 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.743851 26285 net.cpp:165] Memory required for data: 5317447680
I0912 04:00:07.743865 26285 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 04:00:07.743877 26285 net.cpp:100] Creating Layer relu1_2_D
I0912 04:00:07.743885 26285 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 04:00:07.743896 26285 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 04:00:07.744144 26285 net.cpp:150] Setting up relu1_2_D
I0912 04:00:07.744156 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.744163 26285 net.cpp:165] Memory required for data: 5494394880
I0912 04:00:07.744168 26285 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 04:00:07.744187 26285 net.cpp:100] Creating Layer conv1_1_1_D
I0912 04:00:07.744194 26285 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 04:00:07.744220 26285 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 04:00:07.746327 26285 net.cpp:150] Setting up conv1_1_1_D
I0912 04:00:07.746346 26285 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 04:00:07.746352 26285 net.cpp:165] Memory required for data: 5499924480
I0912 04:00:07.746364 26285 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 04:00:07.746379 26285 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 04:00:07.746387 26285 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 04:00:07.746395 26285 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 04:00:07.746407 26285 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 04:00:07.746469 26285 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 04:00:07.746480 26285 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 04:00:07.746489 26285 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 04:00:07.746495 26285 net.cpp:165] Memory required for data: 5510983680
I0912 04:00:07.746501 26285 layer_factory.hpp:77] Creating layer loss
I0912 04:00:07.746520 26285 net.cpp:100] Creating Layer loss
I0912 04:00:07.746526 26285 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 04:00:07.746532 26285 net.cpp:434] loss <- label_data_1_split_0
I0912 04:00:07.746546 26285 net.cpp:408] loss -> loss
I0912 04:00:07.746572 26285 layer_factory.hpp:77] Creating layer loss
I0912 04:00:07.750546 26285 net.cpp:150] Setting up loss
I0912 04:00:07.750564 26285 net.cpp:157] Top shape: (1)
I0912 04:00:07.750571 26285 net.cpp:160]     with loss weight 1
I0912 04:00:07.750617 26285 net.cpp:165] Memory required for data: 5510983684
I0912 04:00:07.750624 26285 layer_factory.hpp:77] Creating layer accuracy
I0912 04:00:07.750650 26285 net.cpp:100] Creating Layer accuracy
I0912 04:00:07.750658 26285 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 04:00:07.750666 26285 net.cpp:434] accuracy <- label_data_1_split_1
I0912 04:00:07.750676 26285 net.cpp:408] accuracy -> accuracy
I0912 04:00:07.750689 26285 net.cpp:408] accuracy -> per_class_accuracy
I0912 04:00:07.750752 26285 net.cpp:150] Setting up accuracy
I0912 04:00:07.750763 26285 net.cpp:157] Top shape: (1)
I0912 04:00:07.750771 26285 net.cpp:157] Top shape: 2 (2)
I0912 04:00:07.750777 26285 net.cpp:165] Memory required for data: 5510983696
I0912 04:00:07.750782 26285 net.cpp:228] accuracy does not need backward computation.
I0912 04:00:07.750788 26285 net.cpp:226] loss needs backward computation.
I0912 04:00:07.750797 26285 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 04:00:07.750802 26285 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 04:00:07.750809 26285 net.cpp:226] relu1_2_D needs backward computation.
I0912 04:00:07.750814 26285 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 04:00:07.750819 26285 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 04:00:07.750826 26285 net.cpp:226] conv1_2_D needs backward computation.
I0912 04:00:07.750831 26285 net.cpp:226] upsample1 needs backward computation.
I0912 04:00:07.750838 26285 net.cpp:226] relu2_1_D needs backward computation.
I0912 04:00:07.750844 26285 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 04:00:07.750849 26285 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 04:00:07.750854 26285 net.cpp:226] conv2_1_D needs backward computation.
I0912 04:00:07.750859 26285 net.cpp:226] relu2_2_D needs backward computation.
I0912 04:00:07.750864 26285 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 04:00:07.750869 26285 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 04:00:07.750874 26285 net.cpp:226] conv2_2_D needs backward computation.
I0912 04:00:07.750881 26285 net.cpp:226] upsample2 needs backward computation.
I0912 04:00:07.750887 26285 net.cpp:226] relu3_1_D needs backward computation.
I0912 04:00:07.750895 26285 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 04:00:07.750912 26285 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 04:00:07.750918 26285 net.cpp:226] conv3_1_D needs backward computation.
I0912 04:00:07.750924 26285 net.cpp:226] relu3_2_D needs backward computation.
I0912 04:00:07.750929 26285 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 04:00:07.750934 26285 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 04:00:07.750939 26285 net.cpp:226] conv3_2_D needs backward computation.
I0912 04:00:07.750944 26285 net.cpp:226] relu3_3_D needs backward computation.
I0912 04:00:07.750949 26285 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 04:00:07.750954 26285 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 04:00:07.750962 26285 net.cpp:226] conv3_3_D needs backward computation.
I0912 04:00:07.750967 26285 net.cpp:226] upsample3 needs backward computation.
I0912 04:00:07.750973 26285 net.cpp:226] relu4_1_D needs backward computation.
I0912 04:00:07.750979 26285 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 04:00:07.750984 26285 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 04:00:07.750989 26285 net.cpp:226] conv4_1_D needs backward computation.
I0912 04:00:07.750995 26285 net.cpp:226] relu4_2_D needs backward computation.
I0912 04:00:07.751001 26285 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 04:00:07.751008 26285 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 04:00:07.751013 26285 net.cpp:226] conv4_2_D needs backward computation.
I0912 04:00:07.751020 26285 net.cpp:226] relu4_3_D needs backward computation.
I0912 04:00:07.751025 26285 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 04:00:07.751030 26285 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 04:00:07.751037 26285 net.cpp:226] conv4_3_D needs backward computation.
I0912 04:00:07.751042 26285 net.cpp:226] upsample4 needs backward computation.
I0912 04:00:07.751050 26285 net.cpp:226] relu5_1_D needs backward computation.
I0912 04:00:07.751057 26285 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 04:00:07.751063 26285 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 04:00:07.751068 26285 net.cpp:226] conv5_1_D needs backward computation.
I0912 04:00:07.751075 26285 net.cpp:226] relu5_2_D needs backward computation.
I0912 04:00:07.751080 26285 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 04:00:07.751085 26285 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 04:00:07.751093 26285 net.cpp:226] conv5_2_D needs backward computation.
I0912 04:00:07.751099 26285 net.cpp:226] relu5_3_D needs backward computation.
I0912 04:00:07.751106 26285 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 04:00:07.751111 26285 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 04:00:07.751116 26285 net.cpp:226] conv5_3_D needs backward computation.
I0912 04:00:07.751123 26285 net.cpp:226] upsample5 needs backward computation.
I0912 04:00:07.751130 26285 net.cpp:226] pool5 needs backward computation.
I0912 04:00:07.751142 26285 net.cpp:226] relu5_3 needs backward computation.
I0912 04:00:07.751148 26285 net.cpp:226] conv5_3_scale needs backward computation.
I0912 04:00:07.751153 26285 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 04:00:07.751158 26285 net.cpp:226] conv5_3 needs backward computation.
I0912 04:00:07.751164 26285 net.cpp:226] relu5_2 needs backward computation.
I0912 04:00:07.751171 26285 net.cpp:226] conv5_2_scale needs backward computation.
I0912 04:00:07.751176 26285 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 04:00:07.751183 26285 net.cpp:226] conv5_2 needs backward computation.
I0912 04:00:07.751190 26285 net.cpp:226] relu5_1 needs backward computation.
I0912 04:00:07.751195 26285 net.cpp:226] conv5_1_scale needs backward computation.
I0912 04:00:07.751200 26285 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 04:00:07.751206 26285 net.cpp:226] conv5_1 needs backward computation.
I0912 04:00:07.751214 26285 net.cpp:226] pool4 needs backward computation.
I0912 04:00:07.751230 26285 net.cpp:226] relu4_3 needs backward computation.
I0912 04:00:07.751235 26285 net.cpp:226] conv4_3_scale needs backward computation.
I0912 04:00:07.751241 26285 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 04:00:07.751247 26285 net.cpp:226] conv4_3 needs backward computation.
I0912 04:00:07.751255 26285 net.cpp:226] relu4_2 needs backward computation.
I0912 04:00:07.751262 26285 net.cpp:226] conv4_2_scale needs backward computation.
I0912 04:00:07.751269 26285 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 04:00:07.751276 26285 net.cpp:226] conv4_2 needs backward computation.
I0912 04:00:07.751282 26285 net.cpp:226] relu4_1 needs backward computation.
I0912 04:00:07.751287 26285 net.cpp:226] conv4_1_scale needs backward computation.
I0912 04:00:07.751293 26285 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 04:00:07.751299 26285 net.cpp:226] conv4_1 needs backward computation.
I0912 04:00:07.751305 26285 net.cpp:226] pool3 needs backward computation.
I0912 04:00:07.751312 26285 net.cpp:226] relu3_3 needs backward computation.
I0912 04:00:07.751317 26285 net.cpp:226] conv3_3_scale needs backward computation.
I0912 04:00:07.751322 26285 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 04:00:07.751329 26285 net.cpp:226] conv3_3 needs backward computation.
I0912 04:00:07.751336 26285 net.cpp:226] relu3_2 needs backward computation.
I0912 04:00:07.751343 26285 net.cpp:226] conv3_2_scale needs backward computation.
I0912 04:00:07.751348 26285 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 04:00:07.751355 26285 net.cpp:226] conv3_2 needs backward computation.
I0912 04:00:07.751363 26285 net.cpp:226] relu3_1 needs backward computation.
I0912 04:00:07.751370 26285 net.cpp:226] conv3_1_scale needs backward computation.
I0912 04:00:07.751375 26285 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 04:00:07.751380 26285 net.cpp:226] conv3_1 needs backward computation.
I0912 04:00:07.751387 26285 net.cpp:226] pool2 needs backward computation.
I0912 04:00:07.751394 26285 net.cpp:226] relu2_2 needs backward computation.
I0912 04:00:07.751400 26285 net.cpp:226] conv2_2_scale needs backward computation.
I0912 04:00:07.751405 26285 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 04:00:07.751412 26285 net.cpp:226] conv2_2 needs backward computation.
I0912 04:00:07.751420 26285 net.cpp:226] relu2_1 needs backward computation.
I0912 04:00:07.751425 26285 net.cpp:226] conv2_1_scale needs backward computation.
I0912 04:00:07.751430 26285 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 04:00:07.751436 26285 net.cpp:226] conv2_1 needs backward computation.
I0912 04:00:07.751442 26285 net.cpp:226] pool1 needs backward computation.
I0912 04:00:07.751449 26285 net.cpp:226] relu1_2 needs backward computation.
I0912 04:00:07.751456 26285 net.cpp:226] conv1_2_scale needs backward computation.
I0912 04:00:07.751461 26285 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 04:00:07.751466 26285 net.cpp:226] conv1_2 needs backward computation.
I0912 04:00:07.751474 26285 net.cpp:226] relu1_1 needs backward computation.
I0912 04:00:07.751479 26285 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 04:00:07.751484 26285 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 04:00:07.751492 26285 net.cpp:226] conv1_1_1 needs backward computation.
I0912 04:00:07.751499 26285 net.cpp:228] label_data_1_split does not need backward computation.
I0912 04:00:07.751507 26285 net.cpp:228] data does not need backward computation.
I0912 04:00:07.751513 26285 net.cpp:270] This network produces output accuracy
I0912 04:00:07.751519 26285 net.cpp:270] This network produces output loss
I0912 04:00:07.751526 26285 net.cpp:270] This network produces output per_class_accuracy
I0912 04:00:07.751596 26285 net.cpp:283] Network initialization done.
I0912 04:00:07.753937 26285 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc5/caffe/model_segnet_final/train.prototxt
I0912 04:00:07.754643 26285 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc5/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 04:00:07.755077 26285 layer_factory.hpp:77] Creating layer data
I0912 04:00:07.755092 26285 net.cpp:100] Creating Layer data
I0912 04:00:07.755102 26285 net.cpp:408] data -> data
I0912 04:00:07.755115 26285 net.cpp:408] data -> label
I0912 04:00:07.755127 26285 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc5/HDF5Files/train_combined.txt
I0912 04:00:07.755174 26285 hdf5_data_layer.cpp:93] Number of HDF5 files: 29
I0912 04:00:07.765852 26285 net.cpp:150] Setting up data
I0912 04:00:07.765873 26285 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 04:00:07.765882 26285 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 04:00:07.765887 26285 net.cpp:165] Memory required for data: 24883200
I0912 04:00:07.765909 26285 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 04:00:07.765923 26285 net.cpp:100] Creating Layer label_data_1_split
I0912 04:00:07.765936 26285 net.cpp:434] label_data_1_split <- label
I0912 04:00:07.765945 26285 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 04:00:07.765969 26285 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 04:00:07.766027 26285 net.cpp:150] Setting up label_data_1_split
I0912 04:00:07.766038 26285 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 04:00:07.766047 26285 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 04:00:07.766059 26285 net.cpp:165] Memory required for data: 30412800
I0912 04:00:07.766065 26285 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 04:00:07.766082 26285 net.cpp:100] Creating Layer conv1_1_1
I0912 04:00:07.766088 26285 net.cpp:434] conv1_1_1 <- data
I0912 04:00:07.766096 26285 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 04:00:07.769584 26285 net.cpp:150] Setting up conv1_1_1
I0912 04:00:07.769603 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.769609 26285 net.cpp:165] Memory required for data: 207360000
I0912 04:00:07.769628 26285 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 04:00:07.769640 26285 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 04:00:07.769654 26285 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 04:00:07.769662 26285 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 04:00:07.770071 26285 net.cpp:150] Setting up conv1_1_1_bn
I0912 04:00:07.770083 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.770089 26285 net.cpp:165] Memory required for data: 384307200
I0912 04:00:07.770105 26285 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 04:00:07.770117 26285 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 04:00:07.770123 26285 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 04:00:07.770133 26285 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 04:00:07.770192 26285 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 04:00:07.771854 26285 net.cpp:150] Setting up conv1_1_1_scale
I0912 04:00:07.771872 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.771878 26285 net.cpp:165] Memory required for data: 561254400
I0912 04:00:07.771890 26285 layer_factory.hpp:77] Creating layer relu1_1
I0912 04:00:07.771903 26285 net.cpp:100] Creating Layer relu1_1
I0912 04:00:07.771909 26285 net.cpp:434] relu1_1 <- conv1_1_1
I0912 04:00:07.771919 26285 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 04:00:07.772150 26285 net.cpp:150] Setting up relu1_1
I0912 04:00:07.772162 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.772167 26285 net.cpp:165] Memory required for data: 738201600
I0912 04:00:07.772173 26285 layer_factory.hpp:77] Creating layer conv1_2
I0912 04:00:07.772187 26285 net.cpp:100] Creating Layer conv1_2
I0912 04:00:07.772193 26285 net.cpp:434] conv1_2 <- conv1_1_1
I0912 04:00:07.772203 26285 net.cpp:408] conv1_2 -> conv1_2
I0912 04:00:07.776341 26285 net.cpp:150] Setting up conv1_2
I0912 04:00:07.776360 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.776367 26285 net.cpp:165] Memory required for data: 915148800
I0912 04:00:07.776404 26285 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 04:00:07.776422 26285 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 04:00:07.776433 26285 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 04:00:07.776443 26285 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 04:00:07.776839 26285 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 04:00:07.776851 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.776857 26285 net.cpp:165] Memory required for data: 1092096000
I0912 04:00:07.776870 26285 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 04:00:07.776881 26285 net.cpp:100] Creating Layer conv1_2_scale
I0912 04:00:07.776887 26285 net.cpp:434] conv1_2_scale <- conv1_2
I0912 04:00:07.776897 26285 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 04:00:07.776955 26285 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 04:00:07.778632 26285 net.cpp:150] Setting up conv1_2_scale
I0912 04:00:07.778650 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.778656 26285 net.cpp:165] Memory required for data: 1269043200
I0912 04:00:07.778668 26285 layer_factory.hpp:77] Creating layer relu1_2
I0912 04:00:07.778678 26285 net.cpp:100] Creating Layer relu1_2
I0912 04:00:07.778686 26285 net.cpp:434] relu1_2 <- conv1_2
I0912 04:00:07.778693 26285 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 04:00:07.779826 26285 net.cpp:150] Setting up relu1_2
I0912 04:00:07.779844 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:07.779850 26285 net.cpp:165] Memory required for data: 1445990400
I0912 04:00:07.779856 26285 layer_factory.hpp:77] Creating layer pool1
I0912 04:00:07.779862 26285 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 04:00:07.779875 26285 net.cpp:100] Creating Layer pool1
I0912 04:00:07.779881 26285 net.cpp:434] pool1 <- conv1_2
I0912 04:00:07.779891 26285 net.cpp:408] pool1 -> pool1
I0912 04:00:07.779903 26285 net.cpp:408] pool1 -> pool1_mask
I0912 04:00:07.779969 26285 net.cpp:150] Setting up pool1
I0912 04:00:07.779980 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:07.779988 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:07.779994 26285 net.cpp:165] Memory required for data: 1534464000
I0912 04:00:07.779999 26285 layer_factory.hpp:77] Creating layer conv2_1
I0912 04:00:07.780014 26285 net.cpp:100] Creating Layer conv2_1
I0912 04:00:07.780019 26285 net.cpp:434] conv2_1 <- pool1
I0912 04:00:07.780031 26285 net.cpp:408] conv2_1 -> conv2_1
I0912 04:00:07.784401 26285 net.cpp:150] Setting up conv2_1
I0912 04:00:07.784420 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.784427 26285 net.cpp:165] Memory required for data: 1622937600
I0912 04:00:07.784440 26285 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 04:00:07.784452 26285 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 04:00:07.784466 26285 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 04:00:07.784476 26285 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 04:00:07.784806 26285 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 04:00:07.784817 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.784823 26285 net.cpp:165] Memory required for data: 1711411200
I0912 04:00:07.784842 26285 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 04:00:07.784852 26285 net.cpp:100] Creating Layer conv2_1_scale
I0912 04:00:07.784859 26285 net.cpp:434] conv2_1_scale <- conv2_1
I0912 04:00:07.784868 26285 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 04:00:07.784931 26285 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 04:00:07.785179 26285 net.cpp:150] Setting up conv2_1_scale
I0912 04:00:07.785192 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.785197 26285 net.cpp:165] Memory required for data: 1799884800
I0912 04:00:07.785207 26285 layer_factory.hpp:77] Creating layer relu2_1
I0912 04:00:07.785217 26285 net.cpp:100] Creating Layer relu2_1
I0912 04:00:07.785223 26285 net.cpp:434] relu2_1 <- conv2_1
I0912 04:00:07.785234 26285 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 04:00:07.786392 26285 net.cpp:150] Setting up relu2_1
I0912 04:00:07.786411 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.786417 26285 net.cpp:165] Memory required for data: 1888358400
I0912 04:00:07.786423 26285 layer_factory.hpp:77] Creating layer conv2_2
I0912 04:00:07.786440 26285 net.cpp:100] Creating Layer conv2_2
I0912 04:00:07.786448 26285 net.cpp:434] conv2_2 <- conv2_1
I0912 04:00:07.786460 26285 net.cpp:408] conv2_2 -> conv2_2
I0912 04:00:07.796929 26285 net.cpp:150] Setting up conv2_2
I0912 04:00:07.796950 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.796957 26285 net.cpp:165] Memory required for data: 1976832000
I0912 04:00:07.796972 26285 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 04:00:07.797008 26285 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 04:00:07.797017 26285 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 04:00:07.797036 26285 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 04:00:07.798611 26285 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 04:00:07.798629 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.798635 26285 net.cpp:165] Memory required for data: 2065305600
I0912 04:00:07.798648 26285 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 04:00:07.798668 26285 net.cpp:100] Creating Layer conv2_2_scale
I0912 04:00:07.798677 26285 net.cpp:434] conv2_2_scale <- conv2_2
I0912 04:00:07.798686 26285 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 04:00:07.798758 26285 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 04:00:07.798986 26285 net.cpp:150] Setting up conv2_2_scale
I0912 04:00:07.798997 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.799003 26285 net.cpp:165] Memory required for data: 2153779200
I0912 04:00:07.799013 26285 layer_factory.hpp:77] Creating layer relu2_2
I0912 04:00:07.799026 26285 net.cpp:100] Creating Layer relu2_2
I0912 04:00:07.799033 26285 net.cpp:434] relu2_2 <- conv2_2
I0912 04:00:07.799046 26285 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 04:00:07.799288 26285 net.cpp:150] Setting up relu2_2
I0912 04:00:07.799301 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:07.799307 26285 net.cpp:165] Memory required for data: 2242252800
I0912 04:00:07.799314 26285 layer_factory.hpp:77] Creating layer pool2
I0912 04:00:07.799320 26285 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 04:00:07.799335 26285 net.cpp:100] Creating Layer pool2
I0912 04:00:07.799341 26285 net.cpp:434] pool2 <- conv2_2
I0912 04:00:07.799350 26285 net.cpp:408] pool2 -> pool2
I0912 04:00:07.799362 26285 net.cpp:408] pool2 -> pool2_mask
I0912 04:00:07.799427 26285 net.cpp:150] Setting up pool2
I0912 04:00:07.799438 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:07.799446 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:07.799453 26285 net.cpp:165] Memory required for data: 2286489600
I0912 04:00:07.799458 26285 layer_factory.hpp:77] Creating layer conv3_1
I0912 04:00:07.799479 26285 net.cpp:100] Creating Layer conv3_1
I0912 04:00:07.799484 26285 net.cpp:434] conv3_1 <- pool2
I0912 04:00:07.799497 26285 net.cpp:408] conv3_1 -> conv3_1
I0912 04:00:07.812031 26285 net.cpp:150] Setting up conv3_1
I0912 04:00:07.812049 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.812055 26285 net.cpp:165] Memory required for data: 2330726400
I0912 04:00:07.812068 26285 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 04:00:07.812093 26285 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 04:00:07.812103 26285 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 04:00:07.812111 26285 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 04:00:07.812417 26285 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 04:00:07.812428 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.812434 26285 net.cpp:165] Memory required for data: 2374963200
I0912 04:00:07.812458 26285 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 04:00:07.812484 26285 net.cpp:100] Creating Layer conv3_1_scale
I0912 04:00:07.812494 26285 net.cpp:434] conv3_1_scale <- conv3_1
I0912 04:00:07.812503 26285 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 04:00:07.812568 26285 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 04:00:07.812762 26285 net.cpp:150] Setting up conv3_1_scale
I0912 04:00:07.812773 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.812779 26285 net.cpp:165] Memory required for data: 2419200000
I0912 04:00:07.812791 26285 layer_factory.hpp:77] Creating layer relu3_1
I0912 04:00:07.812806 26285 net.cpp:100] Creating Layer relu3_1
I0912 04:00:07.812813 26285 net.cpp:434] relu3_1 <- conv3_1
I0912 04:00:07.812820 26285 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 04:00:07.813064 26285 net.cpp:150] Setting up relu3_1
I0912 04:00:07.813077 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.813083 26285 net.cpp:165] Memory required for data: 2463436800
I0912 04:00:07.813088 26285 layer_factory.hpp:77] Creating layer conv3_2
I0912 04:00:07.813110 26285 net.cpp:100] Creating Layer conv3_2
I0912 04:00:07.813117 26285 net.cpp:434] conv3_2 <- conv3_1
I0912 04:00:07.813127 26285 net.cpp:408] conv3_2 -> conv3_2
I0912 04:00:07.836702 26285 net.cpp:150] Setting up conv3_2
I0912 04:00:07.836721 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.836729 26285 net.cpp:165] Memory required for data: 2507673600
I0912 04:00:07.836743 26285 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 04:00:07.836765 26285 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 04:00:07.836774 26285 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 04:00:07.836783 26285 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 04:00:07.837090 26285 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 04:00:07.837101 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.837107 26285 net.cpp:165] Memory required for data: 2551910400
I0912 04:00:07.837121 26285 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 04:00:07.837138 26285 net.cpp:100] Creating Layer conv3_2_scale
I0912 04:00:07.837147 26285 net.cpp:434] conv3_2_scale <- conv3_2
I0912 04:00:07.837157 26285 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 04:00:07.837224 26285 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 04:00:07.837427 26285 net.cpp:150] Setting up conv3_2_scale
I0912 04:00:07.837438 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.837445 26285 net.cpp:165] Memory required for data: 2596147200
I0912 04:00:07.837455 26285 layer_factory.hpp:77] Creating layer relu3_2
I0912 04:00:07.837466 26285 net.cpp:100] Creating Layer relu3_2
I0912 04:00:07.837472 26285 net.cpp:434] relu3_2 <- conv3_2
I0912 04:00:07.837483 26285 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 04:00:07.837724 26285 net.cpp:150] Setting up relu3_2
I0912 04:00:07.837736 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.837743 26285 net.cpp:165] Memory required for data: 2640384000
I0912 04:00:07.837748 26285 layer_factory.hpp:77] Creating layer conv3_3
I0912 04:00:07.837767 26285 net.cpp:100] Creating Layer conv3_3
I0912 04:00:07.837774 26285 net.cpp:434] conv3_3 <- conv3_2
I0912 04:00:07.837786 26285 net.cpp:408] conv3_3 -> conv3_3
I0912 04:00:07.861349 26285 net.cpp:150] Setting up conv3_3
I0912 04:00:07.861374 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.861382 26285 net.cpp:165] Memory required for data: 2684620800
I0912 04:00:07.861393 26285 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 04:00:07.861407 26285 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 04:00:07.861428 26285 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 04:00:07.861436 26285 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 04:00:07.861735 26285 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 04:00:07.861747 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.861752 26285 net.cpp:165] Memory required for data: 2728857600
I0912 04:00:07.861768 26285 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 04:00:07.861793 26285 net.cpp:100] Creating Layer conv3_3_scale
I0912 04:00:07.861805 26285 net.cpp:434] conv3_3_scale <- conv3_3
I0912 04:00:07.861814 26285 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 04:00:07.861883 26285 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 04:00:07.862073 26285 net.cpp:150] Setting up conv3_3_scale
I0912 04:00:07.862084 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.862090 26285 net.cpp:165] Memory required for data: 2773094400
I0912 04:00:07.862100 26285 layer_factory.hpp:77] Creating layer relu3_3
I0912 04:00:07.862116 26285 net.cpp:100] Creating Layer relu3_3
I0912 04:00:07.862121 26285 net.cpp:434] relu3_3 <- conv3_3
I0912 04:00:07.862129 26285 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 04:00:07.862372 26285 net.cpp:150] Setting up relu3_3
I0912 04:00:07.862385 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:07.862396 26285 net.cpp:165] Memory required for data: 2817331200
I0912 04:00:07.862401 26285 layer_factory.hpp:77] Creating layer pool3
I0912 04:00:07.862409 26285 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 04:00:07.862421 26285 net.cpp:100] Creating Layer pool3
I0912 04:00:07.862427 26285 net.cpp:434] pool3 <- conv3_3
I0912 04:00:07.862439 26285 net.cpp:408] pool3 -> pool3
I0912 04:00:07.862450 26285 net.cpp:408] pool3 -> pool3_mask
I0912 04:00:07.862515 26285 net.cpp:150] Setting up pool3
I0912 04:00:07.862525 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:07.862537 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:07.862542 26285 net.cpp:165] Memory required for data: 2839449600
I0912 04:00:07.862548 26285 layer_factory.hpp:77] Creating layer conv4_1
I0912 04:00:07.862565 26285 net.cpp:100] Creating Layer conv4_1
I0912 04:00:07.862570 26285 net.cpp:434] conv4_1 <- pool3
I0912 04:00:07.862579 26285 net.cpp:408] conv4_1 -> conv4_1
I0912 04:00:07.906476 26285 net.cpp:150] Setting up conv4_1
I0912 04:00:07.906496 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.906502 26285 net.cpp:165] Memory required for data: 2861568000
I0912 04:00:07.906517 26285 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 04:00:07.906538 26285 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 04:00:07.906548 26285 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 04:00:07.906559 26285 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 04:00:07.906853 26285 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 04:00:07.906865 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.906872 26285 net.cpp:165] Memory required for data: 2883686400
I0912 04:00:07.906883 26285 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 04:00:07.906899 26285 net.cpp:100] Creating Layer conv4_1_scale
I0912 04:00:07.906910 26285 net.cpp:434] conv4_1_scale <- conv4_1
I0912 04:00:07.906919 26285 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 04:00:07.906976 26285 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 04:00:07.907158 26285 net.cpp:150] Setting up conv4_1_scale
I0912 04:00:07.907169 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.907174 26285 net.cpp:165] Memory required for data: 2905804800
I0912 04:00:07.907186 26285 layer_factory.hpp:77] Creating layer relu4_1
I0912 04:00:07.907194 26285 net.cpp:100] Creating Layer relu4_1
I0912 04:00:07.907202 26285 net.cpp:434] relu4_1 <- conv4_1
I0912 04:00:07.907215 26285 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 04:00:07.908373 26285 net.cpp:150] Setting up relu4_1
I0912 04:00:07.908390 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.908396 26285 net.cpp:165] Memory required for data: 2927923200
I0912 04:00:07.908402 26285 layer_factory.hpp:77] Creating layer conv4_2
I0912 04:00:07.908421 26285 net.cpp:100] Creating Layer conv4_2
I0912 04:00:07.908427 26285 net.cpp:434] conv4_2 <- conv4_1
I0912 04:00:07.908438 26285 net.cpp:408] conv4_2 -> conv4_2
I0912 04:00:07.991592 26285 net.cpp:150] Setting up conv4_2
I0912 04:00:07.991624 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.991631 26285 net.cpp:165] Memory required for data: 2950041600
I0912 04:00:07.991644 26285 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 04:00:07.991657 26285 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 04:00:07.991675 26285 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 04:00:07.991685 26285 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 04:00:07.991976 26285 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 04:00:07.991986 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.991992 26285 net.cpp:165] Memory required for data: 2972160000
I0912 04:00:07.992005 26285 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 04:00:07.992020 26285 net.cpp:100] Creating Layer conv4_2_scale
I0912 04:00:07.992032 26285 net.cpp:434] conv4_2_scale <- conv4_2
I0912 04:00:07.992040 26285 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 04:00:07.992107 26285 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 04:00:07.992286 26285 net.cpp:150] Setting up conv4_2_scale
I0912 04:00:07.992297 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.992302 26285 net.cpp:165] Memory required for data: 2994278400
I0912 04:00:07.992313 26285 layer_factory.hpp:77] Creating layer relu4_2
I0912 04:00:07.992323 26285 net.cpp:100] Creating Layer relu4_2
I0912 04:00:07.992329 26285 net.cpp:434] relu4_2 <- conv4_2
I0912 04:00:07.992341 26285 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 04:00:07.993512 26285 net.cpp:150] Setting up relu4_2
I0912 04:00:07.993532 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:07.993538 26285 net.cpp:165] Memory required for data: 3016396800
I0912 04:00:07.993546 26285 layer_factory.hpp:77] Creating layer conv4_3
I0912 04:00:07.993562 26285 net.cpp:100] Creating Layer conv4_3
I0912 04:00:07.993569 26285 net.cpp:434] conv4_3 <- conv4_2
I0912 04:00:07.993580 26285 net.cpp:408] conv4_3 -> conv4_3
I0912 04:00:08.077230 26285 net.cpp:150] Setting up conv4_3
I0912 04:00:08.077250 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.077256 26285 net.cpp:165] Memory required for data: 3038515200
I0912 04:00:08.077288 26285 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 04:00:08.077302 26285 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 04:00:08.077316 26285 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 04:00:08.077334 26285 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 04:00:08.077633 26285 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 04:00:08.077646 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.077651 26285 net.cpp:165] Memory required for data: 3060633600
I0912 04:00:08.077664 26285 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 04:00:08.077678 26285 net.cpp:100] Creating Layer conv4_3_scale
I0912 04:00:08.077685 26285 net.cpp:434] conv4_3_scale <- conv4_3
I0912 04:00:08.077697 26285 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 04:00:08.077754 26285 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 04:00:08.077929 26285 net.cpp:150] Setting up conv4_3_scale
I0912 04:00:08.077939 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.077945 26285 net.cpp:165] Memory required for data: 3082752000
I0912 04:00:08.077955 26285 layer_factory.hpp:77] Creating layer relu4_3
I0912 04:00:08.077968 26285 net.cpp:100] Creating Layer relu4_3
I0912 04:00:08.077975 26285 net.cpp:434] relu4_3 <- conv4_3
I0912 04:00:08.077982 26285 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 04:00:08.078217 26285 net.cpp:150] Setting up relu4_3
I0912 04:00:08.078230 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.078238 26285 net.cpp:165] Memory required for data: 3104870400
I0912 04:00:08.078243 26285 layer_factory.hpp:77] Creating layer pool4
I0912 04:00:08.078253 26285 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 04:00:08.078263 26285 net.cpp:100] Creating Layer pool4
I0912 04:00:08.078269 26285 net.cpp:434] pool4 <- conv4_3
I0912 04:00:08.078292 26285 net.cpp:408] pool4 -> pool4
I0912 04:00:08.078308 26285 net.cpp:408] pool4 -> pool4_mask
I0912 04:00:08.078373 26285 net.cpp:150] Setting up pool4
I0912 04:00:08.078383 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.078392 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.078397 26285 net.cpp:165] Memory required for data: 3116175360
I0912 04:00:08.078404 26285 layer_factory.hpp:77] Creating layer conv5_1
I0912 04:00:08.078425 26285 net.cpp:100] Creating Layer conv5_1
I0912 04:00:08.078431 26285 net.cpp:434] conv5_1 <- pool4
I0912 04:00:08.078441 26285 net.cpp:408] conv5_1 -> conv5_1
I0912 04:00:08.162060 26285 net.cpp:150] Setting up conv5_1
I0912 04:00:08.162081 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.162086 26285 net.cpp:165] Memory required for data: 3121827840
I0912 04:00:08.162097 26285 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 04:00:08.162127 26285 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 04:00:08.162137 26285 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 04:00:08.162145 26285 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 04:00:08.162449 26285 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 04:00:08.162461 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.162467 26285 net.cpp:165] Memory required for data: 3127480320
I0912 04:00:08.162482 26285 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 04:00:08.162493 26285 net.cpp:100] Creating Layer conv5_1_scale
I0912 04:00:08.162506 26285 net.cpp:434] conv5_1_scale <- conv5_1
I0912 04:00:08.162514 26285 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 04:00:08.162580 26285 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 04:00:08.162746 26285 net.cpp:150] Setting up conv5_1_scale
I0912 04:00:08.162756 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.162761 26285 net.cpp:165] Memory required for data: 3133132800
I0912 04:00:08.162772 26285 layer_factory.hpp:77] Creating layer relu5_1
I0912 04:00:08.162786 26285 net.cpp:100] Creating Layer relu5_1
I0912 04:00:08.162791 26285 net.cpp:434] relu5_1 <- conv5_1
I0912 04:00:08.162799 26285 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 04:00:08.163029 26285 net.cpp:150] Setting up relu5_1
I0912 04:00:08.163043 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.163048 26285 net.cpp:165] Memory required for data: 3138785280
I0912 04:00:08.163055 26285 layer_factory.hpp:77] Creating layer conv5_2
I0912 04:00:08.163074 26285 net.cpp:100] Creating Layer conv5_2
I0912 04:00:08.163080 26285 net.cpp:434] conv5_2 <- conv5_1
I0912 04:00:08.163091 26285 net.cpp:408] conv5_2 -> conv5_2
I0912 04:00:08.246722 26285 net.cpp:150] Setting up conv5_2
I0912 04:00:08.246742 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.246747 26285 net.cpp:165] Memory required for data: 3144437760
I0912 04:00:08.246759 26285 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 04:00:08.246783 26285 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 04:00:08.246798 26285 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 04:00:08.246809 26285 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 04:00:08.247102 26285 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 04:00:08.247112 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.247118 26285 net.cpp:165] Memory required for data: 3150090240
I0912 04:00:08.247131 26285 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 04:00:08.247143 26285 net.cpp:100] Creating Layer conv5_2_scale
I0912 04:00:08.247158 26285 net.cpp:434] conv5_2_scale <- conv5_2
I0912 04:00:08.247165 26285 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 04:00:08.247232 26285 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 04:00:08.247401 26285 net.cpp:150] Setting up conv5_2_scale
I0912 04:00:08.247412 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.247417 26285 net.cpp:165] Memory required for data: 3155742720
I0912 04:00:08.247427 26285 layer_factory.hpp:77] Creating layer relu5_2
I0912 04:00:08.247452 26285 net.cpp:100] Creating Layer relu5_2
I0912 04:00:08.247462 26285 net.cpp:434] relu5_2 <- conv5_2
I0912 04:00:08.247470 26285 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 04:00:08.247706 26285 net.cpp:150] Setting up relu5_2
I0912 04:00:08.247719 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.247725 26285 net.cpp:165] Memory required for data: 3161395200
I0912 04:00:08.247732 26285 layer_factory.hpp:77] Creating layer conv5_3
I0912 04:00:08.247750 26285 net.cpp:100] Creating Layer conv5_3
I0912 04:00:08.247756 26285 net.cpp:434] conv5_3 <- conv5_2
I0912 04:00:08.247769 26285 net.cpp:408] conv5_3 -> conv5_3
I0912 04:00:08.331475 26285 net.cpp:150] Setting up conv5_3
I0912 04:00:08.331493 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.331499 26285 net.cpp:165] Memory required for data: 3167047680
I0912 04:00:08.331511 26285 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 04:00:08.331537 26285 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 04:00:08.331547 26285 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 04:00:08.331565 26285 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 04:00:08.331864 26285 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 04:00:08.331876 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.331881 26285 net.cpp:165] Memory required for data: 3172700160
I0912 04:00:08.331894 26285 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 04:00:08.331907 26285 net.cpp:100] Creating Layer conv5_3_scale
I0912 04:00:08.331915 26285 net.cpp:434] conv5_3_scale <- conv5_3
I0912 04:00:08.331928 26285 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 04:00:08.331990 26285 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 04:00:08.332157 26285 net.cpp:150] Setting up conv5_3_scale
I0912 04:00:08.332170 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.332177 26285 net.cpp:165] Memory required for data: 3178352640
I0912 04:00:08.332188 26285 layer_factory.hpp:77] Creating layer relu5_3
I0912 04:00:08.332198 26285 net.cpp:100] Creating Layer relu5_3
I0912 04:00:08.332206 26285 net.cpp:434] relu5_3 <- conv5_3
I0912 04:00:08.332213 26285 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 04:00:08.332444 26285 net.cpp:150] Setting up relu5_3
I0912 04:00:08.332459 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.332464 26285 net.cpp:165] Memory required for data: 3184005120
I0912 04:00:08.332474 26285 layer_factory.hpp:77] Creating layer pool5
I0912 04:00:08.332482 26285 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 04:00:08.332492 26285 net.cpp:100] Creating Layer pool5
I0912 04:00:08.332499 26285 net.cpp:434] pool5 <- conv5_3
I0912 04:00:08.332507 26285 net.cpp:408] pool5 -> pool5
I0912 04:00:08.332521 26285 net.cpp:408] pool5 -> pool5_mask
I0912 04:00:08.332587 26285 net.cpp:150] Setting up pool5
I0912 04:00:08.332597 26285 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 04:00:08.332607 26285 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 04:00:08.332613 26285 net.cpp:165] Memory required for data: 3186954240
I0912 04:00:08.332619 26285 layer_factory.hpp:77] Creating layer upsample5
I0912 04:00:08.332633 26285 net.cpp:100] Creating Layer upsample5
I0912 04:00:08.332639 26285 net.cpp:434] upsample5 <- pool5
I0912 04:00:08.332646 26285 net.cpp:434] upsample5 <- pool5_mask
I0912 04:00:08.332656 26285 net.cpp:408] upsample5 -> pool5_D
I0912 04:00:08.332698 26285 net.cpp:150] Setting up upsample5
I0912 04:00:08.332708 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.332713 26285 net.cpp:165] Memory required for data: 3192606720
I0912 04:00:08.332718 26285 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 04:00:08.332736 26285 net.cpp:100] Creating Layer conv5_3_D
I0912 04:00:08.332742 26285 net.cpp:434] conv5_3_D <- pool5_D
I0912 04:00:08.332754 26285 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 04:00:08.416406 26285 net.cpp:150] Setting up conv5_3_D
I0912 04:00:08.416426 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.416465 26285 net.cpp:165] Memory required for data: 3198259200
I0912 04:00:08.416477 26285 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 04:00:08.416499 26285 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 04:00:08.416507 26285 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 04:00:08.416517 26285 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 04:00:08.416821 26285 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 04:00:08.416833 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.416838 26285 net.cpp:165] Memory required for data: 3203911680
I0912 04:00:08.416856 26285 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 04:00:08.416867 26285 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 04:00:08.416873 26285 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 04:00:08.416882 26285 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 04:00:08.416950 26285 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 04:00:08.417121 26285 net.cpp:150] Setting up conv5_3_D_scale
I0912 04:00:08.417132 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.417137 26285 net.cpp:165] Memory required for data: 3209564160
I0912 04:00:08.417148 26285 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 04:00:08.417160 26285 net.cpp:100] Creating Layer relu5_3_D
I0912 04:00:08.417167 26285 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 04:00:08.417174 26285 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 04:00:08.418339 26285 net.cpp:150] Setting up relu5_3_D
I0912 04:00:08.418359 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.418365 26285 net.cpp:165] Memory required for data: 3215216640
I0912 04:00:08.418372 26285 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 04:00:08.418400 26285 net.cpp:100] Creating Layer conv5_2_D
I0912 04:00:08.418407 26285 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 04:00:08.418418 26285 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 04:00:08.502089 26285 net.cpp:150] Setting up conv5_2_D
I0912 04:00:08.502109 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.502115 26285 net.cpp:165] Memory required for data: 3220869120
I0912 04:00:08.502131 26285 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 04:00:08.502148 26285 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 04:00:08.502162 26285 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 04:00:08.502171 26285 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 04:00:08.502481 26285 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 04:00:08.502493 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.502498 26285 net.cpp:165] Memory required for data: 3226521600
I0912 04:00:08.502511 26285 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 04:00:08.502524 26285 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 04:00:08.502538 26285 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 04:00:08.502547 26285 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 04:00:08.502616 26285 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 04:00:08.502787 26285 net.cpp:150] Setting up conv5_2_D_scale
I0912 04:00:08.502799 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.502804 26285 net.cpp:165] Memory required for data: 3232174080
I0912 04:00:08.502815 26285 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 04:00:08.502830 26285 net.cpp:100] Creating Layer relu5_2_D
I0912 04:00:08.502836 26285 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 04:00:08.502851 26285 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 04:00:08.504019 26285 net.cpp:150] Setting up relu5_2_D
I0912 04:00:08.504035 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.504042 26285 net.cpp:165] Memory required for data: 3237826560
I0912 04:00:08.504048 26285 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 04:00:08.504067 26285 net.cpp:100] Creating Layer conv5_1_D
I0912 04:00:08.504075 26285 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 04:00:08.504088 26285 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 04:00:08.587754 26285 net.cpp:150] Setting up conv5_1_D
I0912 04:00:08.587774 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.587779 26285 net.cpp:165] Memory required for data: 3243479040
I0912 04:00:08.587791 26285 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 04:00:08.587817 26285 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 04:00:08.587828 26285 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 04:00:08.587837 26285 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 04:00:08.588141 26285 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 04:00:08.588152 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.588158 26285 net.cpp:165] Memory required for data: 3249131520
I0912 04:00:08.588171 26285 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 04:00:08.588191 26285 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 04:00:08.588198 26285 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 04:00:08.588207 26285 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 04:00:08.588275 26285 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 04:00:08.588450 26285 net.cpp:150] Setting up conv5_1_D_scale
I0912 04:00:08.588461 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.588466 26285 net.cpp:165] Memory required for data: 3254784000
I0912 04:00:08.588477 26285 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 04:00:08.588490 26285 net.cpp:100] Creating Layer relu5_1_D
I0912 04:00:08.588496 26285 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 04:00:08.588505 26285 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 04:00:08.588739 26285 net.cpp:150] Setting up relu5_1_D
I0912 04:00:08.588752 26285 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 04:00:08.588757 26285 net.cpp:165] Memory required for data: 3260436480
I0912 04:00:08.588763 26285 layer_factory.hpp:77] Creating layer upsample4
I0912 04:00:08.588778 26285 net.cpp:100] Creating Layer upsample4
I0912 04:00:08.588783 26285 net.cpp:434] upsample4 <- conv5_1_D
I0912 04:00:08.588790 26285 net.cpp:434] upsample4 <- pool4_mask
I0912 04:00:08.588800 26285 net.cpp:408] upsample4 -> pool4_D
I0912 04:00:08.588850 26285 net.cpp:150] Setting up upsample4
I0912 04:00:08.588860 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.588865 26285 net.cpp:165] Memory required for data: 3282554880
I0912 04:00:08.588874 26285 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 04:00:08.588892 26285 net.cpp:100] Creating Layer conv4_3_D
I0912 04:00:08.588898 26285 net.cpp:434] conv4_3_D <- pool4_D
I0912 04:00:08.588912 26285 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 04:00:08.673323 26285 net.cpp:150] Setting up conv4_3_D
I0912 04:00:08.673349 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.673357 26285 net.cpp:165] Memory required for data: 3304673280
I0912 04:00:08.673384 26285 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 04:00:08.673405 26285 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 04:00:08.673424 26285 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 04:00:08.673449 26285 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 04:00:08.673758 26285 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 04:00:08.673770 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.673776 26285 net.cpp:165] Memory required for data: 3326791680
I0912 04:00:08.673789 26285 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 04:00:08.673804 26285 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 04:00:08.673811 26285 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 04:00:08.673820 26285 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 04:00:08.673882 26285 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 04:00:08.674069 26285 net.cpp:150] Setting up conv4_3_D_scale
I0912 04:00:08.674080 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.674085 26285 net.cpp:165] Memory required for data: 3348910080
I0912 04:00:08.674096 26285 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 04:00:08.674126 26285 net.cpp:100] Creating Layer relu4_3_D
I0912 04:00:08.674132 26285 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 04:00:08.674140 26285 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 04:00:08.674381 26285 net.cpp:150] Setting up relu4_3_D
I0912 04:00:08.674396 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.674401 26285 net.cpp:165] Memory required for data: 3371028480
I0912 04:00:08.674412 26285 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 04:00:08.674428 26285 net.cpp:100] Creating Layer conv4_2_D
I0912 04:00:08.674434 26285 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 04:00:08.674446 26285 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 04:00:08.758203 26285 net.cpp:150] Setting up conv4_2_D
I0912 04:00:08.758224 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.758229 26285 net.cpp:165] Memory required for data: 3393146880
I0912 04:00:08.758241 26285 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 04:00:08.758268 26285 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 04:00:08.758280 26285 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 04:00:08.758289 26285 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 04:00:08.758615 26285 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 04:00:08.758626 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.758632 26285 net.cpp:165] Memory required for data: 3415265280
I0912 04:00:08.758646 26285 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 04:00:08.758659 26285 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 04:00:08.758672 26285 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 04:00:08.758684 26285 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 04:00:08.758746 26285 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 04:00:08.758936 26285 net.cpp:150] Setting up conv4_2_D_scale
I0912 04:00:08.758946 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.758952 26285 net.cpp:165] Memory required for data: 3437383680
I0912 04:00:08.758962 26285 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 04:00:08.758972 26285 net.cpp:100] Creating Layer relu4_2_D
I0912 04:00:08.758980 26285 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 04:00:08.758987 26285 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 04:00:08.759227 26285 net.cpp:150] Setting up relu4_2_D
I0912 04:00:08.759238 26285 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 04:00:08.759244 26285 net.cpp:165] Memory required for data: 3459502080
I0912 04:00:08.759251 26285 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 04:00:08.759270 26285 net.cpp:100] Creating Layer conv4_1_D
I0912 04:00:08.759276 26285 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 04:00:08.759289 26285 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 04:00:08.803278 26285 net.cpp:150] Setting up conv4_1_D
I0912 04:00:08.803298 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:08.803304 26285 net.cpp:165] Memory required for data: 3470561280
I0912 04:00:08.803318 26285 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 04:00:08.803340 26285 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 04:00:08.803351 26285 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 04:00:08.803361 26285 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 04:00:08.803688 26285 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 04:00:08.803699 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:08.803704 26285 net.cpp:165] Memory required for data: 3481620480
I0912 04:00:08.803788 26285 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 04:00:08.803799 26285 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 04:00:08.803815 26285 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 04:00:08.803828 26285 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 04:00:08.803899 26285 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 04:00:08.804090 26285 net.cpp:150] Setting up conv4_1_D_scale
I0912 04:00:08.804100 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:08.804121 26285 net.cpp:165] Memory required for data: 3492679680
I0912 04:00:08.804132 26285 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 04:00:08.804142 26285 net.cpp:100] Creating Layer relu4_1_D
I0912 04:00:08.804149 26285 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 04:00:08.804157 26285 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 04:00:08.804409 26285 net.cpp:150] Setting up relu4_1_D
I0912 04:00:08.804422 26285 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 04:00:08.804427 26285 net.cpp:165] Memory required for data: 3503738880
I0912 04:00:08.804433 26285 layer_factory.hpp:77] Creating layer upsample3
I0912 04:00:08.804448 26285 net.cpp:100] Creating Layer upsample3
I0912 04:00:08.804455 26285 net.cpp:434] upsample3 <- conv4_1_D
I0912 04:00:08.804466 26285 net.cpp:434] upsample3 <- pool3_mask
I0912 04:00:08.804477 26285 net.cpp:408] upsample3 -> pool3_D
I0912 04:00:08.804491 26285 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 04:00:08.804534 26285 net.cpp:150] Setting up upsample3
I0912 04:00:08.804544 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:08.804549 26285 net.cpp:165] Memory required for data: 3547975680
I0912 04:00:08.804556 26285 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 04:00:08.804574 26285 net.cpp:100] Creating Layer conv3_3_D
I0912 04:00:08.804580 26285 net.cpp:434] conv3_3_D <- pool3_D
I0912 04:00:08.804594 26285 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 04:00:08.828332 26285 net.cpp:150] Setting up conv3_3_D
I0912 04:00:08.828351 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:08.828358 26285 net.cpp:165] Memory required for data: 3592212480
I0912 04:00:08.828373 26285 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 04:00:08.828390 26285 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 04:00:08.828404 26285 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 04:00:08.828413 26285 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 04:00:08.828748 26285 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 04:00:08.828760 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:08.828766 26285 net.cpp:165] Memory required for data: 3636449280
I0912 04:00:08.828779 26285 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 04:00:08.828795 26285 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 04:00:08.828806 26285 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 04:00:08.828814 26285 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 04:00:08.828883 26285 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 04:00:08.829092 26285 net.cpp:150] Setting up conv3_3_D_scale
I0912 04:00:08.829103 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:08.829109 26285 net.cpp:165] Memory required for data: 3680686080
I0912 04:00:08.829119 26285 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 04:00:08.829130 26285 net.cpp:100] Creating Layer relu3_3_D
I0912 04:00:08.829138 26285 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 04:00:08.829147 26285 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 04:00:08.830348 26285 net.cpp:150] Setting up relu3_3_D
I0912 04:00:08.830366 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:08.830373 26285 net.cpp:165] Memory required for data: 3724922880
I0912 04:00:08.830379 26285 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 04:00:08.830397 26285 net.cpp:100] Creating Layer conv3_2_D
I0912 04:00:08.830404 26285 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 04:00:08.830417 26285 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 04:00:08.853257 26285 net.cpp:150] Setting up conv3_2_D
I0912 04:00:08.853276 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:08.853281 26285 net.cpp:165] Memory required for data: 3769159680
I0912 04:00:08.853294 26285 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 04:00:08.853317 26285 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 04:00:08.853327 26285 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 04:00:08.853355 26285 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 04:00:08.853694 26285 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 04:00:08.853708 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:08.853713 26285 net.cpp:165] Memory required for data: 3813396480
I0912 04:00:08.853726 26285 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 04:00:08.853747 26285 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 04:00:08.853755 26285 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 04:00:08.853763 26285 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 04:00:08.853830 26285 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 04:00:08.854038 26285 net.cpp:150] Setting up conv3_2_D_scale
I0912 04:00:08.854049 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:08.854055 26285 net.cpp:165] Memory required for data: 3857633280
I0912 04:00:08.854068 26285 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 04:00:08.854079 26285 net.cpp:100] Creating Layer relu3_2_D
I0912 04:00:08.854085 26285 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 04:00:08.854094 26285 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 04:00:08.855279 26285 net.cpp:150] Setting up relu3_2_D
I0912 04:00:08.855295 26285 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 04:00:08.855301 26285 net.cpp:165] Memory required for data: 3901870080
I0912 04:00:08.855307 26285 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 04:00:08.855325 26285 net.cpp:100] Creating Layer conv3_1_D
I0912 04:00:08.855332 26285 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 04:00:08.855347 26285 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 04:00:08.869289 26285 net.cpp:150] Setting up conv3_1_D
I0912 04:00:08.869307 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:08.869314 26285 net.cpp:165] Memory required for data: 3923988480
I0912 04:00:08.869326 26285 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 04:00:08.869351 26285 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 04:00:08.869362 26285 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 04:00:08.869382 26285 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 04:00:08.869720 26285 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 04:00:08.869734 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:08.869740 26285 net.cpp:165] Memory required for data: 3946106880
I0912 04:00:08.869752 26285 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 04:00:08.869776 26285 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 04:00:08.869786 26285 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 04:00:08.869796 26285 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 04:00:08.869863 26285 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 04:00:08.871341 26285 net.cpp:150] Setting up conv3_1_D_scale
I0912 04:00:08.871358 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:08.871364 26285 net.cpp:165] Memory required for data: 3968225280
I0912 04:00:08.871378 26285 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 04:00:08.871400 26285 net.cpp:100] Creating Layer relu3_1_D
I0912 04:00:08.871407 26285 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 04:00:08.871417 26285 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 04:00:08.871680 26285 net.cpp:150] Setting up relu3_1_D
I0912 04:00:08.871691 26285 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 04:00:08.871697 26285 net.cpp:165] Memory required for data: 3990343680
I0912 04:00:08.871703 26285 layer_factory.hpp:77] Creating layer upsample2
I0912 04:00:08.871717 26285 net.cpp:100] Creating Layer upsample2
I0912 04:00:08.871723 26285 net.cpp:434] upsample2 <- conv3_1_D
I0912 04:00:08.871731 26285 net.cpp:434] upsample2 <- pool2_mask
I0912 04:00:08.871744 26285 net.cpp:408] upsample2 -> pool2_D
I0912 04:00:08.871757 26285 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 04:00:08.871803 26285 net.cpp:150] Setting up upsample2
I0912 04:00:08.871826 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:08.871834 26285 net.cpp:165] Memory required for data: 4078817280
I0912 04:00:08.871840 26285 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 04:00:08.871856 26285 net.cpp:100] Creating Layer conv2_2_D
I0912 04:00:08.871863 26285 net.cpp:434] conv2_2_D <- pool2_D
I0912 04:00:08.871873 26285 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 04:00:08.879828 26285 net.cpp:150] Setting up conv2_2_D
I0912 04:00:08.879847 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:08.879853 26285 net.cpp:165] Memory required for data: 4167290880
I0912 04:00:08.879865 26285 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 04:00:08.879889 26285 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 04:00:08.879899 26285 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 04:00:08.879907 26285 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 04:00:08.880267 26285 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 04:00:08.880280 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:08.880285 26285 net.cpp:165] Memory required for data: 4255764480
I0912 04:00:08.880302 26285 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 04:00:08.880316 26285 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 04:00:08.880327 26285 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 04:00:08.880336 26285 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 04:00:08.880409 26285 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 04:00:08.880683 26285 net.cpp:150] Setting up conv2_2_D_scale
I0912 04:00:08.880695 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:08.880702 26285 net.cpp:165] Memory required for data: 4344238080
I0912 04:00:08.880712 26285 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 04:00:08.880728 26285 net.cpp:100] Creating Layer relu2_2_D
I0912 04:00:08.880733 26285 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 04:00:08.880743 26285 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 04:00:08.880996 26285 net.cpp:150] Setting up relu2_2_D
I0912 04:00:08.881008 26285 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 04:00:08.881014 26285 net.cpp:165] Memory required for data: 4432711680
I0912 04:00:08.881019 26285 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 04:00:08.881037 26285 net.cpp:100] Creating Layer conv2_1_D
I0912 04:00:08.881043 26285 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 04:00:08.881055 26285 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 04:00:08.886598 26285 net.cpp:150] Setting up conv2_1_D
I0912 04:00:08.886616 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:08.886623 26285 net.cpp:165] Memory required for data: 4476948480
I0912 04:00:08.886636 26285 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 04:00:08.886660 26285 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 04:00:08.886669 26285 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 04:00:08.886678 26285 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 04:00:08.887065 26285 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 04:00:08.887078 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:08.887082 26285 net.cpp:165] Memory required for data: 4521185280
I0912 04:00:08.887097 26285 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 04:00:08.887114 26285 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 04:00:08.887120 26285 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 04:00:08.887128 26285 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 04:00:08.887198 26285 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 04:00:08.887486 26285 net.cpp:150] Setting up conv2_1_D_scale
I0912 04:00:08.887498 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:08.887503 26285 net.cpp:165] Memory required for data: 4565422080
I0912 04:00:08.887513 26285 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 04:00:08.887526 26285 net.cpp:100] Creating Layer relu2_1_D
I0912 04:00:08.887533 26285 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 04:00:08.887555 26285 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 04:00:08.887810 26285 net.cpp:150] Setting up relu2_1_D
I0912 04:00:08.887822 26285 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 04:00:08.887828 26285 net.cpp:165] Memory required for data: 4609658880
I0912 04:00:08.887835 26285 layer_factory.hpp:77] Creating layer upsample1
I0912 04:00:08.887846 26285 net.cpp:100] Creating Layer upsample1
I0912 04:00:08.887852 26285 net.cpp:434] upsample1 <- conv2_1_D
I0912 04:00:08.887861 26285 net.cpp:434] upsample1 <- pool1_mask
I0912 04:00:08.887876 26285 net.cpp:408] upsample1 -> pool1_D
I0912 04:00:08.887887 26285 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 04:00:08.887931 26285 net.cpp:150] Setting up upsample1
I0912 04:00:08.887941 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:08.887946 26285 net.cpp:165] Memory required for data: 4786606080
I0912 04:00:08.887953 26285 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 04:00:08.887971 26285 net.cpp:100] Creating Layer conv1_2_D
I0912 04:00:08.887977 26285 net.cpp:434] conv1_2_D <- pool1_D
I0912 04:00:08.887987 26285 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 04:00:08.892719 26285 net.cpp:150] Setting up conv1_2_D
I0912 04:00:08.892737 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:08.892745 26285 net.cpp:165] Memory required for data: 4963553280
I0912 04:00:08.892757 26285 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 04:00:08.892776 26285 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 04:00:08.892789 26285 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 04:00:08.892812 26285 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 04:00:08.893265 26285 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 04:00:08.893277 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:08.893283 26285 net.cpp:165] Memory required for data: 5140500480
I0912 04:00:08.893296 26285 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 04:00:08.893308 26285 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 04:00:08.893316 26285 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 04:00:08.893329 26285 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 04:00:08.893404 26285 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 04:00:08.895154 26285 net.cpp:150] Setting up conv1_2_D_scale
I0912 04:00:08.895171 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:08.895177 26285 net.cpp:165] Memory required for data: 5317447680
I0912 04:00:08.895189 26285 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 04:00:08.895203 26285 net.cpp:100] Creating Layer relu1_2_D
I0912 04:00:08.895210 26285 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 04:00:08.895220 26285 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 04:00:08.895480 26285 net.cpp:150] Setting up relu1_2_D
I0912 04:00:08.895493 26285 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 04:00:08.895498 26285 net.cpp:165] Memory required for data: 5494394880
I0912 04:00:08.895503 26285 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 04:00:08.895521 26285 net.cpp:100] Creating Layer conv1_1_1_D
I0912 04:00:08.895529 26285 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 04:00:08.895539 26285 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 04:00:08.897816 26285 net.cpp:150] Setting up conv1_1_1_D
I0912 04:00:08.897835 26285 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 04:00:08.897840 26285 net.cpp:165] Memory required for data: 5499924480
I0912 04:00:08.897852 26285 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 04:00:08.897867 26285 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 04:00:08.897874 26285 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 04:00:08.897886 26285 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 04:00:08.897898 26285 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 04:00:08.897980 26285 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 04:00:08.897992 26285 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 04:00:08.898000 26285 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 04:00:08.898006 26285 net.cpp:165] Memory required for data: 5510983680
I0912 04:00:08.898013 26285 layer_factory.hpp:77] Creating layer loss
I0912 04:00:08.898030 26285 net.cpp:100] Creating Layer loss
I0912 04:00:08.898036 26285 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 04:00:08.898044 26285 net.cpp:434] loss <- label_data_1_split_0
I0912 04:00:08.898053 26285 net.cpp:408] loss -> loss
I0912 04:00:08.898069 26285 layer_factory.hpp:77] Creating layer loss
I0912 04:00:08.902140 26285 net.cpp:150] Setting up loss
I0912 04:00:08.902158 26285 net.cpp:157] Top shape: (1)
I0912 04:00:08.902164 26285 net.cpp:160]     with loss weight 1
I0912 04:00:08.902189 26285 net.cpp:165] Memory required for data: 5510983684
I0912 04:00:08.902196 26285 layer_factory.hpp:77] Creating layer accuracy
I0912 04:00:08.902222 26285 net.cpp:100] Creating Layer accuracy
I0912 04:00:08.902230 26285 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 04:00:08.902238 26285 net.cpp:434] accuracy <- label_data_1_split_1
I0912 04:00:08.902248 26285 net.cpp:408] accuracy -> accuracy
I0912 04:00:08.902261 26285 net.cpp:408] accuracy -> per_class_accuracy
I0912 04:00:08.902326 26285 net.cpp:150] Setting up accuracy
I0912 04:00:08.902338 26285 net.cpp:157] Top shape: (1)
I0912 04:00:08.902344 26285 net.cpp:157] Top shape: 2 (2)
I0912 04:00:08.902350 26285 net.cpp:165] Memory required for data: 5510983696
I0912 04:00:08.902356 26285 net.cpp:228] accuracy does not need backward computation.
I0912 04:00:08.902364 26285 net.cpp:226] loss needs backward computation.
I0912 04:00:08.902371 26285 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 04:00:08.902377 26285 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 04:00:08.902384 26285 net.cpp:226] relu1_2_D needs backward computation.
I0912 04:00:08.902389 26285 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 04:00:08.902393 26285 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 04:00:08.902398 26285 net.cpp:226] conv1_2_D needs backward computation.
I0912 04:00:08.902405 26285 net.cpp:226] upsample1 needs backward computation.
I0912 04:00:08.902412 26285 net.cpp:226] relu2_1_D needs backward computation.
I0912 04:00:08.902418 26285 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 04:00:08.902425 26285 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 04:00:08.902429 26285 net.cpp:226] conv2_1_D needs backward computation.
I0912 04:00:08.902434 26285 net.cpp:226] relu2_2_D needs backward computation.
I0912 04:00:08.902439 26285 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 04:00:08.902444 26285 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 04:00:08.902449 26285 net.cpp:226] conv2_2_D needs backward computation.
I0912 04:00:08.902456 26285 net.cpp:226] upsample2 needs backward computation.
I0912 04:00:08.902462 26285 net.cpp:226] relu3_1_D needs backward computation.
I0912 04:00:08.902467 26285 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 04:00:08.902472 26285 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 04:00:08.902477 26285 net.cpp:226] conv3_1_D needs backward computation.
I0912 04:00:08.902482 26285 net.cpp:226] relu3_2_D needs backward computation.
I0912 04:00:08.902487 26285 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 04:00:08.902494 26285 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 04:00:08.902499 26285 net.cpp:226] conv3_2_D needs backward computation.
I0912 04:00:08.902504 26285 net.cpp:226] relu3_3_D needs backward computation.
I0912 04:00:08.902509 26285 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 04:00:08.902514 26285 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 04:00:08.902534 26285 net.cpp:226] conv3_3_D needs backward computation.
I0912 04:00:08.902540 26285 net.cpp:226] upsample3 needs backward computation.
I0912 04:00:08.902547 26285 net.cpp:226] relu4_1_D needs backward computation.
I0912 04:00:08.902552 26285 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 04:00:08.902559 26285 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 04:00:08.902565 26285 net.cpp:226] conv4_1_D needs backward computation.
I0912 04:00:08.902570 26285 net.cpp:226] relu4_2_D needs backward computation.
I0912 04:00:08.902575 26285 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 04:00:08.902582 26285 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 04:00:08.902587 26285 net.cpp:226] conv4_2_D needs backward computation.
I0912 04:00:08.902593 26285 net.cpp:226] relu4_3_D needs backward computation.
I0912 04:00:08.902598 26285 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 04:00:08.902603 26285 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 04:00:08.902609 26285 net.cpp:226] conv4_3_D needs backward computation.
I0912 04:00:08.902616 26285 net.cpp:226] upsample4 needs backward computation.
I0912 04:00:08.902622 26285 net.cpp:226] relu5_1_D needs backward computation.
I0912 04:00:08.902629 26285 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 04:00:08.902634 26285 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 04:00:08.902642 26285 net.cpp:226] conv5_1_D needs backward computation.
I0912 04:00:08.902648 26285 net.cpp:226] relu5_2_D needs backward computation.
I0912 04:00:08.902653 26285 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 04:00:08.902662 26285 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 04:00:08.902667 26285 net.cpp:226] conv5_2_D needs backward computation.
I0912 04:00:08.902673 26285 net.cpp:226] relu5_3_D needs backward computation.
I0912 04:00:08.902680 26285 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 04:00:08.902686 26285 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 04:00:08.902693 26285 net.cpp:226] conv5_3_D needs backward computation.
I0912 04:00:08.902698 26285 net.cpp:226] upsample5 needs backward computation.
I0912 04:00:08.902706 26285 net.cpp:226] pool5 needs backward computation.
I0912 04:00:08.902715 26285 net.cpp:226] relu5_3 needs backward computation.
I0912 04:00:08.902722 26285 net.cpp:226] conv5_3_scale needs backward computation.
I0912 04:00:08.902727 26285 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 04:00:08.902734 26285 net.cpp:226] conv5_3 needs backward computation.
I0912 04:00:08.902743 26285 net.cpp:226] relu5_2 needs backward computation.
I0912 04:00:08.902750 26285 net.cpp:226] conv5_2_scale needs backward computation.
I0912 04:00:08.902755 26285 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 04:00:08.902762 26285 net.cpp:226] conv5_2 needs backward computation.
I0912 04:00:08.902770 26285 net.cpp:226] relu5_1 needs backward computation.
I0912 04:00:08.902776 26285 net.cpp:226] conv5_1_scale needs backward computation.
I0912 04:00:08.902781 26285 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 04:00:08.902788 26285 net.cpp:226] conv5_1 needs backward computation.
I0912 04:00:08.902797 26285 net.cpp:226] pool4 needs backward computation.
I0912 04:00:08.902804 26285 net.cpp:226] relu4_3 needs backward computation.
I0912 04:00:08.902809 26285 net.cpp:226] conv4_3_scale needs backward computation.
I0912 04:00:08.902817 26285 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 04:00:08.902822 26285 net.cpp:226] conv4_3 needs backward computation.
I0912 04:00:08.902829 26285 net.cpp:226] relu4_2 needs backward computation.
I0912 04:00:08.902835 26285 net.cpp:226] conv4_2_scale needs backward computation.
I0912 04:00:08.902840 26285 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 04:00:08.902848 26285 net.cpp:226] conv4_2 needs backward computation.
I0912 04:00:08.902853 26285 net.cpp:226] relu4_1 needs backward computation.
I0912 04:00:08.902868 26285 net.cpp:226] conv4_1_scale needs backward computation.
I0912 04:00:08.902873 26285 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 04:00:08.902878 26285 net.cpp:226] conv4_1 needs backward computation.
I0912 04:00:08.902884 26285 net.cpp:226] pool3 needs backward computation.
I0912 04:00:08.902894 26285 net.cpp:226] relu3_3 needs backward computation.
I0912 04:00:08.902899 26285 net.cpp:226] conv3_3_scale needs backward computation.
I0912 04:00:08.902905 26285 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 04:00:08.902911 26285 net.cpp:226] conv3_3 needs backward computation.
I0912 04:00:08.902918 26285 net.cpp:226] relu3_2 needs backward computation.
I0912 04:00:08.902925 26285 net.cpp:226] conv3_2_scale needs backward computation.
I0912 04:00:08.902930 26285 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 04:00:08.902935 26285 net.cpp:226] conv3_2 needs backward computation.
I0912 04:00:08.902942 26285 net.cpp:226] relu3_1 needs backward computation.
I0912 04:00:08.902947 26285 net.cpp:226] conv3_1_scale needs backward computation.
I0912 04:00:08.902953 26285 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 04:00:08.902958 26285 net.cpp:226] conv3_1 needs backward computation.
I0912 04:00:08.902966 26285 net.cpp:226] pool2 needs backward computation.
I0912 04:00:08.902976 26285 net.cpp:226] relu2_2 needs backward computation.
I0912 04:00:08.902982 26285 net.cpp:226] conv2_2_scale needs backward computation.
I0912 04:00:08.902987 26285 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 04:00:08.902994 26285 net.cpp:226] conv2_2 needs backward computation.
I0912 04:00:08.903000 26285 net.cpp:226] relu2_1 needs backward computation.
I0912 04:00:08.903007 26285 net.cpp:226] conv2_1_scale needs backward computation.
I0912 04:00:08.903012 26285 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 04:00:08.903019 26285 net.cpp:226] conv2_1 needs backward computation.
I0912 04:00:08.903025 26285 net.cpp:226] pool1 needs backward computation.
I0912 04:00:08.903033 26285 net.cpp:226] relu1_2 needs backward computation.
I0912 04:00:08.903039 26285 net.cpp:226] conv1_2_scale needs backward computation.
I0912 04:00:08.903045 26285 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 04:00:08.903053 26285 net.cpp:226] conv1_2 needs backward computation.
I0912 04:00:08.903060 26285 net.cpp:226] relu1_1 needs backward computation.
I0912 04:00:08.903067 26285 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 04:00:08.903072 26285 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 04:00:08.903077 26285 net.cpp:226] conv1_1_1 needs backward computation.
I0912 04:00:08.903084 26285 net.cpp:228] label_data_1_split does not need backward computation.
I0912 04:00:08.903092 26285 net.cpp:228] data does not need backward computation.
I0912 04:00:08.903100 26285 net.cpp:270] This network produces output accuracy
I0912 04:00:08.903105 26285 net.cpp:270] This network produces output loss
I0912 04:00:08.903111 26285 net.cpp:270] This network produces output per_class_accuracy
I0912 04:00:08.903183 26285 net.cpp:283] Network initialization done.
I0912 04:00:08.903586 26285 solver.cpp:60] Solver scaffolding done.
I0912 04:00:08.913202 26285 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0912 04:00:09.148001 26285 net.cpp:761] Ignoring source layer conv1_1
I0912 04:00:09.148028 26285 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 04:00:09.148089 26285 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 04:00:09.148100 26285 net.cpp:761] Ignoring source layer pool1_drop
I0912 04:00:09.148181 26285 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 04:00:09.148329 26285 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 04:00:09.148337 26285 net.cpp:761] Ignoring source layer pool2_drop
I0912 04:00:09.148620 26285 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 04:00:09.149171 26285 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 04:00:09.149694 26285 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 04:00:09.149722 26285 net.cpp:761] Ignoring source layer pool3_drop
I0912 04:00:09.150737 26285 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 04:00:09.152757 26285 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 04:00:09.154765 26285 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 04:00:09.154775 26285 net.cpp:761] Ignoring source layer pool4_drop
I0912 04:00:09.156780 26285 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 04:00:09.158805 26285 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 04:00:09.160818 26285 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 04:00:09.160827 26285 net.cpp:761] Ignoring source layer pool5_drop
I0912 04:00:09.160835 26285 net.cpp:761] Ignoring source layer upsample5_drop
I0912 04:00:09.162838 26285 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 04:00:09.164854 26285 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 04:00:09.166852 26285 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 04:00:09.166864 26285 net.cpp:761] Ignoring source layer upsample4_drop
I0912 04:00:09.168862 26285 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 04:00:09.170866 26285 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 04:00:09.171871 26285 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 04:00:09.171881 26285 net.cpp:761] Ignoring source layer upsample3_drop
I0912 04:00:09.172396 26285 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 04:00:09.172914 26285 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 04:00:09.173182 26285 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 04:00:09.173189 26285 net.cpp:761] Ignoring source layer upsample2_drop
I0912 04:00:09.173327 26285 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 04:00:09.173418 26285 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 04:00:09.173426 26285 net.cpp:761] Ignoring source layer upsample1_drop
I0912 04:00:09.173473 26285 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 04:00:09.173481 26285 net.cpp:761] Ignoring source layer conv1_1_D
I0912 04:00:09.173487 26285 net.cpp:761] Ignoring source layer prob
I0912 04:00:09.418172 26285 net.cpp:761] Ignoring source layer conv1_1
I0912 04:00:09.418200 26285 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 04:00:09.418252 26285 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 04:00:09.418270 26285 net.cpp:761] Ignoring source layer pool1_drop
I0912 04:00:09.418351 26285 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 04:00:09.418496 26285 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 04:00:09.418503 26285 net.cpp:761] Ignoring source layer pool2_drop
I0912 04:00:09.418781 26285 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 04:00:09.419325 26285 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 04:00:09.419839 26285 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 04:00:09.419847 26285 net.cpp:761] Ignoring source layer pool3_drop
I0912 04:00:09.420861 26285 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 04:00:09.422876 26285 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 04:00:09.424885 26285 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 04:00:09.424893 26285 net.cpp:761] Ignoring source layer pool4_drop
I0912 04:00:09.426898 26285 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 04:00:09.428917 26285 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 04:00:09.430922 26285 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 04:00:09.430932 26285 net.cpp:761] Ignoring source layer pool5_drop
I0912 04:00:09.430938 26285 net.cpp:761] Ignoring source layer upsample5_drop
I0912 04:00:09.432935 26285 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 04:00:09.434929 26285 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 04:00:09.436939 26285 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 04:00:09.436947 26285 net.cpp:761] Ignoring source layer upsample4_drop
I0912 04:00:09.438951 26285 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 04:00:09.440955 26285 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 04:00:09.441990 26285 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 04:00:09.441999 26285 net.cpp:761] Ignoring source layer upsample3_drop
I0912 04:00:09.442508 26285 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 04:00:09.443017 26285 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 04:00:09.443279 26285 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 04:00:09.443286 26285 net.cpp:761] Ignoring source layer upsample2_drop
I0912 04:00:09.443424 26285 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 04:00:09.443506 26285 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 04:00:09.443513 26285 net.cpp:761] Ignoring source layer upsample1_drop
I0912 04:00:09.443559 26285 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 04:00:09.443567 26285 net.cpp:761] Ignoring source layer conv1_1_D
I0912 04:00:09.443572 26285 net.cpp:761] Ignoring source layer prob
I0912 04:00:09.451313 26285 caffe.cpp:251] Starting Optimization
I0912 04:00:09.451334 26285 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0912 04:00:09.451346 26285 solver.cpp:280] Learning Rate Policy: step
I0912 04:00:10.438123 26285 solver.cpp:228] Iteration 0, loss = 0.835478
I0912 04:00:10.438163 26285 solver.cpp:244]     Train net output #0: accuracy = 0.444008
I0912 04:00:10.438179 26285 solver.cpp:244]     Train net output #1: loss = 0.835478 (* 1 = 0.835478 loss)
I0912 04:00:10.438189 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.43649
I0912 04:00:10.438197 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.475861
I0912 04:00:10.438228 26285 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0912 04:00:26.618626 26285 solver.cpp:228] Iteration 20, loss = 0.395227
I0912 04:00:26.618674 26285 solver.cpp:244]     Train net output #0: accuracy = 0.836791
I0912 04:00:26.618690 26285 solver.cpp:244]     Train net output #1: loss = 0.395227 (* 1 = 0.395227 loss)
I0912 04:00:26.618698 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.782307
I0912 04:00:26.618705 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.905117
I0912 04:00:26.618716 26285 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0912 04:00:43.208683 26285 solver.cpp:228] Iteration 40, loss = 0.208539
I0912 04:00:43.208819 26285 solver.cpp:244]     Train net output #0: accuracy = 0.966646
I0912 04:00:43.208838 26285 solver.cpp:244]     Train net output #1: loss = 0.208539 (* 1 = 0.208539 loss)
I0912 04:00:43.208848 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.951637
I0912 04:00:43.208856 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978705
I0912 04:00:43.208866 26285 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0912 04:00:59.798063 26285 solver.cpp:228] Iteration 60, loss = 0.221358
I0912 04:00:59.798108 26285 solver.cpp:244]     Train net output #0: accuracy = 0.966826
I0912 04:00:59.798125 26285 solver.cpp:244]     Train net output #1: loss = 0.221358 (* 1 = 0.221358 loss)
I0912 04:00:59.798133 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983751
I0912 04:00:59.798141 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.955077
I0912 04:00:59.798151 26285 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0912 04:01:16.396600 26285 solver.cpp:228] Iteration 80, loss = 0.1187
I0912 04:01:16.396749 26285 solver.cpp:244]     Train net output #0: accuracy = 0.953945
I0912 04:01:16.396769 26285 solver.cpp:244]     Train net output #1: loss = 0.1187 (* 1 = 0.1187 loss)
I0912 04:01:16.396778 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.93773
I0912 04:01:16.396787 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9868
I0912 04:01:16.396798 26285 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0912 04:01:33.010135 26285 solver.cpp:228] Iteration 100, loss = 0.0911168
I0912 04:01:33.010177 26285 solver.cpp:244]     Train net output #0: accuracy = 0.971586
I0912 04:01:33.010193 26285 solver.cpp:244]     Train net output #1: loss = 0.0911168 (* 1 = 0.0911168 loss)
I0912 04:01:33.010201 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.964393
I0912 04:01:33.010208 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986374
I0912 04:01:33.010217 26285 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0912 04:01:49.612300 26285 solver.cpp:228] Iteration 120, loss = 0.173034
I0912 04:01:49.612485 26285 solver.cpp:244]     Train net output #0: accuracy = 0.955007
I0912 04:01:49.612509 26285 solver.cpp:244]     Train net output #1: loss = 0.173034 (* 1 = 0.173034 loss)
I0912 04:01:49.612517 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991508
I0912 04:01:49.612525 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.902072
I0912 04:01:49.612537 26285 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0912 04:02:06.198582 26285 solver.cpp:228] Iteration 140, loss = 0.0889827
I0912 04:02:06.198621 26285 solver.cpp:244]     Train net output #0: accuracy = 0.968592
I0912 04:02:06.198642 26285 solver.cpp:244]     Train net output #1: loss = 0.0889827 (* 1 = 0.0889827 loss)
I0912 04:02:06.198650 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.962397
I0912 04:02:06.198657 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978491
I0912 04:02:06.198668 26285 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0912 04:02:22.794811 26285 solver.cpp:228] Iteration 160, loss = 0.0420644
I0912 04:02:22.794919 26285 solver.cpp:244]     Train net output #0: accuracy = 0.991269
I0912 04:02:22.794939 26285 solver.cpp:244]     Train net output #1: loss = 0.0420644 (* 1 = 0.0420644 loss)
I0912 04:02:22.794947 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989285
I0912 04:02:22.794972 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993324
I0912 04:02:22.794983 26285 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0912 04:02:39.395753 26285 solver.cpp:228] Iteration 180, loss = 0.0653599
I0912 04:02:39.395797 26285 solver.cpp:244]     Train net output #0: accuracy = 0.968844
I0912 04:02:39.395817 26285 solver.cpp:244]     Train net output #1: loss = 0.0653599 (* 1 = 0.0653599 loss)
I0912 04:02:39.395825 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.958018
I0912 04:02:39.395833 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993391
I0912 04:02:39.395843 26285 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0912 04:02:55.993849 26285 solver.cpp:228] Iteration 200, loss = 0.0348819
I0912 04:02:55.993955 26285 solver.cpp:244]     Train net output #0: accuracy = 0.988614
I0912 04:02:55.993974 26285 solver.cpp:244]     Train net output #1: loss = 0.0348819 (* 1 = 0.0348819 loss)
I0912 04:02:55.993983 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98376
I0912 04:02:55.993990 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995442
I0912 04:02:55.994000 26285 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0912 04:03:12.594161 26285 solver.cpp:228] Iteration 220, loss = 0.0750265
I0912 04:03:12.594203 26285 solver.cpp:244]     Train net output #0: accuracy = 0.969008
I0912 04:03:12.594220 26285 solver.cpp:244]     Train net output #1: loss = 0.0750265 (* 1 = 0.0750265 loss)
I0912 04:03:12.594229 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.952382
I0912 04:03:12.594238 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996006
I0912 04:03:12.594247 26285 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0912 04:03:29.197985 26285 solver.cpp:228] Iteration 240, loss = 0.0892988
I0912 04:03:29.198102 26285 solver.cpp:244]     Train net output #0: accuracy = 0.98228
I0912 04:03:29.198120 26285 solver.cpp:244]     Train net output #1: loss = 0.0892988 (* 1 = 0.0892988 loss)
I0912 04:03:29.198129 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98827
I0912 04:03:29.198151 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.977382
I0912 04:03:29.198163 26285 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0912 04:03:45.785104 26285 solver.cpp:228] Iteration 260, loss = 0.0717388
I0912 04:03:45.785142 26285 solver.cpp:244]     Train net output #0: accuracy = 0.972998
I0912 04:03:45.785158 26285 solver.cpp:244]     Train net output #1: loss = 0.0717388 (* 1 = 0.0717388 loss)
I0912 04:03:45.785166 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969383
I0912 04:03:45.785173 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981682
I0912 04:03:45.785182 26285 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0912 04:04:02.371306 26285 solver.cpp:228] Iteration 280, loss = 0.257454
I0912 04:04:02.371490 26285 solver.cpp:244]     Train net output #0: accuracy = 0.913572
I0912 04:04:02.371515 26285 solver.cpp:244]     Train net output #1: loss = 0.257454 (* 1 = 0.257454 loss)
I0912 04:04:02.371534 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.909228
I0912 04:04:02.371551 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999789
I0912 04:04:02.371570 26285 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0912 04:04:18.948189 26285 solver.cpp:228] Iteration 300, loss = 0.115402
I0912 04:04:18.948230 26285 solver.cpp:244]     Train net output #0: accuracy = 0.954485
I0912 04:04:18.948245 26285 solver.cpp:244]     Train net output #1: loss = 0.115402 (* 1 = 0.115402 loss)
I0912 04:04:18.948253 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.947221
I0912 04:04:18.948261 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994108
I0912 04:04:18.948271 26285 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0912 04:04:35.544155 26285 solver.cpp:228] Iteration 320, loss = 0.0515008
I0912 04:04:35.544275 26285 solver.cpp:244]     Train net output #0: accuracy = 0.986124
I0912 04:04:35.544296 26285 solver.cpp:244]     Train net output #1: loss = 0.0515009 (* 1 = 0.0515009 loss)
I0912 04:04:35.544304 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99017
I0912 04:04:35.544312 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.971474
I0912 04:04:35.544322 26285 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0912 04:04:52.132191 26285 solver.cpp:228] Iteration 340, loss = 0.0349531
I0912 04:04:52.132233 26285 solver.cpp:244]     Train net output #0: accuracy = 0.988471
I0912 04:04:52.132251 26285 solver.cpp:244]     Train net output #1: loss = 0.0349531 (* 1 = 0.0349531 loss)
I0912 04:04:52.132258 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985199
I0912 04:04:52.132266 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999005
I0912 04:04:52.132274 26285 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0912 04:05:08.733065 26285 solver.cpp:228] Iteration 360, loss = 0.0222212
I0912 04:05:08.733175 26285 solver.cpp:244]     Train net output #0: accuracy = 0.990813
I0912 04:05:08.733193 26285 solver.cpp:244]     Train net output #1: loss = 0.0222212 (* 1 = 0.0222212 loss)
I0912 04:05:08.733202 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985777
I0912 04:05:08.733224 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999101
I0912 04:05:08.733234 26285 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0912 04:05:25.338634 26285 solver.cpp:228] Iteration 380, loss = 0.0122637
I0912 04:05:25.338677 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997484
I0912 04:05:25.338696 26285 solver.cpp:244]     Train net output #1: loss = 0.0122637 (* 1 = 0.0122637 loss)
I0912 04:05:25.338703 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998063
I0912 04:05:25.338711 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996227
I0912 04:05:25.338721 26285 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0912 04:05:41.935223 26285 solver.cpp:228] Iteration 400, loss = 0.0613565
I0912 04:05:41.935333 26285 solver.cpp:244]     Train net output #0: accuracy = 0.980735
I0912 04:05:41.935353 26285 solver.cpp:244]     Train net output #1: loss = 0.0613565 (* 1 = 0.0613565 loss)
I0912 04:05:41.935361 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991469
I0912 04:05:41.935369 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.957021
I0912 04:05:41.935380 26285 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0912 04:05:58.517552 26285 solver.cpp:228] Iteration 420, loss = 0.0383311
I0912 04:05:58.517596 26285 solver.cpp:244]     Train net output #0: accuracy = 0.988912
I0912 04:05:58.517616 26285 solver.cpp:244]     Train net output #1: loss = 0.0383312 (* 1 = 0.0383312 loss)
I0912 04:05:58.517623 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988492
I0912 04:05:58.517632 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989265
I0912 04:05:58.517640 26285 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0912 04:06:15.108126 26285 solver.cpp:228] Iteration 440, loss = 0.0448411
I0912 04:06:15.108314 26285 solver.cpp:244]     Train net output #0: accuracy = 0.986283
I0912 04:06:15.108336 26285 solver.cpp:244]     Train net output #1: loss = 0.0448412 (* 1 = 0.0448412 loss)
I0912 04:06:15.108357 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983044
I0912 04:06:15.108371 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988715
I0912 04:06:15.108389 26285 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0912 04:06:31.710369 26285 solver.cpp:228] Iteration 460, loss = 0.038881
I0912 04:06:31.710412 26285 solver.cpp:244]     Train net output #0: accuracy = 0.986713
I0912 04:06:31.710433 26285 solver.cpp:244]     Train net output #1: loss = 0.0388811 (* 1 = 0.0388811 loss)
I0912 04:06:31.710441 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982505
I0912 04:06:31.710448 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990756
I0912 04:06:31.710459 26285 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0912 04:06:48.316596 26285 solver.cpp:228] Iteration 480, loss = 0.0325125
I0912 04:06:48.316704 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993391
I0912 04:06:48.316725 26285 solver.cpp:244]     Train net output #1: loss = 0.0325126 (* 1 = 0.0325126 loss)
I0912 04:06:48.316735 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995392
I0912 04:06:48.316743 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992154
I0912 04:06:48.316753 26285 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0912 04:07:04.900156 26285 solver.cpp:228] Iteration 500, loss = 0.0120156
I0912 04:07:04.900197 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99679
I0912 04:07:04.900213 26285 solver.cpp:244]     Train net output #1: loss = 0.0120157 (* 1 = 0.0120157 loss)
I0912 04:07:04.900221 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996803
I0912 04:07:04.900228 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996748
I0912 04:07:04.900239 26285 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0912 04:07:21.500743 26285 solver.cpp:228] Iteration 520, loss = 0.0259094
I0912 04:07:21.500857 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993539
I0912 04:07:21.500879 26285 solver.cpp:244]     Train net output #1: loss = 0.0259095 (* 1 = 0.0259095 loss)
I0912 04:07:21.500888 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995249
I0912 04:07:21.500913 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985139
I0912 04:07:21.500923 26285 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0912 04:07:38.098024 26285 solver.cpp:228] Iteration 540, loss = 0.0158149
I0912 04:07:38.098067 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993717
I0912 04:07:38.098084 26285 solver.cpp:244]     Train net output #1: loss = 0.015815 (* 1 = 0.015815 loss)
I0912 04:07:38.098093 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992923
I0912 04:07:38.098100 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995292
I0912 04:07:38.098110 26285 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0912 04:07:54.695057 26285 solver.cpp:228] Iteration 560, loss = 0.0190871
I0912 04:07:54.695221 26285 solver.cpp:244]     Train net output #0: accuracy = 0.992669
I0912 04:07:54.695245 26285 solver.cpp:244]     Train net output #1: loss = 0.0190871 (* 1 = 0.0190871 loss)
I0912 04:07:54.695266 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988215
I0912 04:07:54.695281 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997003
I0912 04:07:54.695300 26285 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0912 04:08:11.297441 26285 solver.cpp:228] Iteration 580, loss = 0.0140252
I0912 04:08:11.297482 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99577
I0912 04:08:11.297499 26285 solver.cpp:244]     Train net output #1: loss = 0.0140252 (* 1 = 0.0140252 loss)
I0912 04:08:11.297508 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996156
I0912 04:08:11.297514 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994626
I0912 04:08:11.297525 26285 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0912 04:08:27.884994 26285 solver.cpp:228] Iteration 600, loss = 0.0112908
I0912 04:08:27.885124 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996921
I0912 04:08:27.885143 26285 solver.cpp:244]     Train net output #1: loss = 0.0112909 (* 1 = 0.0112909 loss)
I0912 04:08:27.885154 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996894
I0912 04:08:27.885161 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996955
I0912 04:08:27.885172 26285 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0912 04:08:44.553735 26285 solver.cpp:228] Iteration 620, loss = 0.0223695
I0912 04:08:44.553779 26285 solver.cpp:244]     Train net output #0: accuracy = 0.990003
I0912 04:08:44.553798 26285 solver.cpp:244]     Train net output #1: loss = 0.0223696 (* 1 = 0.0223696 loss)
I0912 04:08:44.553808 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983711
I0912 04:08:44.553817 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997604
I0912 04:08:44.553827 26285 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0912 04:09:01.137944 26285 solver.cpp:228] Iteration 640, loss = 0.0357969
I0912 04:09:01.138067 26285 solver.cpp:244]     Train net output #0: accuracy = 0.988666
I0912 04:09:01.138085 26285 solver.cpp:244]     Train net output #1: loss = 0.035797 (* 1 = 0.035797 loss)
I0912 04:09:01.138095 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993627
I0912 04:09:01.138103 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981853
I0912 04:09:01.138113 26285 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0912 04:09:17.736065 26285 solver.cpp:228] Iteration 660, loss = 0.0178693
I0912 04:09:17.736110 26285 solver.cpp:244]     Train net output #0: accuracy = 0.992862
I0912 04:09:17.736129 26285 solver.cpp:244]     Train net output #1: loss = 0.0178694 (* 1 = 0.0178694 loss)
I0912 04:09:17.736138 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990763
I0912 04:09:17.736145 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995773
I0912 04:09:17.736155 26285 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0912 04:09:34.347195 26285 solver.cpp:228] Iteration 680, loss = 0.0290734
I0912 04:09:34.347322 26285 solver.cpp:244]     Train net output #0: accuracy = 0.987578
I0912 04:09:34.347340 26285 solver.cpp:244]     Train net output #1: loss = 0.0290735 (* 1 = 0.0290735 loss)
I0912 04:09:34.347349 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981789
I0912 04:09:34.347370 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994452
I0912 04:09:34.347383 26285 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0912 04:09:50.947353 26285 solver.cpp:228] Iteration 700, loss = 0.0107387
I0912 04:09:50.947398 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995871
I0912 04:09:50.947417 26285 solver.cpp:244]     Train net output #1: loss = 0.0107387 (* 1 = 0.0107387 loss)
I0912 04:09:50.947427 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995251
I0912 04:09:50.947435 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997284
I0912 04:09:50.947445 26285 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0912 04:10:07.550809 26285 solver.cpp:228] Iteration 720, loss = 0.0201341
I0912 04:10:07.550974 26285 solver.cpp:244]     Train net output #0: accuracy = 0.991591
I0912 04:10:07.550995 26285 solver.cpp:244]     Train net output #1: loss = 0.0201342 (* 1 = 0.0201342 loss)
I0912 04:10:07.551005 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985879
I0912 04:10:07.551013 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997636
I0912 04:10:07.551023 26285 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0912 04:10:24.130017 26285 solver.cpp:228] Iteration 740, loss = 0.0132784
I0912 04:10:24.130059 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994829
I0912 04:10:24.130075 26285 solver.cpp:244]     Train net output #1: loss = 0.0132785 (* 1 = 0.0132785 loss)
I0912 04:10:24.130084 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991151
I0912 04:10:24.130090 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998687
I0912 04:10:24.130100 26285 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0912 04:10:40.734817 26285 solver.cpp:228] Iteration 760, loss = 0.0146915
I0912 04:10:40.734938 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995388
I0912 04:10:40.734959 26285 solver.cpp:244]     Train net output #1: loss = 0.0146916 (* 1 = 0.0146916 loss)
I0912 04:10:40.734968 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995924
I0912 04:10:40.734992 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993524
I0912 04:10:40.735002 26285 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0912 04:10:57.334019 26285 solver.cpp:228] Iteration 780, loss = 0.0181906
I0912 04:10:57.334060 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993202
I0912 04:10:57.334077 26285 solver.cpp:244]     Train net output #1: loss = 0.0181906 (* 1 = 0.0181906 loss)
I0912 04:10:57.334086 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98991
I0912 04:10:57.334094 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996208
I0912 04:10:57.334103 26285 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0912 04:11:13.937919 26285 solver.cpp:228] Iteration 800, loss = 0.0102676
I0912 04:11:13.938046 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995849
I0912 04:11:13.938067 26285 solver.cpp:244]     Train net output #1: loss = 0.0102676 (* 1 = 0.0102676 loss)
I0912 04:11:13.938077 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994727
I0912 04:11:13.938099 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997652
I0912 04:11:13.938122 26285 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0912 04:11:30.531406 26285 solver.cpp:228] Iteration 820, loss = 0.0173638
I0912 04:11:30.531448 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993559
I0912 04:11:30.531466 26285 solver.cpp:244]     Train net output #1: loss = 0.0173639 (* 1 = 0.0173639 loss)
I0912 04:11:30.531474 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99375
I0912 04:11:30.531481 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993245
I0912 04:11:30.531491 26285 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0912 04:11:47.123513 26285 solver.cpp:228] Iteration 840, loss = 0.00970656
I0912 04:11:47.123633 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997159
I0912 04:11:47.123654 26285 solver.cpp:244]     Train net output #1: loss = 0.00970663 (* 1 = 0.00970663 loss)
I0912 04:11:47.123664 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99557
I0912 04:11:47.123672 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998486
I0912 04:11:47.123682 26285 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0912 04:12:03.708596 26285 solver.cpp:228] Iteration 860, loss = 0.0265891
I0912 04:12:03.708640 26285 solver.cpp:244]     Train net output #0: accuracy = 0.990897
I0912 04:12:03.708659 26285 solver.cpp:244]     Train net output #1: loss = 0.0265892 (* 1 = 0.0265892 loss)
I0912 04:12:03.708667 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992321
I0912 04:12:03.708674 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984481
I0912 04:12:03.708685 26285 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0912 04:12:20.308333 26285 solver.cpp:228] Iteration 880, loss = 0.0129073
I0912 04:12:20.308519 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994805
I0912 04:12:20.308539 26285 solver.cpp:244]     Train net output #1: loss = 0.0129073 (* 1 = 0.0129073 loss)
I0912 04:12:20.308549 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994303
I0912 04:12:20.308557 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996096
I0912 04:12:20.308568 26285 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0912 04:12:36.898499 26285 solver.cpp:228] Iteration 900, loss = 0.0119918
I0912 04:12:36.898543 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995357
I0912 04:12:36.898562 26285 solver.cpp:244]     Train net output #1: loss = 0.0119919 (* 1 = 0.0119919 loss)
I0912 04:12:36.898571 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993988
I0912 04:12:36.898578 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996975
I0912 04:12:36.898588 26285 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0912 04:12:53.482705 26285 solver.cpp:228] Iteration 920, loss = 0.0143466
I0912 04:12:53.482812 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995255
I0912 04:12:53.482833 26285 solver.cpp:244]     Train net output #1: loss = 0.0143466 (* 1 = 0.0143466 loss)
I0912 04:12:53.482842 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99507
I0912 04:12:53.482867 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995992
I0912 04:12:53.482878 26285 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0912 04:13:10.082800 26285 solver.cpp:228] Iteration 940, loss = 0.0183284
I0912 04:13:10.082844 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994227
I0912 04:13:10.082864 26285 solver.cpp:244]     Train net output #1: loss = 0.0183284 (* 1 = 0.0183284 loss)
I0912 04:13:10.082873 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994952
I0912 04:13:10.082881 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990841
I0912 04:13:10.082891 26285 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0912 04:13:26.676091 26285 solver.cpp:228] Iteration 960, loss = 0.0225589
I0912 04:13:26.676209 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99037
I0912 04:13:26.676231 26285 solver.cpp:244]     Train net output #1: loss = 0.0225589 (* 1 = 0.0225589 loss)
I0912 04:13:26.676241 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984872
I0912 04:13:26.676249 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997104
I0912 04:13:26.676260 26285 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0912 04:13:43.266175 26285 solver.cpp:228] Iteration 980, loss = 0.037144
I0912 04:13:43.266217 26285 solver.cpp:244]     Train net output #0: accuracy = 0.987937
I0912 04:13:43.266233 26285 solver.cpp:244]     Train net output #1: loss = 0.037144 (* 1 = 0.037144 loss)
I0912 04:13:43.266243 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9871
I0912 04:13:43.266250 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992146
I0912 04:13:43.266260 26285 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0912 04:13:59.872885 26285 solver.cpp:228] Iteration 1000, loss = 0.026176
I0912 04:13:59.873013 26285 solver.cpp:244]     Train net output #0: accuracy = 0.992907
I0912 04:13:59.873034 26285 solver.cpp:244]     Train net output #1: loss = 0.026176 (* 1 = 0.026176 loss)
I0912 04:13:59.873044 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99022
I0912 04:13:59.873052 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994744
I0912 04:13:59.873062 26285 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0912 04:14:16.472028 26285 solver.cpp:228] Iteration 1020, loss = 0.0110444
I0912 04:14:16.472069 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995707
I0912 04:14:16.472085 26285 solver.cpp:244]     Train net output #1: loss = 0.0110444 (* 1 = 0.0110444 loss)
I0912 04:14:16.472095 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992082
I0912 04:14:16.472101 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999279
I0912 04:14:16.472111 26285 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0912 04:14:33.083189 26285 solver.cpp:228] Iteration 1040, loss = 0.0207199
I0912 04:14:33.083370 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993124
I0912 04:14:33.083394 26285 solver.cpp:244]     Train net output #1: loss = 0.0207199 (* 1 = 0.0207199 loss)
I0912 04:14:33.083403 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986733
I0912 04:14:33.083412 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997519
I0912 04:14:33.083422 26285 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0912 04:14:49.692193 26285 solver.cpp:228] Iteration 1060, loss = 0.0201478
I0912 04:14:49.692234 26285 solver.cpp:244]     Train net output #0: accuracy = 0.992607
I0912 04:14:49.692252 26285 solver.cpp:244]     Train net output #1: loss = 0.0201478 (* 1 = 0.0201478 loss)
I0912 04:14:49.692260 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993207
I0912 04:14:49.692268 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991457
I0912 04:14:49.692278 26285 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0912 04:15:06.272296 26285 solver.cpp:228] Iteration 1080, loss = 0.0146969
I0912 04:15:06.272430 26285 solver.cpp:244]     Train net output #0: accuracy = 0.992995
I0912 04:15:06.272451 26285 solver.cpp:244]     Train net output #1: loss = 0.0146969 (* 1 = 0.0146969 loss)
I0912 04:15:06.272461 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989211
I0912 04:15:06.272469 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999131
I0912 04:15:06.272480 26285 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0912 04:15:22.863313 26285 solver.cpp:228] Iteration 1100, loss = 0.0125894
I0912 04:15:22.863358 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99547
I0912 04:15:22.863374 26285 solver.cpp:244]     Train net output #1: loss = 0.0125894 (* 1 = 0.0125894 loss)
I0912 04:15:22.863384 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991706
I0912 04:15:22.863391 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99869
I0912 04:15:22.863404 26285 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0912 04:15:39.455236 26285 solver.cpp:228] Iteration 1120, loss = 0.0160236
I0912 04:15:39.455361 26285 solver.cpp:244]     Train net output #0: accuracy = 0.992729
I0912 04:15:39.455381 26285 solver.cpp:244]     Train net output #1: loss = 0.0160236 (* 1 = 0.0160236 loss)
I0912 04:15:39.455390 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989546
I0912 04:15:39.455399 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997493
I0912 04:15:39.455409 26285 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0912 04:15:56.040534 26285 solver.cpp:228] Iteration 1140, loss = 0.00713965
I0912 04:15:56.040576 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997216
I0912 04:15:56.040594 26285 solver.cpp:244]     Train net output #1: loss = 0.00713964 (* 1 = 0.00713964 loss)
I0912 04:15:56.040603 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996611
I0912 04:15:56.040611 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998451
I0912 04:15:56.040621 26285 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0912 04:16:12.642689 26285 solver.cpp:228] Iteration 1160, loss = 0.0151413
I0912 04:16:12.642861 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994343
I0912 04:16:12.642884 26285 solver.cpp:244]     Train net output #1: loss = 0.0151413 (* 1 = 0.0151413 loss)
I0912 04:16:12.642895 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990496
I0912 04:16:12.642915 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997671
I0912 04:16:12.642935 26285 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0912 04:16:29.263608 26285 solver.cpp:228] Iteration 1180, loss = 0.00938844
I0912 04:16:29.263653 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996379
I0912 04:16:29.263672 26285 solver.cpp:244]     Train net output #1: loss = 0.00938843 (* 1 = 0.00938843 loss)
I0912 04:16:29.263682 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995941
I0912 04:16:29.263691 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99706
I0912 04:16:29.263703 26285 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0912 04:16:45.848161 26285 solver.cpp:228] Iteration 1200, loss = 0.0186776
I0912 04:16:45.848279 26285 solver.cpp:244]     Train net output #0: accuracy = 0.992585
I0912 04:16:45.848299 26285 solver.cpp:244]     Train net output #1: loss = 0.0186776 (* 1 = 0.0186776 loss)
I0912 04:16:45.848309 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991422
I0912 04:16:45.848317 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994087
I0912 04:16:45.848327 26285 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0912 04:17:02.438555 26285 solver.cpp:228] Iteration 1220, loss = 0.011245
I0912 04:17:02.438596 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995852
I0912 04:17:02.438613 26285 solver.cpp:244]     Train net output #1: loss = 0.0112449 (* 1 = 0.0112449 loss)
I0912 04:17:02.438622 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995905
I0912 04:17:02.438629 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995656
I0912 04:17:02.438639 26285 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0912 04:17:19.026309 26285 solver.cpp:228] Iteration 1240, loss = 0.012962
I0912 04:17:19.026443 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994605
I0912 04:17:19.026464 26285 solver.cpp:244]     Train net output #1: loss = 0.012962 (* 1 = 0.012962 loss)
I0912 04:17:19.026475 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99336
I0912 04:17:19.026484 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996497
I0912 04:17:19.026494 26285 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0912 04:17:35.627331 26285 solver.cpp:228] Iteration 1260, loss = 0.0108784
I0912 04:17:35.627372 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995793
I0912 04:17:35.627389 26285 solver.cpp:244]     Train net output #1: loss = 0.0108784 (* 1 = 0.0108784 loss)
I0912 04:17:35.627398 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99475
I0912 04:17:35.627406 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997141
I0912 04:17:35.627416 26285 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0912 04:17:52.249301 26285 solver.cpp:228] Iteration 1280, loss = 0.0139589
I0912 04:17:52.249413 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993977
I0912 04:17:52.249434 26285 solver.cpp:244]     Train net output #1: loss = 0.0139589 (* 1 = 0.0139589 loss)
I0912 04:17:52.249444 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992913
I0912 04:17:52.249451 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995921
I0912 04:17:52.249464 26285 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0912 04:18:08.846743 26285 solver.cpp:228] Iteration 1300, loss = 0.0154381
I0912 04:18:08.846787 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993519
I0912 04:18:08.846806 26285 solver.cpp:244]     Train net output #1: loss = 0.0154381 (* 1 = 0.0154381 loss)
I0912 04:18:08.846815 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992641
I0912 04:18:08.846822 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995312
I0912 04:18:08.846833 26285 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0912 04:18:25.443784 26285 solver.cpp:228] Iteration 1320, loss = 0.00846059
I0912 04:18:25.443958 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997104
I0912 04:18:25.443980 26285 solver.cpp:244]     Train net output #1: loss = 0.00846058 (* 1 = 0.00846058 loss)
I0912 04:18:25.444001 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995943
I0912 04:18:25.444018 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998145
I0912 04:18:25.444038 26285 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0912 04:18:42.041631 26285 solver.cpp:228] Iteration 1340, loss = 0.0170943
I0912 04:18:42.041676 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993886
I0912 04:18:42.041695 26285 solver.cpp:244]     Train net output #1: loss = 0.0170943 (* 1 = 0.0170943 loss)
I0912 04:18:42.041704 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992096
I0912 04:18:42.041712 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995561
I0912 04:18:42.041723 26285 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0912 04:18:58.637167 26285 solver.cpp:228] Iteration 1360, loss = 0.00788518
I0912 04:18:58.637276 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997355
I0912 04:18:58.637296 26285 solver.cpp:244]     Train net output #1: loss = 0.00788517 (* 1 = 0.00788517 loss)
I0912 04:18:58.637305 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998155
I0912 04:18:58.637313 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995526
I0912 04:18:58.637325 26285 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0912 04:19:15.219763 26285 solver.cpp:228] Iteration 1380, loss = 0.00504888
I0912 04:19:15.219806 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998349
I0912 04:19:15.219825 26285 solver.cpp:244]     Train net output #1: loss = 0.00504887 (* 1 = 0.00504887 loss)
I0912 04:19:15.219835 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998821
I0912 04:19:15.219841 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997285
I0912 04:19:15.219851 26285 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0912 04:19:31.813796 26285 solver.cpp:228] Iteration 1400, loss = 0.0103344
I0912 04:19:31.813915 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996089
I0912 04:19:31.813935 26285 solver.cpp:244]     Train net output #1: loss = 0.0103344 (* 1 = 0.0103344 loss)
I0912 04:19:31.813944 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995556
I0912 04:19:31.813967 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99683
I0912 04:19:31.813978 26285 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0912 04:19:48.415956 26285 solver.cpp:228] Iteration 1420, loss = 0.0127505
I0912 04:19:48.415993 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995297
I0912 04:19:48.416013 26285 solver.cpp:244]     Train net output #1: loss = 0.0127505 (* 1 = 0.0127505 loss)
I0912 04:19:48.416023 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992744
I0912 04:19:48.416029 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997535
I0912 04:19:48.416040 26285 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0912 04:20:05.009804 26285 solver.cpp:228] Iteration 1440, loss = 0.00748566
I0912 04:20:05.009922 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997593
I0912 04:20:05.009944 26285 solver.cpp:244]     Train net output #1: loss = 0.00748565 (* 1 = 0.00748565 loss)
I0912 04:20:05.009953 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995649
I0912 04:20:05.009961 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999161
I0912 04:20:05.009973 26285 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0912 04:20:21.611516 26285 solver.cpp:228] Iteration 1460, loss = 0.0163106
I0912 04:20:21.611558 26285 solver.cpp:244]     Train net output #0: accuracy = 0.992745
I0912 04:20:21.611575 26285 solver.cpp:244]     Train net output #1: loss = 0.0163106 (* 1 = 0.0163106 loss)
I0912 04:20:21.611583 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991316
I0912 04:20:21.611593 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995958
I0912 04:20:21.611603 26285 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0912 04:20:38.198740 26285 solver.cpp:228] Iteration 1480, loss = 0.011031
I0912 04:20:38.198923 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994819
I0912 04:20:38.198947 26285 solver.cpp:244]     Train net output #1: loss = 0.011031 (* 1 = 0.011031 loss)
I0912 04:20:38.198966 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991911
I0912 04:20:38.198983 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998621
I0912 04:20:38.199003 26285 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0912 04:20:54.806912 26285 solver.cpp:228] Iteration 1500, loss = 0.00721475
I0912 04:20:54.806953 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997271
I0912 04:20:54.806970 26285 solver.cpp:244]     Train net output #1: loss = 0.00721474 (* 1 = 0.00721474 loss)
I0912 04:20:54.806979 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996678
I0912 04:20:54.806988 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99799
I0912 04:20:54.806998 26285 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0912 04:21:11.416782 26285 solver.cpp:228] Iteration 1520, loss = 0.0210468
I0912 04:21:11.416906 26285 solver.cpp:244]     Train net output #0: accuracy = 0.992701
I0912 04:21:11.416927 26285 solver.cpp:244]     Train net output #1: loss = 0.0210468 (* 1 = 0.0210468 loss)
I0912 04:21:11.416936 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991926
I0912 04:21:11.416944 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997797
I0912 04:21:11.416955 26285 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0912 04:21:28.016343 26285 solver.cpp:228] Iteration 1540, loss = 0.00843556
I0912 04:21:28.016381 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996914
I0912 04:21:28.016399 26285 solver.cpp:244]     Train net output #1: loss = 0.00843555 (* 1 = 0.00843555 loss)
I0912 04:21:28.016407 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997125
I0912 04:21:28.016414 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996308
I0912 04:21:28.016424 26285 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0912 04:21:44.617274 26285 solver.cpp:228] Iteration 1560, loss = 0.0085288
I0912 04:21:44.617429 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996466
I0912 04:21:44.617465 26285 solver.cpp:244]     Train net output #1: loss = 0.00852879 (* 1 = 0.00852879 loss)
I0912 04:21:44.617472 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995308
I0912 04:21:44.617478 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998103
I0912 04:21:44.617486 26285 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0912 04:22:01.301978 26285 solver.cpp:228] Iteration 1580, loss = 0.00957913
I0912 04:22:01.302026 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997034
I0912 04:22:01.302042 26285 solver.cpp:244]     Train net output #1: loss = 0.00957912 (* 1 = 0.00957912 loss)
I0912 04:22:01.302047 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996801
I0912 04:22:01.302052 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998268
I0912 04:22:01.302062 26285 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0912 04:22:18.008200 26285 solver.cpp:228] Iteration 1600, loss = 0.00694473
I0912 04:22:18.008357 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997473
I0912 04:22:18.008371 26285 solver.cpp:244]     Train net output #1: loss = 0.00694471 (* 1 = 0.00694471 loss)
I0912 04:22:18.008378 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996541
I0912 04:22:18.008383 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998493
I0912 04:22:18.008393 26285 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0912 04:22:34.771925 26285 solver.cpp:228] Iteration 1620, loss = 0.0138171
I0912 04:22:34.771991 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995658
I0912 04:22:34.772011 26285 solver.cpp:244]     Train net output #1: loss = 0.0138171 (* 1 = 0.0138171 loss)
I0912 04:22:34.772022 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996934
I0912 04:22:34.772027 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993826
I0912 04:22:34.772039 26285 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0912 04:22:51.462472 26285 solver.cpp:228] Iteration 1640, loss = 0.0249601
I0912 04:22:51.462605 26285 solver.cpp:244]     Train net output #0: accuracy = 0.991791
I0912 04:22:51.462620 26285 solver.cpp:244]     Train net output #1: loss = 0.0249601 (* 1 = 0.0249601 loss)
I0912 04:22:51.462626 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995016
I0912 04:22:51.462631 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979304
I0912 04:22:51.462640 26285 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0912 04:23:08.128939 26285 solver.cpp:228] Iteration 1660, loss = 0.00504644
I0912 04:23:08.128983 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998138
I0912 04:23:08.129000 26285 solver.cpp:244]     Train net output #1: loss = 0.00504642 (* 1 = 0.00504642 loss)
I0912 04:23:08.129007 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998083
I0912 04:23:08.129012 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998299
I0912 04:23:08.129020 26285 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0912 04:23:24.821138 26285 solver.cpp:228] Iteration 1680, loss = 0.00864882
I0912 04:23:24.821267 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996659
I0912 04:23:24.821283 26285 solver.cpp:244]     Train net output #1: loss = 0.00864881 (* 1 = 0.00864881 loss)
I0912 04:23:24.821290 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996351
I0912 04:23:24.821295 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997125
I0912 04:23:24.821303 26285 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0912 04:23:41.489416 26285 solver.cpp:228] Iteration 1700, loss = 0.00637719
I0912 04:23:41.489464 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997894
I0912 04:23:41.489490 26285 solver.cpp:244]     Train net output #1: loss = 0.00637718 (* 1 = 0.00637718 loss)
I0912 04:23:41.489500 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998032
I0912 04:23:41.489504 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99737
I0912 04:23:41.489512 26285 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0912 04:23:58.180212 26285 solver.cpp:228] Iteration 1720, loss = 0.00857797
I0912 04:23:58.180341 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996671
I0912 04:23:58.180368 26285 solver.cpp:244]     Train net output #1: loss = 0.00857795 (* 1 = 0.00857795 loss)
I0912 04:23:58.180375 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996695
I0912 04:23:58.180380 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996613
I0912 04:23:58.180388 26285 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0912 04:24:14.860260 26285 solver.cpp:228] Iteration 1740, loss = 0.00590115
I0912 04:24:14.860306 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997523
I0912 04:24:14.860340 26285 solver.cpp:244]     Train net output #1: loss = 0.00590114 (* 1 = 0.00590114 loss)
I0912 04:24:14.860349 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996903
I0912 04:24:14.860354 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998374
I0912 04:24:14.860363 26285 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0912 04:24:31.543470 26285 solver.cpp:228] Iteration 1760, loss = 0.0154337
I0912 04:24:31.543642 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994038
I0912 04:24:31.543659 26285 solver.cpp:244]     Train net output #1: loss = 0.0154337 (* 1 = 0.0154337 loss)
I0912 04:24:31.543665 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994191
I0912 04:24:31.543682 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993676
I0912 04:24:31.543692 26285 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0912 04:24:48.211998 26285 solver.cpp:228] Iteration 1780, loss = 0.0321833
I0912 04:24:48.212045 26285 solver.cpp:244]     Train net output #0: accuracy = 0.987185
I0912 04:24:48.212059 26285 solver.cpp:244]     Train net output #1: loss = 0.0321833 (* 1 = 0.0321833 loss)
I0912 04:24:48.212065 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980393
I0912 04:24:48.212070 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99441
I0912 04:24:48.212079 26285 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0912 04:25:04.961515 26285 solver.cpp:228] Iteration 1800, loss = 0.00901913
I0912 04:25:04.961660 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996688
I0912 04:25:04.961696 26285 solver.cpp:244]     Train net output #1: loss = 0.00901914 (* 1 = 0.00901914 loss)
I0912 04:25:04.961705 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996543
I0912 04:25:04.961710 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996858
I0912 04:25:04.961720 26285 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0912 04:25:21.643892 26285 solver.cpp:228] Iteration 1820, loss = 0.0133256
I0912 04:25:21.643939 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994252
I0912 04:25:21.643950 26285 solver.cpp:244]     Train net output #1: loss = 0.0133256 (* 1 = 0.0133256 loss)
I0912 04:25:21.643956 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987963
I0912 04:25:21.643961 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998896
I0912 04:25:21.643970 26285 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0912 04:25:38.324133 26285 solver.cpp:228] Iteration 1840, loss = 0.00708765
I0912 04:25:38.324275 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997606
I0912 04:25:38.324307 26285 solver.cpp:244]     Train net output #1: loss = 0.00708767 (* 1 = 0.00708767 loss)
I0912 04:25:38.324326 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997416
I0912 04:25:38.324332 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998397
I0912 04:25:38.324340 26285 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0912 04:25:54.997561 26285 solver.cpp:228] Iteration 1860, loss = 0.0105513
I0912 04:25:54.997612 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995558
I0912 04:25:54.997627 26285 solver.cpp:244]     Train net output #1: loss = 0.0105514 (* 1 = 0.0105514 loss)
I0912 04:25:54.997633 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993047
I0912 04:25:54.997638 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997984
I0912 04:25:54.997647 26285 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0912 04:26:11.668017 26285 solver.cpp:228] Iteration 1880, loss = 0.0134456
I0912 04:26:11.668145 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994903
I0912 04:26:11.668161 26285 solver.cpp:244]     Train net output #1: loss = 0.0134457 (* 1 = 0.0134457 loss)
I0912 04:26:11.668167 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995606
I0912 04:26:11.668172 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993176
I0912 04:26:11.668180 26285 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0912 04:26:28.338454 26285 solver.cpp:228] Iteration 1900, loss = 0.0123688
I0912 04:26:28.338501 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995174
I0912 04:26:28.338516 26285 solver.cpp:244]     Train net output #1: loss = 0.0123688 (* 1 = 0.0123688 loss)
I0912 04:26:28.338521 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99179
I0912 04:26:28.338526 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997869
I0912 04:26:28.338534 26285 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0912 04:26:45.015468 26285 solver.cpp:228] Iteration 1920, loss = 0.00764143
I0912 04:26:45.015661 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997203
I0912 04:26:45.015699 26285 solver.cpp:244]     Train net output #1: loss = 0.00764145 (* 1 = 0.00764145 loss)
I0912 04:26:45.015707 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997652
I0912 04:26:45.015717 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996237
I0912 04:26:45.015725 26285 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0912 04:27:01.695626 26285 solver.cpp:228] Iteration 1940, loss = 0.013188
I0912 04:27:01.695675 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994235
I0912 04:27:01.695693 26285 solver.cpp:244]     Train net output #1: loss = 0.013188 (* 1 = 0.013188 loss)
I0912 04:27:01.695700 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993357
I0912 04:27:01.695708 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996745
I0912 04:27:01.695716 26285 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0912 04:27:18.441124 26285 solver.cpp:228] Iteration 1960, loss = 0.00625896
I0912 04:27:18.441262 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998034
I0912 04:27:18.441280 26285 solver.cpp:244]     Train net output #1: loss = 0.00625898 (* 1 = 0.00625898 loss)
I0912 04:27:18.441287 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998787
I0912 04:27:18.441292 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995788
I0912 04:27:18.441300 26285 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0912 04:27:35.068713 26285 solver.cpp:228] Iteration 1980, loss = 0.00941941
I0912 04:27:35.068759 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996571
I0912 04:27:35.068774 26285 solver.cpp:244]     Train net output #1: loss = 0.00941943 (* 1 = 0.00941943 loss)
I0912 04:27:35.068780 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996698
I0912 04:27:35.068786 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996146
I0912 04:27:35.068794 26285 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0912 04:27:51.699672 26285 solver.cpp:228] Iteration 2000, loss = 0.0135081
I0912 04:27:51.699818 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994324
I0912 04:27:51.699842 26285 solver.cpp:244]     Train net output #1: loss = 0.0135081 (* 1 = 0.0135081 loss)
I0912 04:27:51.699852 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993979
I0912 04:27:51.699857 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995362
I0912 04:27:51.699867 26285 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0912 04:28:08.321270 26285 solver.cpp:228] Iteration 2020, loss = 0.0127867
I0912 04:28:08.321336 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996073
I0912 04:28:08.321350 26285 solver.cpp:244]     Train net output #1: loss = 0.0127867 (* 1 = 0.0127867 loss)
I0912 04:28:08.321357 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991297
I0912 04:28:08.321362 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998715
I0912 04:28:08.321374 26285 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0912 04:28:24.951530 26285 solver.cpp:228] Iteration 2040, loss = 0.00827279
I0912 04:28:24.951683 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997587
I0912 04:28:24.951723 26285 solver.cpp:244]     Train net output #1: loss = 0.00827281 (* 1 = 0.00827281 loss)
I0912 04:28:24.951731 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99861
I0912 04:28:24.951737 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992747
I0912 04:28:24.951746 26285 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0912 04:28:41.577100 26285 solver.cpp:228] Iteration 2060, loss = 0.0141675
I0912 04:28:41.577143 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994877
I0912 04:28:41.577155 26285 solver.cpp:244]     Train net output #1: loss = 0.0141676 (* 1 = 0.0141676 loss)
I0912 04:28:41.577162 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994189
I0912 04:28:41.577167 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995566
I0912 04:28:41.577173 26285 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0912 04:28:58.200814 26285 solver.cpp:228] Iteration 2080, loss = 0.0116433
I0912 04:28:58.200992 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995017
I0912 04:28:58.201020 26285 solver.cpp:244]     Train net output #1: loss = 0.0116433 (* 1 = 0.0116433 loss)
I0912 04:28:58.201028 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991952
I0912 04:28:58.201040 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998036
I0912 04:28:58.201055 26285 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0912 04:29:14.806799 26285 solver.cpp:228] Iteration 2100, loss = 0.010264
I0912 04:29:14.806839 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99498
I0912 04:29:14.806852 26285 solver.cpp:244]     Train net output #1: loss = 0.010264 (* 1 = 0.010264 loss)
I0912 04:29:14.806857 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99164
I0912 04:29:14.806862 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999027
I0912 04:29:14.806870 26285 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0912 04:29:31.422622 26285 solver.cpp:228] Iteration 2120, loss = 0.00995188
I0912 04:29:31.422726 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996296
I0912 04:29:31.422741 26285 solver.cpp:244]     Train net output #1: loss = 0.00995191 (* 1 = 0.00995191 loss)
I0912 04:29:31.422747 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994108
I0912 04:29:31.422751 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998064
I0912 04:29:31.422758 26285 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0912 04:29:48.026736 26285 solver.cpp:228] Iteration 2140, loss = 0.0134948
I0912 04:29:48.026778 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994052
I0912 04:29:48.026792 26285 solver.cpp:244]     Train net output #1: loss = 0.0134949 (* 1 = 0.0134949 loss)
I0912 04:29:48.026798 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993586
I0912 04:29:48.026803 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995281
I0912 04:29:48.026808 26285 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0912 04:30:04.644110 26285 solver.cpp:228] Iteration 2160, loss = 0.00951896
I0912 04:30:04.644214 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995755
I0912 04:30:04.644229 26285 solver.cpp:244]     Train net output #1: loss = 0.00951898 (* 1 = 0.00951898 loss)
I0912 04:30:04.644242 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994612
I0912 04:30:04.644253 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997844
I0912 04:30:04.644258 26285 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0912 04:30:21.240478 26285 solver.cpp:228] Iteration 2180, loss = 0.0107045
I0912 04:30:21.240521 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995104
I0912 04:30:21.240547 26285 solver.cpp:244]     Train net output #1: loss = 0.0107046 (* 1 = 0.0107046 loss)
I0912 04:30:21.240556 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992727
I0912 04:30:21.240561 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998161
I0912 04:30:21.240567 26285 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0912 04:30:37.848335 26285 solver.cpp:228] Iteration 2200, loss = 0.00814191
I0912 04:30:37.848500 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996904
I0912 04:30:37.848515 26285 solver.cpp:244]     Train net output #1: loss = 0.00814193 (* 1 = 0.00814193 loss)
I0912 04:30:37.848520 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997245
I0912 04:30:37.848525 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996111
I0912 04:30:37.848534 26285 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0912 04:30:54.593629 26285 solver.cpp:228] Iteration 2220, loss = 0.00848281
I0912 04:30:54.593672 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99627
I0912 04:30:54.593683 26285 solver.cpp:244]     Train net output #1: loss = 0.00848283 (* 1 = 0.00848283 loss)
I0912 04:30:54.593690 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995258
I0912 04:30:54.593696 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998184
I0912 04:30:54.593704 26285 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0912 04:31:11.195524 26285 solver.cpp:228] Iteration 2240, loss = 0.0142848
I0912 04:31:11.195629 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993736
I0912 04:31:11.195642 26285 solver.cpp:244]     Train net output #1: loss = 0.0142848 (* 1 = 0.0142848 loss)
I0912 04:31:11.195652 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991688
I0912 04:31:11.195657 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996861
I0912 04:31:11.195664 26285 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0912 04:31:27.801959 26285 solver.cpp:228] Iteration 2260, loss = 0.0122321
I0912 04:31:27.802000 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994702
I0912 04:31:27.802012 26285 solver.cpp:244]     Train net output #1: loss = 0.0122321 (* 1 = 0.0122321 loss)
I0912 04:31:27.802018 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994026
I0912 04:31:27.802023 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996434
I0912 04:31:27.802031 26285 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0912 04:31:44.418494 26285 solver.cpp:228] Iteration 2280, loss = 0.00573046
I0912 04:31:44.418603 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997554
I0912 04:31:44.418619 26285 solver.cpp:244]     Train net output #1: loss = 0.00573047 (* 1 = 0.00573047 loss)
I0912 04:31:44.418625 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996598
I0912 04:31:44.418637 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998911
I0912 04:31:44.418656 26285 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0912 04:32:01.022594 26285 solver.cpp:228] Iteration 2300, loss = 0.0120884
I0912 04:32:01.022634 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994887
I0912 04:32:01.022646 26285 solver.cpp:244]     Train net output #1: loss = 0.0120884 (* 1 = 0.0120884 loss)
I0912 04:32:01.022651 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991711
I0912 04:32:01.022662 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998095
I0912 04:32:01.022670 26285 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0912 04:32:17.633473 26285 solver.cpp:228] Iteration 2320, loss = 0.0110612
I0912 04:32:17.633581 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995174
I0912 04:32:17.633597 26285 solver.cpp:244]     Train net output #1: loss = 0.0110612 (* 1 = 0.0110612 loss)
I0912 04:32:17.633607 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994795
I0912 04:32:17.633613 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996127
I0912 04:32:17.633621 26285 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0912 04:32:34.241742 26285 solver.cpp:228] Iteration 2340, loss = 0.00515384
I0912 04:32:34.241778 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99794
I0912 04:32:34.241792 26285 solver.cpp:244]     Train net output #1: loss = 0.00515385 (* 1 = 0.00515385 loss)
I0912 04:32:34.241797 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996587
I0912 04:32:34.241802 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999218
I0912 04:32:34.241809 26285 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0912 04:32:50.849716 26285 solver.cpp:228] Iteration 2360, loss = 0.00698685
I0912 04:32:50.849871 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99742
I0912 04:32:50.849887 26285 solver.cpp:244]     Train net output #1: loss = 0.00698687 (* 1 = 0.00698687 loss)
I0912 04:32:50.849900 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997677
I0912 04:32:50.849905 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996425
I0912 04:32:50.849911 26285 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0912 04:33:07.459693 26285 solver.cpp:228] Iteration 2380, loss = 0.0126084
I0912 04:33:07.459736 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995001
I0912 04:33:07.459749 26285 solver.cpp:244]     Train net output #1: loss = 0.0126084 (* 1 = 0.0126084 loss)
I0912 04:33:07.459755 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994782
I0912 04:33:07.459760 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995354
I0912 04:33:07.459767 26285 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0912 04:33:24.081739 26285 solver.cpp:228] Iteration 2400, loss = 0.00834671
I0912 04:33:24.081841 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996727
I0912 04:33:24.081854 26285 solver.cpp:244]     Train net output #1: loss = 0.00834673 (* 1 = 0.00834673 loss)
I0912 04:33:24.081866 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995956
I0912 04:33:24.081876 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997743
I0912 04:33:24.081882 26285 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0912 04:33:40.687687 26285 solver.cpp:228] Iteration 2420, loss = 0.00406243
I0912 04:33:40.687727 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998536
I0912 04:33:40.687741 26285 solver.cpp:244]     Train net output #1: loss = 0.00406245 (* 1 = 0.00406245 loss)
I0912 04:33:40.687753 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998804
I0912 04:33:40.687758 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99794
I0912 04:33:40.687765 26285 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0912 04:33:57.307785 26285 solver.cpp:228] Iteration 2440, loss = 0.00449992
I0912 04:33:57.307893 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998009
I0912 04:33:57.307907 26285 solver.cpp:244]     Train net output #1: loss = 0.00449994 (* 1 = 0.00449994 loss)
I0912 04:33:57.307914 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997273
I0912 04:33:57.307919 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999121
I0912 04:33:57.307926 26285 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0912 04:34:13.900537 26285 solver.cpp:228] Iteration 2460, loss = 0.0120556
I0912 04:34:13.900573 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995242
I0912 04:34:13.900588 26285 solver.cpp:244]     Train net output #1: loss = 0.0120556 (* 1 = 0.0120556 loss)
I0912 04:34:13.900594 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993738
I0912 04:34:13.900599 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996919
I0912 04:34:13.900605 26285 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0912 04:34:30.505259 26285 solver.cpp:228] Iteration 2480, loss = 0.00903231
I0912 04:34:30.505353 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996325
I0912 04:34:30.505374 26285 solver.cpp:244]     Train net output #1: loss = 0.00903233 (* 1 = 0.00903233 loss)
I0912 04:34:30.505380 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993951
I0912 04:34:30.505385 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998309
I0912 04:34:30.505393 26285 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0912 04:34:47.104671 26285 solver.cpp:228] Iteration 2500, loss = 0.01437
I0912 04:34:47.104709 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994514
I0912 04:34:47.104722 26285 solver.cpp:244]     Train net output #1: loss = 0.01437 (* 1 = 0.01437 loss)
I0912 04:34:47.104728 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995588
I0912 04:34:47.104733 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99035
I0912 04:34:47.104740 26285 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0912 04:35:03.714275 26285 solver.cpp:228] Iteration 2520, loss = 0.00827192
I0912 04:35:03.714407 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996808
I0912 04:35:03.714442 26285 solver.cpp:244]     Train net output #1: loss = 0.00827193 (* 1 = 0.00827193 loss)
I0912 04:35:03.714449 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995797
I0912 04:35:03.714454 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997831
I0912 04:35:03.714465 26285 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0912 04:35:20.318416 26285 solver.cpp:228] Iteration 2540, loss = 0.0063042
I0912 04:35:20.318455 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997144
I0912 04:35:20.318469 26285 solver.cpp:244]     Train net output #1: loss = 0.00630422 (* 1 = 0.00630422 loss)
I0912 04:35:20.318473 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996061
I0912 04:35:20.318480 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998736
I0912 04:35:20.318487 26285 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0912 04:35:36.932664 26285 solver.cpp:228] Iteration 2560, loss = 0.0153635
I0912 04:35:36.932760 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994164
I0912 04:35:36.932776 26285 solver.cpp:244]     Train net output #1: loss = 0.0153635 (* 1 = 0.0153635 loss)
I0912 04:35:36.932790 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98679
I0912 04:35:36.932802 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99849
I0912 04:35:36.932811 26285 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0912 04:35:53.532833 26285 solver.cpp:228] Iteration 2580, loss = 0.00964336
I0912 04:35:53.532871 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995639
I0912 04:35:53.532884 26285 solver.cpp:244]     Train net output #1: loss = 0.00964338 (* 1 = 0.00964338 loss)
I0912 04:35:53.532889 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993615
I0912 04:35:53.532894 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998177
I0912 04:35:53.532902 26285 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0912 04:36:10.148001 26285 solver.cpp:228] Iteration 2600, loss = 0.0106833
I0912 04:36:10.148092 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995809
I0912 04:36:10.148108 26285 solver.cpp:244]     Train net output #1: loss = 0.0106833 (* 1 = 0.0106833 loss)
I0912 04:36:10.148119 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994367
I0912 04:36:10.148124 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997327
I0912 04:36:10.148131 26285 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0912 04:36:26.760864 26285 solver.cpp:228] Iteration 2620, loss = 0.00981201
I0912 04:36:26.760906 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995783
I0912 04:36:26.760918 26285 solver.cpp:244]     Train net output #1: loss = 0.00981202 (* 1 = 0.00981202 loss)
I0912 04:36:26.760924 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99308
I0912 04:36:26.760929 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998114
I0912 04:36:26.760937 26285 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0912 04:36:43.382568 26285 solver.cpp:228] Iteration 2640, loss = 0.0067658
I0912 04:36:43.382669 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997622
I0912 04:36:43.382683 26285 solver.cpp:244]     Train net output #1: loss = 0.00676582 (* 1 = 0.00676582 loss)
I0912 04:36:43.382689 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997587
I0912 04:36:43.382694 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997662
I0912 04:36:43.382702 26285 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0912 04:36:59.987923 26285 solver.cpp:228] Iteration 2660, loss = 0.00646731
I0912 04:36:59.987964 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996969
I0912 04:36:59.987978 26285 solver.cpp:244]     Train net output #1: loss = 0.00646733 (* 1 = 0.00646733 loss)
I0912 04:36:59.987984 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995954
I0912 04:36:59.987989 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998891
I0912 04:36:59.987996 26285 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0912 04:37:16.597960 26285 solver.cpp:228] Iteration 2680, loss = 0.0135316
I0912 04:37:16.598109 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994057
I0912 04:37:16.598125 26285 solver.cpp:244]     Train net output #1: loss = 0.0135316 (* 1 = 0.0135316 loss)
I0912 04:37:16.598135 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9916
I0912 04:37:16.598140 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997601
I0912 04:37:16.598146 26285 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0912 04:37:33.215893 26285 solver.cpp:228] Iteration 2700, loss = 0.0224951
I0912 04:37:33.215927 26285 solver.cpp:244]     Train net output #0: accuracy = 0.989711
I0912 04:37:33.215941 26285 solver.cpp:244]     Train net output #1: loss = 0.0224951 (* 1 = 0.0224951 loss)
I0912 04:37:33.215947 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.976669
I0912 04:37:33.215952 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999508
I0912 04:37:33.215960 26285 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0912 04:37:50.013754 26285 solver.cpp:228] Iteration 2720, loss = 0.0133472
I0912 04:37:50.013865 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995752
I0912 04:37:50.013881 26285 solver.cpp:244]     Train net output #1: loss = 0.0133472 (* 1 = 0.0133472 loss)
I0912 04:37:50.013886 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99495
I0912 04:37:50.013891 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99641
I0912 04:37:50.013898 26285 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0912 04:38:06.635257 26285 solver.cpp:228] Iteration 2740, loss = 0.0476177
I0912 04:38:06.635298 26285 solver.cpp:244]     Train net output #0: accuracy = 0.980373
I0912 04:38:06.635309 26285 solver.cpp:244]     Train net output #1: loss = 0.0476177 (* 1 = 0.0476177 loss)
I0912 04:38:06.635315 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969338
I0912 04:38:06.635320 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997389
I0912 04:38:06.635327 26285 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0912 04:38:23.236624 26285 solver.cpp:228] Iteration 2760, loss = 0.0264597
I0912 04:38:23.236729 26285 solver.cpp:244]     Train net output #0: accuracy = 0.988663
I0912 04:38:23.236745 26285 solver.cpp:244]     Train net output #1: loss = 0.0264597 (* 1 = 0.0264597 loss)
I0912 04:38:23.236757 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985031
I0912 04:38:23.236760 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997716
I0912 04:38:23.236768 26285 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0912 04:38:39.841083 26285 solver.cpp:228] Iteration 2780, loss = 0.0475996
I0912 04:38:39.841121 26285 solver.cpp:244]     Train net output #0: accuracy = 0.986564
I0912 04:38:39.841135 26285 solver.cpp:244]     Train net output #1: loss = 0.0475996 (* 1 = 0.0475996 loss)
I0912 04:38:39.841140 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985484
I0912 04:38:39.841145 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987887
I0912 04:38:39.841151 26285 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0912 04:38:56.440059 26285 solver.cpp:228] Iteration 2800, loss = 0.0264782
I0912 04:38:56.440220 26285 solver.cpp:244]     Train net output #0: accuracy = 0.989413
I0912 04:38:56.440238 26285 solver.cpp:244]     Train net output #1: loss = 0.0264783 (* 1 = 0.0264783 loss)
I0912 04:38:56.440244 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982204
I0912 04:38:56.440255 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996158
I0912 04:38:56.440263 26285 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0912 04:39:13.056820 26285 solver.cpp:228] Iteration 2820, loss = 0.0446143
I0912 04:39:13.056856 26285 solver.cpp:244]     Train net output #0: accuracy = 0.987433
I0912 04:39:13.056871 26285 solver.cpp:244]     Train net output #1: loss = 0.0446143 (* 1 = 0.0446143 loss)
I0912 04:39:13.056885 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986855
I0912 04:39:13.056890 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98796
I0912 04:39:13.056897 26285 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0912 04:39:29.657922 26285 solver.cpp:228] Iteration 2840, loss = 0.0145209
I0912 04:39:29.658037 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995972
I0912 04:39:29.658052 26285 solver.cpp:244]     Train net output #1: loss = 0.014521 (* 1 = 0.014521 loss)
I0912 04:39:29.658062 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997515
I0912 04:39:29.658067 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990223
I0912 04:39:29.658074 26285 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0912 04:39:46.277801 26285 solver.cpp:228] Iteration 2860, loss = 0.00772734
I0912 04:39:46.277842 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997473
I0912 04:39:46.277855 26285 solver.cpp:244]     Train net output #1: loss = 0.00772736 (* 1 = 0.00772736 loss)
I0912 04:39:46.277869 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997313
I0912 04:39:46.277879 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997645
I0912 04:39:46.277887 26285 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0912 04:40:02.887665 26285 solver.cpp:228] Iteration 2880, loss = 0.0145183
I0912 04:40:02.887751 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994048
I0912 04:40:02.887764 26285 solver.cpp:244]     Train net output #1: loss = 0.0145183 (* 1 = 0.0145183 loss)
I0912 04:40:02.887770 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993217
I0912 04:40:02.887774 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9958
I0912 04:40:02.887781 26285 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0912 04:40:19.500049 26285 solver.cpp:228] Iteration 2900, loss = 0.0127408
I0912 04:40:19.500093 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995058
I0912 04:40:19.500108 26285 solver.cpp:244]     Train net output #1: loss = 0.0127409 (* 1 = 0.0127409 loss)
I0912 04:40:19.500114 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995193
I0912 04:40:19.500121 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994536
I0912 04:40:19.500129 26285 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0912 04:40:36.098799 26285 solver.cpp:228] Iteration 2920, loss = 0.0100734
I0912 04:40:36.098892 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995331
I0912 04:40:36.098906 26285 solver.cpp:244]     Train net output #1: loss = 0.0100735 (* 1 = 0.0100735 loss)
I0912 04:40:36.098912 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992319
I0912 04:40:36.098925 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999719
I0912 04:40:36.098932 26285 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0912 04:40:52.703725 26285 solver.cpp:228] Iteration 2940, loss = 0.00821495
I0912 04:40:52.703761 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99661
I0912 04:40:52.703774 26285 solver.cpp:244]     Train net output #1: loss = 0.00821497 (* 1 = 0.00821497 loss)
I0912 04:40:52.703780 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995908
I0912 04:40:52.703785 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997928
I0912 04:40:52.703794 26285 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0912 04:41:09.315078 26285 solver.cpp:228] Iteration 2960, loss = 0.00818463
I0912 04:41:09.315227 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996882
I0912 04:41:09.315248 26285 solver.cpp:244]     Train net output #1: loss = 0.00818465 (* 1 = 0.00818465 loss)
I0912 04:41:09.315255 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996657
I0912 04:41:09.315260 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998045
I0912 04:41:09.315268 26285 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0912 04:41:25.913413 26285 solver.cpp:228] Iteration 2980, loss = 0.0172926
I0912 04:41:25.913452 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99242
I0912 04:41:25.913465 26285 solver.cpp:244]     Train net output #1: loss = 0.0172926 (* 1 = 0.0172926 loss)
I0912 04:41:25.913470 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989738
I0912 04:41:25.913475 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997196
I0912 04:41:25.913483 26285 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0912 04:41:42.515700 26285 solver.cpp:228] Iteration 3000, loss = 0.0170795
I0912 04:41:42.515791 26285 solver.cpp:244]     Train net output #0: accuracy = 0.992361
I0912 04:41:42.515805 26285 solver.cpp:244]     Train net output #1: loss = 0.0170795 (* 1 = 0.0170795 loss)
I0912 04:41:42.515811 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985083
I0912 04:41:42.515815 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998389
I0912 04:41:42.515822 26285 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0912 04:41:59.129767 26285 solver.cpp:228] Iteration 3020, loss = 0.00743694
I0912 04:41:59.129806 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996726
I0912 04:41:59.129820 26285 solver.cpp:244]     Train net output #1: loss = 0.00743696 (* 1 = 0.00743696 loss)
I0912 04:41:59.129825 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994663
I0912 04:41:59.129832 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99909
I0912 04:41:59.129838 26285 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0912 04:42:15.729758 26285 solver.cpp:228] Iteration 3040, loss = 0.0159004
I0912 04:42:15.729846 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993584
I0912 04:42:15.729861 26285 solver.cpp:244]     Train net output #1: loss = 0.0159005 (* 1 = 0.0159005 loss)
I0912 04:42:15.729868 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985409
I0912 04:42:15.729873 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99879
I0912 04:42:15.729882 26285 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0912 04:42:32.341737 26285 solver.cpp:228] Iteration 3060, loss = 0.00769586
I0912 04:42:32.341773 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997089
I0912 04:42:32.341787 26285 solver.cpp:244]     Train net output #1: loss = 0.00769588 (* 1 = 0.00769588 loss)
I0912 04:42:32.341794 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997182
I0912 04:42:32.341799 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996757
I0912 04:42:32.341805 26285 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0912 04:42:48.934170 26285 solver.cpp:228] Iteration 3080, loss = 0.0127488
I0912 04:42:48.934299 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995192
I0912 04:42:48.934340 26285 solver.cpp:244]     Train net output #1: loss = 0.0127488 (* 1 = 0.0127488 loss)
I0912 04:42:48.934350 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99534
I0912 04:42:48.934360 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994969
I0912 04:42:48.934368 26285 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0912 04:43:05.530941 26285 solver.cpp:228] Iteration 3100, loss = 0.00649247
I0912 04:43:05.530988 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998352
I0912 04:43:05.531002 26285 solver.cpp:244]     Train net output #1: loss = 0.00649249 (* 1 = 0.00649249 loss)
I0912 04:43:05.531010 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998353
I0912 04:43:05.531014 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998346
I0912 04:43:05.531023 26285 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0912 04:43:22.117944 26285 solver.cpp:228] Iteration 3120, loss = 0.0090927
I0912 04:43:22.118098 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996428
I0912 04:43:22.118113 26285 solver.cpp:244]     Train net output #1: loss = 0.00909272 (* 1 = 0.00909272 loss)
I0912 04:43:22.118126 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99655
I0912 04:43:22.118131 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996044
I0912 04:43:22.118139 26285 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0912 04:43:38.709640 26285 solver.cpp:228] Iteration 3140, loss = 0.0114091
I0912 04:43:38.709682 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995933
I0912 04:43:38.709697 26285 solver.cpp:244]     Train net output #1: loss = 0.0114092 (* 1 = 0.0114092 loss)
I0912 04:43:38.709703 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996684
I0912 04:43:38.709709 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99308
I0912 04:43:38.709717 26285 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0912 04:43:55.311529 26285 solver.cpp:228] Iteration 3160, loss = 0.0115489
I0912 04:43:55.311662 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996238
I0912 04:43:55.311703 26285 solver.cpp:244]     Train net output #1: loss = 0.0115489 (* 1 = 0.0115489 loss)
I0912 04:43:55.311713 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997327
I0912 04:43:55.311722 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994924
I0912 04:43:55.311731 26285 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0912 04:44:12.012154 26285 solver.cpp:228] Iteration 3180, loss = 0.00853949
I0912 04:44:12.012197 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99668
I0912 04:44:12.012210 26285 solver.cpp:244]     Train net output #1: loss = 0.00853951 (* 1 = 0.00853951 loss)
I0912 04:44:12.012217 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996038
I0912 04:44:12.012223 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997488
I0912 04:44:12.012230 26285 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0912 04:44:28.653784 26285 solver.cpp:228] Iteration 3200, loss = 0.00886106
I0912 04:44:28.653903 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995982
I0912 04:44:28.653919 26285 solver.cpp:244]     Train net output #1: loss = 0.00886108 (* 1 = 0.00886108 loss)
I0912 04:44:28.653925 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9925
I0912 04:44:28.653929 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999338
I0912 04:44:28.653937 26285 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0912 04:44:45.264575 26285 solver.cpp:228] Iteration 3220, loss = 0.00749859
I0912 04:44:45.264616 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996416
I0912 04:44:45.264628 26285 solver.cpp:244]     Train net output #1: loss = 0.0074986 (* 1 = 0.0074986 loss)
I0912 04:44:45.264634 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994704
I0912 04:44:45.264641 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999135
I0912 04:44:45.264647 26285 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0912 04:45:01.881094 26285 solver.cpp:228] Iteration 3240, loss = 0.0123745
I0912 04:45:01.881206 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99566
I0912 04:45:01.881222 26285 solver.cpp:244]     Train net output #1: loss = 0.0123745 (* 1 = 0.0123745 loss)
I0912 04:45:01.881234 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991492
I0912 04:45:01.881239 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998284
I0912 04:45:01.881247 26285 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0912 04:45:18.490396 26285 solver.cpp:228] Iteration 3260, loss = 0.0143951
I0912 04:45:18.490435 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994566
I0912 04:45:18.490447 26285 solver.cpp:244]     Train net output #1: loss = 0.0143951 (* 1 = 0.0143951 loss)
I0912 04:45:18.490453 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995204
I0912 04:45:18.490458 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99351
I0912 04:45:18.490464 26285 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0912 04:45:35.120234 26285 solver.cpp:228] Iteration 3280, loss = 0.00743974
I0912 04:45:35.120399 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99646
I0912 04:45:35.120416 26285 solver.cpp:244]     Train net output #1: loss = 0.00743976 (* 1 = 0.00743976 loss)
I0912 04:45:35.120425 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994877
I0912 04:45:35.120431 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999149
I0912 04:45:35.120441 26285 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0912 04:45:51.744885 26285 solver.cpp:228] Iteration 3300, loss = 0.00570423
I0912 04:45:51.744923 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997517
I0912 04:45:51.744937 26285 solver.cpp:244]     Train net output #1: loss = 0.00570425 (* 1 = 0.00570425 loss)
I0912 04:45:51.744942 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99657
I0912 04:45:51.744948 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998962
I0912 04:45:51.744956 26285 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0912 04:46:08.364758 26285 solver.cpp:228] Iteration 3320, loss = 0.0123731
I0912 04:46:08.364884 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996011
I0912 04:46:08.364923 26285 solver.cpp:244]     Train net output #1: loss = 0.0123731 (* 1 = 0.0123731 loss)
I0912 04:46:08.364931 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991943
I0912 04:46:08.364938 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998309
I0912 04:46:08.364946 26285 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0912 04:46:25.000578 26285 solver.cpp:228] Iteration 3340, loss = 0.00543198
I0912 04:46:25.000622 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998027
I0912 04:46:25.000635 26285 solver.cpp:244]     Train net output #1: loss = 0.005432 (* 1 = 0.005432 loss)
I0912 04:46:25.000641 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998145
I0912 04:46:25.000646 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99757
I0912 04:46:25.000653 26285 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0912 04:46:41.619491 26285 solver.cpp:228] Iteration 3360, loss = 0.0123379
I0912 04:46:41.619603 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994831
I0912 04:46:41.619617 26285 solver.cpp:244]     Train net output #1: loss = 0.0123379 (* 1 = 0.0123379 loss)
I0912 04:46:41.619624 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992087
I0912 04:46:41.619637 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9973
I0912 04:46:41.619644 26285 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0912 04:46:58.246315 26285 solver.cpp:228] Iteration 3380, loss = 0.0101955
I0912 04:46:58.246359 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995476
I0912 04:46:58.246373 26285 solver.cpp:244]     Train net output #1: loss = 0.0101955 (* 1 = 0.0101955 loss)
I0912 04:46:58.246381 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994559
I0912 04:46:58.246387 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997214
I0912 04:46:58.246395 26285 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0912 04:47:14.907626 26285 solver.cpp:228] Iteration 3400, loss = 0.0114549
I0912 04:47:14.907814 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994544
I0912 04:47:14.907829 26285 solver.cpp:244]     Train net output #1: loss = 0.0114549 (* 1 = 0.0114549 loss)
I0912 04:47:14.907835 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992623
I0912 04:47:14.907840 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997765
I0912 04:47:14.907847 26285 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0912 04:47:31.519569 26285 solver.cpp:228] Iteration 3420, loss = 0.00668399
I0912 04:47:31.519605 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997159
I0912 04:47:31.519620 26285 solver.cpp:244]     Train net output #1: loss = 0.00668401 (* 1 = 0.00668401 loss)
I0912 04:47:31.519626 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995828
I0912 04:47:31.519630 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998642
I0912 04:47:31.519639 26285 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0912 04:47:48.125875 26285 solver.cpp:228] Iteration 3440, loss = 0.00356811
I0912 04:47:48.125991 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998252
I0912 04:47:48.126008 26285 solver.cpp:244]     Train net output #1: loss = 0.00356813 (* 1 = 0.00356813 loss)
I0912 04:47:48.126014 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997605
I0912 04:47:48.126024 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999668
I0912 04:47:48.126031 26285 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0912 04:48:04.720741 26285 solver.cpp:228] Iteration 3460, loss = 0.0131995
I0912 04:48:04.720782 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994333
I0912 04:48:04.720793 26285 solver.cpp:244]     Train net output #1: loss = 0.0131995 (* 1 = 0.0131995 loss)
I0912 04:48:04.720799 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993263
I0912 04:48:04.720804 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996412
I0912 04:48:04.720811 26285 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0912 04:48:21.335324 26285 solver.cpp:228] Iteration 3480, loss = 0.00706386
I0912 04:48:21.335448 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997027
I0912 04:48:21.335464 26285 solver.cpp:244]     Train net output #1: loss = 0.00706388 (* 1 = 0.00706388 loss)
I0912 04:48:21.335471 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996881
I0912 04:48:21.335477 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997424
I0912 04:48:21.335484 26285 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0912 04:48:37.947707 26285 solver.cpp:228] Iteration 3500, loss = 0.00866246
I0912 04:48:37.947746 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99672
I0912 04:48:37.947759 26285 solver.cpp:244]     Train net output #1: loss = 0.00866248 (* 1 = 0.00866248 loss)
I0912 04:48:37.947765 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997092
I0912 04:48:37.947770 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995981
I0912 04:48:37.947778 26285 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0912 04:48:54.551627 26285 solver.cpp:228] Iteration 3520, loss = 0.00582969
I0912 04:48:54.551758 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99758
I0912 04:48:54.551774 26285 solver.cpp:244]     Train net output #1: loss = 0.00582971 (* 1 = 0.00582971 loss)
I0912 04:48:54.551785 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99684
I0912 04:48:54.551791 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998699
I0912 04:48:54.551800 26285 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0912 04:49:11.167621 26285 solver.cpp:228] Iteration 3540, loss = 0.00485645
I0912 04:49:11.167656 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998174
I0912 04:49:11.167670 26285 solver.cpp:244]     Train net output #1: loss = 0.00485647 (* 1 = 0.00485647 loss)
I0912 04:49:11.167677 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997788
I0912 04:49:11.167683 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998625
I0912 04:49:11.167690 26285 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0912 04:49:27.781494 26285 solver.cpp:228] Iteration 3560, loss = 0.00935722
I0912 04:49:27.781671 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99594
I0912 04:49:27.781687 26285 solver.cpp:244]     Train net output #1: loss = 0.00935724 (* 1 = 0.00935724 loss)
I0912 04:49:27.781692 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993911
I0912 04:49:27.781697 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998365
I0912 04:49:27.781704 26285 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0912 04:49:44.401288 26285 solver.cpp:228] Iteration 3580, loss = 0.0104238
I0912 04:49:44.401329 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996178
I0912 04:49:44.401342 26285 solver.cpp:244]     Train net output #1: loss = 0.0104238 (* 1 = 0.0104238 loss)
I0912 04:49:44.401348 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996859
I0912 04:49:44.401352 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994818
I0912 04:49:44.401360 26285 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0912 04:50:01.018357 26285 solver.cpp:228] Iteration 3600, loss = 0.00669072
I0912 04:50:01.018471 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997473
I0912 04:50:01.018486 26285 solver.cpp:244]     Train net output #1: loss = 0.00669074 (* 1 = 0.00669074 loss)
I0912 04:50:01.018491 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997741
I0912 04:50:01.018496 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996935
I0912 04:50:01.018503 26285 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0912 04:50:17.618762 26285 solver.cpp:228] Iteration 3620, loss = 0.00740019
I0912 04:50:17.618804 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996924
I0912 04:50:17.618818 26285 solver.cpp:244]     Train net output #1: loss = 0.00740021 (* 1 = 0.00740021 loss)
I0912 04:50:17.618825 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996191
I0912 04:50:17.618831 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997901
I0912 04:50:17.618839 26285 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0912 04:50:34.226737 26285 solver.cpp:228] Iteration 3640, loss = 0.00636415
I0912 04:50:34.226850 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997133
I0912 04:50:34.226863 26285 solver.cpp:244]     Train net output #1: loss = 0.00636418 (* 1 = 0.00636418 loss)
I0912 04:50:34.226869 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996576
I0912 04:50:34.226874 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998585
I0912 04:50:34.226882 26285 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0912 04:50:50.872375 26285 solver.cpp:228] Iteration 3660, loss = 0.00572396
I0912 04:50:50.872416 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997794
I0912 04:50:50.872427 26285 solver.cpp:244]     Train net output #1: loss = 0.00572398 (* 1 = 0.00572398 loss)
I0912 04:50:50.872433 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99772
I0912 04:50:50.872438 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997998
I0912 04:50:50.872445 26285 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0912 04:51:07.485494 26285 solver.cpp:228] Iteration 3680, loss = 0.0141343
I0912 04:51:07.485651 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993507
I0912 04:51:07.485693 26285 solver.cpp:244]     Train net output #1: loss = 0.0141344 (* 1 = 0.0141344 loss)
I0912 04:51:07.485702 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988617
I0912 04:51:07.485713 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998422
I0912 04:51:07.485721 26285 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0912 04:51:24.093978 26285 solver.cpp:228] Iteration 3700, loss = 0.0201702
I0912 04:51:24.094018 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996273
I0912 04:51:24.094032 26285 solver.cpp:244]     Train net output #1: loss = 0.0201703 (* 1 = 0.0201703 loss)
I0912 04:51:24.094038 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996174
I0912 04:51:24.094043 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997642
I0912 04:51:24.094049 26285 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0912 04:51:40.735908 26285 solver.cpp:228] Iteration 3720, loss = 0.00604662
I0912 04:51:40.736105 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997179
I0912 04:51:40.736124 26285 solver.cpp:244]     Train net output #1: loss = 0.00604664 (* 1 = 0.00604664 loss)
I0912 04:51:40.736135 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996088
I0912 04:51:40.736140 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999151
I0912 04:51:40.736147 26285 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0912 04:51:57.342541 26285 solver.cpp:228] Iteration 3740, loss = 0.00893738
I0912 04:51:57.342579 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995812
I0912 04:51:57.342592 26285 solver.cpp:244]     Train net output #1: loss = 0.0089374 (* 1 = 0.0089374 loss)
I0912 04:51:57.342598 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990851
I0912 04:51:57.342603 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999472
I0912 04:51:57.342610 26285 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0912 04:52:13.959228 26285 solver.cpp:228] Iteration 3760, loss = 0.00362113
I0912 04:52:13.959349 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998818
I0912 04:52:13.959365 26285 solver.cpp:244]     Train net output #1: loss = 0.00362115 (* 1 = 0.00362115 loss)
I0912 04:52:13.959372 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998806
I0912 04:52:13.959377 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99887
I0912 04:52:13.959383 26285 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0912 04:52:30.554616 26285 solver.cpp:228] Iteration 3780, loss = 0.00693558
I0912 04:52:30.554661 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996758
I0912 04:52:30.554674 26285 solver.cpp:244]     Train net output #1: loss = 0.0069356 (* 1 = 0.0069356 loss)
I0912 04:52:30.554682 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995679
I0912 04:52:30.554687 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998772
I0912 04:52:30.554697 26285 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0912 04:52:47.178951 26285 solver.cpp:228] Iteration 3800, loss = 0.003852
I0912 04:52:47.179093 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998581
I0912 04:52:47.179107 26285 solver.cpp:244]     Train net output #1: loss = 0.00385202 (* 1 = 0.00385202 loss)
I0912 04:52:47.179113 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998481
I0912 04:52:47.179118 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998708
I0912 04:52:47.179126 26285 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0912 04:53:03.779999 26285 solver.cpp:228] Iteration 3820, loss = 0.00943242
I0912 04:53:03.780040 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995897
I0912 04:53:03.780055 26285 solver.cpp:244]     Train net output #1: loss = 0.00943245 (* 1 = 0.00943245 loss)
I0912 04:53:03.780061 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994778
I0912 04:53:03.780066 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997597
I0912 04:53:03.780076 26285 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0912 04:53:20.390151 26285 solver.cpp:228] Iteration 3840, loss = 0.00983073
I0912 04:53:20.390333 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99614
I0912 04:53:20.390349 26285 solver.cpp:244]     Train net output #1: loss = 0.00983075 (* 1 = 0.00983075 loss)
I0912 04:53:20.390355 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993653
I0912 04:53:20.390360 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998042
I0912 04:53:20.390367 26285 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0912 04:53:37.012473 26285 solver.cpp:228] Iteration 3860, loss = 0.00589476
I0912 04:53:37.012516 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997781
I0912 04:53:37.012529 26285 solver.cpp:244]     Train net output #1: loss = 0.00589479 (* 1 = 0.00589479 loss)
I0912 04:53:37.012536 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997106
I0912 04:53:37.012540 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998459
I0912 04:53:37.012547 26285 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0912 04:53:53.613955 26285 solver.cpp:228] Iteration 3880, loss = 0.0126449
I0912 04:53:53.614101 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994899
I0912 04:53:53.614142 26285 solver.cpp:244]     Train net output #1: loss = 0.0126449 (* 1 = 0.0126449 loss)
I0912 04:53:53.614152 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995368
I0912 04:53:53.614161 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993847
I0912 04:53:53.614171 26285 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0912 04:54:10.343369 26285 solver.cpp:228] Iteration 3900, loss = 0.0156872
I0912 04:54:10.343416 26285 solver.cpp:244]     Train net output #0: accuracy = 0.994729
I0912 04:54:10.343436 26285 solver.cpp:244]     Train net output #1: loss = 0.0156872 (* 1 = 0.0156872 loss)
I0912 04:54:10.343449 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994952
I0912 04:54:10.343459 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994477
I0912 04:54:10.343467 26285 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0912 04:54:27.026017 26285 solver.cpp:228] Iteration 3920, loss = 0.00865328
I0912 04:54:27.026155 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996785
I0912 04:54:27.026171 26285 solver.cpp:244]     Train net output #1: loss = 0.0086533 (* 1 = 0.0086533 loss)
I0912 04:54:27.026176 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995989
I0912 04:54:27.026181 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997622
I0912 04:54:27.026190 26285 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0912 04:54:43.644218 26285 solver.cpp:228] Iteration 3940, loss = 0.00644574
I0912 04:54:43.644260 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997192
I0912 04:54:43.644275 26285 solver.cpp:244]     Train net output #1: loss = 0.00644576 (* 1 = 0.00644576 loss)
I0912 04:54:43.644281 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99667
I0912 04:54:43.644287 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998092
I0912 04:54:43.644294 26285 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0912 04:55:00.253518 26285 solver.cpp:228] Iteration 3960, loss = 0.00457404
I0912 04:55:00.253649 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998144
I0912 04:55:00.253666 26285 solver.cpp:244]     Train net output #1: loss = 0.00457406 (* 1 = 0.00457406 loss)
I0912 04:55:00.253674 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9982
I0912 04:55:00.253679 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997979
I0912 04:55:00.253687 26285 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0912 04:55:16.858980 26285 solver.cpp:228] Iteration 3980, loss = 0.00763734
I0912 04:55:16.859020 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99685
I0912 04:55:16.859033 26285 solver.cpp:244]     Train net output #1: loss = 0.00763737 (* 1 = 0.00763737 loss)
I0912 04:55:16.859040 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996673
I0912 04:55:16.859045 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997327
I0912 04:55:16.859052 26285 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0912 04:55:33.480314 26285 solver.cpp:228] Iteration 4000, loss = 0.010822
I0912 04:55:33.480499 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995713
I0912 04:55:33.480514 26285 solver.cpp:244]     Train net output #1: loss = 0.0108221 (* 1 = 0.0108221 loss)
I0912 04:55:33.480520 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996208
I0912 04:55:33.480525 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994074
I0912 04:55:33.480531 26285 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0912 04:55:50.081750 26285 solver.cpp:228] Iteration 4020, loss = 0.0068543
I0912 04:55:50.081790 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996703
I0912 04:55:50.081802 26285 solver.cpp:244]     Train net output #1: loss = 0.00685433 (* 1 = 0.00685433 loss)
I0912 04:55:50.081809 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99604
I0912 04:55:50.081814 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998195
I0912 04:55:50.081822 26285 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0912 04:56:06.691267 26285 solver.cpp:228] Iteration 4040, loss = 0.00524737
I0912 04:56:06.691399 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997633
I0912 04:56:06.691416 26285 solver.cpp:244]     Train net output #1: loss = 0.0052474 (* 1 = 0.0052474 loss)
I0912 04:56:06.691421 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995602
I0912 04:56:06.691426 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999505
I0912 04:56:06.691434 26285 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0912 04:56:23.302659 26285 solver.cpp:228] Iteration 4060, loss = 0.00807518
I0912 04:56:23.302701 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99611
I0912 04:56:23.302716 26285 solver.cpp:244]     Train net output #1: loss = 0.00807521 (* 1 = 0.00807521 loss)
I0912 04:56:23.302723 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995084
I0912 04:56:23.302729 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998219
I0912 04:56:23.302737 26285 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0912 04:56:39.904685 26285 solver.cpp:228] Iteration 4080, loss = 0.00993339
I0912 04:56:39.904809 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995451
I0912 04:56:39.904824 26285 solver.cpp:244]     Train net output #1: loss = 0.00993342 (* 1 = 0.00993342 loss)
I0912 04:56:39.904830 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99296
I0912 04:56:39.904844 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998301
I0912 04:56:39.904852 26285 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0912 04:56:56.504725 26285 solver.cpp:228] Iteration 4100, loss = 0.00790996
I0912 04:56:56.504768 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996832
I0912 04:56:56.504782 26285 solver.cpp:244]     Train net output #1: loss = 0.00790998 (* 1 = 0.00790998 loss)
I0912 04:56:56.504791 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995457
I0912 04:56:56.504796 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998204
I0912 04:56:56.504804 26285 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0912 04:57:13.122864 26285 solver.cpp:228] Iteration 4120, loss = 0.0097616
I0912 04:57:13.122982 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996157
I0912 04:57:13.122997 26285 solver.cpp:244]     Train net output #1: loss = 0.00976162 (* 1 = 0.00976162 loss)
I0912 04:57:13.123003 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989795
I0912 04:57:13.123008 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999478
I0912 04:57:13.123014 26285 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0912 04:57:29.722532 26285 solver.cpp:228] Iteration 4140, loss = 0.0084188
I0912 04:57:29.722574 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996405
I0912 04:57:29.722590 26285 solver.cpp:244]     Train net output #1: loss = 0.00841883 (* 1 = 0.00841883 loss)
I0912 04:57:29.722596 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995566
I0912 04:57:29.722600 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997777
I0912 04:57:29.722609 26285 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0912 04:57:46.402281 26285 solver.cpp:228] Iteration 4160, loss = 0.0037659
I0912 04:57:46.402468 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998435
I0912 04:57:46.402508 26285 solver.cpp:244]     Train net output #1: loss = 0.00376593 (* 1 = 0.00376593 loss)
I0912 04:57:46.402515 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998217
I0912 04:57:46.402520 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998932
I0912 04:57:46.402529 26285 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0912 04:58:03.091264 26285 solver.cpp:228] Iteration 4180, loss = 0.00916099
I0912 04:58:03.091315 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995476
I0912 04:58:03.091336 26285 solver.cpp:244]     Train net output #1: loss = 0.00916101 (* 1 = 0.00916101 loss)
I0912 04:58:03.091347 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99019
I0912 04:58:03.091357 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999544
I0912 04:58:03.091365 26285 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0912 04:58:19.784972 26285 solver.cpp:228] Iteration 4200, loss = 0.00773382
I0912 04:58:19.785086 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997496
I0912 04:58:19.785102 26285 solver.cpp:244]     Train net output #1: loss = 0.00773384 (* 1 = 0.00773384 loss)
I0912 04:58:19.785107 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993815
I0912 04:58:19.785112 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999393
I0912 04:58:19.785121 26285 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0912 04:58:36.485656 26285 solver.cpp:228] Iteration 4220, loss = 0.00620412
I0912 04:58:36.485736 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997151
I0912 04:58:36.485754 26285 solver.cpp:244]     Train net output #1: loss = 0.00620415 (* 1 = 0.00620415 loss)
I0912 04:58:36.485769 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995707
I0912 04:58:36.485779 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998931
I0912 04:58:36.485786 26285 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0912 04:58:53.175081 26285 solver.cpp:228] Iteration 4240, loss = 0.0054737
I0912 04:58:53.175166 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997403
I0912 04:58:53.175185 26285 solver.cpp:244]     Train net output #1: loss = 0.00547373 (* 1 = 0.00547373 loss)
I0912 04:58:53.175195 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996322
I0912 04:58:53.175204 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999149
I0912 04:58:53.175215 26285 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0912 04:59:09.883342 26285 solver.cpp:228] Iteration 4260, loss = 0.00585289
I0912 04:59:09.883393 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997872
I0912 04:59:09.883409 26285 solver.cpp:244]     Train net output #1: loss = 0.00585292 (* 1 = 0.00585292 loss)
I0912 04:59:09.883421 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998341
I0912 04:59:09.883430 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996123
I0912 04:59:09.883440 26285 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0912 04:59:26.573351 26285 solver.cpp:228] Iteration 4280, loss = 0.0108273
I0912 04:59:26.573457 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995441
I0912 04:59:26.573482 26285 solver.cpp:244]     Train net output #1: loss = 0.0108273 (* 1 = 0.0108273 loss)
I0912 04:59:26.573492 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990314
I0912 04:59:26.573501 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998779
I0912 04:59:26.573515 26285 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0912 04:59:43.255060 26285 solver.cpp:228] Iteration 4300, loss = 0.00882966
I0912 04:59:43.255108 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995871
I0912 04:59:43.255126 26285 solver.cpp:244]     Train net output #1: loss = 0.00882968 (* 1 = 0.00882968 loss)
I0912 04:59:43.255134 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992843
I0912 04:59:43.255141 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998747
I0912 04:59:43.255149 26285 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0912 04:59:59.908282 26285 solver.cpp:228] Iteration 4320, loss = 0.0141735
I0912 04:59:59.908473 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993837
I0912 04:59:59.908529 26285 solver.cpp:244]     Train net output #1: loss = 0.0141736 (* 1 = 0.0141736 loss)
I0912 04:59:59.908540 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992307
I0912 04:59:59.908550 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997269
I0912 04:59:59.908556 26285 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0912 05:00:16.550930 26285 solver.cpp:228] Iteration 4340, loss = 0.00996342
I0912 05:00:16.550978 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995833
I0912 05:00:16.550993 26285 solver.cpp:244]     Train net output #1: loss = 0.00996344 (* 1 = 0.00996344 loss)
I0912 05:00:16.550999 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993902
I0912 05:00:16.551005 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997926
I0912 05:00:16.551015 26285 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0912 05:00:33.198400 26285 solver.cpp:228] Iteration 4360, loss = 0.00870679
I0912 05:00:33.198503 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996237
I0912 05:00:33.198518 26285 solver.cpp:244]     Train net output #1: loss = 0.00870681 (* 1 = 0.00870681 loss)
I0912 05:00:33.198525 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996074
I0912 05:00:33.198530 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996649
I0912 05:00:33.198539 26285 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0912 05:00:49.848078 26285 solver.cpp:228] Iteration 4380, loss = 0.00524677
I0912 05:00:49.848127 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99764
I0912 05:00:49.848142 26285 solver.cpp:244]     Train net output #1: loss = 0.0052468 (* 1 = 0.0052468 loss)
I0912 05:00:49.848150 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997034
I0912 05:00:49.848155 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998784
I0912 05:00:49.848162 26285 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0912 05:01:06.543540 26285 solver.cpp:228] Iteration 4400, loss = 0.00848516
I0912 05:01:06.543678 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996438
I0912 05:01:06.543706 26285 solver.cpp:244]     Train net output #1: loss = 0.00848519 (* 1 = 0.00848519 loss)
I0912 05:01:06.543715 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99585
I0912 05:01:06.543720 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997316
I0912 05:01:06.543726 26285 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0912 05:01:23.206717 26285 solver.cpp:228] Iteration 4420, loss = 0.00854
I0912 05:01:23.206766 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996969
I0912 05:01:23.206784 26285 solver.cpp:244]     Train net output #1: loss = 0.00854002 (* 1 = 0.00854002 loss)
I0912 05:01:23.206795 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997237
I0912 05:01:23.206801 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995524
I0912 05:01:23.206810 26285 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0912 05:01:39.840821 26285 solver.cpp:228] Iteration 4440, loss = 0.00935661
I0912 05:01:39.841029 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995799
I0912 05:01:39.841049 26285 solver.cpp:244]     Train net output #1: loss = 0.00935664 (* 1 = 0.00935664 loss)
I0912 05:01:39.841065 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991695
I0912 05:01:39.841075 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998931
I0912 05:01:39.841092 26285 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0912 05:01:56.469103 26285 solver.cpp:228] Iteration 4460, loss = 0.00466852
I0912 05:01:56.469163 26285 solver.cpp:244]     Train net output #0: accuracy = 0.99784
I0912 05:01:56.469177 26285 solver.cpp:244]     Train net output #1: loss = 0.00466854 (* 1 = 0.00466854 loss)
I0912 05:01:56.469184 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997292
I0912 05:01:56.469190 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999086
I0912 05:01:56.469198 26285 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0912 05:02:13.111435 26285 solver.cpp:228] Iteration 4480, loss = 0.0088962
I0912 05:02:13.111557 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996166
I0912 05:02:13.111580 26285 solver.cpp:244]     Train net output #1: loss = 0.00889622 (* 1 = 0.00889622 loss)
I0912 05:02:13.111593 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995974
I0912 05:02:13.111605 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996706
I0912 05:02:13.111620 26285 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0912 05:02:29.756017 26285 solver.cpp:228] Iteration 4500, loss = 0.00560286
I0912 05:02:29.756070 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997925
I0912 05:02:29.756083 26285 solver.cpp:244]     Train net output #1: loss = 0.00560288 (* 1 = 0.00560288 loss)
I0912 05:02:29.756090 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998334
I0912 05:02:29.756095 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996629
I0912 05:02:29.756104 26285 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0912 05:02:46.412222 26285 solver.cpp:228] Iteration 4520, loss = 0.00576486
I0912 05:02:46.412361 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997283
I0912 05:02:46.412397 26285 solver.cpp:244]     Train net output #1: loss = 0.00576489 (* 1 = 0.00576489 loss)
I0912 05:02:46.412406 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996059
I0912 05:02:46.412416 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998938
I0912 05:02:46.412423 26285 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0912 05:03:03.075317 26285 solver.cpp:228] Iteration 4540, loss = 0.00530006
I0912 05:03:03.075366 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997649
I0912 05:03:03.075382 26285 solver.cpp:244]     Train net output #1: loss = 0.00530009 (* 1 = 0.00530009 loss)
I0912 05:03:03.075390 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996992
I0912 05:03:03.075403 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99869
I0912 05:03:03.075412 26285 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0912 05:03:19.696560 26285 solver.cpp:228] Iteration 4560, loss = 0.00844474
I0912 05:03:19.696686 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996046
I0912 05:03:19.696702 26285 solver.cpp:244]     Train net output #1: loss = 0.00844477 (* 1 = 0.00844477 loss)
I0912 05:03:19.696714 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994727
I0912 05:03:19.696720 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998754
I0912 05:03:19.696727 26285 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0912 05:03:36.306159 26285 solver.cpp:228] Iteration 4580, loss = 0.0576274
I0912 05:03:36.306205 26285 solver.cpp:244]     Train net output #0: accuracy = 0.985263
I0912 05:03:36.306218 26285 solver.cpp:244]     Train net output #1: loss = 0.0576274 (* 1 = 0.0576274 loss)
I0912 05:03:36.306223 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973591
I0912 05:03:36.306228 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998941
I0912 05:03:36.306236 26285 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0912 05:03:52.917130 26285 solver.cpp:228] Iteration 4600, loss = 0.0230251
I0912 05:03:52.917297 26285 solver.cpp:244]     Train net output #0: accuracy = 0.991678
I0912 05:03:52.917315 26285 solver.cpp:244]     Train net output #1: loss = 0.0230251 (* 1 = 0.0230251 loss)
I0912 05:03:52.917326 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988578
I0912 05:03:52.917332 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999452
I0912 05:03:52.917340 26285 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0912 05:04:09.526643 26285 solver.cpp:228] Iteration 4620, loss = 0.00793159
I0912 05:04:09.526690 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996685
I0912 05:04:09.526703 26285 solver.cpp:244]     Train net output #1: loss = 0.00793159 (* 1 = 0.00793159 loss)
I0912 05:04:09.526710 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995661
I0912 05:04:09.526726 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998287
I0912 05:04:09.526739 26285 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0912 05:04:26.157393 26285 solver.cpp:228] Iteration 4640, loss = 0.0136028
I0912 05:04:26.157534 26285 solver.cpp:244]     Train net output #0: accuracy = 0.993827
I0912 05:04:26.157575 26285 solver.cpp:244]     Train net output #1: loss = 0.0136028 (* 1 = 0.0136028 loss)
I0912 05:04:26.157584 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987806
I0912 05:04:26.157594 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999372
I0912 05:04:26.157604 26285 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0912 05:04:42.786906 26285 solver.cpp:228] Iteration 4660, loss = 0.0120229
I0912 05:04:42.786950 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995032
I0912 05:04:42.786965 26285 solver.cpp:244]     Train net output #1: loss = 0.0120229 (* 1 = 0.0120229 loss)
I0912 05:04:42.786976 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994286
I0912 05:04:42.786989 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996241
I0912 05:04:42.787004 26285 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0912 05:04:59.423168 26285 solver.cpp:228] Iteration 4680, loss = 0.00659404
I0912 05:04:59.423295 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997416
I0912 05:04:59.423336 26285 solver.cpp:244]     Train net output #1: loss = 0.00659405 (* 1 = 0.00659405 loss)
I0912 05:04:59.423346 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997239
I0912 05:04:59.423355 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997872
I0912 05:04:59.423364 26285 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0912 05:05:16.027793 26285 solver.cpp:228] Iteration 4700, loss = 0.00796241
I0912 05:05:16.027838 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996654
I0912 05:05:16.027853 26285 solver.cpp:244]     Train net output #1: loss = 0.00796242 (* 1 = 0.00796242 loss)
I0912 05:05:16.027860 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994753
I0912 05:05:16.027866 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998699
I0912 05:05:16.027874 26285 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0912 05:05:32.656201 26285 solver.cpp:228] Iteration 4720, loss = 0.0106577
I0912 05:05:32.656330 26285 solver.cpp:244]     Train net output #0: accuracy = 0.995709
I0912 05:05:32.656368 26285 solver.cpp:244]     Train net output #1: loss = 0.0106577 (* 1 = 0.0106577 loss)
I0912 05:05:32.656375 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995631
I0912 05:05:32.656386 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996053
I0912 05:05:32.656394 26285 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0912 05:05:49.306884 26285 solver.cpp:228] Iteration 4740, loss = 0.00270652
I0912 05:05:49.306926 26285 solver.cpp:244]     Train net output #0: accuracy = 0.999109
I0912 05:05:49.306941 26285 solver.cpp:244]     Train net output #1: loss = 0.00270652 (* 1 = 0.00270652 loss)
I0912 05:05:49.306946 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999223
I0912 05:05:49.306951 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998869
I0912 05:05:49.306958 26285 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0912 05:06:05.916817 26285 solver.cpp:228] Iteration 4760, loss = 0.00871801
I0912 05:06:05.917006 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996578
I0912 05:06:05.917045 26285 solver.cpp:244]     Train net output #1: loss = 0.00871802 (* 1 = 0.00871802 loss)
I0912 05:06:05.917055 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994119
I0912 05:06:05.917065 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998649
I0912 05:06:05.917073 26285 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0912 05:06:22.586411 26285 solver.cpp:228] Iteration 4780, loss = 0.00593389
I0912 05:06:22.586457 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997616
I0912 05:06:22.586470 26285 solver.cpp:244]     Train net output #1: loss = 0.0059339 (* 1 = 0.0059339 loss)
I0912 05:06:22.586477 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997762
I0912 05:06:22.586482 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997066
I0912 05:06:22.586488 26285 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0912 05:06:39.203487 26285 solver.cpp:228] Iteration 4800, loss = 0.00655582
I0912 05:06:39.203598 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997486
I0912 05:06:39.203613 26285 solver.cpp:244]     Train net output #1: loss = 0.00655582 (* 1 = 0.00655582 loss)
I0912 05:06:39.203621 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997467
I0912 05:06:39.203634 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997523
I0912 05:06:39.203644 26285 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0912 05:06:55.819856 26285 solver.cpp:228] Iteration 4820, loss = 0.00832122
I0912 05:06:55.819895 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996521
I0912 05:06:55.819908 26285 solver.cpp:244]     Train net output #1: loss = 0.00832123 (* 1 = 0.00832123 loss)
I0912 05:06:55.819914 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993755
I0912 05:06:55.819919 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998847
I0912 05:06:55.819926 26285 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0912 05:07:12.460549 26285 solver.cpp:228] Iteration 4840, loss = 0.00619591
I0912 05:07:12.460698 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997624
I0912 05:07:12.460757 26285 solver.cpp:244]     Train net output #1: loss = 0.00619591 (* 1 = 0.00619591 loss)
I0912 05:07:12.460767 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996032
I0912 05:07:12.460777 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99902
I0912 05:07:12.460788 26285 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0912 05:07:29.126139 26285 solver.cpp:228] Iteration 4860, loss = 0.00440654
I0912 05:07:29.126183 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998216
I0912 05:07:29.126197 26285 solver.cpp:244]     Train net output #1: loss = 0.00440654 (* 1 = 0.00440654 loss)
I0912 05:07:29.126204 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997947
I0912 05:07:29.126209 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998631
I0912 05:07:29.126216 26285 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0912 05:07:45.785248 26285 solver.cpp:228] Iteration 4880, loss = 0.0054994
I0912 05:07:45.785401 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998132
I0912 05:07:45.785423 26285 solver.cpp:244]     Train net output #1: loss = 0.00549941 (* 1 = 0.00549941 loss)
I0912 05:07:45.785434 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998291
I0912 05:07:45.785440 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997944
I0912 05:07:45.785450 26285 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0912 05:08:02.462126 26285 solver.cpp:228] Iteration 4900, loss = 0.00725923
I0912 05:08:02.462170 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997037
I0912 05:08:02.462184 26285 solver.cpp:244]     Train net output #1: loss = 0.00725924 (* 1 = 0.00725924 loss)
I0912 05:08:02.462190 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996672
I0912 05:08:02.462196 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99765
I0912 05:08:02.462203 26285 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0912 05:08:19.069463 26285 solver.cpp:228] Iteration 4920, loss = 0.00812091
I0912 05:08:19.069604 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996522
I0912 05:08:19.069644 26285 solver.cpp:244]     Train net output #1: loss = 0.00812092 (* 1 = 0.00812092 loss)
I0912 05:08:19.069653 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996128
I0912 05:08:19.069664 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997392
I0912 05:08:19.069671 26285 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0912 05:08:35.753743 26285 solver.cpp:228] Iteration 4940, loss = 0.00848027
I0912 05:08:35.753795 26285 solver.cpp:244]     Train net output #0: accuracy = 0.996387
I0912 05:08:35.753813 26285 solver.cpp:244]     Train net output #1: loss = 0.00848028 (* 1 = 0.00848028 loss)
I0912 05:08:35.753821 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994948
I0912 05:08:35.753828 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998328
I0912 05:08:35.753836 26285 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0912 05:08:52.418014 26285 solver.cpp:228] Iteration 4960, loss = 0.00558058
I0912 05:08:52.418118 26285 solver.cpp:244]     Train net output #0: accuracy = 0.997293
I0912 05:08:52.418133 26285 solver.cpp:244]     Train net output #1: loss = 0.00558059 (* 1 = 0.00558059 loss)
I0912 05:08:52.418140 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996287
I0912 05:08:52.418145 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999099
I0912 05:08:52.418154 26285 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0912 05:09:09.095221 26285 solver.cpp:228] Iteration 4980, loss = 0.00344007
I0912 05:09:09.095284 26285 solver.cpp:244]     Train net output #0: accuracy = 0.998553
I0912 05:09:09.095304 26285 solver.cpp:244]     Train net output #1: loss = 0.00344008 (* 1 = 0.00344008 loss)
I0912 05:09:09.095310 26285 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99838
I0912 05:09:09.095316 26285 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999001
I0912 05:09:09.095325 26285 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0912 05:09:25.410740 26285 solver.cpp:454] Snapshotting to binary proto file pocwisc5/training_iter_5000.caffemodel
I0912 05:09:26.471078 26285 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc5/training_iter_5000.solverstate
I0912 05:09:27.073554 26285 solver.cpp:317] Iteration 5000, loss = 0.00463264
I0912 05:09:27.073609 26285 solver.cpp:322] Optimization Done.
I0912 05:09:27.073614 26285 caffe.cpp:254] Optimization Done.

2017-09-12 05:09:27,485 log.framework MainThread  INFO       caffe models found
pocwisc5/training_iter_5000.caffemodel
2017-09-12 05:09:27,486 log.framework MainThread  INFO       Caffe model found: pocwisc5/training_iter_5000.caffemodel
2017-09-12 05:09:29,498 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 05:09:29,639 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 05:09:29,782 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 05:09:29,923 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 05:09:30,071 log.framework MainThread  INFO       train file number: 31
2017-09-12 05:09:30,071 log.framework MainThread  INFO       test file number: 2
2017-09-12 05:09:30,072 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 05:09:30,072 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 05:09:30,072 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-09-12 05:09:30,096 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-09-12 05:09:30,096 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-09-12 05:09:30,097 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc6/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc6/training"
solver_mode: GPU

2017-09-12 05:09:30,098 log.framework MainThread  INFO       caffe training step
2017-09-12 05:09:30,098 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc6/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-09-12 06:18:55,128 log.framework MainThread  INFO       I0912 05:09:30.164474 26718 caffe.cpp:217] Using GPUs 0
I0912 05:09:30.176033 26718 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0912 05:09:30.709267 26718 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc6/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc6/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0912 05:09:30.709447 26718 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc6/caffe/model_segnet_final/train.prototxt
I0912 05:09:30.712244 26718 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc6/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 05:09:30.712759 26718 layer_factory.hpp:77] Creating layer data
I0912 05:09:30.712779 26718 net.cpp:100] Creating Layer data
I0912 05:09:30.712790 26718 net.cpp:408] data -> data
I0912 05:09:30.712821 26718 net.cpp:408] data -> label
I0912 05:09:30.712841 26718 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc6/HDF5Files/train_combined.txt
I0912 05:09:30.712903 26718 hdf5_data_layer.cpp:93] Number of HDF5 files: 31
I0912 05:09:30.714103 26718 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0912 05:09:30.738834 26718 net.cpp:150] Setting up data
I0912 05:09:30.738862 26718 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 05:09:30.738868 26718 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 05:09:30.738871 26718 net.cpp:165] Memory required for data: 24883200
I0912 05:09:30.738879 26718 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 05:09:30.738893 26718 net.cpp:100] Creating Layer label_data_1_split
I0912 05:09:30.738903 26718 net.cpp:434] label_data_1_split <- label
I0912 05:09:30.738915 26718 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 05:09:30.738927 26718 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 05:09:30.738970 26718 net.cpp:150] Setting up label_data_1_split
I0912 05:09:30.738976 26718 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 05:09:30.738981 26718 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 05:09:30.738984 26718 net.cpp:165] Memory required for data: 30412800
I0912 05:09:30.738988 26718 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 05:09:30.739007 26718 net.cpp:100] Creating Layer conv1_1_1
I0912 05:09:30.739012 26718 net.cpp:434] conv1_1_1 <- data
I0912 05:09:30.739018 26718 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 05:09:31.257016 26718 net.cpp:150] Setting up conv1_1_1
I0912 05:09:31.257050 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:31.257055 26718 net.cpp:165] Memory required for data: 207360000
I0912 05:09:31.257081 26718 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 05:09:31.257097 26718 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 05:09:31.257103 26718 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 05:09:31.257110 26718 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 05:09:31.257519 26718 net.cpp:150] Setting up conv1_1_1_bn
I0912 05:09:31.257529 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:31.257534 26718 net.cpp:165] Memory required for data: 384307200
I0912 05:09:31.257545 26718 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 05:09:31.257556 26718 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 05:09:31.257562 26718 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 05:09:31.257567 26718 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 05:09:31.257616 26718 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 05:09:31.259227 26718 net.cpp:150] Setting up conv1_1_1_scale
I0912 05:09:31.259243 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:31.259250 26718 net.cpp:165] Memory required for data: 561254400
I0912 05:09:31.259259 26718 layer_factory.hpp:77] Creating layer relu1_1
I0912 05:09:31.259271 26718 net.cpp:100] Creating Layer relu1_1
I0912 05:09:31.259277 26718 net.cpp:434] relu1_1 <- conv1_1_1
I0912 05:09:31.259284 26718 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 05:09:31.259511 26718 net.cpp:150] Setting up relu1_1
I0912 05:09:31.259521 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:31.259526 26718 net.cpp:165] Memory required for data: 738201600
I0912 05:09:31.259531 26718 layer_factory.hpp:77] Creating layer conv1_2
I0912 05:09:31.259542 26718 net.cpp:100] Creating Layer conv1_2
I0912 05:09:31.259547 26718 net.cpp:434] conv1_2 <- conv1_1_1
I0912 05:09:31.259553 26718 net.cpp:408] conv1_2 -> conv1_2
I0912 05:09:31.263718 26718 net.cpp:150] Setting up conv1_2
I0912 05:09:31.263736 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:31.263744 26718 net.cpp:165] Memory required for data: 915148800
I0912 05:09:31.263756 26718 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 05:09:31.263767 26718 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 05:09:31.263774 26718 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 05:09:31.263779 26718 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 05:09:31.265292 26718 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 05:09:31.265307 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:31.265316 26718 net.cpp:165] Memory required for data: 1092096000
I0912 05:09:31.265326 26718 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 05:09:31.265336 26718 net.cpp:100] Creating Layer conv1_2_scale
I0912 05:09:31.265341 26718 net.cpp:434] conv1_2_scale <- conv1_2
I0912 05:09:31.265347 26718 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 05:09:31.265398 26718 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 05:09:31.265772 26718 net.cpp:150] Setting up conv1_2_scale
I0912 05:09:31.265781 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:31.265785 26718 net.cpp:165] Memory required for data: 1269043200
I0912 05:09:31.265794 26718 layer_factory.hpp:77] Creating layer relu1_2
I0912 05:09:31.265801 26718 net.cpp:100] Creating Layer relu1_2
I0912 05:09:31.265806 26718 net.cpp:434] relu1_2 <- conv1_2
I0912 05:09:31.265811 26718 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 05:09:31.266000 26718 net.cpp:150] Setting up relu1_2
I0912 05:09:31.266010 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:31.266013 26718 net.cpp:165] Memory required for data: 1445990400
I0912 05:09:31.266019 26718 layer_factory.hpp:77] Creating layer pool1
I0912 05:09:31.266024 26718 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 05:09:31.266031 26718 net.cpp:100] Creating Layer pool1
I0912 05:09:31.266034 26718 net.cpp:434] pool1 <- conv1_2
I0912 05:09:31.266041 26718 net.cpp:408] pool1 -> pool1
I0912 05:09:31.266048 26718 net.cpp:408] pool1 -> pool1_mask
I0912 05:09:31.266103 26718 net.cpp:150] Setting up pool1
I0912 05:09:31.266109 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:31.266114 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:31.266118 26718 net.cpp:165] Memory required for data: 1534464000
I0912 05:09:31.266121 26718 layer_factory.hpp:77] Creating layer conv2_1
I0912 05:09:31.266131 26718 net.cpp:100] Creating Layer conv2_1
I0912 05:09:31.266136 26718 net.cpp:434] conv2_1 <- pool1
I0912 05:09:31.266142 26718 net.cpp:408] conv2_1 -> conv2_1
I0912 05:09:31.272212 26718 net.cpp:150] Setting up conv2_1
I0912 05:09:31.272228 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:31.272238 26718 net.cpp:165] Memory required for data: 1622937600
I0912 05:09:31.272245 26718 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 05:09:31.272253 26718 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 05:09:31.272260 26718 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 05:09:31.272265 26718 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 05:09:31.272487 26718 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 05:09:31.272495 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:31.272500 26718 net.cpp:165] Memory required for data: 1711411200
I0912 05:09:31.272511 26718 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 05:09:31.272536 26718 net.cpp:100] Creating Layer conv2_1_scale
I0912 05:09:31.272539 26718 net.cpp:434] conv2_1_scale <- conv2_1
I0912 05:09:31.272544 26718 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 05:09:31.272588 26718 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 05:09:31.272759 26718 net.cpp:150] Setting up conv2_1_scale
I0912 05:09:31.272768 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:31.272771 26718 net.cpp:165] Memory required for data: 1799884800
I0912 05:09:31.272778 26718 layer_factory.hpp:77] Creating layer relu2_1
I0912 05:09:31.272785 26718 net.cpp:100] Creating Layer relu2_1
I0912 05:09:31.272790 26718 net.cpp:434] relu2_1 <- conv2_1
I0912 05:09:31.272795 26718 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 05:09:31.273818 26718 net.cpp:150] Setting up relu2_1
I0912 05:09:31.273833 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:31.273839 26718 net.cpp:165] Memory required for data: 1888358400
I0912 05:09:31.273844 26718 layer_factory.hpp:77] Creating layer conv2_2
I0912 05:09:31.273854 26718 net.cpp:100] Creating Layer conv2_2
I0912 05:09:31.273860 26718 net.cpp:434] conv2_2 <- conv2_1
I0912 05:09:31.273866 26718 net.cpp:408] conv2_2 -> conv2_2
I0912 05:09:31.281224 26718 net.cpp:150] Setting up conv2_2
I0912 05:09:31.281239 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:31.281249 26718 net.cpp:165] Memory required for data: 1976832000
I0912 05:09:31.281256 26718 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 05:09:31.281265 26718 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 05:09:31.281271 26718 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 05:09:31.281277 26718 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 05:09:31.281510 26718 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 05:09:31.281519 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:31.281523 26718 net.cpp:165] Memory required for data: 2065305600
I0912 05:09:31.281530 26718 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 05:09:31.281538 26718 net.cpp:100] Creating Layer conv2_2_scale
I0912 05:09:31.281545 26718 net.cpp:434] conv2_2_scale <- conv2_2
I0912 05:09:31.281550 26718 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 05:09:31.281594 26718 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 05:09:31.281766 26718 net.cpp:150] Setting up conv2_2_scale
I0912 05:09:31.281775 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:31.281779 26718 net.cpp:165] Memory required for data: 2153779200
I0912 05:09:31.281785 26718 layer_factory.hpp:77] Creating layer relu2_2
I0912 05:09:31.281792 26718 net.cpp:100] Creating Layer relu2_2
I0912 05:09:31.281797 26718 net.cpp:434] relu2_2 <- conv2_2
I0912 05:09:31.281802 26718 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 05:09:31.281996 26718 net.cpp:150] Setting up relu2_2
I0912 05:09:31.282003 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:31.282007 26718 net.cpp:165] Memory required for data: 2242252800
I0912 05:09:31.282011 26718 layer_factory.hpp:77] Creating layer pool2
I0912 05:09:31.282016 26718 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 05:09:31.282022 26718 net.cpp:100] Creating Layer pool2
I0912 05:09:31.282025 26718 net.cpp:434] pool2 <- conv2_2
I0912 05:09:31.282033 26718 net.cpp:408] pool2 -> pool2
I0912 05:09:31.282042 26718 net.cpp:408] pool2 -> pool2_mask
I0912 05:09:31.282083 26718 net.cpp:150] Setting up pool2
I0912 05:09:31.282090 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:31.282095 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:31.282099 26718 net.cpp:165] Memory required for data: 2286489600
I0912 05:09:31.282104 26718 layer_factory.hpp:77] Creating layer conv3_1
I0912 05:09:31.282112 26718 net.cpp:100] Creating Layer conv3_1
I0912 05:09:31.282117 26718 net.cpp:434] conv3_1 <- pool2
I0912 05:09:31.282124 26718 net.cpp:408] conv3_1 -> conv3_1
I0912 05:09:31.294342 26718 net.cpp:150] Setting up conv3_1
I0912 05:09:31.294370 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.294380 26718 net.cpp:165] Memory required for data: 2330726400
I0912 05:09:31.294389 26718 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 05:09:31.294395 26718 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 05:09:31.294402 26718 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 05:09:31.294409 26718 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 05:09:31.294616 26718 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 05:09:31.294625 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.294628 26718 net.cpp:165] Memory required for data: 2374963200
I0912 05:09:31.294641 26718 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 05:09:31.294649 26718 net.cpp:100] Creating Layer conv3_1_scale
I0912 05:09:31.294657 26718 net.cpp:434] conv3_1_scale <- conv3_1
I0912 05:09:31.294662 26718 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 05:09:31.294701 26718 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 05:09:31.294833 26718 net.cpp:150] Setting up conv3_1_scale
I0912 05:09:31.294842 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.294845 26718 net.cpp:165] Memory required for data: 2419200000
I0912 05:09:31.294852 26718 layer_factory.hpp:77] Creating layer relu3_1
I0912 05:09:31.294858 26718 net.cpp:100] Creating Layer relu3_1
I0912 05:09:31.294862 26718 net.cpp:434] relu3_1 <- conv3_1
I0912 05:09:31.294869 26718 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 05:09:31.295061 26718 net.cpp:150] Setting up relu3_1
I0912 05:09:31.295070 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.295073 26718 net.cpp:165] Memory required for data: 2463436800
I0912 05:09:31.295078 26718 layer_factory.hpp:77] Creating layer conv3_2
I0912 05:09:31.295089 26718 net.cpp:100] Creating Layer conv3_2
I0912 05:09:31.295094 26718 net.cpp:434] conv3_2 <- conv3_1
I0912 05:09:31.295101 26718 net.cpp:408] conv3_2 -> conv3_2
I0912 05:09:31.318342 26718 net.cpp:150] Setting up conv3_2
I0912 05:09:31.318361 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.318372 26718 net.cpp:165] Memory required for data: 2507673600
I0912 05:09:31.318380 26718 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 05:09:31.318387 26718 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 05:09:31.318397 26718 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 05:09:31.318401 26718 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 05:09:31.318611 26718 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 05:09:31.318619 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.318624 26718 net.cpp:165] Memory required for data: 2551910400
I0912 05:09:31.318631 26718 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 05:09:31.318645 26718 net.cpp:100] Creating Layer conv3_2_scale
I0912 05:09:31.318655 26718 net.cpp:434] conv3_2_scale <- conv3_2
I0912 05:09:31.318660 26718 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 05:09:31.318698 26718 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 05:09:31.318831 26718 net.cpp:150] Setting up conv3_2_scale
I0912 05:09:31.318840 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.318843 26718 net.cpp:165] Memory required for data: 2596147200
I0912 05:09:31.318850 26718 layer_factory.hpp:77] Creating layer relu3_2
I0912 05:09:31.318856 26718 net.cpp:100] Creating Layer relu3_2
I0912 05:09:31.318861 26718 net.cpp:434] relu3_2 <- conv3_2
I0912 05:09:31.318866 26718 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 05:09:31.319061 26718 net.cpp:150] Setting up relu3_2
I0912 05:09:31.319070 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.319074 26718 net.cpp:165] Memory required for data: 2640384000
I0912 05:09:31.319077 26718 layer_factory.hpp:77] Creating layer conv3_3
I0912 05:09:31.319089 26718 net.cpp:100] Creating Layer conv3_3
I0912 05:09:31.319094 26718 net.cpp:434] conv3_3 <- conv3_2
I0912 05:09:31.319100 26718 net.cpp:408] conv3_3 -> conv3_3
I0912 05:09:31.342355 26718 net.cpp:150] Setting up conv3_3
I0912 05:09:31.342386 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.342394 26718 net.cpp:165] Memory required for data: 2684620800
I0912 05:09:31.342403 26718 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 05:09:31.342411 26718 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 05:09:31.342419 26718 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 05:09:31.342425 26718 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 05:09:31.342635 26718 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 05:09:31.342643 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.342648 26718 net.cpp:165] Memory required for data: 2728857600
I0912 05:09:31.342654 26718 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 05:09:31.342663 26718 net.cpp:100] Creating Layer conv3_3_scale
I0912 05:09:31.342669 26718 net.cpp:434] conv3_3_scale <- conv3_3
I0912 05:09:31.342674 26718 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 05:09:31.342712 26718 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 05:09:31.342847 26718 net.cpp:150] Setting up conv3_3_scale
I0912 05:09:31.342855 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.342859 26718 net.cpp:165] Memory required for data: 2773094400
I0912 05:09:31.342864 26718 layer_factory.hpp:77] Creating layer relu3_3
I0912 05:09:31.342872 26718 net.cpp:100] Creating Layer relu3_3
I0912 05:09:31.342877 26718 net.cpp:434] relu3_3 <- conv3_3
I0912 05:09:31.342882 26718 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 05:09:31.343078 26718 net.cpp:150] Setting up relu3_3
I0912 05:09:31.343087 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:31.343091 26718 net.cpp:165] Memory required for data: 2817331200
I0912 05:09:31.343096 26718 layer_factory.hpp:77] Creating layer pool3
I0912 05:09:31.343101 26718 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 05:09:31.343109 26718 net.cpp:100] Creating Layer pool3
I0912 05:09:31.343114 26718 net.cpp:434] pool3 <- conv3_3
I0912 05:09:31.343120 26718 net.cpp:408] pool3 -> pool3
I0912 05:09:31.343129 26718 net.cpp:408] pool3 -> pool3_mask
I0912 05:09:31.343175 26718 net.cpp:150] Setting up pool3
I0912 05:09:31.343183 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:31.343188 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:31.343192 26718 net.cpp:165] Memory required for data: 2839449600
I0912 05:09:31.343196 26718 layer_factory.hpp:77] Creating layer conv4_1
I0912 05:09:31.343206 26718 net.cpp:100] Creating Layer conv4_1
I0912 05:09:31.343211 26718 net.cpp:434] conv4_1 <- pool3
I0912 05:09:31.343217 26718 net.cpp:408] conv4_1 -> conv4_1
I0912 05:09:31.389222 26718 net.cpp:150] Setting up conv4_1
I0912 05:09:31.389240 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.389245 26718 net.cpp:165] Memory required for data: 2861568000
I0912 05:09:31.389252 26718 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 05:09:31.389261 26718 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 05:09:31.389271 26718 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 05:09:31.389277 26718 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 05:09:31.389493 26718 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 05:09:31.389502 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.389505 26718 net.cpp:165] Memory required for data: 2883686400
I0912 05:09:31.389513 26718 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 05:09:31.389521 26718 net.cpp:100] Creating Layer conv4_1_scale
I0912 05:09:31.389528 26718 net.cpp:434] conv4_1_scale <- conv4_1
I0912 05:09:31.389533 26718 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 05:09:31.389576 26718 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 05:09:31.389698 26718 net.cpp:150] Setting up conv4_1_scale
I0912 05:09:31.389706 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.389709 26718 net.cpp:165] Memory required for data: 2905804800
I0912 05:09:31.389715 26718 layer_factory.hpp:77] Creating layer relu4_1
I0912 05:09:31.389735 26718 net.cpp:100] Creating Layer relu4_1
I0912 05:09:31.389741 26718 net.cpp:434] relu4_1 <- conv4_1
I0912 05:09:31.389746 26718 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 05:09:31.389950 26718 net.cpp:150] Setting up relu4_1
I0912 05:09:31.389957 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.389961 26718 net.cpp:165] Memory required for data: 2927923200
I0912 05:09:31.389966 26718 layer_factory.hpp:77] Creating layer conv4_2
I0912 05:09:31.389976 26718 net.cpp:100] Creating Layer conv4_2
I0912 05:09:31.389981 26718 net.cpp:434] conv4_2 <- conv4_1
I0912 05:09:31.389987 26718 net.cpp:408] conv4_2 -> conv4_2
I0912 05:09:31.473836 26718 net.cpp:150] Setting up conv4_2
I0912 05:09:31.473853 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.473857 26718 net.cpp:165] Memory required for data: 2950041600
I0912 05:09:31.473865 26718 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 05:09:31.473872 26718 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 05:09:31.473877 26718 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 05:09:31.473883 26718 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 05:09:31.474089 26718 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 05:09:31.474097 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.474100 26718 net.cpp:165] Memory required for data: 2972160000
I0912 05:09:31.474108 26718 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 05:09:31.474122 26718 net.cpp:100] Creating Layer conv4_2_scale
I0912 05:09:31.474130 26718 net.cpp:434] conv4_2_scale <- conv4_2
I0912 05:09:31.474135 26718 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 05:09:31.474174 26718 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 05:09:31.474297 26718 net.cpp:150] Setting up conv4_2_scale
I0912 05:09:31.474303 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.474308 26718 net.cpp:165] Memory required for data: 2994278400
I0912 05:09:31.474313 26718 layer_factory.hpp:77] Creating layer relu4_2
I0912 05:09:31.474323 26718 net.cpp:100] Creating Layer relu4_2
I0912 05:09:31.474328 26718 net.cpp:434] relu4_2 <- conv4_2
I0912 05:09:31.474334 26718 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 05:09:31.475374 26718 net.cpp:150] Setting up relu4_2
I0912 05:09:31.475389 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.475394 26718 net.cpp:165] Memory required for data: 3016396800
I0912 05:09:31.475399 26718 layer_factory.hpp:77] Creating layer conv4_3
I0912 05:09:31.475409 26718 net.cpp:100] Creating Layer conv4_3
I0912 05:09:31.475414 26718 net.cpp:434] conv4_3 <- conv4_2
I0912 05:09:31.475422 26718 net.cpp:408] conv4_3 -> conv4_3
I0912 05:09:31.559324 26718 net.cpp:150] Setting up conv4_3
I0912 05:09:31.559340 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.559345 26718 net.cpp:165] Memory required for data: 3038515200
I0912 05:09:31.559366 26718 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 05:09:31.559376 26718 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 05:09:31.559386 26718 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 05:09:31.559391 26718 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 05:09:31.559605 26718 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 05:09:31.559613 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.559617 26718 net.cpp:165] Memory required for data: 3060633600
I0912 05:09:31.559625 26718 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 05:09:31.559634 26718 net.cpp:100] Creating Layer conv4_3_scale
I0912 05:09:31.559643 26718 net.cpp:434] conv4_3_scale <- conv4_3
I0912 05:09:31.559648 26718 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 05:09:31.559693 26718 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 05:09:31.559823 26718 net.cpp:150] Setting up conv4_3_scale
I0912 05:09:31.559829 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.559833 26718 net.cpp:165] Memory required for data: 3082752000
I0912 05:09:31.559839 26718 layer_factory.hpp:77] Creating layer relu4_3
I0912 05:09:31.559860 26718 net.cpp:100] Creating Layer relu4_3
I0912 05:09:31.559866 26718 net.cpp:434] relu4_3 <- conv4_3
I0912 05:09:31.559871 26718 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 05:09:31.560073 26718 net.cpp:150] Setting up relu4_3
I0912 05:09:31.560081 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:31.560086 26718 net.cpp:165] Memory required for data: 3104870400
I0912 05:09:31.560088 26718 layer_factory.hpp:77] Creating layer pool4
I0912 05:09:31.560092 26718 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 05:09:31.560099 26718 net.cpp:100] Creating Layer pool4
I0912 05:09:31.560103 26718 net.cpp:434] pool4 <- conv4_3
I0912 05:09:31.560109 26718 net.cpp:408] pool4 -> pool4
I0912 05:09:31.560117 26718 net.cpp:408] pool4 -> pool4_mask
I0912 05:09:31.560165 26718 net.cpp:150] Setting up pool4
I0912 05:09:31.560171 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.560176 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.560179 26718 net.cpp:165] Memory required for data: 3116175360
I0912 05:09:31.560183 26718 layer_factory.hpp:77] Creating layer conv5_1
I0912 05:09:31.560194 26718 net.cpp:100] Creating Layer conv5_1
I0912 05:09:31.560199 26718 net.cpp:434] conv5_1 <- pool4
I0912 05:09:31.560205 26718 net.cpp:408] conv5_1 -> conv5_1
I0912 05:09:31.644022 26718 net.cpp:150] Setting up conv5_1
I0912 05:09:31.644039 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.644044 26718 net.cpp:165] Memory required for data: 3121827840
I0912 05:09:31.644052 26718 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 05:09:31.644060 26718 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 05:09:31.644070 26718 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 05:09:31.644078 26718 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 05:09:31.644291 26718 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 05:09:31.644299 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.644302 26718 net.cpp:165] Memory required for data: 3127480320
I0912 05:09:31.644310 26718 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 05:09:31.644317 26718 net.cpp:100] Creating Layer conv5_1_scale
I0912 05:09:31.644325 26718 net.cpp:434] conv5_1_scale <- conv5_1
I0912 05:09:31.644331 26718 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 05:09:31.644379 26718 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 05:09:31.644497 26718 net.cpp:150] Setting up conv5_1_scale
I0912 05:09:31.644505 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.644508 26718 net.cpp:165] Memory required for data: 3133132800
I0912 05:09:31.644515 26718 layer_factory.hpp:77] Creating layer relu5_1
I0912 05:09:31.644522 26718 net.cpp:100] Creating Layer relu5_1
I0912 05:09:31.644526 26718 net.cpp:434] relu5_1 <- conv5_1
I0912 05:09:31.644532 26718 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 05:09:31.644731 26718 net.cpp:150] Setting up relu5_1
I0912 05:09:31.644739 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.644744 26718 net.cpp:165] Memory required for data: 3138785280
I0912 05:09:31.644748 26718 layer_factory.hpp:77] Creating layer conv5_2
I0912 05:09:31.644758 26718 net.cpp:100] Creating Layer conv5_2
I0912 05:09:31.644764 26718 net.cpp:434] conv5_2 <- conv5_1
I0912 05:09:31.644771 26718 net.cpp:408] conv5_2 -> conv5_2
I0912 05:09:31.730819 26718 net.cpp:150] Setting up conv5_2
I0912 05:09:31.730841 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.730846 26718 net.cpp:165] Memory required for data: 3144437760
I0912 05:09:31.730859 26718 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 05:09:31.730868 26718 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 05:09:31.730881 26718 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 05:09:31.730891 26718 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 05:09:31.731107 26718 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 05:09:31.731114 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.731135 26718 net.cpp:165] Memory required for data: 3150090240
I0912 05:09:31.731147 26718 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 05:09:31.731158 26718 net.cpp:100] Creating Layer conv5_2_scale
I0912 05:09:31.731163 26718 net.cpp:434] conv5_2_scale <- conv5_2
I0912 05:09:31.731168 26718 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 05:09:31.731217 26718 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 05:09:31.731338 26718 net.cpp:150] Setting up conv5_2_scale
I0912 05:09:31.731345 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.731348 26718 net.cpp:165] Memory required for data: 3155742720
I0912 05:09:31.731354 26718 layer_factory.hpp:77] Creating layer relu5_2
I0912 05:09:31.731362 26718 net.cpp:100] Creating Layer relu5_2
I0912 05:09:31.731367 26718 net.cpp:434] relu5_2 <- conv5_2
I0912 05:09:31.731372 26718 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 05:09:31.731570 26718 net.cpp:150] Setting up relu5_2
I0912 05:09:31.731580 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.731582 26718 net.cpp:165] Memory required for data: 3161395200
I0912 05:09:31.731585 26718 layer_factory.hpp:77] Creating layer conv5_3
I0912 05:09:31.731600 26718 net.cpp:100] Creating Layer conv5_3
I0912 05:09:31.731606 26718 net.cpp:434] conv5_3 <- conv5_2
I0912 05:09:31.731612 26718 net.cpp:408] conv5_3 -> conv5_3
I0912 05:09:31.815461 26718 net.cpp:150] Setting up conv5_3
I0912 05:09:31.815479 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.815482 26718 net.cpp:165] Memory required for data: 3167047680
I0912 05:09:31.815490 26718 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 05:09:31.815497 26718 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 05:09:31.815501 26718 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 05:09:31.815508 26718 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 05:09:31.815721 26718 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 05:09:31.815728 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.815732 26718 net.cpp:165] Memory required for data: 3172700160
I0912 05:09:31.815742 26718 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 05:09:31.815753 26718 net.cpp:100] Creating Layer conv5_3_scale
I0912 05:09:31.815762 26718 net.cpp:434] conv5_3_scale <- conv5_3
I0912 05:09:31.815768 26718 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 05:09:31.815817 26718 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 05:09:31.815938 26718 net.cpp:150] Setting up conv5_3_scale
I0912 05:09:31.815945 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.815948 26718 net.cpp:165] Memory required for data: 3178352640
I0912 05:09:31.815954 26718 layer_factory.hpp:77] Creating layer relu5_3
I0912 05:09:31.815963 26718 net.cpp:100] Creating Layer relu5_3
I0912 05:09:31.815968 26718 net.cpp:434] relu5_3 <- conv5_3
I0912 05:09:31.815973 26718 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 05:09:31.816174 26718 net.cpp:150] Setting up relu5_3
I0912 05:09:31.816182 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.816186 26718 net.cpp:165] Memory required for data: 3184005120
I0912 05:09:31.816190 26718 layer_factory.hpp:77] Creating layer pool5
I0912 05:09:31.816195 26718 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 05:09:31.816203 26718 net.cpp:100] Creating Layer pool5
I0912 05:09:31.816208 26718 net.cpp:434] pool5 <- conv5_3
I0912 05:09:31.816217 26718 net.cpp:408] pool5 -> pool5
I0912 05:09:31.816226 26718 net.cpp:408] pool5 -> pool5_mask
I0912 05:09:31.816275 26718 net.cpp:150] Setting up pool5
I0912 05:09:31.816282 26718 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 05:09:31.816287 26718 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 05:09:31.816289 26718 net.cpp:165] Memory required for data: 3186954240
I0912 05:09:31.816293 26718 layer_factory.hpp:77] Creating layer upsample5
I0912 05:09:31.816305 26718 net.cpp:100] Creating Layer upsample5
I0912 05:09:31.816310 26718 net.cpp:434] upsample5 <- pool5
I0912 05:09:31.816329 26718 net.cpp:434] upsample5 <- pool5_mask
I0912 05:09:31.816339 26718 net.cpp:408] upsample5 -> pool5_D
I0912 05:09:31.816375 26718 net.cpp:150] Setting up upsample5
I0912 05:09:31.816382 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.816385 26718 net.cpp:165] Memory required for data: 3192606720
I0912 05:09:31.816390 26718 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 05:09:31.816403 26718 net.cpp:100] Creating Layer conv5_3_D
I0912 05:09:31.816408 26718 net.cpp:434] conv5_3_D <- pool5_D
I0912 05:09:31.816416 26718 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 05:09:31.901115 26718 net.cpp:150] Setting up conv5_3_D
I0912 05:09:31.901132 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.901136 26718 net.cpp:165] Memory required for data: 3198259200
I0912 05:09:31.901144 26718 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 05:09:31.901152 26718 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 05:09:31.901165 26718 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 05:09:31.901170 26718 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 05:09:31.901399 26718 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 05:09:31.901407 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.901412 26718 net.cpp:165] Memory required for data: 3203911680
I0912 05:09:31.901419 26718 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 05:09:31.901427 26718 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 05:09:31.901435 26718 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 05:09:31.901440 26718 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 05:09:31.901486 26718 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 05:09:31.901607 26718 net.cpp:150] Setting up conv5_3_D_scale
I0912 05:09:31.901614 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.901618 26718 net.cpp:165] Memory required for data: 3209564160
I0912 05:09:31.901623 26718 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 05:09:31.901636 26718 net.cpp:100] Creating Layer relu5_3_D
I0912 05:09:31.901641 26718 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 05:09:31.901646 26718 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 05:09:31.901856 26718 net.cpp:150] Setting up relu5_3_D
I0912 05:09:31.901865 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.901868 26718 net.cpp:165] Memory required for data: 3215216640
I0912 05:09:31.901873 26718 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 05:09:31.901903 26718 net.cpp:100] Creating Layer conv5_2_D
I0912 05:09:31.901908 26718 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 05:09:31.901916 26718 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 05:09:31.985716 26718 net.cpp:150] Setting up conv5_2_D
I0912 05:09:31.985733 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.985738 26718 net.cpp:165] Memory required for data: 3220869120
I0912 05:09:31.985745 26718 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 05:09:31.985754 26718 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 05:09:31.985759 26718 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 05:09:31.985765 26718 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 05:09:31.985991 26718 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 05:09:31.985998 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.986001 26718 net.cpp:165] Memory required for data: 3226521600
I0912 05:09:31.986009 26718 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 05:09:31.986022 26718 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 05:09:31.986030 26718 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 05:09:31.986037 26718 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 05:09:31.986088 26718 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 05:09:31.986209 26718 net.cpp:150] Setting up conv5_2_D_scale
I0912 05:09:31.986217 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.986220 26718 net.cpp:165] Memory required for data: 3232174080
I0912 05:09:31.986243 26718 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 05:09:31.986251 26718 net.cpp:100] Creating Layer relu5_2_D
I0912 05:09:31.986256 26718 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 05:09:31.986261 26718 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 05:09:31.987332 26718 net.cpp:150] Setting up relu5_2_D
I0912 05:09:31.987347 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:31.987352 26718 net.cpp:165] Memory required for data: 3237826560
I0912 05:09:31.987359 26718 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 05:09:31.987371 26718 net.cpp:100] Creating Layer conv5_1_D
I0912 05:09:31.987377 26718 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 05:09:31.987385 26718 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 05:09:32.071303 26718 net.cpp:150] Setting up conv5_1_D
I0912 05:09:32.071321 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.071324 26718 net.cpp:165] Memory required for data: 3243479040
I0912 05:09:32.071332 26718 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 05:09:32.071342 26718 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 05:09:32.071353 26718 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 05:09:32.071360 26718 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 05:09:32.071585 26718 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 05:09:32.071593 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.071596 26718 net.cpp:165] Memory required for data: 3249131520
I0912 05:09:32.071605 26718 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 05:09:32.071619 26718 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 05:09:32.071625 26718 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 05:09:32.071630 26718 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 05:09:32.071677 26718 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 05:09:32.071805 26718 net.cpp:150] Setting up conv5_1_D_scale
I0912 05:09:32.071811 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.071815 26718 net.cpp:165] Memory required for data: 3254784000
I0912 05:09:32.071821 26718 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 05:09:32.071828 26718 net.cpp:100] Creating Layer relu5_1_D
I0912 05:09:32.071833 26718 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 05:09:32.071840 26718 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 05:09:32.072038 26718 net.cpp:150] Setting up relu5_1_D
I0912 05:09:32.072047 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.072051 26718 net.cpp:165] Memory required for data: 3260436480
I0912 05:09:32.072054 26718 layer_factory.hpp:77] Creating layer upsample4
I0912 05:09:32.072064 26718 net.cpp:100] Creating Layer upsample4
I0912 05:09:32.072069 26718 net.cpp:434] upsample4 <- conv5_1_D
I0912 05:09:32.072074 26718 net.cpp:434] upsample4 <- pool4_mask
I0912 05:09:32.072082 26718 net.cpp:408] upsample4 -> pool4_D
I0912 05:09:32.072113 26718 net.cpp:150] Setting up upsample4
I0912 05:09:32.072120 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.072124 26718 net.cpp:165] Memory required for data: 3282554880
I0912 05:09:32.072126 26718 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 05:09:32.072139 26718 net.cpp:100] Creating Layer conv4_3_D
I0912 05:09:32.072144 26718 net.cpp:434] conv4_3_D <- pool4_D
I0912 05:09:32.072151 26718 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 05:09:32.156616 26718 net.cpp:150] Setting up conv4_3_D
I0912 05:09:32.156639 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.156643 26718 net.cpp:165] Memory required for data: 3304673280
I0912 05:09:32.156656 26718 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 05:09:32.156669 26718 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 05:09:32.156678 26718 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 05:09:32.156690 26718 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 05:09:32.156929 26718 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 05:09:32.156937 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.156960 26718 net.cpp:165] Memory required for data: 3326791680
I0912 05:09:32.156968 26718 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 05:09:32.156978 26718 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 05:09:32.156985 26718 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 05:09:32.156991 26718 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 05:09:32.157037 26718 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 05:09:32.157182 26718 net.cpp:150] Setting up conv4_3_D_scale
I0912 05:09:32.157191 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.157193 26718 net.cpp:165] Memory required for data: 3348910080
I0912 05:09:32.157199 26718 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 05:09:32.157208 26718 net.cpp:100] Creating Layer relu4_3_D
I0912 05:09:32.157213 26718 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 05:09:32.157219 26718 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 05:09:32.157429 26718 net.cpp:150] Setting up relu4_3_D
I0912 05:09:32.157439 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.157443 26718 net.cpp:165] Memory required for data: 3371028480
I0912 05:09:32.157446 26718 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 05:09:32.157459 26718 net.cpp:100] Creating Layer conv4_2_D
I0912 05:09:32.157464 26718 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 05:09:32.157472 26718 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 05:09:32.241341 26718 net.cpp:150] Setting up conv4_2_D
I0912 05:09:32.241359 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.241369 26718 net.cpp:165] Memory required for data: 3393146880
I0912 05:09:32.241379 26718 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 05:09:32.241386 26718 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 05:09:32.241391 26718 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 05:09:32.241399 26718 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 05:09:32.241641 26718 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 05:09:32.241649 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.241653 26718 net.cpp:165] Memory required for data: 3415265280
I0912 05:09:32.241660 26718 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 05:09:32.241669 26718 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 05:09:32.241677 26718 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 05:09:32.241681 26718 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 05:09:32.241729 26718 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 05:09:32.241873 26718 net.cpp:150] Setting up conv4_2_D_scale
I0912 05:09:32.241880 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.241883 26718 net.cpp:165] Memory required for data: 3437383680
I0912 05:09:32.241889 26718 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 05:09:32.241897 26718 net.cpp:100] Creating Layer relu4_2_D
I0912 05:09:32.241902 26718 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 05:09:32.241909 26718 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 05:09:32.242111 26718 net.cpp:150] Setting up relu4_2_D
I0912 05:09:32.242120 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.242123 26718 net.cpp:165] Memory required for data: 3459502080
I0912 05:09:32.242126 26718 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 05:09:32.242138 26718 net.cpp:100] Creating Layer conv4_1_D
I0912 05:09:32.242144 26718 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 05:09:32.242151 26718 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 05:09:32.286049 26718 net.cpp:150] Setting up conv4_1_D
I0912 05:09:32.286065 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:32.286070 26718 net.cpp:165] Memory required for data: 3470561280
I0912 05:09:32.286080 26718 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 05:09:32.286093 26718 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 05:09:32.286101 26718 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 05:09:32.286108 26718 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 05:09:32.286345 26718 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 05:09:32.286370 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:32.286378 26718 net.cpp:165] Memory required for data: 3481620480
I0912 05:09:32.286461 26718 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 05:09:32.286470 26718 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 05:09:32.286479 26718 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 05:09:32.286485 26718 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 05:09:32.286540 26718 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 05:09:32.286677 26718 net.cpp:150] Setting up conv4_1_D_scale
I0912 05:09:32.286685 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:32.286689 26718 net.cpp:165] Memory required for data: 3492679680
I0912 05:09:32.286695 26718 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 05:09:32.286701 26718 net.cpp:100] Creating Layer relu4_1_D
I0912 05:09:32.286705 26718 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 05:09:32.286711 26718 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 05:09:32.286926 26718 net.cpp:150] Setting up relu4_1_D
I0912 05:09:32.286934 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:32.286938 26718 net.cpp:165] Memory required for data: 3503738880
I0912 05:09:32.286942 26718 layer_factory.hpp:77] Creating layer upsample3
I0912 05:09:32.286953 26718 net.cpp:100] Creating Layer upsample3
I0912 05:09:32.286958 26718 net.cpp:434] upsample3 <- conv4_1_D
I0912 05:09:32.286964 26718 net.cpp:434] upsample3 <- pool3_mask
I0912 05:09:32.286972 26718 net.cpp:408] upsample3 -> pool3_D
I0912 05:09:32.286980 26718 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 05:09:32.287014 26718 net.cpp:150] Setting up upsample3
I0912 05:09:32.287021 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.287024 26718 net.cpp:165] Memory required for data: 3547975680
I0912 05:09:32.287027 26718 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 05:09:32.287039 26718 net.cpp:100] Creating Layer conv3_3_D
I0912 05:09:32.287045 26718 net.cpp:434] conv3_3_D <- pool3_D
I0912 05:09:32.287055 26718 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 05:09:32.310611 26718 net.cpp:150] Setting up conv3_3_D
I0912 05:09:32.310629 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.310639 26718 net.cpp:165] Memory required for data: 3592212480
I0912 05:09:32.310648 26718 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 05:09:32.310655 26718 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 05:09:32.310663 26718 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 05:09:32.310670 26718 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 05:09:32.310926 26718 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 05:09:32.310935 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.310938 26718 net.cpp:165] Memory required for data: 3636449280
I0912 05:09:32.310946 26718 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 05:09:32.310953 26718 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 05:09:32.310961 26718 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 05:09:32.310966 26718 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 05:09:32.311012 26718 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 05:09:32.311173 26718 net.cpp:150] Setting up conv3_3_D_scale
I0912 05:09:32.311182 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.311184 26718 net.cpp:165] Memory required for data: 3680686080
I0912 05:09:32.311190 26718 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 05:09:32.311198 26718 net.cpp:100] Creating Layer relu3_3_D
I0912 05:09:32.311203 26718 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 05:09:32.311210 26718 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 05:09:32.311424 26718 net.cpp:150] Setting up relu3_3_D
I0912 05:09:32.311432 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.311435 26718 net.cpp:165] Memory required for data: 3724922880
I0912 05:09:32.311456 26718 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 05:09:32.311470 26718 net.cpp:100] Creating Layer conv3_2_D
I0912 05:09:32.311475 26718 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 05:09:32.311483 26718 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 05:09:32.334823 26718 net.cpp:150] Setting up conv3_2_D
I0912 05:09:32.334841 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.334851 26718 net.cpp:165] Memory required for data: 3769159680
I0912 05:09:32.334861 26718 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 05:09:32.334874 26718 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 05:09:32.334884 26718 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 05:09:32.334890 26718 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 05:09:32.335146 26718 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 05:09:32.335155 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.335158 26718 net.cpp:165] Memory required for data: 3813396480
I0912 05:09:32.335168 26718 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 05:09:32.335177 26718 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 05:09:32.335186 26718 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 05:09:32.335191 26718 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 05:09:32.335237 26718 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 05:09:32.335398 26718 net.cpp:150] Setting up conv3_2_D_scale
I0912 05:09:32.335407 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.335410 26718 net.cpp:165] Memory required for data: 3857633280
I0912 05:09:32.335417 26718 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 05:09:32.335425 26718 net.cpp:100] Creating Layer relu3_2_D
I0912 05:09:32.335430 26718 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 05:09:32.335435 26718 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 05:09:32.336519 26718 net.cpp:150] Setting up relu3_2_D
I0912 05:09:32.336535 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.336540 26718 net.cpp:165] Memory required for data: 3901870080
I0912 05:09:32.336544 26718 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 05:09:32.336556 26718 net.cpp:100] Creating Layer conv3_1_D
I0912 05:09:32.336562 26718 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 05:09:32.336571 26718 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 05:09:32.350298 26718 net.cpp:150] Setting up conv3_1_D
I0912 05:09:32.350316 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:32.350327 26718 net.cpp:165] Memory required for data: 3923988480
I0912 05:09:32.350337 26718 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 05:09:32.350344 26718 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 05:09:32.350349 26718 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 05:09:32.350358 26718 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 05:09:32.350618 26718 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 05:09:32.350626 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:32.350630 26718 net.cpp:165] Memory required for data: 3946106880
I0912 05:09:32.350638 26718 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 05:09:32.350647 26718 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 05:09:32.350656 26718 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 05:09:32.350661 26718 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 05:09:32.350708 26718 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 05:09:32.350870 26718 net.cpp:150] Setting up conv3_1_D_scale
I0912 05:09:32.350879 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:32.350883 26718 net.cpp:165] Memory required for data: 3968225280
I0912 05:09:32.350888 26718 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 05:09:32.350896 26718 net.cpp:100] Creating Layer relu3_1_D
I0912 05:09:32.350901 26718 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 05:09:32.350908 26718 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 05:09:32.351126 26718 net.cpp:150] Setting up relu3_1_D
I0912 05:09:32.351150 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:32.351155 26718 net.cpp:165] Memory required for data: 3990343680
I0912 05:09:32.351157 26718 layer_factory.hpp:77] Creating layer upsample2
I0912 05:09:32.351166 26718 net.cpp:100] Creating Layer upsample2
I0912 05:09:32.351171 26718 net.cpp:434] upsample2 <- conv3_1_D
I0912 05:09:32.351177 26718 net.cpp:434] upsample2 <- pool2_mask
I0912 05:09:32.351182 26718 net.cpp:408] upsample2 -> pool2_D
I0912 05:09:32.351191 26718 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 05:09:32.351228 26718 net.cpp:150] Setting up upsample2
I0912 05:09:32.351234 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.351238 26718 net.cpp:165] Memory required for data: 4078817280
I0912 05:09:32.351243 26718 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 05:09:32.351255 26718 net.cpp:100] Creating Layer conv2_2_D
I0912 05:09:32.351260 26718 net.cpp:434] conv2_2_D <- pool2_D
I0912 05:09:32.351269 26718 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 05:09:32.358845 26718 net.cpp:150] Setting up conv2_2_D
I0912 05:09:32.358861 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.358871 26718 net.cpp:165] Memory required for data: 4167290880
I0912 05:09:32.358880 26718 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 05:09:32.358887 26718 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 05:09:32.358896 26718 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 05:09:32.358901 26718 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 05:09:32.359200 26718 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 05:09:32.359210 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.359212 26718 net.cpp:165] Memory required for data: 4255764480
I0912 05:09:32.359220 26718 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 05:09:32.359233 26718 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 05:09:32.359237 26718 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 05:09:32.359243 26718 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 05:09:32.359297 26718 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 05:09:32.360731 26718 net.cpp:150] Setting up conv2_2_D_scale
I0912 05:09:32.360746 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.360754 26718 net.cpp:165] Memory required for data: 4344238080
I0912 05:09:32.360762 26718 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 05:09:32.360775 26718 net.cpp:100] Creating Layer relu2_2_D
I0912 05:09:32.360780 26718 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 05:09:32.360786 26718 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 05:09:32.361016 26718 net.cpp:150] Setting up relu2_2_D
I0912 05:09:32.361027 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.361029 26718 net.cpp:165] Memory required for data: 4432711680
I0912 05:09:32.361035 26718 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 05:09:32.361048 26718 net.cpp:100] Creating Layer conv2_1_D
I0912 05:09:32.361054 26718 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 05:09:32.361063 26718 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 05:09:32.366297 26718 net.cpp:150] Setting up conv2_1_D
I0912 05:09:32.366314 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:32.366325 26718 net.cpp:165] Memory required for data: 4476948480
I0912 05:09:32.366335 26718 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 05:09:32.366349 26718 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 05:09:32.366358 26718 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 05:09:32.366364 26718 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 05:09:32.366657 26718 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 05:09:32.366665 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:32.366668 26718 net.cpp:165] Memory required for data: 4521185280
I0912 05:09:32.366677 26718 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 05:09:32.366699 26718 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 05:09:32.366705 26718 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 05:09:32.366710 26718 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 05:09:32.366765 26718 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 05:09:32.366984 26718 net.cpp:150] Setting up conv2_1_D_scale
I0912 05:09:32.366993 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:32.366997 26718 net.cpp:165] Memory required for data: 4565422080
I0912 05:09:32.367003 26718 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 05:09:32.367012 26718 net.cpp:100] Creating Layer relu2_1_D
I0912 05:09:32.367014 26718 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 05:09:32.367019 26718 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 05:09:32.367247 26718 net.cpp:150] Setting up relu2_1_D
I0912 05:09:32.367256 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:32.367260 26718 net.cpp:165] Memory required for data: 4609658880
I0912 05:09:32.367265 26718 layer_factory.hpp:77] Creating layer upsample1
I0912 05:09:32.367274 26718 net.cpp:100] Creating Layer upsample1
I0912 05:09:32.367278 26718 net.cpp:434] upsample1 <- conv2_1_D
I0912 05:09:32.367283 26718 net.cpp:434] upsample1 <- pool1_mask
I0912 05:09:32.367290 26718 net.cpp:408] upsample1 -> pool1_D
I0912 05:09:32.367300 26718 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 05:09:32.367331 26718 net.cpp:150] Setting up upsample1
I0912 05:09:32.367341 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.367346 26718 net.cpp:165] Memory required for data: 4786606080
I0912 05:09:32.367348 26718 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 05:09:32.367360 26718 net.cpp:100] Creating Layer conv1_2_D
I0912 05:09:32.367367 26718 net.cpp:434] conv1_2_D <- pool1_D
I0912 05:09:32.367372 26718 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 05:09:32.371824 26718 net.cpp:150] Setting up conv1_2_D
I0912 05:09:32.371840 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.371850 26718 net.cpp:165] Memory required for data: 4963553280
I0912 05:09:32.371857 26718 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 05:09:32.371867 26718 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 05:09:32.371875 26718 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 05:09:32.371881 26718 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 05:09:32.372272 26718 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 05:09:32.372280 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.372284 26718 net.cpp:165] Memory required for data: 5140500480
I0912 05:09:32.372292 26718 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 05:09:32.372303 26718 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 05:09:32.372308 26718 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 05:09:32.372313 26718 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 05:09:32.372361 26718 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 05:09:32.374009 26718 net.cpp:150] Setting up conv1_2_D_scale
I0912 05:09:32.374027 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.374032 26718 net.cpp:165] Memory required for data: 5317447680
I0912 05:09:32.374042 26718 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 05:09:32.374049 26718 net.cpp:100] Creating Layer relu1_2_D
I0912 05:09:32.374055 26718 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 05:09:32.374060 26718 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 05:09:32.374294 26718 net.cpp:150] Setting up relu1_2_D
I0912 05:09:32.374303 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.374307 26718 net.cpp:165] Memory required for data: 5494394880
I0912 05:09:32.374311 26718 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 05:09:32.374325 26718 net.cpp:100] Creating Layer conv1_1_1_D
I0912 05:09:32.374330 26718 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 05:09:32.374353 26718 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 05:09:32.376387 26718 net.cpp:150] Setting up conv1_1_1_D
I0912 05:09:32.376404 26718 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 05:09:32.376408 26718 net.cpp:165] Memory required for data: 5499924480
I0912 05:09:32.376415 26718 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 05:09:32.376425 26718 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 05:09:32.376430 26718 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 05:09:32.376437 26718 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 05:09:32.376446 26718 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 05:09:32.376499 26718 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 05:09:32.376507 26718 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 05:09:32.376512 26718 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 05:09:32.376514 26718 net.cpp:165] Memory required for data: 5510983680
I0912 05:09:32.376519 26718 layer_factory.hpp:77] Creating layer loss
I0912 05:09:32.376534 26718 net.cpp:100] Creating Layer loss
I0912 05:09:32.376539 26718 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 05:09:32.376544 26718 net.cpp:434] loss <- label_data_1_split_0
I0912 05:09:32.376552 26718 net.cpp:408] loss -> loss
I0912 05:09:32.376574 26718 layer_factory.hpp:77] Creating layer loss
I0912 05:09:32.380583 26718 net.cpp:150] Setting up loss
I0912 05:09:32.380597 26718 net.cpp:157] Top shape: (1)
I0912 05:09:32.380601 26718 net.cpp:160]     with loss weight 1
I0912 05:09:32.380641 26718 net.cpp:165] Memory required for data: 5510983684
I0912 05:09:32.380645 26718 layer_factory.hpp:77] Creating layer accuracy
I0912 05:09:32.380656 26718 net.cpp:100] Creating Layer accuracy
I0912 05:09:32.380661 26718 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 05:09:32.380666 26718 net.cpp:434] accuracy <- label_data_1_split_1
I0912 05:09:32.380676 26718 net.cpp:408] accuracy -> accuracy
I0912 05:09:32.380683 26718 net.cpp:408] accuracy -> per_class_accuracy
I0912 05:09:32.380736 26718 net.cpp:150] Setting up accuracy
I0912 05:09:32.380743 26718 net.cpp:157] Top shape: (1)
I0912 05:09:32.380748 26718 net.cpp:157] Top shape: 2 (2)
I0912 05:09:32.380751 26718 net.cpp:165] Memory required for data: 5510983696
I0912 05:09:32.380756 26718 net.cpp:228] accuracy does not need backward computation.
I0912 05:09:32.380760 26718 net.cpp:226] loss needs backward computation.
I0912 05:09:32.380766 26718 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 05:09:32.380771 26718 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 05:09:32.380774 26718 net.cpp:226] relu1_2_D needs backward computation.
I0912 05:09:32.380779 26718 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 05:09:32.380781 26718 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 05:09:32.380784 26718 net.cpp:226] conv1_2_D needs backward computation.
I0912 05:09:32.380787 26718 net.cpp:226] upsample1 needs backward computation.
I0912 05:09:32.380790 26718 net.cpp:226] relu2_1_D needs backward computation.
I0912 05:09:32.380794 26718 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 05:09:32.380796 26718 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 05:09:32.380800 26718 net.cpp:226] conv2_1_D needs backward computation.
I0912 05:09:32.380803 26718 net.cpp:226] relu2_2_D needs backward computation.
I0912 05:09:32.380806 26718 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 05:09:32.380810 26718 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 05:09:32.380811 26718 net.cpp:226] conv2_2_D needs backward computation.
I0912 05:09:32.380815 26718 net.cpp:226] upsample2 needs backward computation.
I0912 05:09:32.380820 26718 net.cpp:226] relu3_1_D needs backward computation.
I0912 05:09:32.380822 26718 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 05:09:32.380839 26718 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 05:09:32.380842 26718 net.cpp:226] conv3_1_D needs backward computation.
I0912 05:09:32.380846 26718 net.cpp:226] relu3_2_D needs backward computation.
I0912 05:09:32.380848 26718 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 05:09:32.380851 26718 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 05:09:32.380854 26718 net.cpp:226] conv3_2_D needs backward computation.
I0912 05:09:32.380858 26718 net.cpp:226] relu3_3_D needs backward computation.
I0912 05:09:32.380861 26718 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 05:09:32.380864 26718 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 05:09:32.380867 26718 net.cpp:226] conv3_3_D needs backward computation.
I0912 05:09:32.380872 26718 net.cpp:226] upsample3 needs backward computation.
I0912 05:09:32.380875 26718 net.cpp:226] relu4_1_D needs backward computation.
I0912 05:09:32.380879 26718 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 05:09:32.380883 26718 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 05:09:32.380887 26718 net.cpp:226] conv4_1_D needs backward computation.
I0912 05:09:32.380890 26718 net.cpp:226] relu4_2_D needs backward computation.
I0912 05:09:32.380893 26718 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 05:09:32.380897 26718 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 05:09:32.380899 26718 net.cpp:226] conv4_2_D needs backward computation.
I0912 05:09:32.380903 26718 net.cpp:226] relu4_3_D needs backward computation.
I0912 05:09:32.380906 26718 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 05:09:32.380909 26718 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 05:09:32.380913 26718 net.cpp:226] conv4_3_D needs backward computation.
I0912 05:09:32.380916 26718 net.cpp:226] upsample4 needs backward computation.
I0912 05:09:32.380921 26718 net.cpp:226] relu5_1_D needs backward computation.
I0912 05:09:32.380926 26718 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 05:09:32.380929 26718 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 05:09:32.380934 26718 net.cpp:226] conv5_1_D needs backward computation.
I0912 05:09:32.380936 26718 net.cpp:226] relu5_2_D needs backward computation.
I0912 05:09:32.380940 26718 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 05:09:32.380944 26718 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 05:09:32.380949 26718 net.cpp:226] conv5_2_D needs backward computation.
I0912 05:09:32.380955 26718 net.cpp:226] relu5_3_D needs backward computation.
I0912 05:09:32.380959 26718 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 05:09:32.380962 26718 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 05:09:32.380970 26718 net.cpp:226] conv5_3_D needs backward computation.
I0912 05:09:32.380972 26718 net.cpp:226] upsample5 needs backward computation.
I0912 05:09:32.380977 26718 net.cpp:226] pool5 needs backward computation.
I0912 05:09:32.380983 26718 net.cpp:226] relu5_3 needs backward computation.
I0912 05:09:32.380987 26718 net.cpp:226] conv5_3_scale needs backward computation.
I0912 05:09:32.380990 26718 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 05:09:32.380995 26718 net.cpp:226] conv5_3 needs backward computation.
I0912 05:09:32.380998 26718 net.cpp:226] relu5_2 needs backward computation.
I0912 05:09:32.381002 26718 net.cpp:226] conv5_2_scale needs backward computation.
I0912 05:09:32.381006 26718 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 05:09:32.381011 26718 net.cpp:226] conv5_2 needs backward computation.
I0912 05:09:32.381014 26718 net.cpp:226] relu5_1 needs backward computation.
I0912 05:09:32.381018 26718 net.cpp:226] conv5_1_scale needs backward computation.
I0912 05:09:32.381021 26718 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 05:09:32.381024 26718 net.cpp:226] conv5_1 needs backward computation.
I0912 05:09:32.381031 26718 net.cpp:226] pool4 needs backward computation.
I0912 05:09:32.381042 26718 net.cpp:226] relu4_3 needs backward computation.
I0912 05:09:32.381045 26718 net.cpp:226] conv4_3_scale needs backward computation.
I0912 05:09:32.381048 26718 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 05:09:32.381052 26718 net.cpp:226] conv4_3 needs backward computation.
I0912 05:09:32.381057 26718 net.cpp:226] relu4_2 needs backward computation.
I0912 05:09:32.381060 26718 net.cpp:226] conv4_2_scale needs backward computation.
I0912 05:09:32.381063 26718 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 05:09:32.381067 26718 net.cpp:226] conv4_2 needs backward computation.
I0912 05:09:32.381072 26718 net.cpp:226] relu4_1 needs backward computation.
I0912 05:09:32.381075 26718 net.cpp:226] conv4_1_scale needs backward computation.
I0912 05:09:32.381078 26718 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 05:09:32.381081 26718 net.cpp:226] conv4_1 needs backward computation.
I0912 05:09:32.381085 26718 net.cpp:226] pool3 needs backward computation.
I0912 05:09:32.381089 26718 net.cpp:226] relu3_3 needs backward computation.
I0912 05:09:32.381094 26718 net.cpp:226] conv3_3_scale needs backward computation.
I0912 05:09:32.381098 26718 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 05:09:32.381100 26718 net.cpp:226] conv3_3 needs backward computation.
I0912 05:09:32.381104 26718 net.cpp:226] relu3_2 needs backward computation.
I0912 05:09:32.381108 26718 net.cpp:226] conv3_2_scale needs backward computation.
I0912 05:09:32.381111 26718 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 05:09:32.381115 26718 net.cpp:226] conv3_2 needs backward computation.
I0912 05:09:32.381119 26718 net.cpp:226] relu3_1 needs backward computation.
I0912 05:09:32.381122 26718 net.cpp:226] conv3_1_scale needs backward computation.
I0912 05:09:32.381126 26718 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 05:09:32.381130 26718 net.cpp:226] conv3_1 needs backward computation.
I0912 05:09:32.381134 26718 net.cpp:226] pool2 needs backward computation.
I0912 05:09:32.381139 26718 net.cpp:226] relu2_2 needs backward computation.
I0912 05:09:32.381141 26718 net.cpp:226] conv2_2_scale needs backward computation.
I0912 05:09:32.381145 26718 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 05:09:32.381150 26718 net.cpp:226] conv2_2 needs backward computation.
I0912 05:09:32.381155 26718 net.cpp:226] relu2_1 needs backward computation.
I0912 05:09:32.381157 26718 net.cpp:226] conv2_1_scale needs backward computation.
I0912 05:09:32.381161 26718 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 05:09:32.381165 26718 net.cpp:226] conv2_1 needs backward computation.
I0912 05:09:32.381167 26718 net.cpp:226] pool1 needs backward computation.
I0912 05:09:32.381171 26718 net.cpp:226] relu1_2 needs backward computation.
I0912 05:09:32.381176 26718 net.cpp:226] conv1_2_scale needs backward computation.
I0912 05:09:32.381180 26718 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 05:09:32.381184 26718 net.cpp:226] conv1_2 needs backward computation.
I0912 05:09:32.381187 26718 net.cpp:226] relu1_1 needs backward computation.
I0912 05:09:32.381191 26718 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 05:09:32.381194 26718 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 05:09:32.381197 26718 net.cpp:226] conv1_1_1 needs backward computation.
I0912 05:09:32.381203 26718 net.cpp:228] label_data_1_split does not need backward computation.
I0912 05:09:32.381208 26718 net.cpp:228] data does not need backward computation.
I0912 05:09:32.381212 26718 net.cpp:270] This network produces output accuracy
I0912 05:09:32.381216 26718 net.cpp:270] This network produces output loss
I0912 05:09:32.381219 26718 net.cpp:270] This network produces output per_class_accuracy
I0912 05:09:32.381283 26718 net.cpp:283] Network initialization done.
I0912 05:09:32.383622 26718 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc6/caffe/model_segnet_final/train.prototxt
I0912 05:09:32.384311 26718 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc6/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 05:09:32.384729 26718 layer_factory.hpp:77] Creating layer data
I0912 05:09:32.384742 26718 net.cpp:100] Creating Layer data
I0912 05:09:32.384748 26718 net.cpp:408] data -> data
I0912 05:09:32.384757 26718 net.cpp:408] data -> label
I0912 05:09:32.384764 26718 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc6/HDF5Files/train_combined.txt
I0912 05:09:32.384804 26718 hdf5_data_layer.cpp:93] Number of HDF5 files: 31
I0912 05:09:32.395102 26718 net.cpp:150] Setting up data
I0912 05:09:32.395121 26718 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 05:09:32.395128 26718 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 05:09:32.395131 26718 net.cpp:165] Memory required for data: 24883200
I0912 05:09:32.395136 26718 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 05:09:32.395145 26718 net.cpp:100] Creating Layer label_data_1_split
I0912 05:09:32.395156 26718 net.cpp:434] label_data_1_split <- label
I0912 05:09:32.395162 26718 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 05:09:32.395170 26718 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 05:09:32.395220 26718 net.cpp:150] Setting up label_data_1_split
I0912 05:09:32.395227 26718 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 05:09:32.395231 26718 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 05:09:32.395236 26718 net.cpp:165] Memory required for data: 30412800
I0912 05:09:32.395244 26718 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 05:09:32.395254 26718 net.cpp:100] Creating Layer conv1_1_1
I0912 05:09:32.395259 26718 net.cpp:434] conv1_1_1 <- data
I0912 05:09:32.395265 26718 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 05:09:32.398702 26718 net.cpp:150] Setting up conv1_1_1
I0912 05:09:32.398720 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.398728 26718 net.cpp:165] Memory required for data: 207360000
I0912 05:09:32.398741 26718 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 05:09:32.398753 26718 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 05:09:32.398762 26718 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 05:09:32.398768 26718 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 05:09:32.399145 26718 net.cpp:150] Setting up conv1_1_1_bn
I0912 05:09:32.399154 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.399158 26718 net.cpp:165] Memory required for data: 384307200
I0912 05:09:32.399169 26718 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 05:09:32.399178 26718 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 05:09:32.399183 26718 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 05:09:32.399188 26718 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 05:09:32.399235 26718 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 05:09:32.400882 26718 net.cpp:150] Setting up conv1_1_1_scale
I0912 05:09:32.400897 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.400907 26718 net.cpp:165] Memory required for data: 561254400
I0912 05:09:32.400914 26718 layer_factory.hpp:77] Creating layer relu1_1
I0912 05:09:32.400923 26718 net.cpp:100] Creating Layer relu1_1
I0912 05:09:32.400928 26718 net.cpp:434] relu1_1 <- conv1_1_1
I0912 05:09:32.400933 26718 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 05:09:32.401151 26718 net.cpp:150] Setting up relu1_1
I0912 05:09:32.401161 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.401165 26718 net.cpp:165] Memory required for data: 738201600
I0912 05:09:32.401168 26718 layer_factory.hpp:77] Creating layer conv1_2
I0912 05:09:32.401178 26718 net.cpp:100] Creating Layer conv1_2
I0912 05:09:32.401183 26718 net.cpp:434] conv1_2 <- conv1_1_1
I0912 05:09:32.401190 26718 net.cpp:408] conv1_2 -> conv1_2
I0912 05:09:32.405269 26718 net.cpp:150] Setting up conv1_2
I0912 05:09:32.405285 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.405295 26718 net.cpp:165] Memory required for data: 915148800
I0912 05:09:32.405324 26718 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 05:09:32.405335 26718 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 05:09:32.405340 26718 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 05:09:32.405346 26718 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 05:09:32.405727 26718 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 05:09:32.405736 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.405740 26718 net.cpp:165] Memory required for data: 1092096000
I0912 05:09:32.405748 26718 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 05:09:32.405756 26718 net.cpp:100] Creating Layer conv1_2_scale
I0912 05:09:32.405761 26718 net.cpp:434] conv1_2_scale <- conv1_2
I0912 05:09:32.405766 26718 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 05:09:32.405815 26718 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 05:09:32.407485 26718 net.cpp:150] Setting up conv1_2_scale
I0912 05:09:32.407500 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.407505 26718 net.cpp:165] Memory required for data: 1269043200
I0912 05:09:32.407512 26718 layer_factory.hpp:77] Creating layer relu1_2
I0912 05:09:32.407521 26718 net.cpp:100] Creating Layer relu1_2
I0912 05:09:32.407526 26718 net.cpp:434] relu1_2 <- conv1_2
I0912 05:09:32.407531 26718 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 05:09:32.408643 26718 net.cpp:150] Setting up relu1_2
I0912 05:09:32.408656 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:32.408663 26718 net.cpp:165] Memory required for data: 1445990400
I0912 05:09:32.408666 26718 layer_factory.hpp:77] Creating layer pool1
I0912 05:09:32.408670 26718 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 05:09:32.408679 26718 net.cpp:100] Creating Layer pool1
I0912 05:09:32.408681 26718 net.cpp:434] pool1 <- conv1_2
I0912 05:09:32.408687 26718 net.cpp:408] pool1 -> pool1
I0912 05:09:32.408696 26718 net.cpp:408] pool1 -> pool1_mask
I0912 05:09:32.408754 26718 net.cpp:150] Setting up pool1
I0912 05:09:32.408762 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:32.408766 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:32.408771 26718 net.cpp:165] Memory required for data: 1534464000
I0912 05:09:32.408773 26718 layer_factory.hpp:77] Creating layer conv2_1
I0912 05:09:32.408784 26718 net.cpp:100] Creating Layer conv2_1
I0912 05:09:32.408789 26718 net.cpp:434] conv2_1 <- pool1
I0912 05:09:32.408795 26718 net.cpp:408] conv2_1 -> conv2_1
I0912 05:09:32.413122 26718 net.cpp:150] Setting up conv2_1
I0912 05:09:32.413139 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.413147 26718 net.cpp:165] Memory required for data: 1622937600
I0912 05:09:32.413156 26718 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 05:09:32.413162 26718 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 05:09:32.413172 26718 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 05:09:32.413179 26718 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 05:09:32.413496 26718 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 05:09:32.413506 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.413508 26718 net.cpp:165] Memory required for data: 1711411200
I0912 05:09:32.413520 26718 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 05:09:32.413532 26718 net.cpp:100] Creating Layer conv2_1_scale
I0912 05:09:32.413537 26718 net.cpp:434] conv2_1_scale <- conv2_1
I0912 05:09:32.413542 26718 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 05:09:32.413589 26718 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 05:09:32.413827 26718 net.cpp:150] Setting up conv2_1_scale
I0912 05:09:32.413836 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.413839 26718 net.cpp:165] Memory required for data: 1799884800
I0912 05:09:32.413846 26718 layer_factory.hpp:77] Creating layer relu2_1
I0912 05:09:32.413852 26718 net.cpp:100] Creating Layer relu2_1
I0912 05:09:32.413856 26718 net.cpp:434] relu2_1 <- conv2_1
I0912 05:09:32.413861 26718 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 05:09:32.415001 26718 net.cpp:150] Setting up relu2_1
I0912 05:09:32.415015 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.415020 26718 net.cpp:165] Memory required for data: 1888358400
I0912 05:09:32.415024 26718 layer_factory.hpp:77] Creating layer conv2_2
I0912 05:09:32.415037 26718 net.cpp:100] Creating Layer conv2_2
I0912 05:09:32.415042 26718 net.cpp:434] conv2_2 <- conv2_1
I0912 05:09:32.415051 26718 net.cpp:408] conv2_2 -> conv2_2
I0912 05:09:32.424015 26718 net.cpp:150] Setting up conv2_2
I0912 05:09:32.424031 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.424041 26718 net.cpp:165] Memory required for data: 1976832000
I0912 05:09:32.424049 26718 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 05:09:32.424060 26718 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 05:09:32.424067 26718 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 05:09:32.424072 26718 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 05:09:32.425626 26718 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 05:09:32.425640 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.425650 26718 net.cpp:165] Memory required for data: 2065305600
I0912 05:09:32.425659 26718 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 05:09:32.425668 26718 net.cpp:100] Creating Layer conv2_2_scale
I0912 05:09:32.425675 26718 net.cpp:434] conv2_2_scale <- conv2_2
I0912 05:09:32.425683 26718 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 05:09:32.425742 26718 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 05:09:32.425956 26718 net.cpp:150] Setting up conv2_2_scale
I0912 05:09:32.425964 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.425967 26718 net.cpp:165] Memory required for data: 2153779200
I0912 05:09:32.425974 26718 layer_factory.hpp:77] Creating layer relu2_2
I0912 05:09:32.425981 26718 net.cpp:100] Creating Layer relu2_2
I0912 05:09:32.425987 26718 net.cpp:434] relu2_2 <- conv2_2
I0912 05:09:32.425992 26718 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 05:09:32.426221 26718 net.cpp:150] Setting up relu2_2
I0912 05:09:32.426231 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:32.426235 26718 net.cpp:165] Memory required for data: 2242252800
I0912 05:09:32.426239 26718 layer_factory.hpp:77] Creating layer pool2
I0912 05:09:32.426242 26718 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 05:09:32.426249 26718 net.cpp:100] Creating Layer pool2
I0912 05:09:32.426252 26718 net.cpp:434] pool2 <- conv2_2
I0912 05:09:32.426259 26718 net.cpp:408] pool2 -> pool2
I0912 05:09:32.426267 26718 net.cpp:408] pool2 -> pool2_mask
I0912 05:09:32.426323 26718 net.cpp:150] Setting up pool2
I0912 05:09:32.426331 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:32.426336 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:32.426339 26718 net.cpp:165] Memory required for data: 2286489600
I0912 05:09:32.426342 26718 layer_factory.hpp:77] Creating layer conv3_1
I0912 05:09:32.426355 26718 net.cpp:100] Creating Layer conv3_1
I0912 05:09:32.426362 26718 net.cpp:434] conv3_1 <- pool2
I0912 05:09:32.426367 26718 net.cpp:408] conv3_1 -> conv3_1
I0912 05:09:32.438851 26718 net.cpp:150] Setting up conv3_1
I0912 05:09:32.438868 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.438877 26718 net.cpp:165] Memory required for data: 2330726400
I0912 05:09:32.438885 26718 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 05:09:32.438894 26718 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 05:09:32.438901 26718 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 05:09:32.438907 26718 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 05:09:32.439185 26718 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 05:09:32.439193 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.439198 26718 net.cpp:165] Memory required for data: 2374963200
I0912 05:09:32.439214 26718 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 05:09:32.439236 26718 net.cpp:100] Creating Layer conv3_1_scale
I0912 05:09:32.439245 26718 net.cpp:434] conv3_1_scale <- conv3_1
I0912 05:09:32.439250 26718 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 05:09:32.439307 26718 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 05:09:32.439483 26718 net.cpp:150] Setting up conv3_1_scale
I0912 05:09:32.439491 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.439494 26718 net.cpp:165] Memory required for data: 2419200000
I0912 05:09:32.439502 26718 layer_factory.hpp:77] Creating layer relu3_1
I0912 05:09:32.439509 26718 net.cpp:100] Creating Layer relu3_1
I0912 05:09:32.439515 26718 net.cpp:434] relu3_1 <- conv3_1
I0912 05:09:32.439519 26718 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 05:09:32.439743 26718 net.cpp:150] Setting up relu3_1
I0912 05:09:32.439752 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.439759 26718 net.cpp:165] Memory required for data: 2463436800
I0912 05:09:32.439762 26718 layer_factory.hpp:77] Creating layer conv3_2
I0912 05:09:32.439771 26718 net.cpp:100] Creating Layer conv3_2
I0912 05:09:32.439776 26718 net.cpp:434] conv3_2 <- conv3_1
I0912 05:09:32.439785 26718 net.cpp:408] conv3_2 -> conv3_2
I0912 05:09:32.463332 26718 net.cpp:150] Setting up conv3_2
I0912 05:09:32.463351 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.463361 26718 net.cpp:165] Memory required for data: 2507673600
I0912 05:09:32.463369 26718 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 05:09:32.463377 26718 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 05:09:32.463387 26718 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 05:09:32.463392 26718 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 05:09:32.463673 26718 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 05:09:32.463681 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.463685 26718 net.cpp:165] Memory required for data: 2551910400
I0912 05:09:32.463693 26718 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 05:09:32.463706 26718 net.cpp:100] Creating Layer conv3_2_scale
I0912 05:09:32.463716 26718 net.cpp:434] conv3_2_scale <- conv3_2
I0912 05:09:32.463721 26718 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 05:09:32.463773 26718 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 05:09:32.463951 26718 net.cpp:150] Setting up conv3_2_scale
I0912 05:09:32.463959 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.463963 26718 net.cpp:165] Memory required for data: 2596147200
I0912 05:09:32.463969 26718 layer_factory.hpp:77] Creating layer relu3_2
I0912 05:09:32.463976 26718 net.cpp:100] Creating Layer relu3_2
I0912 05:09:32.463981 26718 net.cpp:434] relu3_2 <- conv3_2
I0912 05:09:32.463989 26718 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 05:09:32.464213 26718 net.cpp:150] Setting up relu3_2
I0912 05:09:32.464222 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.464226 26718 net.cpp:165] Memory required for data: 2640384000
I0912 05:09:32.464229 26718 layer_factory.hpp:77] Creating layer conv3_3
I0912 05:09:32.464242 26718 net.cpp:100] Creating Layer conv3_3
I0912 05:09:32.464248 26718 net.cpp:434] conv3_3 <- conv3_2
I0912 05:09:32.464258 26718 net.cpp:408] conv3_3 -> conv3_3
I0912 05:09:32.487761 26718 net.cpp:150] Setting up conv3_3
I0912 05:09:32.487778 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.487782 26718 net.cpp:165] Memory required for data: 2684620800
I0912 05:09:32.487792 26718 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 05:09:32.487800 26718 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 05:09:32.487812 26718 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 05:09:32.487818 26718 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 05:09:32.488099 26718 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 05:09:32.488108 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.488111 26718 net.cpp:165] Memory required for data: 2728857600
I0912 05:09:32.488119 26718 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 05:09:32.488143 26718 net.cpp:100] Creating Layer conv3_3_scale
I0912 05:09:32.488150 26718 net.cpp:434] conv3_3_scale <- conv3_3
I0912 05:09:32.488155 26718 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 05:09:32.488210 26718 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 05:09:32.488389 26718 net.cpp:150] Setting up conv3_3_scale
I0912 05:09:32.488397 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.488400 26718 net.cpp:165] Memory required for data: 2773094400
I0912 05:09:32.488407 26718 layer_factory.hpp:77] Creating layer relu3_3
I0912 05:09:32.488415 26718 net.cpp:100] Creating Layer relu3_3
I0912 05:09:32.488420 26718 net.cpp:434] relu3_3 <- conv3_3
I0912 05:09:32.488427 26718 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 05:09:32.488652 26718 net.cpp:150] Setting up relu3_3
I0912 05:09:32.488662 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:32.488664 26718 net.cpp:165] Memory required for data: 2817331200
I0912 05:09:32.488667 26718 layer_factory.hpp:77] Creating layer pool3
I0912 05:09:32.488672 26718 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 05:09:32.488683 26718 net.cpp:100] Creating Layer pool3
I0912 05:09:32.488689 26718 net.cpp:434] pool3 <- conv3_3
I0912 05:09:32.488696 26718 net.cpp:408] pool3 -> pool3
I0912 05:09:32.488704 26718 net.cpp:408] pool3 -> pool3_mask
I0912 05:09:32.488762 26718 net.cpp:150] Setting up pool3
I0912 05:09:32.488771 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:32.488778 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:32.488781 26718 net.cpp:165] Memory required for data: 2839449600
I0912 05:09:32.488785 26718 layer_factory.hpp:77] Creating layer conv4_1
I0912 05:09:32.488796 26718 net.cpp:100] Creating Layer conv4_1
I0912 05:09:32.488802 26718 net.cpp:434] conv4_1 <- pool3
I0912 05:09:32.488808 26718 net.cpp:408] conv4_1 -> conv4_1
I0912 05:09:32.532672 26718 net.cpp:150] Setting up conv4_1
I0912 05:09:32.532690 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.532701 26718 net.cpp:165] Memory required for data: 2861568000
I0912 05:09:32.532711 26718 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 05:09:32.532726 26718 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 05:09:32.532734 26718 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 05:09:32.532740 26718 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 05:09:32.533020 26718 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 05:09:32.533030 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.533032 26718 net.cpp:165] Memory required for data: 2883686400
I0912 05:09:32.533041 26718 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 05:09:32.533048 26718 net.cpp:100] Creating Layer conv4_1_scale
I0912 05:09:32.533058 26718 net.cpp:434] conv4_1_scale <- conv4_1
I0912 05:09:32.533062 26718 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 05:09:32.533112 26718 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 05:09:32.533277 26718 net.cpp:150] Setting up conv4_1_scale
I0912 05:09:32.533285 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.533288 26718 net.cpp:165] Memory required for data: 2905804800
I0912 05:09:32.533294 26718 layer_factory.hpp:77] Creating layer relu4_1
I0912 05:09:32.533306 26718 net.cpp:100] Creating Layer relu4_1
I0912 05:09:32.533311 26718 net.cpp:434] relu4_1 <- conv4_1
I0912 05:09:32.533315 26718 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 05:09:32.534451 26718 net.cpp:150] Setting up relu4_1
I0912 05:09:32.534468 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.534473 26718 net.cpp:165] Memory required for data: 2927923200
I0912 05:09:32.534477 26718 layer_factory.hpp:77] Creating layer conv4_2
I0912 05:09:32.534490 26718 net.cpp:100] Creating Layer conv4_2
I0912 05:09:32.534495 26718 net.cpp:434] conv4_2 <- conv4_1
I0912 05:09:32.534502 26718 net.cpp:408] conv4_2 -> conv4_2
I0912 05:09:32.617187 26718 net.cpp:150] Setting up conv4_2
I0912 05:09:32.617218 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.617223 26718 net.cpp:165] Memory required for data: 2950041600
I0912 05:09:32.617229 26718 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 05:09:32.617238 26718 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 05:09:32.617247 26718 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 05:09:32.617255 26718 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 05:09:32.617535 26718 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 05:09:32.617545 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.617549 26718 net.cpp:165] Memory required for data: 2972160000
I0912 05:09:32.617558 26718 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 05:09:32.617564 26718 net.cpp:100] Creating Layer conv4_2_scale
I0912 05:09:32.617574 26718 net.cpp:434] conv4_2_scale <- conv4_2
I0912 05:09:32.617580 26718 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 05:09:32.617628 26718 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 05:09:32.617791 26718 net.cpp:150] Setting up conv4_2_scale
I0912 05:09:32.617799 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.617802 26718 net.cpp:165] Memory required for data: 2994278400
I0912 05:09:32.617808 26718 layer_factory.hpp:77] Creating layer relu4_2
I0912 05:09:32.617818 26718 net.cpp:100] Creating Layer relu4_2
I0912 05:09:32.617822 26718 net.cpp:434] relu4_2 <- conv4_2
I0912 05:09:32.617828 26718 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 05:09:32.618991 26718 net.cpp:150] Setting up relu4_2
I0912 05:09:32.619005 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.619014 26718 net.cpp:165] Memory required for data: 3016396800
I0912 05:09:32.619019 26718 layer_factory.hpp:77] Creating layer conv4_3
I0912 05:09:32.619031 26718 net.cpp:100] Creating Layer conv4_3
I0912 05:09:32.619037 26718 net.cpp:434] conv4_3 <- conv4_2
I0912 05:09:32.619045 26718 net.cpp:408] conv4_3 -> conv4_3
I0912 05:09:32.704578 26718 net.cpp:150] Setting up conv4_3
I0912 05:09:32.704597 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.704602 26718 net.cpp:165] Memory required for data: 3038515200
I0912 05:09:32.704627 26718 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 05:09:32.704643 26718 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 05:09:32.704650 26718 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 05:09:32.704661 26718 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 05:09:32.704931 26718 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 05:09:32.704939 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.704943 26718 net.cpp:165] Memory required for data: 3060633600
I0912 05:09:32.704952 26718 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 05:09:32.704963 26718 net.cpp:100] Creating Layer conv4_3_scale
I0912 05:09:32.704969 26718 net.cpp:434] conv4_3_scale <- conv4_3
I0912 05:09:32.704974 26718 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 05:09:32.705024 26718 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 05:09:32.705186 26718 net.cpp:150] Setting up conv4_3_scale
I0912 05:09:32.705194 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.705198 26718 net.cpp:165] Memory required for data: 3082752000
I0912 05:09:32.705204 26718 layer_factory.hpp:77] Creating layer relu4_3
I0912 05:09:32.705212 26718 net.cpp:100] Creating Layer relu4_3
I0912 05:09:32.705217 26718 net.cpp:434] relu4_3 <- conv4_3
I0912 05:09:32.705224 26718 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 05:09:32.705451 26718 net.cpp:150] Setting up relu4_3
I0912 05:09:32.705461 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:32.705463 26718 net.cpp:165] Memory required for data: 3104870400
I0912 05:09:32.705467 26718 layer_factory.hpp:77] Creating layer pool4
I0912 05:09:32.705473 26718 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 05:09:32.705482 26718 net.cpp:100] Creating Layer pool4
I0912 05:09:32.705487 26718 net.cpp:434] pool4 <- conv4_3
I0912 05:09:32.705507 26718 net.cpp:408] pool4 -> pool4
I0912 05:09:32.705516 26718 net.cpp:408] pool4 -> pool4_mask
I0912 05:09:32.705577 26718 net.cpp:150] Setting up pool4
I0912 05:09:32.705585 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.705590 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.705592 26718 net.cpp:165] Memory required for data: 3116175360
I0912 05:09:32.705596 26718 layer_factory.hpp:77] Creating layer conv5_1
I0912 05:09:32.705610 26718 net.cpp:100] Creating Layer conv5_1
I0912 05:09:32.705615 26718 net.cpp:434] conv5_1 <- pool4
I0912 05:09:32.705623 26718 net.cpp:408] conv5_1 -> conv5_1
I0912 05:09:32.789165 26718 net.cpp:150] Setting up conv5_1
I0912 05:09:32.789182 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.789186 26718 net.cpp:165] Memory required for data: 3121827840
I0912 05:09:32.789201 26718 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 05:09:32.789216 26718 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 05:09:32.789222 26718 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 05:09:32.789228 26718 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 05:09:32.789515 26718 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 05:09:32.789525 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.789527 26718 net.cpp:165] Memory required for data: 3127480320
I0912 05:09:32.789535 26718 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 05:09:32.789544 26718 net.cpp:100] Creating Layer conv5_1_scale
I0912 05:09:32.789551 26718 net.cpp:434] conv5_1_scale <- conv5_1
I0912 05:09:32.789554 26718 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 05:09:32.789611 26718 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 05:09:32.789767 26718 net.cpp:150] Setting up conv5_1_scale
I0912 05:09:32.789774 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.789777 26718 net.cpp:165] Memory required for data: 3133132800
I0912 05:09:32.789783 26718 layer_factory.hpp:77] Creating layer relu5_1
I0912 05:09:32.789793 26718 net.cpp:100] Creating Layer relu5_1
I0912 05:09:32.789798 26718 net.cpp:434] relu5_1 <- conv5_1
I0912 05:09:32.789803 26718 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 05:09:32.790019 26718 net.cpp:150] Setting up relu5_1
I0912 05:09:32.790029 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.790035 26718 net.cpp:165] Memory required for data: 3138785280
I0912 05:09:32.790040 26718 layer_factory.hpp:77] Creating layer conv5_2
I0912 05:09:32.790051 26718 net.cpp:100] Creating Layer conv5_2
I0912 05:09:32.790056 26718 net.cpp:434] conv5_2 <- conv5_1
I0912 05:09:32.790065 26718 net.cpp:408] conv5_2 -> conv5_2
I0912 05:09:32.873684 26718 net.cpp:150] Setting up conv5_2
I0912 05:09:32.873702 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.873705 26718 net.cpp:165] Memory required for data: 3144437760
I0912 05:09:32.873713 26718 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 05:09:32.873724 26718 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 05:09:32.873734 26718 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 05:09:32.873742 26718 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 05:09:32.874011 26718 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 05:09:32.874020 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.874023 26718 net.cpp:165] Memory required for data: 3150090240
I0912 05:09:32.874032 26718 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 05:09:32.874045 26718 net.cpp:100] Creating Layer conv5_2_scale
I0912 05:09:32.874053 26718 net.cpp:434] conv5_2_scale <- conv5_2
I0912 05:09:32.874058 26718 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 05:09:32.874114 26718 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 05:09:32.874270 26718 net.cpp:150] Setting up conv5_2_scale
I0912 05:09:32.874279 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.874281 26718 net.cpp:165] Memory required for data: 3155742720
I0912 05:09:32.874289 26718 layer_factory.hpp:77] Creating layer relu5_2
I0912 05:09:32.874310 26718 net.cpp:100] Creating Layer relu5_2
I0912 05:09:32.874316 26718 net.cpp:434] relu5_2 <- conv5_2
I0912 05:09:32.874323 26718 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 05:09:32.874541 26718 net.cpp:150] Setting up relu5_2
I0912 05:09:32.874550 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.874553 26718 net.cpp:165] Memory required for data: 3161395200
I0912 05:09:32.874558 26718 layer_factory.hpp:77] Creating layer conv5_3
I0912 05:09:32.874570 26718 net.cpp:100] Creating Layer conv5_3
I0912 05:09:32.874577 26718 net.cpp:434] conv5_3 <- conv5_2
I0912 05:09:32.874585 26718 net.cpp:408] conv5_3 -> conv5_3
I0912 05:09:32.958115 26718 net.cpp:150] Setting up conv5_3
I0912 05:09:32.958132 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.958137 26718 net.cpp:165] Memory required for data: 3167047680
I0912 05:09:32.958143 26718 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 05:09:32.958155 26718 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 05:09:32.958165 26718 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 05:09:32.958171 26718 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 05:09:32.958449 26718 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 05:09:32.958457 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.958461 26718 net.cpp:165] Memory required for data: 3172700160
I0912 05:09:32.958469 26718 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 05:09:32.958482 26718 net.cpp:100] Creating Layer conv5_3_scale
I0912 05:09:32.958489 26718 net.cpp:434] conv5_3_scale <- conv5_3
I0912 05:09:32.958494 26718 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 05:09:32.958551 26718 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 05:09:32.958709 26718 net.cpp:150] Setting up conv5_3_scale
I0912 05:09:32.958715 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.958719 26718 net.cpp:165] Memory required for data: 3178352640
I0912 05:09:32.958725 26718 layer_factory.hpp:77] Creating layer relu5_3
I0912 05:09:32.958732 26718 net.cpp:100] Creating Layer relu5_3
I0912 05:09:32.958737 26718 net.cpp:434] relu5_3 <- conv5_3
I0912 05:09:32.958744 26718 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 05:09:32.958961 26718 net.cpp:150] Setting up relu5_3
I0912 05:09:32.958971 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.958974 26718 net.cpp:165] Memory required for data: 3184005120
I0912 05:09:32.958979 26718 layer_factory.hpp:77] Creating layer pool5
I0912 05:09:32.958986 26718 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 05:09:32.958993 26718 net.cpp:100] Creating Layer pool5
I0912 05:09:32.958998 26718 net.cpp:434] pool5 <- conv5_3
I0912 05:09:32.959004 26718 net.cpp:408] pool5 -> pool5
I0912 05:09:32.959010 26718 net.cpp:408] pool5 -> pool5_mask
I0912 05:09:32.959071 26718 net.cpp:150] Setting up pool5
I0912 05:09:32.959079 26718 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 05:09:32.959084 26718 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 05:09:32.959086 26718 net.cpp:165] Memory required for data: 3186954240
I0912 05:09:32.959089 26718 layer_factory.hpp:77] Creating layer upsample5
I0912 05:09:32.959100 26718 net.cpp:100] Creating Layer upsample5
I0912 05:09:32.959105 26718 net.cpp:434] upsample5 <- pool5
I0912 05:09:32.959110 26718 net.cpp:434] upsample5 <- pool5_mask
I0912 05:09:32.959115 26718 net.cpp:408] upsample5 -> pool5_D
I0912 05:09:32.959146 26718 net.cpp:150] Setting up upsample5
I0912 05:09:32.959153 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:32.959156 26718 net.cpp:165] Memory required for data: 3192606720
I0912 05:09:32.959159 26718 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 05:09:32.959175 26718 net.cpp:100] Creating Layer conv5_3_D
I0912 05:09:32.959180 26718 net.cpp:434] conv5_3_D <- pool5_D
I0912 05:09:32.959187 26718 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 05:09:33.042721 26718 net.cpp:150] Setting up conv5_3_D
I0912 05:09:33.042737 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.042757 26718 net.cpp:165] Memory required for data: 3198259200
I0912 05:09:33.042765 26718 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 05:09:33.042780 26718 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 05:09:33.042788 26718 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 05:09:33.042796 26718 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 05:09:33.043079 26718 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 05:09:33.043087 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.043090 26718 net.cpp:165] Memory required for data: 3203911680
I0912 05:09:33.043099 26718 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 05:09:33.043107 26718 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 05:09:33.043117 26718 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 05:09:33.043121 26718 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 05:09:33.043179 26718 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 05:09:33.043337 26718 net.cpp:150] Setting up conv5_3_D_scale
I0912 05:09:33.043345 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.043349 26718 net.cpp:165] Memory required for data: 3209564160
I0912 05:09:33.043354 26718 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 05:09:33.043365 26718 net.cpp:100] Creating Layer relu5_3_D
I0912 05:09:33.043370 26718 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 05:09:33.043373 26718 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 05:09:33.044520 26718 net.cpp:150] Setting up relu5_3_D
I0912 05:09:33.044534 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.044539 26718 net.cpp:165] Memory required for data: 3215216640
I0912 05:09:33.044544 26718 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 05:09:33.044575 26718 net.cpp:100] Creating Layer conv5_2_D
I0912 05:09:33.044581 26718 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 05:09:33.044591 26718 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 05:09:33.128156 26718 net.cpp:150] Setting up conv5_2_D
I0912 05:09:33.128173 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.128177 26718 net.cpp:165] Memory required for data: 3220869120
I0912 05:09:33.128186 26718 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 05:09:33.128206 26718 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 05:09:33.128212 26718 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 05:09:33.128218 26718 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 05:09:33.128504 26718 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 05:09:33.128512 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.128515 26718 net.cpp:165] Memory required for data: 3226521600
I0912 05:09:33.128523 26718 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 05:09:33.128530 26718 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 05:09:33.128537 26718 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 05:09:33.128546 26718 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 05:09:33.128607 26718 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 05:09:33.128764 26718 net.cpp:150] Setting up conv5_2_D_scale
I0912 05:09:33.128774 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.128779 26718 net.cpp:165] Memory required for data: 3232174080
I0912 05:09:33.128785 26718 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 05:09:33.128793 26718 net.cpp:100] Creating Layer relu5_2_D
I0912 05:09:33.128795 26718 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 05:09:33.128801 26718 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 05:09:33.129962 26718 net.cpp:150] Setting up relu5_2_D
I0912 05:09:33.129977 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.129982 26718 net.cpp:165] Memory required for data: 3237826560
I0912 05:09:33.129987 26718 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 05:09:33.130002 26718 net.cpp:100] Creating Layer conv5_1_D
I0912 05:09:33.130009 26718 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 05:09:33.130017 26718 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 05:09:33.213572 26718 net.cpp:150] Setting up conv5_1_D
I0912 05:09:33.213589 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.213593 26718 net.cpp:165] Memory required for data: 3243479040
I0912 05:09:33.213601 26718 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 05:09:33.213610 26718 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 05:09:33.213623 26718 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 05:09:33.213632 26718 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 05:09:33.213915 26718 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 05:09:33.213924 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.213927 26718 net.cpp:165] Memory required for data: 3249131520
I0912 05:09:33.213935 26718 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 05:09:33.213944 26718 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 05:09:33.213954 26718 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 05:09:33.213959 26718 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 05:09:33.214016 26718 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 05:09:33.214177 26718 net.cpp:150] Setting up conv5_1_D_scale
I0912 05:09:33.214185 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.214188 26718 net.cpp:165] Memory required for data: 3254784000
I0912 05:09:33.214195 26718 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 05:09:33.214202 26718 net.cpp:100] Creating Layer relu5_1_D
I0912 05:09:33.214207 26718 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 05:09:33.214215 26718 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 05:09:33.214437 26718 net.cpp:150] Setting up relu5_1_D
I0912 05:09:33.214445 26718 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 05:09:33.214449 26718 net.cpp:165] Memory required for data: 3260436480
I0912 05:09:33.214452 26718 layer_factory.hpp:77] Creating layer upsample4
I0912 05:09:33.214462 26718 net.cpp:100] Creating Layer upsample4
I0912 05:09:33.214467 26718 net.cpp:434] upsample4 <- conv5_1_D
I0912 05:09:33.214473 26718 net.cpp:434] upsample4 <- pool4_mask
I0912 05:09:33.214478 26718 net.cpp:408] upsample4 -> pool4_D
I0912 05:09:33.214519 26718 net.cpp:150] Setting up upsample4
I0912 05:09:33.214525 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:33.214529 26718 net.cpp:165] Memory required for data: 3282554880
I0912 05:09:33.214532 26718 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 05:09:33.214545 26718 net.cpp:100] Creating Layer conv4_3_D
I0912 05:09:33.214550 26718 net.cpp:434] conv4_3_D <- pool4_D
I0912 05:09:33.214557 26718 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 05:09:33.298128 26718 net.cpp:150] Setting up conv4_3_D
I0912 05:09:33.298147 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:33.298151 26718 net.cpp:165] Memory required for data: 3304673280
I0912 05:09:33.298158 26718 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 05:09:33.298168 26718 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 05:09:33.298178 26718 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 05:09:33.298187 26718 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 05:09:33.298471 26718 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 05:09:33.298480 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:33.298482 26718 net.cpp:165] Memory required for data: 3326791680
I0912 05:09:33.298491 26718 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 05:09:33.298506 26718 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 05:09:33.298512 26718 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 05:09:33.298517 26718 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 05:09:33.298575 26718 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 05:09:33.298748 26718 net.cpp:150] Setting up conv4_3_D_scale
I0912 05:09:33.298756 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:33.298759 26718 net.cpp:165] Memory required for data: 3348910080
I0912 05:09:33.298765 26718 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 05:09:33.298789 26718 net.cpp:100] Creating Layer relu4_3_D
I0912 05:09:33.298794 26718 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 05:09:33.298800 26718 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 05:09:33.299021 26718 net.cpp:150] Setting up relu4_3_D
I0912 05:09:33.299029 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:33.299032 26718 net.cpp:165] Memory required for data: 3371028480
I0912 05:09:33.299037 26718 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 05:09:33.299051 26718 net.cpp:100] Creating Layer conv4_2_D
I0912 05:09:33.299055 26718 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 05:09:33.299064 26718 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 05:09:33.382637 26718 net.cpp:150] Setting up conv4_2_D
I0912 05:09:33.382653 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:33.382658 26718 net.cpp:165] Memory required for data: 3393146880
I0912 05:09:33.382671 26718 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 05:09:33.382685 26718 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 05:09:33.382692 26718 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 05:09:33.382699 26718 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 05:09:33.382987 26718 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 05:09:33.382995 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:33.382999 26718 net.cpp:165] Memory required for data: 3415265280
I0912 05:09:33.383008 26718 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 05:09:33.383023 26718 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 05:09:33.383029 26718 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 05:09:33.383034 26718 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 05:09:33.383090 26718 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 05:09:33.383262 26718 net.cpp:150] Setting up conv4_2_D_scale
I0912 05:09:33.383270 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:33.383275 26718 net.cpp:165] Memory required for data: 3437383680
I0912 05:09:33.383280 26718 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 05:09:33.383289 26718 net.cpp:100] Creating Layer relu4_2_D
I0912 05:09:33.383294 26718 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 05:09:33.383298 26718 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 05:09:33.383515 26718 net.cpp:150] Setting up relu4_2_D
I0912 05:09:33.383524 26718 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 05:09:33.383528 26718 net.cpp:165] Memory required for data: 3459502080
I0912 05:09:33.383533 26718 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 05:09:33.383549 26718 net.cpp:100] Creating Layer conv4_1_D
I0912 05:09:33.383554 26718 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 05:09:33.383561 26718 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 05:09:33.427517 26718 net.cpp:150] Setting up conv4_1_D
I0912 05:09:33.427534 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:33.427547 26718 net.cpp:165] Memory required for data: 3470561280
I0912 05:09:33.427557 26718 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 05:09:33.427568 26718 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 05:09:33.427575 26718 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 05:09:33.427582 26718 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 05:09:33.427875 26718 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 05:09:33.427882 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:33.427886 26718 net.cpp:165] Memory required for data: 3481620480
I0912 05:09:33.427918 26718 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 05:09:33.427927 26718 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 05:09:33.427937 26718 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 05:09:33.427943 26718 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 05:09:33.428001 26718 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 05:09:33.428176 26718 net.cpp:150] Setting up conv4_1_D_scale
I0912 05:09:33.428185 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:33.428205 26718 net.cpp:165] Memory required for data: 3492679680
I0912 05:09:33.428211 26718 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 05:09:33.428217 26718 net.cpp:100] Creating Layer relu4_1_D
I0912 05:09:33.428222 26718 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 05:09:33.428227 26718 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 05:09:33.428465 26718 net.cpp:150] Setting up relu4_1_D
I0912 05:09:33.428474 26718 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 05:09:33.428478 26718 net.cpp:165] Memory required for data: 3503738880
I0912 05:09:33.428481 26718 layer_factory.hpp:77] Creating layer upsample3
I0912 05:09:33.428491 26718 net.cpp:100] Creating Layer upsample3
I0912 05:09:33.428498 26718 net.cpp:434] upsample3 <- conv4_1_D
I0912 05:09:33.428503 26718 net.cpp:434] upsample3 <- pool3_mask
I0912 05:09:33.428508 26718 net.cpp:408] upsample3 -> pool3_D
I0912 05:09:33.428516 26718 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 05:09:33.428555 26718 net.cpp:150] Setting up upsample3
I0912 05:09:33.428562 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:33.428568 26718 net.cpp:165] Memory required for data: 3547975680
I0912 05:09:33.428572 26718 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 05:09:33.428581 26718 net.cpp:100] Creating Layer conv3_3_D
I0912 05:09:33.428586 26718 net.cpp:434] conv3_3_D <- pool3_D
I0912 05:09:33.428596 26718 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 05:09:33.452235 26718 net.cpp:150] Setting up conv3_3_D
I0912 05:09:33.452252 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:33.452262 26718 net.cpp:165] Memory required for data: 3592212480
I0912 05:09:33.452270 26718 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 05:09:33.452278 26718 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 05:09:33.452286 26718 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 05:09:33.452291 26718 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 05:09:33.452600 26718 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 05:09:33.452610 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:33.452613 26718 net.cpp:165] Memory required for data: 3636449280
I0912 05:09:33.452621 26718 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 05:09:33.452633 26718 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 05:09:33.452643 26718 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 05:09:33.452647 26718 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 05:09:33.452706 26718 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 05:09:33.452900 26718 net.cpp:150] Setting up conv3_3_D_scale
I0912 05:09:33.452909 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:33.452913 26718 net.cpp:165] Memory required for data: 3680686080
I0912 05:09:33.452919 26718 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 05:09:33.452927 26718 net.cpp:100] Creating Layer relu3_3_D
I0912 05:09:33.452934 26718 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 05:09:33.452939 26718 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 05:09:33.454113 26718 net.cpp:150] Setting up relu3_3_D
I0912 05:09:33.454129 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:33.454135 26718 net.cpp:165] Memory required for data: 3724922880
I0912 05:09:33.454139 26718 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 05:09:33.454152 26718 net.cpp:100] Creating Layer conv3_2_D
I0912 05:09:33.454159 26718 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 05:09:33.454167 26718 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 05:09:33.476917 26718 net.cpp:150] Setting up conv3_2_D
I0912 05:09:33.476933 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:33.476943 26718 net.cpp:165] Memory required for data: 3769159680
I0912 05:09:33.476953 26718 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 05:09:33.476960 26718 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 05:09:33.476965 26718 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 05:09:33.476989 26718 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 05:09:33.477295 26718 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 05:09:33.477304 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:33.477308 26718 net.cpp:165] Memory required for data: 3813396480
I0912 05:09:33.477315 26718 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 05:09:33.477325 26718 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 05:09:33.477332 26718 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 05:09:33.477337 26718 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 05:09:33.477401 26718 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 05:09:33.477597 26718 net.cpp:150] Setting up conv3_2_D_scale
I0912 05:09:33.477607 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:33.477609 26718 net.cpp:165] Memory required for data: 3857633280
I0912 05:09:33.477617 26718 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 05:09:33.477627 26718 net.cpp:100] Creating Layer relu3_2_D
I0912 05:09:33.477630 26718 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 05:09:33.477638 26718 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 05:09:33.478797 26718 net.cpp:150] Setting up relu3_2_D
I0912 05:09:33.478811 26718 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 05:09:33.478816 26718 net.cpp:165] Memory required for data: 3901870080
I0912 05:09:33.478821 26718 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 05:09:33.478833 26718 net.cpp:100] Creating Layer conv3_1_D
I0912 05:09:33.478839 26718 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 05:09:33.478848 26718 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 05:09:33.492763 26718 net.cpp:150] Setting up conv3_1_D
I0912 05:09:33.492779 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:33.492789 26718 net.cpp:165] Memory required for data: 3923988480
I0912 05:09:33.492799 26718 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 05:09:33.492807 26718 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 05:09:33.492811 26718 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 05:09:33.492817 26718 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 05:09:33.493125 26718 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 05:09:33.493134 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:33.493137 26718 net.cpp:165] Memory required for data: 3946106880
I0912 05:09:33.493147 26718 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 05:09:33.493158 26718 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 05:09:33.493167 26718 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 05:09:33.493171 26718 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 05:09:33.493227 26718 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 05:09:33.494696 26718 net.cpp:150] Setting up conv3_1_D_scale
I0912 05:09:33.494711 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:33.494721 26718 net.cpp:165] Memory required for data: 3968225280
I0912 05:09:33.494734 26718 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 05:09:33.494741 26718 net.cpp:100] Creating Layer relu3_1_D
I0912 05:09:33.494750 26718 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 05:09:33.494756 26718 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 05:09:33.494994 26718 net.cpp:150] Setting up relu3_1_D
I0912 05:09:33.495007 26718 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 05:09:33.495012 26718 net.cpp:165] Memory required for data: 3990343680
I0912 05:09:33.495014 26718 layer_factory.hpp:77] Creating layer upsample2
I0912 05:09:33.495023 26718 net.cpp:100] Creating Layer upsample2
I0912 05:09:33.495028 26718 net.cpp:434] upsample2 <- conv3_1_D
I0912 05:09:33.495033 26718 net.cpp:434] upsample2 <- pool2_mask
I0912 05:09:33.495038 26718 net.cpp:408] upsample2 -> pool2_D
I0912 05:09:33.495046 26718 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 05:09:33.495087 26718 net.cpp:150] Setting up upsample2
I0912 05:09:33.495108 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:33.495113 26718 net.cpp:165] Memory required for data: 4078817280
I0912 05:09:33.495116 26718 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 05:09:33.495128 26718 net.cpp:100] Creating Layer conv2_2_D
I0912 05:09:33.495133 26718 net.cpp:434] conv2_2_D <- pool2_D
I0912 05:09:33.495142 26718 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 05:09:33.503015 26718 net.cpp:150] Setting up conv2_2_D
I0912 05:09:33.503031 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:33.503041 26718 net.cpp:165] Memory required for data: 4167290880
I0912 05:09:33.503049 26718 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 05:09:33.503058 26718 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 05:09:33.503065 26718 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 05:09:33.503072 26718 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 05:09:33.503412 26718 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 05:09:33.503420 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:33.503423 26718 net.cpp:165] Memory required for data: 4255764480
I0912 05:09:33.503432 26718 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 05:09:33.503445 26718 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 05:09:33.503453 26718 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 05:09:33.503458 26718 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 05:09:33.503521 26718 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 05:09:33.503783 26718 net.cpp:150] Setting up conv2_2_D_scale
I0912 05:09:33.503793 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:33.503795 26718 net.cpp:165] Memory required for data: 4344238080
I0912 05:09:33.503801 26718 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 05:09:33.503811 26718 net.cpp:100] Creating Layer relu2_2_D
I0912 05:09:33.503816 26718 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 05:09:33.503821 26718 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 05:09:33.504055 26718 net.cpp:150] Setting up relu2_2_D
I0912 05:09:33.504063 26718 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 05:09:33.504066 26718 net.cpp:165] Memory required for data: 4432711680
I0912 05:09:33.504070 26718 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 05:09:33.504084 26718 net.cpp:100] Creating Layer conv2_1_D
I0912 05:09:33.504089 26718 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 05:09:33.504097 26718 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 05:09:33.510301 26718 net.cpp:150] Setting up conv2_1_D
I0912 05:09:33.510323 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:33.510332 26718 net.cpp:165] Memory required for data: 4476948480
I0912 05:09:33.510349 26718 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 05:09:33.510360 26718 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 05:09:33.510370 26718 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 05:09:33.510380 26718 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 05:09:33.510742 26718 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 05:09:33.510751 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:33.510754 26718 net.cpp:165] Memory required for data: 4521185280
I0912 05:09:33.510763 26718 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 05:09:33.510772 26718 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 05:09:33.510777 26718 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 05:09:33.510782 26718 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 05:09:33.510843 26718 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 05:09:33.511111 26718 net.cpp:150] Setting up conv2_1_D_scale
I0912 05:09:33.511121 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:33.511124 26718 net.cpp:165] Memory required for data: 4565422080
I0912 05:09:33.511131 26718 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 05:09:33.511140 26718 net.cpp:100] Creating Layer relu2_1_D
I0912 05:09:33.511145 26718 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 05:09:33.511168 26718 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 05:09:33.511402 26718 net.cpp:150] Setting up relu2_1_D
I0912 05:09:33.511411 26718 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 05:09:33.511415 26718 net.cpp:165] Memory required for data: 4609658880
I0912 05:09:33.511420 26718 layer_factory.hpp:77] Creating layer upsample1
I0912 05:09:33.511428 26718 net.cpp:100] Creating Layer upsample1
I0912 05:09:33.511433 26718 net.cpp:434] upsample1 <- conv2_1_D
I0912 05:09:33.511440 26718 net.cpp:434] upsample1 <- pool1_mask
I0912 05:09:33.511447 26718 net.cpp:408] upsample1 -> pool1_D
I0912 05:09:33.511456 26718 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 05:09:33.511493 26718 net.cpp:150] Setting up upsample1
I0912 05:09:33.511500 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:33.511504 26718 net.cpp:165] Memory required for data: 4786606080
I0912 05:09:33.511507 26718 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 05:09:33.511518 26718 net.cpp:100] Creating Layer conv1_2_D
I0912 05:09:33.511523 26718 net.cpp:434] conv1_2_D <- pool1_D
I0912 05:09:33.511531 26718 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 05:09:33.516214 26718 net.cpp:150] Setting up conv1_2_D
I0912 05:09:33.516232 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:33.516245 26718 net.cpp:165] Memory required for data: 4963553280
I0912 05:09:33.516254 26718 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 05:09:33.516264 26718 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 05:09:33.516270 26718 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 05:09:33.516280 26718 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 05:09:33.516718 26718 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 05:09:33.516727 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:33.516731 26718 net.cpp:165] Memory required for data: 5140500480
I0912 05:09:33.516739 26718 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 05:09:33.516751 26718 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 05:09:33.516755 26718 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 05:09:33.516760 26718 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 05:09:33.516819 26718 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 05:09:33.518558 26718 net.cpp:150] Setting up conv1_2_D_scale
I0912 05:09:33.518573 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:33.518579 26718 net.cpp:165] Memory required for data: 5317447680
I0912 05:09:33.518587 26718 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 05:09:33.518596 26718 net.cpp:100] Creating Layer relu1_2_D
I0912 05:09:33.518602 26718 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 05:09:33.518607 26718 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 05:09:33.518851 26718 net.cpp:150] Setting up relu1_2_D
I0912 05:09:33.518862 26718 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 05:09:33.518867 26718 net.cpp:165] Memory required for data: 5494394880
I0912 05:09:33.518869 26718 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 05:09:33.518882 26718 net.cpp:100] Creating Layer conv1_1_1_D
I0912 05:09:33.518888 26718 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 05:09:33.518895 26718 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 05:09:33.521124 26718 net.cpp:150] Setting up conv1_1_1_D
I0912 05:09:33.521139 26718 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 05:09:33.521144 26718 net.cpp:165] Memory required for data: 5499924480
I0912 05:09:33.521152 26718 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 05:09:33.521163 26718 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 05:09:33.521168 26718 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 05:09:33.521174 26718 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 05:09:33.521183 26718 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 05:09:33.521260 26718 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 05:09:33.521268 26718 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 05:09:33.521272 26718 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 05:09:33.521275 26718 net.cpp:165] Memory required for data: 5510983680
I0912 05:09:33.521281 26718 layer_factory.hpp:77] Creating layer loss
I0912 05:09:33.521291 26718 net.cpp:100] Creating Layer loss
I0912 05:09:33.521296 26718 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 05:09:33.521301 26718 net.cpp:434] loss <- label_data_1_split_0
I0912 05:09:33.521309 26718 net.cpp:408] loss -> loss
I0912 05:09:33.521320 26718 layer_factory.hpp:77] Creating layer loss
I0912 05:09:33.525409 26718 net.cpp:150] Setting up loss
I0912 05:09:33.525426 26718 net.cpp:157] Top shape: (1)
I0912 05:09:33.525435 26718 net.cpp:160]     with loss weight 1
I0912 05:09:33.525452 26718 net.cpp:165] Memory required for data: 5510983684
I0912 05:09:33.525456 26718 layer_factory.hpp:77] Creating layer accuracy
I0912 05:09:33.525465 26718 net.cpp:100] Creating Layer accuracy
I0912 05:09:33.525470 26718 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 05:09:33.525475 26718 net.cpp:434] accuracy <- label_data_1_split_1
I0912 05:09:33.525482 26718 net.cpp:408] accuracy -> accuracy
I0912 05:09:33.525490 26718 net.cpp:408] accuracy -> per_class_accuracy
I0912 05:09:33.525547 26718 net.cpp:150] Setting up accuracy
I0912 05:09:33.525553 26718 net.cpp:157] Top shape: (1)
I0912 05:09:33.525557 26718 net.cpp:157] Top shape: 2 (2)
I0912 05:09:33.525560 26718 net.cpp:165] Memory required for data: 5510983696
I0912 05:09:33.525564 26718 net.cpp:228] accuracy does not need backward computation.
I0912 05:09:33.525568 26718 net.cpp:226] loss needs backward computation.
I0912 05:09:33.525573 26718 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 05:09:33.525578 26718 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 05:09:33.525580 26718 net.cpp:226] relu1_2_D needs backward computation.
I0912 05:09:33.525583 26718 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 05:09:33.525586 26718 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 05:09:33.525589 26718 net.cpp:226] conv1_2_D needs backward computation.
I0912 05:09:33.525593 26718 net.cpp:226] upsample1 needs backward computation.
I0912 05:09:33.525596 26718 net.cpp:226] relu2_1_D needs backward computation.
I0912 05:09:33.525599 26718 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 05:09:33.525604 26718 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 05:09:33.525605 26718 net.cpp:226] conv2_1_D needs backward computation.
I0912 05:09:33.525609 26718 net.cpp:226] relu2_2_D needs backward computation.
I0912 05:09:33.525612 26718 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 05:09:33.525616 26718 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 05:09:33.525619 26718 net.cpp:226] conv2_2_D needs backward computation.
I0912 05:09:33.525622 26718 net.cpp:226] upsample2 needs backward computation.
I0912 05:09:33.525627 26718 net.cpp:226] relu3_1_D needs backward computation.
I0912 05:09:33.525632 26718 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 05:09:33.525636 26718 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 05:09:33.525641 26718 net.cpp:226] conv3_1_D needs backward computation.
I0912 05:09:33.525645 26718 net.cpp:226] relu3_2_D needs backward computation.
I0912 05:09:33.525650 26718 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 05:09:33.525655 26718 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 05:09:33.525661 26718 net.cpp:226] conv3_2_D needs backward computation.
I0912 05:09:33.525666 26718 net.cpp:226] relu3_3_D needs backward computation.
I0912 05:09:33.525671 26718 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 05:09:33.525676 26718 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 05:09:33.525696 26718 net.cpp:226] conv3_3_D needs backward computation.
I0912 05:09:33.525701 26718 net.cpp:226] upsample3 needs backward computation.
I0912 05:09:33.525704 26718 net.cpp:226] relu4_1_D needs backward computation.
I0912 05:09:33.525708 26718 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 05:09:33.525712 26718 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 05:09:33.525718 26718 net.cpp:226] conv4_1_D needs backward computation.
I0912 05:09:33.525722 26718 net.cpp:226] relu4_2_D needs backward computation.
I0912 05:09:33.525727 26718 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 05:09:33.525730 26718 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 05:09:33.525735 26718 net.cpp:226] conv4_2_D needs backward computation.
I0912 05:09:33.525740 26718 net.cpp:226] relu4_3_D needs backward computation.
I0912 05:09:33.525744 26718 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 05:09:33.525748 26718 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 05:09:33.525753 26718 net.cpp:226] conv4_3_D needs backward computation.
I0912 05:09:33.525758 26718 net.cpp:226] upsample4 needs backward computation.
I0912 05:09:33.525763 26718 net.cpp:226] relu5_1_D needs backward computation.
I0912 05:09:33.525768 26718 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 05:09:33.525773 26718 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 05:09:33.525779 26718 net.cpp:226] conv5_1_D needs backward computation.
I0912 05:09:33.525781 26718 net.cpp:226] relu5_2_D needs backward computation.
I0912 05:09:33.525785 26718 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 05:09:33.525789 26718 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 05:09:33.525794 26718 net.cpp:226] conv5_2_D needs backward computation.
I0912 05:09:33.525802 26718 net.cpp:226] relu5_3_D needs backward computation.
I0912 05:09:33.525807 26718 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 05:09:33.525811 26718 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 05:09:33.525815 26718 net.cpp:226] conv5_3_D needs backward computation.
I0912 05:09:33.525820 26718 net.cpp:226] upsample5 needs backward computation.
I0912 05:09:33.525825 26718 net.cpp:226] pool5 needs backward computation.
I0912 05:09:33.525831 26718 net.cpp:226] relu5_3 needs backward computation.
I0912 05:09:33.525835 26718 net.cpp:226] conv5_3_scale needs backward computation.
I0912 05:09:33.525840 26718 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 05:09:33.525846 26718 net.cpp:226] conv5_3 needs backward computation.
I0912 05:09:33.525851 26718 net.cpp:226] relu5_2 needs backward computation.
I0912 05:09:33.525856 26718 net.cpp:226] conv5_2_scale needs backward computation.
I0912 05:09:33.525861 26718 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 05:09:33.525866 26718 net.cpp:226] conv5_2 needs backward computation.
I0912 05:09:33.525871 26718 net.cpp:226] relu5_1 needs backward computation.
I0912 05:09:33.525876 26718 net.cpp:226] conv5_1_scale needs backward computation.
I0912 05:09:33.525879 26718 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 05:09:33.525883 26718 net.cpp:226] conv5_1 needs backward computation.
I0912 05:09:33.525890 26718 net.cpp:226] pool4 needs backward computation.
I0912 05:09:33.525893 26718 net.cpp:226] relu4_3 needs backward computation.
I0912 05:09:33.525897 26718 net.cpp:226] conv4_3_scale needs backward computation.
I0912 05:09:33.525902 26718 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 05:09:33.525907 26718 net.cpp:226] conv4_3 needs backward computation.
I0912 05:09:33.525913 26718 net.cpp:226] relu4_2 needs backward computation.
I0912 05:09:33.525916 26718 net.cpp:226] conv4_2_scale needs backward computation.
I0912 05:09:33.525920 26718 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 05:09:33.525924 26718 net.cpp:226] conv4_2 needs backward computation.
I0912 05:09:33.525931 26718 net.cpp:226] relu4_1 needs backward computation.
I0912 05:09:33.525944 26718 net.cpp:226] conv4_1_scale needs backward computation.
I0912 05:09:33.525949 26718 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 05:09:33.525952 26718 net.cpp:226] conv4_1 needs backward computation.
I0912 05:09:33.525959 26718 net.cpp:226] pool3 needs backward computation.
I0912 05:09:33.525964 26718 net.cpp:226] relu3_3 needs backward computation.
I0912 05:09:33.525967 26718 net.cpp:226] conv3_3_scale needs backward computation.
I0912 05:09:33.525971 26718 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 05:09:33.525977 26718 net.cpp:226] conv3_3 needs backward computation.
I0912 05:09:33.525982 26718 net.cpp:226] relu3_2 needs backward computation.
I0912 05:09:33.525988 26718 net.cpp:226] conv3_2_scale needs backward computation.
I0912 05:09:33.525992 26718 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 05:09:33.525996 26718 net.cpp:226] conv3_2 needs backward computation.
I0912 05:09:33.526001 26718 net.cpp:226] relu3_1 needs backward computation.
I0912 05:09:33.526005 26718 net.cpp:226] conv3_1_scale needs backward computation.
I0912 05:09:33.526010 26718 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 05:09:33.526015 26718 net.cpp:226] conv3_1 needs backward computation.
I0912 05:09:33.526021 26718 net.cpp:226] pool2 needs backward computation.
I0912 05:09:33.526026 26718 net.cpp:226] relu2_2 needs backward computation.
I0912 05:09:33.526029 26718 net.cpp:226] conv2_2_scale needs backward computation.
I0912 05:09:33.526034 26718 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 05:09:33.526038 26718 net.cpp:226] conv2_2 needs backward computation.
I0912 05:09:33.526042 26718 net.cpp:226] relu2_1 needs backward computation.
I0912 05:09:33.526047 26718 net.cpp:226] conv2_1_scale needs backward computation.
I0912 05:09:33.526051 26718 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 05:09:33.526055 26718 net.cpp:226] conv2_1 needs backward computation.
I0912 05:09:33.526059 26718 net.cpp:226] pool1 needs backward computation.
I0912 05:09:33.526065 26718 net.cpp:226] relu1_2 needs backward computation.
I0912 05:09:33.526070 26718 net.cpp:226] conv1_2_scale needs backward computation.
I0912 05:09:33.526074 26718 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 05:09:33.526078 26718 net.cpp:226] conv1_2 needs backward computation.
I0912 05:09:33.526082 26718 net.cpp:226] relu1_1 needs backward computation.
I0912 05:09:33.526088 26718 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 05:09:33.526091 26718 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 05:09:33.526095 26718 net.cpp:226] conv1_1_1 needs backward computation.
I0912 05:09:33.526099 26718 net.cpp:228] label_data_1_split does not need backward computation.
I0912 05:09:33.526105 26718 net.cpp:228] data does not need backward computation.
I0912 05:09:33.526108 26718 net.cpp:270] This network produces output accuracy
I0912 05:09:33.526113 26718 net.cpp:270] This network produces output loss
I0912 05:09:33.526116 26718 net.cpp:270] This network produces output per_class_accuracy
I0912 05:09:33.526180 26718 net.cpp:283] Network initialization done.
I0912 05:09:33.526590 26718 solver.cpp:60] Solver scaffolding done.
I0912 05:09:33.535886 26718 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0912 05:09:33.940251 26718 net.cpp:761] Ignoring source layer conv1_1
I0912 05:09:33.940279 26718 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 05:09:33.940333 26718 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 05:09:33.940341 26718 net.cpp:761] Ignoring source layer pool1_drop
I0912 05:09:33.940419 26718 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 05:09:33.940569 26718 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 05:09:33.940577 26718 net.cpp:761] Ignoring source layer pool2_drop
I0912 05:09:33.940861 26718 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 05:09:33.941426 26718 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 05:09:33.941993 26718 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 05:09:33.942025 26718 net.cpp:761] Ignoring source layer pool3_drop
I0912 05:09:33.943289 26718 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 05:09:33.945297 26718 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 05:09:33.947317 26718 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 05:09:33.947327 26718 net.cpp:761] Ignoring source layer pool4_drop
I0912 05:09:33.949314 26718 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 05:09:33.951334 26718 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 05:09:33.953832 26718 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 05:09:33.953841 26718 net.cpp:761] Ignoring source layer pool5_drop
I0912 05:09:33.953846 26718 net.cpp:761] Ignoring source layer upsample5_drop
I0912 05:09:33.955873 26718 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 05:09:33.957993 26718 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 05:09:33.960000 26718 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 05:09:33.960011 26718 net.cpp:761] Ignoring source layer upsample4_drop
I0912 05:09:33.962040 26718 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 05:09:33.964224 26718 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 05:09:33.965304 26718 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 05:09:33.965312 26718 net.cpp:761] Ignoring source layer upsample3_drop
I0912 05:09:33.965885 26718 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 05:09:33.966464 26718 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 05:09:33.966747 26718 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 05:09:33.966753 26718 net.cpp:761] Ignoring source layer upsample2_drop
I0912 05:09:33.966894 26718 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 05:09:33.966972 26718 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 05:09:33.966980 26718 net.cpp:761] Ignoring source layer upsample1_drop
I0912 05:09:33.967022 26718 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 05:09:33.967030 26718 net.cpp:761] Ignoring source layer conv1_1_D
I0912 05:09:33.967033 26718 net.cpp:761] Ignoring source layer prob
I0912 05:09:34.298254 26718 net.cpp:761] Ignoring source layer conv1_1
I0912 05:09:34.298280 26718 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 05:09:34.298331 26718 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 05:09:34.298338 26718 net.cpp:761] Ignoring source layer pool1_drop
I0912 05:09:34.298444 26718 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 05:09:34.298655 26718 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 05:09:34.298661 26718 net.cpp:761] Ignoring source layer pool2_drop
I0912 05:09:34.299007 26718 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 05:09:34.299595 26718 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 05:09:34.300249 26718 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 05:09:34.300257 26718 net.cpp:761] Ignoring source layer pool3_drop
I0912 05:09:34.301518 26718 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 05:09:34.303705 26718 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 05:09:34.305842 26718 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 05:09:34.305850 26718 net.cpp:761] Ignoring source layer pool4_drop
I0912 05:09:34.307971 26718 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 05:09:34.310230 26718 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 05:09:34.312495 26718 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 05:09:34.312503 26718 net.cpp:761] Ignoring source layer pool5_drop
I0912 05:09:34.312508 26718 net.cpp:761] Ignoring source layer upsample5_drop
I0912 05:09:34.314728 26718 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 05:09:34.316905 26718 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 05:09:34.319033 26718 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 05:09:34.319042 26718 net.cpp:761] Ignoring source layer upsample4_drop
I0912 05:09:34.321171 26718 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 05:09:34.323405 26718 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 05:09:34.324506 26718 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 05:09:34.324514 26718 net.cpp:761] Ignoring source layer upsample3_drop
I0912 05:09:34.325083 26718 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 05:09:34.325626 26718 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 05:09:34.325915 26718 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 05:09:34.325922 26718 net.cpp:761] Ignoring source layer upsample2_drop
I0912 05:09:34.326066 26718 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 05:09:34.326146 26718 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 05:09:34.326153 26718 net.cpp:761] Ignoring source layer upsample1_drop
I0912 05:09:34.326195 26718 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 05:09:34.326202 26718 net.cpp:761] Ignoring source layer conv1_1_D
I0912 05:09:34.326205 26718 net.cpp:761] Ignoring source layer prob
I0912 05:09:34.335381 26718 caffe.cpp:251] Starting Optimization
I0912 05:09:34.335399 26718 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0912 05:09:34.335407 26718 solver.cpp:280] Learning Rate Policy: step
I0912 05:09:35.320647 26718 solver.cpp:228] Iteration 0, loss = 0.835057
I0912 05:09:35.320685 26718 solver.cpp:244]     Train net output #0: accuracy = 0.707694
I0912 05:09:35.320699 26718 solver.cpp:244]     Train net output #1: loss = 0.835057 (* 1 = 0.835057 loss)
I0912 05:09:35.320704 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.907739
I0912 05:09:35.320709 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.129961
I0912 05:09:35.320732 26718 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0912 05:09:51.487192 26718 solver.cpp:228] Iteration 20, loss = 0.428461
I0912 05:09:51.487239 26718 solver.cpp:244]     Train net output #0: accuracy = 0.790689
I0912 05:09:51.487251 26718 solver.cpp:244]     Train net output #1: loss = 0.428461 (* 1 = 0.428461 loss)
I0912 05:09:51.487257 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.71133
I0912 05:09:51.487262 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976705
I0912 05:09:51.487268 26718 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0912 05:10:08.069799 26718 solver.cpp:228] Iteration 40, loss = 0.359812
I0912 05:10:08.069941 26718 solver.cpp:244]     Train net output #0: accuracy = 0.83889
I0912 05:10:08.069954 26718 solver.cpp:244]     Train net output #1: loss = 0.359812 (* 1 = 0.359812 loss)
I0912 05:10:08.069959 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.800155
I0912 05:10:08.069964 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.888842
I0912 05:10:08.069972 26718 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0912 05:10:24.654633 26718 solver.cpp:228] Iteration 60, loss = 0.227521
I0912 05:10:24.654677 26718 solver.cpp:244]     Train net output #0: accuracy = 0.942415
I0912 05:10:24.654688 26718 solver.cpp:244]     Train net output #1: loss = 0.227521 (* 1 = 0.227521 loss)
I0912 05:10:24.654693 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986993
I0912 05:10:24.654698 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.898153
I0912 05:10:24.654706 26718 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0912 05:10:41.260921 26718 solver.cpp:228] Iteration 80, loss = 0.311976
I0912 05:10:41.261032 26718 solver.cpp:244]     Train net output #0: accuracy = 0.844466
I0912 05:10:41.261045 26718 solver.cpp:244]     Train net output #1: loss = 0.311976 (* 1 = 0.311976 loss)
I0912 05:10:41.261051 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.773694
I0912 05:10:41.261055 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.966023
I0912 05:10:41.261062 26718 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0912 05:10:57.833894 26718 solver.cpp:228] Iteration 100, loss = 0.164688
I0912 05:10:57.833932 26718 solver.cpp:244]     Train net output #0: accuracy = 0.959766
I0912 05:10:57.833943 26718 solver.cpp:244]     Train net output #1: loss = 0.164688 (* 1 = 0.164688 loss)
I0912 05:10:57.833948 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979833
I0912 05:10:57.833953 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.937403
I0912 05:10:57.833961 26718 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0912 05:11:14.414958 26718 solver.cpp:228] Iteration 120, loss = 0.147378
I0912 05:11:14.415127 26718 solver.cpp:244]     Train net output #0: accuracy = 0.932956
I0912 05:11:14.415164 26718 solver.cpp:244]     Train net output #1: loss = 0.147378 (* 1 = 0.147378 loss)
I0912 05:11:14.415172 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.916463
I0912 05:11:14.415177 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.967221
I0912 05:11:14.415186 26718 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0912 05:11:31.073181 26718 solver.cpp:228] Iteration 140, loss = 0.0854933
I0912 05:11:31.073225 26718 solver.cpp:244]     Train net output #0: accuracy = 0.981502
I0912 05:11:31.073237 26718 solver.cpp:244]     Train net output #1: loss = 0.0854933 (* 1 = 0.0854933 loss)
I0912 05:11:31.073243 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.976708
I0912 05:11:31.073248 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98621
I0912 05:11:31.073256 26718 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0912 05:11:47.743115 26718 solver.cpp:228] Iteration 160, loss = 0.0708781
I0912 05:11:47.743252 26718 solver.cpp:244]     Train net output #0: accuracy = 0.975952
I0912 05:11:47.743269 26718 solver.cpp:244]     Train net output #1: loss = 0.0708781 (* 1 = 0.0708781 loss)
I0912 05:11:47.743276 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.965723
I0912 05:11:47.743281 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995259
I0912 05:11:47.743288 26718 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0912 05:12:04.398644 26718 solver.cpp:228] Iteration 180, loss = 0.149911
I0912 05:12:04.398686 26718 solver.cpp:244]     Train net output #0: accuracy = 0.934873
I0912 05:12:04.398710 26718 solver.cpp:244]     Train net output #1: loss = 0.149911 (* 1 = 0.149911 loss)
I0912 05:12:04.398720 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.936248
I0912 05:12:04.398730 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.933181
I0912 05:12:04.398737 26718 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0912 05:12:21.047554 26718 solver.cpp:228] Iteration 200, loss = 0.0908661
I0912 05:12:21.047679 26718 solver.cpp:244]     Train net output #0: accuracy = 0.962721
I0912 05:12:21.047694 26718 solver.cpp:244]     Train net output #1: loss = 0.0908662 (* 1 = 0.0908662 loss)
I0912 05:12:21.047700 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.951467
I0912 05:12:21.047705 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996009
I0912 05:12:21.047713 26718 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0912 05:12:37.699643 26718 solver.cpp:228] Iteration 220, loss = 0.0848529
I0912 05:12:37.699697 26718 solver.cpp:244]     Train net output #0: accuracy = 0.961944
I0912 05:12:37.699712 26718 solver.cpp:244]     Train net output #1: loss = 0.084853 (* 1 = 0.084853 loss)
I0912 05:12:37.699723 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.941013
I0912 05:12:37.699728 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991634
I0912 05:12:37.699735 26718 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0912 05:12:54.303750 26718 solver.cpp:228] Iteration 240, loss = 0.0922108
I0912 05:12:54.303894 26718 solver.cpp:244]     Train net output #0: accuracy = 0.967646
I0912 05:12:54.303908 26718 solver.cpp:244]     Train net output #1: loss = 0.0922109 (* 1 = 0.0922109 loss)
I0912 05:12:54.303915 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.962746
I0912 05:12:54.303920 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.972824
I0912 05:12:54.303926 26718 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0912 05:13:10.873272 26718 solver.cpp:228] Iteration 260, loss = 0.0645399
I0912 05:13:10.873318 26718 solver.cpp:244]     Train net output #0: accuracy = 0.981685
I0912 05:13:10.873330 26718 solver.cpp:244]     Train net output #1: loss = 0.0645399 (* 1 = 0.0645399 loss)
I0912 05:13:10.873337 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980105
I0912 05:13:10.873342 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983657
I0912 05:13:10.873349 26718 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0912 05:13:27.465207 26718 solver.cpp:228] Iteration 280, loss = 0.10361
I0912 05:13:27.465417 26718 solver.cpp:244]     Train net output #0: accuracy = 0.96543
I0912 05:13:27.465448 26718 solver.cpp:244]     Train net output #1: loss = 0.10361 (* 1 = 0.10361 loss)
I0912 05:13:27.465457 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.953134
I0912 05:13:27.465463 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979723
I0912 05:13:27.465471 26718 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0912 05:13:44.052613 26718 solver.cpp:228] Iteration 300, loss = 0.173612
I0912 05:13:44.052651 26718 solver.cpp:244]     Train net output #0: accuracy = 0.94383
I0912 05:13:44.052661 26718 solver.cpp:244]     Train net output #1: loss = 0.173612 (* 1 = 0.173612 loss)
I0912 05:13:44.052667 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.960443
I0912 05:13:44.052671 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.905386
I0912 05:13:44.052678 26718 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0912 05:14:00.642400 26718 solver.cpp:228] Iteration 320, loss = 0.0855962
I0912 05:14:00.642510 26718 solver.cpp:244]     Train net output #0: accuracy = 0.977121
I0912 05:14:00.642525 26718 solver.cpp:244]     Train net output #1: loss = 0.0855962 (* 1 = 0.0855962 loss)
I0912 05:14:00.642531 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995662
I0912 05:14:00.642536 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.94919
I0912 05:14:00.642544 26718 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0912 05:14:17.234911 26718 solver.cpp:228] Iteration 340, loss = 0.120127
I0912 05:14:17.234951 26718 solver.cpp:244]     Train net output #0: accuracy = 0.949379
I0912 05:14:17.234963 26718 solver.cpp:244]     Train net output #1: loss = 0.120127 (* 1 = 0.120127 loss)
I0912 05:14:17.234968 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.931782
I0912 05:14:17.234973 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984291
I0912 05:14:17.234979 26718 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0912 05:14:33.823984 26718 solver.cpp:228] Iteration 360, loss = 0.0364344
I0912 05:14:33.824092 26718 solver.cpp:244]     Train net output #0: accuracy = 0.986787
I0912 05:14:33.824107 26718 solver.cpp:244]     Train net output #1: loss = 0.0364344 (* 1 = 0.0364344 loss)
I0912 05:14:33.824120 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980481
I0912 05:14:33.824124 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994809
I0912 05:14:33.824131 26718 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0912 05:14:50.418673 26718 solver.cpp:228] Iteration 380, loss = 0.0270197
I0912 05:14:50.418711 26718 solver.cpp:244]     Train net output #0: accuracy = 0.992283
I0912 05:14:50.418725 26718 solver.cpp:244]     Train net output #1: loss = 0.0270198 (* 1 = 0.0270198 loss)
I0912 05:14:50.418730 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994026
I0912 05:14:50.418735 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988468
I0912 05:14:50.418741 26718 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0912 05:15:07.022567 26718 solver.cpp:228] Iteration 400, loss = 0.054543
I0912 05:15:07.022689 26718 solver.cpp:244]     Train net output #0: accuracy = 0.974133
I0912 05:15:07.022703 26718 solver.cpp:244]     Train net output #1: loss = 0.0545431 (* 1 = 0.0545431 loss)
I0912 05:15:07.022712 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.965915
I0912 05:15:07.022718 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998432
I0912 05:15:07.022725 26718 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0912 05:15:23.609689 26718 solver.cpp:228] Iteration 420, loss = 0.0405486
I0912 05:15:23.609730 26718 solver.cpp:244]     Train net output #0: accuracy = 0.98672
I0912 05:15:23.609740 26718 solver.cpp:244]     Train net output #1: loss = 0.0405486 (* 1 = 0.0405486 loss)
I0912 05:15:23.609746 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9778
I0912 05:15:23.609751 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996343
I0912 05:15:23.609758 26718 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0912 05:15:40.227874 26718 solver.cpp:228] Iteration 440, loss = 0.0495574
I0912 05:15:40.228077 26718 solver.cpp:244]     Train net output #0: accuracy = 0.984744
I0912 05:15:40.228096 26718 solver.cpp:244]     Train net output #1: loss = 0.0495574 (* 1 = 0.0495574 loss)
I0912 05:15:40.228103 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984919
I0912 05:15:40.228108 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984221
I0912 05:15:40.228117 26718 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0912 05:15:56.824025 26718 solver.cpp:228] Iteration 460, loss = 0.0673353
I0912 05:15:56.824065 26718 solver.cpp:244]     Train net output #0: accuracy = 0.977039
I0912 05:15:56.824081 26718 solver.cpp:244]     Train net output #1: loss = 0.0673354 (* 1 = 0.0673354 loss)
I0912 05:15:56.824087 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.963949
I0912 05:15:56.824092 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997004
I0912 05:15:56.824100 26718 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0912 05:16:13.416033 26718 solver.cpp:228] Iteration 480, loss = 0.0384077
I0912 05:16:13.416152 26718 solver.cpp:244]     Train net output #0: accuracy = 0.985554
I0912 05:16:13.416167 26718 solver.cpp:244]     Train net output #1: loss = 0.0384078 (* 1 = 0.0384078 loss)
I0912 05:16:13.416182 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97929
I0912 05:16:13.416187 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993538
I0912 05:16:13.416193 26718 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0912 05:16:30.022820 26718 solver.cpp:228] Iteration 500, loss = 0.106481
I0912 05:16:30.022868 26718 solver.cpp:244]     Train net output #0: accuracy = 0.967201
I0912 05:16:30.022881 26718 solver.cpp:244]     Train net output #1: loss = 0.106481 (* 1 = 0.106481 loss)
I0912 05:16:30.022888 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992195
I0912 05:16:30.022893 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.906557
I0912 05:16:30.022900 26718 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0912 05:16:46.646757 26718 solver.cpp:228] Iteration 520, loss = 0.0228088
I0912 05:16:46.646893 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994035
I0912 05:16:46.646908 26718 solver.cpp:244]     Train net output #1: loss = 0.0228088 (* 1 = 0.0228088 loss)
I0912 05:16:46.646914 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995212
I0912 05:16:46.646919 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990555
I0912 05:16:46.646926 26718 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0912 05:17:03.241824 26718 solver.cpp:228] Iteration 540, loss = 0.253907
I0912 05:17:03.241886 26718 solver.cpp:244]     Train net output #0: accuracy = 0.928134
I0912 05:17:03.241899 26718 solver.cpp:244]     Train net output #1: loss = 0.253907 (* 1 = 0.253907 loss)
I0912 05:17:03.241914 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.916674
I0912 05:17:03.241919 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999105
I0912 05:17:03.241925 26718 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0912 05:17:19.849977 26718 solver.cpp:228] Iteration 560, loss = 0.0610949
I0912 05:17:19.850165 26718 solver.cpp:244]     Train net output #0: accuracy = 0.982797
I0912 05:17:19.850180 26718 solver.cpp:244]     Train net output #1: loss = 0.0610949 (* 1 = 0.0610949 loss)
I0912 05:17:19.850188 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972813
I0912 05:17:19.850193 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989563
I0912 05:17:19.850200 26718 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0912 05:17:36.497465 26718 solver.cpp:228] Iteration 580, loss = 0.0384405
I0912 05:17:36.497504 26718 solver.cpp:244]     Train net output #0: accuracy = 0.984369
I0912 05:17:36.497517 26718 solver.cpp:244]     Train net output #1: loss = 0.0384405 (* 1 = 0.0384405 loss)
I0912 05:17:36.497524 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974656
I0912 05:17:36.497529 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994944
I0912 05:17:36.497535 26718 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0912 05:17:53.080307 26718 solver.cpp:228] Iteration 600, loss = 0.0324572
I0912 05:17:53.080444 26718 solver.cpp:244]     Train net output #0: accuracy = 0.990574
I0912 05:17:53.080458 26718 solver.cpp:244]     Train net output #1: loss = 0.0324572 (* 1 = 0.0324572 loss)
I0912 05:17:53.080466 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991321
I0912 05:17:53.080471 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987898
I0912 05:17:53.080476 26718 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0912 05:18:09.687770 26718 solver.cpp:228] Iteration 620, loss = 0.0223731
I0912 05:18:09.687811 26718 solver.cpp:244]     Train net output #0: accuracy = 0.992944
I0912 05:18:09.687824 26718 solver.cpp:244]     Train net output #1: loss = 0.0223731 (* 1 = 0.0223731 loss)
I0912 05:18:09.687830 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992607
I0912 05:18:09.687836 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993402
I0912 05:18:09.687844 26718 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0912 05:18:26.281363 26718 solver.cpp:228] Iteration 640, loss = 0.0168126
I0912 05:18:26.281507 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993967
I0912 05:18:26.281522 26718 solver.cpp:244]     Train net output #1: loss = 0.0168126 (* 1 = 0.0168126 loss)
I0912 05:18:26.281535 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991361
I0912 05:18:26.281540 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996527
I0912 05:18:26.281548 26718 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0912 05:18:42.886180 26718 solver.cpp:228] Iteration 660, loss = 0.012077
I0912 05:18:42.886220 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995628
I0912 05:18:42.886231 26718 solver.cpp:244]     Train net output #1: loss = 0.012077 (* 1 = 0.012077 loss)
I0912 05:18:42.886237 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992994
I0912 05:18:42.886242 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99904
I0912 05:18:42.886250 26718 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0912 05:18:59.462497 26718 solver.cpp:228] Iteration 680, loss = 0.0106929
I0912 05:18:59.462653 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997199
I0912 05:18:59.462702 26718 solver.cpp:244]     Train net output #1: loss = 0.0106929 (* 1 = 0.0106929 loss)
I0912 05:18:59.462709 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996773
I0912 05:18:59.462716 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998375
I0912 05:18:59.462725 26718 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0912 05:19:16.144775 26718 solver.cpp:228] Iteration 700, loss = 0.0126249
I0912 05:19:16.144827 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994578
I0912 05:19:16.144841 26718 solver.cpp:244]     Train net output #1: loss = 0.0126249 (* 1 = 0.0126249 loss)
I0912 05:19:16.144848 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991487
I0912 05:19:16.144853 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99884
I0912 05:19:16.144861 26718 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0912 05:19:32.795013 26718 solver.cpp:228] Iteration 720, loss = 0.0165921
I0912 05:19:32.795188 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993397
I0912 05:19:32.795204 26718 solver.cpp:244]     Train net output #1: loss = 0.0165922 (* 1 = 0.0165922 loss)
I0912 05:19:32.795210 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991024
I0912 05:19:32.795215 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997065
I0912 05:19:32.795223 26718 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0912 05:19:49.417062 26718 solver.cpp:228] Iteration 740, loss = 0.0280488
I0912 05:19:49.417105 26718 solver.cpp:244]     Train net output #0: accuracy = 0.9901
I0912 05:19:49.417119 26718 solver.cpp:244]     Train net output #1: loss = 0.0280488 (* 1 = 0.0280488 loss)
I0912 05:19:49.417125 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990617
I0912 05:19:49.417130 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989417
I0912 05:19:49.417136 26718 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0912 05:20:06.007182 26718 solver.cpp:228] Iteration 760, loss = 0.0117645
I0912 05:20:06.007314 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995887
I0912 05:20:06.007328 26718 solver.cpp:244]     Train net output #1: loss = 0.0117645 (* 1 = 0.0117645 loss)
I0912 05:20:06.007333 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995261
I0912 05:20:06.007339 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996993
I0912 05:20:06.007345 26718 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0912 05:20:22.605250 26718 solver.cpp:228] Iteration 780, loss = 0.0193048
I0912 05:20:22.605294 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99182
I0912 05:20:22.605306 26718 solver.cpp:244]     Train net output #1: loss = 0.0193048 (* 1 = 0.0193048 loss)
I0912 05:20:22.605327 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987971
I0912 05:20:22.605334 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997108
I0912 05:20:22.605342 26718 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0912 05:20:39.200151 26718 solver.cpp:228] Iteration 800, loss = 0.0213627
I0912 05:20:39.200556 26718 solver.cpp:244]     Train net output #0: accuracy = 0.9908
I0912 05:20:39.200597 26718 solver.cpp:244]     Train net output #1: loss = 0.0213627 (* 1 = 0.0213627 loss)
I0912 05:20:39.200605 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983356
I0912 05:20:39.200615 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997605
I0912 05:20:39.200624 26718 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0912 05:20:55.831889 26718 solver.cpp:228] Iteration 820, loss = 0.0239014
I0912 05:20:55.831938 26718 solver.cpp:244]     Train net output #0: accuracy = 0.990544
I0912 05:20:55.831951 26718 solver.cpp:244]     Train net output #1: loss = 0.0239014 (* 1 = 0.0239014 loss)
I0912 05:20:55.831957 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989234
I0912 05:20:55.831962 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994528
I0912 05:20:55.831970 26718 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0912 05:21:12.422788 26718 solver.cpp:228] Iteration 840, loss = 0.027694
I0912 05:21:12.422919 26718 solver.cpp:244]     Train net output #0: accuracy = 0.990088
I0912 05:21:12.422933 26718 solver.cpp:244]     Train net output #1: loss = 0.0276941 (* 1 = 0.0276941 loss)
I0912 05:21:12.422938 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991196
I0912 05:21:12.422943 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988091
I0912 05:21:12.422950 26718 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0912 05:21:29.016937 26718 solver.cpp:228] Iteration 860, loss = 0.0344703
I0912 05:21:29.016981 26718 solver.cpp:244]     Train net output #0: accuracy = 0.987682
I0912 05:21:29.016995 26718 solver.cpp:244]     Train net output #1: loss = 0.0344703 (* 1 = 0.0344703 loss)
I0912 05:21:29.017001 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98551
I0912 05:21:29.017007 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990247
I0912 05:21:29.017016 26718 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0912 05:21:45.604964 26718 solver.cpp:228] Iteration 880, loss = 0.0153604
I0912 05:21:45.605150 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994819
I0912 05:21:45.605165 26718 solver.cpp:244]     Train net output #1: loss = 0.0153605 (* 1 = 0.0153605 loss)
I0912 05:21:45.605170 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995839
I0912 05:21:45.605183 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992829
I0912 05:21:45.605195 26718 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0912 05:22:02.207119 26718 solver.cpp:228] Iteration 900, loss = 0.0344629
I0912 05:22:02.207161 26718 solver.cpp:244]     Train net output #0: accuracy = 0.989809
I0912 05:22:02.207172 26718 solver.cpp:244]     Train net output #1: loss = 0.0344629 (* 1 = 0.0344629 loss)
I0912 05:22:02.207177 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994586
I0912 05:22:02.207182 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984385
I0912 05:22:02.207190 26718 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0912 05:22:18.805397 26718 solver.cpp:228] Iteration 920, loss = 0.0171459
I0912 05:22:18.805541 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994081
I0912 05:22:18.805557 26718 solver.cpp:244]     Train net output #1: loss = 0.0171459 (* 1 = 0.0171459 loss)
I0912 05:22:18.805567 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993442
I0912 05:22:18.805572 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995057
I0912 05:22:18.805579 26718 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0912 05:22:35.394348 26718 solver.cpp:228] Iteration 940, loss = 0.0261011
I0912 05:22:35.394389 26718 solver.cpp:244]     Train net output #0: accuracy = 0.989644
I0912 05:22:35.394400 26718 solver.cpp:244]     Train net output #1: loss = 0.0261011 (* 1 = 0.0261011 loss)
I0912 05:22:35.394407 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980929
I0912 05:22:35.394412 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996839
I0912 05:22:35.394418 26718 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0912 05:22:51.985388 26718 solver.cpp:228] Iteration 960, loss = 0.0171838
I0912 05:22:51.985533 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99249
I0912 05:22:51.985548 26718 solver.cpp:244]     Train net output #1: loss = 0.0171838 (* 1 = 0.0171838 loss)
I0912 05:22:51.985554 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989339
I0912 05:22:51.985566 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998144
I0912 05:22:51.985574 26718 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0912 05:23:08.597122 26718 solver.cpp:228] Iteration 980, loss = 0.0204877
I0912 05:23:08.597163 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993819
I0912 05:23:08.597175 26718 solver.cpp:244]     Train net output #1: loss = 0.0204877 (* 1 = 0.0204877 loss)
I0912 05:23:08.597182 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994008
I0912 05:23:08.597187 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993026
I0912 05:23:08.597195 26718 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0912 05:23:25.195112 26718 solver.cpp:228] Iteration 1000, loss = 0.0166114
I0912 05:23:25.195222 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993343
I0912 05:23:25.195235 26718 solver.cpp:244]     Train net output #1: loss = 0.0166114 (* 1 = 0.0166114 loss)
I0912 05:23:25.195241 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992718
I0912 05:23:25.195246 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994965
I0912 05:23:25.195253 26718 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0912 05:23:41.804464 26718 solver.cpp:228] Iteration 1020, loss = 0.0108928
I0912 05:23:41.804507 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995864
I0912 05:23:41.804520 26718 solver.cpp:244]     Train net output #1: loss = 0.0108928 (* 1 = 0.0108928 loss)
I0912 05:23:41.804527 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995477
I0912 05:23:41.804533 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996382
I0912 05:23:41.804539 26718 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0912 05:23:58.405066 26718 solver.cpp:228] Iteration 1040, loss = 0.0170376
I0912 05:23:58.405230 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993912
I0912 05:23:58.405246 26718 solver.cpp:244]     Train net output #1: loss = 0.0170376 (* 1 = 0.0170376 loss)
I0912 05:23:58.405253 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993875
I0912 05:23:58.405259 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99396
I0912 05:23:58.405266 26718 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0912 05:24:15.008899 26718 solver.cpp:228] Iteration 1060, loss = 0.0360049
I0912 05:24:15.008944 26718 solver.cpp:244]     Train net output #0: accuracy = 0.991882
I0912 05:24:15.008956 26718 solver.cpp:244]     Train net output #1: loss = 0.0360049 (* 1 = 0.0360049 loss)
I0912 05:24:15.008963 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991782
I0912 05:24:15.008968 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992725
I0912 05:24:15.008975 26718 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0912 05:24:31.606911 26718 solver.cpp:228] Iteration 1080, loss = 0.0224374
I0912 05:24:31.607014 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993404
I0912 05:24:31.607028 26718 solver.cpp:244]     Train net output #1: loss = 0.0224374 (* 1 = 0.0224374 loss)
I0912 05:24:31.607044 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993413
I0912 05:24:31.607049 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993355
I0912 05:24:31.607055 26718 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0912 05:24:48.204413 26718 solver.cpp:228] Iteration 1100, loss = 0.0122545
I0912 05:24:48.204457 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994776
I0912 05:24:48.204471 26718 solver.cpp:244]     Train net output #1: loss = 0.0122545 (* 1 = 0.0122545 loss)
I0912 05:24:48.204478 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991654
I0912 05:24:48.204483 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998445
I0912 05:24:48.204493 26718 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0912 05:25:04.791697 26718 solver.cpp:228] Iteration 1120, loss = 0.0155593
I0912 05:25:04.791798 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994687
I0912 05:25:04.791811 26718 solver.cpp:244]     Train net output #1: loss = 0.0155593 (* 1 = 0.0155593 loss)
I0912 05:25:04.791817 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99263
I0912 05:25:04.791822 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996554
I0912 05:25:04.791829 26718 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0912 05:25:21.393048 26718 solver.cpp:228] Iteration 1140, loss = 0.0165538
I0912 05:25:21.393088 26718 solver.cpp:244]     Train net output #0: accuracy = 0.992539
I0912 05:25:21.393100 26718 solver.cpp:244]     Train net output #1: loss = 0.0165538 (* 1 = 0.0165538 loss)
I0912 05:25:21.393106 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988145
I0912 05:25:21.393111 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997723
I0912 05:25:21.393118 26718 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0912 05:25:37.989933 26718 solver.cpp:228] Iteration 1160, loss = 0.0138004
I0912 05:25:37.990085 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993964
I0912 05:25:37.990108 26718 solver.cpp:244]     Train net output #1: loss = 0.0138004 (* 1 = 0.0138004 loss)
I0912 05:25:37.990114 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992688
I0912 05:25:37.990119 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996719
I0912 05:25:37.990126 26718 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0912 05:25:54.592842 26718 solver.cpp:228] Iteration 1180, loss = 0.0145864
I0912 05:25:54.592883 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994816
I0912 05:25:54.592895 26718 solver.cpp:244]     Train net output #1: loss = 0.0145864 (* 1 = 0.0145864 loss)
I0912 05:25:54.592900 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994332
I0912 05:25:54.592905 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995544
I0912 05:25:54.592912 26718 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0912 05:26:11.192980 26718 solver.cpp:228] Iteration 1200, loss = 0.0190914
I0912 05:26:11.193090 26718 solver.cpp:244]     Train net output #0: accuracy = 0.992397
I0912 05:26:11.193106 26718 solver.cpp:244]     Train net output #1: loss = 0.0190914 (* 1 = 0.0190914 loss)
I0912 05:26:11.193112 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984778
I0912 05:26:11.193117 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998091
I0912 05:26:11.193125 26718 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0912 05:26:27.778189 26718 solver.cpp:228] Iteration 1220, loss = 0.0166703
I0912 05:26:27.778228 26718 solver.cpp:244]     Train net output #0: accuracy = 0.992266
I0912 05:26:27.778240 26718 solver.cpp:244]     Train net output #1: loss = 0.0166703 (* 1 = 0.0166703 loss)
I0912 05:26:27.778246 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988622
I0912 05:26:27.778251 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997373
I0912 05:26:27.778259 26718 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0912 05:26:44.384923 26718 solver.cpp:228] Iteration 1240, loss = 0.0134068
I0912 05:26:44.385016 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994878
I0912 05:26:44.385030 26718 solver.cpp:244]     Train net output #1: loss = 0.0134068 (* 1 = 0.0134068 loss)
I0912 05:26:44.385036 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993709
I0912 05:26:44.385041 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996414
I0912 05:26:44.385048 26718 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0912 05:27:01.144973 26718 solver.cpp:228] Iteration 1260, loss = 0.0146856
I0912 05:27:01.145018 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994073
I0912 05:27:01.145031 26718 solver.cpp:244]     Train net output #1: loss = 0.0146856 (* 1 = 0.0146856 loss)
I0912 05:27:01.145037 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99163
I0912 05:27:01.145042 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996869
I0912 05:27:01.145050 26718 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0912 05:27:17.724764 26718 solver.cpp:228] Iteration 1280, loss = 0.0102966
I0912 05:27:17.724887 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996298
I0912 05:27:17.724900 26718 solver.cpp:244]     Train net output #1: loss = 0.0102966 (* 1 = 0.0102966 loss)
I0912 05:27:17.724906 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995826
I0912 05:27:17.724911 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99785
I0912 05:27:17.724918 26718 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0912 05:27:34.315331 26718 solver.cpp:228] Iteration 1300, loss = 0.0138453
I0912 05:27:34.315376 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993465
I0912 05:27:34.315387 26718 solver.cpp:244]     Train net output #1: loss = 0.0138453 (* 1 = 0.0138453 loss)
I0912 05:27:34.315393 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989562
I0912 05:27:34.315398 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998542
I0912 05:27:34.315405 26718 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0912 05:27:50.916375 26718 solver.cpp:228] Iteration 1320, loss = 0.0217272
I0912 05:27:50.916548 26718 solver.cpp:244]     Train net output #0: accuracy = 0.992593
I0912 05:27:50.916563 26718 solver.cpp:244]     Train net output #1: loss = 0.0217272 (* 1 = 0.0217272 loss)
I0912 05:27:50.916569 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992045
I0912 05:27:50.916574 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993169
I0912 05:27:50.916582 26718 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0912 05:28:07.515643 26718 solver.cpp:228] Iteration 1340, loss = 0.0200052
I0912 05:28:07.515681 26718 solver.cpp:244]     Train net output #0: accuracy = 0.991538
I0912 05:28:07.515691 26718 solver.cpp:244]     Train net output #1: loss = 0.0200052 (* 1 = 0.0200052 loss)
I0912 05:28:07.515697 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98957
I0912 05:28:07.515702 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994667
I0912 05:28:07.515708 26718 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0912 05:28:24.107378 26718 solver.cpp:228] Iteration 1360, loss = 0.0210429
I0912 05:28:24.107498 26718 solver.cpp:244]     Train net output #0: accuracy = 0.991406
I0912 05:28:24.107513 26718 solver.cpp:244]     Train net output #1: loss = 0.0210429 (* 1 = 0.0210429 loss)
I0912 05:28:24.107519 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984522
I0912 05:28:24.107524 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997281
I0912 05:28:24.107532 26718 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0912 05:28:40.724830 26718 solver.cpp:228] Iteration 1380, loss = 0.0226047
I0912 05:28:40.724871 26718 solver.cpp:244]     Train net output #0: accuracy = 0.990637
I0912 05:28:40.724884 26718 solver.cpp:244]     Train net output #1: loss = 0.0226047 (* 1 = 0.0226047 loss)
I0912 05:28:40.724889 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987877
I0912 05:28:40.724895 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994354
I0912 05:28:40.724901 26718 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0912 05:28:57.309554 26718 solver.cpp:228] Iteration 1400, loss = 0.0135105
I0912 05:28:57.309695 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994624
I0912 05:28:57.309710 26718 solver.cpp:244]     Train net output #1: loss = 0.0135105 (* 1 = 0.0135105 loss)
I0912 05:28:57.309721 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994216
I0912 05:28:57.309726 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995471
I0912 05:28:57.309733 26718 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0912 05:29:14.035775 26718 solver.cpp:228] Iteration 1420, loss = 0.0227931
I0912 05:29:14.035817 26718 solver.cpp:244]     Train net output #0: accuracy = 0.98954
I0912 05:29:14.035828 26718 solver.cpp:244]     Train net output #1: loss = 0.022793 (* 1 = 0.022793 loss)
I0912 05:29:14.035835 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982309
I0912 05:29:14.035840 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997567
I0912 05:29:14.035846 26718 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0912 05:29:30.628525 26718 solver.cpp:228] Iteration 1440, loss = 0.0242466
I0912 05:29:30.628650 26718 solver.cpp:244]     Train net output #0: accuracy = 0.990528
I0912 05:29:30.628665 26718 solver.cpp:244]     Train net output #1: loss = 0.0242466 (* 1 = 0.0242466 loss)
I0912 05:29:30.628671 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98421
I0912 05:29:30.628676 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995852
I0912 05:29:30.628684 26718 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0912 05:29:47.218695 26718 solver.cpp:228] Iteration 1460, loss = 0.00813603
I0912 05:29:47.218734 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996419
I0912 05:29:47.218746 26718 solver.cpp:244]     Train net output #1: loss = 0.00813602 (* 1 = 0.00813602 loss)
I0912 05:29:47.218752 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993539
I0912 05:29:47.218757 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999347
I0912 05:29:47.218765 26718 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0912 05:30:03.832255 26718 solver.cpp:228] Iteration 1480, loss = 0.0142071
I0912 05:30:03.832414 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995253
I0912 05:30:03.832429 26718 solver.cpp:244]     Train net output #1: loss = 0.0142071 (* 1 = 0.0142071 loss)
I0912 05:30:03.832435 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996326
I0912 05:30:03.832440 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992548
I0912 05:30:03.832448 26718 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0912 05:30:20.445785 26718 solver.cpp:228] Iteration 1500, loss = 0.0289753
I0912 05:30:20.445829 26718 solver.cpp:244]     Train net output #0: accuracy = 0.990234
I0912 05:30:20.445842 26718 solver.cpp:244]     Train net output #1: loss = 0.0289753 (* 1 = 0.0289753 loss)
I0912 05:30:20.445848 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990049
I0912 05:30:20.445853 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9904
I0912 05:30:20.445861 26718 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0912 05:30:37.052006 26718 solver.cpp:228] Iteration 1520, loss = 0.0152202
I0912 05:30:37.052140 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99399
I0912 05:30:37.052155 26718 solver.cpp:244]     Train net output #1: loss = 0.0152202 (* 1 = 0.0152202 loss)
I0912 05:30:37.052161 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992457
I0912 05:30:37.052165 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995976
I0912 05:30:37.052173 26718 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0912 05:30:53.649121 26718 solver.cpp:228] Iteration 1540, loss = 0.0139995
I0912 05:30:53.649165 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994488
I0912 05:30:53.649178 26718 solver.cpp:244]     Train net output #1: loss = 0.0139995 (* 1 = 0.0139995 loss)
I0912 05:30:53.649183 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993796
I0912 05:30:53.649188 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995531
I0912 05:30:53.649195 26718 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0912 05:31:10.254403 26718 solver.cpp:228] Iteration 1560, loss = 0.00917639
I0912 05:31:10.254539 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996188
I0912 05:31:10.254578 26718 solver.cpp:244]     Train net output #1: loss = 0.00917637 (* 1 = 0.00917637 loss)
I0912 05:31:10.254586 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995337
I0912 05:31:10.254592 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997655
I0912 05:31:10.254601 26718 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0912 05:31:26.916584 26718 solver.cpp:228] Iteration 1580, loss = 0.0164288
I0912 05:31:26.916625 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995553
I0912 05:31:26.916641 26718 solver.cpp:244]     Train net output #1: loss = 0.0164288 (* 1 = 0.0164288 loss)
I0912 05:31:26.916648 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992057
I0912 05:31:26.916654 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997538
I0912 05:31:26.916661 26718 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0912 05:31:43.533843 26718 solver.cpp:228] Iteration 1600, loss = 0.0134483
I0912 05:31:43.534024 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99475
I0912 05:31:43.534075 26718 solver.cpp:244]     Train net output #1: loss = 0.0134483 (* 1 = 0.0134483 loss)
I0912 05:31:43.534083 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991449
I0912 05:31:43.534088 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997556
I0912 05:31:43.534096 26718 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0912 05:32:00.172060 26718 solver.cpp:228] Iteration 1620, loss = 0.0176191
I0912 05:32:00.172111 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993673
I0912 05:32:00.172125 26718 solver.cpp:244]     Train net output #1: loss = 0.0176191 (* 1 = 0.0176191 loss)
I0912 05:32:00.172132 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994588
I0912 05:32:00.172137 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991881
I0912 05:32:00.172143 26718 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0912 05:32:16.768479 26718 solver.cpp:228] Iteration 1640, loss = 0.0136401
I0912 05:32:16.768604 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994366
I0912 05:32:16.768617 26718 solver.cpp:244]     Train net output #1: loss = 0.0136401 (* 1 = 0.0136401 loss)
I0912 05:32:16.768623 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993984
I0912 05:32:16.768627 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995189
I0912 05:32:16.768636 26718 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0912 05:32:33.388249 26718 solver.cpp:228] Iteration 1660, loss = 0.0109339
I0912 05:32:33.388296 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995775
I0912 05:32:33.388310 26718 solver.cpp:244]     Train net output #1: loss = 0.0109339 (* 1 = 0.0109339 loss)
I0912 05:32:33.388316 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995216
I0912 05:32:33.388321 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996591
I0912 05:32:33.388329 26718 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0912 05:32:49.989586 26718 solver.cpp:228] Iteration 1680, loss = 0.0170417
I0912 05:32:49.989717 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99395
I0912 05:32:49.989759 26718 solver.cpp:244]     Train net output #1: loss = 0.0170417 (* 1 = 0.0170417 loss)
I0912 05:32:49.989768 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993163
I0912 05:32:49.989778 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994805
I0912 05:32:49.989787 26718 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0912 05:33:06.619834 26718 solver.cpp:228] Iteration 1700, loss = 0.00813393
I0912 05:33:06.619884 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997567
I0912 05:33:06.619899 26718 solver.cpp:244]     Train net output #1: loss = 0.00813392 (* 1 = 0.00813392 loss)
I0912 05:33:06.619905 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998675
I0912 05:33:06.619910 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994166
I0912 05:33:06.619917 26718 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0912 05:33:23.218901 26718 solver.cpp:228] Iteration 1720, loss = 0.0232791
I0912 05:33:23.219025 26718 solver.cpp:244]     Train net output #0: accuracy = 0.990896
I0912 05:33:23.219041 26718 solver.cpp:244]     Train net output #1: loss = 0.0232791 (* 1 = 0.0232791 loss)
I0912 05:33:23.219048 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988919
I0912 05:33:23.219053 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993693
I0912 05:33:23.219061 26718 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0912 05:33:39.846851 26718 solver.cpp:228] Iteration 1740, loss = 0.00688887
I0912 05:33:39.846906 26718 solver.cpp:244]     Train net output #0: accuracy = 0.998247
I0912 05:33:39.846920 26718 solver.cpp:244]     Train net output #1: loss = 0.00688887 (* 1 = 0.00688887 loss)
I0912 05:33:39.846926 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998932
I0912 05:33:39.846931 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995799
I0912 05:33:39.846940 26718 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0912 05:33:56.545006 26718 solver.cpp:228] Iteration 1760, loss = 0.0120656
I0912 05:33:56.545184 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99525
I0912 05:33:56.545200 26718 solver.cpp:244]     Train net output #1: loss = 0.0120655 (* 1 = 0.0120655 loss)
I0912 05:33:56.545208 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994757
I0912 05:33:56.545213 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996025
I0912 05:33:56.545220 26718 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0912 05:34:13.125988 26718 solver.cpp:228] Iteration 1780, loss = 0.012672
I0912 05:34:13.126031 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994484
I0912 05:34:13.126044 26718 solver.cpp:244]     Train net output #1: loss = 0.012672 (* 1 = 0.012672 loss)
I0912 05:34:13.126049 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990507
I0912 05:34:13.126055 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998202
I0912 05:34:13.126061 26718 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0912 05:34:29.717262 26718 solver.cpp:228] Iteration 1800, loss = 0.0119325
I0912 05:34:29.717380 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995234
I0912 05:34:29.717394 26718 solver.cpp:244]     Train net output #1: loss = 0.0119325 (* 1 = 0.0119325 loss)
I0912 05:34:29.717399 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995288
I0912 05:34:29.717404 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995106
I0912 05:34:29.717411 26718 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0912 05:34:46.315863 26718 solver.cpp:228] Iteration 1820, loss = 0.0155991
I0912 05:34:46.315909 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994994
I0912 05:34:46.315923 26718 solver.cpp:244]     Train net output #1: loss = 0.0155991 (* 1 = 0.0155991 loss)
I0912 05:34:46.315929 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994843
I0912 05:34:46.315935 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995126
I0912 05:34:46.315943 26718 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0912 05:35:02.947463 26718 solver.cpp:228] Iteration 1840, loss = 0.013979
I0912 05:35:02.947624 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994724
I0912 05:35:02.947659 26718 solver.cpp:244]     Train net output #1: loss = 0.013979 (* 1 = 0.013979 loss)
I0912 05:35:02.947669 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995399
I0912 05:35:02.947682 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992868
I0912 05:35:02.947700 26718 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0912 05:35:19.580525 26718 solver.cpp:228] Iteration 1860, loss = 0.0150925
I0912 05:35:19.580569 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995363
I0912 05:35:19.580580 26718 solver.cpp:244]     Train net output #1: loss = 0.0150925 (* 1 = 0.0150925 loss)
I0912 05:35:19.580587 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996432
I0912 05:35:19.580592 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990654
I0912 05:35:19.580600 26718 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0912 05:35:36.185334 26718 solver.cpp:228] Iteration 1880, loss = 0.0126696
I0912 05:35:36.185485 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995586
I0912 05:35:36.185524 26718 solver.cpp:244]     Train net output #1: loss = 0.0126696 (* 1 = 0.0126696 loss)
I0912 05:35:36.185534 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993302
I0912 05:35:36.185539 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997269
I0912 05:35:36.185547 26718 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0912 05:35:52.829288 26718 solver.cpp:228] Iteration 1900, loss = 0.0153016
I0912 05:35:52.829334 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994172
I0912 05:35:52.829347 26718 solver.cpp:244]     Train net output #1: loss = 0.0153016 (* 1 = 0.0153016 loss)
I0912 05:35:52.829355 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994279
I0912 05:35:52.829360 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993976
I0912 05:35:52.829371 26718 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0912 05:36:09.499131 26718 solver.cpp:228] Iteration 1920, loss = 0.0155384
I0912 05:36:09.499312 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993403
I0912 05:36:09.499330 26718 solver.cpp:244]     Train net output #1: loss = 0.0155383 (* 1 = 0.0155383 loss)
I0912 05:36:09.499337 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99283
I0912 05:36:09.499342 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994617
I0912 05:36:09.499352 26718 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0912 05:36:26.111654 26718 solver.cpp:228] Iteration 1940, loss = 0.0158083
I0912 05:36:26.111699 26718 solver.cpp:244]     Train net output #0: accuracy = 0.992527
I0912 05:36:26.111729 26718 solver.cpp:244]     Train net output #1: loss = 0.0158083 (* 1 = 0.0158083 loss)
I0912 05:36:26.111737 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988616
I0912 05:36:26.111742 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997598
I0912 05:36:26.111752 26718 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0912 05:36:42.710232 26718 solver.cpp:228] Iteration 1960, loss = 0.0072711
I0912 05:36:42.710364 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996752
I0912 05:36:42.710381 26718 solver.cpp:244]     Train net output #1: loss = 0.0072711 (* 1 = 0.0072711 loss)
I0912 05:36:42.710386 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995432
I0912 05:36:42.710398 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998853
I0912 05:36:42.710405 26718 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0912 05:36:59.318302 26718 solver.cpp:228] Iteration 1980, loss = 0.0143595
I0912 05:36:59.318348 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99387
I0912 05:36:59.318375 26718 solver.cpp:244]     Train net output #1: loss = 0.0143595 (* 1 = 0.0143595 loss)
I0912 05:36:59.318384 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989212
I0912 05:36:59.318389 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998135
I0912 05:36:59.318397 26718 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0912 05:37:15.914594 26718 solver.cpp:228] Iteration 2000, loss = 0.0745075
I0912 05:37:15.914727 26718 solver.cpp:244]     Train net output #0: accuracy = 0.976231
I0912 05:37:15.914769 26718 solver.cpp:244]     Train net output #1: loss = 0.0745075 (* 1 = 0.0745075 loss)
I0912 05:37:15.914777 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990268
I0912 05:37:15.914788 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.953722
I0912 05:37:15.914798 26718 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0912 05:37:32.549335 26718 solver.cpp:228] Iteration 2020, loss = 0.0286337
I0912 05:37:32.549384 26718 solver.cpp:244]     Train net output #0: accuracy = 0.990463
I0912 05:37:32.549397 26718 solver.cpp:244]     Train net output #1: loss = 0.0286336 (* 1 = 0.0286336 loss)
I0912 05:37:32.549405 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986459
I0912 05:37:32.549410 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995434
I0912 05:37:32.549418 26718 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0912 05:37:49.157645 26718 solver.cpp:228] Iteration 2040, loss = 0.013245
I0912 05:37:49.157804 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994703
I0912 05:37:49.157845 26718 solver.cpp:244]     Train net output #1: loss = 0.013245 (* 1 = 0.013245 loss)
I0912 05:37:49.157856 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992744
I0912 05:37:49.157866 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997119
I0912 05:37:49.157878 26718 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0912 05:38:05.802336 26718 solver.cpp:228] Iteration 2060, loss = 0.0198727
I0912 05:38:05.802378 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993492
I0912 05:38:05.802392 26718 solver.cpp:244]     Train net output #1: loss = 0.0198726 (* 1 = 0.0198726 loss)
I0912 05:38:05.802412 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994803
I0912 05:38:05.802419 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989858
I0912 05:38:05.802428 26718 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0912 05:38:22.440460 26718 solver.cpp:228] Iteration 2080, loss = 0.0143436
I0912 05:38:22.440640 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994961
I0912 05:38:22.440677 26718 solver.cpp:244]     Train net output #1: loss = 0.0143436 (* 1 = 0.0143436 loss)
I0912 05:38:22.440687 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991286
I0912 05:38:22.440696 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997796
I0912 05:38:22.440706 26718 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0912 05:38:39.104009 26718 solver.cpp:228] Iteration 2100, loss = 0.111543
I0912 05:38:39.104053 26718 solver.cpp:244]     Train net output #0: accuracy = 0.955644
I0912 05:38:39.104066 26718 solver.cpp:244]     Train net output #1: loss = 0.111543 (* 1 = 0.111543 loss)
I0912 05:38:39.104073 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.951576
I0912 05:38:39.104077 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999966
I0912 05:38:39.104086 26718 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0912 05:38:55.695183 26718 solver.cpp:228] Iteration 2120, loss = 0.0196097
I0912 05:38:55.695314 26718 solver.cpp:244]     Train net output #0: accuracy = 0.990774
I0912 05:38:55.695332 26718 solver.cpp:244]     Train net output #1: loss = 0.0196097 (* 1 = 0.0196097 loss)
I0912 05:38:55.695338 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985821
I0912 05:38:55.695343 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998004
I0912 05:38:55.695349 26718 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0912 05:39:12.338990 26718 solver.cpp:228] Iteration 2140, loss = 0.0144338
I0912 05:39:12.339051 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994418
I0912 05:39:12.339069 26718 solver.cpp:244]     Train net output #1: loss = 0.0144338 (* 1 = 0.0144338 loss)
I0912 05:39:12.339077 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994183
I0912 05:39:12.339082 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994953
I0912 05:39:12.339089 26718 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0912 05:39:28.966042 26718 solver.cpp:228] Iteration 2160, loss = 0.0110814
I0912 05:39:28.966147 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99536
I0912 05:39:28.966174 26718 solver.cpp:244]     Train net output #1: loss = 0.0110814 (* 1 = 0.0110814 loss)
I0912 05:39:28.966183 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993384
I0912 05:39:28.966193 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998021
I0912 05:39:28.966202 26718 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0912 05:39:45.557083 26718 solver.cpp:228] Iteration 2180, loss = 0.0100258
I0912 05:39:45.557121 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996416
I0912 05:39:45.557137 26718 solver.cpp:244]     Train net output #1: loss = 0.0100257 (* 1 = 0.0100257 loss)
I0912 05:39:45.557142 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996186
I0912 05:39:45.557147 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997182
I0912 05:39:45.557155 26718 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0912 05:40:02.171141 26718 solver.cpp:228] Iteration 2200, loss = 0.00981148
I0912 05:40:02.171324 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995279
I0912 05:40:02.171380 26718 solver.cpp:244]     Train net output #1: loss = 0.00981144 (* 1 = 0.00981144 loss)
I0912 05:40:02.171389 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99327
I0912 05:40:02.171401 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999069
I0912 05:40:02.171409 26718 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0912 05:40:18.837273 26718 solver.cpp:228] Iteration 2220, loss = 0.00779075
I0912 05:40:18.837321 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99719
I0912 05:40:18.837333 26718 solver.cpp:244]     Train net output #1: loss = 0.00779072 (* 1 = 0.00779072 loss)
I0912 05:40:18.837347 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996745
I0912 05:40:18.837352 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997778
I0912 05:40:18.837369 26718 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0912 05:40:35.512570 26718 solver.cpp:228] Iteration 2240, loss = 0.0150699
I0912 05:40:35.512709 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993051
I0912 05:40:35.512732 26718 solver.cpp:244]     Train net output #1: loss = 0.0150698 (* 1 = 0.0150698 loss)
I0912 05:40:35.512739 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986997
I0912 05:40:35.512744 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998692
I0912 05:40:35.512753 26718 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0912 05:40:52.177305 26718 solver.cpp:228] Iteration 2260, loss = 0.0125552
I0912 05:40:52.177361 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995233
I0912 05:40:52.177381 26718 solver.cpp:244]     Train net output #1: loss = 0.0125552 (* 1 = 0.0125552 loss)
I0912 05:40:52.177388 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995428
I0912 05:40:52.177399 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994752
I0912 05:40:52.177408 26718 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0912 05:41:08.847846 26718 solver.cpp:228] Iteration 2280, loss = 0.0124685
I0912 05:41:08.847970 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994235
I0912 05:41:08.847987 26718 solver.cpp:244]     Train net output #1: loss = 0.0124684 (* 1 = 0.0124684 loss)
I0912 05:41:08.848001 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988161
I0912 05:41:08.848012 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999228
I0912 05:41:08.848024 26718 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0912 05:41:25.539034 26718 solver.cpp:228] Iteration 2300, loss = 0.0151488
I0912 05:41:25.539077 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993128
I0912 05:41:25.539093 26718 solver.cpp:244]     Train net output #1: loss = 0.0151487 (* 1 = 0.0151487 loss)
I0912 05:41:25.539098 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991157
I0912 05:41:25.539104 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996662
I0912 05:41:25.539113 26718 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0912 05:41:42.223747 26718 solver.cpp:228] Iteration 2320, loss = 0.0165771
I0912 05:41:42.223858 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993526
I0912 05:41:42.223875 26718 solver.cpp:244]     Train net output #1: loss = 0.016577 (* 1 = 0.016577 loss)
I0912 05:41:42.223881 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994379
I0912 05:41:42.223886 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991358
I0912 05:41:42.223893 26718 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0912 05:41:58.909375 26718 solver.cpp:228] Iteration 2340, loss = 0.00985127
I0912 05:41:58.909435 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996201
I0912 05:41:58.909448 26718 solver.cpp:244]     Train net output #1: loss = 0.00985123 (* 1 = 0.00985123 loss)
I0912 05:41:58.909456 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995614
I0912 05:41:58.909466 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996869
I0912 05:41:58.909476 26718 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0912 05:42:15.585451 26718 solver.cpp:228] Iteration 2360, loss = 0.0169752
I0912 05:42:15.585580 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994685
I0912 05:42:15.585597 26718 solver.cpp:244]     Train net output #1: loss = 0.0169752 (* 1 = 0.0169752 loss)
I0912 05:42:15.585604 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990895
I0912 05:42:15.585609 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996917
I0912 05:42:15.585618 26718 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0912 05:42:32.269114 26718 solver.cpp:228] Iteration 2380, loss = 0.0131183
I0912 05:42:32.269157 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994022
I0912 05:42:32.269173 26718 solver.cpp:244]     Train net output #1: loss = 0.0131182 (* 1 = 0.0131182 loss)
I0912 05:42:32.269181 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990522
I0912 05:42:32.269186 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998104
I0912 05:42:32.269194 26718 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0912 05:42:48.957099 26718 solver.cpp:228] Iteration 2400, loss = 0.0141902
I0912 05:42:48.957222 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993754
I0912 05:42:48.957240 26718 solver.cpp:244]     Train net output #1: loss = 0.0141902 (* 1 = 0.0141902 loss)
I0912 05:42:48.957252 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99181
I0912 05:42:48.957257 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997174
I0912 05:42:48.957270 26718 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0912 05:43:05.652822 26718 solver.cpp:228] Iteration 2420, loss = 0.019074
I0912 05:43:05.652878 26718 solver.cpp:244]     Train net output #0: accuracy = 0.992059
I0912 05:43:05.652891 26718 solver.cpp:244]     Train net output #1: loss = 0.0190739 (* 1 = 0.0190739 loss)
I0912 05:43:05.652899 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991965
I0912 05:43:05.652909 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992329
I0912 05:43:05.652917 26718 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0912 05:43:22.333065 26718 solver.cpp:228] Iteration 2440, loss = 0.0151831
I0912 05:43:22.333164 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994488
I0912 05:43:22.333181 26718 solver.cpp:244]     Train net output #1: loss = 0.015183 (* 1 = 0.015183 loss)
I0912 05:43:22.333189 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995609
I0912 05:43:22.333194 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991439
I0912 05:43:22.333204 26718 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0912 05:43:39.040362 26718 solver.cpp:228] Iteration 2460, loss = 0.00996053
I0912 05:43:39.040421 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99612
I0912 05:43:39.040436 26718 solver.cpp:244]     Train net output #1: loss = 0.0099605 (* 1 = 0.0099605 loss)
I0912 05:43:39.040446 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995883
I0912 05:43:39.040452 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996683
I0912 05:43:39.040463 26718 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0912 05:43:55.749841 26718 solver.cpp:228] Iteration 2480, loss = 0.0146145
I0912 05:43:55.749929 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996978
I0912 05:43:55.749946 26718 solver.cpp:244]     Train net output #1: loss = 0.0146144 (* 1 = 0.0146144 loss)
I0912 05:43:55.749955 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997321
I0912 05:43:55.749966 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994268
I0912 05:43:55.749977 26718 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0912 05:44:12.445019 26718 solver.cpp:228] Iteration 2500, loss = 0.0077212
I0912 05:44:12.445065 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996613
I0912 05:44:12.445081 26718 solver.cpp:244]     Train net output #1: loss = 0.00772117 (* 1 = 0.00772117 loss)
I0912 05:44:12.445088 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995133
I0912 05:44:12.445093 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998516
I0912 05:44:12.445101 26718 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0912 05:44:29.107246 26718 solver.cpp:228] Iteration 2520, loss = 0.0140343
I0912 05:44:29.107439 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994525
I0912 05:44:29.107458 26718 solver.cpp:244]     Train net output #1: loss = 0.0140342 (* 1 = 0.0140342 loss)
I0912 05:44:29.107471 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99471
I0912 05:44:29.107477 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99413
I0912 05:44:29.107486 26718 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0912 05:44:45.728906 26718 solver.cpp:228] Iteration 2540, loss = 0.0058735
I0912 05:44:45.728960 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997468
I0912 05:44:45.728974 26718 solver.cpp:244]     Train net output #1: loss = 0.00587347 (* 1 = 0.00587347 loss)
I0912 05:44:45.728984 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996997
I0912 05:44:45.729004 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998428
I0912 05:44:45.729015 26718 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0912 05:45:02.345973 26718 solver.cpp:228] Iteration 2560, loss = 0.0151974
I0912 05:45:02.346129 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993592
I0912 05:45:02.346146 26718 solver.cpp:244]     Train net output #1: loss = 0.0151974 (* 1 = 0.0151974 loss)
I0912 05:45:02.346158 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99134
I0912 05:45:02.346164 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996365
I0912 05:45:02.346173 26718 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0912 05:45:18.958704 26718 solver.cpp:228] Iteration 2580, loss = 0.0116626
I0912 05:45:18.958750 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995149
I0912 05:45:18.958786 26718 solver.cpp:244]     Train net output #1: loss = 0.0116626 (* 1 = 0.0116626 loss)
I0912 05:45:18.958796 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993894
I0912 05:45:18.958807 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996889
I0912 05:45:18.958822 26718 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0912 05:45:35.616698 26718 solver.cpp:228] Iteration 2600, loss = 0.0102374
I0912 05:45:35.616840 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995208
I0912 05:45:35.616858 26718 solver.cpp:244]     Train net output #1: loss = 0.0102374 (* 1 = 0.0102374 loss)
I0912 05:45:35.616863 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992705
I0912 05:45:35.616875 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998715
I0912 05:45:35.616885 26718 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0912 05:45:52.244632 26718 solver.cpp:228] Iteration 2620, loss = 0.0120013
I0912 05:45:52.244669 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994986
I0912 05:45:52.244699 26718 solver.cpp:244]     Train net output #1: loss = 0.0120013 (* 1 = 0.0120013 loss)
I0912 05:45:52.244705 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99158
I0912 05:45:52.244710 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997902
I0912 05:45:52.244719 26718 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0912 05:46:08.892599 26718 solver.cpp:228] Iteration 2640, loss = 0.00611531
I0912 05:46:08.892757 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997464
I0912 05:46:08.892786 26718 solver.cpp:244]     Train net output #1: loss = 0.00611528 (* 1 = 0.00611528 loss)
I0912 05:46:08.892794 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996642
I0912 05:46:08.892799 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998686
I0912 05:46:08.892807 26718 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0912 05:46:25.556874 26718 solver.cpp:228] Iteration 2660, loss = 0.00832358
I0912 05:46:25.556919 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997007
I0912 05:46:25.556932 26718 solver.cpp:244]     Train net output #1: loss = 0.00832355 (* 1 = 0.00832355 loss)
I0912 05:46:25.556939 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996876
I0912 05:46:25.556944 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99716
I0912 05:46:25.556952 26718 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0912 05:46:42.229732 26718 solver.cpp:228] Iteration 2680, loss = 0.00840697
I0912 05:46:42.229908 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996722
I0912 05:46:42.229933 26718 solver.cpp:244]     Train net output #1: loss = 0.00840694 (* 1 = 0.00840694 loss)
I0912 05:46:42.229940 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996272
I0912 05:46:42.229951 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997448
I0912 05:46:42.229962 26718 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0912 05:46:58.890707 26718 solver.cpp:228] Iteration 2700, loss = 0.00830693
I0912 05:46:58.890770 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996856
I0912 05:46:58.890784 26718 solver.cpp:244]     Train net output #1: loss = 0.0083069 (* 1 = 0.0083069 loss)
I0912 05:46:58.890791 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996793
I0912 05:46:58.890796 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99708
I0912 05:46:58.890805 26718 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0912 05:47:15.546916 26718 solver.cpp:228] Iteration 2720, loss = 0.0159727
I0912 05:47:15.547035 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994132
I0912 05:47:15.547060 26718 solver.cpp:244]     Train net output #1: loss = 0.0159727 (* 1 = 0.0159727 loss)
I0912 05:47:15.547071 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995639
I0912 05:47:15.547082 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989369
I0912 05:47:15.547102 26718 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0912 05:47:32.210897 26718 solver.cpp:228] Iteration 2740, loss = 0.0144615
I0912 05:47:32.210937 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994692
I0912 05:47:32.210950 26718 solver.cpp:244]     Train net output #1: loss = 0.0144615 (* 1 = 0.0144615 loss)
I0912 05:47:32.210957 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993475
I0912 05:47:32.210961 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995922
I0912 05:47:32.210969 26718 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0912 05:47:48.881269 26718 solver.cpp:228] Iteration 2760, loss = 0.00807952
I0912 05:47:48.881392 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996733
I0912 05:47:48.881414 26718 solver.cpp:244]     Train net output #1: loss = 0.00807949 (* 1 = 0.00807949 loss)
I0912 05:47:48.881424 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995671
I0912 05:47:48.881430 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998177
I0912 05:47:48.881439 26718 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0912 05:48:05.501273 26718 solver.cpp:228] Iteration 2780, loss = 0.00812354
I0912 05:48:05.501319 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996617
I0912 05:48:05.501333 26718 solver.cpp:244]     Train net output #1: loss = 0.00812351 (* 1 = 0.00812351 loss)
I0912 05:48:05.501340 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995824
I0912 05:48:05.501345 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997811
I0912 05:48:05.501353 26718 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0912 05:48:22.128396 26718 solver.cpp:228] Iteration 2800, loss = 0.00556744
I0912 05:48:22.128605 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997797
I0912 05:48:22.128623 26718 solver.cpp:244]     Train net output #1: loss = 0.00556742 (* 1 = 0.00556742 loss)
I0912 05:48:22.128628 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997285
I0912 05:48:22.128633 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998388
I0912 05:48:22.128641 26718 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0912 05:48:38.824118 26718 solver.cpp:228] Iteration 2820, loss = 0.00855891
I0912 05:48:38.824167 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996428
I0912 05:48:38.824179 26718 solver.cpp:244]     Train net output #1: loss = 0.00855888 (* 1 = 0.00855888 loss)
I0912 05:48:38.824187 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995827
I0912 05:48:38.824190 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997442
I0912 05:48:38.824198 26718 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0912 05:48:55.493649 26718 solver.cpp:228] Iteration 2840, loss = 0.00655732
I0912 05:48:55.493795 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997214
I0912 05:48:55.493813 26718 solver.cpp:244]     Train net output #1: loss = 0.00655729 (* 1 = 0.00655729 loss)
I0912 05:48:55.493818 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996781
I0912 05:48:55.493824 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998094
I0912 05:48:55.493834 26718 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0912 05:49:12.164451 26718 solver.cpp:228] Iteration 2860, loss = 0.00673379
I0912 05:49:12.164497 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997001
I0912 05:49:12.164511 26718 solver.cpp:244]     Train net output #1: loss = 0.00673376 (* 1 = 0.00673376 loss)
I0912 05:49:12.164517 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995829
I0912 05:49:12.164522 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998649
I0912 05:49:12.164530 26718 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0912 05:49:28.854938 26718 solver.cpp:228] Iteration 2880, loss = 0.0135074
I0912 05:49:28.855069 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993534
I0912 05:49:28.855103 26718 solver.cpp:244]     Train net output #1: loss = 0.0135073 (* 1 = 0.0135073 loss)
I0912 05:49:28.855113 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989775
I0912 05:49:28.855123 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997962
I0912 05:49:28.855132 26718 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0912 05:49:45.504683 26718 solver.cpp:228] Iteration 2900, loss = 0.00650996
I0912 05:49:45.504727 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997232
I0912 05:49:45.504741 26718 solver.cpp:244]     Train net output #1: loss = 0.00650993 (* 1 = 0.00650993 loss)
I0912 05:49:45.504747 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995472
I0912 05:49:45.504752 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999002
I0912 05:49:45.504760 26718 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0912 05:50:02.173002 26718 solver.cpp:228] Iteration 2920, loss = 0.0091066
I0912 05:50:02.173141 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995839
I0912 05:50:02.173158 26718 solver.cpp:244]     Train net output #1: loss = 0.00910657 (* 1 = 0.00910657 loss)
I0912 05:50:02.173166 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993974
I0912 05:50:02.173177 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99834
I0912 05:50:02.173185 26718 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0912 05:50:18.825163 26718 solver.cpp:228] Iteration 2940, loss = 0.00357083
I0912 05:50:18.825204 26718 solver.cpp:244]     Train net output #0: accuracy = 0.998889
I0912 05:50:18.825219 26718 solver.cpp:244]     Train net output #1: loss = 0.0035708 (* 1 = 0.0035708 loss)
I0912 05:50:18.825225 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999018
I0912 05:50:18.825230 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998532
I0912 05:50:18.825238 26718 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0912 05:50:35.513968 26718 solver.cpp:228] Iteration 2960, loss = 0.00684827
I0912 05:50:35.514120 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997267
I0912 05:50:35.514137 26718 solver.cpp:244]     Train net output #1: loss = 0.00684824 (* 1 = 0.00684824 loss)
I0912 05:50:35.514143 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997222
I0912 05:50:35.514148 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997351
I0912 05:50:35.514158 26718 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0912 05:50:52.188516 26718 solver.cpp:228] Iteration 2980, loss = 0.0116533
I0912 05:50:52.188565 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99488
I0912 05:50:52.188588 26718 solver.cpp:244]     Train net output #1: loss = 0.0116532 (* 1 = 0.0116532 loss)
I0912 05:50:52.188599 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993162
I0912 05:50:52.188604 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997258
I0912 05:50:52.188612 26718 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0912 05:51:08.857308 26718 solver.cpp:228] Iteration 3000, loss = 0.00610541
I0912 05:51:08.857472 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997501
I0912 05:51:08.857491 26718 solver.cpp:244]     Train net output #1: loss = 0.00610538 (* 1 = 0.00610538 loss)
I0912 05:51:08.857497 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995236
I0912 05:51:08.857502 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999411
I0912 05:51:08.857511 26718 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0912 05:51:25.528101 26718 solver.cpp:228] Iteration 3020, loss = 0.010153
I0912 05:51:25.528164 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99567
I0912 05:51:25.528182 26718 solver.cpp:244]     Train net output #1: loss = 0.010153 (* 1 = 0.010153 loss)
I0912 05:51:25.528195 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994323
I0912 05:51:25.528201 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997616
I0912 05:51:25.528215 26718 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0912 05:51:42.180095 26718 solver.cpp:228] Iteration 3040, loss = 0.00909172
I0912 05:51:42.180233 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996615
I0912 05:51:42.180250 26718 solver.cpp:244]     Train net output #1: loss = 0.00909169 (* 1 = 0.00909169 loss)
I0912 05:51:42.180256 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994083
I0912 05:51:42.180261 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998344
I0912 05:51:42.180270 26718 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0912 05:51:58.843582 26718 solver.cpp:228] Iteration 3060, loss = 0.01038
I0912 05:51:58.843636 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995741
I0912 05:51:58.843662 26718 solver.cpp:244]     Train net output #1: loss = 0.01038 (* 1 = 0.01038 loss)
I0912 05:51:58.843675 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991432
I0912 05:51:58.843688 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998794
I0912 05:51:58.843698 26718 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0912 05:52:15.501947 26718 solver.cpp:228] Iteration 3080, loss = 0.00884632
I0912 05:52:15.502106 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995881
I0912 05:52:15.502140 26718 solver.cpp:244]     Train net output #1: loss = 0.00884629 (* 1 = 0.00884629 loss)
I0912 05:52:15.502148 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992581
I0912 05:52:15.502159 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999123
I0912 05:52:15.502166 26718 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0912 05:52:32.167181 26718 solver.cpp:228] Iteration 3100, loss = 0.010318
I0912 05:52:32.167234 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996183
I0912 05:52:32.167250 26718 solver.cpp:244]     Train net output #1: loss = 0.0103179 (* 1 = 0.0103179 loss)
I0912 05:52:32.167256 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995707
I0912 05:52:32.167263 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9967
I0912 05:52:32.167270 26718 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0912 05:52:48.821859 26718 solver.cpp:228] Iteration 3120, loss = 0.00817828
I0912 05:52:48.822034 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996568
I0912 05:52:48.822054 26718 solver.cpp:244]     Train net output #1: loss = 0.00817825 (* 1 = 0.00817825 loss)
I0912 05:52:48.822067 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994097
I0912 05:52:48.822073 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998793
I0912 05:52:48.822082 26718 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0912 05:53:05.445861 26718 solver.cpp:228] Iteration 3140, loss = 0.00986134
I0912 05:53:05.445935 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996408
I0912 05:53:05.445951 26718 solver.cpp:244]     Train net output #1: loss = 0.00986131 (* 1 = 0.00986131 loss)
I0912 05:53:05.445961 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99693
I0912 05:53:05.445967 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994043
I0912 05:53:05.445976 26718 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0912 05:53:22.069577 26718 solver.cpp:228] Iteration 3160, loss = 0.00932501
I0912 05:53:22.069694 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995883
I0912 05:53:22.069710 26718 solver.cpp:244]     Train net output #1: loss = 0.00932498 (* 1 = 0.00932498 loss)
I0912 05:53:22.069721 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995304
I0912 05:53:22.069726 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997134
I0912 05:53:22.069735 26718 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0912 05:53:38.697968 26718 solver.cpp:228] Iteration 3180, loss = 0.00458134
I0912 05:53:38.698016 26718 solver.cpp:244]     Train net output #0: accuracy = 0.998132
I0912 05:53:38.698031 26718 solver.cpp:244]     Train net output #1: loss = 0.00458131 (* 1 = 0.00458131 loss)
I0912 05:53:38.698045 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997717
I0912 05:53:38.698050 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998778
I0912 05:53:38.698058 26718 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0912 05:53:55.332166 26718 solver.cpp:228] Iteration 3200, loss = 0.0082993
I0912 05:53:55.332311 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99639
I0912 05:53:55.332350 26718 solver.cpp:244]     Train net output #1: loss = 0.00829927 (* 1 = 0.00829927 loss)
I0912 05:53:55.332358 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994461
I0912 05:53:55.332368 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998541
I0912 05:53:55.332377 26718 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0912 05:54:11.990418 26718 solver.cpp:228] Iteration 3220, loss = 0.00598938
I0912 05:54:11.990469 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997418
I0912 05:54:11.990485 26718 solver.cpp:244]     Train net output #1: loss = 0.00598935 (* 1 = 0.00598935 loss)
I0912 05:54:11.990494 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996336
I0912 05:54:11.990499 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998744
I0912 05:54:11.990507 26718 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0912 05:54:28.643178 26718 solver.cpp:228] Iteration 3240, loss = 0.00660188
I0912 05:54:28.643328 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997431
I0912 05:54:28.643368 26718 solver.cpp:244]     Train net output #1: loss = 0.00660185 (* 1 = 0.00660185 loss)
I0912 05:54:28.643375 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99717
I0912 05:54:28.643381 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997835
I0912 05:54:28.643389 26718 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0912 05:54:45.262274 26718 solver.cpp:228] Iteration 3260, loss = 0.00825891
I0912 05:54:45.262326 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997143
I0912 05:54:45.262352 26718 solver.cpp:244]     Train net output #1: loss = 0.00825888 (* 1 = 0.00825888 loss)
I0912 05:54:45.262362 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997856
I0912 05:54:45.262367 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995677
I0912 05:54:45.262374 26718 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0912 05:55:01.880981 26718 solver.cpp:228] Iteration 3280, loss = 0.0102021
I0912 05:55:01.881171 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995032
I0912 05:55:01.881189 26718 solver.cpp:244]     Train net output #1: loss = 0.0102021 (* 1 = 0.0102021 loss)
I0912 05:55:01.881201 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991066
I0912 05:55:01.881206 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999056
I0912 05:55:01.881214 26718 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0912 05:55:18.496474 26718 solver.cpp:228] Iteration 3300, loss = 0.00747409
I0912 05:55:18.496520 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996794
I0912 05:55:18.496547 26718 solver.cpp:244]     Train net output #1: loss = 0.00747406 (* 1 = 0.00747406 loss)
I0912 05:55:18.496557 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996253
I0912 05:55:18.496569 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998131
I0912 05:55:18.496579 26718 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0912 05:55:35.137820 26718 solver.cpp:228] Iteration 3320, loss = 0.00786492
I0912 05:55:35.137950 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996447
I0912 05:55:35.137964 26718 solver.cpp:244]     Train net output #1: loss = 0.00786489 (* 1 = 0.00786489 loss)
I0912 05:55:35.137971 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994272
I0912 05:55:35.137976 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998926
I0912 05:55:35.137986 26718 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0912 05:55:51.757993 26718 solver.cpp:228] Iteration 3340, loss = 0.00262216
I0912 05:55:51.758033 26718 solver.cpp:244]     Train net output #0: accuracy = 0.998955
I0912 05:55:51.758045 26718 solver.cpp:244]     Train net output #1: loss = 0.00262213 (* 1 = 0.00262213 loss)
I0912 05:55:51.758052 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99875
I0912 05:55:51.758059 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9993
I0912 05:55:51.758069 26718 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0912 05:56:08.385885 26718 solver.cpp:228] Iteration 3360, loss = 0.00631698
I0912 05:56:08.385999 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997355
I0912 05:56:08.386032 26718 solver.cpp:244]     Train net output #1: loss = 0.00631695 (* 1 = 0.00631695 loss)
I0912 05:56:08.386041 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997149
I0912 05:56:08.386046 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997783
I0912 05:56:08.386054 26718 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0912 05:56:25.005158 26718 solver.cpp:228] Iteration 3380, loss = 0.00543827
I0912 05:56:25.005201 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99776
I0912 05:56:25.005215 26718 solver.cpp:244]     Train net output #1: loss = 0.00543824 (* 1 = 0.00543824 loss)
I0912 05:56:25.005221 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997172
I0912 05:56:25.005226 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998638
I0912 05:56:25.005234 26718 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0912 05:56:41.623456 26718 solver.cpp:228] Iteration 3400, loss = 0.0087546
I0912 05:56:41.623649 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996577
I0912 05:56:41.623667 26718 solver.cpp:244]     Train net output #1: loss = 0.00875457 (* 1 = 0.00875457 loss)
I0912 05:56:41.623675 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996846
I0912 05:56:41.623680 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995994
I0912 05:56:41.623688 26718 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0912 05:56:58.255535 26718 solver.cpp:228] Iteration 3420, loss = 0.00739492
I0912 05:56:58.255578 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997075
I0912 05:56:58.255604 26718 solver.cpp:244]     Train net output #1: loss = 0.00739489 (* 1 = 0.00739489 loss)
I0912 05:56:58.255614 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99603
I0912 05:56:58.255619 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99821
I0912 05:56:58.255632 26718 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0912 05:57:14.892738 26718 solver.cpp:228] Iteration 3440, loss = 0.00693471
I0912 05:57:14.892881 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997238
I0912 05:57:14.892900 26718 solver.cpp:244]     Train net output #1: loss = 0.00693468 (* 1 = 0.00693468 loss)
I0912 05:57:14.892912 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996441
I0912 05:57:14.892922 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998287
I0912 05:57:14.892930 26718 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0912 05:57:31.544457 26718 solver.cpp:228] Iteration 3460, loss = 0.0034084
I0912 05:57:31.544502 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99897
I0912 05:57:31.544515 26718 solver.cpp:244]     Train net output #1: loss = 0.00340837 (* 1 = 0.00340837 loss)
I0912 05:57:31.544523 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.999184
I0912 05:57:31.544538 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99838
I0912 05:57:31.544549 26718 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0912 05:57:48.216511 26718 solver.cpp:228] Iteration 3480, loss = 0.0056666
I0912 05:57:48.216655 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997513
I0912 05:57:48.216670 26718 solver.cpp:244]     Train net output #1: loss = 0.00566657 (* 1 = 0.00566657 loss)
I0912 05:57:48.216676 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996861
I0912 05:57:48.216681 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998746
I0912 05:57:48.216688 26718 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0912 05:58:04.825805 26718 solver.cpp:228] Iteration 3500, loss = 0.0140891
I0912 05:58:04.825845 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994524
I0912 05:58:04.825857 26718 solver.cpp:244]     Train net output #1: loss = 0.0140891 (* 1 = 0.0140891 loss)
I0912 05:58:04.825863 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993879
I0912 05:58:04.825867 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995365
I0912 05:58:04.825875 26718 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0912 05:58:21.435325 26718 solver.cpp:228] Iteration 3520, loss = 0.00679978
I0912 05:58:21.435461 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997242
I0912 05:58:21.435483 26718 solver.cpp:244]     Train net output #1: loss = 0.00679974 (* 1 = 0.00679974 loss)
I0912 05:58:21.435492 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996664
I0912 05:58:21.435497 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998026
I0912 05:58:21.435504 26718 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0912 05:58:38.058928 26718 solver.cpp:228] Iteration 3540, loss = 0.0110281
I0912 05:58:38.058969 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99556
I0912 05:58:38.058981 26718 solver.cpp:244]     Train net output #1: loss = 0.0110281 (* 1 = 0.0110281 loss)
I0912 05:58:38.058989 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992189
I0912 05:58:38.058992 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998186
I0912 05:58:38.059000 26718 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0912 05:58:54.685809 26718 solver.cpp:228] Iteration 3560, loss = 0.0087483
I0912 05:58:54.685971 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996474
I0912 05:58:54.685987 26718 solver.cpp:244]     Train net output #1: loss = 0.00874827 (* 1 = 0.00874827 loss)
I0912 05:58:54.685997 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994953
I0912 05:58:54.686002 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997951
I0912 05:58:54.686010 26718 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0912 05:59:11.303614 26718 solver.cpp:228] Iteration 3580, loss = 0.00620029
I0912 05:59:11.303652 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997429
I0912 05:59:11.303665 26718 solver.cpp:244]     Train net output #1: loss = 0.00620026 (* 1 = 0.00620026 loss)
I0912 05:59:11.303671 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997109
I0912 05:59:11.303676 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99809
I0912 05:59:11.303683 26718 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0912 05:59:27.916154 26718 solver.cpp:228] Iteration 3600, loss = 0.0117198
I0912 05:59:27.916308 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994537
I0912 05:59:27.916348 26718 solver.cpp:244]     Train net output #1: loss = 0.0117198 (* 1 = 0.0117198 loss)
I0912 05:59:27.916357 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992858
I0912 05:59:27.916368 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997203
I0912 05:59:27.916376 26718 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0912 05:59:44.602222 26718 solver.cpp:228] Iteration 3620, loss = 0.00813214
I0912 05:59:44.602272 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99634
I0912 05:59:44.602301 26718 solver.cpp:244]     Train net output #1: loss = 0.00813211 (* 1 = 0.00813211 loss)
I0912 05:59:44.602311 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99576
I0912 05:59:44.602321 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997871
I0912 05:59:44.602329 26718 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0912 06:00:01.268832 26718 solver.cpp:228] Iteration 3640, loss = 0.00875471
I0912 06:00:01.268947 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996296
I0912 06:00:01.268963 26718 solver.cpp:244]     Train net output #1: loss = 0.00875468 (* 1 = 0.00875468 loss)
I0912 06:00:01.268971 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993004
I0912 06:00:01.268976 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998906
I0912 06:00:01.268985 26718 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0912 06:00:17.920624 26718 solver.cpp:228] Iteration 3660, loss = 0.00368098
I0912 06:00:17.920707 26718 solver.cpp:244]     Train net output #0: accuracy = 0.998568
I0912 06:00:17.920733 26718 solver.cpp:244]     Train net output #1: loss = 0.00368095 (* 1 = 0.00368095 loss)
I0912 06:00:17.920749 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998448
I0912 06:00:17.920760 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998895
I0912 06:00:17.920778 26718 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0912 06:00:34.591944 26718 solver.cpp:228] Iteration 3680, loss = 0.00507728
I0912 06:00:34.592067 26718 solver.cpp:244]     Train net output #0: accuracy = 0.998038
I0912 06:00:34.592083 26718 solver.cpp:244]     Train net output #1: loss = 0.00507725 (* 1 = 0.00507725 loss)
I0912 06:00:34.592089 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998057
I0912 06:00:34.592093 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997989
I0912 06:00:34.592102 26718 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0912 06:00:51.253803 26718 solver.cpp:228] Iteration 3700, loss = 0.007265
I0912 06:00:51.253849 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996901
I0912 06:00:51.253880 26718 solver.cpp:244]     Train net output #1: loss = 0.00726497 (* 1 = 0.00726497 loss)
I0912 06:00:51.253888 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996688
I0912 06:00:51.253895 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99751
I0912 06:00:51.253903 26718 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0912 06:01:07.875347 26718 solver.cpp:228] Iteration 3720, loss = 0.00674481
I0912 06:01:07.875524 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996988
I0912 06:01:07.875540 26718 solver.cpp:244]     Train net output #1: loss = 0.00674478 (* 1 = 0.00674478 loss)
I0912 06:01:07.875551 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994519
I0912 06:01:07.875557 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999185
I0912 06:01:07.875566 26718 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0912 06:01:24.489164 26718 solver.cpp:228] Iteration 3740, loss = 0.0108592
I0912 06:01:24.489233 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995234
I0912 06:01:24.489246 26718 solver.cpp:244]     Train net output #1: loss = 0.0108591 (* 1 = 0.0108591 loss)
I0912 06:01:24.489261 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994856
I0912 06:01:24.489266 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996487
I0912 06:01:24.489274 26718 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0912 06:01:41.092911 26718 solver.cpp:228] Iteration 3760, loss = 0.0079307
I0912 06:01:41.093016 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996787
I0912 06:01:41.093040 26718 solver.cpp:244]     Train net output #1: loss = 0.00793067 (* 1 = 0.00793067 loss)
I0912 06:01:41.093055 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996853
I0912 06:01:41.093070 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996611
I0912 06:01:41.093082 26718 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0912 06:01:57.709969 26718 solver.cpp:228] Iteration 3780, loss = 0.0108067
I0912 06:01:57.710011 26718 solver.cpp:244]     Train net output #0: accuracy = 0.9959
I0912 06:01:57.710022 26718 solver.cpp:244]     Train net output #1: loss = 0.0108067 (* 1 = 0.0108067 loss)
I0912 06:01:57.710028 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995924
I0912 06:01:57.710033 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99586
I0912 06:01:57.710041 26718 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0912 06:02:14.307384 26718 solver.cpp:228] Iteration 3800, loss = 0.00730035
I0912 06:02:14.307505 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996869
I0912 06:02:14.307520 26718 solver.cpp:244]     Train net output #1: loss = 0.00730031 (* 1 = 0.00730031 loss)
I0912 06:02:14.307533 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99554
I0912 06:02:14.307539 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998523
I0912 06:02:14.307546 26718 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0912 06:02:30.917979 26718 solver.cpp:228] Iteration 3820, loss = 0.0059225
I0912 06:02:30.918018 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997894
I0912 06:02:30.918031 26718 solver.cpp:244]     Train net output #1: loss = 0.00592246 (* 1 = 0.00592246 loss)
I0912 06:02:30.918036 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998232
I0912 06:02:30.918041 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997083
I0912 06:02:30.918048 26718 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0912 06:02:47.515301 26718 solver.cpp:228] Iteration 3840, loss = 0.010521
I0912 06:02:47.515489 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995046
I0912 06:02:47.515528 26718 solver.cpp:244]     Train net output #1: loss = 0.0105209 (* 1 = 0.0105209 loss)
I0912 06:02:47.515538 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99308
I0912 06:02:47.515543 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998074
I0912 06:02:47.515552 26718 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0912 06:03:04.211259 26718 solver.cpp:228] Iteration 3860, loss = 0.00994036
I0912 06:03:04.211303 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995584
I0912 06:03:04.211318 26718 solver.cpp:244]     Train net output #1: loss = 0.00994033 (* 1 = 0.00994033 loss)
I0912 06:03:04.211324 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992738
I0912 06:03:04.211329 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998543
I0912 06:03:04.211344 26718 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0912 06:03:20.888128 26718 solver.cpp:228] Iteration 3880, loss = 0.00738325
I0912 06:03:20.888286 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996564
I0912 06:03:20.888308 26718 solver.cpp:244]     Train net output #1: loss = 0.00738321 (* 1 = 0.00738321 loss)
I0912 06:03:20.888315 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993642
I0912 06:03:20.888321 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999388
I0912 06:03:20.888329 26718 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0912 06:03:37.484186 26718 solver.cpp:228] Iteration 3900, loss = 0.00589876
I0912 06:03:37.484233 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997554
I0912 06:03:37.484248 26718 solver.cpp:244]     Train net output #1: loss = 0.00589872 (* 1 = 0.00589872 loss)
I0912 06:03:37.484256 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997074
I0912 06:03:37.484261 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998255
I0912 06:03:37.484271 26718 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0912 06:03:54.121176 26718 solver.cpp:228] Iteration 3920, loss = 0.0121783
I0912 06:03:54.121301 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994612
I0912 06:03:54.121317 26718 solver.cpp:244]     Train net output #1: loss = 0.0121783 (* 1 = 0.0121783 loss)
I0912 06:03:54.121325 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989905
I0912 06:03:54.121330 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998442
I0912 06:03:54.121337 26718 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0912 06:04:10.822137 26718 solver.cpp:228] Iteration 3940, loss = 0.00932403
I0912 06:04:10.822203 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996266
I0912 06:04:10.822221 26718 solver.cpp:244]     Train net output #1: loss = 0.009324 (* 1 = 0.009324 loss)
I0912 06:04:10.822227 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991843
I0912 06:04:10.822232 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999128
I0912 06:04:10.822240 26718 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0912 06:04:27.429057 26718 solver.cpp:228] Iteration 3960, loss = 0.00539388
I0912 06:04:27.429184 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997733
I0912 06:04:27.429201 26718 solver.cpp:244]     Train net output #1: loss = 0.00539384 (* 1 = 0.00539384 loss)
I0912 06:04:27.429214 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996841
I0912 06:04:27.429226 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998817
I0912 06:04:27.429234 26718 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0912 06:04:44.057353 26718 solver.cpp:228] Iteration 3980, loss = 0.00459307
I0912 06:04:44.057405 26718 solver.cpp:244]     Train net output #0: accuracy = 0.998176
I0912 06:04:44.057418 26718 solver.cpp:244]     Train net output #1: loss = 0.00459303 (* 1 = 0.00459303 loss)
I0912 06:04:44.057425 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998069
I0912 06:04:44.057430 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998417
I0912 06:04:44.057438 26718 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0912 06:05:00.736883 26718 solver.cpp:228] Iteration 4000, loss = 0.00568577
I0912 06:05:00.737066 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997565
I0912 06:05:00.737102 26718 solver.cpp:244]     Train net output #1: loss = 0.00568573 (* 1 = 0.00568573 loss)
I0912 06:05:00.737110 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995271
I0912 06:05:00.737121 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999609
I0912 06:05:00.737131 26718 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0912 06:05:17.346439 26718 solver.cpp:228] Iteration 4020, loss = 0.0116739
I0912 06:05:17.346480 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996212
I0912 06:05:17.346493 26718 solver.cpp:244]     Train net output #1: loss = 0.0116739 (* 1 = 0.0116739 loss)
I0912 06:05:17.346500 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997183
I0912 06:05:17.346506 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991201
I0912 06:05:17.346514 26718 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0912 06:05:33.970214 26718 solver.cpp:228] Iteration 4040, loss = 0.00628316
I0912 06:05:33.970350 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997604
I0912 06:05:33.970366 26718 solver.cpp:244]     Train net output #1: loss = 0.00628312 (* 1 = 0.00628312 loss)
I0912 06:05:33.970374 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996142
I0912 06:05:33.970381 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998824
I0912 06:05:33.970388 26718 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0912 06:05:50.563051 26718 solver.cpp:228] Iteration 4060, loss = 0.00855345
I0912 06:05:50.563112 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996408
I0912 06:05:50.563124 26718 solver.cpp:244]     Train net output #1: loss = 0.00855341 (* 1 = 0.00855341 loss)
I0912 06:05:50.563130 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995709
I0912 06:05:50.563135 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997664
I0912 06:05:50.563143 26718 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0912 06:06:07.176463 26718 solver.cpp:228] Iteration 4080, loss = 0.00762565
I0912 06:06:07.176607 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996412
I0912 06:06:07.176647 26718 solver.cpp:244]     Train net output #1: loss = 0.00762561 (* 1 = 0.00762561 loss)
I0912 06:06:07.176656 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994693
I0912 06:06:07.176666 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999053
I0912 06:06:07.176676 26718 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0912 06:06:23.855116 26718 solver.cpp:228] Iteration 4100, loss = 0.00771304
I0912 06:06:23.855160 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996681
I0912 06:06:23.855175 26718 solver.cpp:244]     Train net output #1: loss = 0.007713 (* 1 = 0.007713 loss)
I0912 06:06:23.855181 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996312
I0912 06:06:23.855186 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998035
I0912 06:06:23.855202 26718 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0912 06:06:40.527940 26718 solver.cpp:228] Iteration 4120, loss = 0.00805475
I0912 06:06:40.528086 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997147
I0912 06:06:40.528111 26718 solver.cpp:244]     Train net output #1: loss = 0.00805472 (* 1 = 0.00805472 loss)
I0912 06:06:40.528120 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997934
I0912 06:06:40.528125 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995409
I0912 06:06:40.528142 26718 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0912 06:06:57.199374 26718 solver.cpp:228] Iteration 4140, loss = 0.00847209
I0912 06:06:57.199450 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996486
I0912 06:06:57.199471 26718 solver.cpp:244]     Train net output #1: loss = 0.00847206 (* 1 = 0.00847206 loss)
I0912 06:06:57.199486 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995262
I0912 06:06:57.199498 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997925
I0912 06:06:57.199512 26718 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0912 06:07:13.868407 26718 solver.cpp:228] Iteration 4160, loss = 0.00958861
I0912 06:07:13.868537 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996522
I0912 06:07:13.868554 26718 solver.cpp:244]     Train net output #1: loss = 0.00958858 (* 1 = 0.00958858 loss)
I0912 06:07:13.868561 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996461
I0912 06:07:13.868566 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996839
I0912 06:07:13.868573 26718 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0912 06:07:30.522523 26718 solver.cpp:228] Iteration 4180, loss = 0.00480406
I0912 06:07:30.522569 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99809
I0912 06:07:30.522586 26718 solver.cpp:244]     Train net output #1: loss = 0.00480403 (* 1 = 0.00480403 loss)
I0912 06:07:30.522598 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998031
I0912 06:07:30.522603 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998255
I0912 06:07:30.522610 26718 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0912 06:07:47.193172 26718 solver.cpp:228] Iteration 4200, loss = 0.0144453
I0912 06:07:47.193281 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993857
I0912 06:07:47.193302 26718 solver.cpp:244]     Train net output #1: loss = 0.0144452 (* 1 = 0.0144452 loss)
I0912 06:07:47.193311 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993109
I0912 06:07:47.193322 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995501
I0912 06:07:47.193331 26718 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0912 06:08:03.858417 26718 solver.cpp:228] Iteration 4220, loss = 0.00635343
I0912 06:08:03.858470 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997335
I0912 06:08:03.858494 26718 solver.cpp:244]     Train net output #1: loss = 0.0063534 (* 1 = 0.0063534 loss)
I0912 06:08:03.858508 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996397
I0912 06:08:03.858520 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998592
I0912 06:08:03.858530 26718 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0912 06:08:20.519096 26718 solver.cpp:228] Iteration 4240, loss = 0.0109766
I0912 06:08:20.519217 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995909
I0912 06:08:20.519229 26718 solver.cpp:244]     Train net output #1: loss = 0.0109765 (* 1 = 0.0109765 loss)
I0912 06:08:20.519235 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995836
I0912 06:08:20.519240 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996
I0912 06:08:20.519248 26718 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0912 06:08:37.196913 26718 solver.cpp:228] Iteration 4260, loss = 0.0128187
I0912 06:08:37.196965 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994677
I0912 06:08:37.196998 26718 solver.cpp:244]     Train net output #1: loss = 0.0128186 (* 1 = 0.0128186 loss)
I0912 06:08:37.197013 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992258
I0912 06:08:37.197023 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999567
I0912 06:08:37.197032 26718 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0912 06:08:53.814769 26718 solver.cpp:228] Iteration 4280, loss = 0.0464337
I0912 06:08:53.814873 26718 solver.cpp:244]     Train net output #0: accuracy = 0.982422
I0912 06:08:53.814890 26718 solver.cpp:244]     Train net output #1: loss = 0.0464336 (* 1 = 0.0464336 loss)
I0912 06:08:53.814903 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975295
I0912 06:08:53.814909 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995232
I0912 06:08:53.814918 26718 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0912 06:09:10.453814 26718 solver.cpp:228] Iteration 4300, loss = 0.0409197
I0912 06:09:10.453886 26718 solver.cpp:244]     Train net output #0: accuracy = 0.985194
I0912 06:09:10.453902 26718 solver.cpp:244]     Train net output #1: loss = 0.0409196 (* 1 = 0.0409196 loss)
I0912 06:09:10.453915 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981119
I0912 06:09:10.453922 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991619
I0912 06:09:10.453928 26718 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0912 06:09:27.080014 26718 solver.cpp:228] Iteration 4320, loss = 0.0536069
I0912 06:09:27.080216 26718 solver.cpp:244]     Train net output #0: accuracy = 0.977956
I0912 06:09:27.080234 26718 solver.cpp:244]     Train net output #1: loss = 0.0536068 (* 1 = 0.0536068 loss)
I0912 06:09:27.080243 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.96496
I0912 06:09:27.080248 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994145
I0912 06:09:27.080257 26718 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0912 06:09:43.734411 26718 solver.cpp:228] Iteration 4340, loss = 0.0369636
I0912 06:09:43.734459 26718 solver.cpp:244]     Train net output #0: accuracy = 0.985923
I0912 06:09:43.734473 26718 solver.cpp:244]     Train net output #1: loss = 0.0369634 (* 1 = 0.0369634 loss)
I0912 06:09:43.734479 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983156
I0912 06:09:43.734485 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990336
I0912 06:09:43.734493 26718 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0912 06:10:00.376025 26718 solver.cpp:228] Iteration 4360, loss = 0.0176411
I0912 06:10:00.376143 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993598
I0912 06:10:00.376168 26718 solver.cpp:244]     Train net output #1: loss = 0.017641 (* 1 = 0.017641 loss)
I0912 06:10:00.376178 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989333
I0912 06:10:00.376188 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997157
I0912 06:10:00.376197 26718 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0912 06:10:16.990973 26718 solver.cpp:228] Iteration 4380, loss = 0.0961196
I0912 06:10:16.991016 26718 solver.cpp:244]     Train net output #0: accuracy = 0.975495
I0912 06:10:16.991030 26718 solver.cpp:244]     Train net output #1: loss = 0.0961195 (* 1 = 0.0961195 loss)
I0912 06:10:16.991037 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97301
I0912 06:10:16.991044 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980766
I0912 06:10:16.991051 26718 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0912 06:10:33.637262 26718 solver.cpp:228] Iteration 4400, loss = 0.0436144
I0912 06:10:33.637413 26718 solver.cpp:244]     Train net output #0: accuracy = 0.985152
I0912 06:10:33.637468 26718 solver.cpp:244]     Train net output #1: loss = 0.0436143 (* 1 = 0.0436143 loss)
I0912 06:10:33.637480 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987144
I0912 06:10:33.637488 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982714
I0912 06:10:33.637498 26718 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0912 06:10:50.308143 26718 solver.cpp:228] Iteration 4420, loss = 0.0152758
I0912 06:10:50.308188 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994122
I0912 06:10:50.308202 26718 solver.cpp:244]     Train net output #1: loss = 0.0152756 (* 1 = 0.0152756 loss)
I0912 06:10:50.308207 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992538
I0912 06:10:50.308213 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996153
I0912 06:10:50.308221 26718 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0912 06:11:06.984714 26718 solver.cpp:228] Iteration 4440, loss = 0.014221
I0912 06:11:06.984848 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994389
I0912 06:11:06.984868 26718 solver.cpp:244]     Train net output #1: loss = 0.0142208 (* 1 = 0.0142208 loss)
I0912 06:11:06.984874 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993553
I0912 06:11:06.984884 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995777
I0912 06:11:06.984891 26718 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0912 06:11:23.641295 26718 solver.cpp:228] Iteration 4460, loss = 0.0140501
I0912 06:11:23.641345 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993644
I0912 06:11:23.641360 26718 solver.cpp:244]     Train net output #1: loss = 0.0140499 (* 1 = 0.0140499 loss)
I0912 06:11:23.641371 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991296
I0912 06:11:23.641377 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997004
I0912 06:11:23.641386 26718 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0912 06:11:40.319378 26718 solver.cpp:228] Iteration 4480, loss = 0.014167
I0912 06:11:40.319486 26718 solver.cpp:244]     Train net output #0: accuracy = 0.9947
I0912 06:11:40.319505 26718 solver.cpp:244]     Train net output #1: loss = 0.0141669 (* 1 = 0.0141669 loss)
I0912 06:11:40.319514 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995328
I0912 06:11:40.319519 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993313
I0912 06:11:40.319527 26718 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0912 06:11:57.008529 26718 solver.cpp:228] Iteration 4500, loss = 0.0146234
I0912 06:11:57.008584 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994557
I0912 06:11:57.008600 26718 solver.cpp:244]     Train net output #1: loss = 0.0146232 (* 1 = 0.0146232 loss)
I0912 06:11:57.008612 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991505
I0912 06:11:57.008626 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997071
I0912 06:11:57.008640 26718 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0912 06:12:13.678699 26718 solver.cpp:228] Iteration 4520, loss = 0.0330207
I0912 06:12:13.678853 26718 solver.cpp:244]     Train net output #0: accuracy = 0.988591
I0912 06:12:13.678879 26718 solver.cpp:244]     Train net output #1: loss = 0.0330206 (* 1 = 0.0330206 loss)
I0912 06:12:13.678887 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98924
I0912 06:12:13.678899 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987674
I0912 06:12:13.678911 26718 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0912 06:12:30.356416 26718 solver.cpp:228] Iteration 4540, loss = 0.0111074
I0912 06:12:30.356470 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996204
I0912 06:12:30.356498 26718 solver.cpp:244]     Train net output #1: loss = 0.0111073 (* 1 = 0.0111073 loss)
I0912 06:12:30.356508 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997018
I0912 06:12:30.356514 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994463
I0912 06:12:30.356523 26718 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0912 06:12:47.008868 26718 solver.cpp:228] Iteration 4560, loss = 0.0121402
I0912 06:12:47.009011 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995175
I0912 06:12:47.009039 26718 solver.cpp:244]     Train net output #1: loss = 0.0121401 (* 1 = 0.0121401 loss)
I0912 06:12:47.009048 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992251
I0912 06:12:47.009060 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998022
I0912 06:12:47.009069 26718 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0912 06:13:03.696672 26718 solver.cpp:228] Iteration 4580, loss = 0.014492
I0912 06:13:03.696718 26718 solver.cpp:244]     Train net output #0: accuracy = 0.994562
I0912 06:13:03.696732 26718 solver.cpp:244]     Train net output #1: loss = 0.0144919 (* 1 = 0.0144919 loss)
I0912 06:13:03.696739 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995415
I0912 06:13:03.696744 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992688
I0912 06:13:03.696753 26718 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0912 06:13:20.367905 26718 solver.cpp:228] Iteration 4600, loss = 0.00635524
I0912 06:13:20.368068 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99781
I0912 06:13:20.368086 26718 solver.cpp:244]     Train net output #1: loss = 0.0063551 (* 1 = 0.0063551 loss)
I0912 06:13:20.368096 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998345
I0912 06:13:20.368101 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996196
I0912 06:13:20.368114 26718 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0912 06:13:37.029801 26718 solver.cpp:228] Iteration 4620, loss = 0.0100037
I0912 06:13:37.029856 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99636
I0912 06:13:37.029872 26718 solver.cpp:244]     Train net output #1: loss = 0.0100035 (* 1 = 0.0100035 loss)
I0912 06:13:37.029881 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994736
I0912 06:13:37.029887 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997873
I0912 06:13:37.029897 26718 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0912 06:13:53.694674 26718 solver.cpp:228] Iteration 4640, loss = 0.0153637
I0912 06:13:53.694810 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993825
I0912 06:13:53.694826 26718 solver.cpp:244]     Train net output #1: loss = 0.0153636 (* 1 = 0.0153636 loss)
I0912 06:13:53.694833 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992335
I0912 06:13:53.694838 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995913
I0912 06:13:53.694845 26718 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0912 06:14:10.352460 26718 solver.cpp:228] Iteration 4660, loss = 0.010126
I0912 06:14:10.352514 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996606
I0912 06:14:10.352542 26718 solver.cpp:244]     Train net output #1: loss = 0.0101259 (* 1 = 0.0101259 loss)
I0912 06:14:10.352550 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995334
I0912 06:14:10.352556 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997613
I0912 06:14:10.352566 26718 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0912 06:14:27.017547 26718 solver.cpp:228] Iteration 4680, loss = 0.0170134
I0912 06:14:27.017704 26718 solver.cpp:244]     Train net output #0: accuracy = 0.992407
I0912 06:14:27.017735 26718 solver.cpp:244]     Train net output #1: loss = 0.0170132 (* 1 = 0.0170132 loss)
I0912 06:14:27.017743 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991576
I0912 06:14:27.017748 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995126
I0912 06:14:27.017755 26718 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0912 06:14:43.675302 26718 solver.cpp:228] Iteration 4700, loss = 0.0070291
I0912 06:14:43.675354 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997073
I0912 06:14:43.675369 26718 solver.cpp:244]     Train net output #1: loss = 0.00702895 (* 1 = 0.00702895 loss)
I0912 06:14:43.675376 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995858
I0912 06:14:43.675382 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998518
I0912 06:14:43.675391 26718 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0912 06:15:00.313889 26718 solver.cpp:228] Iteration 4720, loss = 0.0129487
I0912 06:15:00.314010 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995881
I0912 06:15:00.314028 26718 solver.cpp:244]     Train net output #1: loss = 0.0129486 (* 1 = 0.0129486 loss)
I0912 06:15:00.314034 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997244
I0912 06:15:00.314039 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990083
I0912 06:15:00.314045 26718 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0912 06:15:16.970018 26718 solver.cpp:228] Iteration 4740, loss = 0.0143103
I0912 06:15:16.970072 26718 solver.cpp:244]     Train net output #0: accuracy = 0.993776
I0912 06:15:16.970088 26718 solver.cpp:244]     Train net output #1: loss = 0.0143101 (* 1 = 0.0143101 loss)
I0912 06:15:16.970094 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991125
I0912 06:15:16.970100 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997029
I0912 06:15:16.970109 26718 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0912 06:15:33.636765 26718 solver.cpp:228] Iteration 4760, loss = 0.00986137
I0912 06:15:33.636951 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996055
I0912 06:15:33.636988 26718 solver.cpp:244]     Train net output #1: loss = 0.00986122 (* 1 = 0.00986122 loss)
I0912 06:15:33.636997 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995926
I0912 06:15:33.637002 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996495
I0912 06:15:33.637012 26718 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0912 06:15:50.277623 26718 solver.cpp:228] Iteration 4780, loss = 0.0094601
I0912 06:15:50.277673 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996095
I0912 06:15:50.277688 26718 solver.cpp:244]     Train net output #1: loss = 0.00945995 (* 1 = 0.00945995 loss)
I0912 06:15:50.277694 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994697
I0912 06:15:50.277699 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997821
I0912 06:15:50.277707 26718 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0912 06:16:06.923440 26718 solver.cpp:228] Iteration 4800, loss = 0.0075289
I0912 06:16:06.923552 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997034
I0912 06:16:06.923586 26718 solver.cpp:244]     Train net output #1: loss = 0.00752875 (* 1 = 0.00752875 loss)
I0912 06:16:06.923602 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997157
I0912 06:16:06.923609 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996749
I0912 06:16:06.923619 26718 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0912 06:16:23.568267 26718 solver.cpp:228] Iteration 4820, loss = 0.00781534
I0912 06:16:23.568315 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996872
I0912 06:16:23.568330 26718 solver.cpp:244]     Train net output #1: loss = 0.00781519 (* 1 = 0.00781519 loss)
I0912 06:16:23.568336 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99619
I0912 06:16:23.568341 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997821
I0912 06:16:23.568351 26718 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0912 06:16:40.217432 26718 solver.cpp:228] Iteration 4840, loss = 0.00589578
I0912 06:16:40.217572 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997627
I0912 06:16:40.217602 26718 solver.cpp:244]     Train net output #1: loss = 0.00589563 (* 1 = 0.00589563 loss)
I0912 06:16:40.217610 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997644
I0912 06:16:40.217622 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997601
I0912 06:16:40.217631 26718 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0912 06:16:56.892210 26718 solver.cpp:228] Iteration 4860, loss = 0.00575843
I0912 06:16:56.892258 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997757
I0912 06:16:56.892273 26718 solver.cpp:244]     Train net output #1: loss = 0.00575828 (* 1 = 0.00575828 loss)
I0912 06:16:56.892280 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99787
I0912 06:16:56.892285 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997486
I0912 06:16:56.892293 26718 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0912 06:17:13.566478 26718 solver.cpp:228] Iteration 4880, loss = 0.00593241
I0912 06:17:13.566640 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997911
I0912 06:17:13.566676 26718 solver.cpp:244]     Train net output #1: loss = 0.00593225 (* 1 = 0.00593225 loss)
I0912 06:17:13.566685 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997998
I0912 06:17:13.566696 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997667
I0912 06:17:13.566704 26718 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0912 06:17:30.235862 26718 solver.cpp:228] Iteration 4900, loss = 0.00882088
I0912 06:17:30.235909 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996325
I0912 06:17:30.235924 26718 solver.cpp:244]     Train net output #1: loss = 0.00882072 (* 1 = 0.00882072 loss)
I0912 06:17:30.235930 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996034
I0912 06:17:30.235935 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997469
I0912 06:17:30.235942 26718 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0912 06:17:46.887960 26718 solver.cpp:228] Iteration 4920, loss = 0.00942759
I0912 06:17:46.888167 26718 solver.cpp:244]     Train net output #0: accuracy = 0.995885
I0912 06:17:46.888187 26718 solver.cpp:244]     Train net output #1: loss = 0.00942744 (* 1 = 0.00942744 loss)
I0912 06:17:46.888196 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995386
I0912 06:17:46.888201 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997387
I0912 06:17:46.888209 26718 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0912 06:18:03.546895 26718 solver.cpp:228] Iteration 4940, loss = 0.00830948
I0912 06:18:03.546963 26718 solver.cpp:244]     Train net output #0: accuracy = 0.996389
I0912 06:18:03.546993 26718 solver.cpp:244]     Train net output #1: loss = 0.00830933 (* 1 = 0.00830933 loss)
I0912 06:18:03.547001 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994018
I0912 06:18:03.547008 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998625
I0912 06:18:03.547016 26718 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0912 06:18:20.161877 26718 solver.cpp:228] Iteration 4960, loss = 0.00954998
I0912 06:18:20.162039 26718 solver.cpp:244]     Train net output #0: accuracy = 0.997295
I0912 06:18:20.162062 26718 solver.cpp:244]     Train net output #1: loss = 0.00954983 (* 1 = 0.00954983 loss)
I0912 06:18:20.162071 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99717
I0912 06:18:20.162083 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998129
I0912 06:18:20.162092 26718 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0912 06:18:36.799196 26718 solver.cpp:228] Iteration 4980, loss = 0.0118128
I0912 06:18:36.799245 26718 solver.cpp:244]     Train net output #0: accuracy = 0.99554
I0912 06:18:36.799263 26718 solver.cpp:244]     Train net output #1: loss = 0.0118126 (* 1 = 0.0118126 loss)
I0912 06:18:36.799276 26718 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995798
I0912 06:18:36.799288 26718 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994825
I0912 06:18:36.799296 26718 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0912 06:18:53.042934 26718 solver.cpp:454] Snapshotting to binary proto file pocwisc6/training_iter_5000.caffemodel
I0912 06:18:54.126348 26718 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc6/training_iter_5000.solverstate
I0912 06:18:54.726902 26718 solver.cpp:317] Iteration 5000, loss = 0.00689193
I0912 06:18:54.726949 26718 solver.cpp:322] Optimization Done.
I0912 06:18:54.726953 26718 caffe.cpp:254] Optimization Done.

2017-09-12 06:18:55,130 log.framework MainThread  INFO       caffe models found
pocwisc6/training_iter_5000.caffemodel
2017-09-12 06:18:55,130 log.framework MainThread  INFO       Caffe model found: pocwisc6/training_iter_5000.caffemodel
2017-09-12 06:18:56,730 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 06:18:56,875 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 06:18:57,025 log.framework MainThread  INFO       train file number: 29
2017-09-12 06:18:57,025 log.framework MainThread  INFO       test file number: 4
2017-09-12 06:18:57,026 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 06:18:57,026 log.framework MainThread  INFO       subdirectory tree 
2017-09-12 06:18:57,026 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-09-12 06:18:57,027 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-09-12 06:18:57,027 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-09-12 06:18:57,028 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc7/training"
solver_mode: GPU

2017-09-12 06:18:57,028 log.framework MainThread  INFO       caffe training step
2017-09-12 06:18:57,028 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-09-12 07:28:18,362 log.framework MainThread  INFO       I0912 06:18:57.337620 28411 caffe.cpp:217] Using GPUs 0
I0912 06:18:57.372891 28411 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0912 06:18:57.901685 28411 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc7/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0912 06:18:57.901862 28411 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/train.prototxt
I0912 06:18:57.904655 28411 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 06:18:57.905151 28411 layer_factory.hpp:77] Creating layer data
I0912 06:18:57.905170 28411 net.cpp:100] Creating Layer data
I0912 06:18:57.905180 28411 net.cpp:408] data -> data
I0912 06:18:57.905210 28411 net.cpp:408] data -> label
I0912 06:18:57.905230 28411 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt
I0912 06:18:57.905553 28411 hdf5_data_layer.cpp:93] Number of HDF5 files: 29
I0912 06:18:57.906751 28411 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0912 06:18:57.932046 28411 net.cpp:150] Setting up data
I0912 06:18:57.932073 28411 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 06:18:57.932086 28411 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 06:18:57.932090 28411 net.cpp:165] Memory required for data: 24883200
I0912 06:18:57.932099 28411 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 06:18:57.932112 28411 net.cpp:100] Creating Layer label_data_1_split
I0912 06:18:57.932119 28411 net.cpp:434] label_data_1_split <- label
I0912 06:18:57.932137 28411 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 06:18:57.932150 28411 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 06:18:57.932191 28411 net.cpp:150] Setting up label_data_1_split
I0912 06:18:57.932199 28411 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 06:18:57.932204 28411 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 06:18:57.932209 28411 net.cpp:165] Memory required for data: 30412800
I0912 06:18:57.932212 28411 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 06:18:57.932231 28411 net.cpp:100] Creating Layer conv1_1_1
I0912 06:18:57.932236 28411 net.cpp:434] conv1_1_1 <- data
I0912 06:18:57.932242 28411 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 06:18:58.764576 28411 net.cpp:150] Setting up conv1_1_1
I0912 06:18:58.764612 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:58.764616 28411 net.cpp:165] Memory required for data: 207360000
I0912 06:18:58.764642 28411 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 06:18:58.764657 28411 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 06:18:58.764663 28411 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 06:18:58.764670 28411 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 06:18:58.765069 28411 net.cpp:150] Setting up conv1_1_1_bn
I0912 06:18:58.765077 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:58.765081 28411 net.cpp:165] Memory required for data: 384307200
I0912 06:18:58.765094 28411 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 06:18:58.765106 28411 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 06:18:58.765111 28411 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 06:18:58.765116 28411 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 06:18:58.765164 28411 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 06:18:58.766778 28411 net.cpp:150] Setting up conv1_1_1_scale
I0912 06:18:58.766793 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:58.766803 28411 net.cpp:165] Memory required for data: 561254400
I0912 06:18:58.766811 28411 layer_factory.hpp:77] Creating layer relu1_1
I0912 06:18:58.766824 28411 net.cpp:100] Creating Layer relu1_1
I0912 06:18:58.766829 28411 net.cpp:434] relu1_1 <- conv1_1_1
I0912 06:18:58.766834 28411 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 06:18:58.767071 28411 net.cpp:150] Setting up relu1_1
I0912 06:18:58.767079 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:58.767084 28411 net.cpp:165] Memory required for data: 738201600
I0912 06:18:58.767088 28411 layer_factory.hpp:77] Creating layer conv1_2
I0912 06:18:58.767101 28411 net.cpp:100] Creating Layer conv1_2
I0912 06:18:58.767105 28411 net.cpp:434] conv1_2 <- conv1_1_1
I0912 06:18:58.767112 28411 net.cpp:408] conv1_2 -> conv1_2
I0912 06:18:58.771303 28411 net.cpp:150] Setting up conv1_2
I0912 06:18:58.771320 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:58.771329 28411 net.cpp:165] Memory required for data: 915148800
I0912 06:18:58.771340 28411 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 06:18:58.771353 28411 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 06:18:58.771363 28411 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 06:18:58.771368 28411 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 06:18:58.772895 28411 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 06:18:58.772910 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:58.772918 28411 net.cpp:165] Memory required for data: 1092096000
I0912 06:18:58.772928 28411 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 06:18:58.772938 28411 net.cpp:100] Creating Layer conv1_2_scale
I0912 06:18:58.772944 28411 net.cpp:434] conv1_2_scale <- conv1_2
I0912 06:18:58.772949 28411 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 06:18:58.772992 28411 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 06:18:58.773370 28411 net.cpp:150] Setting up conv1_2_scale
I0912 06:18:58.773380 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:58.773383 28411 net.cpp:165] Memory required for data: 1269043200
I0912 06:18:58.773391 28411 layer_factory.hpp:77] Creating layer relu1_2
I0912 06:18:58.773398 28411 net.cpp:100] Creating Layer relu1_2
I0912 06:18:58.773403 28411 net.cpp:434] relu1_2 <- conv1_2
I0912 06:18:58.773408 28411 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 06:18:58.773607 28411 net.cpp:150] Setting up relu1_2
I0912 06:18:58.773617 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:58.773620 28411 net.cpp:165] Memory required for data: 1445990400
I0912 06:18:58.773624 28411 layer_factory.hpp:77] Creating layer pool1
I0912 06:18:58.773629 28411 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 06:18:58.773636 28411 net.cpp:100] Creating Layer pool1
I0912 06:18:58.773641 28411 net.cpp:434] pool1 <- conv1_2
I0912 06:18:58.773648 28411 net.cpp:408] pool1 -> pool1
I0912 06:18:58.773658 28411 net.cpp:408] pool1 -> pool1_mask
I0912 06:18:58.773711 28411 net.cpp:150] Setting up pool1
I0912 06:18:58.773718 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:18:58.773722 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:18:58.773727 28411 net.cpp:165] Memory required for data: 1534464000
I0912 06:18:58.773730 28411 layer_factory.hpp:77] Creating layer conv2_1
I0912 06:18:58.773739 28411 net.cpp:100] Creating Layer conv2_1
I0912 06:18:58.773744 28411 net.cpp:434] conv2_1 <- pool1
I0912 06:18:58.773751 28411 net.cpp:408] conv2_1 -> conv2_1
I0912 06:18:58.779850 28411 net.cpp:150] Setting up conv2_1
I0912 06:18:58.779866 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:58.779876 28411 net.cpp:165] Memory required for data: 1622937600
I0912 06:18:58.779884 28411 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 06:18:58.779893 28411 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 06:18:58.779902 28411 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 06:18:58.779908 28411 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 06:18:58.780141 28411 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 06:18:58.780149 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:58.780153 28411 net.cpp:165] Memory required for data: 1711411200
I0912 06:18:58.780165 28411 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 06:18:58.780189 28411 net.cpp:100] Creating Layer conv2_1_scale
I0912 06:18:58.780192 28411 net.cpp:434] conv2_1_scale <- conv2_1
I0912 06:18:58.780197 28411 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 06:18:58.780239 28411 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 06:18:58.780416 28411 net.cpp:150] Setting up conv2_1_scale
I0912 06:18:58.780423 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:58.780429 28411 net.cpp:165] Memory required for data: 1799884800
I0912 06:18:58.780436 28411 layer_factory.hpp:77] Creating layer relu2_1
I0912 06:18:58.780443 28411 net.cpp:100] Creating Layer relu2_1
I0912 06:18:58.780447 28411 net.cpp:434] relu2_1 <- conv2_1
I0912 06:18:58.780452 28411 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 06:18:58.781476 28411 net.cpp:150] Setting up relu2_1
I0912 06:18:58.781491 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:58.781497 28411 net.cpp:165] Memory required for data: 1888358400
I0912 06:18:58.781502 28411 layer_factory.hpp:77] Creating layer conv2_2
I0912 06:18:58.781512 28411 net.cpp:100] Creating Layer conv2_2
I0912 06:18:58.781517 28411 net.cpp:434] conv2_2 <- conv2_1
I0912 06:18:58.781523 28411 net.cpp:408] conv2_2 -> conv2_2
I0912 06:18:58.788859 28411 net.cpp:150] Setting up conv2_2
I0912 06:18:58.788875 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:58.788885 28411 net.cpp:165] Memory required for data: 1976832000
I0912 06:18:58.788893 28411 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 06:18:58.788905 28411 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 06:18:58.788913 28411 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 06:18:58.788918 28411 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 06:18:58.789156 28411 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 06:18:58.789165 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:58.789167 28411 net.cpp:165] Memory required for data: 2065305600
I0912 06:18:58.789176 28411 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 06:18:58.789182 28411 net.cpp:100] Creating Layer conv2_2_scale
I0912 06:18:58.789191 28411 net.cpp:434] conv2_2_scale <- conv2_2
I0912 06:18:58.789196 28411 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 06:18:58.789234 28411 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 06:18:58.789418 28411 net.cpp:150] Setting up conv2_2_scale
I0912 06:18:58.789427 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:58.789430 28411 net.cpp:165] Memory required for data: 2153779200
I0912 06:18:58.789438 28411 layer_factory.hpp:77] Creating layer relu2_2
I0912 06:18:58.789444 28411 net.cpp:100] Creating Layer relu2_2
I0912 06:18:58.789449 28411 net.cpp:434] relu2_2 <- conv2_2
I0912 06:18:58.789454 28411 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 06:18:58.789650 28411 net.cpp:150] Setting up relu2_2
I0912 06:18:58.789659 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:58.789665 28411 net.cpp:165] Memory required for data: 2242252800
I0912 06:18:58.789669 28411 layer_factory.hpp:77] Creating layer pool2
I0912 06:18:58.789674 28411 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 06:18:58.789679 28411 net.cpp:100] Creating Layer pool2
I0912 06:18:58.789683 28411 net.cpp:434] pool2 <- conv2_2
I0912 06:18:58.789688 28411 net.cpp:408] pool2 -> pool2
I0912 06:18:58.789697 28411 net.cpp:408] pool2 -> pool2_mask
I0912 06:18:58.789741 28411 net.cpp:150] Setting up pool2
I0912 06:18:58.789747 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:18:58.789752 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:18:58.789754 28411 net.cpp:165] Memory required for data: 2286489600
I0912 06:18:58.789758 28411 layer_factory.hpp:77] Creating layer conv3_1
I0912 06:18:58.789767 28411 net.cpp:100] Creating Layer conv3_1
I0912 06:18:58.789772 28411 net.cpp:434] conv3_1 <- pool2
I0912 06:18:58.789778 28411 net.cpp:408] conv3_1 -> conv3_1
I0912 06:18:58.801939 28411 net.cpp:150] Setting up conv3_1
I0912 06:18:58.801970 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.801978 28411 net.cpp:165] Memory required for data: 2330726400
I0912 06:18:58.801987 28411 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 06:18:58.801996 28411 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 06:18:58.802006 28411 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 06:18:58.802011 28411 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 06:18:58.802232 28411 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 06:18:58.802239 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.802243 28411 net.cpp:165] Memory required for data: 2374963200
I0912 06:18:58.802256 28411 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 06:18:58.802265 28411 net.cpp:100] Creating Layer conv3_1_scale
I0912 06:18:58.802270 28411 net.cpp:434] conv3_1_scale <- conv3_1
I0912 06:18:58.802275 28411 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 06:18:58.802317 28411 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 06:18:58.802453 28411 net.cpp:150] Setting up conv3_1_scale
I0912 06:18:58.802460 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.802464 28411 net.cpp:165] Memory required for data: 2419200000
I0912 06:18:58.802470 28411 layer_factory.hpp:77] Creating layer relu3_1
I0912 06:18:58.802477 28411 net.cpp:100] Creating Layer relu3_1
I0912 06:18:58.802482 28411 net.cpp:434] relu3_1 <- conv3_1
I0912 06:18:58.802487 28411 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 06:18:58.802685 28411 net.cpp:150] Setting up relu3_1
I0912 06:18:58.802695 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.802697 28411 net.cpp:165] Memory required for data: 2463436800
I0912 06:18:58.802702 28411 layer_factory.hpp:77] Creating layer conv3_2
I0912 06:18:58.802713 28411 net.cpp:100] Creating Layer conv3_2
I0912 06:18:58.802718 28411 net.cpp:434] conv3_2 <- conv3_1
I0912 06:18:58.802724 28411 net.cpp:408] conv3_2 -> conv3_2
I0912 06:18:58.825876 28411 net.cpp:150] Setting up conv3_2
I0912 06:18:58.825892 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.825902 28411 net.cpp:165] Memory required for data: 2507673600
I0912 06:18:58.825911 28411 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 06:18:58.825918 28411 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 06:18:58.825922 28411 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 06:18:58.825928 28411 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 06:18:58.826141 28411 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 06:18:58.826149 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.826153 28411 net.cpp:165] Memory required for data: 2551910400
I0912 06:18:58.826161 28411 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 06:18:58.826169 28411 net.cpp:100] Creating Layer conv3_2_scale
I0912 06:18:58.826179 28411 net.cpp:434] conv3_2_scale <- conv3_2
I0912 06:18:58.826184 28411 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 06:18:58.826227 28411 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 06:18:58.826364 28411 net.cpp:150] Setting up conv3_2_scale
I0912 06:18:58.826371 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.826375 28411 net.cpp:165] Memory required for data: 2596147200
I0912 06:18:58.826381 28411 layer_factory.hpp:77] Creating layer relu3_2
I0912 06:18:58.826388 28411 net.cpp:100] Creating Layer relu3_2
I0912 06:18:58.826392 28411 net.cpp:434] relu3_2 <- conv3_2
I0912 06:18:58.826400 28411 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 06:18:58.826601 28411 net.cpp:150] Setting up relu3_2
I0912 06:18:58.826611 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.826614 28411 net.cpp:165] Memory required for data: 2640384000
I0912 06:18:58.826618 28411 layer_factory.hpp:77] Creating layer conv3_3
I0912 06:18:58.826629 28411 net.cpp:100] Creating Layer conv3_3
I0912 06:18:58.826634 28411 net.cpp:434] conv3_3 <- conv3_2
I0912 06:18:58.826642 28411 net.cpp:408] conv3_3 -> conv3_3
I0912 06:18:58.852172 28411 net.cpp:150] Setting up conv3_3
I0912 06:18:58.852205 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.852216 28411 net.cpp:165] Memory required for data: 2684620800
I0912 06:18:58.852228 28411 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 06:18:58.852242 28411 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 06:18:58.852252 28411 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 06:18:58.852263 28411 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 06:18:58.852484 28411 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 06:18:58.852493 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.852496 28411 net.cpp:165] Memory required for data: 2728857600
I0912 06:18:58.852504 28411 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 06:18:58.852514 28411 net.cpp:100] Creating Layer conv3_3_scale
I0912 06:18:58.852520 28411 net.cpp:434] conv3_3_scale <- conv3_3
I0912 06:18:58.852525 28411 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 06:18:58.852566 28411 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 06:18:58.852710 28411 net.cpp:150] Setting up conv3_3_scale
I0912 06:18:58.852717 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.852721 28411 net.cpp:165] Memory required for data: 2773094400
I0912 06:18:58.852728 28411 layer_factory.hpp:77] Creating layer relu3_3
I0912 06:18:58.852735 28411 net.cpp:100] Creating Layer relu3_3
I0912 06:18:58.852741 28411 net.cpp:434] relu3_3 <- conv3_3
I0912 06:18:58.852746 28411 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 06:18:58.852951 28411 net.cpp:150] Setting up relu3_3
I0912 06:18:58.852959 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:58.852964 28411 net.cpp:165] Memory required for data: 2817331200
I0912 06:18:58.852968 28411 layer_factory.hpp:77] Creating layer pool3
I0912 06:18:58.852972 28411 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 06:18:58.852988 28411 net.cpp:100] Creating Layer pool3
I0912 06:18:58.852993 28411 net.cpp:434] pool3 <- conv3_3
I0912 06:18:58.852999 28411 net.cpp:408] pool3 -> pool3
I0912 06:18:58.853008 28411 net.cpp:408] pool3 -> pool3_mask
I0912 06:18:58.853055 28411 net.cpp:150] Setting up pool3
I0912 06:18:58.853063 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:18:58.853068 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:18:58.853072 28411 net.cpp:165] Memory required for data: 2839449600
I0912 06:18:58.853076 28411 layer_factory.hpp:77] Creating layer conv4_1
I0912 06:18:58.853088 28411 net.cpp:100] Creating Layer conv4_1
I0912 06:18:58.853093 28411 net.cpp:434] conv4_1 <- pool3
I0912 06:18:58.853099 28411 net.cpp:408] conv4_1 -> conv4_1
I0912 06:18:58.899008 28411 net.cpp:150] Setting up conv4_1
I0912 06:18:58.899025 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:58.899030 28411 net.cpp:165] Memory required for data: 2861568000
I0912 06:18:58.899039 28411 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 06:18:58.899047 28411 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 06:18:58.899051 28411 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 06:18:58.899057 28411 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 06:18:58.899266 28411 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 06:18:58.899274 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:58.899277 28411 net.cpp:165] Memory required for data: 2883686400
I0912 06:18:58.899286 28411 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 06:18:58.899299 28411 net.cpp:100] Creating Layer conv4_1_scale
I0912 06:18:58.899307 28411 net.cpp:434] conv4_1_scale <- conv4_1
I0912 06:18:58.899312 28411 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 06:18:58.899350 28411 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 06:18:58.899477 28411 net.cpp:150] Setting up conv4_1_scale
I0912 06:18:58.899485 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:58.899488 28411 net.cpp:165] Memory required for data: 2905804800
I0912 06:18:58.899495 28411 layer_factory.hpp:77] Creating layer relu4_1
I0912 06:18:58.899516 28411 net.cpp:100] Creating Layer relu4_1
I0912 06:18:58.899523 28411 net.cpp:434] relu4_1 <- conv4_1
I0912 06:18:58.899528 28411 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 06:18:58.899736 28411 net.cpp:150] Setting up relu4_1
I0912 06:18:58.899745 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:58.899750 28411 net.cpp:165] Memory required for data: 2927923200
I0912 06:18:58.899756 28411 layer_factory.hpp:77] Creating layer conv4_2
I0912 06:18:58.899768 28411 net.cpp:100] Creating Layer conv4_2
I0912 06:18:58.899773 28411 net.cpp:434] conv4_2 <- conv4_1
I0912 06:18:58.899780 28411 net.cpp:408] conv4_2 -> conv4_2
I0912 06:18:58.983043 28411 net.cpp:150] Setting up conv4_2
I0912 06:18:58.983062 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:58.983065 28411 net.cpp:165] Memory required for data: 2950041600
I0912 06:18:58.983073 28411 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 06:18:58.983083 28411 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 06:18:58.983088 28411 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 06:18:58.983094 28411 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 06:18:58.983299 28411 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 06:18:58.983307 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:58.983310 28411 net.cpp:165] Memory required for data: 2972160000
I0912 06:18:58.983319 28411 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 06:18:58.983326 28411 net.cpp:100] Creating Layer conv4_2_scale
I0912 06:18:58.983335 28411 net.cpp:434] conv4_2_scale <- conv4_2
I0912 06:18:58.983340 28411 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 06:18:58.983381 28411 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 06:18:58.983507 28411 net.cpp:150] Setting up conv4_2_scale
I0912 06:18:58.983515 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:58.983518 28411 net.cpp:165] Memory required for data: 2994278400
I0912 06:18:58.983525 28411 layer_factory.hpp:77] Creating layer relu4_2
I0912 06:18:58.983532 28411 net.cpp:100] Creating Layer relu4_2
I0912 06:18:58.983537 28411 net.cpp:434] relu4_2 <- conv4_2
I0912 06:18:58.983542 28411 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 06:18:58.984585 28411 net.cpp:150] Setting up relu4_2
I0912 06:18:58.984598 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:58.984603 28411 net.cpp:165] Memory required for data: 3016396800
I0912 06:18:58.984609 28411 layer_factory.hpp:77] Creating layer conv4_3
I0912 06:18:58.984623 28411 net.cpp:100] Creating Layer conv4_3
I0912 06:18:58.984629 28411 net.cpp:434] conv4_3 <- conv4_2
I0912 06:18:58.984637 28411 net.cpp:408] conv4_3 -> conv4_3
I0912 06:18:59.067903 28411 net.cpp:150] Setting up conv4_3
I0912 06:18:59.067920 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.067925 28411 net.cpp:165] Memory required for data: 3038515200
I0912 06:18:59.067946 28411 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 06:18:59.067958 28411 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 06:18:59.067965 28411 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 06:18:59.067970 28411 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 06:18:59.068186 28411 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 06:18:59.068193 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.068197 28411 net.cpp:165] Memory required for data: 3060633600
I0912 06:18:59.068207 28411 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 06:18:59.068215 28411 net.cpp:100] Creating Layer conv4_3_scale
I0912 06:18:59.068222 28411 net.cpp:434] conv4_3_scale <- conv4_3
I0912 06:18:59.068228 28411 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 06:18:59.068269 28411 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 06:18:59.068398 28411 net.cpp:150] Setting up conv4_3_scale
I0912 06:18:59.068405 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.068409 28411 net.cpp:165] Memory required for data: 3082752000
I0912 06:18:59.068415 28411 layer_factory.hpp:77] Creating layer relu4_3
I0912 06:18:59.068437 28411 net.cpp:100] Creating Layer relu4_3
I0912 06:18:59.068442 28411 net.cpp:434] relu4_3 <- conv4_3
I0912 06:18:59.068449 28411 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 06:18:59.068647 28411 net.cpp:150] Setting up relu4_3
I0912 06:18:59.068656 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.068661 28411 net.cpp:165] Memory required for data: 3104870400
I0912 06:18:59.068667 28411 layer_factory.hpp:77] Creating layer pool4
I0912 06:18:59.068675 28411 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 06:18:59.068681 28411 net.cpp:100] Creating Layer pool4
I0912 06:18:59.068686 28411 net.cpp:434] pool4 <- conv4_3
I0912 06:18:59.068692 28411 net.cpp:408] pool4 -> pool4
I0912 06:18:59.068701 28411 net.cpp:408] pool4 -> pool4_mask
I0912 06:18:59.068750 28411 net.cpp:150] Setting up pool4
I0912 06:18:59.068758 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.068763 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.068766 28411 net.cpp:165] Memory required for data: 3116175360
I0912 06:18:59.068769 28411 layer_factory.hpp:77] Creating layer conv5_1
I0912 06:18:59.068780 28411 net.cpp:100] Creating Layer conv5_1
I0912 06:18:59.068785 28411 net.cpp:434] conv5_1 <- pool4
I0912 06:18:59.068792 28411 net.cpp:408] conv5_1 -> conv5_1
I0912 06:18:59.152112 28411 net.cpp:150] Setting up conv5_1
I0912 06:18:59.152130 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.152134 28411 net.cpp:165] Memory required for data: 3121827840
I0912 06:18:59.152143 28411 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 06:18:59.152150 28411 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 06:18:59.152155 28411 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 06:18:59.152163 28411 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 06:18:59.152375 28411 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 06:18:59.152384 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.152387 28411 net.cpp:165] Memory required for data: 3127480320
I0912 06:18:59.152395 28411 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 06:18:59.152406 28411 net.cpp:100] Creating Layer conv5_1_scale
I0912 06:18:59.152415 28411 net.cpp:434] conv5_1_scale <- conv5_1
I0912 06:18:59.152420 28411 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 06:18:59.152470 28411 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 06:18:59.152590 28411 net.cpp:150] Setting up conv5_1_scale
I0912 06:18:59.152597 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.152601 28411 net.cpp:165] Memory required for data: 3133132800
I0912 06:18:59.152608 28411 layer_factory.hpp:77] Creating layer relu5_1
I0912 06:18:59.152616 28411 net.cpp:100] Creating Layer relu5_1
I0912 06:18:59.152621 28411 net.cpp:434] relu5_1 <- conv5_1
I0912 06:18:59.152626 28411 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 06:18:59.152827 28411 net.cpp:150] Setting up relu5_1
I0912 06:18:59.152835 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.152838 28411 net.cpp:165] Memory required for data: 3138785280
I0912 06:18:59.152842 28411 layer_factory.hpp:77] Creating layer conv5_2
I0912 06:18:59.152854 28411 net.cpp:100] Creating Layer conv5_2
I0912 06:18:59.152859 28411 net.cpp:434] conv5_2 <- conv5_1
I0912 06:18:59.152866 28411 net.cpp:408] conv5_2 -> conv5_2
I0912 06:18:59.236197 28411 net.cpp:150] Setting up conv5_2
I0912 06:18:59.236214 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.236219 28411 net.cpp:165] Memory required for data: 3144437760
I0912 06:18:59.236227 28411 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 06:18:59.236241 28411 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 06:18:59.236248 28411 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 06:18:59.236255 28411 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 06:18:59.236470 28411 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 06:18:59.236479 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.236497 28411 net.cpp:165] Memory required for data: 3150090240
I0912 06:18:59.236506 28411 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 06:18:59.236515 28411 net.cpp:100] Creating Layer conv5_2_scale
I0912 06:18:59.236521 28411 net.cpp:434] conv5_2_scale <- conv5_2
I0912 06:18:59.236526 28411 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 06:18:59.236575 28411 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 06:18:59.236697 28411 net.cpp:150] Setting up conv5_2_scale
I0912 06:18:59.236706 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.236709 28411 net.cpp:165] Memory required for data: 3155742720
I0912 06:18:59.236718 28411 layer_factory.hpp:77] Creating layer relu5_2
I0912 06:18:59.236726 28411 net.cpp:100] Creating Layer relu5_2
I0912 06:18:59.236732 28411 net.cpp:434] relu5_2 <- conv5_2
I0912 06:18:59.236737 28411 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 06:18:59.236934 28411 net.cpp:150] Setting up relu5_2
I0912 06:18:59.236943 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.236948 28411 net.cpp:165] Memory required for data: 3161395200
I0912 06:18:59.236951 28411 layer_factory.hpp:77] Creating layer conv5_3
I0912 06:18:59.236963 28411 net.cpp:100] Creating Layer conv5_3
I0912 06:18:59.236968 28411 net.cpp:434] conv5_3 <- conv5_2
I0912 06:18:59.236975 28411 net.cpp:408] conv5_3 -> conv5_3
I0912 06:18:59.320303 28411 net.cpp:150] Setting up conv5_3
I0912 06:18:59.320322 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.320327 28411 net.cpp:165] Memory required for data: 3167047680
I0912 06:18:59.320334 28411 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 06:18:59.320343 28411 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 06:18:59.320346 28411 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 06:18:59.320354 28411 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 06:18:59.320569 28411 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 06:18:59.320577 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.320581 28411 net.cpp:165] Memory required for data: 3172700160
I0912 06:18:59.320590 28411 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 06:18:59.320598 28411 net.cpp:100] Creating Layer conv5_3_scale
I0912 06:18:59.320605 28411 net.cpp:434] conv5_3_scale <- conv5_3
I0912 06:18:59.320611 28411 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 06:18:59.320662 28411 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 06:18:59.320782 28411 net.cpp:150] Setting up conv5_3_scale
I0912 06:18:59.320791 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.320793 28411 net.cpp:165] Memory required for data: 3178352640
I0912 06:18:59.320802 28411 layer_factory.hpp:77] Creating layer relu5_3
I0912 06:18:59.320811 28411 net.cpp:100] Creating Layer relu5_3
I0912 06:18:59.320816 28411 net.cpp:434] relu5_3 <- conv5_3
I0912 06:18:59.320821 28411 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 06:18:59.321018 28411 net.cpp:150] Setting up relu5_3
I0912 06:18:59.321027 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.321033 28411 net.cpp:165] Memory required for data: 3184005120
I0912 06:18:59.321035 28411 layer_factory.hpp:77] Creating layer pool5
I0912 06:18:59.321043 28411 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 06:18:59.321051 28411 net.cpp:100] Creating Layer pool5
I0912 06:18:59.321056 28411 net.cpp:434] pool5 <- conv5_3
I0912 06:18:59.321063 28411 net.cpp:408] pool5 -> pool5
I0912 06:18:59.321071 28411 net.cpp:408] pool5 -> pool5_mask
I0912 06:18:59.321121 28411 net.cpp:150] Setting up pool5
I0912 06:18:59.321131 28411 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 06:18:59.321137 28411 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 06:18:59.321141 28411 net.cpp:165] Memory required for data: 3186954240
I0912 06:18:59.321144 28411 layer_factory.hpp:77] Creating layer upsample5
I0912 06:18:59.321159 28411 net.cpp:100] Creating Layer upsample5
I0912 06:18:59.321164 28411 net.cpp:434] upsample5 <- pool5
I0912 06:18:59.321185 28411 net.cpp:434] upsample5 <- pool5_mask
I0912 06:18:59.321192 28411 net.cpp:408] upsample5 -> pool5_D
I0912 06:18:59.321229 28411 net.cpp:150] Setting up upsample5
I0912 06:18:59.321236 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.321239 28411 net.cpp:165] Memory required for data: 3192606720
I0912 06:18:59.321243 28411 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 06:18:59.321254 28411 net.cpp:100] Creating Layer conv5_3_D
I0912 06:18:59.321259 28411 net.cpp:434] conv5_3_D <- pool5_D
I0912 06:18:59.321265 28411 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 06:18:59.406061 28411 net.cpp:150] Setting up conv5_3_D
I0912 06:18:59.406082 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.406086 28411 net.cpp:165] Memory required for data: 3198259200
I0912 06:18:59.406098 28411 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 06:18:59.406111 28411 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 06:18:59.406126 28411 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 06:18:59.406136 28411 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 06:18:59.406374 28411 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 06:18:59.406383 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.406385 28411 net.cpp:165] Memory required for data: 3203911680
I0912 06:18:59.406395 28411 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 06:18:59.406404 28411 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 06:18:59.406412 28411 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 06:18:59.406417 28411 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 06:18:59.406466 28411 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 06:18:59.406594 28411 net.cpp:150] Setting up conv5_3_D_scale
I0912 06:18:59.406601 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.406605 28411 net.cpp:165] Memory required for data: 3209564160
I0912 06:18:59.406611 28411 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 06:18:59.406622 28411 net.cpp:100] Creating Layer relu5_3_D
I0912 06:18:59.406627 28411 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 06:18:59.406632 28411 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 06:18:59.406852 28411 net.cpp:150] Setting up relu5_3_D
I0912 06:18:59.406862 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.406867 28411 net.cpp:165] Memory required for data: 3215216640
I0912 06:18:59.406870 28411 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 06:18:59.406916 28411 net.cpp:100] Creating Layer conv5_2_D
I0912 06:18:59.406922 28411 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 06:18:59.406929 28411 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 06:18:59.490295 28411 net.cpp:150] Setting up conv5_2_D
I0912 06:18:59.490312 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.490316 28411 net.cpp:165] Memory required for data: 3220869120
I0912 06:18:59.490324 28411 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 06:18:59.490334 28411 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 06:18:59.490339 28411 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 06:18:59.490344 28411 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 06:18:59.490574 28411 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 06:18:59.490582 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.490586 28411 net.cpp:165] Memory required for data: 3226521600
I0912 06:18:59.490594 28411 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 06:18:59.490602 28411 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 06:18:59.490612 28411 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 06:18:59.490617 28411 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 06:18:59.490665 28411 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 06:18:59.490794 28411 net.cpp:150] Setting up conv5_2_D_scale
I0912 06:18:59.490803 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.490805 28411 net.cpp:165] Memory required for data: 3232174080
I0912 06:18:59.490829 28411 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 06:18:59.490838 28411 net.cpp:100] Creating Layer relu5_2_D
I0912 06:18:59.490842 28411 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 06:18:59.490847 28411 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 06:18:59.491925 28411 net.cpp:150] Setting up relu5_2_D
I0912 06:18:59.491938 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.491943 28411 net.cpp:165] Memory required for data: 3237826560
I0912 06:18:59.491950 28411 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 06:18:59.491964 28411 net.cpp:100] Creating Layer conv5_1_D
I0912 06:18:59.491971 28411 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 06:18:59.491977 28411 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 06:18:59.575458 28411 net.cpp:150] Setting up conv5_1_D
I0912 06:18:59.575474 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.575479 28411 net.cpp:165] Memory required for data: 3243479040
I0912 06:18:59.575486 28411 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 06:18:59.575495 28411 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 06:18:59.575500 28411 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 06:18:59.575506 28411 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 06:18:59.575750 28411 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 06:18:59.575758 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.575762 28411 net.cpp:165] Memory required for data: 3249131520
I0912 06:18:59.575770 28411 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 06:18:59.575783 28411 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 06:18:59.575788 28411 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 06:18:59.575793 28411 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 06:18:59.575845 28411 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 06:18:59.575978 28411 net.cpp:150] Setting up conv5_1_D_scale
I0912 06:18:59.575985 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.575989 28411 net.cpp:165] Memory required for data: 3254784000
I0912 06:18:59.575994 28411 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 06:18:59.576004 28411 net.cpp:100] Creating Layer relu5_1_D
I0912 06:18:59.576009 28411 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 06:18:59.576014 28411 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 06:18:59.576225 28411 net.cpp:150] Setting up relu5_1_D
I0912 06:18:59.576233 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:18:59.576241 28411 net.cpp:165] Memory required for data: 3260436480
I0912 06:18:59.576243 28411 layer_factory.hpp:77] Creating layer upsample4
I0912 06:18:59.576251 28411 net.cpp:100] Creating Layer upsample4
I0912 06:18:59.576256 28411 net.cpp:434] upsample4 <- conv5_1_D
I0912 06:18:59.576262 28411 net.cpp:434] upsample4 <- pool4_mask
I0912 06:18:59.576268 28411 net.cpp:408] upsample4 -> pool4_D
I0912 06:18:59.576303 28411 net.cpp:150] Setting up upsample4
I0912 06:18:59.576308 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.576311 28411 net.cpp:165] Memory required for data: 3282554880
I0912 06:18:59.576316 28411 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 06:18:59.576329 28411 net.cpp:100] Creating Layer conv4_3_D
I0912 06:18:59.576334 28411 net.cpp:434] conv4_3_D <- pool4_D
I0912 06:18:59.576341 28411 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 06:18:59.659657 28411 net.cpp:150] Setting up conv4_3_D
I0912 06:18:59.659675 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.659678 28411 net.cpp:165] Memory required for data: 3304673280
I0912 06:18:59.659687 28411 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 06:18:59.659696 28411 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 06:18:59.659700 28411 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 06:18:59.659708 28411 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 06:18:59.659948 28411 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 06:18:59.659957 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.659978 28411 net.cpp:165] Memory required for data: 3326791680
I0912 06:18:59.659987 28411 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 06:18:59.659998 28411 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 06:18:59.660004 28411 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 06:18:59.660009 28411 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 06:18:59.660058 28411 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 06:18:59.660204 28411 net.cpp:150] Setting up conv4_3_D_scale
I0912 06:18:59.660212 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.660215 28411 net.cpp:165] Memory required for data: 3348910080
I0912 06:18:59.660221 28411 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 06:18:59.660229 28411 net.cpp:100] Creating Layer relu4_3_D
I0912 06:18:59.660235 28411 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 06:18:59.660241 28411 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 06:18:59.660446 28411 net.cpp:150] Setting up relu4_3_D
I0912 06:18:59.660455 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.660459 28411 net.cpp:165] Memory required for data: 3371028480
I0912 06:18:59.660462 28411 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 06:18:59.660476 28411 net.cpp:100] Creating Layer conv4_2_D
I0912 06:18:59.660481 28411 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 06:18:59.660490 28411 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 06:18:59.743804 28411 net.cpp:150] Setting up conv4_2_D
I0912 06:18:59.743821 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.743825 28411 net.cpp:165] Memory required for data: 3393146880
I0912 06:18:59.743834 28411 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 06:18:59.743842 28411 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 06:18:59.743850 28411 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 06:18:59.743856 28411 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 06:18:59.744103 28411 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 06:18:59.744112 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.744114 28411 net.cpp:165] Memory required for data: 3415265280
I0912 06:18:59.744124 28411 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 06:18:59.744134 28411 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 06:18:59.744144 28411 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 06:18:59.744149 28411 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 06:18:59.744191 28411 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 06:18:59.744338 28411 net.cpp:150] Setting up conv4_2_D_scale
I0912 06:18:59.744344 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.744348 28411 net.cpp:165] Memory required for data: 3437383680
I0912 06:18:59.744354 28411 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 06:18:59.744365 28411 net.cpp:100] Creating Layer relu4_2_D
I0912 06:18:59.744370 28411 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 06:18:59.744374 28411 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 06:18:59.744582 28411 net.cpp:150] Setting up relu4_2_D
I0912 06:18:59.744591 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:18:59.744595 28411 net.cpp:165] Memory required for data: 3459502080
I0912 06:18:59.744598 28411 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 06:18:59.744611 28411 net.cpp:100] Creating Layer conv4_1_D
I0912 06:18:59.744616 28411 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 06:18:59.744622 28411 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 06:18:59.788305 28411 net.cpp:150] Setting up conv4_1_D
I0912 06:18:59.788321 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:18:59.788331 28411 net.cpp:165] Memory required for data: 3470561280
I0912 06:18:59.788339 28411 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 06:18:59.788352 28411 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 06:18:59.788357 28411 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 06:18:59.788363 28411 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 06:18:59.788607 28411 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 06:18:59.788630 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:18:59.788640 28411 net.cpp:165] Memory required for data: 3481620480
I0912 06:18:59.788697 28411 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 06:18:59.788708 28411 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 06:18:59.788713 28411 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 06:18:59.788719 28411 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 06:18:59.788772 28411 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 06:18:59.788913 28411 net.cpp:150] Setting up conv4_1_D_scale
I0912 06:18:59.788920 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:18:59.788923 28411 net.cpp:165] Memory required for data: 3492679680
I0912 06:18:59.788929 28411 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 06:18:59.788938 28411 net.cpp:100] Creating Layer relu4_1_D
I0912 06:18:59.788942 28411 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 06:18:59.788947 28411 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 06:18:59.789175 28411 net.cpp:150] Setting up relu4_1_D
I0912 06:18:59.789185 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:18:59.789188 28411 net.cpp:165] Memory required for data: 3503738880
I0912 06:18:59.789192 28411 layer_factory.hpp:77] Creating layer upsample3
I0912 06:18:59.789199 28411 net.cpp:100] Creating Layer upsample3
I0912 06:18:59.789204 28411 net.cpp:434] upsample3 <- conv4_1_D
I0912 06:18:59.789209 28411 net.cpp:434] upsample3 <- pool3_mask
I0912 06:18:59.789216 28411 net.cpp:408] upsample3 -> pool3_D
I0912 06:18:59.789225 28411 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 06:18:59.789258 28411 net.cpp:150] Setting up upsample3
I0912 06:18:59.789265 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.789269 28411 net.cpp:165] Memory required for data: 3547975680
I0912 06:18:59.789274 28411 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 06:18:59.789286 28411 net.cpp:100] Creating Layer conv3_3_D
I0912 06:18:59.789291 28411 net.cpp:434] conv3_3_D <- pool3_D
I0912 06:18:59.789297 28411 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 06:18:59.812666 28411 net.cpp:150] Setting up conv3_3_D
I0912 06:18:59.812683 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.812692 28411 net.cpp:165] Memory required for data: 3592212480
I0912 06:18:59.812702 28411 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 06:18:59.812711 28411 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 06:18:59.812721 28411 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 06:18:59.812726 28411 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 06:18:59.812996 28411 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 06:18:59.813004 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.813007 28411 net.cpp:165] Memory required for data: 3636449280
I0912 06:18:59.813019 28411 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 06:18:59.813029 28411 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 06:18:59.813033 28411 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 06:18:59.813038 28411 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 06:18:59.813087 28411 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 06:18:59.813259 28411 net.cpp:150] Setting up conv3_3_D_scale
I0912 06:18:59.813267 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.813271 28411 net.cpp:165] Memory required for data: 3680686080
I0912 06:18:59.813277 28411 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 06:18:59.813287 28411 net.cpp:100] Creating Layer relu3_3_D
I0912 06:18:59.813290 28411 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 06:18:59.813297 28411 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 06:18:59.813524 28411 net.cpp:150] Setting up relu3_3_D
I0912 06:18:59.813534 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.813537 28411 net.cpp:165] Memory required for data: 3724922880
I0912 06:18:59.813555 28411 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 06:18:59.813570 28411 net.cpp:100] Creating Layer conv3_2_D
I0912 06:18:59.813575 28411 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 06:18:59.813583 28411 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 06:18:59.836954 28411 net.cpp:150] Setting up conv3_2_D
I0912 06:18:59.836971 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.836982 28411 net.cpp:165] Memory required for data: 3769159680
I0912 06:18:59.836989 28411 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 06:18:59.837002 28411 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 06:18:59.837009 28411 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 06:18:59.837015 28411 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 06:18:59.837277 28411 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 06:18:59.837285 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.837288 28411 net.cpp:165] Memory required for data: 3813396480
I0912 06:18:59.837298 28411 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 06:18:59.837307 28411 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 06:18:59.837316 28411 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 06:18:59.837321 28411 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 06:18:59.837373 28411 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 06:18:59.837548 28411 net.cpp:150] Setting up conv3_2_D_scale
I0912 06:18:59.837556 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.837559 28411 net.cpp:165] Memory required for data: 3857633280
I0912 06:18:59.837565 28411 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 06:18:59.837574 28411 net.cpp:100] Creating Layer relu3_2_D
I0912 06:18:59.837579 28411 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 06:18:59.837584 28411 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 06:18:59.838673 28411 net.cpp:150] Setting up relu3_2_D
I0912 06:18:59.838687 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.838692 28411 net.cpp:165] Memory required for data: 3901870080
I0912 06:18:59.838696 28411 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 06:18:59.838709 28411 net.cpp:100] Creating Layer conv3_1_D
I0912 06:18:59.838714 28411 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 06:18:59.838723 28411 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 06:18:59.854220 28411 net.cpp:150] Setting up conv3_1_D
I0912 06:18:59.854239 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:18:59.854250 28411 net.cpp:165] Memory required for data: 3923988480
I0912 06:18:59.854262 28411 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 06:18:59.854274 28411 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 06:18:59.854285 28411 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 06:18:59.854293 28411 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 06:18:59.854569 28411 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 06:18:59.854578 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:18:59.854580 28411 net.cpp:165] Memory required for data: 3946106880
I0912 06:18:59.854590 28411 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 06:18:59.854600 28411 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 06:18:59.854605 28411 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 06:18:59.854611 28411 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 06:18:59.854660 28411 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 06:18:59.854840 28411 net.cpp:150] Setting up conv3_1_D_scale
I0912 06:18:59.854846 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:18:59.854849 28411 net.cpp:165] Memory required for data: 3968225280
I0912 06:18:59.854856 28411 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 06:18:59.854863 28411 net.cpp:100] Creating Layer relu3_1_D
I0912 06:18:59.854868 28411 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 06:18:59.854874 28411 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 06:18:59.855108 28411 net.cpp:150] Setting up relu3_1_D
I0912 06:18:59.855131 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:18:59.855136 28411 net.cpp:165] Memory required for data: 3990343680
I0912 06:18:59.855140 28411 layer_factory.hpp:77] Creating layer upsample2
I0912 06:18:59.855149 28411 net.cpp:100] Creating Layer upsample2
I0912 06:18:59.855154 28411 net.cpp:434] upsample2 <- conv3_1_D
I0912 06:18:59.855160 28411 net.cpp:434] upsample2 <- pool2_mask
I0912 06:18:59.855170 28411 net.cpp:408] upsample2 -> pool2_D
I0912 06:18:59.855177 28411 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 06:18:59.855209 28411 net.cpp:150] Setting up upsample2
I0912 06:18:59.855216 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.855219 28411 net.cpp:165] Memory required for data: 4078817280
I0912 06:18:59.855222 28411 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 06:18:59.855237 28411 net.cpp:100] Creating Layer conv2_2_D
I0912 06:18:59.855242 28411 net.cpp:434] conv2_2_D <- pool2_D
I0912 06:18:59.855248 28411 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 06:18:59.862910 28411 net.cpp:150] Setting up conv2_2_D
I0912 06:18:59.862927 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.862936 28411 net.cpp:165] Memory required for data: 4167290880
I0912 06:18:59.862946 28411 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 06:18:59.862957 28411 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 06:18:59.862963 28411 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 06:18:59.862968 28411 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 06:18:59.863284 28411 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 06:18:59.863293 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.863297 28411 net.cpp:165] Memory required for data: 4255764480
I0912 06:18:59.863307 28411 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 06:18:59.863317 28411 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 06:18:59.863322 28411 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 06:18:59.863327 28411 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 06:18:59.863379 28411 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 06:18:59.864816 28411 net.cpp:150] Setting up conv2_2_D_scale
I0912 06:18:59.864831 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.864838 28411 net.cpp:165] Memory required for data: 4344238080
I0912 06:18:59.864846 28411 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 06:18:59.864855 28411 net.cpp:100] Creating Layer relu2_2_D
I0912 06:18:59.864859 28411 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 06:18:59.864864 28411 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 06:18:59.865101 28411 net.cpp:150] Setting up relu2_2_D
I0912 06:18:59.865113 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.865118 28411 net.cpp:165] Memory required for data: 4432711680
I0912 06:18:59.865121 28411 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 06:18:59.865135 28411 net.cpp:100] Creating Layer conv2_1_D
I0912 06:18:59.865140 28411 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 06:18:59.865149 28411 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 06:18:59.870399 28411 net.cpp:150] Setting up conv2_1_D
I0912 06:18:59.870415 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:18:59.870424 28411 net.cpp:165] Memory required for data: 4476948480
I0912 06:18:59.870434 28411 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 06:18:59.870445 28411 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 06:18:59.870450 28411 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 06:18:59.870456 28411 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 06:18:59.870766 28411 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 06:18:59.870775 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:18:59.870779 28411 net.cpp:165] Memory required for data: 4521185280
I0912 06:18:59.870787 28411 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 06:18:59.870808 28411 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 06:18:59.870813 28411 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 06:18:59.870818 28411 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 06:18:59.870877 28411 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 06:18:59.871100 28411 net.cpp:150] Setting up conv2_1_D_scale
I0912 06:18:59.871110 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:18:59.871115 28411 net.cpp:165] Memory required for data: 4565422080
I0912 06:18:59.871122 28411 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 06:18:59.871130 28411 net.cpp:100] Creating Layer relu2_1_D
I0912 06:18:59.871135 28411 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 06:18:59.871140 28411 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 06:18:59.871372 28411 net.cpp:150] Setting up relu2_1_D
I0912 06:18:59.871383 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:18:59.871388 28411 net.cpp:165] Memory required for data: 4609658880
I0912 06:18:59.871392 28411 layer_factory.hpp:77] Creating layer upsample1
I0912 06:18:59.871398 28411 net.cpp:100] Creating Layer upsample1
I0912 06:18:59.871402 28411 net.cpp:434] upsample1 <- conv2_1_D
I0912 06:18:59.871407 28411 net.cpp:434] upsample1 <- pool1_mask
I0912 06:18:59.871414 28411 net.cpp:408] upsample1 -> pool1_D
I0912 06:18:59.871421 28411 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 06:18:59.871454 28411 net.cpp:150] Setting up upsample1
I0912 06:18:59.871461 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.871464 28411 net.cpp:165] Memory required for data: 4786606080
I0912 06:18:59.871469 28411 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 06:18:59.871481 28411 net.cpp:100] Creating Layer conv1_2_D
I0912 06:18:59.871486 28411 net.cpp:434] conv1_2_D <- pool1_D
I0912 06:18:59.871493 28411 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 06:18:59.875988 28411 net.cpp:150] Setting up conv1_2_D
I0912 06:18:59.876004 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.876013 28411 net.cpp:165] Memory required for data: 4963553280
I0912 06:18:59.876021 28411 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 06:18:59.876034 28411 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 06:18:59.876039 28411 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 06:18:59.876046 28411 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 06:18:59.876453 28411 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 06:18:59.876461 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.876464 28411 net.cpp:165] Memory required for data: 5140500480
I0912 06:18:59.876472 28411 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 06:18:59.876482 28411 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 06:18:59.876487 28411 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 06:18:59.876492 28411 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 06:18:59.876543 28411 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 06:18:59.878195 28411 net.cpp:150] Setting up conv1_2_D_scale
I0912 06:18:59.878208 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.878213 28411 net.cpp:165] Memory required for data: 5317447680
I0912 06:18:59.878221 28411 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 06:18:59.878232 28411 net.cpp:100] Creating Layer relu1_2_D
I0912 06:18:59.878237 28411 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 06:18:59.878242 28411 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 06:18:59.878478 28411 net.cpp:150] Setting up relu1_2_D
I0912 06:18:59.878486 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.878494 28411 net.cpp:165] Memory required for data: 5494394880
I0912 06:18:59.878499 28411 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 06:18:59.878510 28411 net.cpp:100] Creating Layer conv1_1_1_D
I0912 06:18:59.878515 28411 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 06:18:59.878538 28411 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 06:18:59.880620 28411 net.cpp:150] Setting up conv1_1_1_D
I0912 06:18:59.880638 28411 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 06:18:59.880643 28411 net.cpp:165] Memory required for data: 5499924480
I0912 06:18:59.880651 28411 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 06:18:59.880659 28411 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 06:18:59.880664 28411 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 06:18:59.880671 28411 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 06:18:59.880679 28411 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 06:18:59.880735 28411 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 06:18:59.880743 28411 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 06:18:59.880746 28411 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 06:18:59.880750 28411 net.cpp:165] Memory required for data: 5510983680
I0912 06:18:59.880754 28411 layer_factory.hpp:77] Creating layer loss
I0912 06:18:59.880769 28411 net.cpp:100] Creating Layer loss
I0912 06:18:59.880774 28411 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 06:18:59.880779 28411 net.cpp:434] loss <- label_data_1_split_0
I0912 06:18:59.880785 28411 net.cpp:408] loss -> loss
I0912 06:18:59.880805 28411 layer_factory.hpp:77] Creating layer loss
I0912 06:18:59.884789 28411 net.cpp:150] Setting up loss
I0912 06:18:59.884804 28411 net.cpp:157] Top shape: (1)
I0912 06:18:59.884807 28411 net.cpp:160]     with loss weight 1
I0912 06:18:59.884846 28411 net.cpp:165] Memory required for data: 5510983684
I0912 06:18:59.884850 28411 layer_factory.hpp:77] Creating layer accuracy
I0912 06:18:59.884860 28411 net.cpp:100] Creating Layer accuracy
I0912 06:18:59.884865 28411 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 06:18:59.884871 28411 net.cpp:434] accuracy <- label_data_1_split_1
I0912 06:18:59.884877 28411 net.cpp:408] accuracy -> accuracy
I0912 06:18:59.884886 28411 net.cpp:408] accuracy -> per_class_accuracy
I0912 06:18:59.884941 28411 net.cpp:150] Setting up accuracy
I0912 06:18:59.884948 28411 net.cpp:157] Top shape: (1)
I0912 06:18:59.884953 28411 net.cpp:157] Top shape: 2 (2)
I0912 06:18:59.884956 28411 net.cpp:165] Memory required for data: 5510983696
I0912 06:18:59.884960 28411 net.cpp:228] accuracy does not need backward computation.
I0912 06:18:59.884964 28411 net.cpp:226] loss needs backward computation.
I0912 06:18:59.884968 28411 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 06:18:59.884974 28411 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 06:18:59.884977 28411 net.cpp:226] relu1_2_D needs backward computation.
I0912 06:18:59.884980 28411 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 06:18:59.884984 28411 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 06:18:59.884985 28411 net.cpp:226] conv1_2_D needs backward computation.
I0912 06:18:59.884989 28411 net.cpp:226] upsample1 needs backward computation.
I0912 06:18:59.884992 28411 net.cpp:226] relu2_1_D needs backward computation.
I0912 06:18:59.884995 28411 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 06:18:59.884999 28411 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 06:18:59.885001 28411 net.cpp:226] conv2_1_D needs backward computation.
I0912 06:18:59.885004 28411 net.cpp:226] relu2_2_D needs backward computation.
I0912 06:18:59.885007 28411 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 06:18:59.885010 28411 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 06:18:59.885013 28411 net.cpp:226] conv2_2_D needs backward computation.
I0912 06:18:59.885016 28411 net.cpp:226] upsample2 needs backward computation.
I0912 06:18:59.885020 28411 net.cpp:226] relu3_1_D needs backward computation.
I0912 06:18:59.885023 28411 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 06:18:59.885040 28411 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 06:18:59.885043 28411 net.cpp:226] conv3_1_D needs backward computation.
I0912 06:18:59.885048 28411 net.cpp:226] relu3_2_D needs backward computation.
I0912 06:18:59.885051 28411 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 06:18:59.885054 28411 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 06:18:59.885056 28411 net.cpp:226] conv3_2_D needs backward computation.
I0912 06:18:59.885062 28411 net.cpp:226] relu3_3_D needs backward computation.
I0912 06:18:59.885067 28411 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 06:18:59.885069 28411 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 06:18:59.885072 28411 net.cpp:226] conv3_3_D needs backward computation.
I0912 06:18:59.885076 28411 net.cpp:226] upsample3 needs backward computation.
I0912 06:18:59.885080 28411 net.cpp:226] relu4_1_D needs backward computation.
I0912 06:18:59.885083 28411 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 06:18:59.885087 28411 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 06:18:59.885089 28411 net.cpp:226] conv4_1_D needs backward computation.
I0912 06:18:59.885093 28411 net.cpp:226] relu4_2_D needs backward computation.
I0912 06:18:59.885099 28411 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 06:18:59.885102 28411 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 06:18:59.885105 28411 net.cpp:226] conv4_2_D needs backward computation.
I0912 06:18:59.885109 28411 net.cpp:226] relu4_3_D needs backward computation.
I0912 06:18:59.885113 28411 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 06:18:59.885115 28411 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 06:18:59.885118 28411 net.cpp:226] conv4_3_D needs backward computation.
I0912 06:18:59.885123 28411 net.cpp:226] upsample4 needs backward computation.
I0912 06:18:59.885128 28411 net.cpp:226] relu5_1_D needs backward computation.
I0912 06:18:59.885133 28411 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 06:18:59.885135 28411 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 06:18:59.885138 28411 net.cpp:226] conv5_1_D needs backward computation.
I0912 06:18:59.885143 28411 net.cpp:226] relu5_2_D needs backward computation.
I0912 06:18:59.885148 28411 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 06:18:59.885151 28411 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 06:18:59.885155 28411 net.cpp:226] conv5_2_D needs backward computation.
I0912 06:18:59.885159 28411 net.cpp:226] relu5_3_D needs backward computation.
I0912 06:18:59.885162 28411 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 06:18:59.885165 28411 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 06:18:59.885169 28411 net.cpp:226] conv5_3_D needs backward computation.
I0912 06:18:59.885172 28411 net.cpp:226] upsample5 needs backward computation.
I0912 06:18:59.885179 28411 net.cpp:226] pool5 needs backward computation.
I0912 06:18:59.885184 28411 net.cpp:226] relu5_3 needs backward computation.
I0912 06:18:59.885187 28411 net.cpp:226] conv5_3_scale needs backward computation.
I0912 06:18:59.885191 28411 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 06:18:59.885195 28411 net.cpp:226] conv5_3 needs backward computation.
I0912 06:18:59.885198 28411 net.cpp:226] relu5_2 needs backward computation.
I0912 06:18:59.885203 28411 net.cpp:226] conv5_2_scale needs backward computation.
I0912 06:18:59.885206 28411 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 06:18:59.885210 28411 net.cpp:226] conv5_2 needs backward computation.
I0912 06:18:59.885213 28411 net.cpp:226] relu5_1 needs backward computation.
I0912 06:18:59.885216 28411 net.cpp:226] conv5_1_scale needs backward computation.
I0912 06:18:59.885220 28411 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 06:18:59.885222 28411 net.cpp:226] conv5_1 needs backward computation.
I0912 06:18:59.885227 28411 net.cpp:226] pool4 needs backward computation.
I0912 06:18:59.885238 28411 net.cpp:226] relu4_3 needs backward computation.
I0912 06:18:59.885242 28411 net.cpp:226] conv4_3_scale needs backward computation.
I0912 06:18:59.885247 28411 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 06:18:59.885251 28411 net.cpp:226] conv4_3 needs backward computation.
I0912 06:18:59.885254 28411 net.cpp:226] relu4_2 needs backward computation.
I0912 06:18:59.885257 28411 net.cpp:226] conv4_2_scale needs backward computation.
I0912 06:18:59.885260 28411 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 06:18:59.885263 28411 net.cpp:226] conv4_2 needs backward computation.
I0912 06:18:59.885267 28411 net.cpp:226] relu4_1 needs backward computation.
I0912 06:18:59.885270 28411 net.cpp:226] conv4_1_scale needs backward computation.
I0912 06:18:59.885274 28411 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 06:18:59.885277 28411 net.cpp:226] conv4_1 needs backward computation.
I0912 06:18:59.885282 28411 net.cpp:226] pool3 needs backward computation.
I0912 06:18:59.885287 28411 net.cpp:226] relu3_3 needs backward computation.
I0912 06:18:59.885289 28411 net.cpp:226] conv3_3_scale needs backward computation.
I0912 06:18:59.885293 28411 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 06:18:59.885299 28411 net.cpp:226] conv3_3 needs backward computation.
I0912 06:18:59.885303 28411 net.cpp:226] relu3_2 needs backward computation.
I0912 06:18:59.885306 28411 net.cpp:226] conv3_2_scale needs backward computation.
I0912 06:18:59.885309 28411 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 06:18:59.885314 28411 net.cpp:226] conv3_2 needs backward computation.
I0912 06:18:59.885318 28411 net.cpp:226] relu3_1 needs backward computation.
I0912 06:18:59.885321 28411 net.cpp:226] conv3_1_scale needs backward computation.
I0912 06:18:59.885324 28411 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 06:18:59.885329 28411 net.cpp:226] conv3_1 needs backward computation.
I0912 06:18:59.885331 28411 net.cpp:226] pool2 needs backward computation.
I0912 06:18:59.885336 28411 net.cpp:226] relu2_2 needs backward computation.
I0912 06:18:59.885339 28411 net.cpp:226] conv2_2_scale needs backward computation.
I0912 06:18:59.885344 28411 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 06:18:59.885347 28411 net.cpp:226] conv2_2 needs backward computation.
I0912 06:18:59.885350 28411 net.cpp:226] relu2_1 needs backward computation.
I0912 06:18:59.885354 28411 net.cpp:226] conv2_1_scale needs backward computation.
I0912 06:18:59.885356 28411 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 06:18:59.885360 28411 net.cpp:226] conv2_1 needs backward computation.
I0912 06:18:59.885363 28411 net.cpp:226] pool1 needs backward computation.
I0912 06:18:59.885372 28411 net.cpp:226] relu1_2 needs backward computation.
I0912 06:18:59.885377 28411 net.cpp:226] conv1_2_scale needs backward computation.
I0912 06:18:59.885380 28411 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 06:18:59.885383 28411 net.cpp:226] conv1_2 needs backward computation.
I0912 06:18:59.885387 28411 net.cpp:226] relu1_1 needs backward computation.
I0912 06:18:59.885390 28411 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 06:18:59.885393 28411 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 06:18:59.885396 28411 net.cpp:226] conv1_1_1 needs backward computation.
I0912 06:18:59.885401 28411 net.cpp:228] label_data_1_split does not need backward computation.
I0912 06:18:59.885407 28411 net.cpp:228] data does not need backward computation.
I0912 06:18:59.885414 28411 net.cpp:270] This network produces output accuracy
I0912 06:18:59.885417 28411 net.cpp:270] This network produces output loss
I0912 06:18:59.885426 28411 net.cpp:270] This network produces output per_class_accuracy
I0912 06:18:59.885493 28411 net.cpp:283] Network initialization done.
I0912 06:18:59.887836 28411 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/train.prototxt
I0912 06:18:59.888523 28411 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0912 06:18:59.888933 28411 layer_factory.hpp:77] Creating layer data
I0912 06:18:59.888947 28411 net.cpp:100] Creating Layer data
I0912 06:18:59.888952 28411 net.cpp:408] data -> data
I0912 06:18:59.888960 28411 net.cpp:408] data -> label
I0912 06:18:59.888969 28411 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt
I0912 06:18:59.889009 28411 hdf5_data_layer.cpp:93] Number of HDF5 files: 29
I0912 06:18:59.899121 28411 net.cpp:150] Setting up data
I0912 06:18:59.899138 28411 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0912 06:18:59.899144 28411 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 06:18:59.899148 28411 net.cpp:165] Memory required for data: 24883200
I0912 06:18:59.899153 28411 layer_factory.hpp:77] Creating layer label_data_1_split
I0912 06:18:59.899163 28411 net.cpp:100] Creating Layer label_data_1_split
I0912 06:18:59.899173 28411 net.cpp:434] label_data_1_split <- label
I0912 06:18:59.899179 28411 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0912 06:18:59.899193 28411 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0912 06:18:59.899242 28411 net.cpp:150] Setting up label_data_1_split
I0912 06:18:59.899250 28411 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 06:18:59.899255 28411 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0912 06:18:59.899258 28411 net.cpp:165] Memory required for data: 30412800
I0912 06:18:59.899261 28411 layer_factory.hpp:77] Creating layer conv1_1_1
I0912 06:18:59.899271 28411 net.cpp:100] Creating Layer conv1_1_1
I0912 06:18:59.899276 28411 net.cpp:434] conv1_1_1 <- data
I0912 06:18:59.899281 28411 net.cpp:408] conv1_1_1 -> conv1_1_1
I0912 06:18:59.902752 28411 net.cpp:150] Setting up conv1_1_1
I0912 06:18:59.902770 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.902778 28411 net.cpp:165] Memory required for data: 207360000
I0912 06:18:59.902791 28411 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0912 06:18:59.902799 28411 net.cpp:100] Creating Layer conv1_1_1_bn
I0912 06:18:59.902807 28411 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0912 06:18:59.902812 28411 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0912 06:18:59.903211 28411 net.cpp:150] Setting up conv1_1_1_bn
I0912 06:18:59.903220 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.903223 28411 net.cpp:165] Memory required for data: 384307200
I0912 06:18:59.903236 28411 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 06:18:59.903244 28411 net.cpp:100] Creating Layer conv1_1_1_scale
I0912 06:18:59.903249 28411 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0912 06:18:59.903254 28411 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0912 06:18:59.903304 28411 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0912 06:18:59.904956 28411 net.cpp:150] Setting up conv1_1_1_scale
I0912 06:18:59.904971 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.904976 28411 net.cpp:165] Memory required for data: 561254400
I0912 06:18:59.904984 28411 layer_factory.hpp:77] Creating layer relu1_1
I0912 06:18:59.904992 28411 net.cpp:100] Creating Layer relu1_1
I0912 06:18:59.904997 28411 net.cpp:434] relu1_1 <- conv1_1_1
I0912 06:18:59.905004 28411 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0912 06:18:59.905226 28411 net.cpp:150] Setting up relu1_1
I0912 06:18:59.905236 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.905241 28411 net.cpp:165] Memory required for data: 738201600
I0912 06:18:59.905244 28411 layer_factory.hpp:77] Creating layer conv1_2
I0912 06:18:59.905253 28411 net.cpp:100] Creating Layer conv1_2
I0912 06:18:59.905258 28411 net.cpp:434] conv1_2 <- conv1_1_1
I0912 06:18:59.905264 28411 net.cpp:408] conv1_2 -> conv1_2
I0912 06:18:59.909370 28411 net.cpp:150] Setting up conv1_2
I0912 06:18:59.909386 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.909395 28411 net.cpp:165] Memory required for data: 915148800
I0912 06:18:59.909422 28411 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0912 06:18:59.909433 28411 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0912 06:18:59.909438 28411 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0912 06:18:59.909445 28411 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0912 06:18:59.909832 28411 net.cpp:150] Setting up conv1_2_bn_tmp
I0912 06:18:59.909840 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.909844 28411 net.cpp:165] Memory required for data: 1092096000
I0912 06:18:59.909852 28411 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 06:18:59.909862 28411 net.cpp:100] Creating Layer conv1_2_scale
I0912 06:18:59.909865 28411 net.cpp:434] conv1_2_scale <- conv1_2
I0912 06:18:59.909870 28411 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0912 06:18:59.909920 28411 layer_factory.hpp:77] Creating layer conv1_2_scale
I0912 06:18:59.911578 28411 net.cpp:150] Setting up conv1_2_scale
I0912 06:18:59.911593 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.911598 28411 net.cpp:165] Memory required for data: 1269043200
I0912 06:18:59.911605 28411 layer_factory.hpp:77] Creating layer relu1_2
I0912 06:18:59.911613 28411 net.cpp:100] Creating Layer relu1_2
I0912 06:18:59.911618 28411 net.cpp:434] relu1_2 <- conv1_2
I0912 06:18:59.911624 28411 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0912 06:18:59.912747 28411 net.cpp:150] Setting up relu1_2
I0912 06:18:59.912762 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:18:59.912767 28411 net.cpp:165] Memory required for data: 1445990400
I0912 06:18:59.912771 28411 layer_factory.hpp:77] Creating layer pool1
I0912 06:18:59.912776 28411 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 06:18:59.912782 28411 net.cpp:100] Creating Layer pool1
I0912 06:18:59.912787 28411 net.cpp:434] pool1 <- conv1_2
I0912 06:18:59.912793 28411 net.cpp:408] pool1 -> pool1
I0912 06:18:59.912802 28411 net.cpp:408] pool1 -> pool1_mask
I0912 06:18:59.912863 28411 net.cpp:150] Setting up pool1
I0912 06:18:59.912869 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:18:59.912874 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:18:59.912879 28411 net.cpp:165] Memory required for data: 1534464000
I0912 06:18:59.912883 28411 layer_factory.hpp:77] Creating layer conv2_1
I0912 06:18:59.912894 28411 net.cpp:100] Creating Layer conv2_1
I0912 06:18:59.912899 28411 net.cpp:434] conv2_1 <- pool1
I0912 06:18:59.912905 28411 net.cpp:408] conv2_1 -> conv2_1
I0912 06:18:59.917249 28411 net.cpp:150] Setting up conv2_1
I0912 06:18:59.917268 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.917274 28411 net.cpp:165] Memory required for data: 1622937600
I0912 06:18:59.917282 28411 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0912 06:18:59.917290 28411 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0912 06:18:59.917299 28411 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0912 06:18:59.917307 28411 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0912 06:18:59.917634 28411 net.cpp:150] Setting up conv2_1_bn_tmp
I0912 06:18:59.917642 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.917646 28411 net.cpp:165] Memory required for data: 1711411200
I0912 06:18:59.917659 28411 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 06:18:59.917665 28411 net.cpp:100] Creating Layer conv2_1_scale
I0912 06:18:59.917671 28411 net.cpp:434] conv2_1_scale <- conv2_1
I0912 06:18:59.917678 28411 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0912 06:18:59.917729 28411 layer_factory.hpp:77] Creating layer conv2_1_scale
I0912 06:18:59.917968 28411 net.cpp:150] Setting up conv2_1_scale
I0912 06:18:59.917976 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.917980 28411 net.cpp:165] Memory required for data: 1799884800
I0912 06:18:59.917986 28411 layer_factory.hpp:77] Creating layer relu2_1
I0912 06:18:59.917995 28411 net.cpp:100] Creating Layer relu2_1
I0912 06:18:59.918000 28411 net.cpp:434] relu2_1 <- conv2_1
I0912 06:18:59.918004 28411 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0912 06:18:59.919139 28411 net.cpp:150] Setting up relu2_1
I0912 06:18:59.919154 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.919159 28411 net.cpp:165] Memory required for data: 1888358400
I0912 06:18:59.919163 28411 layer_factory.hpp:77] Creating layer conv2_2
I0912 06:18:59.919178 28411 net.cpp:100] Creating Layer conv2_2
I0912 06:18:59.919183 28411 net.cpp:434] conv2_2 <- conv2_1
I0912 06:18:59.919189 28411 net.cpp:408] conv2_2 -> conv2_2
I0912 06:18:59.928203 28411 net.cpp:150] Setting up conv2_2
I0912 06:18:59.928220 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.928234 28411 net.cpp:165] Memory required for data: 1976832000
I0912 06:18:59.928244 28411 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0912 06:18:59.928256 28411 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0912 06:18:59.928262 28411 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0912 06:18:59.928268 28411 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0912 06:18:59.929821 28411 net.cpp:150] Setting up conv2_2_bn_tmp
I0912 06:18:59.929836 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.929841 28411 net.cpp:165] Memory required for data: 2065305600
I0912 06:18:59.929849 28411 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 06:18:59.929857 28411 net.cpp:100] Creating Layer conv2_2_scale
I0912 06:18:59.929860 28411 net.cpp:434] conv2_2_scale <- conv2_2
I0912 06:18:59.929867 28411 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0912 06:18:59.929929 28411 layer_factory.hpp:77] Creating layer conv2_2_scale
I0912 06:18:59.930145 28411 net.cpp:150] Setting up conv2_2_scale
I0912 06:18:59.930155 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.930157 28411 net.cpp:165] Memory required for data: 2153779200
I0912 06:18:59.930163 28411 layer_factory.hpp:77] Creating layer relu2_2
I0912 06:18:59.930174 28411 net.cpp:100] Creating Layer relu2_2
I0912 06:18:59.930179 28411 net.cpp:434] relu2_2 <- conv2_2
I0912 06:18:59.930184 28411 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0912 06:18:59.930420 28411 net.cpp:150] Setting up relu2_2
I0912 06:18:59.930429 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:18:59.930436 28411 net.cpp:165] Memory required for data: 2242252800
I0912 06:18:59.930440 28411 layer_factory.hpp:77] Creating layer pool2
I0912 06:18:59.930444 28411 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 06:18:59.930449 28411 net.cpp:100] Creating Layer pool2
I0912 06:18:59.930454 28411 net.cpp:434] pool2 <- conv2_2
I0912 06:18:59.930459 28411 net.cpp:408] pool2 -> pool2
I0912 06:18:59.930466 28411 net.cpp:408] pool2 -> pool2_mask
I0912 06:18:59.930526 28411 net.cpp:150] Setting up pool2
I0912 06:18:59.930532 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:18:59.930537 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:18:59.930541 28411 net.cpp:165] Memory required for data: 2286489600
I0912 06:18:59.930543 28411 layer_factory.hpp:77] Creating layer conv3_1
I0912 06:18:59.930554 28411 net.cpp:100] Creating Layer conv3_1
I0912 06:18:59.930559 28411 net.cpp:434] conv3_1 <- pool2
I0912 06:18:59.930567 28411 net.cpp:408] conv3_1 -> conv3_1
I0912 06:18:59.943084 28411 net.cpp:150] Setting up conv3_1
I0912 06:18:59.943099 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.943109 28411 net.cpp:165] Memory required for data: 2330726400
I0912 06:18:59.943120 28411 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0912 06:18:59.943128 28411 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0912 06:18:59.943136 28411 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0912 06:18:59.943145 28411 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0912 06:18:59.943435 28411 net.cpp:150] Setting up conv3_1_bn_tmp
I0912 06:18:59.943444 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.943447 28411 net.cpp:165] Memory required for data: 2374963200
I0912 06:18:59.943461 28411 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 06:18:59.943482 28411 net.cpp:100] Creating Layer conv3_1_scale
I0912 06:18:59.943487 28411 net.cpp:434] conv3_1_scale <- conv3_1
I0912 06:18:59.943492 28411 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0912 06:18:59.943552 28411 layer_factory.hpp:77] Creating layer conv3_1_scale
I0912 06:18:59.943742 28411 net.cpp:150] Setting up conv3_1_scale
I0912 06:18:59.943748 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.943753 28411 net.cpp:165] Memory required for data: 2419200000
I0912 06:18:59.943759 28411 layer_factory.hpp:77] Creating layer relu3_1
I0912 06:18:59.943766 28411 net.cpp:100] Creating Layer relu3_1
I0912 06:18:59.943771 28411 net.cpp:434] relu3_1 <- conv3_1
I0912 06:18:59.943778 28411 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0912 06:18:59.944012 28411 net.cpp:150] Setting up relu3_1
I0912 06:18:59.944022 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.944027 28411 net.cpp:165] Memory required for data: 2463436800
I0912 06:18:59.944031 28411 layer_factory.hpp:77] Creating layer conv3_2
I0912 06:18:59.944041 28411 net.cpp:100] Creating Layer conv3_2
I0912 06:18:59.944047 28411 net.cpp:434] conv3_2 <- conv3_1
I0912 06:18:59.944056 28411 net.cpp:408] conv3_2 -> conv3_2
I0912 06:18:59.967605 28411 net.cpp:150] Setting up conv3_2
I0912 06:18:59.967622 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.967633 28411 net.cpp:165] Memory required for data: 2507673600
I0912 06:18:59.967640 28411 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0912 06:18:59.967651 28411 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0912 06:18:59.967658 28411 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0912 06:18:59.967664 28411 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0912 06:18:59.967967 28411 net.cpp:150] Setting up conv3_2_bn_tmp
I0912 06:18:59.967974 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.967978 28411 net.cpp:165] Memory required for data: 2551910400
I0912 06:18:59.967988 28411 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 06:18:59.967999 28411 net.cpp:100] Creating Layer conv3_2_scale
I0912 06:18:59.968004 28411 net.cpp:434] conv3_2_scale <- conv3_2
I0912 06:18:59.968009 28411 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0912 06:18:59.968062 28411 layer_factory.hpp:77] Creating layer conv3_2_scale
I0912 06:18:59.968255 28411 net.cpp:150] Setting up conv3_2_scale
I0912 06:18:59.968262 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.968266 28411 net.cpp:165] Memory required for data: 2596147200
I0912 06:18:59.968271 28411 layer_factory.hpp:77] Creating layer relu3_2
I0912 06:18:59.968281 28411 net.cpp:100] Creating Layer relu3_2
I0912 06:18:59.968286 28411 net.cpp:434] relu3_2 <- conv3_2
I0912 06:18:59.968291 28411 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0912 06:18:59.968520 28411 net.cpp:150] Setting up relu3_2
I0912 06:18:59.968530 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.968533 28411 net.cpp:165] Memory required for data: 2640384000
I0912 06:18:59.968538 28411 layer_factory.hpp:77] Creating layer conv3_3
I0912 06:18:59.968552 28411 net.cpp:100] Creating Layer conv3_3
I0912 06:18:59.968557 28411 net.cpp:434] conv3_3 <- conv3_2
I0912 06:18:59.968562 28411 net.cpp:408] conv3_3 -> conv3_3
I0912 06:18:59.992075 28411 net.cpp:150] Setting up conv3_3
I0912 06:18:59.992091 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.992102 28411 net.cpp:165] Memory required for data: 2684620800
I0912 06:18:59.992110 28411 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0912 06:18:59.992122 28411 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0912 06:18:59.992130 28411 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0912 06:18:59.992136 28411 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0912 06:18:59.992427 28411 net.cpp:150] Setting up conv3_3_bn_tmp
I0912 06:18:59.992435 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.992439 28411 net.cpp:165] Memory required for data: 2728857600
I0912 06:18:59.992447 28411 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 06:18:59.992470 28411 net.cpp:100] Creating Layer conv3_3_scale
I0912 06:18:59.992475 28411 net.cpp:434] conv3_3_scale <- conv3_3
I0912 06:18:59.992481 28411 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0912 06:18:59.992534 28411 layer_factory.hpp:77] Creating layer conv3_3_scale
I0912 06:18:59.992722 28411 net.cpp:150] Setting up conv3_3_scale
I0912 06:18:59.992730 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.992733 28411 net.cpp:165] Memory required for data: 2773094400
I0912 06:18:59.992739 28411 layer_factory.hpp:77] Creating layer relu3_3
I0912 06:18:59.992746 28411 net.cpp:100] Creating Layer relu3_3
I0912 06:18:59.992751 28411 net.cpp:434] relu3_3 <- conv3_3
I0912 06:18:59.992755 28411 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0912 06:18:59.992995 28411 net.cpp:150] Setting up relu3_3
I0912 06:18:59.993003 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:18:59.993006 28411 net.cpp:165] Memory required for data: 2817331200
I0912 06:18:59.993010 28411 layer_factory.hpp:77] Creating layer pool3
I0912 06:18:59.993016 28411 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 06:18:59.993026 28411 net.cpp:100] Creating Layer pool3
I0912 06:18:59.993031 28411 net.cpp:434] pool3 <- conv3_3
I0912 06:18:59.993036 28411 net.cpp:408] pool3 -> pool3
I0912 06:18:59.993043 28411 net.cpp:408] pool3 -> pool3_mask
I0912 06:18:59.993103 28411 net.cpp:150] Setting up pool3
I0912 06:18:59.993109 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:18:59.993113 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:18:59.993118 28411 net.cpp:165] Memory required for data: 2839449600
I0912 06:18:59.993120 28411 layer_factory.hpp:77] Creating layer conv4_1
I0912 06:18:59.993131 28411 net.cpp:100] Creating Layer conv4_1
I0912 06:18:59.993136 28411 net.cpp:434] conv4_1 <- pool3
I0912 06:18:59.993144 28411 net.cpp:408] conv4_1 -> conv4_1
I0912 06:19:00.036933 28411 net.cpp:150] Setting up conv4_1
I0912 06:19:00.036952 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.036962 28411 net.cpp:165] Memory required for data: 2861568000
I0912 06:19:00.036969 28411 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0912 06:19:00.036981 28411 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0912 06:19:00.036988 28411 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0912 06:19:00.036993 28411 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0912 06:19:00.037276 28411 net.cpp:150] Setting up conv4_1_bn_tmp
I0912 06:19:00.037284 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.037287 28411 net.cpp:165] Memory required for data: 2883686400
I0912 06:19:00.037295 28411 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 06:19:00.037304 28411 net.cpp:100] Creating Layer conv4_1_scale
I0912 06:19:00.037309 28411 net.cpp:434] conv4_1_scale <- conv4_1
I0912 06:19:00.037314 28411 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0912 06:19:00.037370 28411 layer_factory.hpp:77] Creating layer conv4_1_scale
I0912 06:19:00.037540 28411 net.cpp:150] Setting up conv4_1_scale
I0912 06:19:00.037549 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.037552 28411 net.cpp:165] Memory required for data: 2905804800
I0912 06:19:00.037559 28411 layer_factory.hpp:77] Creating layer relu4_1
I0912 06:19:00.037566 28411 net.cpp:100] Creating Layer relu4_1
I0912 06:19:00.037571 28411 net.cpp:434] relu4_1 <- conv4_1
I0912 06:19:00.037580 28411 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0912 06:19:00.038718 28411 net.cpp:150] Setting up relu4_1
I0912 06:19:00.038733 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.038738 28411 net.cpp:165] Memory required for data: 2927923200
I0912 06:19:00.038743 28411 layer_factory.hpp:77] Creating layer conv4_2
I0912 06:19:00.038756 28411 net.cpp:100] Creating Layer conv4_2
I0912 06:19:00.038763 28411 net.cpp:434] conv4_2 <- conv4_1
I0912 06:19:00.038770 28411 net.cpp:408] conv4_2 -> conv4_2
I0912 06:19:00.121430 28411 net.cpp:150] Setting up conv4_2
I0912 06:19:00.121460 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.121464 28411 net.cpp:165] Memory required for data: 2950041600
I0912 06:19:00.121472 28411 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0912 06:19:00.121481 28411 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0912 06:19:00.121486 28411 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0912 06:19:00.121492 28411 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0912 06:19:00.121767 28411 net.cpp:150] Setting up conv4_2_bn_tmp
I0912 06:19:00.121778 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.121786 28411 net.cpp:165] Memory required for data: 2972160000
I0912 06:19:00.121794 28411 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 06:19:00.121804 28411 net.cpp:100] Creating Layer conv4_2_scale
I0912 06:19:00.121814 28411 net.cpp:434] conv4_2_scale <- conv4_2
I0912 06:19:00.121819 28411 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0912 06:19:00.121866 28411 layer_factory.hpp:77] Creating layer conv4_2_scale
I0912 06:19:00.122032 28411 net.cpp:150] Setting up conv4_2_scale
I0912 06:19:00.122040 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.122043 28411 net.cpp:165] Memory required for data: 2994278400
I0912 06:19:00.122050 28411 layer_factory.hpp:77] Creating layer relu4_2
I0912 06:19:00.122058 28411 net.cpp:100] Creating Layer relu4_2
I0912 06:19:00.122062 28411 net.cpp:434] relu4_2 <- conv4_2
I0912 06:19:00.122067 28411 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0912 06:19:00.123224 28411 net.cpp:150] Setting up relu4_2
I0912 06:19:00.123239 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.123244 28411 net.cpp:165] Memory required for data: 3016396800
I0912 06:19:00.123248 28411 layer_factory.hpp:77] Creating layer conv4_3
I0912 06:19:00.123261 28411 net.cpp:100] Creating Layer conv4_3
I0912 06:19:00.123266 28411 net.cpp:434] conv4_3 <- conv4_2
I0912 06:19:00.123275 28411 net.cpp:408] conv4_3 -> conv4_3
I0912 06:19:00.206897 28411 net.cpp:150] Setting up conv4_3
I0912 06:19:00.206914 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.206918 28411 net.cpp:165] Memory required for data: 3038515200
I0912 06:19:00.206941 28411 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0912 06:19:00.206953 28411 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0912 06:19:00.206959 28411 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0912 06:19:00.206967 28411 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0912 06:19:00.207244 28411 net.cpp:150] Setting up conv4_3_bn_tmp
I0912 06:19:00.207252 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.207255 28411 net.cpp:165] Memory required for data: 3060633600
I0912 06:19:00.207264 28411 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 06:19:00.207278 28411 net.cpp:100] Creating Layer conv4_3_scale
I0912 06:19:00.207281 28411 net.cpp:434] conv4_3_scale <- conv4_3
I0912 06:19:00.207288 28411 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0912 06:19:00.207336 28411 layer_factory.hpp:77] Creating layer conv4_3_scale
I0912 06:19:00.207506 28411 net.cpp:150] Setting up conv4_3_scale
I0912 06:19:00.207515 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.207517 28411 net.cpp:165] Memory required for data: 3082752000
I0912 06:19:00.207523 28411 layer_factory.hpp:77] Creating layer relu4_3
I0912 06:19:00.207530 28411 net.cpp:100] Creating Layer relu4_3
I0912 06:19:00.207535 28411 net.cpp:434] relu4_3 <- conv4_3
I0912 06:19:00.207540 28411 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0912 06:19:00.207762 28411 net.cpp:150] Setting up relu4_3
I0912 06:19:00.207772 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.207775 28411 net.cpp:165] Memory required for data: 3104870400
I0912 06:19:00.207778 28411 layer_factory.hpp:77] Creating layer pool4
I0912 06:19:00.207784 28411 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 06:19:00.207789 28411 net.cpp:100] Creating Layer pool4
I0912 06:19:00.207794 28411 net.cpp:434] pool4 <- conv4_3
I0912 06:19:00.207816 28411 net.cpp:408] pool4 -> pool4
I0912 06:19:00.207825 28411 net.cpp:408] pool4 -> pool4_mask
I0912 06:19:00.207883 28411 net.cpp:150] Setting up pool4
I0912 06:19:00.207890 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.207895 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.207900 28411 net.cpp:165] Memory required for data: 3116175360
I0912 06:19:00.207903 28411 layer_factory.hpp:77] Creating layer conv5_1
I0912 06:19:00.207916 28411 net.cpp:100] Creating Layer conv5_1
I0912 06:19:00.207921 28411 net.cpp:434] conv5_1 <- pool4
I0912 06:19:00.207927 28411 net.cpp:408] conv5_1 -> conv5_1
I0912 06:19:00.291539 28411 net.cpp:150] Setting up conv5_1
I0912 06:19:00.291559 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.291568 28411 net.cpp:165] Memory required for data: 3121827840
I0912 06:19:00.291575 28411 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0912 06:19:00.291585 28411 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0912 06:19:00.291595 28411 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0912 06:19:00.291607 28411 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0912 06:19:00.291887 28411 net.cpp:150] Setting up conv5_1_bn_tmp
I0912 06:19:00.291895 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.291899 28411 net.cpp:165] Memory required for data: 3127480320
I0912 06:19:00.291908 28411 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 06:19:00.291919 28411 net.cpp:100] Creating Layer conv5_1_scale
I0912 06:19:00.291924 28411 net.cpp:434] conv5_1_scale <- conv5_1
I0912 06:19:00.291929 28411 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0912 06:19:00.291986 28411 layer_factory.hpp:77] Creating layer conv5_1_scale
I0912 06:19:00.292140 28411 net.cpp:150] Setting up conv5_1_scale
I0912 06:19:00.292146 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.292150 28411 net.cpp:165] Memory required for data: 3133132800
I0912 06:19:00.292156 28411 layer_factory.hpp:77] Creating layer relu5_1
I0912 06:19:00.292163 28411 net.cpp:100] Creating Layer relu5_1
I0912 06:19:00.292167 28411 net.cpp:434] relu5_1 <- conv5_1
I0912 06:19:00.292176 28411 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0912 06:19:00.292397 28411 net.cpp:150] Setting up relu5_1
I0912 06:19:00.292407 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.292409 28411 net.cpp:165] Memory required for data: 3138785280
I0912 06:19:00.292413 28411 layer_factory.hpp:77] Creating layer conv5_2
I0912 06:19:00.292424 28411 net.cpp:100] Creating Layer conv5_2
I0912 06:19:00.292429 28411 net.cpp:434] conv5_2 <- conv5_1
I0912 06:19:00.292438 28411 net.cpp:408] conv5_2 -> conv5_2
I0912 06:19:00.376144 28411 net.cpp:150] Setting up conv5_2
I0912 06:19:00.376161 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.376165 28411 net.cpp:165] Memory required for data: 3144437760
I0912 06:19:00.376173 28411 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0912 06:19:00.376183 28411 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0912 06:19:00.376194 28411 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0912 06:19:00.376199 28411 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0912 06:19:00.376477 28411 net.cpp:150] Setting up conv5_2_bn_tmp
I0912 06:19:00.376485 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.376488 28411 net.cpp:165] Memory required for data: 3150090240
I0912 06:19:00.376497 28411 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 06:19:00.376503 28411 net.cpp:100] Creating Layer conv5_2_scale
I0912 06:19:00.376512 28411 net.cpp:434] conv5_2_scale <- conv5_2
I0912 06:19:00.376519 28411 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0912 06:19:00.376576 28411 layer_factory.hpp:77] Creating layer conv5_2_scale
I0912 06:19:00.376729 28411 net.cpp:150] Setting up conv5_2_scale
I0912 06:19:00.376739 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.376742 28411 net.cpp:165] Memory required for data: 3155742720
I0912 06:19:00.376749 28411 layer_factory.hpp:77] Creating layer relu5_2
I0912 06:19:00.376770 28411 net.cpp:100] Creating Layer relu5_2
I0912 06:19:00.376775 28411 net.cpp:434] relu5_2 <- conv5_2
I0912 06:19:00.376780 28411 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0912 06:19:00.377009 28411 net.cpp:150] Setting up relu5_2
I0912 06:19:00.377020 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.377024 28411 net.cpp:165] Memory required for data: 3161395200
I0912 06:19:00.377028 28411 layer_factory.hpp:77] Creating layer conv5_3
I0912 06:19:00.377041 28411 net.cpp:100] Creating Layer conv5_3
I0912 06:19:00.377046 28411 net.cpp:434] conv5_3 <- conv5_2
I0912 06:19:00.377053 28411 net.cpp:408] conv5_3 -> conv5_3
I0912 06:19:00.460629 28411 net.cpp:150] Setting up conv5_3
I0912 06:19:00.460646 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.460650 28411 net.cpp:165] Memory required for data: 3167047680
I0912 06:19:00.460665 28411 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0912 06:19:00.460680 28411 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0912 06:19:00.460686 28411 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0912 06:19:00.460693 28411 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0912 06:19:00.460970 28411 net.cpp:150] Setting up conv5_3_bn_tmp
I0912 06:19:00.460979 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.460983 28411 net.cpp:165] Memory required for data: 3172700160
I0912 06:19:00.460991 28411 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 06:19:00.460999 28411 net.cpp:100] Creating Layer conv5_3_scale
I0912 06:19:00.461005 28411 net.cpp:434] conv5_3_scale <- conv5_3
I0912 06:19:00.461010 28411 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0912 06:19:00.461066 28411 layer_factory.hpp:77] Creating layer conv5_3_scale
I0912 06:19:00.461222 28411 net.cpp:150] Setting up conv5_3_scale
I0912 06:19:00.461230 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.461233 28411 net.cpp:165] Memory required for data: 3178352640
I0912 06:19:00.461242 28411 layer_factory.hpp:77] Creating layer relu5_3
I0912 06:19:00.461249 28411 net.cpp:100] Creating Layer relu5_3
I0912 06:19:00.461253 28411 net.cpp:434] relu5_3 <- conv5_3
I0912 06:19:00.461257 28411 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0912 06:19:00.461505 28411 net.cpp:150] Setting up relu5_3
I0912 06:19:00.461515 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.461519 28411 net.cpp:165] Memory required for data: 3184005120
I0912 06:19:00.461522 28411 layer_factory.hpp:77] Creating layer pool5
I0912 06:19:00.461529 28411 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0912 06:19:00.461534 28411 net.cpp:100] Creating Layer pool5
I0912 06:19:00.461539 28411 net.cpp:434] pool5 <- conv5_3
I0912 06:19:00.461546 28411 net.cpp:408] pool5 -> pool5
I0912 06:19:00.461555 28411 net.cpp:408] pool5 -> pool5_mask
I0912 06:19:00.461616 28411 net.cpp:150] Setting up pool5
I0912 06:19:00.461622 28411 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 06:19:00.461627 28411 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0912 06:19:00.461632 28411 net.cpp:165] Memory required for data: 3186954240
I0912 06:19:00.461635 28411 layer_factory.hpp:77] Creating layer upsample5
I0912 06:19:00.461644 28411 net.cpp:100] Creating Layer upsample5
I0912 06:19:00.461649 28411 net.cpp:434] upsample5 <- pool5
I0912 06:19:00.461653 28411 net.cpp:434] upsample5 <- pool5_mask
I0912 06:19:00.461661 28411 net.cpp:408] upsample5 -> pool5_D
I0912 06:19:00.461694 28411 net.cpp:150] Setting up upsample5
I0912 06:19:00.461700 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.461704 28411 net.cpp:165] Memory required for data: 3192606720
I0912 06:19:00.461709 28411 layer_factory.hpp:77] Creating layer conv5_3_D
I0912 06:19:00.461720 28411 net.cpp:100] Creating Layer conv5_3_D
I0912 06:19:00.461725 28411 net.cpp:434] conv5_3_D <- pool5_D
I0912 06:19:00.461732 28411 net.cpp:408] conv5_3_D -> conv5_3_D
I0912 06:19:00.545259 28411 net.cpp:150] Setting up conv5_3_D
I0912 06:19:00.545279 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.545300 28411 net.cpp:165] Memory required for data: 3198259200
I0912 06:19:00.545308 28411 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0912 06:19:00.545317 28411 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0912 06:19:00.545326 28411 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0912 06:19:00.545332 28411 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0912 06:19:00.545635 28411 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0912 06:19:00.545645 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.545650 28411 net.cpp:165] Memory required for data: 3203911680
I0912 06:19:00.545658 28411 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 06:19:00.545667 28411 net.cpp:100] Creating Layer conv5_3_D_scale
I0912 06:19:00.545675 28411 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0912 06:19:00.545681 28411 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0912 06:19:00.545744 28411 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0912 06:19:00.545904 28411 net.cpp:150] Setting up conv5_3_D_scale
I0912 06:19:00.545912 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.545915 28411 net.cpp:165] Memory required for data: 3209564160
I0912 06:19:00.545922 28411 layer_factory.hpp:77] Creating layer relu5_3_D
I0912 06:19:00.545929 28411 net.cpp:100] Creating Layer relu5_3_D
I0912 06:19:00.545933 28411 net.cpp:434] relu5_3_D <- conv5_3_D
I0912 06:19:00.545940 28411 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0912 06:19:00.547087 28411 net.cpp:150] Setting up relu5_3_D
I0912 06:19:00.547102 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.547107 28411 net.cpp:165] Memory required for data: 3215216640
I0912 06:19:00.547111 28411 layer_factory.hpp:77] Creating layer conv5_2_D
I0912 06:19:00.547137 28411 net.cpp:100] Creating Layer conv5_2_D
I0912 06:19:00.547142 28411 net.cpp:434] conv5_2_D <- conv5_3_D
I0912 06:19:00.547149 28411 net.cpp:408] conv5_2_D -> conv5_2_D
I0912 06:19:00.630853 28411 net.cpp:150] Setting up conv5_2_D
I0912 06:19:00.630870 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.630874 28411 net.cpp:165] Memory required for data: 3220869120
I0912 06:19:00.630883 28411 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0912 06:19:00.630890 28411 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0912 06:19:00.630895 28411 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0912 06:19:00.630903 28411 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0912 06:19:00.631191 28411 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0912 06:19:00.631199 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.631202 28411 net.cpp:165] Memory required for data: 3226521600
I0912 06:19:00.631211 28411 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 06:19:00.631219 28411 net.cpp:100] Creating Layer conv5_2_D_scale
I0912 06:19:00.631229 28411 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0912 06:19:00.631234 28411 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0912 06:19:00.631297 28411 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0912 06:19:00.631455 28411 net.cpp:150] Setting up conv5_2_D_scale
I0912 06:19:00.631464 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.631466 28411 net.cpp:165] Memory required for data: 3232174080
I0912 06:19:00.631472 28411 layer_factory.hpp:77] Creating layer relu5_2_D
I0912 06:19:00.631479 28411 net.cpp:100] Creating Layer relu5_2_D
I0912 06:19:00.631484 28411 net.cpp:434] relu5_2_D <- conv5_2_D
I0912 06:19:00.631490 28411 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0912 06:19:00.632659 28411 net.cpp:150] Setting up relu5_2_D
I0912 06:19:00.632674 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.632679 28411 net.cpp:165] Memory required for data: 3237826560
I0912 06:19:00.632683 28411 layer_factory.hpp:77] Creating layer conv5_1_D
I0912 06:19:00.632696 28411 net.cpp:100] Creating Layer conv5_1_D
I0912 06:19:00.632702 28411 net.cpp:434] conv5_1_D <- conv5_2_D
I0912 06:19:00.632711 28411 net.cpp:408] conv5_1_D -> conv5_1_D
I0912 06:19:00.717208 28411 net.cpp:150] Setting up conv5_1_D
I0912 06:19:00.717229 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.717242 28411 net.cpp:165] Memory required for data: 3243479040
I0912 06:19:00.717257 28411 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0912 06:19:00.717268 28411 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0912 06:19:00.717279 28411 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0912 06:19:00.717288 28411 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0912 06:19:00.717602 28411 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0912 06:19:00.717610 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.717614 28411 net.cpp:165] Memory required for data: 3249131520
I0912 06:19:00.717622 28411 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 06:19:00.717630 28411 net.cpp:100] Creating Layer conv5_1_D_scale
I0912 06:19:00.717635 28411 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0912 06:19:00.717641 28411 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0912 06:19:00.717702 28411 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0912 06:19:00.717860 28411 net.cpp:150] Setting up conv5_1_D_scale
I0912 06:19:00.717867 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.717871 28411 net.cpp:165] Memory required for data: 3254784000
I0912 06:19:00.717877 28411 layer_factory.hpp:77] Creating layer relu5_1_D
I0912 06:19:00.717886 28411 net.cpp:100] Creating Layer relu5_1_D
I0912 06:19:00.717891 28411 net.cpp:434] relu5_1_D <- conv5_1_D
I0912 06:19:00.717896 28411 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0912 06:19:00.718122 28411 net.cpp:150] Setting up relu5_1_D
I0912 06:19:00.718132 28411 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0912 06:19:00.718137 28411 net.cpp:165] Memory required for data: 3260436480
I0912 06:19:00.718139 28411 layer_factory.hpp:77] Creating layer upsample4
I0912 06:19:00.718147 28411 net.cpp:100] Creating Layer upsample4
I0912 06:19:00.718152 28411 net.cpp:434] upsample4 <- conv5_1_D
I0912 06:19:00.718158 28411 net.cpp:434] upsample4 <- pool4_mask
I0912 06:19:00.718166 28411 net.cpp:408] upsample4 -> pool4_D
I0912 06:19:00.718206 28411 net.cpp:150] Setting up upsample4
I0912 06:19:00.718214 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.718217 28411 net.cpp:165] Memory required for data: 3282554880
I0912 06:19:00.718220 28411 layer_factory.hpp:77] Creating layer conv4_3_D
I0912 06:19:00.718235 28411 net.cpp:100] Creating Layer conv4_3_D
I0912 06:19:00.718241 28411 net.cpp:434] conv4_3_D <- pool4_D
I0912 06:19:00.718247 28411 net.cpp:408] conv4_3_D -> conv4_3_D
I0912 06:19:00.802039 28411 net.cpp:150] Setting up conv4_3_D
I0912 06:19:00.802057 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.802067 28411 net.cpp:165] Memory required for data: 3304673280
I0912 06:19:00.802074 28411 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0912 06:19:00.802088 28411 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0912 06:19:00.802094 28411 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0912 06:19:00.802100 28411 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0912 06:19:00.802390 28411 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0912 06:19:00.802398 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.802402 28411 net.cpp:165] Memory required for data: 3326791680
I0912 06:19:00.802410 28411 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 06:19:00.802417 28411 net.cpp:100] Creating Layer conv4_3_D_scale
I0912 06:19:00.802424 28411 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0912 06:19:00.802431 28411 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0912 06:19:00.802482 28411 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0912 06:19:00.802655 28411 net.cpp:150] Setting up conv4_3_D_scale
I0912 06:19:00.802662 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.802666 28411 net.cpp:165] Memory required for data: 3348910080
I0912 06:19:00.802672 28411 layer_factory.hpp:77] Creating layer relu4_3_D
I0912 06:19:00.802696 28411 net.cpp:100] Creating Layer relu4_3_D
I0912 06:19:00.802701 28411 net.cpp:434] relu4_3_D <- conv4_3_D
I0912 06:19:00.802706 28411 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0912 06:19:00.802938 28411 net.cpp:150] Setting up relu4_3_D
I0912 06:19:00.802947 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.802953 28411 net.cpp:165] Memory required for data: 3371028480
I0912 06:19:00.802956 28411 layer_factory.hpp:77] Creating layer conv4_2_D
I0912 06:19:00.802968 28411 net.cpp:100] Creating Layer conv4_2_D
I0912 06:19:00.802973 28411 net.cpp:434] conv4_2_D <- conv4_3_D
I0912 06:19:00.802980 28411 net.cpp:408] conv4_2_D -> conv4_2_D
I0912 06:19:00.886654 28411 net.cpp:150] Setting up conv4_2_D
I0912 06:19:00.886672 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.886675 28411 net.cpp:165] Memory required for data: 3393146880
I0912 06:19:00.886683 28411 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0912 06:19:00.886693 28411 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0912 06:19:00.886704 28411 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0912 06:19:00.886713 28411 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0912 06:19:00.887017 28411 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0912 06:19:00.887025 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.887028 28411 net.cpp:165] Memory required for data: 3415265280
I0912 06:19:00.887037 28411 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 06:19:00.887048 28411 net.cpp:100] Creating Layer conv4_2_D_scale
I0912 06:19:00.887054 28411 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0912 06:19:00.887059 28411 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0912 06:19:00.887116 28411 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0912 06:19:00.887293 28411 net.cpp:150] Setting up conv4_2_D_scale
I0912 06:19:00.887301 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.887305 28411 net.cpp:165] Memory required for data: 3437383680
I0912 06:19:00.887311 28411 layer_factory.hpp:77] Creating layer relu4_2_D
I0912 06:19:00.887318 28411 net.cpp:100] Creating Layer relu4_2_D
I0912 06:19:00.887323 28411 net.cpp:434] relu4_2_D <- conv4_2_D
I0912 06:19:00.887329 28411 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0912 06:19:00.887553 28411 net.cpp:150] Setting up relu4_2_D
I0912 06:19:00.887562 28411 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0912 06:19:00.887565 28411 net.cpp:165] Memory required for data: 3459502080
I0912 06:19:00.887569 28411 layer_factory.hpp:77] Creating layer conv4_1_D
I0912 06:19:00.887580 28411 net.cpp:100] Creating Layer conv4_1_D
I0912 06:19:00.887586 28411 net.cpp:434] conv4_1_D <- conv4_2_D
I0912 06:19:00.887594 28411 net.cpp:408] conv4_1_D -> conv4_1_D
I0912 06:19:00.931648 28411 net.cpp:150] Setting up conv4_1_D
I0912 06:19:00.931665 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:19:00.931676 28411 net.cpp:165] Memory required for data: 3470561280
I0912 06:19:00.931684 28411 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0912 06:19:00.931694 28411 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0912 06:19:00.931697 28411 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0912 06:19:00.931705 28411 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0912 06:19:00.932011 28411 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0912 06:19:00.932019 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:19:00.932024 28411 net.cpp:165] Memory required for data: 3481620480
I0912 06:19:00.932098 28411 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 06:19:00.932108 28411 net.cpp:100] Creating Layer conv4_1_D_scale
I0912 06:19:00.932116 28411 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0912 06:19:00.932122 28411 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0912 06:19:00.932188 28411 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0912 06:19:00.932366 28411 net.cpp:150] Setting up conv4_1_D_scale
I0912 06:19:00.932375 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:19:00.932394 28411 net.cpp:165] Memory required for data: 3492679680
I0912 06:19:00.932401 28411 layer_factory.hpp:77] Creating layer relu4_1_D
I0912 06:19:00.932407 28411 net.cpp:100] Creating Layer relu4_1_D
I0912 06:19:00.932412 28411 net.cpp:434] relu4_1_D <- conv4_1_D
I0912 06:19:00.932416 28411 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0912 06:19:00.932660 28411 net.cpp:150] Setting up relu4_1_D
I0912 06:19:00.932669 28411 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0912 06:19:00.932673 28411 net.cpp:165] Memory required for data: 3503738880
I0912 06:19:00.932677 28411 layer_factory.hpp:77] Creating layer upsample3
I0912 06:19:00.932687 28411 net.cpp:100] Creating Layer upsample3
I0912 06:19:00.932693 28411 net.cpp:434] upsample3 <- conv4_1_D
I0912 06:19:00.932698 28411 net.cpp:434] upsample3 <- pool3_mask
I0912 06:19:00.932703 28411 net.cpp:408] upsample3 -> pool3_D
I0912 06:19:00.932711 28411 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 06:19:00.932749 28411 net.cpp:150] Setting up upsample3
I0912 06:19:00.932756 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:19:00.932760 28411 net.cpp:165] Memory required for data: 3547975680
I0912 06:19:00.932763 28411 layer_factory.hpp:77] Creating layer conv3_3_D
I0912 06:19:00.932775 28411 net.cpp:100] Creating Layer conv3_3_D
I0912 06:19:00.932780 28411 net.cpp:434] conv3_3_D <- pool3_D
I0912 06:19:00.932790 28411 net.cpp:408] conv3_3_D -> conv3_3_D
I0912 06:19:00.956532 28411 net.cpp:150] Setting up conv3_3_D
I0912 06:19:00.956548 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:19:00.956557 28411 net.cpp:165] Memory required for data: 3592212480
I0912 06:19:00.956565 28411 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0912 06:19:00.956575 28411 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0912 06:19:00.956579 28411 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0912 06:19:00.956585 28411 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0912 06:19:00.956900 28411 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0912 06:19:00.956909 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:19:00.956913 28411 net.cpp:165] Memory required for data: 3636449280
I0912 06:19:00.956923 28411 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 06:19:00.956931 28411 net.cpp:100] Creating Layer conv3_3_D_scale
I0912 06:19:00.956940 28411 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0912 06:19:00.956945 28411 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0912 06:19:00.957008 28411 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0912 06:19:00.957206 28411 net.cpp:150] Setting up conv3_3_D_scale
I0912 06:19:00.957214 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:19:00.957218 28411 net.cpp:165] Memory required for data: 3680686080
I0912 06:19:00.957224 28411 layer_factory.hpp:77] Creating layer relu3_3_D
I0912 06:19:00.957233 28411 net.cpp:100] Creating Layer relu3_3_D
I0912 06:19:00.957238 28411 net.cpp:434] relu3_3_D <- conv3_3_D
I0912 06:19:00.957242 28411 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0912 06:19:00.958431 28411 net.cpp:150] Setting up relu3_3_D
I0912 06:19:00.958446 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:19:00.958451 28411 net.cpp:165] Memory required for data: 3724922880
I0912 06:19:00.958454 28411 layer_factory.hpp:77] Creating layer conv3_2_D
I0912 06:19:00.958468 28411 net.cpp:100] Creating Layer conv3_2_D
I0912 06:19:00.958474 28411 net.cpp:434] conv3_2_D <- conv3_3_D
I0912 06:19:00.958482 28411 net.cpp:408] conv3_2_D -> conv3_2_D
I0912 06:19:00.981307 28411 net.cpp:150] Setting up conv3_2_D
I0912 06:19:00.981323 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:19:00.981334 28411 net.cpp:165] Memory required for data: 3769159680
I0912 06:19:00.981343 28411 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0912 06:19:00.981354 28411 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0912 06:19:00.981361 28411 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0912 06:19:00.981400 28411 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0912 06:19:00.981719 28411 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0912 06:19:00.981729 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:19:00.981732 28411 net.cpp:165] Memory required for data: 3813396480
I0912 06:19:00.981741 28411 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 06:19:00.981750 28411 net.cpp:100] Creating Layer conv3_2_D_scale
I0912 06:19:00.981756 28411 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0912 06:19:00.981762 28411 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0912 06:19:00.981817 28411 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0912 06:19:00.982015 28411 net.cpp:150] Setting up conv3_2_D_scale
I0912 06:19:00.982023 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:19:00.982026 28411 net.cpp:165] Memory required for data: 3857633280
I0912 06:19:00.982033 28411 layer_factory.hpp:77] Creating layer relu3_2_D
I0912 06:19:00.982040 28411 net.cpp:100] Creating Layer relu3_2_D
I0912 06:19:00.982045 28411 net.cpp:434] relu3_2_D <- conv3_2_D
I0912 06:19:00.982050 28411 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0912 06:19:00.983217 28411 net.cpp:150] Setting up relu3_2_D
I0912 06:19:00.983232 28411 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0912 06:19:00.983237 28411 net.cpp:165] Memory required for data: 3901870080
I0912 06:19:00.983242 28411 layer_factory.hpp:77] Creating layer conv3_1_D
I0912 06:19:00.983258 28411 net.cpp:100] Creating Layer conv3_1_D
I0912 06:19:00.983263 28411 net.cpp:434] conv3_1_D <- conv3_2_D
I0912 06:19:00.983269 28411 net.cpp:408] conv3_1_D -> conv3_1_D
I0912 06:19:00.997238 28411 net.cpp:150] Setting up conv3_1_D
I0912 06:19:00.997257 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:19:00.997265 28411 net.cpp:165] Memory required for data: 3923988480
I0912 06:19:00.997273 28411 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0912 06:19:00.997285 28411 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0912 06:19:00.997292 28411 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0912 06:19:00.997298 28411 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0912 06:19:00.997637 28411 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0912 06:19:00.997648 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:19:00.997651 28411 net.cpp:165] Memory required for data: 3946106880
I0912 06:19:00.997659 28411 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 06:19:00.997670 28411 net.cpp:100] Creating Layer conv3_1_D_scale
I0912 06:19:00.997678 28411 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0912 06:19:00.997683 28411 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0912 06:19:00.997740 28411 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0912 06:19:00.999202 28411 net.cpp:150] Setting up conv3_1_D_scale
I0912 06:19:00.999217 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:19:00.999227 28411 net.cpp:165] Memory required for data: 3968225280
I0912 06:19:00.999234 28411 layer_factory.hpp:77] Creating layer relu3_1_D
I0912 06:19:00.999243 28411 net.cpp:100] Creating Layer relu3_1_D
I0912 06:19:00.999248 28411 net.cpp:434] relu3_1_D <- conv3_1_D
I0912 06:19:00.999255 28411 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0912 06:19:00.999505 28411 net.cpp:150] Setting up relu3_1_D
I0912 06:19:00.999514 28411 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0912 06:19:00.999519 28411 net.cpp:165] Memory required for data: 3990343680
I0912 06:19:00.999523 28411 layer_factory.hpp:77] Creating layer upsample2
I0912 06:19:00.999531 28411 net.cpp:100] Creating Layer upsample2
I0912 06:19:00.999537 28411 net.cpp:434] upsample2 <- conv3_1_D
I0912 06:19:00.999541 28411 net.cpp:434] upsample2 <- pool2_mask
I0912 06:19:00.999548 28411 net.cpp:408] upsample2 -> pool2_D
I0912 06:19:00.999555 28411 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 06:19:00.999593 28411 net.cpp:150] Setting up upsample2
I0912 06:19:00.999614 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:19:00.999617 28411 net.cpp:165] Memory required for data: 4078817280
I0912 06:19:00.999621 28411 layer_factory.hpp:77] Creating layer conv2_2_D
I0912 06:19:00.999636 28411 net.cpp:100] Creating Layer conv2_2_D
I0912 06:19:00.999641 28411 net.cpp:434] conv2_2_D <- pool2_D
I0912 06:19:00.999647 28411 net.cpp:408] conv2_2_D -> conv2_2_D
I0912 06:19:01.007609 28411 net.cpp:150] Setting up conv2_2_D
I0912 06:19:01.007628 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:19:01.007635 28411 net.cpp:165] Memory required for data: 4167290880
I0912 06:19:01.007643 28411 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0912 06:19:01.007653 28411 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0912 06:19:01.007663 28411 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0912 06:19:01.007669 28411 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0912 06:19:01.008021 28411 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0912 06:19:01.008029 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:19:01.008033 28411 net.cpp:165] Memory required for data: 4255764480
I0912 06:19:01.008041 28411 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 06:19:01.008055 28411 net.cpp:100] Creating Layer conv2_2_D_scale
I0912 06:19:01.008060 28411 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0912 06:19:01.008065 28411 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0912 06:19:01.008123 28411 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0912 06:19:01.008386 28411 net.cpp:150] Setting up conv2_2_D_scale
I0912 06:19:01.008394 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:19:01.008399 28411 net.cpp:165] Memory required for data: 4344238080
I0912 06:19:01.008404 28411 layer_factory.hpp:77] Creating layer relu2_2_D
I0912 06:19:01.008412 28411 net.cpp:100] Creating Layer relu2_2_D
I0912 06:19:01.008416 28411 net.cpp:434] relu2_2_D <- conv2_2_D
I0912 06:19:01.008424 28411 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0912 06:19:01.008669 28411 net.cpp:150] Setting up relu2_2_D
I0912 06:19:01.008678 28411 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0912 06:19:01.008683 28411 net.cpp:165] Memory required for data: 4432711680
I0912 06:19:01.008687 28411 layer_factory.hpp:77] Creating layer conv2_1_D
I0912 06:19:01.008698 28411 net.cpp:100] Creating Layer conv2_1_D
I0912 06:19:01.008703 28411 net.cpp:434] conv2_1_D <- conv2_2_D
I0912 06:19:01.008713 28411 net.cpp:408] conv2_1_D -> conv2_1_D
I0912 06:19:01.014257 28411 net.cpp:150] Setting up conv2_1_D
I0912 06:19:01.014274 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:19:01.014289 28411 net.cpp:165] Memory required for data: 4476948480
I0912 06:19:01.014297 28411 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0912 06:19:01.014310 28411 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0912 06:19:01.014317 28411 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0912 06:19:01.014325 28411 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0912 06:19:01.014693 28411 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0912 06:19:01.014700 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:19:01.014704 28411 net.cpp:165] Memory required for data: 4521185280
I0912 06:19:01.014713 28411 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 06:19:01.014724 28411 net.cpp:100] Creating Layer conv2_1_D_scale
I0912 06:19:01.014729 28411 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0912 06:19:01.014734 28411 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0912 06:19:01.014793 28411 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0912 06:19:01.015074 28411 net.cpp:150] Setting up conv2_1_D_scale
I0912 06:19:01.015082 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:19:01.015085 28411 net.cpp:165] Memory required for data: 4565422080
I0912 06:19:01.015092 28411 layer_factory.hpp:77] Creating layer relu2_1_D
I0912 06:19:01.015100 28411 net.cpp:100] Creating Layer relu2_1_D
I0912 06:19:01.015103 28411 net.cpp:434] relu2_1_D <- conv2_1_D
I0912 06:19:01.015125 28411 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0912 06:19:01.015368 28411 net.cpp:150] Setting up relu2_1_D
I0912 06:19:01.015377 28411 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0912 06:19:01.015383 28411 net.cpp:165] Memory required for data: 4609658880
I0912 06:19:01.015386 28411 layer_factory.hpp:77] Creating layer upsample1
I0912 06:19:01.015393 28411 net.cpp:100] Creating Layer upsample1
I0912 06:19:01.015398 28411 net.cpp:434] upsample1 <- conv2_1_D
I0912 06:19:01.015403 28411 net.cpp:434] upsample1 <- pool1_mask
I0912 06:19:01.015411 28411 net.cpp:408] upsample1 -> pool1_D
I0912 06:19:01.015419 28411 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0912 06:19:01.015457 28411 net.cpp:150] Setting up upsample1
I0912 06:19:01.015465 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:19:01.015467 28411 net.cpp:165] Memory required for data: 4786606080
I0912 06:19:01.015470 28411 layer_factory.hpp:77] Creating layer conv1_2_D
I0912 06:19:01.015483 28411 net.cpp:100] Creating Layer conv1_2_D
I0912 06:19:01.015488 28411 net.cpp:434] conv1_2_D <- pool1_D
I0912 06:19:01.015494 28411 net.cpp:408] conv1_2_D -> conv1_2_D
I0912 06:19:01.020222 28411 net.cpp:150] Setting up conv1_2_D
I0912 06:19:01.020238 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:19:01.020247 28411 net.cpp:165] Memory required for data: 4963553280
I0912 06:19:01.020256 28411 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0912 06:19:01.020267 28411 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0912 06:19:01.020273 28411 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0912 06:19:01.020279 28411 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0912 06:19:01.020722 28411 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0912 06:19:01.020730 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:19:01.020735 28411 net.cpp:165] Memory required for data: 5140500480
I0912 06:19:01.020743 28411 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 06:19:01.020751 28411 net.cpp:100] Creating Layer conv1_2_D_scale
I0912 06:19:01.020756 28411 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0912 06:19:01.020763 28411 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0912 06:19:01.020822 28411 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0912 06:19:01.022573 28411 net.cpp:150] Setting up conv1_2_D_scale
I0912 06:19:01.022588 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:19:01.022593 28411 net.cpp:165] Memory required for data: 5317447680
I0912 06:19:01.022601 28411 layer_factory.hpp:77] Creating layer relu1_2_D
I0912 06:19:01.022610 28411 net.cpp:100] Creating Layer relu1_2_D
I0912 06:19:01.022615 28411 net.cpp:434] relu1_2_D <- conv1_2_D
I0912 06:19:01.022624 28411 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0912 06:19:01.022876 28411 net.cpp:150] Setting up relu1_2_D
I0912 06:19:01.022886 28411 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0912 06:19:01.022891 28411 net.cpp:165] Memory required for data: 5494394880
I0912 06:19:01.022893 28411 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0912 06:19:01.022905 28411 net.cpp:100] Creating Layer conv1_1_1_D
I0912 06:19:01.022910 28411 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0912 06:19:01.022918 28411 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0912 06:19:01.025147 28411 net.cpp:150] Setting up conv1_1_1_D
I0912 06:19:01.025163 28411 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 06:19:01.025168 28411 net.cpp:165] Memory required for data: 5499924480
I0912 06:19:01.025177 28411 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 06:19:01.025185 28411 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0912 06:19:01.025192 28411 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0912 06:19:01.025199 28411 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 06:19:01.025208 28411 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 06:19:01.025285 28411 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0912 06:19:01.025292 28411 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 06:19:01.025297 28411 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0912 06:19:01.025300 28411 net.cpp:165] Memory required for data: 5510983680
I0912 06:19:01.025305 28411 layer_factory.hpp:77] Creating layer loss
I0912 06:19:01.025315 28411 net.cpp:100] Creating Layer loss
I0912 06:19:01.025319 28411 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0912 06:19:01.025324 28411 net.cpp:434] loss <- label_data_1_split_0
I0912 06:19:01.025332 28411 net.cpp:408] loss -> loss
I0912 06:19:01.025343 28411 layer_factory.hpp:77] Creating layer loss
I0912 06:19:01.029418 28411 net.cpp:150] Setting up loss
I0912 06:19:01.029433 28411 net.cpp:157] Top shape: (1)
I0912 06:19:01.029443 28411 net.cpp:160]     with loss weight 1
I0912 06:19:01.029459 28411 net.cpp:165] Memory required for data: 5510983684
I0912 06:19:01.029464 28411 layer_factory.hpp:77] Creating layer accuracy
I0912 06:19:01.029470 28411 net.cpp:100] Creating Layer accuracy
I0912 06:19:01.029476 28411 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0912 06:19:01.029484 28411 net.cpp:434] accuracy <- label_data_1_split_1
I0912 06:19:01.029490 28411 net.cpp:408] accuracy -> accuracy
I0912 06:19:01.029498 28411 net.cpp:408] accuracy -> per_class_accuracy
I0912 06:19:01.029556 28411 net.cpp:150] Setting up accuracy
I0912 06:19:01.029563 28411 net.cpp:157] Top shape: (1)
I0912 06:19:01.029567 28411 net.cpp:157] Top shape: 2 (2)
I0912 06:19:01.029570 28411 net.cpp:165] Memory required for data: 5510983696
I0912 06:19:01.029574 28411 net.cpp:228] accuracy does not need backward computation.
I0912 06:19:01.029578 28411 net.cpp:226] loss needs backward computation.
I0912 06:19:01.029583 28411 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0912 06:19:01.029587 28411 net.cpp:226] conv1_1_1_D needs backward computation.
I0912 06:19:01.029590 28411 net.cpp:226] relu1_2_D needs backward computation.
I0912 06:19:01.029593 28411 net.cpp:226] conv1_2_D_scale needs backward computation.
I0912 06:19:01.029597 28411 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0912 06:19:01.029599 28411 net.cpp:226] conv1_2_D needs backward computation.
I0912 06:19:01.029603 28411 net.cpp:226] upsample1 needs backward computation.
I0912 06:19:01.029606 28411 net.cpp:226] relu2_1_D needs backward computation.
I0912 06:19:01.029609 28411 net.cpp:226] conv2_1_D_scale needs backward computation.
I0912 06:19:01.029613 28411 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0912 06:19:01.029615 28411 net.cpp:226] conv2_1_D needs backward computation.
I0912 06:19:01.029618 28411 net.cpp:226] relu2_2_D needs backward computation.
I0912 06:19:01.029623 28411 net.cpp:226] conv2_2_D_scale needs backward computation.
I0912 06:19:01.029625 28411 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0912 06:19:01.029628 28411 net.cpp:226] conv2_2_D needs backward computation.
I0912 06:19:01.029631 28411 net.cpp:226] upsample2 needs backward computation.
I0912 06:19:01.029637 28411 net.cpp:226] relu3_1_D needs backward computation.
I0912 06:19:01.029640 28411 net.cpp:226] conv3_1_D_scale needs backward computation.
I0912 06:19:01.029642 28411 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0912 06:19:01.029645 28411 net.cpp:226] conv3_1_D needs backward computation.
I0912 06:19:01.029649 28411 net.cpp:226] relu3_2_D needs backward computation.
I0912 06:19:01.029651 28411 net.cpp:226] conv3_2_D_scale needs backward computation.
I0912 06:19:01.029654 28411 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0912 06:19:01.029657 28411 net.cpp:226] conv3_2_D needs backward computation.
I0912 06:19:01.029660 28411 net.cpp:226] relu3_3_D needs backward computation.
I0912 06:19:01.029664 28411 net.cpp:226] conv3_3_D_scale needs backward computation.
I0912 06:19:01.029667 28411 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0912 06:19:01.029683 28411 net.cpp:226] conv3_3_D needs backward computation.
I0912 06:19:01.029687 28411 net.cpp:226] upsample3 needs backward computation.
I0912 06:19:01.029691 28411 net.cpp:226] relu4_1_D needs backward computation.
I0912 06:19:01.029695 28411 net.cpp:226] conv4_1_D_scale needs backward computation.
I0912 06:19:01.029697 28411 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0912 06:19:01.029700 28411 net.cpp:226] conv4_1_D needs backward computation.
I0912 06:19:01.029703 28411 net.cpp:226] relu4_2_D needs backward computation.
I0912 06:19:01.029707 28411 net.cpp:226] conv4_2_D_scale needs backward computation.
I0912 06:19:01.029711 28411 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0912 06:19:01.029713 28411 net.cpp:226] conv4_2_D needs backward computation.
I0912 06:19:01.029718 28411 net.cpp:226] relu4_3_D needs backward computation.
I0912 06:19:01.029721 28411 net.cpp:226] conv4_3_D_scale needs backward computation.
I0912 06:19:01.029724 28411 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0912 06:19:01.029728 28411 net.cpp:226] conv4_3_D needs backward computation.
I0912 06:19:01.029731 28411 net.cpp:226] upsample4 needs backward computation.
I0912 06:19:01.029736 28411 net.cpp:226] relu5_1_D needs backward computation.
I0912 06:19:01.029739 28411 net.cpp:226] conv5_1_D_scale needs backward computation.
I0912 06:19:01.029743 28411 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0912 06:19:01.029747 28411 net.cpp:226] conv5_1_D needs backward computation.
I0912 06:19:01.029750 28411 net.cpp:226] relu5_2_D needs backward computation.
I0912 06:19:01.029753 28411 net.cpp:226] conv5_2_D_scale needs backward computation.
I0912 06:19:01.029757 28411 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0912 06:19:01.029762 28411 net.cpp:226] conv5_2_D needs backward computation.
I0912 06:19:01.029767 28411 net.cpp:226] relu5_3_D needs backward computation.
I0912 06:19:01.029769 28411 net.cpp:226] conv5_3_D_scale needs backward computation.
I0912 06:19:01.029772 28411 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0912 06:19:01.029777 28411 net.cpp:226] conv5_3_D needs backward computation.
I0912 06:19:01.029779 28411 net.cpp:226] upsample5 needs backward computation.
I0912 06:19:01.029785 28411 net.cpp:226] pool5 needs backward computation.
I0912 06:19:01.029790 28411 net.cpp:226] relu5_3 needs backward computation.
I0912 06:19:01.029794 28411 net.cpp:226] conv5_3_scale needs backward computation.
I0912 06:19:01.029798 28411 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0912 06:19:01.029801 28411 net.cpp:226] conv5_3 needs backward computation.
I0912 06:19:01.029806 28411 net.cpp:226] relu5_2 needs backward computation.
I0912 06:19:01.029810 28411 net.cpp:226] conv5_2_scale needs backward computation.
I0912 06:19:01.029814 28411 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0912 06:19:01.029819 28411 net.cpp:226] conv5_2 needs backward computation.
I0912 06:19:01.029824 28411 net.cpp:226] relu5_1 needs backward computation.
I0912 06:19:01.029827 28411 net.cpp:226] conv5_1_scale needs backward computation.
I0912 06:19:01.029830 28411 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0912 06:19:01.029834 28411 net.cpp:226] conv5_1 needs backward computation.
I0912 06:19:01.029839 28411 net.cpp:226] pool4 needs backward computation.
I0912 06:19:01.029844 28411 net.cpp:226] relu4_3 needs backward computation.
I0912 06:19:01.029846 28411 net.cpp:226] conv4_3_scale needs backward computation.
I0912 06:19:01.029850 28411 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0912 06:19:01.029855 28411 net.cpp:226] conv4_3 needs backward computation.
I0912 06:19:01.029857 28411 net.cpp:226] relu4_2 needs backward computation.
I0912 06:19:01.029860 28411 net.cpp:226] conv4_2_scale needs backward computation.
I0912 06:19:01.029863 28411 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0912 06:19:01.029870 28411 net.cpp:226] conv4_2 needs backward computation.
I0912 06:19:01.029872 28411 net.cpp:226] relu4_1 needs backward computation.
I0912 06:19:01.029883 28411 net.cpp:226] conv4_1_scale needs backward computation.
I0912 06:19:01.029886 28411 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0912 06:19:01.029891 28411 net.cpp:226] conv4_1 needs backward computation.
I0912 06:19:01.029893 28411 net.cpp:226] pool3 needs backward computation.
I0912 06:19:01.029898 28411 net.cpp:226] relu3_3 needs backward computation.
I0912 06:19:01.029902 28411 net.cpp:226] conv3_3_scale needs backward computation.
I0912 06:19:01.029906 28411 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0912 06:19:01.029911 28411 net.cpp:226] conv3_3 needs backward computation.
I0912 06:19:01.029913 28411 net.cpp:226] relu3_2 needs backward computation.
I0912 06:19:01.029918 28411 net.cpp:226] conv3_2_scale needs backward computation.
I0912 06:19:01.029922 28411 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0912 06:19:01.029925 28411 net.cpp:226] conv3_2 needs backward computation.
I0912 06:19:01.029929 28411 net.cpp:226] relu3_1 needs backward computation.
I0912 06:19:01.029932 28411 net.cpp:226] conv3_1_scale needs backward computation.
I0912 06:19:01.029935 28411 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0912 06:19:01.029940 28411 net.cpp:226] conv3_1 needs backward computation.
I0912 06:19:01.029944 28411 net.cpp:226] pool2 needs backward computation.
I0912 06:19:01.029952 28411 net.cpp:226] relu2_2 needs backward computation.
I0912 06:19:01.029955 28411 net.cpp:226] conv2_2_scale needs backward computation.
I0912 06:19:01.029959 28411 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0912 06:19:01.029964 28411 net.cpp:226] conv2_2 needs backward computation.
I0912 06:19:01.029969 28411 net.cpp:226] relu2_1 needs backward computation.
I0912 06:19:01.029973 28411 net.cpp:226] conv2_1_scale needs backward computation.
I0912 06:19:01.029975 28411 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0912 06:19:01.029979 28411 net.cpp:226] conv2_1 needs backward computation.
I0912 06:19:01.029985 28411 net.cpp:226] pool1 needs backward computation.
I0912 06:19:01.029990 28411 net.cpp:226] relu1_2 needs backward computation.
I0912 06:19:01.029994 28411 net.cpp:226] conv1_2_scale needs backward computation.
I0912 06:19:01.029999 28411 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0912 06:19:01.030004 28411 net.cpp:226] conv1_2 needs backward computation.
I0912 06:19:01.030006 28411 net.cpp:226] relu1_1 needs backward computation.
I0912 06:19:01.030010 28411 net.cpp:226] conv1_1_1_scale needs backward computation.
I0912 06:19:01.030014 28411 net.cpp:226] conv1_1_1_bn needs backward computation.
I0912 06:19:01.030017 28411 net.cpp:226] conv1_1_1 needs backward computation.
I0912 06:19:01.030021 28411 net.cpp:228] label_data_1_split does not need backward computation.
I0912 06:19:01.030027 28411 net.cpp:228] data does not need backward computation.
I0912 06:19:01.030030 28411 net.cpp:270] This network produces output accuracy
I0912 06:19:01.030035 28411 net.cpp:270] This network produces output loss
I0912 06:19:01.030037 28411 net.cpp:270] This network produces output per_class_accuracy
I0912 06:19:01.030102 28411 net.cpp:283] Network initialization done.
I0912 06:19:01.030463 28411 solver.cpp:60] Solver scaffolding done.
I0912 06:19:01.040025 28411 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0912 06:19:01.929687 28411 net.cpp:761] Ignoring source layer conv1_1
I0912 06:19:01.929715 28411 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 06:19:01.929765 28411 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 06:19:01.929774 28411 net.cpp:761] Ignoring source layer pool1_drop
I0912 06:19:01.929849 28411 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 06:19:01.930007 28411 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 06:19:01.930014 28411 net.cpp:761] Ignoring source layer pool2_drop
I0912 06:19:01.930369 28411 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 06:19:01.931071 28411 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 06:19:01.931658 28411 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 06:19:01.931687 28411 net.cpp:761] Ignoring source layer pool3_drop
I0912 06:19:01.932973 28411 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 06:19:01.935322 28411 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 06:19:01.937710 28411 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 06:19:01.937719 28411 net.cpp:761] Ignoring source layer pool4_drop
I0912 06:19:01.940057 28411 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 06:19:01.942582 28411 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 06:19:01.945371 28411 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 06:19:01.945379 28411 net.cpp:761] Ignoring source layer pool5_drop
I0912 06:19:01.945384 28411 net.cpp:761] Ignoring source layer upsample5_drop
I0912 06:19:01.948164 28411 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 06:19:01.950484 28411 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 06:19:01.953039 28411 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 06:19:01.953049 28411 net.cpp:761] Ignoring source layer upsample4_drop
I0912 06:19:01.955121 28411 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 06:19:01.957512 28411 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 06:19:01.958575 28411 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 06:19:01.958585 28411 net.cpp:761] Ignoring source layer upsample3_drop
I0912 06:19:01.959125 28411 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 06:19:01.959707 28411 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 06:19:01.960032 28411 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 06:19:01.960039 28411 net.cpp:761] Ignoring source layer upsample2_drop
I0912 06:19:01.960214 28411 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 06:19:01.960311 28411 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 06:19:01.960317 28411 net.cpp:761] Ignoring source layer upsample1_drop
I0912 06:19:01.960371 28411 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 06:19:01.960377 28411 net.cpp:761] Ignoring source layer conv1_1_D
I0912 06:19:01.960381 28411 net.cpp:761] Ignoring source layer prob
I0912 06:19:02.197585 28411 net.cpp:761] Ignoring source layer conv1_1
I0912 06:19:02.197607 28411 net.cpp:761] Ignoring source layer conv1_1_bn
I0912 06:19:02.197665 28411 net.cpp:761] Ignoring source layer conv1_2_bn
I0912 06:19:02.197672 28411 net.cpp:761] Ignoring source layer pool1_drop
I0912 06:19:02.197752 28411 net.cpp:761] Ignoring source layer conv2_1_bn
I0912 06:19:02.197935 28411 net.cpp:761] Ignoring source layer conv2_2_bn
I0912 06:19:02.197942 28411 net.cpp:761] Ignoring source layer pool2_drop
I0912 06:19:02.198288 28411 net.cpp:761] Ignoring source layer conv3_1_bn
I0912 06:19:02.198961 28411 net.cpp:761] Ignoring source layer conv3_2_bn
I0912 06:19:02.199632 28411 net.cpp:761] Ignoring source layer conv3_3_bn
I0912 06:19:02.199640 28411 net.cpp:761] Ignoring source layer pool3_drop
I0912 06:19:02.200873 28411 net.cpp:761] Ignoring source layer conv4_1_bn
I0912 06:19:02.203359 28411 net.cpp:761] Ignoring source layer conv4_2_bn
I0912 06:19:02.205478 28411 net.cpp:761] Ignoring source layer conv4_3_bn
I0912 06:19:02.205487 28411 net.cpp:761] Ignoring source layer pool4_drop
I0912 06:19:02.207610 28411 net.cpp:761] Ignoring source layer conv5_1_bn
I0912 06:19:02.209746 28411 net.cpp:761] Ignoring source layer conv5_2_bn
I0912 06:19:02.211941 28411 net.cpp:761] Ignoring source layer conv5_3_bn
I0912 06:19:02.211948 28411 net.cpp:761] Ignoring source layer pool5_drop
I0912 06:19:02.211953 28411 net.cpp:761] Ignoring source layer upsample5_drop
I0912 06:19:02.214419 28411 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0912 06:19:02.216846 28411 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0912 06:19:02.218987 28411 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0912 06:19:02.218996 28411 net.cpp:761] Ignoring source layer upsample4_drop
I0912 06:19:02.221026 28411 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0912 06:19:02.223096 28411 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0912 06:19:02.224184 28411 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0912 06:19:02.224191 28411 net.cpp:761] Ignoring source layer upsample3_drop
I0912 06:19:02.224758 28411 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0912 06:19:02.225328 28411 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0912 06:19:02.225678 28411 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0912 06:19:02.225685 28411 net.cpp:761] Ignoring source layer upsample2_drop
I0912 06:19:02.225860 28411 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0912 06:19:02.225958 28411 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0912 06:19:02.225965 28411 net.cpp:761] Ignoring source layer upsample1_drop
I0912 06:19:02.226023 28411 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0912 06:19:02.226029 28411 net.cpp:761] Ignoring source layer conv1_1_D
I0912 06:19:02.226033 28411 net.cpp:761] Ignoring source layer prob
I0912 06:19:02.234040 28411 caffe.cpp:251] Starting Optimization
I0912 06:19:02.234062 28411 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0912 06:19:02.234067 28411 solver.cpp:280] Learning Rate Policy: step
I0912 06:19:03.216202 28411 solver.cpp:228] Iteration 0, loss = 0.989256
I0912 06:19:03.216240 28411 solver.cpp:244]     Train net output #0: accuracy = 0.2498
I0912 06:19:03.216254 28411 solver.cpp:244]     Train net output #1: loss = 0.989256 (* 1 = 0.989256 loss)
I0912 06:19:03.216266 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.206367
I0912 06:19:03.216270 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.500549
I0912 06:19:03.216294 28411 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0912 06:19:19.405707 28411 solver.cpp:228] Iteration 20, loss = 0.517122
I0912 06:19:19.405751 28411 solver.cpp:244]     Train net output #0: accuracy = 0.743097
I0912 06:19:19.405762 28411 solver.cpp:244]     Train net output #1: loss = 0.517122 (* 1 = 0.517122 loss)
I0912 06:19:19.405768 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.637096
I0912 06:19:19.405773 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.93863
I0912 06:19:19.405779 28411 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0912 06:19:35.980088 28411 solver.cpp:228] Iteration 40, loss = 0.324213
I0912 06:19:35.980227 28411 solver.cpp:244]     Train net output #0: accuracy = 0.841008
I0912 06:19:35.980242 28411 solver.cpp:244]     Train net output #1: loss = 0.324213 (* 1 = 0.324213 loss)
I0912 06:19:35.980247 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.773139
I0912 06:19:35.980252 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986557
I0912 06:19:35.980259 28411 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0912 06:19:52.567155 28411 solver.cpp:228] Iteration 60, loss = 0.255991
I0912 06:19:52.567200 28411 solver.cpp:244]     Train net output #0: accuracy = 0.912433
I0912 06:19:52.567212 28411 solver.cpp:244]     Train net output #1: loss = 0.255991 (* 1 = 0.255991 loss)
I0912 06:19:52.567219 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.85932
I0912 06:19:52.567224 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980471
I0912 06:19:52.567230 28411 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0912 06:20:09.151072 28411 solver.cpp:228] Iteration 80, loss = 0.199704
I0912 06:20:09.151213 28411 solver.cpp:244]     Train net output #0: accuracy = 0.898579
I0912 06:20:09.151227 28411 solver.cpp:244]     Train net output #1: loss = 0.199704 (* 1 = 0.199704 loss)
I0912 06:20:09.151232 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.862427
I0912 06:20:09.151237 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984491
I0912 06:20:09.151243 28411 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0912 06:20:25.739789 28411 solver.cpp:228] Iteration 100, loss = 0.299147
I0912 06:20:25.739827 28411 solver.cpp:244]     Train net output #0: accuracy = 0.866299
I0912 06:20:25.739838 28411 solver.cpp:244]     Train net output #1: loss = 0.299147 (* 1 = 0.299147 loss)
I0912 06:20:25.739843 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.810864
I0912 06:20:25.739848 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987472
I0912 06:20:25.739856 28411 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0912 06:20:42.338613 28411 solver.cpp:228] Iteration 120, loss = 0.223377
I0912 06:20:42.338796 28411 solver.cpp:244]     Train net output #0: accuracy = 0.870888
I0912 06:20:42.338819 28411 solver.cpp:244]     Train net output #1: loss = 0.223378 (* 1 = 0.223378 loss)
I0912 06:20:42.338826 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.810432
I0912 06:20:42.338830 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995315
I0912 06:20:42.338837 28411 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0912 06:20:58.932958 28411 solver.cpp:228] Iteration 140, loss = 0.176802
I0912 06:20:58.932997 28411 solver.cpp:244]     Train net output #0: accuracy = 0.954064
I0912 06:20:58.933009 28411 solver.cpp:244]     Train net output #1: loss = 0.176802 (* 1 = 0.176802 loss)
I0912 06:20:58.933014 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.962134
I0912 06:20:58.933019 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.945696
I0912 06:20:58.933027 28411 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0912 06:21:15.519647 28411 solver.cpp:228] Iteration 160, loss = 0.0900158
I0912 06:21:15.519757 28411 solver.cpp:244]     Train net output #0: accuracy = 0.971756
I0912 06:21:15.519771 28411 solver.cpp:244]     Train net output #1: loss = 0.0900159 (* 1 = 0.0900159 loss)
I0912 06:21:15.519776 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.959333
I0912 06:21:15.519781 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983582
I0912 06:21:15.519788 28411 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0912 06:21:32.107563 28411 solver.cpp:228] Iteration 180, loss = 0.159589
I0912 06:21:32.107604 28411 solver.cpp:244]     Train net output #0: accuracy = 0.930058
I0912 06:21:32.107615 28411 solver.cpp:244]     Train net output #1: loss = 0.159589 (* 1 = 0.159589 loss)
I0912 06:21:32.107621 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.918558
I0912 06:21:32.107626 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.941933
I0912 06:21:32.107632 28411 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0912 06:21:48.687085 28411 solver.cpp:228] Iteration 200, loss = 0.147401
I0912 06:21:48.687207 28411 solver.cpp:244]     Train net output #0: accuracy = 0.940966
I0912 06:21:48.687219 28411 solver.cpp:244]     Train net output #1: loss = 0.147401 (* 1 = 0.147401 loss)
I0912 06:21:48.687232 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.905314
I0912 06:21:48.687237 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984301
I0912 06:21:48.687242 28411 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0912 06:22:05.285739 28411 solver.cpp:228] Iteration 220, loss = 0.0866068
I0912 06:22:05.285782 28411 solver.cpp:244]     Train net output #0: accuracy = 0.956985
I0912 06:22:05.285795 28411 solver.cpp:244]     Train net output #1: loss = 0.0866068 (* 1 = 0.0866068 loss)
I0912 06:22:05.285801 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.935984
I0912 06:22:05.285805 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993116
I0912 06:22:05.285812 28411 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0912 06:22:21.868499 28411 solver.cpp:228] Iteration 240, loss = 0.0915904
I0912 06:22:21.868613 28411 solver.cpp:244]     Train net output #0: accuracy = 0.970399
I0912 06:22:21.868626 28411 solver.cpp:244]     Train net output #1: loss = 0.0915904 (* 1 = 0.0915904 loss)
I0912 06:22:21.868631 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.963999
I0912 06:22:21.868635 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976097
I0912 06:22:21.868643 28411 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0912 06:22:38.459312 28411 solver.cpp:228] Iteration 260, loss = 0.0686136
I0912 06:22:38.459352 28411 solver.cpp:244]     Train net output #0: accuracy = 0.97718
I0912 06:22:38.459364 28411 solver.cpp:244]     Train net output #1: loss = 0.0686136 (* 1 = 0.0686136 loss)
I0912 06:22:38.459370 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.963235
I0912 06:22:38.459374 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989677
I0912 06:22:38.459383 28411 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0912 06:22:55.040568 28411 solver.cpp:228] Iteration 280, loss = 0.0390426
I0912 06:22:55.040726 28411 solver.cpp:244]     Train net output #0: accuracy = 0.990027
I0912 06:22:55.040742 28411 solver.cpp:244]     Train net output #1: loss = 0.0390426 (* 1 = 0.0390426 loss)
I0912 06:22:55.040751 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985473
I0912 06:22:55.040755 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994039
I0912 06:22:55.040762 28411 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0912 06:23:11.632625 28411 solver.cpp:228] Iteration 300, loss = 0.0265717
I0912 06:23:11.632665 28411 solver.cpp:244]     Train net output #0: accuracy = 0.991322
I0912 06:23:11.632676 28411 solver.cpp:244]     Train net output #1: loss = 0.0265717 (* 1 = 0.0265717 loss)
I0912 06:23:11.632683 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986609
I0912 06:23:11.632686 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998588
I0912 06:23:11.632694 28411 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0912 06:23:28.234869 28411 solver.cpp:228] Iteration 320, loss = 0.0347391
I0912 06:23:28.234990 28411 solver.cpp:244]     Train net output #0: accuracy = 0.988273
I0912 06:23:28.235005 28411 solver.cpp:244]     Train net output #1: loss = 0.034739 (* 1 = 0.034739 loss)
I0912 06:23:28.235015 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982211
I0912 06:23:28.235020 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997453
I0912 06:23:28.235026 28411 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0912 06:23:44.814358 28411 solver.cpp:228] Iteration 340, loss = 0.147772
I0912 06:23:44.814399 28411 solver.cpp:244]     Train net output #0: accuracy = 0.927598
I0912 06:23:44.814411 28411 solver.cpp:244]     Train net output #1: loss = 0.147772 (* 1 = 0.147772 loss)
I0912 06:23:44.814417 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.883316
I0912 06:23:44.814421 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997293
I0912 06:23:44.814429 28411 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0912 06:24:01.401651 28411 solver.cpp:228] Iteration 360, loss = 0.0525687
I0912 06:24:01.401787 28411 solver.cpp:244]     Train net output #0: accuracy = 0.977221
I0912 06:24:01.401801 28411 solver.cpp:244]     Train net output #1: loss = 0.0525686 (* 1 = 0.0525686 loss)
I0912 06:24:01.401808 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.967706
I0912 06:24:01.401813 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993732
I0912 06:24:01.401820 28411 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0912 06:24:18.007640 28411 solver.cpp:228] Iteration 380, loss = 0.049652
I0912 06:24:18.007679 28411 solver.cpp:244]     Train net output #0: accuracy = 0.980175
I0912 06:24:18.007690 28411 solver.cpp:244]     Train net output #1: loss = 0.0496519 (* 1 = 0.0496519 loss)
I0912 06:24:18.007696 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.962586
I0912 06:24:18.007700 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996308
I0912 06:24:18.007707 28411 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0912 06:24:34.616181 28411 solver.cpp:228] Iteration 400, loss = 0.104757
I0912 06:24:34.616300 28411 solver.cpp:244]     Train net output #0: accuracy = 0.96593
I0912 06:24:34.616314 28411 solver.cpp:244]     Train net output #1: loss = 0.104757 (* 1 = 0.104757 loss)
I0912 06:24:34.616320 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.955373
I0912 06:24:34.616324 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.974272
I0912 06:24:34.616331 28411 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0912 06:24:51.206382 28411 solver.cpp:228] Iteration 420, loss = 0.0426634
I0912 06:24:51.206424 28411 solver.cpp:244]     Train net output #0: accuracy = 0.984761
I0912 06:24:51.206439 28411 solver.cpp:244]     Train net output #1: loss = 0.0426634 (* 1 = 0.0426634 loss)
I0912 06:24:51.206444 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978501
I0912 06:24:51.206449 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990858
I0912 06:24:51.206456 28411 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0912 06:25:07.798609 28411 solver.cpp:228] Iteration 440, loss = 0.0324796
I0912 06:25:07.798820 28411 solver.cpp:244]     Train net output #0: accuracy = 0.988417
I0912 06:25:07.798835 28411 solver.cpp:244]     Train net output #1: loss = 0.0324796 (* 1 = 0.0324796 loss)
I0912 06:25:07.798840 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98671
I0912 06:25:07.798844 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992733
I0912 06:25:07.798851 28411 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0912 06:25:24.701552 28411 solver.cpp:228] Iteration 460, loss = 0.0638364
I0912 06:25:24.701594 28411 solver.cpp:244]     Train net output #0: accuracy = 0.9766
I0912 06:25:24.701606 28411 solver.cpp:244]     Train net output #1: loss = 0.0638363 (* 1 = 0.0638363 loss)
I0912 06:25:24.701611 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.971025
I0912 06:25:24.701617 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994504
I0912 06:25:24.701622 28411 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0912 06:25:41.300976 28411 solver.cpp:228] Iteration 480, loss = 0.025614
I0912 06:25:41.301141 28411 solver.cpp:244]     Train net output #0: accuracy = 0.989878
I0912 06:25:41.301177 28411 solver.cpp:244]     Train net output #1: loss = 0.025614 (* 1 = 0.025614 loss)
I0912 06:25:41.301185 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985986
I0912 06:25:41.301190 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996576
I0912 06:25:41.301198 28411 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0912 06:25:57.935534 28411 solver.cpp:228] Iteration 500, loss = 0.0108873
I0912 06:25:57.935575 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997089
I0912 06:25:57.935586 28411 solver.cpp:244]     Train net output #1: loss = 0.0108873 (* 1 = 0.0108873 loss)
I0912 06:25:57.935592 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996377
I0912 06:25:57.935597 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998587
I0912 06:25:57.935606 28411 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0912 06:26:14.535918 28411 solver.cpp:228] Iteration 520, loss = 0.0189329
I0912 06:26:14.536075 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99263
I0912 06:26:14.536090 28411 solver.cpp:244]     Train net output #1: loss = 0.0189328 (* 1 = 0.0189328 loss)
I0912 06:26:14.536098 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989404
I0912 06:26:14.536103 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996889
I0912 06:26:14.536109 28411 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0912 06:26:31.223950 28411 solver.cpp:228] Iteration 540, loss = 0.0209715
I0912 06:26:31.223992 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993022
I0912 06:26:31.224004 28411 solver.cpp:244]     Train net output #1: loss = 0.0209715 (* 1 = 0.0209715 loss)
I0912 06:26:31.224009 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987674
I0912 06:26:31.224014 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997696
I0912 06:26:31.224021 28411 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0912 06:26:47.828716 28411 solver.cpp:228] Iteration 560, loss = 0.0376265
I0912 06:26:47.828910 28411 solver.cpp:244]     Train net output #0: accuracy = 0.990101
I0912 06:26:47.828933 28411 solver.cpp:244]     Train net output #1: loss = 0.0376264 (* 1 = 0.0376264 loss)
I0912 06:26:47.828939 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992287
I0912 06:26:47.828944 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988313
I0912 06:26:47.828951 28411 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0912 06:27:04.425761 28411 solver.cpp:228] Iteration 580, loss = 0.035223
I0912 06:27:04.425803 28411 solver.cpp:244]     Train net output #0: accuracy = 0.990787
I0912 06:27:04.425817 28411 solver.cpp:244]     Train net output #1: loss = 0.0352229 (* 1 = 0.0352229 loss)
I0912 06:27:04.425822 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9894
I0912 06:27:04.425827 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996052
I0912 06:27:04.425834 28411 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0912 06:27:21.030854 28411 solver.cpp:228] Iteration 600, loss = 0.0197178
I0912 06:27:21.030993 28411 solver.cpp:244]     Train net output #0: accuracy = 0.992944
I0912 06:27:21.031008 28411 solver.cpp:244]     Train net output #1: loss = 0.0197177 (* 1 = 0.0197177 loss)
I0912 06:27:21.031013 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99188
I0912 06:27:21.031018 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994246
I0912 06:27:21.031025 28411 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0912 06:27:37.623805 28411 solver.cpp:228] Iteration 620, loss = 0.0290419
I0912 06:27:37.623841 28411 solver.cpp:244]     Train net output #0: accuracy = 0.98864
I0912 06:27:37.623852 28411 solver.cpp:244]     Train net output #1: loss = 0.0290419 (* 1 = 0.0290419 loss)
I0912 06:27:37.623858 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986081
I0912 06:27:37.623862 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992471
I0912 06:27:37.623869 28411 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0912 06:27:54.225050 28411 solver.cpp:228] Iteration 640, loss = 0.0223708
I0912 06:27:54.225179 28411 solver.cpp:244]     Train net output #0: accuracy = 0.990288
I0912 06:27:54.225193 28411 solver.cpp:244]     Train net output #1: loss = 0.0223707 (* 1 = 0.0223707 loss)
I0912 06:27:54.225204 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983395
I0912 06:27:54.225209 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997567
I0912 06:27:54.225216 28411 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0912 06:28:10.863382 28411 solver.cpp:228] Iteration 660, loss = 0.0584736
I0912 06:28:10.863427 28411 solver.cpp:244]     Train net output #0: accuracy = 0.989398
I0912 06:28:10.863440 28411 solver.cpp:244]     Train net output #1: loss = 0.0584735 (* 1 = 0.0584735 loss)
I0912 06:28:10.863445 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98777
I0912 06:28:10.863451 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989984
I0912 06:28:10.863457 28411 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0912 06:28:27.462450 28411 solver.cpp:228] Iteration 680, loss = 0.0204508
I0912 06:28:27.462579 28411 solver.cpp:244]     Train net output #0: accuracy = 0.992935
I0912 06:28:27.462592 28411 solver.cpp:244]     Train net output #1: loss = 0.0204507 (* 1 = 0.0204507 loss)
I0912 06:28:27.462602 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992981
I0912 06:28:27.462607 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992858
I0912 06:28:27.462615 28411 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0912 06:28:44.078567 28411 solver.cpp:228] Iteration 700, loss = 0.0305718
I0912 06:28:44.078611 28411 solver.cpp:244]     Train net output #0: accuracy = 0.990524
I0912 06:28:44.078624 28411 solver.cpp:244]     Train net output #1: loss = 0.0305717 (* 1 = 0.0305717 loss)
I0912 06:28:44.078639 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988438
I0912 06:28:44.078644 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999385
I0912 06:28:44.078650 28411 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0912 06:29:00.687803 28411 solver.cpp:228] Iteration 720, loss = 0.0485647
I0912 06:29:00.688002 28411 solver.cpp:244]     Train net output #0: accuracy = 0.988332
I0912 06:29:00.688021 28411 solver.cpp:244]     Train net output #1: loss = 0.0485646 (* 1 = 0.0485646 loss)
I0912 06:29:00.688030 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98766
I0912 06:29:00.688035 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992507
I0912 06:29:00.688045 28411 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0912 06:29:17.292307 28411 solver.cpp:228] Iteration 740, loss = 0.0262995
I0912 06:29:17.292345 28411 solver.cpp:244]     Train net output #0: accuracy = 0.989764
I0912 06:29:17.292356 28411 solver.cpp:244]     Train net output #1: loss = 0.0262995 (* 1 = 0.0262995 loss)
I0912 06:29:17.292361 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986441
I0912 06:29:17.292366 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993616
I0912 06:29:17.292373 28411 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0912 06:29:33.889734 28411 solver.cpp:228] Iteration 760, loss = 0.0242361
I0912 06:29:33.889860 28411 solver.cpp:244]     Train net output #0: accuracy = 0.9901
I0912 06:29:33.889875 28411 solver.cpp:244]     Train net output #1: loss = 0.0242361 (* 1 = 0.0242361 loss)
I0912 06:29:33.889883 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983022
I0912 06:29:33.889888 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996423
I0912 06:29:33.889894 28411 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0912 06:29:50.503927 28411 solver.cpp:228] Iteration 780, loss = 0.0273521
I0912 06:29:50.503968 28411 solver.cpp:244]     Train net output #0: accuracy = 0.990107
I0912 06:29:50.503978 28411 solver.cpp:244]     Train net output #1: loss = 0.0273521 (* 1 = 0.0273521 loss)
I0912 06:29:50.503984 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984392
I0912 06:29:50.503989 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994688
I0912 06:29:50.503998 28411 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0912 06:30:07.116971 28411 solver.cpp:228] Iteration 800, loss = 0.0455441
I0912 06:30:07.117102 28411 solver.cpp:244]     Train net output #0: accuracy = 0.982928
I0912 06:30:07.117126 28411 solver.cpp:244]     Train net output #1: loss = 0.0455441 (* 1 = 0.0455441 loss)
I0912 06:30:07.117132 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97965
I0912 06:30:07.117137 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987297
I0912 06:30:07.117144 28411 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0912 06:30:23.724453 28411 solver.cpp:228] Iteration 820, loss = 0.0368064
I0912 06:30:23.724493 28411 solver.cpp:244]     Train net output #0: accuracy = 0.984473
I0912 06:30:23.724506 28411 solver.cpp:244]     Train net output #1: loss = 0.0368064 (* 1 = 0.0368064 loss)
I0912 06:30:23.724512 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981881
I0912 06:30:23.724517 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989611
I0912 06:30:23.724524 28411 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0912 06:30:40.322850 28411 solver.cpp:228] Iteration 840, loss = 0.0242895
I0912 06:30:40.322971 28411 solver.cpp:244]     Train net output #0: accuracy = 0.992786
I0912 06:30:40.322988 28411 solver.cpp:244]     Train net output #1: loss = 0.0242894 (* 1 = 0.0242894 loss)
I0912 06:30:40.322993 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99435
I0912 06:30:40.322999 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987784
I0912 06:30:40.323005 28411 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0912 06:30:56.940680 28411 solver.cpp:228] Iteration 860, loss = 0.0400857
I0912 06:30:56.940717 28411 solver.cpp:244]     Train net output #0: accuracy = 0.983061
I0912 06:30:56.940732 28411 solver.cpp:244]     Train net output #1: loss = 0.0400857 (* 1 = 0.0400857 loss)
I0912 06:30:56.940737 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97714
I0912 06:30:56.940742 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991757
I0912 06:30:56.940749 28411 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0912 06:31:13.544595 28411 solver.cpp:228] Iteration 880, loss = 0.0229296
I0912 06:31:13.544757 28411 solver.cpp:244]     Train net output #0: accuracy = 0.98952
I0912 06:31:13.544780 28411 solver.cpp:244]     Train net output #1: loss = 0.0229296 (* 1 = 0.0229296 loss)
I0912 06:31:13.544798 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986506
I0912 06:31:13.544805 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995279
I0912 06:31:13.544812 28411 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0912 06:31:30.141355 28411 solver.cpp:228] Iteration 900, loss = 0.0293484
I0912 06:31:30.141404 28411 solver.cpp:244]     Train net output #0: accuracy = 0.986205
I0912 06:31:30.141417 28411 solver.cpp:244]     Train net output #1: loss = 0.0293483 (* 1 = 0.0293483 loss)
I0912 06:31:30.141422 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977522
I0912 06:31:30.141427 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996965
I0912 06:31:30.141434 28411 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0912 06:31:46.750015 28411 solver.cpp:228] Iteration 920, loss = 0.0177097
I0912 06:31:46.750118 28411 solver.cpp:244]     Train net output #0: accuracy = 0.992008
I0912 06:31:46.750133 28411 solver.cpp:244]     Train net output #1: loss = 0.0177097 (* 1 = 0.0177097 loss)
I0912 06:31:46.750142 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986217
I0912 06:31:46.750147 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998229
I0912 06:31:46.750154 28411 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0912 06:32:03.357863 28411 solver.cpp:228] Iteration 940, loss = 0.0413733
I0912 06:32:03.357908 28411 solver.cpp:244]     Train net output #0: accuracy = 0.989426
I0912 06:32:03.357921 28411 solver.cpp:244]     Train net output #1: loss = 0.0413732 (* 1 = 0.0413732 loss)
I0912 06:32:03.357928 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991084
I0912 06:32:03.357933 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980133
I0912 06:32:03.357939 28411 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0912 06:32:19.963026 28411 solver.cpp:228] Iteration 960, loss = 0.0143943
I0912 06:32:19.963131 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99424
I0912 06:32:19.963146 28411 solver.cpp:244]     Train net output #1: loss = 0.0143943 (* 1 = 0.0143943 loss)
I0912 06:32:19.963155 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992885
I0912 06:32:19.963160 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996167
I0912 06:32:19.963166 28411 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0912 06:32:36.569145 28411 solver.cpp:228] Iteration 980, loss = 0.0348967
I0912 06:32:36.569182 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99148
I0912 06:32:36.569193 28411 solver.cpp:244]     Train net output #1: loss = 0.0348967 (* 1 = 0.0348967 loss)
I0912 06:32:36.569200 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992424
I0912 06:32:36.569213 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986022
I0912 06:32:36.569221 28411 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0912 06:32:53.167925 28411 solver.cpp:228] Iteration 1000, loss = 0.0130147
I0912 06:32:53.168020 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995919
I0912 06:32:53.168035 28411 solver.cpp:244]     Train net output #1: loss = 0.0130147 (* 1 = 0.0130147 loss)
I0912 06:32:53.168042 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996292
I0912 06:32:53.168047 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994752
I0912 06:32:53.168056 28411 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0912 06:33:09.771636 28411 solver.cpp:228] Iteration 1020, loss = 0.0124229
I0912 06:33:09.771677 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995729
I0912 06:33:09.771688 28411 solver.cpp:244]     Train net output #1: loss = 0.0124228 (* 1 = 0.0124228 loss)
I0912 06:33:09.771694 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996062
I0912 06:33:09.771699 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995352
I0912 06:33:09.771706 28411 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0912 06:33:26.385830 28411 solver.cpp:228] Iteration 1040, loss = 0.0126686
I0912 06:33:26.385984 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995304
I0912 06:33:26.386006 28411 solver.cpp:244]     Train net output #1: loss = 0.0126685 (* 1 = 0.0126685 loss)
I0912 06:33:26.386013 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995476
I0912 06:33:26.386018 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994922
I0912 06:33:26.386025 28411 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0912 06:33:43.003370 28411 solver.cpp:228] Iteration 1060, loss = 0.0180449
I0912 06:33:43.003412 28411 solver.cpp:244]     Train net output #0: accuracy = 0.992733
I0912 06:33:43.003423 28411 solver.cpp:244]     Train net output #1: loss = 0.0180449 (* 1 = 0.0180449 loss)
I0912 06:33:43.003429 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991733
I0912 06:33:43.003434 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994148
I0912 06:33:43.003442 28411 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0912 06:33:59.605573 28411 solver.cpp:228] Iteration 1080, loss = 0.0160812
I0912 06:33:59.605677 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993183
I0912 06:33:59.605693 28411 solver.cpp:244]     Train net output #1: loss = 0.0160812 (* 1 = 0.0160812 loss)
I0912 06:33:59.605700 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987257
I0912 06:33:59.605705 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998061
I0912 06:33:59.605712 28411 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0912 06:34:16.208813 28411 solver.cpp:228] Iteration 1100, loss = 0.0223756
I0912 06:34:16.208849 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994748
I0912 06:34:16.208863 28411 solver.cpp:244]     Train net output #1: loss = 0.0223756 (* 1 = 0.0223756 loss)
I0912 06:34:16.208869 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991919
I0912 06:34:16.208874 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996106
I0912 06:34:16.208881 28411 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0912 06:34:32.806247 28411 solver.cpp:228] Iteration 1120, loss = 0.0163151
I0912 06:34:32.806344 28411 solver.cpp:244]     Train net output #0: accuracy = 0.992614
I0912 06:34:32.806357 28411 solver.cpp:244]     Train net output #1: loss = 0.016315 (* 1 = 0.016315 loss)
I0912 06:34:32.806363 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988037
I0912 06:34:32.806368 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997945
I0912 06:34:32.806375 28411 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0912 06:34:49.403297 28411 solver.cpp:228] Iteration 1140, loss = 0.0223268
I0912 06:34:49.403340 28411 solver.cpp:244]     Train net output #0: accuracy = 0.991144
I0912 06:34:49.403354 28411 solver.cpp:244]     Train net output #1: loss = 0.0223268 (* 1 = 0.0223268 loss)
I0912 06:34:49.403359 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986621
I0912 06:34:49.403364 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995064
I0912 06:34:49.403372 28411 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0912 06:35:06.007308 28411 solver.cpp:228] Iteration 1160, loss = 0.0145142
I0912 06:35:06.007455 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993556
I0912 06:35:06.007475 28411 solver.cpp:244]     Train net output #1: loss = 0.0145142 (* 1 = 0.0145142 loss)
I0912 06:35:06.007483 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988616
I0912 06:35:06.007488 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998194
I0912 06:35:06.007493 28411 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0912 06:35:22.600523 28411 solver.cpp:228] Iteration 1180, loss = 0.0165587
I0912 06:35:22.600567 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994505
I0912 06:35:22.600580 28411 solver.cpp:244]     Train net output #1: loss = 0.0165586 (* 1 = 0.0165586 loss)
I0912 06:35:22.600586 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993292
I0912 06:35:22.600590 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995448
I0912 06:35:22.600597 28411 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0912 06:35:39.206704 28411 solver.cpp:228] Iteration 1200, loss = 0.019889
I0912 06:35:39.206799 28411 solver.cpp:244]     Train net output #0: accuracy = 0.991736
I0912 06:35:39.206814 28411 solver.cpp:244]     Train net output #1: loss = 0.0198889 (* 1 = 0.0198889 loss)
I0912 06:35:39.206820 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99003
I0912 06:35:39.206823 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995405
I0912 06:35:39.206830 28411 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0912 06:35:55.799382 28411 solver.cpp:228] Iteration 1220, loss = 0.0167847
I0912 06:35:55.799420 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993527
I0912 06:35:55.799434 28411 solver.cpp:244]     Train net output #1: loss = 0.0167847 (* 1 = 0.0167847 loss)
I0912 06:35:55.799439 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993099
I0912 06:35:55.799444 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994329
I0912 06:35:55.799451 28411 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0912 06:36:12.401466 28411 solver.cpp:228] Iteration 1240, loss = 0.0274604
I0912 06:36:12.401559 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994466
I0912 06:36:12.401574 28411 solver.cpp:244]     Train net output #1: loss = 0.0274604 (* 1 = 0.0274604 loss)
I0912 06:36:12.401581 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995121
I0912 06:36:12.401585 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990099
I0912 06:36:12.401592 28411 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0912 06:36:29.018826 28411 solver.cpp:228] Iteration 1260, loss = 0.0126163
I0912 06:36:29.018867 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996292
I0912 06:36:29.018880 28411 solver.cpp:244]     Train net output #1: loss = 0.0126162 (* 1 = 0.0126162 loss)
I0912 06:36:29.018885 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997777
I0912 06:36:29.018892 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99195
I0912 06:36:29.018898 28411 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0912 06:36:45.614387 28411 solver.cpp:228] Iteration 1280, loss = 0.0180499
I0912 06:36:45.614485 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993426
I0912 06:36:45.614501 28411 solver.cpp:244]     Train net output #1: loss = 0.0180499 (* 1 = 0.0180499 loss)
I0912 06:36:45.614506 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994155
I0912 06:36:45.614511 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992388
I0912 06:36:45.614518 28411 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0912 06:37:02.244915 28411 solver.cpp:228] Iteration 1300, loss = 0.0187485
I0912 06:37:02.244956 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995126
I0912 06:37:02.244968 28411 solver.cpp:244]     Train net output #1: loss = 0.0187484 (* 1 = 0.0187484 loss)
I0912 06:37:02.244974 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991696
I0912 06:37:02.244979 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996976
I0912 06:37:02.244985 28411 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0912 06:37:18.847803 28411 solver.cpp:228] Iteration 1320, loss = 0.0121454
I0912 06:37:18.847950 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994595
I0912 06:37:18.847967 28411 solver.cpp:244]     Train net output #1: loss = 0.0121454 (* 1 = 0.0121454 loss)
I0912 06:37:18.847980 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992916
I0912 06:37:18.847986 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997449
I0912 06:37:18.847996 28411 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0912 06:37:35.460978 28411 solver.cpp:228] Iteration 1340, loss = 0.0248164
I0912 06:37:35.461016 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993766
I0912 06:37:35.461030 28411 solver.cpp:244]     Train net output #1: loss = 0.0248164 (* 1 = 0.0248164 loss)
I0912 06:37:35.461036 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993941
I0912 06:37:35.461041 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992726
I0912 06:37:35.461048 28411 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0912 06:37:52.055953 28411 solver.cpp:228] Iteration 1360, loss = 0.0180485
I0912 06:37:52.056056 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993022
I0912 06:37:52.056071 28411 solver.cpp:244]     Train net output #1: loss = 0.0180485 (* 1 = 0.0180485 loss)
I0912 06:37:52.056077 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988179
I0912 06:37:52.056082 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996684
I0912 06:37:52.056089 28411 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0912 06:38:08.657968 28411 solver.cpp:228] Iteration 1380, loss = 0.0104189
I0912 06:38:08.658010 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996042
I0912 06:38:08.658025 28411 solver.cpp:244]     Train net output #1: loss = 0.0104188 (* 1 = 0.0104188 loss)
I0912 06:38:08.658030 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995801
I0912 06:38:08.658035 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996434
I0912 06:38:08.658042 28411 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0912 06:38:25.254304 28411 solver.cpp:228] Iteration 1400, loss = 0.015209
I0912 06:38:25.254415 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994067
I0912 06:38:25.254429 28411 solver.cpp:244]     Train net output #1: loss = 0.0152089 (* 1 = 0.0152089 loss)
I0912 06:38:25.254436 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989961
I0912 06:38:25.254441 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997378
I0912 06:38:25.254447 28411 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0912 06:38:41.857059 28411 solver.cpp:228] Iteration 1420, loss = 0.00891682
I0912 06:38:41.857101 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996549
I0912 06:38:41.857115 28411 solver.cpp:244]     Train net output #1: loss = 0.00891678 (* 1 = 0.00891678 loss)
I0912 06:38:41.857120 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995574
I0912 06:38:41.857125 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997658
I0912 06:38:41.857132 28411 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0912 06:38:58.473765 28411 solver.cpp:228] Iteration 1440, loss = 0.0088111
I0912 06:38:58.473886 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996487
I0912 06:38:58.473901 28411 solver.cpp:244]     Train net output #1: loss = 0.00881106 (* 1 = 0.00881106 loss)
I0912 06:38:58.473907 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994527
I0912 06:38:58.473912 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998352
I0912 06:38:58.473919 28411 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0912 06:39:15.088063 28411 solver.cpp:228] Iteration 1460, loss = 0.0181347
I0912 06:39:15.088100 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994554
I0912 06:39:15.088114 28411 solver.cpp:244]     Train net output #1: loss = 0.0181346 (* 1 = 0.0181346 loss)
I0912 06:39:15.088120 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994579
I0912 06:39:15.088124 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994425
I0912 06:39:15.088132 28411 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0912 06:39:31.686800 28411 solver.cpp:228] Iteration 1480, loss = 0.0179586
I0912 06:39:31.686961 28411 solver.cpp:244]     Train net output #0: accuracy = 0.991972
I0912 06:39:31.686978 28411 solver.cpp:244]     Train net output #1: loss = 0.0179585 (* 1 = 0.0179585 loss)
I0912 06:39:31.686985 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98404
I0912 06:39:31.686990 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997919
I0912 06:39:31.686997 28411 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0912 06:39:48.288516 28411 solver.cpp:228] Iteration 1500, loss = 0.0193005
I0912 06:39:48.288558 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99389
I0912 06:39:48.288570 28411 solver.cpp:244]     Train net output #1: loss = 0.0193004 (* 1 = 0.0193004 loss)
I0912 06:39:48.288576 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99435
I0912 06:39:48.288583 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991746
I0912 06:39:48.288590 28411 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0912 06:40:04.881394 28411 solver.cpp:228] Iteration 1520, loss = 0.00983763
I0912 06:40:04.881513 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995796
I0912 06:40:04.881530 28411 solver.cpp:244]     Train net output #1: loss = 0.00983759 (* 1 = 0.00983759 loss)
I0912 06:40:04.881536 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99461
I0912 06:40:04.881541 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997893
I0912 06:40:04.881548 28411 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0912 06:40:21.482853 28411 solver.cpp:228] Iteration 1540, loss = 0.0147917
I0912 06:40:21.482893 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993571
I0912 06:40:21.482908 28411 solver.cpp:244]     Train net output #1: loss = 0.0147917 (* 1 = 0.0147917 loss)
I0912 06:40:21.482913 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991936
I0912 06:40:21.482918 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996283
I0912 06:40:21.482924 28411 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0912 06:40:38.088629 28411 solver.cpp:228] Iteration 1560, loss = 0.0144501
I0912 06:40:38.088733 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994187
I0912 06:40:38.088747 28411 solver.cpp:244]     Train net output #1: loss = 0.0144501 (* 1 = 0.0144501 loss)
I0912 06:40:38.088753 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992689
I0912 06:40:38.088764 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995834
I0912 06:40:38.088771 28411 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0912 06:40:54.687994 28411 solver.cpp:228] Iteration 1580, loss = 0.00670289
I0912 06:40:54.688036 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997156
I0912 06:40:54.688050 28411 solver.cpp:244]     Train net output #1: loss = 0.00670285 (* 1 = 0.00670285 loss)
I0912 06:40:54.688056 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995984
I0912 06:40:54.688060 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998798
I0912 06:40:54.688067 28411 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0912 06:41:11.296430 28411 solver.cpp:228] Iteration 1600, loss = 0.124706
I0912 06:41:11.296591 28411 solver.cpp:244]     Train net output #0: accuracy = 0.961875
I0912 06:41:11.296607 28411 solver.cpp:244]     Train net output #1: loss = 0.124706 (* 1 = 0.124706 loss)
I0912 06:41:11.296612 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.959721
I0912 06:41:11.296617 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999892
I0912 06:41:11.296624 28411 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0912 06:41:27.890316 28411 solver.cpp:228] Iteration 1620, loss = 0.0178106
I0912 06:41:27.890359 28411 solver.cpp:244]     Train net output #0: accuracy = 0.991461
I0912 06:41:27.890373 28411 solver.cpp:244]     Train net output #1: loss = 0.0178105 (* 1 = 0.0178105 loss)
I0912 06:41:27.890379 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983253
I0912 06:41:27.890384 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998614
I0912 06:41:27.890391 28411 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0912 06:41:44.494887 28411 solver.cpp:228] Iteration 1640, loss = 0.0191495
I0912 06:41:44.494997 28411 solver.cpp:244]     Train net output #0: accuracy = 0.992757
I0912 06:41:44.495012 28411 solver.cpp:244]     Train net output #1: loss = 0.0191494 (* 1 = 0.0191494 loss)
I0912 06:41:44.495016 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992884
I0912 06:41:44.495021 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992559
I0912 06:41:44.495028 28411 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0912 06:42:01.086673 28411 solver.cpp:228] Iteration 1660, loss = 0.0144123
I0912 06:42:01.086714 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996581
I0912 06:42:01.086729 28411 solver.cpp:244]     Train net output #1: loss = 0.0144123 (* 1 = 0.0144123 loss)
I0912 06:42:01.086735 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997412
I0912 06:42:01.086738 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99236
I0912 06:42:01.086745 28411 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0912 06:42:17.666196 28411 solver.cpp:228] Iteration 1680, loss = 0.0136824
I0912 06:42:17.666298 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995062
I0912 06:42:17.666312 28411 solver.cpp:244]     Train net output #1: loss = 0.0136824 (* 1 = 0.0136824 loss)
I0912 06:42:17.666317 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994954
I0912 06:42:17.666322 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995454
I0912 06:42:17.666330 28411 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0912 06:42:34.256523 28411 solver.cpp:228] Iteration 1700, loss = 0.0122999
I0912 06:42:34.256566 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995185
I0912 06:42:34.256577 28411 solver.cpp:244]     Train net output #1: loss = 0.0122999 (* 1 = 0.0122999 loss)
I0912 06:42:34.256583 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995097
I0912 06:42:34.256588 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995328
I0912 06:42:34.256595 28411 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0912 06:42:50.862443 28411 solver.cpp:228] Iteration 1720, loss = 0.0133408
I0912 06:42:50.862556 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995353
I0912 06:42:50.862571 28411 solver.cpp:244]     Train net output #1: loss = 0.0133408 (* 1 = 0.0133408 loss)
I0912 06:42:50.862577 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994923
I0912 06:42:50.862581 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99575
I0912 06:42:50.862589 28411 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0912 06:43:07.461542 28411 solver.cpp:228] Iteration 1740, loss = 0.0112103
I0912 06:43:07.461583 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995404
I0912 06:43:07.461596 28411 solver.cpp:244]     Train net output #1: loss = 0.0112103 (* 1 = 0.0112103 loss)
I0912 06:43:07.461601 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994361
I0912 06:43:07.461606 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996919
I0912 06:43:07.461612 28411 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0912 06:43:24.062522 28411 solver.cpp:228] Iteration 1760, loss = 0.0181172
I0912 06:43:24.062696 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993533
I0912 06:43:24.062714 28411 solver.cpp:244]     Train net output #1: loss = 0.0181171 (* 1 = 0.0181171 loss)
I0912 06:43:24.062726 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995362
I0912 06:43:24.062734 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989724
I0912 06:43:24.062741 28411 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0912 06:43:40.669963 28411 solver.cpp:228] Iteration 1780, loss = 0.014431
I0912 06:43:40.670004 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994239
I0912 06:43:40.670018 28411 solver.cpp:244]     Train net output #1: loss = 0.014431 (* 1 = 0.014431 loss)
I0912 06:43:40.670024 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993005
I0912 06:43:40.670029 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99591
I0912 06:43:40.670037 28411 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0912 06:43:57.274423 28411 solver.cpp:228] Iteration 1800, loss = 0.0142678
I0912 06:43:57.274538 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995354
I0912 06:43:57.274552 28411 solver.cpp:244]     Train net output #1: loss = 0.0142677 (* 1 = 0.0142677 loss)
I0912 06:43:57.274557 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996991
I0912 06:43:57.274562 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990614
I0912 06:43:57.274569 28411 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0912 06:44:13.883802 28411 solver.cpp:228] Iteration 1820, loss = 0.0108339
I0912 06:44:13.883846 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995463
I0912 06:44:13.883859 28411 solver.cpp:244]     Train net output #1: loss = 0.0108339 (* 1 = 0.0108339 loss)
I0912 06:44:13.883865 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995075
I0912 06:44:13.883870 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996327
I0912 06:44:13.883878 28411 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0912 06:44:30.476032 28411 solver.cpp:228] Iteration 1840, loss = 0.00577742
I0912 06:44:30.476145 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99797
I0912 06:44:30.476160 28411 solver.cpp:244]     Train net output #1: loss = 0.00577738 (* 1 = 0.00577738 loss)
I0912 06:44:30.476166 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997663
I0912 06:44:30.476171 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998288
I0912 06:44:30.476177 28411 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0912 06:44:47.083375 28411 solver.cpp:228] Iteration 1860, loss = 0.00988908
I0912 06:44:47.083420 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996641
I0912 06:44:47.083433 28411 solver.cpp:244]     Train net output #1: loss = 0.00988904 (* 1 = 0.00988904 loss)
I0912 06:44:47.083439 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997389
I0912 06:44:47.083444 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995196
I0912 06:44:47.083451 28411 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0912 06:45:03.696872 28411 solver.cpp:228] Iteration 1880, loss = 0.0111678
I0912 06:45:03.696993 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994816
I0912 06:45:03.697008 28411 solver.cpp:244]     Train net output #1: loss = 0.0111677 (* 1 = 0.0111677 loss)
I0912 06:45:03.697015 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99257
I0912 06:45:03.697026 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997954
I0912 06:45:03.697033 28411 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0912 06:45:20.292246 28411 solver.cpp:228] Iteration 1900, loss = 0.0126069
I0912 06:45:20.292289 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995651
I0912 06:45:20.292304 28411 solver.cpp:244]     Train net output #1: loss = 0.0126068 (* 1 = 0.0126068 loss)
I0912 06:45:20.292310 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992998
I0912 06:45:20.292315 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997464
I0912 06:45:20.292323 28411 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0912 06:45:36.899791 28411 solver.cpp:228] Iteration 1920, loss = 0.00942681
I0912 06:45:36.899965 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996082
I0912 06:45:36.899982 28411 solver.cpp:244]     Train net output #1: loss = 0.00942678 (* 1 = 0.00942678 loss)
I0912 06:45:36.899988 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995183
I0912 06:45:36.899992 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997818
I0912 06:45:36.899999 28411 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0912 06:45:53.518636 28411 solver.cpp:228] Iteration 1940, loss = 0.00888728
I0912 06:45:53.518676 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996029
I0912 06:45:53.518687 28411 solver.cpp:244]     Train net output #1: loss = 0.00888724 (* 1 = 0.00888724 loss)
I0912 06:45:53.518693 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995078
I0912 06:45:53.518698 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998064
I0912 06:45:53.518705 28411 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0912 06:46:10.154307 28411 solver.cpp:228] Iteration 1960, loss = 0.00822874
I0912 06:46:10.154443 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996644
I0912 06:46:10.154459 28411 solver.cpp:244]     Train net output #1: loss = 0.0082287 (* 1 = 0.0082287 loss)
I0912 06:46:10.154465 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996279
I0912 06:46:10.154469 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997608
I0912 06:46:10.154476 28411 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0912 06:46:26.759198 28411 solver.cpp:228] Iteration 1980, loss = 0.0112618
I0912 06:46:26.759239 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995198
I0912 06:46:26.759251 28411 solver.cpp:244]     Train net output #1: loss = 0.0112617 (* 1 = 0.0112617 loss)
I0912 06:46:26.759258 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991633
I0912 06:46:26.759263 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998284
I0912 06:46:26.759269 28411 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0912 06:46:43.349162 28411 solver.cpp:228] Iteration 2000, loss = 0.0131711
I0912 06:46:43.349279 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994455
I0912 06:46:43.349295 28411 solver.cpp:244]     Train net output #1: loss = 0.0131711 (* 1 = 0.0131711 loss)
I0912 06:46:43.349301 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993977
I0912 06:46:43.349305 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995855
I0912 06:46:43.349313 28411 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0912 06:46:59.955381 28411 solver.cpp:228] Iteration 2020, loss = 0.00658038
I0912 06:46:59.955421 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996999
I0912 06:46:59.955433 28411 solver.cpp:244]     Train net output #1: loss = 0.00658034 (* 1 = 0.00658034 loss)
I0912 06:46:59.955438 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995363
I0912 06:46:59.955443 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999054
I0912 06:46:59.955451 28411 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0912 06:47:16.541877 28411 solver.cpp:228] Iteration 2040, loss = 0.0278439
I0912 06:47:16.541986 28411 solver.cpp:244]     Train net output #0: accuracy = 0.990304
I0912 06:47:16.542002 28411 solver.cpp:244]     Train net output #1: loss = 0.0278438 (* 1 = 0.0278438 loss)
I0912 06:47:16.542008 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987766
I0912 06:47:16.542013 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99301
I0912 06:47:16.542021 28411 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0912 06:47:33.147053 28411 solver.cpp:228] Iteration 2060, loss = 0.0192814
I0912 06:47:33.147096 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993194
I0912 06:47:33.147109 28411 solver.cpp:244]     Train net output #1: loss = 0.0192813 (* 1 = 0.0192813 loss)
I0912 06:47:33.147116 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99416
I0912 06:47:33.147121 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991866
I0912 06:47:33.147128 28411 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0912 06:47:49.755726 28411 solver.cpp:228] Iteration 2080, loss = 0.0110367
I0912 06:47:49.755897 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996076
I0912 06:47:49.755913 28411 solver.cpp:244]     Train net output #1: loss = 0.0110367 (* 1 = 0.0110367 loss)
I0912 06:47:49.755918 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996206
I0912 06:47:49.755923 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995801
I0912 06:47:49.755929 28411 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0912 06:48:06.359920 28411 solver.cpp:228] Iteration 2100, loss = 0.0110768
I0912 06:48:06.359963 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995603
I0912 06:48:06.359977 28411 solver.cpp:244]     Train net output #1: loss = 0.0110767 (* 1 = 0.0110767 loss)
I0912 06:48:06.359983 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995324
I0912 06:48:06.359987 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996287
I0912 06:48:06.359994 28411 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0912 06:48:22.971132 28411 solver.cpp:228] Iteration 2120, loss = 0.00880428
I0912 06:48:22.971243 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997076
I0912 06:48:22.971259 28411 solver.cpp:244]     Train net output #1: loss = 0.00880423 (* 1 = 0.00880423 loss)
I0912 06:48:22.971266 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997886
I0912 06:48:22.971271 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995602
I0912 06:48:22.971276 28411 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0912 06:48:39.572320 28411 solver.cpp:228] Iteration 2140, loss = 0.0188196
I0912 06:48:39.572365 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993035
I0912 06:48:39.572381 28411 solver.cpp:244]     Train net output #1: loss = 0.0188195 (* 1 = 0.0188195 loss)
I0912 06:48:39.572387 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992728
I0912 06:48:39.572393 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993524
I0912 06:48:39.572402 28411 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0912 06:48:56.166146 28411 solver.cpp:228] Iteration 2160, loss = 0.0131333
I0912 06:48:56.166265 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994745
I0912 06:48:56.166281 28411 solver.cpp:244]     Train net output #1: loss = 0.0131332 (* 1 = 0.0131332 loss)
I0912 06:48:56.166287 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993894
I0912 06:48:56.166292 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995957
I0912 06:48:56.166299 28411 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0912 06:49:12.782606 28411 solver.cpp:228] Iteration 2180, loss = 0.0200126
I0912 06:49:12.782646 28411 solver.cpp:244]     Train net output #0: accuracy = 0.991487
I0912 06:49:12.782660 28411 solver.cpp:244]     Train net output #1: loss = 0.0200126 (* 1 = 0.0200126 loss)
I0912 06:49:12.782665 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987209
I0912 06:49:12.782670 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996191
I0912 06:49:12.782677 28411 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0912 06:49:29.379691 28411 solver.cpp:228] Iteration 2200, loss = 0.023164
I0912 06:49:29.379863 28411 solver.cpp:244]     Train net output #0: accuracy = 0.990809
I0912 06:49:29.379879 28411 solver.cpp:244]     Train net output #1: loss = 0.0231639 (* 1 = 0.0231639 loss)
I0912 06:49:29.379884 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988773
I0912 06:49:29.379889 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993329
I0912 06:49:29.379896 28411 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0912 06:49:45.988303 28411 solver.cpp:228] Iteration 2220, loss = 0.0153895
I0912 06:49:45.988343 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993283
I0912 06:49:45.988355 28411 solver.cpp:244]     Train net output #1: loss = 0.0153894 (* 1 = 0.0153894 loss)
I0912 06:49:45.988361 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991417
I0912 06:49:45.988368 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996001
I0912 06:49:45.988373 28411 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0912 06:50:02.580338 28411 solver.cpp:228] Iteration 2240, loss = 0.0298086
I0912 06:50:02.580471 28411 solver.cpp:244]     Train net output #0: accuracy = 0.986845
I0912 06:50:02.580487 28411 solver.cpp:244]     Train net output #1: loss = 0.0298086 (* 1 = 0.0298086 loss)
I0912 06:50:02.580493 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984008
I0912 06:50:02.580498 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994114
I0912 06:50:02.580507 28411 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0912 06:50:19.190481 28411 solver.cpp:228] Iteration 2260, loss = 0.00955345
I0912 06:50:19.190522 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995903
I0912 06:50:19.190534 28411 solver.cpp:244]     Train net output #1: loss = 0.0095534 (* 1 = 0.0095534 loss)
I0912 06:50:19.190541 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993821
I0912 06:50:19.190546 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998182
I0912 06:50:19.190553 28411 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0912 06:50:35.797044 28411 solver.cpp:228] Iteration 2280, loss = 0.0128326
I0912 06:50:35.797153 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994569
I0912 06:50:35.797168 28411 solver.cpp:244]     Train net output #1: loss = 0.0128325 (* 1 = 0.0128325 loss)
I0912 06:50:35.797173 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994254
I0912 06:50:35.797178 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995327
I0912 06:50:35.797185 28411 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0912 06:50:52.400609 28411 solver.cpp:228] Iteration 2300, loss = 0.0135089
I0912 06:50:52.400652 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994693
I0912 06:50:52.400666 28411 solver.cpp:244]     Train net output #1: loss = 0.0135088 (* 1 = 0.0135088 loss)
I0912 06:50:52.400672 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994007
I0912 06:50:52.400676 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995434
I0912 06:50:52.400683 28411 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0912 06:51:09.014097 28411 solver.cpp:228] Iteration 2320, loss = 0.0109893
I0912 06:51:09.014204 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995512
I0912 06:51:09.014217 28411 solver.cpp:244]     Train net output #1: loss = 0.0109893 (* 1 = 0.0109893 loss)
I0912 06:51:09.014225 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9922
I0912 06:51:09.014230 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99821
I0912 06:51:09.014236 28411 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0912 06:51:25.620873 28411 solver.cpp:228] Iteration 2340, loss = 0.00613087
I0912 06:51:25.620916 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997348
I0912 06:51:25.620930 28411 solver.cpp:244]     Train net output #1: loss = 0.00613082 (* 1 = 0.00613082 loss)
I0912 06:51:25.620937 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99677
I0912 06:51:25.620942 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998807
I0912 06:51:25.620949 28411 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0912 06:51:42.218111 28411 solver.cpp:228] Iteration 2360, loss = 0.00631283
I0912 06:51:42.218271 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997681
I0912 06:51:42.218286 28411 solver.cpp:244]     Train net output #1: loss = 0.00631278 (* 1 = 0.00631278 loss)
I0912 06:51:42.218291 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997717
I0912 06:51:42.218297 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997593
I0912 06:51:42.218304 28411 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0912 06:51:58.814447 28411 solver.cpp:228] Iteration 2380, loss = 0.0126609
I0912 06:51:58.814491 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994802
I0912 06:51:58.814505 28411 solver.cpp:244]     Train net output #1: loss = 0.0126608 (* 1 = 0.0126608 loss)
I0912 06:51:58.814512 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994241
I0912 06:51:58.814517 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996701
I0912 06:51:58.814527 28411 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0912 06:52:15.408805 28411 solver.cpp:228] Iteration 2400, loss = 0.0113281
I0912 06:52:15.408936 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99637
I0912 06:52:15.408973 28411 solver.cpp:244]     Train net output #1: loss = 0.011328 (* 1 = 0.011328 loss)
I0912 06:52:15.408982 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995032
I0912 06:52:15.408987 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997302
I0912 06:52:15.408996 28411 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0912 06:52:32.012605 28411 solver.cpp:228] Iteration 2420, loss = 0.00421755
I0912 06:52:32.012650 28411 solver.cpp:244]     Train net output #0: accuracy = 0.998155
I0912 06:52:32.012663 28411 solver.cpp:244]     Train net output #1: loss = 0.0042175 (* 1 = 0.0042175 loss)
I0912 06:52:32.012668 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997599
I0912 06:52:32.012673 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999173
I0912 06:52:32.012681 28411 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0912 06:52:48.619124 28411 solver.cpp:228] Iteration 2440, loss = 0.00595005
I0912 06:52:48.619257 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99764
I0912 06:52:48.619272 28411 solver.cpp:244]     Train net output #1: loss = 0.00595 (* 1 = 0.00595 loss)
I0912 06:52:48.619283 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996927
I0912 06:52:48.619288 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998373
I0912 06:52:48.619295 28411 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0912 06:53:05.219341 28411 solver.cpp:228] Iteration 2460, loss = 0.0111968
I0912 06:53:05.219382 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996073
I0912 06:53:05.219394 28411 solver.cpp:244]     Train net output #1: loss = 0.0111967 (* 1 = 0.0111967 loss)
I0912 06:53:05.219400 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997057
I0912 06:53:05.219405 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993944
I0912 06:53:05.219413 28411 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0912 06:53:21.827622 28411 solver.cpp:228] Iteration 2480, loss = 0.0108114
I0912 06:53:21.827754 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996104
I0912 06:53:21.827769 28411 solver.cpp:244]     Train net output #1: loss = 0.0108114 (* 1 = 0.0108114 loss)
I0912 06:53:21.827782 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993066
I0912 06:53:21.827786 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998042
I0912 06:53:21.827793 28411 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0912 06:53:38.424849 28411 solver.cpp:228] Iteration 2500, loss = 0.0103939
I0912 06:53:38.424891 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995514
I0912 06:53:38.424904 28411 solver.cpp:244]     Train net output #1: loss = 0.0103938 (* 1 = 0.0103938 loss)
I0912 06:53:38.424911 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994331
I0912 06:53:38.424916 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997407
I0912 06:53:38.424922 28411 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0912 06:53:55.018254 28411 solver.cpp:228] Iteration 2520, loss = 0.0129107
I0912 06:53:55.018419 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994599
I0912 06:53:55.018435 28411 solver.cpp:244]     Train net output #1: loss = 0.0129107 (* 1 = 0.0129107 loss)
I0912 06:53:55.018447 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990938
I0912 06:53:55.018452 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997811
I0912 06:53:55.018465 28411 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0912 06:54:11.610227 28411 solver.cpp:228] Iteration 2540, loss = 0.0123171
I0912 06:54:11.610270 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995677
I0912 06:54:11.610285 28411 solver.cpp:244]     Train net output #1: loss = 0.0123171 (* 1 = 0.0123171 loss)
I0912 06:54:11.610291 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994994
I0912 06:54:11.610296 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996584
I0912 06:54:11.610303 28411 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0912 06:54:28.218971 28411 solver.cpp:228] Iteration 2560, loss = 0.0117774
I0912 06:54:28.219085 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995132
I0912 06:54:28.219100 28411 solver.cpp:244]     Train net output #1: loss = 0.0117774 (* 1 = 0.0117774 loss)
I0912 06:54:28.219106 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991324
I0912 06:54:28.219111 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998157
I0912 06:54:28.219118 28411 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0912 06:54:44.843183 28411 solver.cpp:228] Iteration 2580, loss = 0.0100493
I0912 06:54:44.843226 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995875
I0912 06:54:44.843240 28411 solver.cpp:244]     Train net output #1: loss = 0.0100492 (* 1 = 0.0100492 loss)
I0912 06:54:44.843245 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995175
I0912 06:54:44.843250 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996933
I0912 06:54:44.843257 28411 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0912 06:55:01.436589 28411 solver.cpp:228] Iteration 2600, loss = 0.00771011
I0912 06:55:01.436702 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996571
I0912 06:55:01.436717 28411 solver.cpp:244]     Train net output #1: loss = 0.00771006 (* 1 = 0.00771006 loss)
I0912 06:55:01.436723 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994824
I0912 06:55:01.436735 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998643
I0912 06:55:01.436743 28411 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0912 06:55:18.046012 28411 solver.cpp:228] Iteration 2620, loss = 0.0120325
I0912 06:55:18.046049 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994883
I0912 06:55:18.046061 28411 solver.cpp:244]     Train net output #1: loss = 0.0120325 (* 1 = 0.0120325 loss)
I0912 06:55:18.046067 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991986
I0912 06:55:18.046072 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99768
I0912 06:55:18.046079 28411 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0912 06:55:34.652319 28411 solver.cpp:228] Iteration 2640, loss = 0.0101103
I0912 06:55:34.652438 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995768
I0912 06:55:34.652454 28411 solver.cpp:244]     Train net output #1: loss = 0.0101102 (* 1 = 0.0101102 loss)
I0912 06:55:34.652465 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994989
I0912 06:55:34.652470 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997053
I0912 06:55:34.652477 28411 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0912 06:55:51.251102 28411 solver.cpp:228] Iteration 2660, loss = 0.00627642
I0912 06:55:51.251144 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997836
I0912 06:55:51.251157 28411 solver.cpp:244]     Train net output #1: loss = 0.00627637 (* 1 = 0.00627637 loss)
I0912 06:55:51.251163 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998166
I0912 06:55:51.251168 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997451
I0912 06:55:51.251175 28411 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0912 06:56:07.838734 28411 solver.cpp:228] Iteration 2680, loss = 0.0100389
I0912 06:56:07.838922 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996102
I0912 06:56:07.838939 28411 solver.cpp:244]     Train net output #1: loss = 0.0100388 (* 1 = 0.0100388 loss)
I0912 06:56:07.838948 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996141
I0912 06:56:07.838954 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995996
I0912 06:56:07.838961 28411 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0912 06:56:24.451009 28411 solver.cpp:228] Iteration 2700, loss = 0.0122702
I0912 06:56:24.451050 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994876
I0912 06:56:24.451061 28411 solver.cpp:244]     Train net output #1: loss = 0.0122702 (* 1 = 0.0122702 loss)
I0912 06:56:24.451067 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991425
I0912 06:56:24.451072 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997664
I0912 06:56:24.451079 28411 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0912 06:56:41.064103 28411 solver.cpp:228] Iteration 2720, loss = 0.0122789
I0912 06:56:41.064224 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996124
I0912 06:56:41.064240 28411 solver.cpp:244]     Train net output #1: loss = 0.0122789 (* 1 = 0.0122789 loss)
I0912 06:56:41.064254 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994037
I0912 06:56:41.064267 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997341
I0912 06:56:41.064275 28411 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0912 06:56:57.686547 28411 solver.cpp:228] Iteration 2740, loss = 0.00995437
I0912 06:56:57.686584 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995418
I0912 06:56:57.686597 28411 solver.cpp:244]     Train net output #1: loss = 0.00995431 (* 1 = 0.00995431 loss)
I0912 06:56:57.686604 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992366
I0912 06:56:57.686609 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998663
I0912 06:56:57.686617 28411 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0912 06:57:14.292546 28411 solver.cpp:228] Iteration 2760, loss = 0.00986479
I0912 06:57:14.292665 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995992
I0912 06:57:14.292680 28411 solver.cpp:244]     Train net output #1: loss = 0.00986474 (* 1 = 0.00986474 loss)
I0912 06:57:14.292686 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995335
I0912 06:57:14.292698 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99698
I0912 06:57:14.292706 28411 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0912 06:57:30.886464 28411 solver.cpp:228] Iteration 2780, loss = 0.00724604
I0912 06:57:30.886507 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996675
I0912 06:57:30.886521 28411 solver.cpp:244]     Train net output #1: loss = 0.00724598 (* 1 = 0.00724598 loss)
I0912 06:57:30.886529 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995758
I0912 06:57:30.886534 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998694
I0912 06:57:30.886541 28411 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0912 06:57:47.489141 28411 solver.cpp:228] Iteration 2800, loss = 0.0128567
I0912 06:57:47.489300 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994666
I0912 06:57:47.489315 28411 solver.cpp:244]     Train net output #1: loss = 0.0128567 (* 1 = 0.0128567 loss)
I0912 06:57:47.489320 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994112
I0912 06:57:47.489326 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99666
I0912 06:57:47.489332 28411 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0912 06:58:04.097582 28411 solver.cpp:228] Iteration 2820, loss = 0.00788058
I0912 06:58:04.097625 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996785
I0912 06:58:04.097638 28411 solver.cpp:244]     Train net output #1: loss = 0.00788052 (* 1 = 0.00788052 loss)
I0912 06:58:04.097645 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995843
I0912 06:58:04.097651 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997892
I0912 06:58:04.097656 28411 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0912 06:58:20.694260 28411 solver.cpp:228] Iteration 2840, loss = 0.012519
I0912 06:58:20.694381 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994948
I0912 06:58:20.694396 28411 solver.cpp:244]     Train net output #1: loss = 0.012519 (* 1 = 0.012519 loss)
I0912 06:58:20.694401 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994803
I0912 06:58:20.694406 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995188
I0912 06:58:20.694413 28411 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0912 06:58:37.308799 28411 solver.cpp:228] Iteration 2860, loss = 0.00786201
I0912 06:58:37.308835 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996438
I0912 06:58:37.308850 28411 solver.cpp:244]     Train net output #1: loss = 0.00786196 (* 1 = 0.00786196 loss)
I0912 06:58:37.308856 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99481
I0912 06:58:37.308861 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998349
I0912 06:58:37.308876 28411 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0912 06:58:53.913152 28411 solver.cpp:228] Iteration 2880, loss = 0.00814549
I0912 06:58:53.913260 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996594
I0912 06:58:53.913276 28411 solver.cpp:244]     Train net output #1: loss = 0.00814544 (* 1 = 0.00814544 loss)
I0912 06:58:53.913282 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994691
I0912 06:58:53.913287 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998413
I0912 06:58:53.913295 28411 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0912 06:59:10.513711 28411 solver.cpp:228] Iteration 2900, loss = 0.0101813
I0912 06:59:10.513753 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996633
I0912 06:59:10.513767 28411 solver.cpp:244]     Train net output #1: loss = 0.0101812 (* 1 = 0.0101812 loss)
I0912 06:59:10.513772 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996663
I0912 06:59:10.513777 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996501
I0912 06:59:10.513783 28411 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0912 06:59:27.113282 28411 solver.cpp:228] Iteration 2920, loss = 0.0132632
I0912 06:59:27.113415 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994946
I0912 06:59:27.113459 28411 solver.cpp:244]     Train net output #1: loss = 0.0132632 (* 1 = 0.0132632 loss)
I0912 06:59:27.113467 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994949
I0912 06:59:27.113481 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994943
I0912 06:59:27.113489 28411 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0912 06:59:43.824439 28411 solver.cpp:228] Iteration 2940, loss = 0.00838971
I0912 06:59:43.824484 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996691
I0912 06:59:43.824497 28411 solver.cpp:244]     Train net output #1: loss = 0.00838966 (* 1 = 0.00838966 loss)
I0912 06:59:43.824503 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996148
I0912 06:59:43.824509 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99739
I0912 06:59:43.824517 28411 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0912 07:00:00.532102 28411 solver.cpp:228] Iteration 2960, loss = 0.00508657
I0912 07:00:00.532248 28411 solver.cpp:244]     Train net output #0: accuracy = 0.998022
I0912 07:00:00.532269 28411 solver.cpp:244]     Train net output #1: loss = 0.00508651 (* 1 = 0.00508651 loss)
I0912 07:00:00.532277 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997913
I0912 07:00:00.532289 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998317
I0912 07:00:00.532297 28411 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0912 07:00:17.229059 28411 solver.cpp:228] Iteration 2980, loss = 0.0144156
I0912 07:00:17.229100 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995613
I0912 07:00:17.229116 28411 solver.cpp:244]     Train net output #1: loss = 0.0144155 (* 1 = 0.0144155 loss)
I0912 07:00:17.229123 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998391
I0912 07:00:17.229135 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989882
I0912 07:00:17.229145 28411 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0912 07:00:33.894445 28411 solver.cpp:228] Iteration 3000, loss = 0.0150767
I0912 07:00:33.894582 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994352
I0912 07:00:33.894598 28411 solver.cpp:244]     Train net output #1: loss = 0.0150767 (* 1 = 0.0150767 loss)
I0912 07:00:33.894604 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991863
I0912 07:00:33.894609 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996611
I0912 07:00:33.894618 28411 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0912 07:00:50.567253 28411 solver.cpp:228] Iteration 3020, loss = 0.0101199
I0912 07:00:50.567324 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995519
I0912 07:00:50.567344 28411 solver.cpp:244]     Train net output #1: loss = 0.0101198 (* 1 = 0.0101198 loss)
I0912 07:00:50.567355 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992445
I0912 07:00:50.567360 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998499
I0912 07:00:50.567368 28411 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0912 07:01:07.236460 28411 solver.cpp:228] Iteration 3040, loss = 0.00810281
I0912 07:01:07.236562 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996616
I0912 07:01:07.236578 28411 solver.cpp:244]     Train net output #1: loss = 0.00810276 (* 1 = 0.00810276 loss)
I0912 07:01:07.236584 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995013
I0912 07:01:07.236589 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998399
I0912 07:01:07.236598 28411 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0912 07:01:23.909409 28411 solver.cpp:228] Iteration 3060, loss = 0.0169217
I0912 07:01:23.909456 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996376
I0912 07:01:23.909471 28411 solver.cpp:244]     Train net output #1: loss = 0.0169216 (* 1 = 0.0169216 loss)
I0912 07:01:23.909477 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996307
I0912 07:01:23.909482 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996993
I0912 07:01:23.909489 28411 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0912 07:01:40.528723 28411 solver.cpp:228] Iteration 3080, loss = 0.00946528
I0912 07:01:40.528863 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996299
I0912 07:01:40.528882 28411 solver.cpp:244]     Train net output #1: loss = 0.00946523 (* 1 = 0.00946523 loss)
I0912 07:01:40.528892 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994314
I0912 07:01:40.528903 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997956
I0912 07:01:40.528910 28411 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0912 07:01:57.138882 28411 solver.cpp:228] Iteration 3100, loss = 0.00435441
I0912 07:01:57.138947 28411 solver.cpp:244]     Train net output #0: accuracy = 0.998559
I0912 07:01:57.138959 28411 solver.cpp:244]     Train net output #1: loss = 0.00435436 (* 1 = 0.00435436 loss)
I0912 07:01:57.138967 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998821
I0912 07:01:57.138972 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998016
I0912 07:01:57.138978 28411 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0912 07:02:13.744843 28411 solver.cpp:228] Iteration 3120, loss = 0.0116787
I0912 07:02:13.744994 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994903
I0912 07:02:13.745023 28411 solver.cpp:244]     Train net output #1: loss = 0.0116786 (* 1 = 0.0116786 loss)
I0912 07:02:13.745035 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994428
I0912 07:02:13.745045 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996106
I0912 07:02:13.745060 28411 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0912 07:02:30.356451 28411 solver.cpp:228] Iteration 3140, loss = 0.0123976
I0912 07:02:30.356492 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994326
I0912 07:02:30.356506 28411 solver.cpp:244]     Train net output #1: loss = 0.0123976 (* 1 = 0.0123976 loss)
I0912 07:02:30.356511 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992185
I0912 07:02:30.356516 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998484
I0912 07:02:30.356523 28411 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0912 07:02:46.965272 28411 solver.cpp:228] Iteration 3160, loss = 0.00900992
I0912 07:02:46.965392 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996853
I0912 07:02:46.965410 28411 solver.cpp:244]     Train net output #1: loss = 0.00900987 (* 1 = 0.00900987 loss)
I0912 07:02:46.965425 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996377
I0912 07:02:46.965431 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99722
I0912 07:02:46.965438 28411 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0912 07:03:03.570567 28411 solver.cpp:228] Iteration 3180, loss = 0.00882765
I0912 07:03:03.570606 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996602
I0912 07:03:03.570619 28411 solver.cpp:244]     Train net output #1: loss = 0.0088276 (* 1 = 0.0088276 loss)
I0912 07:03:03.570626 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996338
I0912 07:03:03.570631 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996922
I0912 07:03:03.570637 28411 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0912 07:03:20.179301 28411 solver.cpp:228] Iteration 3200, loss = 0.013793
I0912 07:03:20.179411 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996266
I0912 07:03:20.179428 28411 solver.cpp:244]     Train net output #1: loss = 0.013793 (* 1 = 0.013793 loss)
I0912 07:03:20.179438 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997445
I0912 07:03:20.179450 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995488
I0912 07:03:20.179458 28411 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0912 07:03:36.798822 28411 solver.cpp:228] Iteration 3220, loss = 0.0106397
I0912 07:03:36.798863 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996234
I0912 07:03:36.798877 28411 solver.cpp:244]     Train net output #1: loss = 0.0106397 (* 1 = 0.0106397 loss)
I0912 07:03:36.798883 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993462
I0912 07:03:36.798888 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997968
I0912 07:03:36.798897 28411 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0912 07:03:53.400845 28411 solver.cpp:228] Iteration 3240, loss = 0.00711461
I0912 07:03:53.400960 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996882
I0912 07:03:53.400976 28411 solver.cpp:244]     Train net output #1: loss = 0.00711456 (* 1 = 0.00711456 loss)
I0912 07:03:53.400982 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996046
I0912 07:03:53.400987 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998263
I0912 07:03:53.400995 28411 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0912 07:04:09.997851 28411 solver.cpp:228] Iteration 3260, loss = 0.0116699
I0912 07:04:09.997895 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995473
I0912 07:04:09.997910 28411 solver.cpp:244]     Train net output #1: loss = 0.0116699 (* 1 = 0.0116699 loss)
I0912 07:04:09.997915 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995283
I0912 07:04:09.997920 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995716
I0912 07:04:09.997926 28411 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0912 07:04:26.598255 28411 solver.cpp:228] Iteration 3280, loss = 0.0119375
I0912 07:04:26.598417 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995119
I0912 07:04:26.598433 28411 solver.cpp:244]     Train net output #1: loss = 0.0119374 (* 1 = 0.0119374 loss)
I0912 07:04:26.598441 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993943
I0912 07:04:26.598446 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996639
I0912 07:04:26.598453 28411 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0912 07:04:43.203761 28411 solver.cpp:228] Iteration 3300, loss = 0.00566
I0912 07:04:43.203804 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997772
I0912 07:04:43.203819 28411 solver.cpp:244]     Train net output #1: loss = 0.00565995 (* 1 = 0.00565995 loss)
I0912 07:04:43.203824 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996784
I0912 07:04:43.203830 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998756
I0912 07:04:43.203838 28411 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0912 07:04:59.953306 28411 solver.cpp:228] Iteration 3320, loss = 0.00706372
I0912 07:04:59.953454 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997007
I0912 07:04:59.953492 28411 solver.cpp:244]     Train net output #1: loss = 0.00706367 (* 1 = 0.00706367 loss)
I0912 07:04:59.953500 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996118
I0912 07:04:59.953511 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998215
I0912 07:04:59.953521 28411 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0912 07:05:16.560349 28411 solver.cpp:228] Iteration 3340, loss = 0.00802925
I0912 07:05:16.560394 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996606
I0912 07:05:16.560408 28411 solver.cpp:244]     Train net output #1: loss = 0.0080292 (* 1 = 0.0080292 loss)
I0912 07:05:16.560415 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99456
I0912 07:05:16.560421 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998393
I0912 07:05:16.560430 28411 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0912 07:05:33.156298 28411 solver.cpp:228] Iteration 3360, loss = 0.0083867
I0912 07:05:33.156430 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996655
I0912 07:05:33.156476 28411 solver.cpp:244]     Train net output #1: loss = 0.00838665 (* 1 = 0.00838665 loss)
I0912 07:05:33.156484 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99695
I0912 07:05:33.156494 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996065
I0912 07:05:33.156505 28411 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0912 07:05:49.809501 28411 solver.cpp:228] Iteration 3380, loss = 0.010658
I0912 07:05:49.809547 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99637
I0912 07:05:49.809561 28411 solver.cpp:244]     Train net output #1: loss = 0.0106579 (* 1 = 0.0106579 loss)
I0912 07:05:49.809568 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992873
I0912 07:05:49.809573 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998295
I0912 07:05:49.809581 28411 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0912 07:06:06.421463 28411 solver.cpp:228] Iteration 3400, loss = 0.00905306
I0912 07:06:06.421617 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995674
I0912 07:06:06.421635 28411 solver.cpp:244]     Train net output #1: loss = 0.00905301 (* 1 = 0.00905301 loss)
I0912 07:06:06.421643 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993029
I0912 07:06:06.421648 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998853
I0912 07:06:06.421656 28411 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0912 07:06:23.036029 28411 solver.cpp:228] Iteration 3420, loss = 0.0137942
I0912 07:06:23.036073 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993505
I0912 07:06:23.036087 28411 solver.cpp:244]     Train net output #1: loss = 0.0137941 (* 1 = 0.0137941 loss)
I0912 07:06:23.036093 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990894
I0912 07:06:23.036098 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997292
I0912 07:06:23.036106 28411 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0912 07:06:39.644219 28411 solver.cpp:228] Iteration 3440, loss = 0.00608019
I0912 07:06:39.644361 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997554
I0912 07:06:39.644379 28411 solver.cpp:244]     Train net output #1: loss = 0.00608014 (* 1 = 0.00608014 loss)
I0912 07:06:39.644393 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99738
I0912 07:06:39.644404 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99789
I0912 07:06:39.644413 28411 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0912 07:06:56.249651 28411 solver.cpp:228] Iteration 3460, loss = 0.00824482
I0912 07:06:56.249691 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996701
I0912 07:06:56.249706 28411 solver.cpp:244]     Train net output #1: loss = 0.00824477 (* 1 = 0.00824477 loss)
I0912 07:06:56.249713 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995118
I0912 07:06:56.249724 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998086
I0912 07:06:56.249732 28411 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0912 07:07:12.858141 28411 solver.cpp:228] Iteration 3480, loss = 0.0054599
I0912 07:07:12.858260 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997757
I0912 07:07:12.858275 28411 solver.cpp:244]     Train net output #1: loss = 0.00545985 (* 1 = 0.00545985 loss)
I0912 07:07:12.858286 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997224
I0912 07:07:12.858291 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998442
I0912 07:07:12.858299 28411 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0912 07:07:29.485981 28411 solver.cpp:228] Iteration 3500, loss = 0.00985553
I0912 07:07:29.486027 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99589
I0912 07:07:29.486043 28411 solver.cpp:244]     Train net output #1: loss = 0.00985548 (* 1 = 0.00985548 loss)
I0912 07:07:29.486049 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995307
I0912 07:07:29.486054 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996815
I0912 07:07:29.486062 28411 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0912 07:07:46.112824 28411 solver.cpp:228] Iteration 3520, loss = 0.00535476
I0912 07:07:46.112944 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997953
I0912 07:07:46.112962 28411 solver.cpp:244]     Train net output #1: loss = 0.00535471 (* 1 = 0.00535471 loss)
I0912 07:07:46.112967 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997807
I0912 07:07:46.112972 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998273
I0912 07:07:46.112979 28411 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0912 07:08:02.752121 28411 solver.cpp:228] Iteration 3540, loss = 0.00614437
I0912 07:08:02.752167 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99747
I0912 07:08:02.752183 28411 solver.cpp:244]     Train net output #1: loss = 0.00614432 (* 1 = 0.00614432 loss)
I0912 07:08:02.752192 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997018
I0912 07:08:02.752197 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998088
I0912 07:08:02.752207 28411 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0912 07:08:19.383203 28411 solver.cpp:228] Iteration 3560, loss = 0.00559835
I0912 07:08:19.383350 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997879
I0912 07:08:19.383369 28411 solver.cpp:244]     Train net output #1: loss = 0.0055983 (* 1 = 0.0055983 loss)
I0912 07:08:19.383378 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997471
I0912 07:08:19.383383 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99844
I0912 07:08:19.383390 28411 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0912 07:08:36.008678 28411 solver.cpp:228] Iteration 3580, loss = 0.0165561
I0912 07:08:36.008718 28411 solver.cpp:244]     Train net output #0: accuracy = 0.993196
I0912 07:08:36.008733 28411 solver.cpp:244]     Train net output #1: loss = 0.0165561 (* 1 = 0.0165561 loss)
I0912 07:08:36.008744 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990191
I0912 07:08:36.008749 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996446
I0912 07:08:36.008757 28411 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0912 07:08:52.648267 28411 solver.cpp:228] Iteration 3600, loss = 0.00426076
I0912 07:08:52.648373 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99804
I0912 07:08:52.648391 28411 solver.cpp:244]     Train net output #1: loss = 0.00426071 (* 1 = 0.00426071 loss)
I0912 07:08:52.648398 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997002
I0912 07:08:52.648404 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99947
I0912 07:08:52.648411 28411 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0912 07:09:09.275701 28411 solver.cpp:228] Iteration 3620, loss = 0.0103409
I0912 07:09:09.275743 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995255
I0912 07:09:09.275758 28411 solver.cpp:244]     Train net output #1: loss = 0.0103409 (* 1 = 0.0103409 loss)
I0912 07:09:09.275763 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990574
I0912 07:09:09.275768 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99891
I0912 07:09:09.275776 28411 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0912 07:09:25.894877 28411 solver.cpp:228] Iteration 3640, loss = 0.00432789
I0912 07:09:25.894984 28411 solver.cpp:244]     Train net output #0: accuracy = 0.998287
I0912 07:09:25.895000 28411 solver.cpp:244]     Train net output #1: loss = 0.00432784 (* 1 = 0.00432784 loss)
I0912 07:09:25.895012 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99791
I0912 07:09:25.895017 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998775
I0912 07:09:25.895025 28411 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0912 07:09:42.520728 28411 solver.cpp:228] Iteration 3660, loss = 0.00970508
I0912 07:09:42.520771 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99553
I0912 07:09:42.520786 28411 solver.cpp:244]     Train net output #1: loss = 0.00970503 (* 1 = 0.00970503 loss)
I0912 07:09:42.520799 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994431
I0912 07:09:42.520804 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997614
I0912 07:09:42.520812 28411 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0912 07:09:59.137269 28411 solver.cpp:228] Iteration 3680, loss = 0.00795557
I0912 07:09:59.137379 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996764
I0912 07:09:59.137401 28411 solver.cpp:244]     Train net output #1: loss = 0.00795551 (* 1 = 0.00795551 loss)
I0912 07:09:59.137409 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994813
I0912 07:09:59.137421 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998379
I0912 07:09:59.137436 28411 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0912 07:10:15.742628 28411 solver.cpp:228] Iteration 3700, loss = 0.0114149
I0912 07:10:15.742667 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99624
I0912 07:10:15.742683 28411 solver.cpp:244]     Train net output #1: loss = 0.0114148 (* 1 = 0.0114148 loss)
I0912 07:10:15.742692 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997332
I0912 07:10:15.742702 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992154
I0912 07:10:15.742710 28411 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0912 07:10:32.360949 28411 solver.cpp:228] Iteration 3720, loss = 0.0038592
I0912 07:10:32.361110 28411 solver.cpp:244]     Train net output #0: accuracy = 0.998352
I0912 07:10:32.361132 28411 solver.cpp:244]     Train net output #1: loss = 0.00385914 (* 1 = 0.00385914 loss)
I0912 07:10:32.361140 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99797
I0912 07:10:32.361152 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998932
I0912 07:10:32.361161 28411 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0912 07:10:48.964663 28411 solver.cpp:228] Iteration 3740, loss = 0.00848946
I0912 07:10:48.964706 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997002
I0912 07:10:48.964720 28411 solver.cpp:244]     Train net output #1: loss = 0.00848941 (* 1 = 0.00848941 loss)
I0912 07:10:48.964727 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994406
I0912 07:10:48.964732 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998533
I0912 07:10:48.964740 28411 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0912 07:11:05.584630 28411 solver.cpp:228] Iteration 3760, loss = 0.00507255
I0912 07:11:05.584728 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99797
I0912 07:11:05.584744 28411 solver.cpp:244]     Train net output #1: loss = 0.00507249 (* 1 = 0.00507249 loss)
I0912 07:11:05.584753 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997221
I0912 07:11:05.584765 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99881
I0912 07:11:05.584774 28411 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0912 07:11:22.187115 28411 solver.cpp:228] Iteration 3780, loss = 0.0143643
I0912 07:11:22.187158 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994073
I0912 07:11:22.187171 28411 solver.cpp:244]     Train net output #1: loss = 0.0143643 (* 1 = 0.0143643 loss)
I0912 07:11:22.187177 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993841
I0912 07:11:22.187182 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994795
I0912 07:11:22.187191 28411 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0912 07:11:38.812307 28411 solver.cpp:228] Iteration 3800, loss = 0.0124272
I0912 07:11:38.812409 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99492
I0912 07:11:38.812427 28411 solver.cpp:244]     Train net output #1: loss = 0.0124272 (* 1 = 0.0124272 loss)
I0912 07:11:38.812438 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987124
I0912 07:11:38.812444 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999232
I0912 07:11:38.812453 28411 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0912 07:11:55.436604 28411 solver.cpp:228] Iteration 3820, loss = 0.0134434
I0912 07:11:55.436645 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994324
I0912 07:11:55.436658 28411 solver.cpp:244]     Train net output #1: loss = 0.0134434 (* 1 = 0.0134434 loss)
I0912 07:11:55.436664 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988571
I0912 07:11:55.436669 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998017
I0912 07:11:55.436677 28411 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0912 07:12:12.048928 28411 solver.cpp:228] Iteration 3840, loss = 0.00580127
I0912 07:12:12.049087 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997522
I0912 07:12:12.049106 28411 solver.cpp:244]     Train net output #1: loss = 0.00580122 (* 1 = 0.00580122 loss)
I0912 07:12:12.049115 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997117
I0912 07:12:12.049120 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998467
I0912 07:12:12.049129 28411 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0912 07:12:28.674933 28411 solver.cpp:228] Iteration 3860, loss = 0.00808894
I0912 07:12:28.674976 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996644
I0912 07:12:28.674990 28411 solver.cpp:244]     Train net output #1: loss = 0.00808888 (* 1 = 0.00808888 loss)
I0912 07:12:28.674996 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994919
I0912 07:12:28.675001 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998416
I0912 07:12:28.675009 28411 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0912 07:12:45.298187 28411 solver.cpp:228] Iteration 3880, loss = 0.0103029
I0912 07:12:45.298288 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996111
I0912 07:12:45.298307 28411 solver.cpp:244]     Train net output #1: loss = 0.0103029 (* 1 = 0.0103029 loss)
I0912 07:12:45.298318 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996163
I0912 07:12:45.298323 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996043
I0912 07:12:45.298331 28411 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0912 07:13:01.927389 28411 solver.cpp:228] Iteration 3900, loss = 0.00925887
I0912 07:13:01.927438 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995982
I0912 07:13:01.927453 28411 solver.cpp:244]     Train net output #1: loss = 0.00925882 (* 1 = 0.00925882 loss)
I0912 07:13:01.927461 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991742
I0912 07:13:01.927467 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998963
I0912 07:13:01.927477 28411 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0912 07:13:18.558598 28411 solver.cpp:228] Iteration 3920, loss = 0.0108145
I0912 07:13:18.558696 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99622
I0912 07:13:18.558712 28411 solver.cpp:244]     Train net output #1: loss = 0.0108145 (* 1 = 0.0108145 loss)
I0912 07:13:18.558720 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997263
I0912 07:13:18.558727 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994642
I0912 07:13:18.558734 28411 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0912 07:13:35.176225 28411 solver.cpp:228] Iteration 3940, loss = 0.00744477
I0912 07:13:35.176270 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996745
I0912 07:13:35.176286 28411 solver.cpp:244]     Train net output #1: loss = 0.00744471 (* 1 = 0.00744471 loss)
I0912 07:13:35.176293 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99483
I0912 07:13:35.176300 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998741
I0912 07:13:35.176308 28411 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0912 07:13:51.770073 28411 solver.cpp:228] Iteration 3960, loss = 0.00617823
I0912 07:13:51.770161 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997636
I0912 07:13:51.770176 28411 solver.cpp:244]     Train net output #1: loss = 0.00617818 (* 1 = 0.00617818 loss)
I0912 07:13:51.770190 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997688
I0912 07:13:51.770195 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997522
I0912 07:13:51.770202 28411 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0912 07:14:08.403692 28411 solver.cpp:228] Iteration 3980, loss = 0.00505649
I0912 07:14:08.403738 28411 solver.cpp:244]     Train net output #0: accuracy = 0.998312
I0912 07:14:08.403754 28411 solver.cpp:244]     Train net output #1: loss = 0.00505643 (* 1 = 0.00505643 loss)
I0912 07:14:08.403761 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99899
I0912 07:14:08.403767 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996359
I0912 07:14:08.403776 28411 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0912 07:14:25.030817 28411 solver.cpp:228] Iteration 4000, loss = 0.0173884
I0912 07:14:25.030953 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994891
I0912 07:14:25.030990 28411 solver.cpp:244]     Train net output #1: loss = 0.0173884 (* 1 = 0.0173884 loss)
I0912 07:14:25.030998 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997577
I0912 07:14:25.031009 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981168
I0912 07:14:25.031018 28411 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0912 07:14:41.647563 28411 solver.cpp:228] Iteration 4020, loss = 0.00779815
I0912 07:14:41.647610 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996992
I0912 07:14:41.647626 28411 solver.cpp:244]     Train net output #1: loss = 0.0077981 (* 1 = 0.0077981 loss)
I0912 07:14:41.647634 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9967
I0912 07:14:41.647639 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998198
I0912 07:14:41.647649 28411 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0912 07:14:58.265664 28411 solver.cpp:228] Iteration 4040, loss = 0.00465491
I0912 07:14:58.265771 28411 solver.cpp:244]     Train net output #0: accuracy = 0.998413
I0912 07:14:58.265789 28411 solver.cpp:244]     Train net output #1: loss = 0.00465485 (* 1 = 0.00465485 loss)
I0912 07:14:58.265800 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998453
I0912 07:14:58.265805 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998362
I0912 07:14:58.265813 28411 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0912 07:15:14.889961 28411 solver.cpp:228] Iteration 4060, loss = 0.0117342
I0912 07:15:14.890005 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994825
I0912 07:15:14.890022 28411 solver.cpp:244]     Train net output #1: loss = 0.0117342 (* 1 = 0.0117342 loss)
I0912 07:15:14.890027 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991592
I0912 07:15:14.890033 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998165
I0912 07:15:14.890040 28411 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0912 07:15:31.525362 28411 solver.cpp:228] Iteration 4080, loss = 0.0104476
I0912 07:15:31.525466 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995466
I0912 07:15:31.525485 28411 solver.cpp:244]     Train net output #1: loss = 0.0104476 (* 1 = 0.0104476 loss)
I0912 07:15:31.525494 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994213
I0912 07:15:31.525506 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997393
I0912 07:15:31.525516 28411 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0912 07:15:48.143702 28411 solver.cpp:228] Iteration 4100, loss = 0.00834963
I0912 07:15:48.143744 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996609
I0912 07:15:48.143759 28411 solver.cpp:244]     Train net output #1: loss = 0.00834958 (* 1 = 0.00834958 loss)
I0912 07:15:48.143765 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995695
I0912 07:15:48.143770 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997674
I0912 07:15:48.143779 28411 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0912 07:16:04.774262 28411 solver.cpp:228] Iteration 4120, loss = 0.00464096
I0912 07:16:04.774350 28411 solver.cpp:244]     Train net output #0: accuracy = 0.998158
I0912 07:16:04.774368 28411 solver.cpp:244]     Train net output #1: loss = 0.0046409 (* 1 = 0.0046409 loss)
I0912 07:16:04.774379 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997707
I0912 07:16:04.774384 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998673
I0912 07:16:04.774394 28411 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0912 07:16:21.385793 28411 solver.cpp:228] Iteration 4140, loss = 0.0113249
I0912 07:16:21.385835 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994576
I0912 07:16:21.385849 28411 solver.cpp:244]     Train net output #1: loss = 0.0113249 (* 1 = 0.0113249 loss)
I0912 07:16:21.385855 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991416
I0912 07:16:21.385860 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998885
I0912 07:16:21.385869 28411 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0912 07:16:38.010920 28411 solver.cpp:228] Iteration 4160, loss = 0.00436771
I0912 07:16:38.011065 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997733
I0912 07:16:38.011086 28411 solver.cpp:244]     Train net output #1: loss = 0.00436766 (* 1 = 0.00436766 loss)
I0912 07:16:38.011096 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996715
I0912 07:16:38.011107 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999521
I0912 07:16:38.011116 28411 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0912 07:16:54.635987 28411 solver.cpp:228] Iteration 4180, loss = 0.0059815
I0912 07:16:54.636029 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997569
I0912 07:16:54.636042 28411 solver.cpp:244]     Train net output #1: loss = 0.00598144 (* 1 = 0.00598144 loss)
I0912 07:16:54.636049 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996569
I0912 07:16:54.636054 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998626
I0912 07:16:54.636060 28411 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0912 07:17:11.258400 28411 solver.cpp:228] Iteration 4200, loss = 0.0100624
I0912 07:17:11.258512 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996709
I0912 07:17:11.258529 28411 solver.cpp:244]     Train net output #1: loss = 0.0100623 (* 1 = 0.0100623 loss)
I0912 07:17:11.258536 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991926
I0912 07:17:11.258543 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99891
I0912 07:17:11.258550 28411 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0912 07:17:27.890486 28411 solver.cpp:228] Iteration 4220, loss = 0.0102311
I0912 07:17:27.890529 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996275
I0912 07:17:27.890543 28411 solver.cpp:244]     Train net output #1: loss = 0.010231 (* 1 = 0.010231 loss)
I0912 07:17:27.890549 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992606
I0912 07:17:27.890560 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998386
I0912 07:17:27.890568 28411 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0912 07:17:44.501485 28411 solver.cpp:228] Iteration 4240, loss = 0.00748947
I0912 07:17:44.501585 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996992
I0912 07:17:44.501601 28411 solver.cpp:244]     Train net output #1: loss = 0.00748941 (* 1 = 0.00748941 loss)
I0912 07:17:44.501610 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996719
I0912 07:17:44.501616 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997441
I0912 07:17:44.501622 28411 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0912 07:18:01.109006 28411 solver.cpp:228] Iteration 4260, loss = 0.0208852
I0912 07:18:01.109047 28411 solver.cpp:244]     Train net output #0: accuracy = 0.991458
I0912 07:18:01.109061 28411 solver.cpp:244]     Train net output #1: loss = 0.0208852 (* 1 = 0.0208852 loss)
I0912 07:18:01.109066 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990737
I0912 07:18:01.109071 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993698
I0912 07:18:01.109079 28411 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0912 07:18:17.720185 28411 solver.cpp:228] Iteration 4280, loss = 0.0094512
I0912 07:18:17.720280 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996278
I0912 07:18:17.720296 28411 solver.cpp:244]     Train net output #1: loss = 0.00945114 (* 1 = 0.00945114 loss)
I0912 07:18:17.720309 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993627
I0912 07:18:17.720315 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998145
I0912 07:18:17.720322 28411 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0912 07:18:34.335593 28411 solver.cpp:228] Iteration 4300, loss = 0.00932621
I0912 07:18:34.335639 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996733
I0912 07:18:34.335655 28411 solver.cpp:244]     Train net output #1: loss = 0.00932615 (* 1 = 0.00932615 loss)
I0912 07:18:34.335662 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997403
I0912 07:18:34.335669 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994394
I0912 07:18:34.335677 28411 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0912 07:18:50.959451 28411 solver.cpp:228] Iteration 4320, loss = 0.0108765
I0912 07:18:50.959625 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995524
I0912 07:18:50.959664 28411 solver.cpp:244]     Train net output #1: loss = 0.0108765 (* 1 = 0.0108765 loss)
I0912 07:18:50.959674 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994238
I0912 07:18:50.959684 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997102
I0912 07:18:50.959692 28411 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0912 07:19:07.585001 28411 solver.cpp:228] Iteration 4340, loss = 0.00604843
I0912 07:19:07.585047 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997284
I0912 07:19:07.585063 28411 solver.cpp:244]     Train net output #1: loss = 0.00604838 (* 1 = 0.00604838 loss)
I0912 07:19:07.585070 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995593
I0912 07:19:07.585077 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999091
I0912 07:19:07.585085 28411 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0912 07:19:24.198949 28411 solver.cpp:228] Iteration 4360, loss = 0.0109448
I0912 07:19:24.199048 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995054
I0912 07:19:24.199064 28411 solver.cpp:244]     Train net output #1: loss = 0.0109448 (* 1 = 0.0109448 loss)
I0912 07:19:24.199075 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993499
I0912 07:19:24.199080 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997844
I0912 07:19:24.199087 28411 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0912 07:19:40.806299 28411 solver.cpp:228] Iteration 4380, loss = 0.00542346
I0912 07:19:40.806344 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997387
I0912 07:19:40.806358 28411 solver.cpp:244]     Train net output #1: loss = 0.00542341 (* 1 = 0.00542341 loss)
I0912 07:19:40.806365 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996092
I0912 07:19:40.806372 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999289
I0912 07:19:40.806380 28411 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0912 07:19:57.414031 28411 solver.cpp:228] Iteration 4400, loss = 0.00736975
I0912 07:19:57.414165 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997383
I0912 07:19:57.414203 28411 solver.cpp:244]     Train net output #1: loss = 0.0073697 (* 1 = 0.0073697 loss)
I0912 07:19:57.414211 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99768
I0912 07:19:57.414224 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997082
I0912 07:19:57.414238 28411 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0912 07:20:14.032380 28411 solver.cpp:228] Iteration 4420, loss = 0.00915958
I0912 07:20:14.032425 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996541
I0912 07:20:14.032438 28411 solver.cpp:244]     Train net output #1: loss = 0.00915953 (* 1 = 0.00915953 loss)
I0912 07:20:14.032444 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997302
I0912 07:20:14.032449 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994945
I0912 07:20:14.032455 28411 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0912 07:20:30.638443 28411 solver.cpp:228] Iteration 4440, loss = 0.00540479
I0912 07:20:30.638618 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997833
I0912 07:20:30.638660 28411 solver.cpp:244]     Train net output #1: loss = 0.00540474 (* 1 = 0.00540474 loss)
I0912 07:20:30.638672 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997597
I0912 07:20:30.638681 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998323
I0912 07:20:30.638690 28411 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0912 07:20:47.288105 28411 solver.cpp:228] Iteration 4460, loss = 0.00646184
I0912 07:20:47.288154 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997635
I0912 07:20:47.288170 28411 solver.cpp:244]     Train net output #1: loss = 0.00646179 (* 1 = 0.00646179 loss)
I0912 07:20:47.288177 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997059
I0912 07:20:47.288182 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998178
I0912 07:20:47.288190 28411 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0912 07:21:03.918807 28411 solver.cpp:228] Iteration 4480, loss = 0.0122671
I0912 07:21:03.918941 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994805
I0912 07:21:03.918959 28411 solver.cpp:244]     Train net output #1: loss = 0.012267 (* 1 = 0.012267 loss)
I0912 07:21:03.918969 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992364
I0912 07:21:03.918984 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99743
I0912 07:21:03.918998 28411 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0912 07:21:20.550353 28411 solver.cpp:228] Iteration 4500, loss = 0.00674492
I0912 07:21:20.550395 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996797
I0912 07:21:20.550408 28411 solver.cpp:244]     Train net output #1: loss = 0.00674487 (* 1 = 0.00674487 loss)
I0912 07:21:20.550415 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994382
I0912 07:21:20.550420 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999154
I0912 07:21:20.550437 28411 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0912 07:21:37.172564 28411 solver.cpp:228] Iteration 4520, loss = 0.00670079
I0912 07:21:37.172691 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997636
I0912 07:21:37.172708 28411 solver.cpp:244]     Train net output #1: loss = 0.00670074 (* 1 = 0.00670074 loss)
I0912 07:21:37.172719 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997991
I0912 07:21:37.172732 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997135
I0912 07:21:37.172746 28411 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0912 07:21:53.783287 28411 solver.cpp:228] Iteration 4540, loss = 0.00796795
I0912 07:21:53.783327 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996387
I0912 07:21:53.783342 28411 solver.cpp:244]     Train net output #1: loss = 0.0079679 (* 1 = 0.0079679 loss)
I0912 07:21:53.783349 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995411
I0912 07:21:53.783354 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997994
I0912 07:21:53.783361 28411 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0912 07:22:10.413902 28411 solver.cpp:228] Iteration 4560, loss = 0.00703667
I0912 07:22:10.414029 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997005
I0912 07:22:10.414047 28411 solver.cpp:244]     Train net output #1: loss = 0.00703662 (* 1 = 0.00703662 loss)
I0912 07:22:10.414058 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994262
I0912 07:22:10.414070 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999057
I0912 07:22:10.414078 28411 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0912 07:22:27.034246 28411 solver.cpp:228] Iteration 4580, loss = 0.00698293
I0912 07:22:27.034291 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99729
I0912 07:22:27.034304 28411 solver.cpp:244]     Train net output #1: loss = 0.00698288 (* 1 = 0.00698288 loss)
I0912 07:22:27.034312 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99753
I0912 07:22:27.034317 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996772
I0912 07:22:27.034323 28411 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0912 07:22:43.667464 28411 solver.cpp:228] Iteration 4600, loss = 0.0080226
I0912 07:22:43.667662 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99647
I0912 07:22:43.667680 28411 solver.cpp:244]     Train net output #1: loss = 0.00802255 (* 1 = 0.00802255 loss)
I0912 07:22:43.667690 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992056
I0912 07:22:43.667701 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99924
I0912 07:22:43.667711 28411 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0912 07:23:00.306926 28411 solver.cpp:228] Iteration 4620, loss = 0.0067111
I0912 07:23:00.306968 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997127
I0912 07:23:00.306982 28411 solver.cpp:244]     Train net output #1: loss = 0.00671105 (* 1 = 0.00671105 loss)
I0912 07:23:00.306989 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996402
I0912 07:23:00.306994 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998145
I0912 07:23:00.307003 28411 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0912 07:23:16.943527 28411 solver.cpp:228] Iteration 4640, loss = 0.00643354
I0912 07:23:16.943661 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99769
I0912 07:23:16.943678 28411 solver.cpp:244]     Train net output #1: loss = 0.00643349 (* 1 = 0.00643349 loss)
I0912 07:23:16.943691 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99604
I0912 07:23:16.943696 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998708
I0912 07:23:16.943704 28411 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0912 07:23:33.547103 28411 solver.cpp:228] Iteration 4660, loss = 0.0115011
I0912 07:23:33.547148 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995438
I0912 07:23:33.547164 28411 solver.cpp:244]     Train net output #1: loss = 0.011501 (* 1 = 0.011501 loss)
I0912 07:23:33.547171 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990118
I0912 07:23:33.547178 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998464
I0912 07:23:33.547186 28411 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0912 07:23:50.173128 28411 solver.cpp:228] Iteration 4680, loss = 0.00477486
I0912 07:23:50.173264 28411 solver.cpp:244]     Train net output #0: accuracy = 0.998077
I0912 07:23:50.173281 28411 solver.cpp:244]     Train net output #1: loss = 0.00477481 (* 1 = 0.00477481 loss)
I0912 07:23:50.173287 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997998
I0912 07:23:50.173292 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998217
I0912 07:23:50.173300 28411 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0912 07:24:06.798503 28411 solver.cpp:228] Iteration 4700, loss = 0.00795772
I0912 07:24:06.798548 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99685
I0912 07:24:06.798565 28411 solver.cpp:244]     Train net output #1: loss = 0.00795767 (* 1 = 0.00795767 loss)
I0912 07:24:06.798573 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994989
I0912 07:24:06.798578 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998234
I0912 07:24:06.798588 28411 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0912 07:24:23.416095 28411 solver.cpp:228] Iteration 4720, loss = 0.00841916
I0912 07:24:23.416223 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996644
I0912 07:24:23.416239 28411 solver.cpp:244]     Train net output #1: loss = 0.00841911 (* 1 = 0.00841911 loss)
I0912 07:24:23.416250 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996939
I0912 07:24:23.416255 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995807
I0912 07:24:23.416262 28411 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0912 07:24:40.104339 28411 solver.cpp:228] Iteration 4740, loss = 0.00708591
I0912 07:24:40.104385 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996962
I0912 07:24:40.104401 28411 solver.cpp:244]     Train net output #1: loss = 0.00708586 (* 1 = 0.00708586 loss)
I0912 07:24:40.104408 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995649
I0912 07:24:40.104414 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998392
I0912 07:24:40.104423 28411 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0912 07:24:56.694802 28411 solver.cpp:228] Iteration 4760, loss = 0.00648079
I0912 07:24:56.694995 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99751
I0912 07:24:56.695019 28411 solver.cpp:244]     Train net output #1: loss = 0.00648074 (* 1 = 0.00648074 loss)
I0912 07:24:56.695027 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996965
I0912 07:24:56.695039 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998169
I0912 07:24:56.695046 28411 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0912 07:25:13.301215 28411 solver.cpp:228] Iteration 4780, loss = 0.00562797
I0912 07:25:13.301261 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997863
I0912 07:25:13.301277 28411 solver.cpp:244]     Train net output #1: loss = 0.00562792 (* 1 = 0.00562792 loss)
I0912 07:25:13.301285 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996256
I0912 07:25:13.301290 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998959
I0912 07:25:13.301301 28411 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0912 07:25:29.943975 28411 solver.cpp:228] Iteration 4800, loss = 0.00785175
I0912 07:25:29.944108 28411 solver.cpp:244]     Train net output #0: accuracy = 0.996944
I0912 07:25:29.944123 28411 solver.cpp:244]     Train net output #1: loss = 0.0078517 (* 1 = 0.0078517 loss)
I0912 07:25:29.944130 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997159
I0912 07:25:29.944135 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996203
I0912 07:25:29.944144 28411 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0912 07:25:46.561846 28411 solver.cpp:228] Iteration 4820, loss = 0.012117
I0912 07:25:46.561895 28411 solver.cpp:244]     Train net output #0: accuracy = 0.994213
I0912 07:25:46.561913 28411 solver.cpp:244]     Train net output #1: loss = 0.0121169 (* 1 = 0.0121169 loss)
I0912 07:25:46.561918 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988428
I0912 07:25:46.561923 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998948
I0912 07:25:46.561931 28411 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0912 07:26:03.198523 28411 solver.cpp:228] Iteration 4840, loss = 0.00998435
I0912 07:26:03.198665 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997386
I0912 07:26:03.198683 28411 solver.cpp:244]     Train net output #1: loss = 0.0099843 (* 1 = 0.0099843 loss)
I0912 07:26:03.198693 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994921
I0912 07:26:03.198699 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998482
I0912 07:26:03.198709 28411 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0912 07:26:19.822042 28411 solver.cpp:228] Iteration 4860, loss = 0.00432536
I0912 07:26:19.822084 28411 solver.cpp:244]     Train net output #0: accuracy = 0.998111
I0912 07:26:19.822098 28411 solver.cpp:244]     Train net output #1: loss = 0.00432531 (* 1 = 0.00432531 loss)
I0912 07:26:19.822105 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997487
I0912 07:26:19.822111 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999021
I0912 07:26:19.822119 28411 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0912 07:26:36.451449 28411 solver.cpp:228] Iteration 4880, loss = 0.0054117
I0912 07:26:36.451586 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997666
I0912 07:26:36.451602 28411 solver.cpp:244]     Train net output #1: loss = 0.00541165 (* 1 = 0.00541165 loss)
I0912 07:26:36.451614 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997244
I0912 07:26:36.451620 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998395
I0912 07:26:36.451629 28411 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0912 07:26:53.076292 28411 solver.cpp:228] Iteration 4900, loss = 0.00526862
I0912 07:26:53.076334 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99799
I0912 07:26:53.076349 28411 solver.cpp:244]     Train net output #1: loss = 0.00526856 (* 1 = 0.00526856 loss)
I0912 07:26:53.076354 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998126
I0912 07:26:53.076360 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997702
I0912 07:26:53.076369 28411 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0912 07:27:09.717011 28411 solver.cpp:228] Iteration 4920, loss = 0.0124651
I0912 07:27:09.717202 28411 solver.cpp:244]     Train net output #0: accuracy = 0.995059
I0912 07:27:09.717226 28411 solver.cpp:244]     Train net output #1: loss = 0.012465 (* 1 = 0.012465 loss)
I0912 07:27:09.717236 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995393
I0912 07:27:09.717247 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99411
I0912 07:27:09.717255 28411 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0912 07:27:26.330173 28411 solver.cpp:228] Iteration 4940, loss = 0.00779788
I0912 07:27:26.330215 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997216
I0912 07:27:26.330229 28411 solver.cpp:244]     Train net output #1: loss = 0.00779782 (* 1 = 0.00779782 loss)
I0912 07:27:26.330235 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997458
I0912 07:27:26.330240 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99619
I0912 07:27:26.330248 28411 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0912 07:27:42.946880 28411 solver.cpp:228] Iteration 4960, loss = 0.0052878
I0912 07:27:42.947005 28411 solver.cpp:244]     Train net output #0: accuracy = 0.997788
I0912 07:27:42.947021 28411 solver.cpp:244]     Train net output #1: loss = 0.00528775 (* 1 = 0.00528775 loss)
I0912 07:27:42.947031 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99756
I0912 07:27:42.947041 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998198
I0912 07:27:42.947051 28411 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0912 07:27:59.552058 28411 solver.cpp:228] Iteration 4980, loss = 0.00463534
I0912 07:27:59.552101 28411 solver.cpp:244]     Train net output #0: accuracy = 0.99821
I0912 07:27:59.552114 28411 solver.cpp:244]     Train net output #1: loss = 0.00463528 (* 1 = 0.00463528 loss)
I0912 07:27:59.552121 28411 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99809
I0912 07:27:59.552127 28411 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998623
I0912 07:27:59.552135 28411 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0912 07:28:15.871206 28411 solver.cpp:454] Snapshotting to binary proto file pocwisc7/training_iter_5000.caffemodel
I0912 07:28:17.363185 28411 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc7/training_iter_5000.solverstate
I0912 07:28:17.956823 28411 solver.cpp:317] Iteration 5000, loss = 0.00454419
I0912 07:28:17.956871 28411 solver.cpp:322] Optimization Done.
I0912 07:28:17.956876 28411 caffe.cpp:254] Optimization Done.

2017-09-12 07:28:18,363 log.framework MainThread  INFO       caffe models found
pocwisc7/training_iter_5000.caffemodel
2017-09-12 07:28:18,364 log.framework MainThread  INFO       Caffe model found: pocwisc7/training_iter_5000.caffemodel
2017-09-12 07:28:21,182 log.framework MainThread  INFO       uniques of label [0 1]
2017-09-12 07:28:21,327 log.framework MainThread  INFO       uniques of label [0]
2017-09-12 07:28:21,329 log.framework MainThread  INFO       Image_1 has only one class - no confusion matrix is calculate!
2017-09-12 07:28:21,419 log.framework MainThread  INFO       uniques of label [0]
2017-09-12 07:28:21,421 log.framework MainThread  INFO       Image_2 has only one class - no confusion matrix is calculate!
2017-09-12 07:28:21,508 log.framework MainThread  INFO       uniques of label [0 1]
