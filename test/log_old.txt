2017-08-24 16:08:57,095 log.framework MainThread  INFO       Picture selection is done from the global 'gpic_selection_file' file!
2017-08-24 16:08:57,102 log.framework MainThread  INFO       The framework runs with this configuration: 
work_area: ['pocwisc1', 'pocwisc2', 'pocwisc3', 'pocwisc4', 'pocwisc5', 'pocwisc6', 'pocwisc7']
job_type: 
input_csv: CRF_full_data_corrected_v6.csv
time_interval: 0
n_split: 7
shuffle: False
random_state: None
split_method: burnarea
keep_logs: False
gpic_selection_file: /disk2/nik/Analyzer/test/pics.txt
2017-08-24 16:08:57,102 log.framework MainThread  INFO       Creating HDF5Files area
2017-08-24 16:08:59,201 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:08:59,201 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:08:59,224 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:08:59,224 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:08:59,224 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:08:59,229 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:08:59,229 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:08:59,229 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:08:59,229 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_6
2017-08-24 16:08:59,472 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:08:59,472 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:08:59,492 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:08:59,492 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:08:59,492 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:08:59,496 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:08:59,497 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:08:59,497 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:08:59,497 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_5
2017-08-24 16:08:59,735 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:08:59,736 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:08:59,753 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:08:59,754 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:08:59,754 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:08:59,758 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:08:59,758 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:08:59,758 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:08:59,758 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_4
2017-08-24 16:09:00,006 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:00,006 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:00,025 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:00,026 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:00,026 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:00,030 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:00,030 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:00,030 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:00,030 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_3
2017-08-24 16:09:00,269 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:00,269 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:00,288 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:00,288 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:00,288 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:00,292 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:00,293 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:00,293 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:00,293 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_2
2017-08-24 16:09:00,531 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:00,532 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:00,549 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:00,549 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:00,549 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:00,553 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:00,553 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:00,553 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:00,553 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_1
2017-08-24 16:09:00,554 log.framework MainThread  INFO       Creating HDF5Files area
2017-08-24 16:09:00,796 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:00,796 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:00,814 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:00,814 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:00,814 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:00,818 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:00,818 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:00,818 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:00,818 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_6
2017-08-24 16:09:01,057 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:01,057 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:01,079 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:01,079 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:01,079 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:01,083 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:01,083 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:01,083 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:01,083 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_10
2017-08-24 16:09:01,335 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:01,335 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:01,354 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:01,354 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:01,354 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:01,358 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:01,358 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:01,358 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:01,358 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_10
2017-08-24 16:09:01,598 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:01,598 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:01,615 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:01,616 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:01,616 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:01,620 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:01,620 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:01,620 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:01,620 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_9
2017-08-24 16:09:01,858 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:01,858 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:01,878 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:01,878 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:01,878 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:01,882 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:01,883 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:01,883 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:01,883 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_7
2017-08-24 16:09:02,122 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:02,122 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:02,142 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:02,142 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:02,142 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:02,147 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:02,147 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:02,147 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:02,147 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_8
2017-08-24 16:09:02,390 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:02,390 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:02,409 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:02,409 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:02,409 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:02,413 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:02,413 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:02,413 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:02,414 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:09:02,656 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:02,656 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:02,674 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:02,674 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:02,674 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:02,678 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:02,678 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:02,678 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:02,678 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:02,919 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:02,919 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:02,939 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:02,939 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:02,939 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:02,943 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:02,943 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:02,943 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:02,943 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_3
2017-08-24 16:09:03,190 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:03,190 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:03,212 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:03,212 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:03,212 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:03,216 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:03,217 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:03,217 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:03,217 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_4
2017-08-24 16:09:03,464 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:03,464 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:03,481 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:03,482 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:03,482 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:03,486 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:03,486 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:03,486 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:03,486 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_5
2017-08-24 16:09:03,737 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:03,737 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:03,756 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:03,756 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:03,756 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:03,760 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:03,760 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:03,760 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:03,760 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_8
2017-08-24 16:09:04,018 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:04,018 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:04,037 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:04,037 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:04,037 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:04,041 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:04,042 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:04,042 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:04,042 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_9
2017-08-24 16:09:04,299 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:04,299 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:04,318 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:04,318 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:04,318 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:04,322 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:04,322 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:04,322 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:04,322 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_6
2017-08-24 16:09:04,523 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:04,523 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:04,540 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:04,540 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:04,540 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:04,544 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:04,544 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:04,544 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:04,544 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_7
2017-08-24 16:09:04,787 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:04,787 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:04,804 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:04,805 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:04,805 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:04,809 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:04,809 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:04,809 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:04,809 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_4
2017-08-24 16:09:05,055 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:05,055 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:05,074 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:05,074 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:05,074 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:05,078 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:05,078 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:05,079 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:05,079 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_5
2017-08-24 16:09:05,322 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:05,322 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:05,340 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:05,340 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:05,340 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:05,345 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:05,345 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:05,345 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:05,345 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_2
2017-08-24 16:09:05,587 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:05,587 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:05,606 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:05,606 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:05,606 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:05,610 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:05,610 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:05,610 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:05,610 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_3
2017-08-24 16:09:05,851 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:05,851 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:05,869 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:05,869 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:05,869 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:05,873 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:05,874 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:05,874 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:05,874 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_1
2017-08-24 16:09:05,874 log.framework MainThread  INFO       Creating HDF5Files area
2017-08-24 16:09:06,112 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:06,112 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:06,131 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:06,131 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:06,131 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:06,135 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:06,136 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:06,136 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:06,136 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:09:06,376 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:06,376 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:06,395 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:06,395 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:06,395 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:06,399 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:06,399 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:06,399 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:06,399 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:09:06,654 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:06,654 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:06,673 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:06,674 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:06,674 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:06,678 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:06,678 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:06,678 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:06,678 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:09:06,917 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:06,918 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:06,936 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:06,936 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:06,936 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:06,941 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:06,941 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:06,941 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:06,941 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_3
2017-08-24 16:09:07,182 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:07,182 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:07,201 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:07,201 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:07,201 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:07,205 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:07,205 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:07,205 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:07,205 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:09:07,442 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:07,442 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:07,461 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:07,461 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:07,461 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:07,465 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:07,466 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:07,466 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:07,466 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_4
2017-08-24 16:09:07,704 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:07,704 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:07,724 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:07,724 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:07,724 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:07,728 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:07,729 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:07,729 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:07,729 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_1
2017-08-24 16:09:07,967 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:07,967 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:07,983 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:07,983 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:07,983 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:07,988 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:07,988 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:07,988 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:07,988 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_2
2017-08-24 16:09:08,235 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:08,235 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:08,254 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:08,254 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:08,254 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:08,258 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:08,258 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:08,259 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:08,259 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_4
2017-08-24 16:09:08,259 log.framework MainThread  INFO       Creating HDF5Files area
2017-08-24 16:09:08,511 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:08,511 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:08,530 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:08,530 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:08,530 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:08,534 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:08,534 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:08,534 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:08,534 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:08,795 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:08,795 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:08,814 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:08,814 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:08,814 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:08,818 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:08,819 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:08,819 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:08,819 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:09:08,819 log.framework MainThread  INFO       Creating HDF5Files area
2017-08-24 16:09:09,089 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:09,089 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:09,109 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:09,109 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:09,109 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:09,113 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:09,113 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:09,113 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:09,113 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_2
2017-08-24 16:09:09,379 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:09,379 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:09,396 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:09,396 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:09,396 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:09,400 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:09,400 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:09,400 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:09,400 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_1
2017-08-24 16:09:09,646 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:09,646 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:09,665 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:09,665 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:09,665 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:09,670 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:09,670 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:09,670 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:09,670 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_1
2017-08-24 16:09:09,868 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:09,868 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:09,888 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:09,888 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:09,888 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:09,892 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:09,892 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:09,892 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:09,892 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_2
2017-08-24 16:09:10,132 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:10,132 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:10,148 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:10,148 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:10,148 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:10,153 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:10,153 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:10,153 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:10,153 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_2
2017-08-24 16:09:10,391 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:10,391 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:10,411 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:10,411 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:10,411 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:10,415 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:10,415 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:10,415 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:10,415 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_1
2017-08-24 16:09:10,416 log.framework MainThread  INFO       Creating HDF5Files area
2017-08-24 16:09:10,657 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:10,657 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:10,675 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:10,675 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:10,675 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:10,680 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:10,680 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:10,680 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:10,680 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_1
2017-08-24 16:09:10,920 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:10,921 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:10,940 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:10,940 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:10,940 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:10,944 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:10,944 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:10,944 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:10,944 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_2
2017-08-24 16:09:11,183 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:11,183 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:11,200 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:11,200 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:11,200 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:11,204 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:11,204 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:11,204 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:11,204 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_1
2017-08-24 16:09:11,445 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:11,446 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:11,464 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:11,464 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:11,464 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:11,468 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:11,469 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:11,469 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:11,469 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_2
2017-08-24 16:09:11,711 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:11,711 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:11,731 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:11,731 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:11,731 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:11,735 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:11,735 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:11,735 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:11,735 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:11,736 log.framework MainThread  INFO       Creating HDF5Files area
2017-08-24 16:09:11,976 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:11,976 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:11,994 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:11,994 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:11,994 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:11,999 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:11,999 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:11,999 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:11,999 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:09:12,236 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:12,236 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:12,255 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:12,255 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:12,255 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:12,259 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:12,260 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:12,260 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:12,260 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:09:12,498 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:12,498 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:12,516 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:12,516 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:12,517 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:12,521 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:12,521 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:12,521 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:12,521 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_3
2017-08-24 16:09:12,761 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:12,762 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:12,782 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:12,782 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:12,782 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:12,786 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:12,786 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:12,786 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:12,786 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:09:13,025 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:13,026 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:13,043 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:13,043 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:13,043 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:13,047 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:13,047 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:13,047 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:13,047 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:09:13,287 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:13,287 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:13,306 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:13,306 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:13,306 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:13,310 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:13,310 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:13,310 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:13,310 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_4
2017-08-24 16:09:13,549 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:13,549 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:13,568 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:13,568 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:13,568 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:13,572 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:13,572 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:13,572 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:13,572 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.U.Trunk_ImageColl_2
2017-08-24 16:09:13,573 log.framework MainThread  ERROR      HDF5Files already there
2017-08-24 16:09:13,814 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:13,814 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:13,833 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:13,833 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:13,833 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:13,837 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:13,837 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:13,837 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:13,837 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:14,076 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:14,077 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:14,095 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:14,095 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:14,095 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:14,099 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:14,099 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:14,099 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:14,099 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:09:14,336 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:14,336 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:14,354 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:14,355 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:14,355 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:14,359 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:14,359 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:14,359 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:14,359 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_4
2017-08-24 16:09:14,594 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:14,594 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:14,613 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:14,613 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:14,613 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:14,617 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:14,617 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:14,617 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:14,617 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_1
2017-08-24 16:09:14,864 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:14,864 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:14,883 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:14,883 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:14,883 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:14,888 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:14,888 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:14,888 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:14,888 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_2
2017-08-24 16:09:15,128 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:15,129 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:15,147 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:15,147 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:15,147 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:15,153 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:15,153 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:15,153 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:15,153 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_3
2017-08-24 16:09:15,345 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:15,345 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:15,367 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:15,367 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:15,367 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:15,371 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:15,372 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:15,372 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:15,372 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_10
2017-08-24 16:09:15,612 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:15,612 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:15,630 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:15,631 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:15,631 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:15,635 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:15,635 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:15,635 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:15,635 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:09:15,875 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:15,875 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:15,891 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:15,891 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:15,891 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:15,895 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:15,895 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:15,895 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:15,896 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:09:16,132 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:16,133 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:16,152 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:16,152 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:16,152 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:16,156 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:16,157 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:16,157 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:16,157 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_1
2017-08-24 16:09:16,398 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:16,398 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:16,415 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:16,415 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:16,415 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:16,419 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:16,419 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:16,419 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:16,419 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_10
2017-08-24 16:09:16,655 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:16,655 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:16,672 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:16,672 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:16,672 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:16,676 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:16,676 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:16,676 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:16,676 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.U.Trunk_ImageColl_2
2017-08-24 16:09:16,918 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:16,918 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:16,935 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:16,935 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:16,935 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:16,939 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:16,939 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:16,939 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:16,940 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:09:17,179 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:17,179 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:17,196 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:17,196 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:17,196 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:17,200 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:17,200 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:17,200 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:17,200 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_6
2017-08-24 16:09:17,443 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:17,443 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:17,462 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:17,462 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:17,462 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:17,466 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:17,466 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:17,466 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:17,466 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_2
2017-08-24 16:09:17,704 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:17,704 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:17,721 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:17,721 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:17,721 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:17,725 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:17,725 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:17,726 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:17,726 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:09:17,966 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:17,966 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:17,985 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:17,986 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:17,986 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:17,990 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:17,990 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:17,990 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:17,990 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:09:18,233 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:18,233 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:18,251 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:18,251 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:18,251 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:18,255 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:18,255 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:18,255 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:18,255 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_8
2017-08-24 16:09:18,497 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:18,497 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:18,516 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:18,517 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:18,517 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:18,521 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:18,521 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:18,521 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:18,521 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:09:18,763 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:18,763 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:18,780 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:18,780 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:18,780 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:18,784 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:18,785 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:18,785 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:18,785 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_1
2017-08-24 16:09:19,025 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:19,025 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:19,045 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:19,045 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:19,045 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:19,049 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:19,049 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:19,049 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:19,049 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_2
2017-08-24 16:09:19,287 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:19,287 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:19,305 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:19,305 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:19,305 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:19,309 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:19,309 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:19,309 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:19,309 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_9
2017-08-24 16:09:19,554 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:19,554 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:19,573 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:19,573 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:19,573 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:19,577 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:19,577 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:19,577 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:19,578 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_2
2017-08-24 16:09:19,814 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:19,815 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:19,831 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:19,832 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:19,832 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:19,836 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:19,836 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:19,836 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:19,836 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_1
2017-08-24 16:09:20,074 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:20,075 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:20,093 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:20,094 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:20,094 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:20,098 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:20,098 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:20,098 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:20,098 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_3
2017-08-24 16:09:20,339 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:20,339 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:20,357 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:20,357 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:20,357 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:20,362 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:20,362 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:20,362 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:20,362 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_2
2017-08-24 16:09:20,602 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:20,602 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:20,622 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:20,622 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:20,622 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:20,626 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:20,626 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:20,626 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:20,627 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_4
2017-08-24 16:09:20,811 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:20,811 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:20,827 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:20,827 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:20,827 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:20,831 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:20,832 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:20,832 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:20,832 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_7
2017-08-24 16:09:21,014 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:21,015 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:21,031 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:21,031 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:21,031 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:21,035 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:21,035 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:21,035 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:21,036 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_1
2017-08-24 16:09:21,220 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:21,220 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:21,236 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:21,236 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:21,236 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:21,240 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:21,240 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:21,240 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:21,240 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_2
2017-08-24 16:09:21,424 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:21,424 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:21,440 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:21,440 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:21,440 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:21,444 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:21,445 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:21,445 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:21,445 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_4
2017-08-24 16:09:21,630 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:21,630 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:21,646 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:21,647 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:21,647 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:21,651 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:21,651 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:21,651 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:21,651 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:21,836 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:21,836 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:21,852 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:21,852 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:21,852 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:21,856 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:21,856 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:21,856 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:21,856 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:09:22,042 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:22,043 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:22,059 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:22,059 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:22,059 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:22,064 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:22,064 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:22,064 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:22,064 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:09:22,247 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:22,247 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:22,263 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:22,263 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:22,263 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:22,267 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:22,267 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:22,267 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:22,267 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_1
2017-08-24 16:09:22,440 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:22,441 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:22,457 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:22,458 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:22,458 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:22,462 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:22,462 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:22,462 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:22,462 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:09:22,637 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:22,637 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:22,654 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:22,654 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:22,654 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:22,658 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:22,659 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:22,659 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:22,659 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:22,832 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:22,832 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:22,849 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:22,849 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:22,849 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:22,853 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:22,853 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:22,853 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:22,853 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_3
2017-08-24 16:09:23,035 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:23,035 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:23,051 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:23,051 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:23,051 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:23,056 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:23,056 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:23,056 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:23,056 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_4
2017-08-24 16:09:23,245 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:23,245 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:23,263 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:23,264 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:23,264 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:23,268 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:23,268 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:23,268 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:23,268 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_5
2017-08-24 16:09:23,454 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:23,454 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:23,473 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:23,473 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:23,473 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:23,477 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:23,477 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:23,477 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:23,477 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_6
2017-08-24 16:09:23,668 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:23,668 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:23,687 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:23,687 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:23,688 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:23,692 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:23,692 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:23,692 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:23,692 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_7
2017-08-24 16:09:23,883 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:23,884 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:23,902 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:23,902 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:23,902 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:23,906 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:23,906 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:23,906 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:23,906 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_8
2017-08-24 16:09:24,093 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:24,093 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:24,111 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:24,112 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:24,112 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:24,116 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:24,116 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:24,116 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:24,116 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_9
2017-08-24 16:09:24,304 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:24,304 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:24,323 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:24,323 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:24,323 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:24,328 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:24,328 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:24,328 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:24,328 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_4
2017-08-24 16:09:24,522 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:24,522 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:24,541 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:24,541 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:24,541 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:24,546 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:24,546 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:24,546 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:24,546 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_5
2017-08-24 16:09:24,734 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:24,734 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:24,752 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:24,752 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:24,752 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:24,756 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:24,756 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:24,757 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:24,757 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_2
2017-08-24 16:09:24,948 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:24,948 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:24,967 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:24,967 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:24,967 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:24,971 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:24,971 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:24,971 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:24,972 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_3
2017-08-24 16:09:25,127 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:25,127 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:25,144 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:25,144 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:25,144 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:25,148 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:25,148 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:25,148 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:25,148 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_1
2017-08-24 16:09:25,149 log.framework MainThread  ERROR      HDF5Files already there
2017-08-24 16:09:25,394 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:25,394 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:25,412 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:25,412 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:25,413 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:25,417 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:25,417 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:25,417 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:25,417 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:25,655 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:25,655 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:25,674 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:25,674 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:25,675 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:25,679 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:25,679 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:25,679 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:25,679 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:09:25,914 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:25,915 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:25,933 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:25,934 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:25,934 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:25,938 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:25,938 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:25,938 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:25,938 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_1
2017-08-24 16:09:26,177 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:26,177 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:26,197 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:26,197 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:26,197 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:26,201 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:26,201 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:26,201 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:26,201 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_2
2017-08-24 16:09:26,441 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:26,441 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:26,460 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:26,460 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:26,460 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:26,464 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:26,464 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:26,465 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:26,465 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_3
2017-08-24 16:09:26,704 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:26,704 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:26,723 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:26,723 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:26,723 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:26,727 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:26,727 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:26,728 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:26,728 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:09:26,967 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:26,967 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:26,986 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:26,986 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:26,986 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:26,990 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:26,990 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:26,990 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:26,990 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:09:27,229 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:27,229 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:27,248 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:27,248 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:27,249 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:27,253 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:27,253 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:27,253 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:27,253 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_4
2017-08-24 16:09:27,491 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:27,491 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:27,509 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:27,509 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:27,509 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:27,513 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:27,513 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:27,514 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:27,514 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:09:27,753 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:27,753 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:27,772 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:27,773 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:27,773 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:27,777 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:27,777 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:27,777 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:27,777 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:09:28,012 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:28,013 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:28,033 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:28,033 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:28,033 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:28,037 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:28,038 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:28,038 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:28,038 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_6
2017-08-24 16:09:28,276 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:28,277 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:28,294 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:28,294 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:28,294 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:28,298 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:28,298 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:28,298 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:28,298 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_5
2017-08-24 16:09:28,538 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:28,538 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:28,554 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:28,554 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:28,555 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:28,559 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:28,559 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:28,559 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:28,559 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_4
2017-08-24 16:09:28,796 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:28,796 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:28,816 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:28,816 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:28,816 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:28,820 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:28,820 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:28,820 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:28,820 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_3
2017-08-24 16:09:29,060 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:29,060 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:29,077 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:29,077 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:29,077 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:29,081 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:29,081 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:29,081 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:29,081 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_2
2017-08-24 16:09:29,317 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:29,317 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:29,336 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:29,336 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:29,336 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:29,340 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:29,340 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:29,340 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:29,340 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_1
2017-08-24 16:09:29,579 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:29,579 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:29,597 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:29,597 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:29,597 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:29,601 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:29,601 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:29,601 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:29,602 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:09:29,841 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:29,841 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:29,860 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:29,860 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:29,860 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:29,865 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:29,865 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:29,865 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:29,865 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:09:30,102 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:30,102 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:30,118 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:30,118 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:30,118 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:30,123 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:30,123 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:30,123 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:30,123 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_1
2017-08-24 16:09:30,366 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:30,366 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:30,384 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:30,384 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:30,384 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:30,388 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:30,388 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:30,388 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:30,389 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_2
2017-08-24 16:09:30,579 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:30,579 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:30,595 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:30,595 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:30,595 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:30,599 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:30,599 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:30,599 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:30,599 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_2
2017-08-24 16:09:30,838 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:30,838 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:30,857 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:30,857 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:30,857 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:30,861 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:30,861 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:30,861 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:30,861 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_1
2017-08-24 16:09:31,100 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:31,100 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:31,118 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:31,119 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:31,119 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:31,123 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:31,123 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:31,123 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:31,123 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_1
2017-08-24 16:09:31,361 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:31,361 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:31,380 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:31,380 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:31,380 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:31,384 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:31,385 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:31,385 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:31,385 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_2
2017-08-24 16:09:31,622 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:31,622 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:31,641 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:31,641 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:31,641 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:31,645 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:31,645 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:31,646 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:31,646 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_4
2017-08-24 16:09:31,884 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:31,884 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:31,900 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:31,900 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:31,900 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:31,904 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:31,905 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:31,905 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:31,905 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_1
2017-08-24 16:09:32,146 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:32,147 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:32,165 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:32,166 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:32,166 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:32,170 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:32,170 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:32,170 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:32,170 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_2
2017-08-24 16:09:32,409 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:32,409 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:32,425 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:32,425 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:32,425 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:32,429 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:32,429 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:32,429 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:32,429 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_4
2017-08-24 16:09:32,670 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:32,670 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:32,688 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:32,688 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:32,688 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:32,692 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:32,692 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:32,692 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:32,692 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:09:32,933 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:32,933 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:32,949 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:32,949 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:32,949 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:32,953 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:32,953 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:32,954 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:32,954 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:09:33,193 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:33,193 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:33,209 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:33,209 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:33,209 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:33,214 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:33,214 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:33,214 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:33,214 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_3
2017-08-24 16:09:33,454 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:33,454 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:33,473 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:33,473 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:33,473 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:33,477 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:33,477 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:33,477 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:33,477 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:33,715 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:33,715 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:33,734 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:33,735 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:33,735 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:33,739 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:33,739 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:33,739 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:33,739 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_2
2017-08-24 16:09:33,979 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:33,979 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:33,996 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:33,996 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:33,996 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:34,000 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:34,000 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:34,001 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:34,001 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.U.Trunk_ImageColl_2
2017-08-24 16:09:34,239 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:34,239 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:34,257 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:34,257 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:34,257 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:34,261 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:34,261 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:34,261 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:34,261 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_1
2017-08-24 16:09:34,262 log.framework MainThread  ERROR      HDF5Files already there
2017-08-24 16:09:34,502 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:34,502 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:34,519 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:34,519 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:34,519 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:34,523 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:34,523 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:34,523 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:34,523 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:34,757 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:34,758 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:34,776 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:34,776 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:34,776 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:34,780 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:34,781 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:34,781 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:34,781 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:09:35,016 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:35,016 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:35,034 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:35,034 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:35,034 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:35,038 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:35,039 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:35,039 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:35,039 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_1
2017-08-24 16:09:35,276 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:35,277 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:35,295 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:35,295 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:35,295 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:35,299 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:35,299 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:35,299 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:35,299 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_2
2017-08-24 16:09:35,538 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:35,538 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:35,557 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:35,557 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:35,557 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:35,561 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:35,561 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:35,561 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:35,561 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_3
2017-08-24 16:09:35,814 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:35,814 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:35,833 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:35,833 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:35,833 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:35,838 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:35,838 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:35,838 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:35,838 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_10
2017-08-24 16:09:36,026 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:36,026 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:36,042 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:36,042 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:36,042 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:36,047 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:36,047 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:36,047 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:36,047 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:09:36,285 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:36,286 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:36,305 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:36,305 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:36,305 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:36,309 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:36,309 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:36,309 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:36,309 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:09:36,553 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:36,553 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:36,573 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:36,574 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:36,574 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:36,578 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:36,578 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:36,578 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:36,578 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_4
2017-08-24 16:09:36,819 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:36,819 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:36,835 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:36,835 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:36,835 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:36,839 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:36,840 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:36,840 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:36,840 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_10
2017-08-24 16:09:37,077 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:37,077 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:37,095 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:37,095 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:37,095 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:37,099 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:37,100 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:37,100 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:37,100 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:09:37,336 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:37,336 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:37,354 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:37,354 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:37,354 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:37,358 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:37,358 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:37,359 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:37,359 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:09:37,595 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:37,595 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:37,613 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:37,613 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:37,613 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:37,617 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:37,617 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:37,618 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:37,618 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_2
2017-08-24 16:09:37,854 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:37,854 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:37,873 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:37,873 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:37,873 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:37,878 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:37,878 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:37,878 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:37,878 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_6
2017-08-24 16:09:38,113 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:38,114 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:38,131 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:38,132 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:38,132 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:38,136 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:38,136 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:38,136 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:38,136 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_5
2017-08-24 16:09:38,371 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:38,371 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:38,389 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:38,389 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:38,389 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:38,393 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:38,393 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:38,394 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:38,394 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_4
2017-08-24 16:09:38,628 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:38,629 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:38,646 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:38,647 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:38,647 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:38,651 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:38,651 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:38,651 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:38,651 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_3
2017-08-24 16:09:38,889 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:38,889 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:38,906 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:38,906 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:38,906 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:38,910 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:38,910 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:38,910 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:38,910 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_2
2017-08-24 16:09:39,147 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:39,147 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:39,163 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:39,163 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:39,163 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:39,167 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:39,167 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:39,167 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:39,167 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_1
2017-08-24 16:09:39,404 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:39,405 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:39,422 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:39,423 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:39,423 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:39,427 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:39,427 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:39,427 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:39,427 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_8
2017-08-24 16:09:39,664 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:39,664 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:39,680 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:39,680 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:39,680 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:39,684 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:39,684 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:39,684 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:39,685 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_1
2017-08-24 16:09:39,923 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:39,923 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:39,942 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:39,942 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:39,942 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:39,946 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:39,946 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:39,946 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:39,946 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_2
2017-08-24 16:09:40,182 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:40,182 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:40,198 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:40,198 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:40,198 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:40,202 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:40,203 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:40,203 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:40,203 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_7
2017-08-24 16:09:40,444 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:40,444 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:40,462 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:40,462 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:40,462 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:40,466 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:40,466 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:40,466 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:40,467 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_2
2017-08-24 16:09:40,702 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:40,703 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:40,721 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:40,721 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:40,721 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:40,725 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:40,725 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:40,725 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:40,725 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_1
2017-08-24 16:09:40,962 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:40,962 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:40,980 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:40,980 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:40,980 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:40,984 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:40,984 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:40,984 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:40,985 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_8
2017-08-24 16:09:41,230 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:41,230 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:41,247 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:41,247 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:41,247 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:41,251 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:41,251 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:41,251 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:41,251 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_2
2017-08-24 16:09:41,433 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:41,434 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:41,449 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:41,449 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:41,449 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:41,453 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:41,453 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:41,453 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:41,453 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_9
2017-08-24 16:09:41,638 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:41,639 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:41,655 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:41,655 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:41,656 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:41,660 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:41,660 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:41,660 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:41,660 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.U.Trunk_ImageColl_2
2017-08-24 16:09:41,842 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:41,843 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:41,859 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:41,859 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:41,859 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:41,863 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:41,863 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:41,863 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:41,864 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:42,048 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:42,048 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:42,064 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:42,064 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:42,064 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:42,068 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:42,068 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:42,068 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:42,068 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_1
2017-08-24 16:09:42,251 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:42,251 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:42,267 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:42,268 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:42,268 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:42,272 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:42,272 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:42,272 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:42,272 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_1
2017-08-24 16:09:42,454 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:42,455 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:42,470 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:42,470 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:42,470 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:42,474 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:42,474 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:42,474 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:42,474 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:09:42,657 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:42,657 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:42,673 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:42,673 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:42,673 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:42,678 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:42,678 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:42,678 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:42,678 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:42,863 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:42,863 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:42,878 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:42,878 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:42,879 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:42,883 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:42,883 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:42,883 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:42,883 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_3
2017-08-24 16:09:43,056 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:43,056 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:43,072 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:43,072 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:43,072 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:43,076 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:43,076 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:43,076 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:43,076 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_4
2017-08-24 16:09:43,249 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:43,249 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:43,265 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:43,265 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:43,265 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:43,270 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:43,270 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:43,270 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:43,270 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_5
2017-08-24 16:09:43,452 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:43,452 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:43,468 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:43,468 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:43,468 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:43,472 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:43,472 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:43,472 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:43,472 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_6
2017-08-24 16:09:43,655 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:43,655 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:43,673 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:43,673 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:43,674 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:43,677 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:43,678 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:43,678 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:43,678 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_9
2017-08-24 16:09:43,864 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:43,864 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:43,884 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:43,884 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:43,884 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:43,888 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:43,888 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:43,889 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:43,889 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_6
2017-08-24 16:09:44,079 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:44,079 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:44,097 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:44,097 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:44,097 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:44,101 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:44,101 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:44,101 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:44,101 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_7
2017-08-24 16:09:44,293 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:44,293 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:44,311 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:44,311 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:44,311 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:44,316 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:44,316 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:44,316 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:44,316 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_4
2017-08-24 16:09:44,508 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:44,508 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:44,526 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:44,526 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:44,526 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:44,530 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:44,530 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:44,530 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:44,530 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_5
2017-08-24 16:09:44,720 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:44,720 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:44,738 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:44,738 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:44,738 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:44,742 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:44,742 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:44,742 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:44,742 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_2
2017-08-24 16:09:44,932 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:44,932 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:44,950 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:44,950 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:44,950 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:44,954 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:44,954 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:44,954 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:44,954 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_3
2017-08-24 16:09:45,145 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:45,145 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:45,163 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:45,163 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:45,164 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:45,168 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:45,168 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:45,168 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:45,168 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_1
2017-08-24 16:09:45,168 log.framework MainThread  ERROR      HDF5Files already there
2017-08-24 16:09:45,361 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:45,361 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:45,379 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:45,379 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:45,379 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:45,383 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:45,383 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:45,383 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:45,383 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:09:45,574 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:45,574 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:45,592 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:45,592 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:45,592 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:45,596 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:45,597 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:45,597 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:45,597 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_2
2017-08-24 16:09:45,755 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:45,755 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:45,772 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:45,772 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:45,772 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:45,776 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:45,776 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:45,776 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:45,776 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_4
2017-08-24 16:09:46,010 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:46,010 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:46,030 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:46,030 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:46,030 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:46,034 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:46,034 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:46,034 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:46,034 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_1
2017-08-24 16:09:46,272 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:46,272 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:46,288 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:46,288 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:46,289 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:46,293 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:46,293 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:46,293 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:46,293 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_2
2017-08-24 16:09:46,522 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:46,522 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:46,539 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:46,539 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:46,539 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:46,543 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:46,543 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:46,543 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:46,543 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_3
2017-08-24 16:09:46,786 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:46,786 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:46,803 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:46,803 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:46,803 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:46,807 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:46,807 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:46,808 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:46,808 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_10
2017-08-24 16:09:47,045 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:47,045 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:47,063 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:47,063 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:47,063 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:47,067 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:47,067 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:47,067 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:47,067 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:09:47,303 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:47,304 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:47,322 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:47,322 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:47,322 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:47,326 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:47,326 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:47,326 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:47,326 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_1
2017-08-24 16:09:47,563 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:47,563 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:47,582 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:47,582 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:47,582 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:47,586 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:47,586 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:47,586 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:47,586 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_1
2017-08-24 16:09:47,825 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:47,825 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:47,842 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:47,842 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:47,842 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:47,847 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:47,847 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:47,847 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:47,847 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_10
2017-08-24 16:09:48,084 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:48,085 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:48,103 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:48,103 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:48,103 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:48,107 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:48,107 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:48,107 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:48,107 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.U.Trunk_ImageColl_2
2017-08-24 16:09:48,343 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:48,343 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:48,361 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:48,362 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:48,362 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:48,366 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:48,366 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:48,366 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:48,366 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:09:48,601 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:48,602 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:48,620 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:48,620 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:48,620 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:48,624 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:48,624 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:48,624 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:48,625 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_6
2017-08-24 16:09:48,859 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:48,859 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:48,878 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:48,878 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:48,878 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:48,882 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:48,883 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:48,883 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:48,883 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_5
2017-08-24 16:09:49,118 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:49,118 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:49,136 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:49,136 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:49,136 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:49,140 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:49,140 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:49,140 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:49,140 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_4
2017-08-24 16:09:49,377 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:49,377 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:49,396 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:49,396 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:49,396 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:49,400 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:49,400 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:49,400 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:49,400 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_3
2017-08-24 16:09:49,636 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:49,636 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:49,653 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:49,653 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:49,653 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:49,657 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:49,657 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:49,657 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:49,657 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_2
2017-08-24 16:09:49,894 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:49,894 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:49,913 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:49,914 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:49,914 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:49,918 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:49,918 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:49,918 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:49,918 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_1
2017-08-24 16:09:50,157 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:50,157 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:50,173 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:50,173 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:50,174 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:50,178 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:50,178 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:50,178 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:50,178 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:09:50,417 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:50,417 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:50,435 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:50,435 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:50,435 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:50,439 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:50,439 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:50,439 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:50,439 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:09:50,678 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:50,679 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:50,697 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:50,697 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:50,697 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:50,701 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:50,702 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:50,702 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:50,702 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_8
2017-08-24 16:09:50,993 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:50,993 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:51,011 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:51,011 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:51,011 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:51,015 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:51,015 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:51,015 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:51,015 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:09:51,199 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:51,199 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:51,214 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:51,215 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:51,215 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:51,219 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:51,219 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:51,219 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:51,219 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_1
2017-08-24 16:09:51,401 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:51,402 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:51,417 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:51,417 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:51,417 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:51,421 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:51,421 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:51,421 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:51,421 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_2
2017-08-24 16:09:51,604 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:51,604 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:51,619 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:51,619 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:51,619 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:51,623 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:51,623 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:51,623 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:51,623 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_7
2017-08-24 16:09:51,806 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:51,807 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:51,821 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:51,822 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:51,822 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:51,826 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:51,826 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:51,826 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:51,826 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_2
2017-08-24 16:09:52,008 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:52,008 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:52,023 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:52,024 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:52,024 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:52,028 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:52,028 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:52,028 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:52,028 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_1
2017-08-24 16:09:52,202 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:52,202 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:52,217 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:52,217 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:52,217 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:52,221 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:52,221 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:52,221 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:52,221 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_8
2017-08-24 16:09:52,394 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:52,394 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:52,409 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:52,409 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:52,409 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:52,413 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:52,414 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:52,414 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:52,414 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_2
2017-08-24 16:09:52,584 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:52,585 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:52,600 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:52,600 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:52,600 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:52,604 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:52,604 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:52,605 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:52,605 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_4
2017-08-24 16:09:52,777 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:52,777 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:52,793 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:52,793 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:52,793 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:52,797 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:52,797 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:52,797 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:52,797 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_9
2017-08-24 16:09:52,980 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:52,980 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:52,995 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:52,996 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:52,996 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:53,000 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:53,000 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:53,000 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:53,000 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_1
2017-08-24 16:09:53,191 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:53,191 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:53,209 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:53,209 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:53,209 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:53,214 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:53,214 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:53,214 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:53,214 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_2
2017-08-24 16:09:53,403 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:53,404 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:53,420 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:53,420 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:53,420 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:53,424 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:53,424 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:53,424 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:53,424 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_4
2017-08-24 16:09:53,615 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:53,615 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:53,634 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:53,635 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:53,635 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:53,639 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:53,639 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:53,639 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:53,639 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:53,831 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:53,831 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:53,848 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:53,848 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:53,848 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:53,852 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:53,852 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:53,852 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:53,852 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:09:54,044 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:54,044 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:54,060 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:54,060 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:54,061 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:54,065 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:54,065 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:54,065 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:54,065 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:09:54,256 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:54,256 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:54,274 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:54,274 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:54,274 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:54,279 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:54,279 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:54,279 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:54,279 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_3
2017-08-24 16:09:54,470 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:54,470 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:54,488 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:54,489 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:54,489 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:54,493 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:54,493 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:54,493 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:54,493 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:09:54,684 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:54,684 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:54,702 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:54,702 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:54,702 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:54,706 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:54,706 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:54,706 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:54,707 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:54,897 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:54,897 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:54,916 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:54,916 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:54,916 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:54,920 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:54,920 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:54,920 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:54,920 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_3
2017-08-24 16:09:55,112 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:55,112 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:55,130 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:55,130 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:55,130 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:55,134 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:55,135 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:55,135 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:55,135 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_4
2017-08-24 16:09:55,325 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:55,326 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:55,344 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:55,344 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:55,344 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:55,348 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:55,348 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:55,348 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:55,348 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_5
2017-08-24 16:09:55,512 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:55,512 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:55,528 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:55,528 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:55,528 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:55,532 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:55,532 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:55,532 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:55,532 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_6
2017-08-24 16:09:55,716 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:55,716 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:55,733 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:55,733 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:55,733 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:55,737 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:55,737 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:55,737 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:55,737 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_9
2017-08-24 16:09:55,926 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:55,926 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:55,945 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:55,945 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:55,945 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:55,949 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:55,949 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:55,949 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:55,949 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_6
2017-08-24 16:09:56,187 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:56,187 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:56,205 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:56,205 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:56,205 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:56,209 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:56,209 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:56,209 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:56,209 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_7
2017-08-24 16:09:56,447 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:56,448 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:56,465 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:56,465 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:56,465 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:56,469 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:56,469 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:56,469 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:56,470 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_4
2017-08-24 16:09:56,706 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:56,706 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:56,721 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:56,721 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:56,721 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:56,725 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:56,726 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:56,726 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:56,726 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_5
2017-08-24 16:09:56,963 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:56,963 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:56,980 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:56,980 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:56,980 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:56,985 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:56,985 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:56,985 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:56,985 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_2
2017-08-24 16:09:57,220 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:57,220 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:57,236 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:57,236 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:57,236 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:57,240 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:57,240 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:57,240 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:57,240 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_3
2017-08-24 16:09:57,475 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:57,475 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:57,494 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:57,495 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:57,495 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:57,499 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:57,499 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:57,499 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:57,499 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_1
2017-08-24 16:09:57,499 log.framework MainThread  ERROR      HDF5Files already there
2017-08-24 16:09:57,736 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:57,737 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:57,755 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:57,755 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:57,756 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:57,760 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:57,760 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:57,760 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:57,760 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:09:57,996 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:57,997 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:58,014 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:58,014 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:58,014 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:58,018 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:58,018 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:58,018 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:58,018 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:09:58,253 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:58,253 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:58,271 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:58,272 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:58,272 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:58,276 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:58,276 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:58,276 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:58,276 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_1
2017-08-24 16:09:58,511 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:58,511 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:58,527 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:58,527 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:58,527 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:58,531 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:58,531 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:58,531 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:58,532 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_2
2017-08-24 16:09:58,773 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:58,773 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:58,792 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:58,792 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:58,792 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:58,796 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:58,796 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:58,796 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:58,796 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_3
2017-08-24 16:09:59,032 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:59,032 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:59,049 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:59,049 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:59,049 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:59,054 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:59,054 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:59,054 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:59,054 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_10
2017-08-24 16:09:59,292 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:59,292 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:59,311 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:59,311 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:59,311 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:59,315 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:59,315 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:59,315 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:59,315 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:09:59,556 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:59,556 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:59,573 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:59,573 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:59,573 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:59,578 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:59,578 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:59,578 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:59,578 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:09:59,816 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:09:59,817 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:09:59,834 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:09:59,835 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:09:59,835 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:09:59,839 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:09:59,839 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:09:59,839 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:09:59,839 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_4
2017-08-24 16:10:00,076 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:00,077 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:00,094 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:00,094 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:00,094 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:00,098 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:00,098 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:00,098 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:00,098 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_10
2017-08-24 16:10:00,349 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:00,349 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:00,366 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:00,366 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:00,366 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:00,371 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:00,371 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:00,371 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:00,371 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.U.Trunk_ImageColl_2
2017-08-24 16:10:00,623 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:00,623 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:00,639 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:00,639 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:00,640 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:00,644 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:00,644 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:00,644 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:00,644 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:10:00,802 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:00,802 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:00,817 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:00,817 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:00,817 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:00,821 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:00,821 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:00,821 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:00,821 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_6
2017-08-24 16:10:01,009 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:01,009 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:01,028 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:01,028 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:01,028 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:01,032 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:01,032 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:01,032 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:01,032 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_5
2017-08-24 16:10:01,267 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:01,267 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:01,287 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:01,287 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:01,287 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:01,291 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:01,291 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:01,292 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:01,292 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_4
2017-08-24 16:10:01,530 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:01,531 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:01,547 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:01,547 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:01,547 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:01,551 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:01,551 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:01,551 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:01,552 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_3
2017-08-24 16:10:01,789 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:01,789 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:01,805 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:01,805 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:01,806 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:01,810 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:01,810 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:01,810 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:01,810 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_2
2017-08-24 16:10:02,044 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:02,044 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:02,065 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:02,065 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:02,065 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:02,069 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:02,070 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:02,070 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:02,070 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_1
2017-08-24 16:10:02,308 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:02,308 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:02,326 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:02,326 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:02,326 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:02,330 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:02,330 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:02,330 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:02,331 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:10:02,571 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:02,571 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:02,588 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:02,588 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:02,588 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:02,592 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:02,593 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:02,593 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:02,593 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:10:02,831 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:02,831 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:02,849 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:02,849 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:02,849 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:02,853 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:02,853 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:02,853 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:02,853 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_8
2017-08-24 16:10:03,089 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:03,089 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:03,106 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:03,107 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:03,107 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:03,111 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:03,111 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:03,111 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:03,111 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:10:03,348 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:03,348 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:03,366 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:03,366 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:03,366 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:03,370 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:03,370 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:03,370 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:03,370 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_1
2017-08-24 16:10:03,604 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:03,605 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:03,622 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:03,622 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:03,622 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:03,626 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:03,626 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:03,626 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:03,626 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_2
2017-08-24 16:10:03,863 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:03,863 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:03,881 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:03,881 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:03,881 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:03,885 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:03,885 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:03,886 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:03,886 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_7
2017-08-24 16:10:04,121 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:04,121 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:04,138 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:04,139 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:04,139 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:04,143 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:04,143 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:04,143 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:04,143 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_8
2017-08-24 16:10:04,380 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:04,380 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:04,398 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:04,398 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:04,398 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:04,402 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:04,402 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:04,402 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:04,402 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_4
2017-08-24 16:10:04,637 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:04,637 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:04,654 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:04,654 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:04,654 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:04,658 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:04,659 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:04,659 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:04,659 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_9
2017-08-24 16:10:04,895 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:04,895 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:04,913 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:04,914 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:04,914 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:04,918 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:04,918 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:04,918 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:04,918 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_1
2017-08-24 16:10:05,156 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:05,156 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:05,173 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:05,173 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:05,173 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:05,177 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:05,177 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:05,177 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:05,178 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_2
2017-08-24 16:10:05,418 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:05,418 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:05,437 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:05,437 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:05,437 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:05,441 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:05,441 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:05,441 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:05,441 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_4
2017-08-24 16:10:05,683 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:05,683 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:05,700 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:05,700 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:05,700 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:05,704 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:05,704 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:05,705 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:05,705 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:10:05,956 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:05,956 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:05,974 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:05,974 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:05,974 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:05,978 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:05,979 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:05,979 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:05,979 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:10:06,167 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:06,167 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:06,182 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:06,183 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:06,183 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:06,187 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:06,187 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:06,187 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:06,188 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:10:06,370 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:06,370 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:06,385 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:06,386 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:06,386 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:06,390 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:06,390 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:06,390 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:06,390 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_3
2017-08-24 16:10:06,610 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:06,611 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:06,628 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:06,628 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:06,628 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:06,632 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:06,632 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:06,633 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:06,633 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:10:06,869 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:06,869 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:06,887 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:06,887 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:06,887 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:06,891 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:06,891 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:06,892 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:06,892 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:10:07,127 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:07,127 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:07,142 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:07,143 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:07,143 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:07,147 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:07,147 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:07,147 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:07,147 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_3
2017-08-24 16:10:07,386 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:07,386 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:07,403 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:07,403 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:07,403 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:07,407 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:07,408 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:07,408 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:07,408 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_4
2017-08-24 16:10:07,643 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:07,643 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:07,658 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:07,659 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:07,659 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:07,663 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:07,663 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:07,663 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:07,663 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_5
2017-08-24 16:10:07,897 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:07,897 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:07,916 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:07,916 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:07,916 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:07,920 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:07,920 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:07,921 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:07,921 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_6
2017-08-24 16:10:08,157 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:08,157 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:08,176 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:08,176 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:08,176 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:08,180 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:08,181 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:08,181 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:08,181 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_9
2017-08-24 16:10:08,416 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:08,416 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:08,433 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:08,433 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:08,433 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:08,437 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:08,438 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:08,438 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:08,438 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_6
2017-08-24 16:10:08,674 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:08,674 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:08,693 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:08,693 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:08,693 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:08,697 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:08,697 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:08,698 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:08,698 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_7
2017-08-24 16:10:08,933 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:08,934 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:08,950 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:08,951 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:08,951 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:08,955 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:08,955 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:08,955 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:08,955 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_4
2017-08-24 16:10:09,187 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:09,187 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:09,202 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:09,203 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:09,203 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:09,207 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:09,207 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:09,207 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:09,207 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_5
2017-08-24 16:10:09,449 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:09,449 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:09,465 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:09,465 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:09,465 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:09,469 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:09,469 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:09,469 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:09,469 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_2
2017-08-24 16:10:09,706 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:09,706 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:09,725 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:09,725 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:09,725 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:09,729 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:09,729 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:09,729 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:09,729 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_3
2017-08-24 16:10:09,966 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:09,966 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:09,984 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:09,985 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:09,985 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:09,989 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:09,989 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:09,989 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:09,989 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_1
2017-08-24 16:10:09,990 log.framework MainThread  ERROR      HDF5Files already there
2017-08-24 16:10:10,228 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:10,229 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:10,244 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:10,244 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:10,244 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:10,248 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:10,248 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:10,248 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:10,248 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:10:10,488 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:10,488 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:10,503 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:10,504 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:10,504 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:10,508 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:10,508 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:10,508 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:10,508 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:10:10,752 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:10,752 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:10,769 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:10,770 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:10,770 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:10,774 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:10,774 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:10,774 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:10,774 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:10:11,022 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:11,022 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:11,039 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:11,039 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:11,040 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:11,044 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:11,044 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:11,044 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:11,044 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_4
2017-08-24 16:10:11,631 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:11,631 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:11,649 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:11,649 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:11,649 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:11,653 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:11,653 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:11,654 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:11,654 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Post.L.Hand_ImageColl_3
2017-08-24 16:10:11,842 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:11,842 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:11,858 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:11,858 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:11,859 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:11,863 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:11,863 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:11,863 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:11,863 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_10
2017-08-24 16:10:12,047 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:12,047 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:12,064 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:12,064 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:12,064 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:12,068 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:12,068 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:12,068 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:12,068 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:10:12,254 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:12,254 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:12,270 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:12,270 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:12,270 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:12,274 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:12,274 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:12,274 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:12,275 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_1
2017-08-24 16:10:12,457 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:12,457 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:12,473 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:12,473 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:12,473 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:12,477 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:12,477 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:12,477 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:12,477 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_1
2017-08-24 16:10:12,652 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:12,652 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:12,667 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:12,668 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:12,668 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:12,672 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:12,672 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:12,672 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:12,672 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_10
2017-08-24 16:10:12,854 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:12,854 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:12,869 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:12,870 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:12,870 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:12,874 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:12,874 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:12,874 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:12,874 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study11_Ant.L.U.Trunk_ImageColl_2
2017-08-24 16:10:13,047 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:13,048 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:13,064 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:13,065 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:13,065 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:13,069 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:13,069 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:13,069 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:13,069 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:10:13,254 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:13,254 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:13,270 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:13,271 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:13,271 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:13,275 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:13,275 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:13,275 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:13,275 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_2
2017-08-24 16:10:13,458 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:13,458 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:13,474 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:13,474 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:13,474 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:13,478 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:13,478 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:13,478 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:13,478 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_6
2017-08-24 16:10:13,664 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:13,664 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:13,682 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:13,683 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:13,683 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:13,687 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:13,687 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:13,687 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:13,687 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_5
2017-08-24 16:10:13,871 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:13,871 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:13,887 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:13,887 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:13,887 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:13,891 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:13,891 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:13,891 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:13,891 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_4
2017-08-24 16:10:14,082 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:14,082 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:14,098 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:14,098 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:14,098 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:14,102 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:14,102 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:14,102 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:14,102 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_3
2017-08-24 16:10:14,292 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:14,292 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:14,311 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:14,311 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:14,311 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:14,315 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:14,315 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:14,315 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:14,315 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_2
2017-08-24 16:10:14,507 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:14,507 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:14,523 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:14,523 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:14,523 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:14,527 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:14,528 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:14,528 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:14,528 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_1
2017-08-24 16:10:14,717 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:14,718 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:14,736 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:14,736 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:14,736 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:14,740 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:14,740 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:14,740 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:14,740 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:10:14,931 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:14,931 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:14,949 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:14,949 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:14,949 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:14,954 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:14,954 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:14,954 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:14,954 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:10:15,145 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:15,145 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:15,164 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:15,164 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:15,164 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:15,168 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:15,168 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:15,168 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:15,168 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_8
2017-08-24 16:10:15,358 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:15,358 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:15,376 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:15,376 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:15,376 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:15,380 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:15,380 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:15,380 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:15,381 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient14_Burn_Study13_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:10:15,576 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:15,576 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:15,594 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:15,594 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:15,594 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:15,598 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:15,599 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:15,599 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:15,599 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_7
2017-08-24 16:10:15,796 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:15,796 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:15,814 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:15,814 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:15,814 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:15,819 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:15,819 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:15,819 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:15,819 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_2
2017-08-24 16:10:16,020 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:16,020 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:16,039 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:16,039 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:16,039 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:16,043 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:16,043 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:16,043 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:16,043 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_1
2017-08-24 16:10:16,197 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:16,198 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:16,213 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:16,213 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:16,213 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:16,217 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:16,217 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:16,217 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:16,218 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_8
2017-08-24 16:10:16,406 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:16,407 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:16,427 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:16,428 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:16,428 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:16,432 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:16,432 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:16,432 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:16,432 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_2
2017-08-24 16:10:16,667 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:16,667 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:16,684 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:16,684 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:16,684 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:16,688 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:16,689 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:16,689 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:16,689 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_4
2017-08-24 16:10:16,924 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:16,924 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:16,942 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:16,942 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:16,942 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:16,946 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:16,946 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:16,947 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:16,947 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_9
2017-08-24 16:10:17,182 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:17,182 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:17,199 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:17,199 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:17,199 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:17,203 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:17,203 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:17,204 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:17,204 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_1
2017-08-24 16:10:17,440 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:17,440 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:17,457 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:17,458 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:17,458 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:17,462 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:17,462 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:17,462 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:17,463 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_2
2017-08-24 16:10:17,698 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:17,698 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:17,713 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:17,713 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:17,713 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:17,718 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:17,718 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:17,718 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:17,718 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_4
2017-08-24 16:10:17,956 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:17,956 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:17,974 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:17,974 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:17,974 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:17,979 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:17,979 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:17,979 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:17,979 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:10:18,218 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:18,218 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:18,234 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:18,234 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:18,234 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:18,238 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:18,238 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:18,238 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:18,238 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:10:18,475 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:18,475 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:18,492 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:18,492 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:18,493 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:18,497 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:18,497 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:18,497 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:18,497 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_3
2017-08-24 16:10:18,732 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:18,733 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:18,748 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:18,748 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:18,748 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:18,752 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:18,752 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:18,752 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:18,752 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:10:18,992 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:18,992 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:19,010 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:19,010 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:19,010 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:19,014 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:19,015 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:19,015 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:19,015 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:10:19,251 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:19,251 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:19,267 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:19,267 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:19,267 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:19,271 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:19,271 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:19,271 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:19,271 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_3
2017-08-24 16:10:19,511 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:19,511 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:19,529 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:19,529 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:19,529 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:19,533 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:19,533 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:19,533 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:19,533 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_4
2017-08-24 16:10:19,770 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:19,770 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:19,786 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:19,786 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:19,786 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:19,790 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:19,790 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:19,790 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:19,790 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_5
2017-08-24 16:10:20,038 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:20,038 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:20,056 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:20,056 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:20,056 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:20,060 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:20,061 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:20,061 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:20,061 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_6
2017-08-24 16:10:20,306 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:20,306 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:20,322 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:20,322 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:20,322 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:20,326 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:20,327 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:20,327 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:20,327 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_9
2017-08-24 16:10:20,581 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:20,581 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:20,598 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:20,598 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:20,598 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:20,602 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:20,603 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:20,603 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:20,603 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_6
2017-08-24 16:10:21,003 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:21,003 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:21,019 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:21,019 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:21,019 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:21,023 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:21,023 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:21,023 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:21,023 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_7
2017-08-24 16:10:21,287 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:21,287 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:21,305 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:21,305 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:21,305 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:21,310 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:21,310 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:21,310 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:21,310 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_4
2017-08-24 16:10:21,603 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:21,603 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:21,619 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:21,619 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:21,620 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:21,624 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:21,624 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:21,624 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:21,624 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_5
2017-08-24 16:10:21,818 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:21,818 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:21,834 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:21,834 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:21,834 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:21,838 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:21,839 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:21,839 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:21,839 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_2
2017-08-24 16:10:22,073 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:22,073 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:22,088 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:22,088 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:22,089 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:22,093 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:22,093 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:22,093 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:22,093 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_3
2017-08-24 16:10:22,328 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:22,328 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:22,346 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:22,346 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:22,346 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:22,350 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:22,350 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:22,350 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:22,350 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_1
2017-08-24 16:10:22,351 log.framework MainThread  ERROR      HDF5Files already there
2017-08-24 16:10:22,590 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:22,590 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:22,609 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:22,609 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:22,609 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:22,613 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:22,613 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:22,613 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:22,613 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:10:22,852 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:22,852 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:22,868 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:22,868 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:22,868 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:22,872 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:22,872 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:22,872 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:22,872 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient12_Burn_Study16_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:10:23,105 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:23,105 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:23,123 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:23,123 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:23,123 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:23,127 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:23,128 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:23,128 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:23,128 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_1
2017-08-24 16:10:23,365 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:23,365 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:23,382 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:23,382 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:23,382 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:23,386 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:23,386 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:23,386 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:23,386 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.Head_ImageColl_2
2017-08-24 16:10:23,622 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:23,622 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:23,640 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:23,640 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:23,640 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:23,644 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:23,644 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:23,644 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:23,644 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_10
2017-08-24 16:10:23,881 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:23,881 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:23,899 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:23,899 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:23,899 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:23,903 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:23,903 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:23,903 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:23,903 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_1
2017-08-24 16:10:24,139 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:24,139 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:24,157 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:24,157 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:24,157 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:24,162 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:24,162 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:24,162 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:24,162 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_1
2017-08-24 16:10:24,400 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:24,400 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:24,417 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:24,418 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:24,418 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:24,422 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:24,422 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:24,422 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:24,422 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_10
2017-08-24 16:10:24,658 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:24,658 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:24,675 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:24,676 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:24,676 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:24,680 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:24,680 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:24,680 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:24,680 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Leg_ImageColl_2
2017-08-24 16:10:24,917 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:24,917 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:24,935 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:24,935 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:24,935 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:24,939 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:24,939 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:24,939 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:24,939 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_6
2017-08-24 16:10:25,177 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:25,177 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:25,195 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:25,195 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:25,195 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:25,199 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:25,199 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:25,199 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:25,199 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_5
2017-08-24 16:10:25,442 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:25,443 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:25,460 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:25,460 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:25,460 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:25,464 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:25,464 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:25,464 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:25,464 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_4
2017-08-24 16:10:25,721 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:25,721 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:25,739 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:25,739 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:25,739 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:25,743 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:25,743 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:25,743 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:25,743 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_3
2017-08-24 16:10:26,008 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:26,008 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:26,025 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:26,025 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:26,026 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:26,030 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:26,030 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:26,030 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:26,030 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_2
2017-08-24 16:10:26,329 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:26,329 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:26,347 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:26,348 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:26,348 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:26,352 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:26,352 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:26,352 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:26,352 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient7_Ant.R.Leg_ImageColl_1
2017-08-24 16:10:26,724 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:26,724 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:26,740 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:26,740 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:26,740 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:26,744 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:26,744 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:26,744 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:26,744 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_1
2017-08-24 16:10:27,116 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:27,116 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:27,133 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:27,133 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:27,134 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:27,138 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:27,138 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:27,138 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:27,138 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.Shoulder_ImageColl_2
2017-08-24 16:10:27,596 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:27,596 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:27,672 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:27,672 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:27,672 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:27,676 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:27,676 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:27,676 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:27,676 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_8
2017-08-24 16:10:27,897 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:27,897 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:27,916 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:27,916 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:27,916 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:27,920 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:27,920 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:27,920 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:27,920 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_1
2017-08-24 16:10:28,162 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:28,162 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:28,178 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:28,178 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:28,178 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:28,182 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:28,182 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:28,182 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:28,182 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.Shoulder_ImageColl_2
2017-08-24 16:10:28,418 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:28,419 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:28,434 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:28,434 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:28,434 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:28,438 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:28,438 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:28,438 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:28,439 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_7
2017-08-24 16:10:28,676 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:28,676 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:28,694 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:28,695 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:28,695 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:28,699 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:28,699 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:28,699 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:28,699 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_2
2017-08-24 16:10:28,936 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:28,936 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:28,955 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:28,955 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:28,955 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:28,960 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:28,960 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:28,960 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:28,960 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.R.Thigh_ImageColl_1
2017-08-24 16:10:29,200 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:29,200 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:29,215 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:29,216 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:29,216 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:29,220 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:29,220 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:29,220 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:29,220 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_8
2017-08-24 16:10:29,469 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:29,469 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:29,488 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:29,488 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:29,489 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:29,493 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:29,493 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:29,493 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:29,493 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient11_Burn_Study15_Ant.L.Thigh_ImageColl_2
2017-08-24 16:10:29,780 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:29,780 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:29,796 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:29,797 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:29,797 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:29,801 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:29,801 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:29,801 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:29,801 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_4
2017-08-24 16:10:30,085 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:30,086 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:30,105 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:30,105 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:30,105 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:30,109 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:30,109 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:30,109 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:30,109 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_9
2017-08-24 16:10:30,473 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:30,473 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:30,489 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:30,489 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:30,489 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:30,494 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:30,494 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:30,494 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:30,494 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_1
2017-08-24 16:10:30,871 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:30,872 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:30,891 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:30,891 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:30,891 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:30,895 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:30,895 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:30,895 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:30,895 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_2
2017-08-24 16:10:31,345 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:31,345 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:31,362 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:31,362 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:31,362 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:31,366 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:31,366 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:31,366 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:31,366 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.U.Arm_ImageColl_4
2017-08-24 16:10:31,949 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:31,949 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:31,972 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:31,972 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:31,972 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:31,977 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:31,977 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:31,977 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:31,977 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient15_Burn_Study14_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:10:35,521 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:35,521 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:35,538 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:35,538 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:35,538 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:35,543 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:35,543 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:35,543 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:35,543 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_1
2017-08-24 16:10:35,974 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:35,974 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:35,996 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:35,996 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:35,996 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:36,000 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:36,000 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:36,000 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:36,000 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.R.U.Trunk_ImageColl_2
2017-08-24 16:10:36,425 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:36,425 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:36,446 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:36,446 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:36,446 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:36,450 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:36,450 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:36,450 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:36,450 log.framework MainThread  INFO       h5name _disk1_wiscr_data__Patient13_Burn_Study17_Ant.L.L.Trunk_ImageColl_3
2017-08-24 16:10:36,777 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:36,777 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:36,794 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:36,794 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:36,794 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:36,799 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:36,799 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:36,799 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:36,799 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_1
2017-08-24 16:10:37,118 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:37,118 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:37,139 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:37,139 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:37,139 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:37,143 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:37,143 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:37,143 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:37,143 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_2
2017-08-24 16:10:37,535 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:37,535 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:37,552 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:37,552 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:37,552 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:37,556 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:37,556 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:37,556 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:37,556 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_3
2017-08-24 16:10:37,949 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:37,949 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:37,970 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:37,971 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:37,971 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:37,975 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:37,975 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:37,975 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:37,975 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_4
2017-08-24 16:10:38,499 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:38,499 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:38,518 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:38,518 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:38,518 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:38,522 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:38,522 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:38,523 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:38,523 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_5
2017-08-24 16:10:38,797 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:38,797 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:38,826 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:38,826 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:38,826 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:38,831 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:38,831 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:38,831 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:38,831 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.L.Trunk_ImageColl_6
2017-08-24 16:10:39,094 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:39,094 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:39,111 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:39,111 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:39,111 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:39,115 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:39,115 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:39,115 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:39,115 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_9
2017-08-24 16:10:39,374 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:39,374 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:39,393 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:39,393 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:39,393 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:39,398 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:39,398 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:39,398 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:39,398 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_6
2017-08-24 16:10:39,653 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:39,653 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:39,669 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:39,670 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:39,670 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:39,674 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:39,674 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:39,674 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:39,674 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_7
2017-08-24 16:10:40,002 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:40,002 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:40,021 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:40,021 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:40,021 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:40,025 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:40,025 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:40,025 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:40,025 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_4
2017-08-24 16:10:40,309 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:40,309 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:40,326 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:40,327 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:40,327 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:40,331 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:40,331 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:40,331 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:40,331 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_5
2017-08-24 16:10:40,680 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:40,680 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:40,698 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:40,698 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:40,698 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:40,703 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:40,703 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:40,703 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:40,703 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_2
2017-08-24 16:10:41,091 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:41,091 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:41,112 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:41,112 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:41,112 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:41,116 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:41,116 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:41,116 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:41,116 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_3
2017-08-24 16:10:41,519 log.framework MainThread  INFO       datashape(360, 480, 9, 1), data type uint8
2017-08-24 16:10:41,519 log.framework MainThread  INFO       label shape(360, 480, 1, 1), label type float64
2017-08-24 16:10:41,541 log.framework MainThread  INFO       Each image in the hdf5 database has dimensions: (1, 360, 480)
2017-08-24 16:10:41,541 log.framework MainThread  INFO       Each set of images from one image capture in the hdf5 database has dimensions: (8, 360, 480)
2017-08-24 16:10:41,542 log.framework MainThread  INFO       In the hdf5 database there are a total of 1 images.
2017-08-24 16:10:41,546 log.framework MainThread  INFO       The mask has these unique classes: [ 0.  1.]
2017-08-24 16:10:41,546 log.framework MainThread  INFO       The hdf5 database in located in: HDF5Files
2017-08-24 16:10:41,546 log.framework MainThread  INFO       self.saveloc HDF5Files
2017-08-24 16:10:41,546 log.framework MainThread  INFO       h5name _disk1_poc_data_all__Patient10_Ant.R.Thigh_ImageColl_1
2017-08-24 16:10:41,546 log.framework MainThread  INFO       train file number: 49
2017-08-24 16:10:41,546 log.framework MainThread  INFO       test file number: 6
2017-08-24 16:10:41,546 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 16:10:41,547 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 16:10:41,547 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-08-24 16:10:41,548 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-08-24 16:10:41,548 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-08-24 16:10:41,549 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc1/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc1/training"
solver_mode: GPU

2017-08-24 16:10:41,549 log.framework MainThread  INFO       caffe training step
2017-08-24 16:10:41,549 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc1/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-08-24 17:20:19,862 log.framework MainThread  INFO       I0824 16:10:41.583314 41289 caffe.cpp:217] Using GPUs 0
I0824 16:10:41.595036 41289 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0824 16:10:42.225914 41289 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc1/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc1/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0824 16:10:42.226086 41289 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc1/caffe/model_segnet_final/train.prototxt
I0824 16:10:42.228953 41289 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc1/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 16:10:42.229506 41289 layer_factory.hpp:77] Creating layer data
I0824 16:10:42.229528 41289 net.cpp:100] Creating Layer data
I0824 16:10:42.229538 41289 net.cpp:408] data -> data
I0824 16:10:42.229568 41289 net.cpp:408] data -> label
I0824 16:10:42.229588 41289 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc1/HDF5Files/train_combined.txt
I0824 16:10:42.229660 41289 hdf5_data_layer.cpp:93] Number of HDF5 files: 49
I0824 16:10:42.230995 41289 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0824 16:10:42.257323 41289 net.cpp:150] Setting up data
I0824 16:10:42.257360 41289 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 16:10:42.257378 41289 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 16:10:42.257382 41289 net.cpp:165] Memory required for data: 24883200
I0824 16:10:42.257392 41289 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 16:10:42.257411 41289 net.cpp:100] Creating Layer label_data_1_split
I0824 16:10:42.257423 41289 net.cpp:434] label_data_1_split <- label
I0824 16:10:42.257446 41289 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 16:10:42.257458 41289 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 16:10:42.257500 41289 net.cpp:150] Setting up label_data_1_split
I0824 16:10:42.257508 41289 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 16:10:42.257513 41289 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 16:10:42.257517 41289 net.cpp:165] Memory required for data: 30412800
I0824 16:10:42.257521 41289 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 16:10:42.257542 41289 net.cpp:100] Creating Layer conv1_1_1
I0824 16:10:42.257549 41289 net.cpp:434] conv1_1_1 <- data
I0824 16:10:42.257555 41289 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 16:10:42.792306 41289 net.cpp:150] Setting up conv1_1_1
I0824 16:10:42.792341 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:42.792347 41289 net.cpp:165] Memory required for data: 207360000
I0824 16:10:42.792379 41289 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 16:10:42.792395 41289 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 16:10:42.792402 41289 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 16:10:42.792410 41289 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 16:10:42.792805 41289 net.cpp:150] Setting up conv1_1_1_bn
I0824 16:10:42.792814 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:42.792824 41289 net.cpp:165] Memory required for data: 384307200
I0824 16:10:42.792837 41289 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 16:10:42.792850 41289 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 16:10:42.792856 41289 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 16:10:42.792861 41289 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 16:10:42.792910 41289 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 16:10:42.794626 41289 net.cpp:150] Setting up conv1_1_1_scale
I0824 16:10:42.794641 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:42.794651 41289 net.cpp:165] Memory required for data: 561254400
I0824 16:10:42.794659 41289 layer_factory.hpp:77] Creating layer relu1_1
I0824 16:10:42.794672 41289 net.cpp:100] Creating Layer relu1_1
I0824 16:10:42.794677 41289 net.cpp:434] relu1_1 <- conv1_1_1
I0824 16:10:42.794683 41289 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 16:10:42.794911 41289 net.cpp:150] Setting up relu1_1
I0824 16:10:42.794921 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:42.794926 41289 net.cpp:165] Memory required for data: 738201600
I0824 16:10:42.794930 41289 layer_factory.hpp:77] Creating layer conv1_2
I0824 16:10:42.794944 41289 net.cpp:100] Creating Layer conv1_2
I0824 16:10:42.794948 41289 net.cpp:434] conv1_2 <- conv1_1_1
I0824 16:10:42.794955 41289 net.cpp:408] conv1_2 -> conv1_2
I0824 16:10:42.799194 41289 net.cpp:150] Setting up conv1_2
I0824 16:10:42.799211 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:42.799221 41289 net.cpp:165] Memory required for data: 915148800
I0824 16:10:42.799232 41289 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 16:10:42.799245 41289 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 16:10:42.799253 41289 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 16:10:42.799259 41289 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 16:10:42.800814 41289 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 16:10:42.800829 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:42.800838 41289 net.cpp:165] Memory required for data: 1092096000
I0824 16:10:42.800848 41289 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 16:10:42.800859 41289 net.cpp:100] Creating Layer conv1_2_scale
I0824 16:10:42.800865 41289 net.cpp:434] conv1_2_scale <- conv1_2
I0824 16:10:42.800871 41289 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 16:10:42.800914 41289 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 16:10:42.801287 41289 net.cpp:150] Setting up conv1_2_scale
I0824 16:10:42.801295 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:42.801300 41289 net.cpp:165] Memory required for data: 1269043200
I0824 16:10:42.801306 41289 layer_factory.hpp:77] Creating layer relu1_2
I0824 16:10:42.801314 41289 net.cpp:100] Creating Layer relu1_2
I0824 16:10:42.801319 41289 net.cpp:434] relu1_2 <- conv1_2
I0824 16:10:42.801324 41289 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 16:10:42.801537 41289 net.cpp:150] Setting up relu1_2
I0824 16:10:42.801548 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:42.801553 41289 net.cpp:165] Memory required for data: 1445990400
I0824 16:10:42.801558 41289 layer_factory.hpp:77] Creating layer pool1
I0824 16:10:42.801563 41289 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 16:10:42.801570 41289 net.cpp:100] Creating Layer pool1
I0824 16:10:42.801575 41289 net.cpp:434] pool1 <- conv1_2
I0824 16:10:42.801581 41289 net.cpp:408] pool1 -> pool1
I0824 16:10:42.801591 41289 net.cpp:408] pool1 -> pool1_mask
I0824 16:10:42.801645 41289 net.cpp:150] Setting up pool1
I0824 16:10:42.801653 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:42.801657 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:42.801662 41289 net.cpp:165] Memory required for data: 1534464000
I0824 16:10:42.801666 41289 layer_factory.hpp:77] Creating layer conv2_1
I0824 16:10:42.801676 41289 net.cpp:100] Creating Layer conv2_1
I0824 16:10:42.801681 41289 net.cpp:434] conv2_1 <- pool1
I0824 16:10:42.801687 41289 net.cpp:408] conv2_1 -> conv2_1
I0824 16:10:42.807983 41289 net.cpp:150] Setting up conv2_1
I0824 16:10:42.808001 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:42.808013 41289 net.cpp:165] Memory required for data: 1622937600
I0824 16:10:42.808022 41289 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 16:10:42.808030 41289 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 16:10:42.808037 41289 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 16:10:42.808043 41289 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 16:10:42.808270 41289 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 16:10:42.808279 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:42.808284 41289 net.cpp:165] Memory required for data: 1711411200
I0824 16:10:42.808296 41289 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 16:10:42.808321 41289 net.cpp:100] Creating Layer conv2_1_scale
I0824 16:10:42.808326 41289 net.cpp:434] conv2_1_scale <- conv2_1
I0824 16:10:42.808331 41289 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 16:10:42.808372 41289 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 16:10:42.808548 41289 net.cpp:150] Setting up conv2_1_scale
I0824 16:10:42.808557 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:42.808560 41289 net.cpp:165] Memory required for data: 1799884800
I0824 16:10:42.808568 41289 layer_factory.hpp:77] Creating layer relu2_1
I0824 16:10:42.808575 41289 net.cpp:100] Creating Layer relu2_1
I0824 16:10:42.808580 41289 net.cpp:434] relu2_1 <- conv2_1
I0824 16:10:42.808585 41289 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 16:10:42.809638 41289 net.cpp:150] Setting up relu2_1
I0824 16:10:42.809653 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:42.809659 41289 net.cpp:165] Memory required for data: 1888358400
I0824 16:10:42.809664 41289 layer_factory.hpp:77] Creating layer conv2_2
I0824 16:10:42.809675 41289 net.cpp:100] Creating Layer conv2_2
I0824 16:10:42.809681 41289 net.cpp:434] conv2_2 <- conv2_1
I0824 16:10:42.809689 41289 net.cpp:408] conv2_2 -> conv2_2
I0824 16:10:42.817082 41289 net.cpp:150] Setting up conv2_2
I0824 16:10:42.817098 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:42.817111 41289 net.cpp:165] Memory required for data: 1976832000
I0824 16:10:42.817119 41289 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 16:10:42.817131 41289 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 16:10:42.817136 41289 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 16:10:42.817143 41289 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 16:10:42.817399 41289 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 16:10:42.817409 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:42.817412 41289 net.cpp:165] Memory required for data: 2065305600
I0824 16:10:42.817421 41289 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 16:10:42.817430 41289 net.cpp:100] Creating Layer conv2_2_scale
I0824 16:10:42.817440 41289 net.cpp:434] conv2_2_scale <- conv2_2
I0824 16:10:42.817446 41289 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 16:10:42.817486 41289 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 16:10:42.817667 41289 net.cpp:150] Setting up conv2_2_scale
I0824 16:10:42.817675 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:42.817678 41289 net.cpp:165] Memory required for data: 2153779200
I0824 16:10:42.817685 41289 layer_factory.hpp:77] Creating layer relu2_2
I0824 16:10:42.817693 41289 net.cpp:100] Creating Layer relu2_2
I0824 16:10:42.817698 41289 net.cpp:434] relu2_2 <- conv2_2
I0824 16:10:42.817703 41289 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 16:10:42.817900 41289 net.cpp:150] Setting up relu2_2
I0824 16:10:42.817909 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:42.817914 41289 net.cpp:165] Memory required for data: 2242252800
I0824 16:10:42.817919 41289 layer_factory.hpp:77] Creating layer pool2
I0824 16:10:42.817924 41289 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 16:10:42.817930 41289 net.cpp:100] Creating Layer pool2
I0824 16:10:42.817935 41289 net.cpp:434] pool2 <- conv2_2
I0824 16:10:42.817941 41289 net.cpp:408] pool2 -> pool2
I0824 16:10:42.817950 41289 net.cpp:408] pool2 -> pool2_mask
I0824 16:10:42.817994 41289 net.cpp:150] Setting up pool2
I0824 16:10:42.818002 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:42.818006 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:42.818011 41289 net.cpp:165] Memory required for data: 2286489600
I0824 16:10:42.818014 41289 layer_factory.hpp:77] Creating layer conv3_1
I0824 16:10:42.818025 41289 net.cpp:100] Creating Layer conv3_1
I0824 16:10:42.818030 41289 net.cpp:434] conv3_1 <- pool2
I0824 16:10:42.818037 41289 net.cpp:408] conv3_1 -> conv3_1
I0824 16:10:42.830279 41289 net.cpp:150] Setting up conv3_1
I0824 16:10:42.830310 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.830322 41289 net.cpp:165] Memory required for data: 2330726400
I0824 16:10:42.830330 41289 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 16:10:42.830339 41289 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 16:10:42.830343 41289 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 16:10:42.830350 41289 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 16:10:42.830574 41289 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 16:10:42.830581 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.830585 41289 net.cpp:165] Memory required for data: 2374963200
I0824 16:10:42.830600 41289 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 16:10:42.830610 41289 net.cpp:100] Creating Layer conv3_1_scale
I0824 16:10:42.830617 41289 net.cpp:434] conv3_1_scale <- conv3_1
I0824 16:10:42.830622 41289 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 16:10:42.830665 41289 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 16:10:42.830802 41289 net.cpp:150] Setting up conv3_1_scale
I0824 16:10:42.830811 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.830813 41289 net.cpp:165] Memory required for data: 2419200000
I0824 16:10:42.830821 41289 layer_factory.hpp:77] Creating layer relu3_1
I0824 16:10:42.830828 41289 net.cpp:100] Creating Layer relu3_1
I0824 16:10:42.830833 41289 net.cpp:434] relu3_1 <- conv3_1
I0824 16:10:42.830839 41289 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 16:10:42.831040 41289 net.cpp:150] Setting up relu3_1
I0824 16:10:42.831049 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.831054 41289 net.cpp:165] Memory required for data: 2463436800
I0824 16:10:42.831058 41289 layer_factory.hpp:77] Creating layer conv3_2
I0824 16:10:42.831069 41289 net.cpp:100] Creating Layer conv3_2
I0824 16:10:42.831074 41289 net.cpp:434] conv3_2 <- conv3_1
I0824 16:10:42.831082 41289 net.cpp:408] conv3_2 -> conv3_2
I0824 16:10:42.854885 41289 net.cpp:150] Setting up conv3_2
I0824 16:10:42.854903 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.854907 41289 net.cpp:165] Memory required for data: 2507673600
I0824 16:10:42.854923 41289 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 16:10:42.854934 41289 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 16:10:42.854943 41289 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 16:10:42.854949 41289 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 16:10:42.855167 41289 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 16:10:42.855175 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.855180 41289 net.cpp:165] Memory required for data: 2551910400
I0824 16:10:42.855188 41289 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 16:10:42.855197 41289 net.cpp:100] Creating Layer conv3_2_scale
I0824 16:10:42.855206 41289 net.cpp:434] conv3_2_scale <- conv3_2
I0824 16:10:42.855211 41289 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 16:10:42.855254 41289 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 16:10:42.855397 41289 net.cpp:150] Setting up conv3_2_scale
I0824 16:10:42.855406 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.855409 41289 net.cpp:165] Memory required for data: 2596147200
I0824 16:10:42.855417 41289 layer_factory.hpp:77] Creating layer relu3_2
I0824 16:10:42.855425 41289 net.cpp:100] Creating Layer relu3_2
I0824 16:10:42.855430 41289 net.cpp:434] relu3_2 <- conv3_2
I0824 16:10:42.855435 41289 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 16:10:42.855643 41289 net.cpp:150] Setting up relu3_2
I0824 16:10:42.855653 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.855657 41289 net.cpp:165] Memory required for data: 2640384000
I0824 16:10:42.855661 41289 layer_factory.hpp:77] Creating layer conv3_3
I0824 16:10:42.855674 41289 net.cpp:100] Creating Layer conv3_3
I0824 16:10:42.855679 41289 net.cpp:434] conv3_3 <- conv3_2
I0824 16:10:42.855686 41289 net.cpp:408] conv3_3 -> conv3_3
I0824 16:10:42.878991 41289 net.cpp:150] Setting up conv3_3
I0824 16:10:42.879025 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.879039 41289 net.cpp:165] Memory required for data: 2684620800
I0824 16:10:42.879047 41289 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 16:10:42.879062 41289 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 16:10:42.879070 41289 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 16:10:42.879076 41289 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 16:10:42.879303 41289 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 16:10:42.879312 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.879315 41289 net.cpp:165] Memory required for data: 2728857600
I0824 16:10:42.879329 41289 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 16:10:42.879339 41289 net.cpp:100] Creating Layer conv3_3_scale
I0824 16:10:42.879344 41289 net.cpp:434] conv3_3_scale <- conv3_3
I0824 16:10:42.879350 41289 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 16:10:42.879395 41289 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 16:10:42.879541 41289 net.cpp:150] Setting up conv3_3_scale
I0824 16:10:42.879549 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.879554 41289 net.cpp:165] Memory required for data: 2773094400
I0824 16:10:42.879561 41289 layer_factory.hpp:77] Creating layer relu3_3
I0824 16:10:42.879570 41289 net.cpp:100] Creating Layer relu3_3
I0824 16:10:42.879575 41289 net.cpp:434] relu3_3 <- conv3_3
I0824 16:10:42.879581 41289 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 16:10:42.879787 41289 net.cpp:150] Setting up relu3_3
I0824 16:10:42.879796 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:42.879801 41289 net.cpp:165] Memory required for data: 2817331200
I0824 16:10:42.879806 41289 layer_factory.hpp:77] Creating layer pool3
I0824 16:10:42.879811 41289 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 16:10:42.879824 41289 net.cpp:100] Creating Layer pool3
I0824 16:10:42.879829 41289 net.cpp:434] pool3 <- conv3_3
I0824 16:10:42.879837 41289 net.cpp:408] pool3 -> pool3
I0824 16:10:42.879847 41289 net.cpp:408] pool3 -> pool3_mask
I0824 16:10:42.879897 41289 net.cpp:150] Setting up pool3
I0824 16:10:42.879904 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:42.879912 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:42.879917 41289 net.cpp:165] Memory required for data: 2839449600
I0824 16:10:42.879920 41289 layer_factory.hpp:77] Creating layer conv4_1
I0824 16:10:42.879933 41289 net.cpp:100] Creating Layer conv4_1
I0824 16:10:42.879938 41289 net.cpp:434] conv4_1 <- pool3
I0824 16:10:42.879946 41289 net.cpp:408] conv4_1 -> conv4_1
I0824 16:10:42.927055 41289 net.cpp:150] Setting up conv4_1
I0824 16:10:42.927081 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:42.927086 41289 net.cpp:165] Memory required for data: 2861568000
I0824 16:10:42.927096 41289 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 16:10:42.927114 41289 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 16:10:42.927121 41289 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 16:10:42.927129 41289 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 16:10:42.927352 41289 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 16:10:42.927361 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:42.927364 41289 net.cpp:165] Memory required for data: 2883686400
I0824 16:10:42.927373 41289 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 16:10:42.927386 41289 net.cpp:100] Creating Layer conv4_1_scale
I0824 16:10:42.927393 41289 net.cpp:434] conv4_1_scale <- conv4_1
I0824 16:10:42.927399 41289 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 16:10:42.927448 41289 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 16:10:42.927582 41289 net.cpp:150] Setting up conv4_1_scale
I0824 16:10:42.927590 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:42.927593 41289 net.cpp:165] Memory required for data: 2905804800
I0824 16:10:42.927600 41289 layer_factory.hpp:77] Creating layer relu4_1
I0824 16:10:42.927628 41289 net.cpp:100] Creating Layer relu4_1
I0824 16:10:42.927634 41289 net.cpp:434] relu4_1 <- conv4_1
I0824 16:10:42.927639 41289 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 16:10:42.927855 41289 net.cpp:150] Setting up relu4_1
I0824 16:10:42.927865 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:42.927868 41289 net.cpp:165] Memory required for data: 2927923200
I0824 16:10:42.927872 41289 layer_factory.hpp:77] Creating layer conv4_2
I0824 16:10:42.927886 41289 net.cpp:100] Creating Layer conv4_2
I0824 16:10:42.927891 41289 net.cpp:434] conv4_2 <- conv4_1
I0824 16:10:42.927899 41289 net.cpp:408] conv4_2 -> conv4_2
I0824 16:10:43.012351 41289 net.cpp:150] Setting up conv4_2
I0824 16:10:43.012382 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.012388 41289 net.cpp:165] Memory required for data: 2950041600
I0824 16:10:43.012399 41289 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 16:10:43.012413 41289 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 16:10:43.012421 41289 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 16:10:43.012435 41289 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 16:10:43.012660 41289 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 16:10:43.012668 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.012672 41289 net.cpp:165] Memory required for data: 2972160000
I0824 16:10:43.012682 41289 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 16:10:43.012693 41289 net.cpp:100] Creating Layer conv4_2_scale
I0824 16:10:43.012699 41289 net.cpp:434] conv4_2_scale <- conv4_2
I0824 16:10:43.012706 41289 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 16:10:43.012748 41289 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 16:10:43.012884 41289 net.cpp:150] Setting up conv4_2_scale
I0824 16:10:43.012892 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.012895 41289 net.cpp:165] Memory required for data: 2994278400
I0824 16:10:43.012903 41289 layer_factory.hpp:77] Creating layer relu4_2
I0824 16:10:43.012913 41289 net.cpp:100] Creating Layer relu4_2
I0824 16:10:43.012918 41289 net.cpp:434] relu4_2 <- conv4_2
I0824 16:10:43.012924 41289 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 16:10:43.014034 41289 net.cpp:150] Setting up relu4_2
I0824 16:10:43.014048 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.014055 41289 net.cpp:165] Memory required for data: 3016396800
I0824 16:10:43.014060 41289 layer_factory.hpp:77] Creating layer conv4_3
I0824 16:10:43.014075 41289 net.cpp:100] Creating Layer conv4_3
I0824 16:10:43.014081 41289 net.cpp:434] conv4_3 <- conv4_2
I0824 16:10:43.014088 41289 net.cpp:408] conv4_3 -> conv4_3
I0824 16:10:43.101204 41289 net.cpp:150] Setting up conv4_3
I0824 16:10:43.101241 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.101253 41289 net.cpp:165] Memory required for data: 3038515200
I0824 16:10:43.101287 41289 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 16:10:43.101305 41289 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 16:10:43.101320 41289 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 16:10:43.101328 41289 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 16:10:43.101584 41289 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 16:10:43.101593 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.101598 41289 net.cpp:165] Memory required for data: 3060633600
I0824 16:10:43.101608 41289 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 16:10:43.101622 41289 net.cpp:100] Creating Layer conv4_3_scale
I0824 16:10:43.101629 41289 net.cpp:434] conv4_3_scale <- conv4_3
I0824 16:10:43.101634 41289 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 16:10:43.101681 41289 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 16:10:43.101822 41289 net.cpp:150] Setting up conv4_3_scale
I0824 16:10:43.101830 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.101833 41289 net.cpp:165] Memory required for data: 3082752000
I0824 16:10:43.101842 41289 layer_factory.hpp:77] Creating layer relu4_3
I0824 16:10:43.101876 41289 net.cpp:100] Creating Layer relu4_3
I0824 16:10:43.101881 41289 net.cpp:434] relu4_3 <- conv4_3
I0824 16:10:43.101887 41289 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 16:10:43.102090 41289 net.cpp:150] Setting up relu4_3
I0824 16:10:43.102100 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.102104 41289 net.cpp:165] Memory required for data: 3104870400
I0824 16:10:43.102109 41289 layer_factory.hpp:77] Creating layer pool4
I0824 16:10:43.102114 41289 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 16:10:43.102121 41289 net.cpp:100] Creating Layer pool4
I0824 16:10:43.102126 41289 net.cpp:434] pool4 <- conv4_3
I0824 16:10:43.102136 41289 net.cpp:408] pool4 -> pool4
I0824 16:10:43.102146 41289 net.cpp:408] pool4 -> pool4_mask
I0824 16:10:43.102197 41289 net.cpp:150] Setting up pool4
I0824 16:10:43.102205 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.102210 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.102214 41289 net.cpp:165] Memory required for data: 3116175360
I0824 16:10:43.102217 41289 layer_factory.hpp:77] Creating layer conv5_1
I0824 16:10:43.102233 41289 net.cpp:100] Creating Layer conv5_1
I0824 16:10:43.102238 41289 net.cpp:434] conv5_1 <- pool4
I0824 16:10:43.102246 41289 net.cpp:408] conv5_1 -> conv5_1
I0824 16:10:43.187117 41289 net.cpp:150] Setting up conv5_1
I0824 16:10:43.187150 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.187155 41289 net.cpp:165] Memory required for data: 3121827840
I0824 16:10:43.187175 41289 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 16:10:43.187192 41289 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 16:10:43.187201 41289 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 16:10:43.187216 41289 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 16:10:43.187443 41289 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 16:10:43.187451 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.187455 41289 net.cpp:165] Memory required for data: 3127480320
I0824 16:10:43.187465 41289 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 16:10:43.187476 41289 net.cpp:100] Creating Layer conv5_1_scale
I0824 16:10:43.187481 41289 net.cpp:434] conv5_1_scale <- conv5_1
I0824 16:10:43.187489 41289 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 16:10:43.187537 41289 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 16:10:43.187661 41289 net.cpp:150] Setting up conv5_1_scale
I0824 16:10:43.187669 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.187672 41289 net.cpp:165] Memory required for data: 3133132800
I0824 16:10:43.187680 41289 layer_factory.hpp:77] Creating layer relu5_1
I0824 16:10:43.187690 41289 net.cpp:100] Creating Layer relu5_1
I0824 16:10:43.187693 41289 net.cpp:434] relu5_1 <- conv5_1
I0824 16:10:43.187700 41289 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 16:10:43.187898 41289 net.cpp:150] Setting up relu5_1
I0824 16:10:43.187907 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.187912 41289 net.cpp:165] Memory required for data: 3138785280
I0824 16:10:43.187916 41289 layer_factory.hpp:77] Creating layer conv5_2
I0824 16:10:43.187932 41289 net.cpp:100] Creating Layer conv5_2
I0824 16:10:43.187937 41289 net.cpp:434] conv5_2 <- conv5_1
I0824 16:10:43.187944 41289 net.cpp:408] conv5_2 -> conv5_2
I0824 16:10:43.272956 41289 net.cpp:150] Setting up conv5_2
I0824 16:10:43.272989 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.272994 41289 net.cpp:165] Memory required for data: 3144437760
I0824 16:10:43.273005 41289 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 16:10:43.273025 41289 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 16:10:43.273032 41289 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 16:10:43.273046 41289 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 16:10:43.273267 41289 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 16:10:43.273273 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.273300 41289 net.cpp:165] Memory required for data: 3150090240
I0824 16:10:43.273315 41289 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 16:10:43.273327 41289 net.cpp:100] Creating Layer conv5_2_scale
I0824 16:10:43.273332 41289 net.cpp:434] conv5_2_scale <- conv5_2
I0824 16:10:43.273339 41289 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 16:10:43.273414 41289 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 16:10:43.273542 41289 net.cpp:150] Setting up conv5_2_scale
I0824 16:10:43.273550 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.273555 41289 net.cpp:165] Memory required for data: 3155742720
I0824 16:10:43.273561 41289 layer_factory.hpp:77] Creating layer relu5_2
I0824 16:10:43.273571 41289 net.cpp:100] Creating Layer relu5_2
I0824 16:10:43.273576 41289 net.cpp:434] relu5_2 <- conv5_2
I0824 16:10:43.273581 41289 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 16:10:43.273780 41289 net.cpp:150] Setting up relu5_2
I0824 16:10:43.273788 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.273792 41289 net.cpp:165] Memory required for data: 3161395200
I0824 16:10:43.273795 41289 layer_factory.hpp:77] Creating layer conv5_3
I0824 16:10:43.273813 41289 net.cpp:100] Creating Layer conv5_3
I0824 16:10:43.273818 41289 net.cpp:434] conv5_3 <- conv5_2
I0824 16:10:43.273824 41289 net.cpp:408] conv5_3 -> conv5_3
I0824 16:10:43.359069 41289 net.cpp:150] Setting up conv5_3
I0824 16:10:43.359102 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.359107 41289 net.cpp:165] Memory required for data: 3167047680
I0824 16:10:43.359127 41289 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 16:10:43.359140 41289 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 16:10:43.359149 41289 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 16:10:43.359165 41289 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 16:10:43.359401 41289 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 16:10:43.359410 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.359413 41289 net.cpp:165] Memory required for data: 3172700160
I0824 16:10:43.359426 41289 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 16:10:43.359436 41289 net.cpp:100] Creating Layer conv5_3_scale
I0824 16:10:43.359441 41289 net.cpp:434] conv5_3_scale <- conv5_3
I0824 16:10:43.359447 41289 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 16:10:43.359498 41289 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 16:10:43.359633 41289 net.cpp:150] Setting up conv5_3_scale
I0824 16:10:43.359642 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.359644 41289 net.cpp:165] Memory required for data: 3178352640
I0824 16:10:43.359652 41289 layer_factory.hpp:77] Creating layer relu5_3
I0824 16:10:43.359665 41289 net.cpp:100] Creating Layer relu5_3
I0824 16:10:43.359670 41289 net.cpp:434] relu5_3 <- conv5_3
I0824 16:10:43.359675 41289 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 16:10:43.359889 41289 net.cpp:150] Setting up relu5_3
I0824 16:10:43.359899 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.359902 41289 net.cpp:165] Memory required for data: 3184005120
I0824 16:10:43.359907 41289 layer_factory.hpp:77] Creating layer pool5
I0824 16:10:43.359912 41289 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 16:10:43.359921 41289 net.cpp:100] Creating Layer pool5
I0824 16:10:43.359926 41289 net.cpp:434] pool5 <- conv5_3
I0824 16:10:43.359933 41289 net.cpp:408] pool5 -> pool5
I0824 16:10:43.359942 41289 net.cpp:408] pool5 -> pool5_mask
I0824 16:10:43.359994 41289 net.cpp:150] Setting up pool5
I0824 16:10:43.360002 41289 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 16:10:43.360005 41289 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 16:10:43.360009 41289 net.cpp:165] Memory required for data: 3186954240
I0824 16:10:43.360013 41289 layer_factory.hpp:77] Creating layer upsample5
I0824 16:10:43.360026 41289 net.cpp:100] Creating Layer upsample5
I0824 16:10:43.360031 41289 net.cpp:434] upsample5 <- pool5
I0824 16:10:43.360059 41289 net.cpp:434] upsample5 <- pool5_mask
I0824 16:10:43.360069 41289 net.cpp:408] upsample5 -> pool5_D
I0824 16:10:43.360108 41289 net.cpp:150] Setting up upsample5
I0824 16:10:43.360116 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.360118 41289 net.cpp:165] Memory required for data: 3192606720
I0824 16:10:43.360123 41289 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 16:10:43.360141 41289 net.cpp:100] Creating Layer conv5_3_D
I0824 16:10:43.360146 41289 net.cpp:434] conv5_3_D <- pool5_D
I0824 16:10:43.360155 41289 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 16:10:43.446179 41289 net.cpp:150] Setting up conv5_3_D
I0824 16:10:43.446213 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.446216 41289 net.cpp:165] Memory required for data: 3198259200
I0824 16:10:43.446228 41289 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 16:10:43.446249 41289 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 16:10:43.446257 41289 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 16:10:43.446271 41289 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 16:10:43.446513 41289 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 16:10:43.446522 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.446526 41289 net.cpp:165] Memory required for data: 3203911680
I0824 16:10:43.446534 41289 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 16:10:43.446544 41289 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 16:10:43.446549 41289 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 16:10:43.446557 41289 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 16:10:43.446605 41289 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 16:10:43.446743 41289 net.cpp:150] Setting up conv5_3_D_scale
I0824 16:10:43.446751 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.446754 41289 net.cpp:165] Memory required for data: 3209564160
I0824 16:10:43.446763 41289 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 16:10:43.446776 41289 net.cpp:100] Creating Layer relu5_3_D
I0824 16:10:43.446781 41289 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 16:10:43.446786 41289 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 16:10:43.447011 41289 net.cpp:150] Setting up relu5_3_D
I0824 16:10:43.447023 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.447028 41289 net.cpp:165] Memory required for data: 3215216640
I0824 16:10:43.447034 41289 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 16:10:43.447072 41289 net.cpp:100] Creating Layer conv5_2_D
I0824 16:10:43.447078 41289 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 16:10:43.447084 41289 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 16:10:43.533087 41289 net.cpp:150] Setting up conv5_2_D
I0824 16:10:43.533118 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.533123 41289 net.cpp:165] Memory required for data: 3220869120
I0824 16:10:43.533135 41289 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 16:10:43.533156 41289 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 16:10:43.533164 41289 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 16:10:43.533177 41289 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 16:10:43.533453 41289 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 16:10:43.533463 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.533466 41289 net.cpp:165] Memory required for data: 3226521600
I0824 16:10:43.533478 41289 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 16:10:43.533493 41289 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 16:10:43.533498 41289 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 16:10:43.533504 41289 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 16:10:43.533555 41289 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 16:10:43.533690 41289 net.cpp:150] Setting up conv5_2_D_scale
I0824 16:10:43.533697 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.533701 41289 net.cpp:165] Memory required for data: 3232174080
I0824 16:10:43.533731 41289 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 16:10:43.533743 41289 net.cpp:100] Creating Layer relu5_2_D
I0824 16:10:43.533748 41289 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 16:10:43.533753 41289 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 16:10:43.534843 41289 net.cpp:150] Setting up relu5_2_D
I0824 16:10:43.534860 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.534865 41289 net.cpp:165] Memory required for data: 3237826560
I0824 16:10:43.534871 41289 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 16:10:43.534888 41289 net.cpp:100] Creating Layer conv5_1_D
I0824 16:10:43.534894 41289 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 16:10:43.534901 41289 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 16:10:43.621390 41289 net.cpp:150] Setting up conv5_1_D
I0824 16:10:43.621429 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.621434 41289 net.cpp:165] Memory required for data: 3243479040
I0824 16:10:43.621453 41289 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 16:10:43.621472 41289 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 16:10:43.621487 41289 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 16:10:43.621496 41289 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 16:10:43.621745 41289 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 16:10:43.621753 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.621757 41289 net.cpp:165] Memory required for data: 3249131520
I0824 16:10:43.621767 41289 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 16:10:43.621779 41289 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 16:10:43.621785 41289 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 16:10:43.621790 41289 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 16:10:43.621841 41289 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 16:10:43.621981 41289 net.cpp:150] Setting up conv5_1_D_scale
I0824 16:10:43.621989 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.621994 41289 net.cpp:165] Memory required for data: 3254784000
I0824 16:10:43.622000 41289 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 16:10:43.622009 41289 net.cpp:100] Creating Layer relu5_1_D
I0824 16:10:43.622014 41289 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 16:10:43.622022 41289 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 16:10:43.622243 41289 net.cpp:150] Setting up relu5_1_D
I0824 16:10:43.622252 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:43.622257 41289 net.cpp:165] Memory required for data: 3260436480
I0824 16:10:43.622263 41289 layer_factory.hpp:77] Creating layer upsample4
I0824 16:10:43.622272 41289 net.cpp:100] Creating Layer upsample4
I0824 16:10:43.622277 41289 net.cpp:434] upsample4 <- conv5_1_D
I0824 16:10:43.622288 41289 net.cpp:434] upsample4 <- pool4_mask
I0824 16:10:43.622297 41289 net.cpp:408] upsample4 -> pool4_D
I0824 16:10:43.622334 41289 net.cpp:150] Setting up upsample4
I0824 16:10:43.622341 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.622344 41289 net.cpp:165] Memory required for data: 3282554880
I0824 16:10:43.622347 41289 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 16:10:43.622365 41289 net.cpp:100] Creating Layer conv4_3_D
I0824 16:10:43.622371 41289 net.cpp:434] conv4_3_D <- pool4_D
I0824 16:10:43.622380 41289 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 16:10:43.706794 41289 net.cpp:150] Setting up conv4_3_D
I0824 16:10:43.706833 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.706841 41289 net.cpp:165] Memory required for data: 3304673280
I0824 16:10:43.706852 41289 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 16:10:43.706869 41289 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 16:10:43.706877 41289 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 16:10:43.706889 41289 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 16:10:43.707150 41289 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 16:10:43.707159 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.707187 41289 net.cpp:165] Memory required for data: 3326791680
I0824 16:10:43.707196 41289 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 16:10:43.707206 41289 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 16:10:43.707212 41289 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 16:10:43.707217 41289 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 16:10:43.707268 41289 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 16:10:43.707422 41289 net.cpp:150] Setting up conv4_3_D_scale
I0824 16:10:43.707430 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.707433 41289 net.cpp:165] Memory required for data: 3348910080
I0824 16:10:43.707440 41289 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 16:10:43.707454 41289 net.cpp:100] Creating Layer relu4_3_D
I0824 16:10:43.707459 41289 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 16:10:43.707468 41289 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 16:10:43.707677 41289 net.cpp:150] Setting up relu4_3_D
I0824 16:10:43.707686 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.707691 41289 net.cpp:165] Memory required for data: 3371028480
I0824 16:10:43.707695 41289 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 16:10:43.707710 41289 net.cpp:100] Creating Layer conv4_2_D
I0824 16:10:43.707715 41289 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 16:10:43.707726 41289 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 16:10:43.792004 41289 net.cpp:150] Setting up conv4_2_D
I0824 16:10:43.792037 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.792042 41289 net.cpp:165] Memory required for data: 3393146880
I0824 16:10:43.792052 41289 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 16:10:43.792068 41289 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 16:10:43.792076 41289 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 16:10:43.792088 41289 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 16:10:43.792338 41289 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 16:10:43.792347 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.792351 41289 net.cpp:165] Memory required for data: 3415265280
I0824 16:10:43.792359 41289 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 16:10:43.792374 41289 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 16:10:43.792379 41289 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 16:10:43.792387 41289 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 16:10:43.792433 41289 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 16:10:43.792582 41289 net.cpp:150] Setting up conv4_2_D_scale
I0824 16:10:43.792589 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.792593 41289 net.cpp:165] Memory required for data: 3437383680
I0824 16:10:43.792600 41289 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 16:10:43.792610 41289 net.cpp:100] Creating Layer relu4_2_D
I0824 16:10:43.792616 41289 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 16:10:43.792620 41289 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 16:10:43.792829 41289 net.cpp:150] Setting up relu4_2_D
I0824 16:10:43.792840 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:43.792845 41289 net.cpp:165] Memory required for data: 3459502080
I0824 16:10:43.792847 41289 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 16:10:43.792861 41289 net.cpp:100] Creating Layer conv4_1_D
I0824 16:10:43.792867 41289 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 16:10:43.792874 41289 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 16:10:43.836871 41289 net.cpp:150] Setting up conv4_1_D
I0824 16:10:43.836892 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:43.836896 41289 net.cpp:165] Memory required for data: 3470561280
I0824 16:10:43.836905 41289 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 16:10:43.836922 41289 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 16:10:43.836930 41289 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 16:10:43.836941 41289 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 16:10:43.837184 41289 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 16:10:43.837213 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:43.837222 41289 net.cpp:165] Memory required for data: 3481620480
I0824 16:10:43.837318 41289 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 16:10:43.837327 41289 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 16:10:43.837332 41289 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 16:10:43.837338 41289 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 16:10:43.837414 41289 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 16:10:43.837558 41289 net.cpp:150] Setting up conv4_1_D_scale
I0824 16:10:43.837566 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:43.837570 41289 net.cpp:165] Memory required for data: 3492679680
I0824 16:10:43.837577 41289 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 16:10:43.837587 41289 net.cpp:100] Creating Layer relu4_1_D
I0824 16:10:43.837592 41289 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 16:10:43.837597 41289 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 16:10:43.837812 41289 net.cpp:150] Setting up relu4_1_D
I0824 16:10:43.837823 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:43.837828 41289 net.cpp:165] Memory required for data: 3503738880
I0824 16:10:43.837832 41289 layer_factory.hpp:77] Creating layer upsample3
I0824 16:10:43.837841 41289 net.cpp:100] Creating Layer upsample3
I0824 16:10:43.837846 41289 net.cpp:434] upsample3 <- conv4_1_D
I0824 16:10:43.837851 41289 net.cpp:434] upsample3 <- pool3_mask
I0824 16:10:43.837858 41289 net.cpp:408] upsample3 -> pool3_D
I0824 16:10:43.837867 41289 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 16:10:43.837898 41289 net.cpp:150] Setting up upsample3
I0824 16:10:43.837904 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.837908 41289 net.cpp:165] Memory required for data: 3547975680
I0824 16:10:43.837911 41289 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 16:10:43.837929 41289 net.cpp:100] Creating Layer conv3_3_D
I0824 16:10:43.837934 41289 net.cpp:434] conv3_3_D <- pool3_D
I0824 16:10:43.837940 41289 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 16:10:43.861582 41289 net.cpp:150] Setting up conv3_3_D
I0824 16:10:43.861600 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.861604 41289 net.cpp:165] Memory required for data: 3592212480
I0824 16:10:43.861614 41289 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 16:10:43.861625 41289 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 16:10:43.861630 41289 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 16:10:43.861635 41289 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 16:10:43.861901 41289 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 16:10:43.861910 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.861920 41289 net.cpp:165] Memory required for data: 3636449280
I0824 16:10:43.861929 41289 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 16:10:43.861938 41289 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 16:10:43.861946 41289 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 16:10:43.861954 41289 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 16:10:43.862005 41289 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 16:10:43.862174 41289 net.cpp:150] Setting up conv3_3_D_scale
I0824 16:10:43.862185 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.862190 41289 net.cpp:165] Memory required for data: 3680686080
I0824 16:10:43.862197 41289 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 16:10:43.862206 41289 net.cpp:100] Creating Layer relu3_3_D
I0824 16:10:43.862211 41289 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 16:10:43.862216 41289 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 16:10:43.862437 41289 net.cpp:150] Setting up relu3_3_D
I0824 16:10:43.862447 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.862452 41289 net.cpp:165] Memory required for data: 3724922880
I0824 16:10:43.862469 41289 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 16:10:43.862485 41289 net.cpp:100] Creating Layer conv3_2_D
I0824 16:10:43.862490 41289 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 16:10:43.862499 41289 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 16:10:43.886478 41289 net.cpp:150] Setting up conv3_2_D
I0824 16:10:43.886497 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.886500 41289 net.cpp:165] Memory required for data: 3769159680
I0824 16:10:43.886529 41289 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 16:10:43.886538 41289 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 16:10:43.886548 41289 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 16:10:43.886555 41289 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 16:10:43.886816 41289 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 16:10:43.886823 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.886827 41289 net.cpp:165] Memory required for data: 3813396480
I0824 16:10:43.886835 41289 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 16:10:43.886852 41289 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 16:10:43.886858 41289 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 16:10:43.886863 41289 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 16:10:43.886914 41289 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 16:10:43.887075 41289 net.cpp:150] Setting up conv3_2_D_scale
I0824 16:10:43.887084 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.887087 41289 net.cpp:165] Memory required for data: 3857633280
I0824 16:10:43.887094 41289 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 16:10:43.887100 41289 net.cpp:100] Creating Layer relu3_2_D
I0824 16:10:43.887104 41289 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 16:10:43.887111 41289 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 16:10:43.888212 41289 net.cpp:150] Setting up relu3_2_D
I0824 16:10:43.888226 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.888232 41289 net.cpp:165] Memory required for data: 3901870080
I0824 16:10:43.888236 41289 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 16:10:43.888249 41289 net.cpp:100] Creating Layer conv3_1_D
I0824 16:10:43.888254 41289 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 16:10:43.888272 41289 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 16:10:43.902027 41289 net.cpp:150] Setting up conv3_1_D
I0824 16:10:43.902043 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:43.902048 41289 net.cpp:165] Memory required for data: 3923988480
I0824 16:10:43.902065 41289 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 16:10:43.902079 41289 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 16:10:43.902086 41289 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 16:10:43.902092 41289 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 16:10:43.902354 41289 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 16:10:43.902361 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:43.902365 41289 net.cpp:165] Memory required for data: 3946106880
I0824 16:10:43.902374 41289 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 16:10:43.902385 41289 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 16:10:43.902395 41289 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 16:10:43.902403 41289 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 16:10:43.902449 41289 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 16:10:43.902614 41289 net.cpp:150] Setting up conv3_1_D_scale
I0824 16:10:43.902622 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:43.902626 41289 net.cpp:165] Memory required for data: 3968225280
I0824 16:10:43.902632 41289 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 16:10:43.902639 41289 net.cpp:100] Creating Layer relu3_1_D
I0824 16:10:43.902643 41289 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 16:10:43.902647 41289 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 16:10:43.902869 41289 net.cpp:150] Setting up relu3_1_D
I0824 16:10:43.902894 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:43.902900 41289 net.cpp:165] Memory required for data: 3990343680
I0824 16:10:43.902904 41289 layer_factory.hpp:77] Creating layer upsample2
I0824 16:10:43.902910 41289 net.cpp:100] Creating Layer upsample2
I0824 16:10:43.902915 41289 net.cpp:434] upsample2 <- conv3_1_D
I0824 16:10:43.902921 41289 net.cpp:434] upsample2 <- pool2_mask
I0824 16:10:43.902928 41289 net.cpp:408] upsample2 -> pool2_D
I0824 16:10:43.902937 41289 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 16:10:43.902973 41289 net.cpp:150] Setting up upsample2
I0824 16:10:43.902981 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.902987 41289 net.cpp:165] Memory required for data: 4078817280
I0824 16:10:43.902997 41289 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 16:10:43.903012 41289 net.cpp:100] Creating Layer conv2_2_D
I0824 16:10:43.903017 41289 net.cpp:434] conv2_2_D <- pool2_D
I0824 16:10:43.903024 41289 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 16:10:43.910713 41289 net.cpp:150] Setting up conv2_2_D
I0824 16:10:43.910729 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.910740 41289 net.cpp:165] Memory required for data: 4167290880
I0824 16:10:43.910748 41289 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 16:10:43.910758 41289 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 16:10:43.910763 41289 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 16:10:43.910769 41289 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 16:10:43.911068 41289 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 16:10:43.911077 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.911082 41289 net.cpp:165] Memory required for data: 4255764480
I0824 16:10:43.911089 41289 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 16:10:43.911100 41289 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 16:10:43.911109 41289 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 16:10:43.911114 41289 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 16:10:43.911164 41289 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 16:10:43.912611 41289 net.cpp:150] Setting up conv2_2_D_scale
I0824 16:10:43.912626 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.912634 41289 net.cpp:165] Memory required for data: 4344238080
I0824 16:10:43.912642 41289 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 16:10:43.912655 41289 net.cpp:100] Creating Layer relu2_2_D
I0824 16:10:43.912662 41289 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 16:10:43.912668 41289 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 16:10:43.912901 41289 net.cpp:150] Setting up relu2_2_D
I0824 16:10:43.912910 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.912914 41289 net.cpp:165] Memory required for data: 4432711680
I0824 16:10:43.912919 41289 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 16:10:43.912936 41289 net.cpp:100] Creating Layer conv2_1_D
I0824 16:10:43.912942 41289 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 16:10:43.912948 41289 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 16:10:43.918212 41289 net.cpp:150] Setting up conv2_1_D
I0824 16:10:43.918228 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:43.918238 41289 net.cpp:165] Memory required for data: 4476948480
I0824 16:10:43.918247 41289 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 16:10:43.918254 41289 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 16:10:43.918259 41289 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 16:10:43.918267 41289 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 16:10:43.918565 41289 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 16:10:43.918572 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:43.918576 41289 net.cpp:165] Memory required for data: 4521185280
I0824 16:10:43.918586 41289 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 16:10:43.918609 41289 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 16:10:43.918615 41289 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 16:10:43.918623 41289 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 16:10:43.918673 41289 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 16:10:43.918890 41289 net.cpp:150] Setting up conv2_1_D_scale
I0824 16:10:43.918900 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:43.918905 41289 net.cpp:165] Memory required for data: 4565422080
I0824 16:10:43.918911 41289 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 16:10:43.918920 41289 net.cpp:100] Creating Layer relu2_1_D
I0824 16:10:43.918925 41289 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 16:10:43.918931 41289 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 16:10:43.919155 41289 net.cpp:150] Setting up relu2_1_D
I0824 16:10:43.919164 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:43.919168 41289 net.cpp:165] Memory required for data: 4609658880
I0824 16:10:43.919173 41289 layer_factory.hpp:77] Creating layer upsample1
I0824 16:10:43.919184 41289 net.cpp:100] Creating Layer upsample1
I0824 16:10:43.919189 41289 net.cpp:434] upsample1 <- conv2_1_D
I0824 16:10:43.919194 41289 net.cpp:434] upsample1 <- pool1_mask
I0824 16:10:43.919200 41289 net.cpp:408] upsample1 -> pool1_D
I0824 16:10:43.919209 41289 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 16:10:43.919241 41289 net.cpp:150] Setting up upsample1
I0824 16:10:43.919248 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.919251 41289 net.cpp:165] Memory required for data: 4786606080
I0824 16:10:43.919255 41289 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 16:10:43.919268 41289 net.cpp:100] Creating Layer conv1_2_D
I0824 16:10:43.919273 41289 net.cpp:434] conv1_2_D <- pool1_D
I0824 16:10:43.919283 41289 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 16:10:43.923745 41289 net.cpp:150] Setting up conv1_2_D
I0824 16:10:43.923761 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.923771 41289 net.cpp:165] Memory required for data: 4963553280
I0824 16:10:43.923779 41289 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 16:10:43.923791 41289 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 16:10:43.923797 41289 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 16:10:43.923804 41289 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 16:10:43.924196 41289 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 16:10:43.924204 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.924211 41289 net.cpp:165] Memory required for data: 5140500480
I0824 16:10:43.924218 41289 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 16:10:43.924227 41289 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 16:10:43.924232 41289 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 16:10:43.924237 41289 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 16:10:43.924289 41289 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 16:10:43.926347 41289 net.cpp:150] Setting up conv1_2_D_scale
I0824 16:10:43.926362 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.926367 41289 net.cpp:165] Memory required for data: 5317447680
I0824 16:10:43.926378 41289 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 16:10:43.926386 41289 net.cpp:100] Creating Layer relu1_2_D
I0824 16:10:43.926391 41289 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 16:10:43.926400 41289 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 16:10:43.926645 41289 net.cpp:150] Setting up relu1_2_D
I0824 16:10:43.926656 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.926661 41289 net.cpp:165] Memory required for data: 5494394880
I0824 16:10:43.926664 41289 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 16:10:43.926681 41289 net.cpp:100] Creating Layer conv1_1_1_D
I0824 16:10:43.926689 41289 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 16:10:43.926712 41289 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 16:10:43.928807 41289 net.cpp:150] Setting up conv1_1_1_D
I0824 16:10:43.928822 41289 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 16:10:43.928827 41289 net.cpp:165] Memory required for data: 5499924480
I0824 16:10:43.928834 41289 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 16:10:43.928848 41289 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 16:10:43.928853 41289 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 16:10:43.928859 41289 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 16:10:43.928869 41289 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 16:10:43.928923 41289 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 16:10:43.928930 41289 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 16:10:43.928936 41289 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 16:10:43.928939 41289 net.cpp:165] Memory required for data: 5510983680
I0824 16:10:43.928946 41289 layer_factory.hpp:77] Creating layer loss
I0824 16:10:43.928961 41289 net.cpp:100] Creating Layer loss
I0824 16:10:43.928966 41289 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 16:10:43.928972 41289 net.cpp:434] loss <- label_data_1_split_0
I0824 16:10:43.928977 41289 net.cpp:408] loss -> loss
I0824 16:10:43.928998 41289 layer_factory.hpp:77] Creating layer loss
I0824 16:10:43.934216 41289 net.cpp:150] Setting up loss
I0824 16:10:43.934231 41289 net.cpp:157] Top shape: (1)
I0824 16:10:43.934234 41289 net.cpp:160]     with loss weight 1
I0824 16:10:43.934273 41289 net.cpp:165] Memory required for data: 5510983684
I0824 16:10:43.934278 41289 layer_factory.hpp:77] Creating layer accuracy
I0824 16:10:43.934291 41289 net.cpp:100] Creating Layer accuracy
I0824 16:10:43.934298 41289 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 16:10:43.934303 41289 net.cpp:434] accuracy <- label_data_1_split_1
I0824 16:10:43.934310 41289 net.cpp:408] accuracy -> accuracy
I0824 16:10:43.934322 41289 net.cpp:408] accuracy -> per_class_accuracy
I0824 16:10:43.934378 41289 net.cpp:150] Setting up accuracy
I0824 16:10:43.934386 41289 net.cpp:157] Top shape: (1)
I0824 16:10:43.934389 41289 net.cpp:157] Top shape: 2 (2)
I0824 16:10:43.934392 41289 net.cpp:165] Memory required for data: 5510983696
I0824 16:10:43.934396 41289 net.cpp:228] accuracy does not need backward computation.
I0824 16:10:43.934401 41289 net.cpp:226] loss needs backward computation.
I0824 16:10:43.934407 41289 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 16:10:43.934411 41289 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 16:10:43.934414 41289 net.cpp:226] relu1_2_D needs backward computation.
I0824 16:10:43.934417 41289 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 16:10:43.934420 41289 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 16:10:43.934423 41289 net.cpp:226] conv1_2_D needs backward computation.
I0824 16:10:43.934427 41289 net.cpp:226] upsample1 needs backward computation.
I0824 16:10:43.934430 41289 net.cpp:226] relu2_1_D needs backward computation.
I0824 16:10:43.934434 41289 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 16:10:43.934437 41289 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 16:10:43.934440 41289 net.cpp:226] conv2_1_D needs backward computation.
I0824 16:10:43.934443 41289 net.cpp:226] relu2_2_D needs backward computation.
I0824 16:10:43.934447 41289 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 16:10:43.934449 41289 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 16:10:43.934453 41289 net.cpp:226] conv2_2_D needs backward computation.
I0824 16:10:43.934456 41289 net.cpp:226] upsample2 needs backward computation.
I0824 16:10:43.934459 41289 net.cpp:226] relu3_1_D needs backward computation.
I0824 16:10:43.934463 41289 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 16:10:43.934481 41289 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 16:10:43.934484 41289 net.cpp:226] conv3_1_D needs backward computation.
I0824 16:10:43.934489 41289 net.cpp:226] relu3_2_D needs backward computation.
I0824 16:10:43.934491 41289 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 16:10:43.934494 41289 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 16:10:43.934499 41289 net.cpp:226] conv3_2_D needs backward computation.
I0824 16:10:43.934504 41289 net.cpp:226] relu3_3_D needs backward computation.
I0824 16:10:43.934506 41289 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 16:10:43.934510 41289 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 16:10:43.934514 41289 net.cpp:226] conv3_3_D needs backward computation.
I0824 16:10:43.934517 41289 net.cpp:226] upsample3 needs backward computation.
I0824 16:10:43.934522 41289 net.cpp:226] relu4_1_D needs backward computation.
I0824 16:10:43.934527 41289 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 16:10:43.934530 41289 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 16:10:43.934535 41289 net.cpp:226] conv4_1_D needs backward computation.
I0824 16:10:43.934538 41289 net.cpp:226] relu4_2_D needs backward computation.
I0824 16:10:43.934541 41289 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 16:10:43.934545 41289 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 16:10:43.934548 41289 net.cpp:226] conv4_2_D needs backward computation.
I0824 16:10:43.934552 41289 net.cpp:226] relu4_3_D needs backward computation.
I0824 16:10:43.934556 41289 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 16:10:43.934561 41289 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 16:10:43.934564 41289 net.cpp:226] conv4_3_D needs backward computation.
I0824 16:10:43.934568 41289 net.cpp:226] upsample4 needs backward computation.
I0824 16:10:43.934572 41289 net.cpp:226] relu5_1_D needs backward computation.
I0824 16:10:43.934576 41289 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 16:10:43.934579 41289 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 16:10:43.934583 41289 net.cpp:226] conv5_1_D needs backward computation.
I0824 16:10:43.934588 41289 net.cpp:226] relu5_2_D needs backward computation.
I0824 16:10:43.934592 41289 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 16:10:43.934595 41289 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 16:10:43.934599 41289 net.cpp:226] conv5_2_D needs backward computation.
I0824 16:10:43.934605 41289 net.cpp:226] relu5_3_D needs backward computation.
I0824 16:10:43.934610 41289 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 16:10:43.934614 41289 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 16:10:43.934619 41289 net.cpp:226] conv5_3_D needs backward computation.
I0824 16:10:43.934623 41289 net.cpp:226] upsample5 needs backward computation.
I0824 16:10:43.934630 41289 net.cpp:226] pool5 needs backward computation.
I0824 16:10:43.934635 41289 net.cpp:226] relu5_3 needs backward computation.
I0824 16:10:43.934640 41289 net.cpp:226] conv5_3_scale needs backward computation.
I0824 16:10:43.934644 41289 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 16:10:43.934648 41289 net.cpp:226] conv5_3 needs backward computation.
I0824 16:10:43.934654 41289 net.cpp:226] relu5_2 needs backward computation.
I0824 16:10:43.934659 41289 net.cpp:226] conv5_2_scale needs backward computation.
I0824 16:10:43.934662 41289 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 16:10:43.934666 41289 net.cpp:226] conv5_2 needs backward computation.
I0824 16:10:43.934671 41289 net.cpp:226] relu5_1 needs backward computation.
I0824 16:10:43.934676 41289 net.cpp:226] conv5_1_scale needs backward computation.
I0824 16:10:43.934679 41289 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 16:10:43.934684 41289 net.cpp:226] conv5_1 needs backward computation.
I0824 16:10:43.934687 41289 net.cpp:226] pool4 needs backward computation.
I0824 16:10:43.934701 41289 net.cpp:226] relu4_3 needs backward computation.
I0824 16:10:43.934706 41289 net.cpp:226] conv4_3_scale needs backward computation.
I0824 16:10:43.934710 41289 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 16:10:43.934713 41289 net.cpp:226] conv4_3 needs backward computation.
I0824 16:10:43.934717 41289 net.cpp:226] relu4_2 needs backward computation.
I0824 16:10:43.934721 41289 net.cpp:226] conv4_2_scale needs backward computation.
I0824 16:10:43.934725 41289 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 16:10:43.934731 41289 net.cpp:226] conv4_2 needs backward computation.
I0824 16:10:43.934736 41289 net.cpp:226] relu4_1 needs backward computation.
I0824 16:10:43.934739 41289 net.cpp:226] conv4_1_scale needs backward computation.
I0824 16:10:43.934746 41289 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 16:10:43.934748 41289 net.cpp:226] conv4_1 needs backward computation.
I0824 16:10:43.934752 41289 net.cpp:226] pool3 needs backward computation.
I0824 16:10:43.934756 41289 net.cpp:226] relu3_3 needs backward computation.
I0824 16:10:43.934761 41289 net.cpp:226] conv3_3_scale needs backward computation.
I0824 16:10:43.934765 41289 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 16:10:43.934769 41289 net.cpp:226] conv3_3 needs backward computation.
I0824 16:10:43.934773 41289 net.cpp:226] relu3_2 needs backward computation.
I0824 16:10:43.934777 41289 net.cpp:226] conv3_2_scale needs backward computation.
I0824 16:10:43.934782 41289 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 16:10:43.934787 41289 net.cpp:226] conv3_2 needs backward computation.
I0824 16:10:43.934790 41289 net.cpp:226] relu3_1 needs backward computation.
I0824 16:10:43.934794 41289 net.cpp:226] conv3_1_scale needs backward computation.
I0824 16:10:43.934798 41289 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 16:10:43.934803 41289 net.cpp:226] conv3_1 needs backward computation.
I0824 16:10:43.934808 41289 net.cpp:226] pool2 needs backward computation.
I0824 16:10:43.934811 41289 net.cpp:226] relu2_2 needs backward computation.
I0824 16:10:43.934815 41289 net.cpp:226] conv2_2_scale needs backward computation.
I0824 16:10:43.934819 41289 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 16:10:43.934823 41289 net.cpp:226] conv2_2 needs backward computation.
I0824 16:10:43.934828 41289 net.cpp:226] relu2_1 needs backward computation.
I0824 16:10:43.934831 41289 net.cpp:226] conv2_1_scale needs backward computation.
I0824 16:10:43.934837 41289 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 16:10:43.934840 41289 net.cpp:226] conv2_1 needs backward computation.
I0824 16:10:43.934845 41289 net.cpp:226] pool1 needs backward computation.
I0824 16:10:43.934849 41289 net.cpp:226] relu1_2 needs backward computation.
I0824 16:10:43.934852 41289 net.cpp:226] conv1_2_scale needs backward computation.
I0824 16:10:43.934855 41289 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 16:10:43.934860 41289 net.cpp:226] conv1_2 needs backward computation.
I0824 16:10:43.934865 41289 net.cpp:226] relu1_1 needs backward computation.
I0824 16:10:43.934870 41289 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 16:10:43.934872 41289 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 16:10:43.934876 41289 net.cpp:226] conv1_1_1 needs backward computation.
I0824 16:10:43.934881 41289 net.cpp:228] label_data_1_split does not need backward computation.
I0824 16:10:43.934886 41289 net.cpp:228] data does not need backward computation.
I0824 16:10:43.934891 41289 net.cpp:270] This network produces output accuracy
I0824 16:10:43.934895 41289 net.cpp:270] This network produces output loss
I0824 16:10:43.934900 41289 net.cpp:270] This network produces output per_class_accuracy
I0824 16:10:43.934970 41289 net.cpp:283] Network initialization done.
I0824 16:10:43.937392 41289 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc1/caffe/model_segnet_final/train.prototxt
I0824 16:10:43.938091 41289 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc1/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 16:10:43.938537 41289 layer_factory.hpp:77] Creating layer data
I0824 16:10:43.938550 41289 net.cpp:100] Creating Layer data
I0824 16:10:43.938556 41289 net.cpp:408] data -> data
I0824 16:10:43.938565 41289 net.cpp:408] data -> label
I0824 16:10:43.938573 41289 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc1/HDF5Files/train_combined.txt
I0824 16:10:43.938627 41289 hdf5_data_layer.cpp:93] Number of HDF5 files: 49
I0824 16:10:43.951421 41289 net.cpp:150] Setting up data
I0824 16:10:43.951445 41289 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 16:10:43.951452 41289 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 16:10:43.951459 41289 net.cpp:165] Memory required for data: 24883200
I0824 16:10:43.951467 41289 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 16:10:43.951479 41289 net.cpp:100] Creating Layer label_data_1_split
I0824 16:10:43.951484 41289 net.cpp:434] label_data_1_split <- label
I0824 16:10:43.951493 41289 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 16:10:43.951501 41289 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 16:10:43.951546 41289 net.cpp:150] Setting up label_data_1_split
I0824 16:10:43.951553 41289 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 16:10:43.951558 41289 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 16:10:43.951567 41289 net.cpp:165] Memory required for data: 30412800
I0824 16:10:43.951570 41289 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 16:10:43.951583 41289 net.cpp:100] Creating Layer conv1_1_1
I0824 16:10:43.951588 41289 net.cpp:434] conv1_1_1 <- data
I0824 16:10:43.951594 41289 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 16:10:43.955250 41289 net.cpp:150] Setting up conv1_1_1
I0824 16:10:43.955268 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.955278 41289 net.cpp:165] Memory required for data: 207360000
I0824 16:10:43.955292 41289 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 16:10:43.955302 41289 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 16:10:43.955309 41289 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 16:10:43.955315 41289 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 16:10:43.955693 41289 net.cpp:150] Setting up conv1_1_1_bn
I0824 16:10:43.955703 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.955706 41289 net.cpp:165] Memory required for data: 384307200
I0824 16:10:43.955719 41289 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 16:10:43.955729 41289 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 16:10:43.955734 41289 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 16:10:43.955739 41289 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 16:10:43.955788 41289 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 16:10:43.957473 41289 net.cpp:150] Setting up conv1_1_1_scale
I0824 16:10:43.957487 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.957496 41289 net.cpp:165] Memory required for data: 561254400
I0824 16:10:43.957505 41289 layer_factory.hpp:77] Creating layer relu1_1
I0824 16:10:43.957515 41289 net.cpp:100] Creating Layer relu1_1
I0824 16:10:43.957520 41289 net.cpp:434] relu1_1 <- conv1_1_1
I0824 16:10:43.957526 41289 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 16:10:43.957752 41289 net.cpp:150] Setting up relu1_1
I0824 16:10:43.957762 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.957765 41289 net.cpp:165] Memory required for data: 738201600
I0824 16:10:43.957769 41289 layer_factory.hpp:77] Creating layer conv1_2
I0824 16:10:43.957782 41289 net.cpp:100] Creating Layer conv1_2
I0824 16:10:43.957787 41289 net.cpp:434] conv1_2 <- conv1_1_1
I0824 16:10:43.957793 41289 net.cpp:408] conv1_2 -> conv1_2
I0824 16:10:43.961911 41289 net.cpp:150] Setting up conv1_2
I0824 16:10:43.961927 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.961936 41289 net.cpp:165] Memory required for data: 915148800
I0824 16:10:43.961967 41289 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 16:10:43.961979 41289 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 16:10:43.961984 41289 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 16:10:43.961989 41289 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 16:10:43.962369 41289 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 16:10:43.962378 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.962383 41289 net.cpp:165] Memory required for data: 1092096000
I0824 16:10:43.962393 41289 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 16:10:43.962401 41289 net.cpp:100] Creating Layer conv1_2_scale
I0824 16:10:43.962406 41289 net.cpp:434] conv1_2_scale <- conv1_2
I0824 16:10:43.962412 41289 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 16:10:43.962461 41289 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 16:10:43.964112 41289 net.cpp:150] Setting up conv1_2_scale
I0824 16:10:43.964126 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.964131 41289 net.cpp:165] Memory required for data: 1269043200
I0824 16:10:43.964139 41289 layer_factory.hpp:77] Creating layer relu1_2
I0824 16:10:43.964148 41289 net.cpp:100] Creating Layer relu1_2
I0824 16:10:43.964152 41289 net.cpp:434] relu1_2 <- conv1_2
I0824 16:10:43.964159 41289 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 16:10:43.965286 41289 net.cpp:150] Setting up relu1_2
I0824 16:10:43.965301 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:43.965306 41289 net.cpp:165] Memory required for data: 1445990400
I0824 16:10:43.965311 41289 layer_factory.hpp:77] Creating layer pool1
I0824 16:10:43.965315 41289 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 16:10:43.965322 41289 net.cpp:100] Creating Layer pool1
I0824 16:10:43.965327 41289 net.cpp:434] pool1 <- conv1_2
I0824 16:10:43.965333 41289 net.cpp:408] pool1 -> pool1
I0824 16:10:43.965342 41289 net.cpp:408] pool1 -> pool1_mask
I0824 16:10:43.965422 41289 net.cpp:150] Setting up pool1
I0824 16:10:43.965431 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:43.965436 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:43.965440 41289 net.cpp:165] Memory required for data: 1534464000
I0824 16:10:43.965443 41289 layer_factory.hpp:77] Creating layer conv2_1
I0824 16:10:43.965458 41289 net.cpp:100] Creating Layer conv2_1
I0824 16:10:43.965464 41289 net.cpp:434] conv2_1 <- pool1
I0824 16:10:43.965471 41289 net.cpp:408] conv2_1 -> conv2_1
I0824 16:10:43.969827 41289 net.cpp:150] Setting up conv2_1
I0824 16:10:43.969842 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.969853 41289 net.cpp:165] Memory required for data: 1622937600
I0824 16:10:43.969861 41289 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 16:10:43.969871 41289 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 16:10:43.969877 41289 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 16:10:43.969882 41289 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 16:10:43.970199 41289 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 16:10:43.970208 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.970212 41289 net.cpp:165] Memory required for data: 1711411200
I0824 16:10:43.970226 41289 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 16:10:43.970235 41289 net.cpp:100] Creating Layer conv2_1_scale
I0824 16:10:43.970240 41289 net.cpp:434] conv2_1_scale <- conv2_1
I0824 16:10:43.970247 41289 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 16:10:43.970299 41289 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 16:10:43.970536 41289 net.cpp:150] Setting up conv2_1_scale
I0824 16:10:43.970544 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.970548 41289 net.cpp:165] Memory required for data: 1799884800
I0824 16:10:43.970556 41289 layer_factory.hpp:77] Creating layer relu2_1
I0824 16:10:43.970562 41289 net.cpp:100] Creating Layer relu2_1
I0824 16:10:43.970567 41289 net.cpp:434] relu2_1 <- conv2_1
I0824 16:10:43.970572 41289 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 16:10:43.971722 41289 net.cpp:150] Setting up relu2_1
I0824 16:10:43.971736 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.971741 41289 net.cpp:165] Memory required for data: 1888358400
I0824 16:10:43.971746 41289 layer_factory.hpp:77] Creating layer conv2_2
I0824 16:10:43.971760 41289 net.cpp:100] Creating Layer conv2_2
I0824 16:10:43.971765 41289 net.cpp:434] conv2_2 <- conv2_1
I0824 16:10:43.971773 41289 net.cpp:408] conv2_2 -> conv2_2
I0824 16:10:43.980793 41289 net.cpp:150] Setting up conv2_2
I0824 16:10:43.980810 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.980820 41289 net.cpp:165] Memory required for data: 1976832000
I0824 16:10:43.980831 41289 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 16:10:43.980846 41289 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 16:10:43.980852 41289 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 16:10:43.980859 41289 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 16:10:43.982534 41289 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 16:10:43.982549 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.982559 41289 net.cpp:165] Memory required for data: 2065305600
I0824 16:10:43.982569 41289 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 16:10:43.982586 41289 net.cpp:100] Creating Layer conv2_2_scale
I0824 16:10:43.982591 41289 net.cpp:434] conv2_2_scale <- conv2_2
I0824 16:10:43.982597 41289 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 16:10:43.982661 41289 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 16:10:43.982882 41289 net.cpp:150] Setting up conv2_2_scale
I0824 16:10:43.982890 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.982893 41289 net.cpp:165] Memory required for data: 2153779200
I0824 16:10:43.982900 41289 layer_factory.hpp:77] Creating layer relu2_2
I0824 16:10:43.982909 41289 net.cpp:100] Creating Layer relu2_2
I0824 16:10:43.982913 41289 net.cpp:434] relu2_2 <- conv2_2
I0824 16:10:43.982918 41289 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 16:10:43.983155 41289 net.cpp:150] Setting up relu2_2
I0824 16:10:43.983165 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:43.983170 41289 net.cpp:165] Memory required for data: 2242252800
I0824 16:10:43.983173 41289 layer_factory.hpp:77] Creating layer pool2
I0824 16:10:43.983178 41289 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 16:10:43.983186 41289 net.cpp:100] Creating Layer pool2
I0824 16:10:43.983191 41289 net.cpp:434] pool2 <- conv2_2
I0824 16:10:43.983198 41289 net.cpp:408] pool2 -> pool2
I0824 16:10:43.983206 41289 net.cpp:408] pool2 -> pool2_mask
I0824 16:10:43.983263 41289 net.cpp:150] Setting up pool2
I0824 16:10:43.983270 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:43.983275 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:43.983278 41289 net.cpp:165] Memory required for data: 2286489600
I0824 16:10:43.983281 41289 layer_factory.hpp:77] Creating layer conv3_1
I0824 16:10:43.983299 41289 net.cpp:100] Creating Layer conv3_1
I0824 16:10:43.983304 41289 net.cpp:434] conv3_1 <- pool2
I0824 16:10:43.983310 41289 net.cpp:408] conv3_1 -> conv3_1
I0824 16:10:43.995898 41289 net.cpp:150] Setting up conv3_1
I0824 16:10:43.995913 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.995918 41289 net.cpp:165] Memory required for data: 2330726400
I0824 16:10:43.995926 41289 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 16:10:43.995942 41289 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 16:10:43.995949 41289 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 16:10:43.995955 41289 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 16:10:43.996249 41289 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 16:10:43.996258 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.996261 41289 net.cpp:165] Memory required for data: 2374963200
I0824 16:10:43.996279 41289 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 16:10:43.996301 41289 net.cpp:100] Creating Layer conv3_1_scale
I0824 16:10:43.996309 41289 net.cpp:434] conv3_1_scale <- conv3_1
I0824 16:10:43.996317 41289 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 16:10:43.996377 41289 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 16:10:43.996563 41289 net.cpp:150] Setting up conv3_1_scale
I0824 16:10:43.996572 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.996577 41289 net.cpp:165] Memory required for data: 2419200000
I0824 16:10:43.996583 41289 layer_factory.hpp:77] Creating layer relu3_1
I0824 16:10:43.996594 41289 net.cpp:100] Creating Layer relu3_1
I0824 16:10:43.996599 41289 net.cpp:434] relu3_1 <- conv3_1
I0824 16:10:43.996604 41289 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 16:10:43.996834 41289 net.cpp:150] Setting up relu3_1
I0824 16:10:43.996847 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:43.996852 41289 net.cpp:165] Memory required for data: 2463436800
I0824 16:10:43.996855 41289 layer_factory.hpp:77] Creating layer conv3_2
I0824 16:10:43.996870 41289 net.cpp:100] Creating Layer conv3_2
I0824 16:10:43.996875 41289 net.cpp:434] conv3_2 <- conv3_1
I0824 16:10:43.996881 41289 net.cpp:408] conv3_2 -> conv3_2
I0824 16:10:44.021041 41289 net.cpp:150] Setting up conv3_2
I0824 16:10:44.021061 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:44.021070 41289 net.cpp:165] Memory required for data: 2507673600
I0824 16:10:44.021078 41289 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 16:10:44.021086 41289 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 16:10:44.021093 41289 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 16:10:44.021102 41289 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 16:10:44.021419 41289 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 16:10:44.021428 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:44.021432 41289 net.cpp:165] Memory required for data: 2551910400
I0824 16:10:44.021440 41289 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 16:10:44.021448 41289 net.cpp:100] Creating Layer conv3_2_scale
I0824 16:10:44.021452 41289 net.cpp:434] conv3_2_scale <- conv3_2
I0824 16:10:44.021457 41289 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 16:10:44.021512 41289 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 16:10:44.021699 41289 net.cpp:150] Setting up conv3_2_scale
I0824 16:10:44.021708 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:44.021710 41289 net.cpp:165] Memory required for data: 2596147200
I0824 16:10:44.021718 41289 layer_factory.hpp:77] Creating layer relu3_2
I0824 16:10:44.021726 41289 net.cpp:100] Creating Layer relu3_2
I0824 16:10:44.021735 41289 net.cpp:434] relu3_2 <- conv3_2
I0824 16:10:44.021742 41289 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 16:10:44.021971 41289 net.cpp:150] Setting up relu3_2
I0824 16:10:44.021981 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:44.021986 41289 net.cpp:165] Memory required for data: 2640384000
I0824 16:10:44.021991 41289 layer_factory.hpp:77] Creating layer conv3_3
I0824 16:10:44.022003 41289 net.cpp:100] Creating Layer conv3_3
I0824 16:10:44.022008 41289 net.cpp:434] conv3_3 <- conv3_2
I0824 16:10:44.022017 41289 net.cpp:408] conv3_3 -> conv3_3
I0824 16:10:44.045744 41289 net.cpp:150] Setting up conv3_3
I0824 16:10:44.045761 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:44.045766 41289 net.cpp:165] Memory required for data: 2684620800
I0824 16:10:44.045785 41289 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 16:10:44.045796 41289 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 16:10:44.045804 41289 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 16:10:44.045809 41289 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 16:10:44.046093 41289 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 16:10:44.046103 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:44.046105 41289 net.cpp:165] Memory required for data: 2728857600
I0824 16:10:44.046114 41289 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 16:10:44.046141 41289 net.cpp:100] Creating Layer conv3_3_scale
I0824 16:10:44.046147 41289 net.cpp:434] conv3_3_scale <- conv3_3
I0824 16:10:44.046152 41289 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 16:10:44.046206 41289 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 16:10:44.046389 41289 net.cpp:150] Setting up conv3_3_scale
I0824 16:10:44.046397 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:44.046401 41289 net.cpp:165] Memory required for data: 2773094400
I0824 16:10:44.046408 41289 layer_factory.hpp:77] Creating layer relu3_3
I0824 16:10:44.046416 41289 net.cpp:100] Creating Layer relu3_3
I0824 16:10:44.046421 41289 net.cpp:434] relu3_3 <- conv3_3
I0824 16:10:44.046427 41289 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 16:10:44.046654 41289 net.cpp:150] Setting up relu3_3
I0824 16:10:44.046663 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:44.046669 41289 net.cpp:165] Memory required for data: 2817331200
I0824 16:10:44.046672 41289 layer_factory.hpp:77] Creating layer pool3
I0824 16:10:44.046677 41289 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 16:10:44.046692 41289 net.cpp:100] Creating Layer pool3
I0824 16:10:44.046697 41289 net.cpp:434] pool3 <- conv3_3
I0824 16:10:44.046706 41289 net.cpp:408] pool3 -> pool3
I0824 16:10:44.046715 41289 net.cpp:408] pool3 -> pool3_mask
I0824 16:10:44.046772 41289 net.cpp:150] Setting up pool3
I0824 16:10:44.046782 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:44.046787 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:44.046792 41289 net.cpp:165] Memory required for data: 2839449600
I0824 16:10:44.046795 41289 layer_factory.hpp:77] Creating layer conv4_1
I0824 16:10:44.046808 41289 net.cpp:100] Creating Layer conv4_1
I0824 16:10:44.046813 41289 net.cpp:434] conv4_1 <- pool3
I0824 16:10:44.046818 41289 net.cpp:408] conv4_1 -> conv4_1
I0824 16:10:44.090919 41289 net.cpp:150] Setting up conv4_1
I0824 16:10:44.090940 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.090945 41289 net.cpp:165] Memory required for data: 2861568000
I0824 16:10:44.090957 41289 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 16:10:44.090966 41289 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 16:10:44.090975 41289 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 16:10:44.090982 41289 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 16:10:44.091274 41289 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 16:10:44.091284 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.091287 41289 net.cpp:165] Memory required for data: 2883686400
I0824 16:10:44.091295 41289 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 16:10:44.091305 41289 net.cpp:100] Creating Layer conv4_1_scale
I0824 16:10:44.091312 41289 net.cpp:434] conv4_1_scale <- conv4_1
I0824 16:10:44.091318 41289 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 16:10:44.091368 41289 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 16:10:44.091538 41289 net.cpp:150] Setting up conv4_1_scale
I0824 16:10:44.091547 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.091550 41289 net.cpp:165] Memory required for data: 2905804800
I0824 16:10:44.091557 41289 layer_factory.hpp:77] Creating layer relu4_1
I0824 16:10:44.091570 41289 net.cpp:100] Creating Layer relu4_1
I0824 16:10:44.091575 41289 net.cpp:434] relu4_1 <- conv4_1
I0824 16:10:44.091583 41289 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 16:10:44.092734 41289 net.cpp:150] Setting up relu4_1
I0824 16:10:44.092749 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.092754 41289 net.cpp:165] Memory required for data: 2927923200
I0824 16:10:44.092759 41289 layer_factory.hpp:77] Creating layer conv4_2
I0824 16:10:44.092775 41289 net.cpp:100] Creating Layer conv4_2
I0824 16:10:44.092780 41289 net.cpp:434] conv4_2 <- conv4_1
I0824 16:10:44.092790 41289 net.cpp:408] conv4_2 -> conv4_2
I0824 16:10:44.177628 41289 net.cpp:150] Setting up conv4_2
I0824 16:10:44.177662 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.177676 41289 net.cpp:165] Memory required for data: 2950041600
I0824 16:10:44.177685 41289 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 16:10:44.177691 41289 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 16:10:44.177700 41289 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 16:10:44.177708 41289 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 16:10:44.177984 41289 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 16:10:44.177992 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.177996 41289 net.cpp:165] Memory required for data: 2972160000
I0824 16:10:44.178004 41289 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 16:10:44.178011 41289 net.cpp:100] Creating Layer conv4_2_scale
I0824 16:10:44.178020 41289 net.cpp:434] conv4_2_scale <- conv4_2
I0824 16:10:44.178025 41289 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 16:10:44.178073 41289 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 16:10:44.178236 41289 net.cpp:150] Setting up conv4_2_scale
I0824 16:10:44.178244 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.178247 41289 net.cpp:165] Memory required for data: 2994278400
I0824 16:10:44.178254 41289 layer_factory.hpp:77] Creating layer relu4_2
I0824 16:10:44.178262 41289 net.cpp:100] Creating Layer relu4_2
I0824 16:10:44.178269 41289 net.cpp:434] relu4_2 <- conv4_2
I0824 16:10:44.178274 41289 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 16:10:44.179445 41289 net.cpp:150] Setting up relu4_2
I0824 16:10:44.179458 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.179463 41289 net.cpp:165] Memory required for data: 3016396800
I0824 16:10:44.179467 41289 layer_factory.hpp:77] Creating layer conv4_3
I0824 16:10:44.179483 41289 net.cpp:100] Creating Layer conv4_3
I0824 16:10:44.179489 41289 net.cpp:434] conv4_3 <- conv4_2
I0824 16:10:44.179497 41289 net.cpp:408] conv4_3 -> conv4_3
I0824 16:10:44.263208 41289 net.cpp:150] Setting up conv4_3
I0824 16:10:44.263226 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.263231 41289 net.cpp:165] Memory required for data: 3038515200
I0824 16:10:44.263257 41289 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 16:10:44.263267 41289 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 16:10:44.263274 41289 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 16:10:44.263281 41289 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 16:10:44.263558 41289 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 16:10:44.263567 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.263571 41289 net.cpp:165] Memory required for data: 3060633600
I0824 16:10:44.263579 41289 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 16:10:44.263591 41289 net.cpp:100] Creating Layer conv4_3_scale
I0824 16:10:44.263597 41289 net.cpp:434] conv4_3_scale <- conv4_3
I0824 16:10:44.263602 41289 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 16:10:44.263653 41289 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 16:10:44.263818 41289 net.cpp:150] Setting up conv4_3_scale
I0824 16:10:44.263825 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.263829 41289 net.cpp:165] Memory required for data: 3082752000
I0824 16:10:44.263835 41289 layer_factory.hpp:77] Creating layer relu4_3
I0824 16:10:44.263844 41289 net.cpp:100] Creating Layer relu4_3
I0824 16:10:44.263849 41289 net.cpp:434] relu4_3 <- conv4_3
I0824 16:10:44.263854 41289 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 16:10:44.264075 41289 net.cpp:150] Setting up relu4_3
I0824 16:10:44.264083 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.264087 41289 net.cpp:165] Memory required for data: 3104870400
I0824 16:10:44.264091 41289 layer_factory.hpp:77] Creating layer pool4
I0824 16:10:44.264097 41289 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 16:10:44.264106 41289 net.cpp:100] Creating Layer pool4
I0824 16:10:44.264111 41289 net.cpp:434] pool4 <- conv4_3
I0824 16:10:44.264132 41289 net.cpp:408] pool4 -> pool4
I0824 16:10:44.264143 41289 net.cpp:408] pool4 -> pool4_mask
I0824 16:10:44.264201 41289 net.cpp:150] Setting up pool4
I0824 16:10:44.264209 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.264212 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.264217 41289 net.cpp:165] Memory required for data: 3116175360
I0824 16:10:44.264221 41289 layer_factory.hpp:77] Creating layer conv5_1
I0824 16:10:44.264233 41289 net.cpp:100] Creating Layer conv5_1
I0824 16:10:44.264238 41289 net.cpp:434] conv5_1 <- pool4
I0824 16:10:44.264246 41289 net.cpp:408] conv5_1 -> conv5_1
I0824 16:10:44.348057 41289 net.cpp:150] Setting up conv5_1
I0824 16:10:44.348074 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.348078 41289 net.cpp:165] Memory required for data: 3121827840
I0824 16:10:44.348086 41289 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 16:10:44.348098 41289 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 16:10:44.348110 41289 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 16:10:44.348116 41289 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 16:10:44.348402 41289 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 16:10:44.348412 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.348414 41289 net.cpp:165] Memory required for data: 3127480320
I0824 16:10:44.348423 41289 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 16:10:44.348430 41289 net.cpp:100] Creating Layer conv5_1_scale
I0824 16:10:44.348439 41289 net.cpp:434] conv5_1_scale <- conv5_1
I0824 16:10:44.348446 41289 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 16:10:44.348505 41289 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 16:10:44.348657 41289 net.cpp:150] Setting up conv5_1_scale
I0824 16:10:44.348664 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.348668 41289 net.cpp:165] Memory required for data: 3133132800
I0824 16:10:44.348675 41289 layer_factory.hpp:77] Creating layer relu5_1
I0824 16:10:44.348685 41289 net.cpp:100] Creating Layer relu5_1
I0824 16:10:44.348690 41289 net.cpp:434] relu5_1 <- conv5_1
I0824 16:10:44.348695 41289 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 16:10:44.348914 41289 net.cpp:150] Setting up relu5_1
I0824 16:10:44.348925 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.348930 41289 net.cpp:165] Memory required for data: 3138785280
I0824 16:10:44.348934 41289 layer_factory.hpp:77] Creating layer conv5_2
I0824 16:10:44.348947 41289 net.cpp:100] Creating Layer conv5_2
I0824 16:10:44.348951 41289 net.cpp:434] conv5_2 <- conv5_1
I0824 16:10:44.348958 41289 net.cpp:408] conv5_2 -> conv5_2
I0824 16:10:44.432678 41289 net.cpp:150] Setting up conv5_2
I0824 16:10:44.432698 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.432701 41289 net.cpp:165] Memory required for data: 3144437760
I0824 16:10:44.432715 41289 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 16:10:44.432729 41289 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 16:10:44.432735 41289 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 16:10:44.432744 41289 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 16:10:44.433015 41289 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 16:10:44.433024 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.433028 41289 net.cpp:165] Memory required for data: 3150090240
I0824 16:10:44.433037 41289 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 16:10:44.433051 41289 net.cpp:100] Creating Layer conv5_2_scale
I0824 16:10:44.433056 41289 net.cpp:434] conv5_2_scale <- conv5_2
I0824 16:10:44.433061 41289 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 16:10:44.433120 41289 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 16:10:44.433274 41289 net.cpp:150] Setting up conv5_2_scale
I0824 16:10:44.433280 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.433284 41289 net.cpp:165] Memory required for data: 3155742720
I0824 16:10:44.433290 41289 layer_factory.hpp:77] Creating layer relu5_2
I0824 16:10:44.433313 41289 net.cpp:100] Creating Layer relu5_2
I0824 16:10:44.433320 41289 net.cpp:434] relu5_2 <- conv5_2
I0824 16:10:44.433326 41289 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 16:10:44.433565 41289 net.cpp:150] Setting up relu5_2
I0824 16:10:44.433576 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.433580 41289 net.cpp:165] Memory required for data: 3161395200
I0824 16:10:44.433583 41289 layer_factory.hpp:77] Creating layer conv5_3
I0824 16:10:44.433598 41289 net.cpp:100] Creating Layer conv5_3
I0824 16:10:44.433604 41289 net.cpp:434] conv5_3 <- conv5_2
I0824 16:10:44.433614 41289 net.cpp:408] conv5_3 -> conv5_3
I0824 16:10:44.517256 41289 net.cpp:150] Setting up conv5_3
I0824 16:10:44.517272 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.517285 41289 net.cpp:165] Memory required for data: 3167047680
I0824 16:10:44.517293 41289 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 16:10:44.517305 41289 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 16:10:44.517313 41289 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 16:10:44.517318 41289 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 16:10:44.517616 41289 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 16:10:44.517626 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.517629 41289 net.cpp:165] Memory required for data: 3172700160
I0824 16:10:44.517638 41289 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 16:10:44.517647 41289 net.cpp:100] Creating Layer conv5_3_scale
I0824 16:10:44.517655 41289 net.cpp:434] conv5_3_scale <- conv5_3
I0824 16:10:44.517662 41289 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 16:10:44.517717 41289 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 16:10:44.517874 41289 net.cpp:150] Setting up conv5_3_scale
I0824 16:10:44.517881 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.517884 41289 net.cpp:165] Memory required for data: 3178352640
I0824 16:10:44.517891 41289 layer_factory.hpp:77] Creating layer relu5_3
I0824 16:10:44.517899 41289 net.cpp:100] Creating Layer relu5_3
I0824 16:10:44.517904 41289 net.cpp:434] relu5_3 <- conv5_3
I0824 16:10:44.517910 41289 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 16:10:44.518129 41289 net.cpp:150] Setting up relu5_3
I0824 16:10:44.518138 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.518144 41289 net.cpp:165] Memory required for data: 3184005120
I0824 16:10:44.518148 41289 layer_factory.hpp:77] Creating layer pool5
I0824 16:10:44.518153 41289 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 16:10:44.518162 41289 net.cpp:100] Creating Layer pool5
I0824 16:10:44.518167 41289 net.cpp:434] pool5 <- conv5_3
I0824 16:10:44.518173 41289 net.cpp:408] pool5 -> pool5
I0824 16:10:44.518184 41289 net.cpp:408] pool5 -> pool5_mask
I0824 16:10:44.518242 41289 net.cpp:150] Setting up pool5
I0824 16:10:44.518249 41289 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 16:10:44.518254 41289 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 16:10:44.518256 41289 net.cpp:165] Memory required for data: 3186954240
I0824 16:10:44.518260 41289 layer_factory.hpp:77] Creating layer upsample5
I0824 16:10:44.518270 41289 net.cpp:100] Creating Layer upsample5
I0824 16:10:44.518275 41289 net.cpp:434] upsample5 <- pool5
I0824 16:10:44.518280 41289 net.cpp:434] upsample5 <- pool5_mask
I0824 16:10:44.518286 41289 net.cpp:408] upsample5 -> pool5_D
I0824 16:10:44.518319 41289 net.cpp:150] Setting up upsample5
I0824 16:10:44.518326 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.518328 41289 net.cpp:165] Memory required for data: 3192606720
I0824 16:10:44.518332 41289 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 16:10:44.518344 41289 net.cpp:100] Creating Layer conv5_3_D
I0824 16:10:44.518349 41289 net.cpp:434] conv5_3_D <- pool5_D
I0824 16:10:44.518357 41289 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 16:10:44.603296 41289 net.cpp:150] Setting up conv5_3_D
I0824 16:10:44.603315 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.603338 41289 net.cpp:165] Memory required for data: 3198259200
I0824 16:10:44.603348 41289 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 16:10:44.603358 41289 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 16:10:44.603365 41289 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 16:10:44.603371 41289 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 16:10:44.603653 41289 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 16:10:44.603662 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.603665 41289 net.cpp:165] Memory required for data: 3203911680
I0824 16:10:44.603674 41289 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 16:10:44.603682 41289 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 16:10:44.603691 41289 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 16:10:44.603696 41289 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 16:10:44.603754 41289 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 16:10:44.603910 41289 net.cpp:150] Setting up conv5_3_D_scale
I0824 16:10:44.603917 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.603921 41289 net.cpp:165] Memory required for data: 3209564160
I0824 16:10:44.603927 41289 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 16:10:44.603937 41289 net.cpp:100] Creating Layer relu5_3_D
I0824 16:10:44.603942 41289 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 16:10:44.603947 41289 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 16:10:44.605098 41289 net.cpp:150] Setting up relu5_3_D
I0824 16:10:44.605113 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.605118 41289 net.cpp:165] Memory required for data: 3215216640
I0824 16:10:44.605121 41289 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 16:10:44.605147 41289 net.cpp:100] Creating Layer conv5_2_D
I0824 16:10:44.605154 41289 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 16:10:44.605162 41289 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 16:10:44.688937 41289 net.cpp:150] Setting up conv5_2_D
I0824 16:10:44.688954 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.688958 41289 net.cpp:165] Memory required for data: 3220869120
I0824 16:10:44.688967 41289 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 16:10:44.688977 41289 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 16:10:44.688982 41289 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 16:10:44.688988 41289 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 16:10:44.689275 41289 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 16:10:44.689283 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.689287 41289 net.cpp:165] Memory required for data: 3226521600
I0824 16:10:44.689296 41289 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 16:10:44.689302 41289 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 16:10:44.689311 41289 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 16:10:44.689317 41289 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 16:10:44.689402 41289 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 16:10:44.689565 41289 net.cpp:150] Setting up conv5_2_D_scale
I0824 16:10:44.689576 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.689584 41289 net.cpp:165] Memory required for data: 3232174080
I0824 16:10:44.689591 41289 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 16:10:44.689599 41289 net.cpp:100] Creating Layer relu5_2_D
I0824 16:10:44.689604 41289 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 16:10:44.689609 41289 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 16:10:44.690775 41289 net.cpp:150] Setting up relu5_2_D
I0824 16:10:44.690790 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.690795 41289 net.cpp:165] Memory required for data: 3237826560
I0824 16:10:44.690799 41289 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 16:10:44.690817 41289 net.cpp:100] Creating Layer conv5_1_D
I0824 16:10:44.690824 41289 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 16:10:44.690830 41289 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 16:10:44.774667 41289 net.cpp:150] Setting up conv5_1_D
I0824 16:10:44.774683 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.774688 41289 net.cpp:165] Memory required for data: 3243479040
I0824 16:10:44.774695 41289 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 16:10:44.774703 41289 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 16:10:44.774708 41289 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 16:10:44.774715 41289 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 16:10:44.774996 41289 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 16:10:44.775005 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.775009 41289 net.cpp:165] Memory required for data: 3249131520
I0824 16:10:44.775017 41289 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 16:10:44.775027 41289 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 16:10:44.775035 41289 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 16:10:44.775040 41289 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 16:10:44.775104 41289 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 16:10:44.775262 41289 net.cpp:150] Setting up conv5_1_D_scale
I0824 16:10:44.775270 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.775274 41289 net.cpp:165] Memory required for data: 3254784000
I0824 16:10:44.775280 41289 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 16:10:44.775290 41289 net.cpp:100] Creating Layer relu5_1_D
I0824 16:10:44.775295 41289 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 16:10:44.775300 41289 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 16:10:44.775549 41289 net.cpp:150] Setting up relu5_1_D
I0824 16:10:44.775559 41289 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 16:10:44.775564 41289 net.cpp:165] Memory required for data: 3260436480
I0824 16:10:44.775568 41289 layer_factory.hpp:77] Creating layer upsample4
I0824 16:10:44.775578 41289 net.cpp:100] Creating Layer upsample4
I0824 16:10:44.775583 41289 net.cpp:434] upsample4 <- conv5_1_D
I0824 16:10:44.775589 41289 net.cpp:434] upsample4 <- pool4_mask
I0824 16:10:44.775596 41289 net.cpp:408] upsample4 -> pool4_D
I0824 16:10:44.775635 41289 net.cpp:150] Setting up upsample4
I0824 16:10:44.775642 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.775646 41289 net.cpp:165] Memory required for data: 3282554880
I0824 16:10:44.775650 41289 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 16:10:44.775662 41289 net.cpp:100] Creating Layer conv4_3_D
I0824 16:10:44.775667 41289 net.cpp:434] conv4_3_D <- pool4_D
I0824 16:10:44.775676 41289 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 16:10:44.859547 41289 net.cpp:150] Setting up conv4_3_D
I0824 16:10:44.859568 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.859580 41289 net.cpp:165] Memory required for data: 3304673280
I0824 16:10:44.859588 41289 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 16:10:44.859596 41289 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 16:10:44.859604 41289 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 16:10:44.859616 41289 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 16:10:44.859908 41289 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 16:10:44.859917 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.859921 41289 net.cpp:165] Memory required for data: 3326791680
I0824 16:10:44.859930 41289 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 16:10:44.859939 41289 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 16:10:44.859946 41289 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 16:10:44.859951 41289 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 16:10:44.860003 41289 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 16:10:44.860177 41289 net.cpp:150] Setting up conv4_3_D_scale
I0824 16:10:44.860184 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.860188 41289 net.cpp:165] Memory required for data: 3348910080
I0824 16:10:44.860194 41289 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 16:10:44.860229 41289 net.cpp:100] Creating Layer relu4_3_D
I0824 16:10:44.860234 41289 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 16:10:44.860241 41289 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 16:10:44.860466 41289 net.cpp:150] Setting up relu4_3_D
I0824 16:10:44.860476 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.860478 41289 net.cpp:165] Memory required for data: 3371028480
I0824 16:10:44.860482 41289 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 16:10:44.860497 41289 net.cpp:100] Creating Layer conv4_2_D
I0824 16:10:44.860503 41289 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 16:10:44.860509 41289 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 16:10:44.944293 41289 net.cpp:150] Setting up conv4_2_D
I0824 16:10:44.944310 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.944314 41289 net.cpp:165] Memory required for data: 3393146880
I0824 16:10:44.944322 41289 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 16:10:44.944332 41289 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 16:10:44.944344 41289 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 16:10:44.944350 41289 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 16:10:44.944644 41289 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 16:10:44.944653 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.944656 41289 net.cpp:165] Memory required for data: 3415265280
I0824 16:10:44.944667 41289 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 16:10:44.944676 41289 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 16:10:44.944685 41289 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 16:10:44.944690 41289 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 16:10:44.944744 41289 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 16:10:44.944917 41289 net.cpp:150] Setting up conv4_2_D_scale
I0824 16:10:44.944924 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.944928 41289 net.cpp:165] Memory required for data: 3437383680
I0824 16:10:44.944934 41289 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 16:10:44.944943 41289 net.cpp:100] Creating Layer relu4_2_D
I0824 16:10:44.944948 41289 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 16:10:44.944953 41289 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 16:10:44.945170 41289 net.cpp:150] Setting up relu4_2_D
I0824 16:10:44.945180 41289 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 16:10:44.945183 41289 net.cpp:165] Memory required for data: 3459502080
I0824 16:10:44.945188 41289 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 16:10:44.945204 41289 net.cpp:100] Creating Layer conv4_1_D
I0824 16:10:44.945209 41289 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 16:10:44.945215 41289 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 16:10:44.989305 41289 net.cpp:150] Setting up conv4_1_D
I0824 16:10:44.989322 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:44.989334 41289 net.cpp:165] Memory required for data: 3470561280
I0824 16:10:44.989342 41289 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 16:10:44.989352 41289 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 16:10:44.989363 41289 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 16:10:44.989384 41289 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 16:10:44.989682 41289 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 16:10:44.989692 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:44.989696 41289 net.cpp:165] Memory required for data: 3481620480
I0824 16:10:44.989730 41289 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 16:10:44.989742 41289 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 16:10:44.989748 41289 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 16:10:44.989753 41289 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 16:10:44.989810 41289 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 16:10:44.989984 41289 net.cpp:150] Setting up conv4_1_D_scale
I0824 16:10:44.989992 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:44.990011 41289 net.cpp:165] Memory required for data: 3492679680
I0824 16:10:44.990018 41289 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 16:10:44.990025 41289 net.cpp:100] Creating Layer relu4_1_D
I0824 16:10:44.990031 41289 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 16:10:44.990036 41289 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 16:10:44.990274 41289 net.cpp:150] Setting up relu4_1_D
I0824 16:10:44.990283 41289 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 16:10:44.990289 41289 net.cpp:165] Memory required for data: 3503738880
I0824 16:10:44.990293 41289 layer_factory.hpp:77] Creating layer upsample3
I0824 16:10:44.990301 41289 net.cpp:100] Creating Layer upsample3
I0824 16:10:44.990306 41289 net.cpp:434] upsample3 <- conv4_1_D
I0824 16:10:44.990311 41289 net.cpp:434] upsample3 <- pool3_mask
I0824 16:10:44.990320 41289 net.cpp:408] upsample3 -> pool3_D
I0824 16:10:44.990329 41289 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 16:10:44.990365 41289 net.cpp:150] Setting up upsample3
I0824 16:10:44.990375 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:44.990380 41289 net.cpp:165] Memory required for data: 3547975680
I0824 16:10:44.990382 41289 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 16:10:44.990394 41289 net.cpp:100] Creating Layer conv3_3_D
I0824 16:10:44.990399 41289 net.cpp:434] conv3_3_D <- pool3_D
I0824 16:10:44.990406 41289 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 16:10:45.014137 41289 net.cpp:150] Setting up conv3_3_D
I0824 16:10:45.014154 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:45.014164 41289 net.cpp:165] Memory required for data: 3592212480
I0824 16:10:45.014173 41289 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 16:10:45.014180 41289 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 16:10:45.014185 41289 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 16:10:45.014192 41289 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 16:10:45.014508 41289 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 16:10:45.014516 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:45.014519 41289 net.cpp:165] Memory required for data: 3636449280
I0824 16:10:45.014528 41289 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 16:10:45.014536 41289 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 16:10:45.014545 41289 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 16:10:45.014550 41289 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 16:10:45.014612 41289 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 16:10:45.014807 41289 net.cpp:150] Setting up conv3_3_D_scale
I0824 16:10:45.014816 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:45.014819 41289 net.cpp:165] Memory required for data: 3680686080
I0824 16:10:45.014827 41289 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 16:10:45.014833 41289 net.cpp:100] Creating Layer relu3_3_D
I0824 16:10:45.014838 41289 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 16:10:45.014845 41289 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 16:10:45.016012 41289 net.cpp:150] Setting up relu3_3_D
I0824 16:10:45.016026 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:45.016031 41289 net.cpp:165] Memory required for data: 3724922880
I0824 16:10:45.016036 41289 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 16:10:45.016049 41289 net.cpp:100] Creating Layer conv3_2_D
I0824 16:10:45.016055 41289 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 16:10:45.016063 41289 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 16:10:45.038841 41289 net.cpp:150] Setting up conv3_2_D
I0824 16:10:45.038857 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:45.038868 41289 net.cpp:165] Memory required for data: 3769159680
I0824 16:10:45.038878 41289 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 16:10:45.038889 41289 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 16:10:45.038897 41289 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 16:10:45.038918 41289 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 16:10:45.039225 41289 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 16:10:45.039234 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:45.039238 41289 net.cpp:165] Memory required for data: 3813396480
I0824 16:10:45.039247 41289 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 16:10:45.039258 41289 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 16:10:45.039263 41289 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 16:10:45.039268 41289 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 16:10:45.039324 41289 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 16:10:45.039517 41289 net.cpp:150] Setting up conv3_2_D_scale
I0824 16:10:45.039525 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:45.039528 41289 net.cpp:165] Memory required for data: 3857633280
I0824 16:10:45.039535 41289 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 16:10:45.039542 41289 net.cpp:100] Creating Layer relu3_2_D
I0824 16:10:45.039547 41289 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 16:10:45.039553 41289 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 16:10:45.040715 41289 net.cpp:150] Setting up relu3_2_D
I0824 16:10:45.040730 41289 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 16:10:45.040735 41289 net.cpp:165] Memory required for data: 3901870080
I0824 16:10:45.040740 41289 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 16:10:45.040752 41289 net.cpp:100] Creating Layer conv3_1_D
I0824 16:10:45.040758 41289 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 16:10:45.040767 41289 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 16:10:45.054762 41289 net.cpp:150] Setting up conv3_1_D
I0824 16:10:45.054780 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:45.054788 41289 net.cpp:165] Memory required for data: 3923988480
I0824 16:10:45.054800 41289 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 16:10:45.054812 41289 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 16:10:45.054821 41289 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 16:10:45.054827 41289 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 16:10:45.055138 41289 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 16:10:45.055146 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:45.055150 41289 net.cpp:165] Memory required for data: 3946106880
I0824 16:10:45.055160 41289 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 16:10:45.055167 41289 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 16:10:45.055176 41289 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 16:10:45.055182 41289 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 16:10:45.055239 41289 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 16:10:45.056691 41289 net.cpp:150] Setting up conv3_1_D_scale
I0824 16:10:45.056705 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:45.056715 41289 net.cpp:165] Memory required for data: 3968225280
I0824 16:10:45.056725 41289 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 16:10:45.056732 41289 net.cpp:100] Creating Layer relu3_1_D
I0824 16:10:45.056738 41289 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 16:10:45.056744 41289 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 16:10:45.056984 41289 net.cpp:150] Setting up relu3_1_D
I0824 16:10:45.056995 41289 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 16:10:45.057000 41289 net.cpp:165] Memory required for data: 3990343680
I0824 16:10:45.057003 41289 layer_factory.hpp:77] Creating layer upsample2
I0824 16:10:45.057011 41289 net.cpp:100] Creating Layer upsample2
I0824 16:10:45.057016 41289 net.cpp:434] upsample2 <- conv3_1_D
I0824 16:10:45.057021 41289 net.cpp:434] upsample2 <- pool2_mask
I0824 16:10:45.057026 41289 net.cpp:408] upsample2 -> pool2_D
I0824 16:10:45.057035 41289 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 16:10:45.057075 41289 net.cpp:150] Setting up upsample2
I0824 16:10:45.057096 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:45.057101 41289 net.cpp:165] Memory required for data: 4078817280
I0824 16:10:45.057104 41289 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 16:10:45.057116 41289 net.cpp:100] Creating Layer conv2_2_D
I0824 16:10:45.057121 41289 net.cpp:434] conv2_2_D <- pool2_D
I0824 16:10:45.057132 41289 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 16:10:45.065054 41289 net.cpp:150] Setting up conv2_2_D
I0824 16:10:45.065070 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:45.065079 41289 net.cpp:165] Memory required for data: 4167290880
I0824 16:10:45.065088 41289 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 16:10:45.065098 41289 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 16:10:45.065104 41289 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 16:10:45.065109 41289 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 16:10:45.065469 41289 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 16:10:45.065479 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:45.065482 41289 net.cpp:165] Memory required for data: 4255764480
I0824 16:10:45.065490 41289 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 16:10:45.065498 41289 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 16:10:45.065508 41289 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 16:10:45.065515 41289 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 16:10:45.065573 41289 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 16:10:45.065832 41289 net.cpp:150] Setting up conv2_2_D_scale
I0824 16:10:45.065840 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:45.065843 41289 net.cpp:165] Memory required for data: 4344238080
I0824 16:10:45.065850 41289 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 16:10:45.065860 41289 net.cpp:100] Creating Layer relu2_2_D
I0824 16:10:45.065865 41289 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 16:10:45.065870 41289 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 16:10:45.066108 41289 net.cpp:150] Setting up relu2_2_D
I0824 16:10:45.066119 41289 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 16:10:45.066124 41289 net.cpp:165] Memory required for data: 4432711680
I0824 16:10:45.066128 41289 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 16:10:45.066140 41289 net.cpp:100] Creating Layer conv2_1_D
I0824 16:10:45.066145 41289 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 16:10:45.066153 41289 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 16:10:45.071647 41289 net.cpp:150] Setting up conv2_1_D
I0824 16:10:45.071663 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:45.071672 41289 net.cpp:165] Memory required for data: 4476948480
I0824 16:10:45.071681 41289 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 16:10:45.071691 41289 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 16:10:45.071696 41289 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 16:10:45.071702 41289 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 16:10:45.072055 41289 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 16:10:45.072064 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:45.072068 41289 net.cpp:165] Memory required for data: 4521185280
I0824 16:10:45.072077 41289 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 16:10:45.072085 41289 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 16:10:45.072094 41289 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 16:10:45.072099 41289 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 16:10:45.072160 41289 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 16:10:45.072438 41289 net.cpp:150] Setting up conv2_1_D_scale
I0824 16:10:45.072446 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:45.072449 41289 net.cpp:165] Memory required for data: 4565422080
I0824 16:10:45.072456 41289 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 16:10:45.072465 41289 net.cpp:100] Creating Layer relu2_1_D
I0824 16:10:45.072470 41289 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 16:10:45.072490 41289 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 16:10:45.072727 41289 net.cpp:150] Setting up relu2_1_D
I0824 16:10:45.072739 41289 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 16:10:45.072744 41289 net.cpp:165] Memory required for data: 4609658880
I0824 16:10:45.072748 41289 layer_factory.hpp:77] Creating layer upsample1
I0824 16:10:45.072755 41289 net.cpp:100] Creating Layer upsample1
I0824 16:10:45.072760 41289 net.cpp:434] upsample1 <- conv2_1_D
I0824 16:10:45.072765 41289 net.cpp:434] upsample1 <- pool1_mask
I0824 16:10:45.072770 41289 net.cpp:408] upsample1 -> pool1_D
I0824 16:10:45.072778 41289 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 16:10:45.072818 41289 net.cpp:150] Setting up upsample1
I0824 16:10:45.072824 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:45.072827 41289 net.cpp:165] Memory required for data: 4786606080
I0824 16:10:45.072831 41289 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 16:10:45.072844 41289 net.cpp:100] Creating Layer conv1_2_D
I0824 16:10:45.072849 41289 net.cpp:434] conv1_2_D <- pool1_D
I0824 16:10:45.072857 41289 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 16:10:45.077595 41289 net.cpp:150] Setting up conv1_2_D
I0824 16:10:45.077611 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:45.077621 41289 net.cpp:165] Memory required for data: 4963553280
I0824 16:10:45.077630 41289 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 16:10:45.077638 41289 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 16:10:45.077644 41289 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 16:10:45.077651 41289 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 16:10:45.078090 41289 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 16:10:45.078099 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:45.078102 41289 net.cpp:165] Memory required for data: 5140500480
I0824 16:10:45.078111 41289 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 16:10:45.078121 41289 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 16:10:45.078126 41289 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 16:10:45.078131 41289 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 16:10:45.078191 41289 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 16:10:45.079957 41289 net.cpp:150] Setting up conv1_2_D_scale
I0824 16:10:45.079972 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:45.079977 41289 net.cpp:165] Memory required for data: 5317447680
I0824 16:10:45.079988 41289 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 16:10:45.079995 41289 net.cpp:100] Creating Layer relu1_2_D
I0824 16:10:45.080001 41289 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 16:10:45.080006 41289 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 16:10:45.080251 41289 net.cpp:150] Setting up relu1_2_D
I0824 16:10:45.080262 41289 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 16:10:45.080267 41289 net.cpp:165] Memory required for data: 5494394880
I0824 16:10:45.080271 41289 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 16:10:45.080283 41289 net.cpp:100] Creating Layer conv1_1_1_D
I0824 16:10:45.080289 41289 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 16:10:45.080296 41289 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 16:10:45.082540 41289 net.cpp:150] Setting up conv1_1_1_D
I0824 16:10:45.082557 41289 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 16:10:45.082562 41289 net.cpp:165] Memory required for data: 5499924480
I0824 16:10:45.082571 41289 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 16:10:45.082579 41289 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 16:10:45.082586 41289 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 16:10:45.082592 41289 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 16:10:45.082600 41289 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 16:10:45.082679 41289 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 16:10:45.082686 41289 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 16:10:45.082691 41289 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 16:10:45.082695 41289 net.cpp:165] Memory required for data: 5510983680
I0824 16:10:45.082700 41289 layer_factory.hpp:77] Creating layer loss
I0824 16:10:45.082711 41289 net.cpp:100] Creating Layer loss
I0824 16:10:45.082716 41289 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 16:10:45.082721 41289 net.cpp:434] loss <- label_data_1_split_0
I0824 16:10:45.082726 41289 net.cpp:408] loss -> loss
I0824 16:10:45.082736 41289 layer_factory.hpp:77] Creating layer loss
I0824 16:10:45.086823 41289 net.cpp:150] Setting up loss
I0824 16:10:45.086840 41289 net.cpp:157] Top shape: (1)
I0824 16:10:45.086849 41289 net.cpp:160]     with loss weight 1
I0824 16:10:45.086863 41289 net.cpp:165] Memory required for data: 5510983684
I0824 16:10:45.086866 41289 layer_factory.hpp:77] Creating layer accuracy
I0824 16:10:45.086874 41289 net.cpp:100] Creating Layer accuracy
I0824 16:10:45.086880 41289 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 16:10:45.086885 41289 net.cpp:434] accuracy <- label_data_1_split_1
I0824 16:10:45.086892 41289 net.cpp:408] accuracy -> accuracy
I0824 16:10:45.086901 41289 net.cpp:408] accuracy -> per_class_accuracy
I0824 16:10:45.086958 41289 net.cpp:150] Setting up accuracy
I0824 16:10:45.086966 41289 net.cpp:157] Top shape: (1)
I0824 16:10:45.086971 41289 net.cpp:157] Top shape: 2 (2)
I0824 16:10:45.086973 41289 net.cpp:165] Memory required for data: 5510983696
I0824 16:10:45.086978 41289 net.cpp:228] accuracy does not need backward computation.
I0824 16:10:45.086982 41289 net.cpp:226] loss needs backward computation.
I0824 16:10:45.086988 41289 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 16:10:45.086992 41289 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 16:10:45.086997 41289 net.cpp:226] relu1_2_D needs backward computation.
I0824 16:10:45.087002 41289 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 16:10:45.087004 41289 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 16:10:45.087007 41289 net.cpp:226] conv1_2_D needs backward computation.
I0824 16:10:45.087010 41289 net.cpp:226] upsample1 needs backward computation.
I0824 16:10:45.087014 41289 net.cpp:226] relu2_1_D needs backward computation.
I0824 16:10:45.087018 41289 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 16:10:45.087021 41289 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 16:10:45.087023 41289 net.cpp:226] conv2_1_D needs backward computation.
I0824 16:10:45.087028 41289 net.cpp:226] relu2_2_D needs backward computation.
I0824 16:10:45.087030 41289 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 16:10:45.087033 41289 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 16:10:45.087036 41289 net.cpp:226] conv2_2_D needs backward computation.
I0824 16:10:45.087040 41289 net.cpp:226] upsample2 needs backward computation.
I0824 16:10:45.087044 41289 net.cpp:226] relu3_1_D needs backward computation.
I0824 16:10:45.087047 41289 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 16:10:45.087050 41289 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 16:10:45.087054 41289 net.cpp:226] conv3_1_D needs backward computation.
I0824 16:10:45.087056 41289 net.cpp:226] relu3_2_D needs backward computation.
I0824 16:10:45.087059 41289 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 16:10:45.087062 41289 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 16:10:45.087065 41289 net.cpp:226] conv3_2_D needs backward computation.
I0824 16:10:45.087069 41289 net.cpp:226] relu3_3_D needs backward computation.
I0824 16:10:45.087072 41289 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 16:10:45.087075 41289 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 16:10:45.087092 41289 net.cpp:226] conv3_3_D needs backward computation.
I0824 16:10:45.087096 41289 net.cpp:226] upsample3 needs backward computation.
I0824 16:10:45.087100 41289 net.cpp:226] relu4_1_D needs backward computation.
I0824 16:10:45.087103 41289 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 16:10:45.087106 41289 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 16:10:45.087110 41289 net.cpp:226] conv4_1_D needs backward computation.
I0824 16:10:45.087112 41289 net.cpp:226] relu4_2_D needs backward computation.
I0824 16:10:45.087116 41289 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 16:10:45.087119 41289 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 16:10:45.087122 41289 net.cpp:226] conv4_2_D needs backward computation.
I0824 16:10:45.087126 41289 net.cpp:226] relu4_3_D needs backward computation.
I0824 16:10:45.087129 41289 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 16:10:45.087132 41289 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 16:10:45.087136 41289 net.cpp:226] conv4_3_D needs backward computation.
I0824 16:10:45.087142 41289 net.cpp:226] upsample4 needs backward computation.
I0824 16:10:45.087147 41289 net.cpp:226] relu5_1_D needs backward computation.
I0824 16:10:45.087152 41289 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 16:10:45.087154 41289 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 16:10:45.087158 41289 net.cpp:226] conv5_1_D needs backward computation.
I0824 16:10:45.087162 41289 net.cpp:226] relu5_2_D needs backward computation.
I0824 16:10:45.087165 41289 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 16:10:45.087170 41289 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 16:10:45.087173 41289 net.cpp:226] conv5_2_D needs backward computation.
I0824 16:10:45.087177 41289 net.cpp:226] relu5_3_D needs backward computation.
I0824 16:10:45.087180 41289 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 16:10:45.087184 41289 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 16:10:45.087188 41289 net.cpp:226] conv5_3_D needs backward computation.
I0824 16:10:45.087191 41289 net.cpp:226] upsample5 needs backward computation.
I0824 16:10:45.087196 41289 net.cpp:226] pool5 needs backward computation.
I0824 16:10:45.087200 41289 net.cpp:226] relu5_3 needs backward computation.
I0824 16:10:45.087205 41289 net.cpp:226] conv5_3_scale needs backward computation.
I0824 16:10:45.087208 41289 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 16:10:45.087213 41289 net.cpp:226] conv5_3 needs backward computation.
I0824 16:10:45.087215 41289 net.cpp:226] relu5_2 needs backward computation.
I0824 16:10:45.087220 41289 net.cpp:226] conv5_2_scale needs backward computation.
I0824 16:10:45.087224 41289 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 16:10:45.087227 41289 net.cpp:226] conv5_2 needs backward computation.
I0824 16:10:45.087231 41289 net.cpp:226] relu5_1 needs backward computation.
I0824 16:10:45.087234 41289 net.cpp:226] conv5_1_scale needs backward computation.
I0824 16:10:45.087240 41289 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 16:10:45.087244 41289 net.cpp:226] conv5_1 needs backward computation.
I0824 16:10:45.087247 41289 net.cpp:226] pool4 needs backward computation.
I0824 16:10:45.087251 41289 net.cpp:226] relu4_3 needs backward computation.
I0824 16:10:45.087255 41289 net.cpp:226] conv4_3_scale needs backward computation.
I0824 16:10:45.087258 41289 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 16:10:45.087262 41289 net.cpp:226] conv4_3 needs backward computation.
I0824 16:10:45.087265 41289 net.cpp:226] relu4_2 needs backward computation.
I0824 16:10:45.087268 41289 net.cpp:226] conv4_2_scale needs backward computation.
I0824 16:10:45.087272 41289 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 16:10:45.087275 41289 net.cpp:226] conv4_2 needs backward computation.
I0824 16:10:45.087280 41289 net.cpp:226] relu4_1 needs backward computation.
I0824 16:10:45.087291 41289 net.cpp:226] conv4_1_scale needs backward computation.
I0824 16:10:45.087294 41289 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 16:10:45.087298 41289 net.cpp:226] conv4_1 needs backward computation.
I0824 16:10:45.087301 41289 net.cpp:226] pool3 needs backward computation.
I0824 16:10:45.087306 41289 net.cpp:226] relu3_3 needs backward computation.
I0824 16:10:45.087311 41289 net.cpp:226] conv3_3_scale needs backward computation.
I0824 16:10:45.087314 41289 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 16:10:45.087317 41289 net.cpp:226] conv3_3 needs backward computation.
I0824 16:10:45.087321 41289 net.cpp:226] relu3_2 needs backward computation.
I0824 16:10:45.087324 41289 net.cpp:226] conv3_2_scale needs backward computation.
I0824 16:10:45.087328 41289 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 16:10:45.087332 41289 net.cpp:226] conv3_2 needs backward computation.
I0824 16:10:45.087335 41289 net.cpp:226] relu3_1 needs backward computation.
I0824 16:10:45.087339 41289 net.cpp:226] conv3_1_scale needs backward computation.
I0824 16:10:45.087342 41289 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 16:10:45.087347 41289 net.cpp:226] conv3_1 needs backward computation.
I0824 16:10:45.087352 41289 net.cpp:226] pool2 needs backward computation.
I0824 16:10:45.087355 41289 net.cpp:226] relu2_2 needs backward computation.
I0824 16:10:45.087358 41289 net.cpp:226] conv2_2_scale needs backward computation.
I0824 16:10:45.087363 41289 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 16:10:45.087365 41289 net.cpp:226] conv2_2 needs backward computation.
I0824 16:10:45.087368 41289 net.cpp:226] relu2_1 needs backward computation.
I0824 16:10:45.087373 41289 net.cpp:226] conv2_1_scale needs backward computation.
I0824 16:10:45.087376 41289 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 16:10:45.087380 41289 net.cpp:226] conv2_1 needs backward computation.
I0824 16:10:45.087384 41289 net.cpp:226] pool1 needs backward computation.
I0824 16:10:45.087388 41289 net.cpp:226] relu1_2 needs backward computation.
I0824 16:10:45.087391 41289 net.cpp:226] conv1_2_scale needs backward computation.
I0824 16:10:45.087395 41289 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 16:10:45.087399 41289 net.cpp:226] conv1_2 needs backward computation.
I0824 16:10:45.087402 41289 net.cpp:226] relu1_1 needs backward computation.
I0824 16:10:45.087407 41289 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 16:10:45.087411 41289 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 16:10:45.087415 41289 net.cpp:226] conv1_1_1 needs backward computation.
I0824 16:10:45.087419 41289 net.cpp:228] label_data_1_split does not need backward computation.
I0824 16:10:45.087425 41289 net.cpp:228] data does not need backward computation.
I0824 16:10:45.087429 41289 net.cpp:270] This network produces output accuracy
I0824 16:10:45.087432 41289 net.cpp:270] This network produces output loss
I0824 16:10:45.087437 41289 net.cpp:270] This network produces output per_class_accuracy
I0824 16:10:45.087502 41289 net.cpp:283] Network initialization done.
I0824 16:10:45.087890 41289 solver.cpp:60] Solver scaffolding done.
I0824 16:10:45.097291 41289 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0824 16:10:45.593490 41289 net.cpp:761] Ignoring source layer conv1_1
I0824 16:10:45.593518 41289 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 16:10:45.593569 41289 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 16:10:45.593576 41289 net.cpp:761] Ignoring source layer pool1_drop
I0824 16:10:45.593653 41289 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 16:10:45.593798 41289 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 16:10:45.593806 41289 net.cpp:761] Ignoring source layer pool2_drop
I0824 16:10:45.594091 41289 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 16:10:45.594718 41289 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 16:10:45.595286 41289 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 16:10:45.595317 41289 net.cpp:761] Ignoring source layer pool3_drop
I0824 16:10:45.596418 41289 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 16:10:45.598704 41289 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 16:10:45.600991 41289 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 16:10:45.600998 41289 net.cpp:761] Ignoring source layer pool4_drop
I0824 16:10:45.603068 41289 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 16:10:45.605337 41289 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 16:10:45.609266 41289 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 16:10:45.609282 41289 net.cpp:761] Ignoring source layer pool5_drop
I0824 16:10:45.609285 41289 net.cpp:761] Ignoring source layer upsample5_drop
I0824 16:10:45.611358 41289 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 16:10:45.613592 41289 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 16:10:45.615712 41289 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 16:10:45.615722 41289 net.cpp:761] Ignoring source layer upsample4_drop
I0824 16:10:45.617800 41289 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 16:10:45.619992 41289 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 16:10:45.621179 41289 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 16:10:45.621187 41289 net.cpp:761] Ignoring source layer upsample3_drop
I0824 16:10:45.621799 41289 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 16:10:45.622443 41289 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 16:10:45.622738 41289 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 16:10:45.622746 41289 net.cpp:761] Ignoring source layer upsample2_drop
I0824 16:10:45.622887 41289 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 16:10:45.622966 41289 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 16:10:45.622972 41289 net.cpp:761] Ignoring source layer upsample1_drop
I0824 16:10:45.623014 41289 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 16:10:45.623021 41289 net.cpp:761] Ignoring source layer conv1_1_D
I0824 16:10:45.623024 41289 net.cpp:761] Ignoring source layer prob
I0824 16:10:45.930662 41289 net.cpp:761] Ignoring source layer conv1_1
I0824 16:10:45.930687 41289 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 16:10:45.930732 41289 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 16:10:45.930739 41289 net.cpp:761] Ignoring source layer pool1_drop
I0824 16:10:45.930816 41289 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 16:10:45.930963 41289 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 16:10:45.930969 41289 net.cpp:761] Ignoring source layer pool2_drop
I0824 16:10:45.931247 41289 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 16:10:45.931843 41289 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 16:10:45.932399 41289 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 16:10:45.932406 41289 net.cpp:761] Ignoring source layer pool3_drop
I0824 16:10:45.933491 41289 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 16:10:45.935943 41289 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 16:10:45.938434 41289 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 16:10:45.938442 41289 net.cpp:761] Ignoring source layer pool4_drop
I0824 16:10:45.940973 41289 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 16:10:45.948019 41289 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 16:10:45.952286 41289 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 16:10:45.952299 41289 net.cpp:761] Ignoring source layer pool5_drop
I0824 16:10:45.952306 41289 net.cpp:761] Ignoring source layer upsample5_drop
I0824 16:10:45.956673 41289 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 16:10:45.960952 41289 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 16:10:45.965235 41289 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 16:10:45.965248 41289 net.cpp:761] Ignoring source layer upsample4_drop
I0824 16:10:45.969352 41289 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 16:10:45.973273 41289 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 16:10:45.975188 41289 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 16:10:45.975199 41289 net.cpp:761] Ignoring source layer upsample3_drop
I0824 16:10:45.976270 41289 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 16:10:45.977196 41289 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 16:10:45.977748 41289 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 16:10:45.977758 41289 net.cpp:761] Ignoring source layer upsample2_drop
I0824 16:10:45.978035 41289 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 16:10:45.978185 41289 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 16:10:45.978193 41289 net.cpp:761] Ignoring source layer upsample1_drop
I0824 16:10:45.978277 41289 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 16:10:45.978286 41289 net.cpp:761] Ignoring source layer conv1_1_D
I0824 16:10:45.978296 41289 net.cpp:761] Ignoring source layer prob
I0824 16:10:45.989861 41289 caffe.cpp:251] Starting Optimization
I0824 16:10:45.989893 41289 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0824 16:10:45.989899 41289 solver.cpp:280] Learning Rate Policy: step
I0824 16:10:46.988276 41289 solver.cpp:228] Iteration 0, loss = 0.939214
I0824 16:10:46.988370 41289 solver.cpp:244]     Train net output #0: accuracy = 0.325408
I0824 16:10:46.988397 41289 solver.cpp:244]     Train net output #1: loss = 0.939214 (* 1 = 0.939214 loss)
I0824 16:10:46.988409 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.246943
I0824 16:10:46.988415 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.747673
I0824 16:10:46.988454 41289 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0824 16:11:03.335821 41289 solver.cpp:228] Iteration 20, loss = 0.65426
I0824 16:11:03.335875 41289 solver.cpp:244]     Train net output #0: accuracy = 0.716631
I0824 16:11:03.335886 41289 solver.cpp:244]     Train net output #1: loss = 0.65426 (* 1 = 0.65426 loss)
I0824 16:11:03.335893 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.760914
I0824 16:11:03.335898 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.661121
I0824 16:11:03.335906 41289 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0824 16:11:20.032409 41289 solver.cpp:228] Iteration 40, loss = 0.352773
I0824 16:11:20.032567 41289 solver.cpp:244]     Train net output #0: accuracy = 0.845084
I0824 16:11:20.032582 41289 solver.cpp:244]     Train net output #1: loss = 0.352773 (* 1 = 0.352773 loss)
I0824 16:11:20.032588 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.802227
I0824 16:11:20.032593 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.926716
I0824 16:11:20.032599 41289 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0824 16:11:36.679155 41289 solver.cpp:228] Iteration 60, loss = 0.315695
I0824 16:11:36.679204 41289 solver.cpp:244]     Train net output #0: accuracy = 0.835097
I0824 16:11:36.679216 41289 solver.cpp:244]     Train net output #1: loss = 0.315695 (* 1 = 0.315695 loss)
I0824 16:11:36.679222 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.782019
I0824 16:11:36.679226 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99026
I0824 16:11:36.679234 41289 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0824 16:11:53.337605 41289 solver.cpp:228] Iteration 80, loss = 0.578419
I0824 16:11:53.337770 41289 solver.cpp:244]     Train net output #0: accuracy = 0.772146
I0824 16:11:53.337785 41289 solver.cpp:244]     Train net output #1: loss = 0.578419 (* 1 = 0.578419 loss)
I0824 16:11:53.337793 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.873559
I0824 16:11:53.337798 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.680879
I0824 16:11:53.337805 41289 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0824 16:12:10.022972 41289 solver.cpp:228] Iteration 100, loss = 0.267894
I0824 16:12:10.023020 41289 solver.cpp:244]     Train net output #0: accuracy = 0.869019
I0824 16:12:10.023033 41289 solver.cpp:244]     Train net output #1: loss = 0.267894 (* 1 = 0.267894 loss)
I0824 16:12:10.023041 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.83677
I0824 16:12:10.023046 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.969758
I0824 16:12:10.023056 41289 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0824 16:12:26.685847 41289 solver.cpp:228] Iteration 120, loss = 0.258742
I0824 16:12:26.686022 41289 solver.cpp:244]     Train net output #0: accuracy = 0.902186
I0824 16:12:26.686043 41289 solver.cpp:244]     Train net output #1: loss = 0.258742 (* 1 = 0.258742 loss)
I0824 16:12:26.686049 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.883376
I0824 16:12:26.686054 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.932157
I0824 16:12:26.686064 41289 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0824 16:12:43.332661 41289 solver.cpp:228] Iteration 140, loss = 0.30603
I0824 16:12:43.332708 41289 solver.cpp:244]     Train net output #0: accuracy = 0.872067
I0824 16:12:43.332722 41289 solver.cpp:244]     Train net output #1: loss = 0.30603 (* 1 = 0.30603 loss)
I0824 16:12:43.332728 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.842831
I0824 16:12:43.332733 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.963201
I0824 16:12:43.332741 41289 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0824 16:12:59.978895 41289 solver.cpp:228] Iteration 160, loss = 0.313452
I0824 16:12:59.979012 41289 solver.cpp:244]     Train net output #0: accuracy = 0.905464
I0824 16:12:59.979025 41289 solver.cpp:244]     Train net output #1: loss = 0.313452 (* 1 = 0.313452 loss)
I0824 16:12:59.979032 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.955622
I0824 16:12:59.979035 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.843475
I0824 16:12:59.979043 41289 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0824 16:13:16.618652 41289 solver.cpp:228] Iteration 180, loss = 0.206415
I0824 16:13:16.618698 41289 solver.cpp:244]     Train net output #0: accuracy = 0.914361
I0824 16:13:16.618710 41289 solver.cpp:244]     Train net output #1: loss = 0.206415 (* 1 = 0.206415 loss)
I0824 16:13:16.618716 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.932234
I0824 16:13:16.618721 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.884672
I0824 16:13:16.618727 41289 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0824 16:13:33.255345 41289 solver.cpp:228] Iteration 200, loss = 0.227793
I0824 16:13:33.255448 41289 solver.cpp:244]     Train net output #0: accuracy = 0.919521
I0824 16:13:33.255461 41289 solver.cpp:244]     Train net output #1: loss = 0.227793 (* 1 = 0.227793 loss)
I0824 16:13:33.255467 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.955947
I0824 16:13:33.255471 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.853867
I0824 16:13:33.255480 41289 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0824 16:13:49.904960 41289 solver.cpp:228] Iteration 220, loss = 0.201918
I0824 16:13:49.905005 41289 solver.cpp:244]     Train net output #0: accuracy = 0.887698
I0824 16:13:49.905019 41289 solver.cpp:244]     Train net output #1: loss = 0.201918 (* 1 = 0.201918 loss)
I0824 16:13:49.905026 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.856224
I0824 16:13:49.905031 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986719
I0824 16:13:49.905038 41289 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0824 16:14:06.564122 41289 solver.cpp:228] Iteration 240, loss = 0.164124
I0824 16:14:06.564249 41289 solver.cpp:244]     Train net output #0: accuracy = 0.930621
I0824 16:14:06.564266 41289 solver.cpp:244]     Train net output #1: loss = 0.164124 (* 1 = 0.164124 loss)
I0824 16:14:06.564273 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.913269
I0824 16:14:06.564278 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.964148
I0824 16:14:06.564286 41289 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0824 16:14:23.234108 41289 solver.cpp:228] Iteration 260, loss = 0.290404
I0824 16:14:23.234156 41289 solver.cpp:244]     Train net output #0: accuracy = 0.850328
I0824 16:14:23.234170 41289 solver.cpp:244]     Train net output #1: loss = 0.290404 (* 1 = 0.290404 loss)
I0824 16:14:23.234176 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.826254
I0824 16:14:23.234182 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981266
I0824 16:14:23.234191 41289 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0824 16:14:39.926877 41289 solver.cpp:228] Iteration 280, loss = 0.201847
I0824 16:14:39.927065 41289 solver.cpp:244]     Train net output #0: accuracy = 0.928686
I0824 16:14:39.927084 41289 solver.cpp:244]     Train net output #1: loss = 0.201847 (* 1 = 0.201847 loss)
I0824 16:14:39.927093 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.951465
I0824 16:14:39.927098 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.898111
I0824 16:14:39.927106 41289 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0824 16:14:56.588765 41289 solver.cpp:228] Iteration 300, loss = 0.0929396
I0824 16:14:56.588814 41289 solver.cpp:244]     Train net output #0: accuracy = 0.960166
I0824 16:14:56.588829 41289 solver.cpp:244]     Train net output #1: loss = 0.0929396 (* 1 = 0.0929396 loss)
I0824 16:14:56.588835 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.949744
I0824 16:14:56.588840 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985121
I0824 16:14:56.588848 41289 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0824 16:15:13.254786 41289 solver.cpp:228] Iteration 320, loss = 0.116798
I0824 16:15:13.254921 41289 solver.cpp:244]     Train net output #0: accuracy = 0.962914
I0824 16:15:13.254946 41289 solver.cpp:244]     Train net output #1: loss = 0.116798 (* 1 = 0.116798 loss)
I0824 16:15:13.254953 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.965402
I0824 16:15:13.254959 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.958942
I0824 16:15:13.254967 41289 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0824 16:15:29.926446 41289 solver.cpp:228] Iteration 340, loss = 0.103948
I0824 16:15:29.926499 41289 solver.cpp:244]     Train net output #0: accuracy = 0.967075
I0824 16:15:29.926514 41289 solver.cpp:244]     Train net output #1: loss = 0.103948 (* 1 = 0.103948 loss)
I0824 16:15:29.926520 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.956003
I0824 16:15:29.926527 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981329
I0824 16:15:29.926534 41289 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0824 16:15:46.587307 41289 solver.cpp:228] Iteration 360, loss = 0.0891835
I0824 16:15:46.587424 41289 solver.cpp:244]     Train net output #0: accuracy = 0.96839
I0824 16:15:46.587438 41289 solver.cpp:244]     Train net output #1: loss = 0.0891835 (* 1 = 0.0891835 loss)
I0824 16:15:46.587443 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.959188
I0824 16:15:46.587448 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982619
I0824 16:15:46.587456 41289 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0824 16:16:03.265513 41289 solver.cpp:228] Iteration 380, loss = 0.11026
I0824 16:16:03.265559 41289 solver.cpp:244]     Train net output #0: accuracy = 0.963992
I0824 16:16:03.265573 41289 solver.cpp:244]     Train net output #1: loss = 0.11026 (* 1 = 0.11026 loss)
I0824 16:16:03.265580 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.965265
I0824 16:16:03.265585 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.962007
I0824 16:16:03.265592 41289 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0824 16:16:19.932778 41289 solver.cpp:228] Iteration 400, loss = 0.0822261
I0824 16:16:19.932895 41289 solver.cpp:244]     Train net output #0: accuracy = 0.968014
I0824 16:16:19.932910 41289 solver.cpp:244]     Train net output #1: loss = 0.0822261 (* 1 = 0.0822261 loss)
I0824 16:16:19.932926 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.961881
I0824 16:16:19.932931 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979714
I0824 16:16:19.932940 41289 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0824 16:16:36.599639 41289 solver.cpp:228] Iteration 420, loss = 0.0725233
I0824 16:16:36.599676 41289 solver.cpp:244]     Train net output #0: accuracy = 0.973135
I0824 16:16:36.599687 41289 solver.cpp:244]     Train net output #1: loss = 0.0725233 (* 1 = 0.0725233 loss)
I0824 16:16:36.599694 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.971163
I0824 16:16:36.599697 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.977743
I0824 16:16:36.599705 41289 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0824 16:16:53.268316 41289 solver.cpp:228] Iteration 440, loss = 0.133681
I0824 16:16:53.268496 41289 solver.cpp:244]     Train net output #0: accuracy = 0.955101
I0824 16:16:53.268515 41289 solver.cpp:244]     Train net output #1: loss = 0.133681 (* 1 = 0.133681 loss)
I0824 16:16:53.268523 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983064
I0824 16:16:53.268528 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.894626
I0824 16:16:53.268537 41289 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0824 16:17:09.948282 41289 solver.cpp:228] Iteration 460, loss = 0.166756
I0824 16:17:09.948326 41289 solver.cpp:244]     Train net output #0: accuracy = 0.928519
I0824 16:17:09.948339 41289 solver.cpp:244]     Train net output #1: loss = 0.166756 (* 1 = 0.166756 loss)
I0824 16:17:09.948345 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.918385
I0824 16:17:09.948350 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.949875
I0824 16:17:09.948357 41289 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0824 16:17:26.604490 41289 solver.cpp:228] Iteration 480, loss = 0.100984
I0824 16:17:26.604604 41289 solver.cpp:244]     Train net output #0: accuracy = 0.967483
I0824 16:17:26.604629 41289 solver.cpp:244]     Train net output #1: loss = 0.100984 (* 1 = 0.100984 loss)
I0824 16:17:26.604636 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988674
I0824 16:17:26.604641 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.929733
I0824 16:17:26.604648 41289 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0824 16:17:43.263695 41289 solver.cpp:228] Iteration 500, loss = 0.0637397
I0824 16:17:43.263736 41289 solver.cpp:244]     Train net output #0: accuracy = 0.978319
I0824 16:17:43.263749 41289 solver.cpp:244]     Train net output #1: loss = 0.0637398 (* 1 = 0.0637398 loss)
I0824 16:17:43.263756 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975121
I0824 16:17:43.263761 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984721
I0824 16:17:43.263768 41289 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0824 16:17:59.917526 41289 solver.cpp:228] Iteration 520, loss = 0.0729744
I0824 16:17:59.917639 41289 solver.cpp:244]     Train net output #0: accuracy = 0.971946
I0824 16:17:59.917655 41289 solver.cpp:244]     Train net output #1: loss = 0.0729744 (* 1 = 0.0729744 loss)
I0824 16:17:59.917668 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.964606
I0824 16:17:59.917680 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988995
I0824 16:17:59.917690 41289 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0824 16:18:16.567896 41289 solver.cpp:228] Iteration 540, loss = 0.0737315
I0824 16:18:16.567936 41289 solver.cpp:244]     Train net output #0: accuracy = 0.965684
I0824 16:18:16.567950 41289 solver.cpp:244]     Train net output #1: loss = 0.0737316 (* 1 = 0.0737316 loss)
I0824 16:18:16.567956 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.953437
I0824 16:18:16.567962 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991494
I0824 16:18:16.567970 41289 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0824 16:18:33.215414 41289 solver.cpp:228] Iteration 560, loss = 0.108097
I0824 16:18:33.215584 41289 solver.cpp:244]     Train net output #0: accuracy = 0.964553
I0824 16:18:33.215605 41289 solver.cpp:244]     Train net output #1: loss = 0.108098 (* 1 = 0.108098 loss)
I0824 16:18:33.215612 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973156
I0824 16:18:33.215617 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.949945
I0824 16:18:33.215625 41289 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0824 16:18:49.880448 41289 solver.cpp:228] Iteration 580, loss = 0.0668863
I0824 16:18:49.880494 41289 solver.cpp:244]     Train net output #0: accuracy = 0.96963
I0824 16:18:49.880507 41289 solver.cpp:244]     Train net output #1: loss = 0.0668864 (* 1 = 0.0668864 loss)
I0824 16:18:49.880513 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.957596
I0824 16:18:49.880518 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990557
I0824 16:18:49.880527 41289 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0824 16:19:06.540596 41289 solver.cpp:228] Iteration 600, loss = 0.070399
I0824 16:19:06.540696 41289 solver.cpp:244]     Train net output #0: accuracy = 0.974317
I0824 16:19:06.540711 41289 solver.cpp:244]     Train net output #1: loss = 0.0703991 (* 1 = 0.0703991 loss)
I0824 16:19:06.540717 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979879
I0824 16:19:06.540722 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.962456
I0824 16:19:06.540729 41289 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0824 16:19:23.201834 41289 solver.cpp:228] Iteration 620, loss = 0.0906778
I0824 16:19:23.201880 41289 solver.cpp:244]     Train net output #0: accuracy = 0.960764
I0824 16:19:23.201894 41289 solver.cpp:244]     Train net output #1: loss = 0.090678 (* 1 = 0.090678 loss)
I0824 16:19:23.201907 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.952052
I0824 16:19:23.201917 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981109
I0824 16:19:23.201925 41289 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0824 16:19:39.866766 41289 solver.cpp:228] Iteration 640, loss = 0.0580095
I0824 16:19:39.866874 41289 solver.cpp:244]     Train net output #0: accuracy = 0.980045
I0824 16:19:39.866890 41289 solver.cpp:244]     Train net output #1: loss = 0.0580096 (* 1 = 0.0580096 loss)
I0824 16:19:39.866904 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982607
I0824 16:19:39.866909 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.970338
I0824 16:19:39.866917 41289 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0824 16:19:56.533448 41289 solver.cpp:228] Iteration 660, loss = 0.0595362
I0824 16:19:56.533484 41289 solver.cpp:244]     Train net output #0: accuracy = 0.973161
I0824 16:19:56.533499 41289 solver.cpp:244]     Train net output #1: loss = 0.0595363 (* 1 = 0.0595363 loss)
I0824 16:19:56.533509 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.966995
I0824 16:19:56.533514 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990781
I0824 16:19:56.533521 41289 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0824 16:20:13.220980 41289 solver.cpp:228] Iteration 680, loss = 0.0475273
I0824 16:20:13.221117 41289 solver.cpp:244]     Train net output #0: accuracy = 0.981824
I0824 16:20:13.221151 41289 solver.cpp:244]     Train net output #1: loss = 0.0475274 (* 1 = 0.0475274 loss)
I0824 16:20:13.221160 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978878
I0824 16:20:13.221171 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986966
I0824 16:20:13.221179 41289 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0824 16:20:29.897639 41289 solver.cpp:228] Iteration 700, loss = 0.0400191
I0824 16:20:29.897692 41289 solver.cpp:244]     Train net output #0: accuracy = 0.983782
I0824 16:20:29.897708 41289 solver.cpp:244]     Train net output #1: loss = 0.0400192 (* 1 = 0.0400192 loss)
I0824 16:20:29.897716 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980192
I0824 16:20:29.897722 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990215
I0824 16:20:29.897732 41289 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0824 16:20:46.549326 41289 solver.cpp:228] Iteration 720, loss = 0.0530717
I0824 16:20:46.549486 41289 solver.cpp:244]     Train net output #0: accuracy = 0.977841
I0824 16:20:46.549510 41289 solver.cpp:244]     Train net output #1: loss = 0.0530718 (* 1 = 0.0530718 loss)
I0824 16:20:46.549518 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97564
I0824 16:20:46.549530 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984042
I0824 16:20:46.549546 41289 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0824 16:21:03.215239 41289 solver.cpp:228] Iteration 740, loss = 0.0555619
I0824 16:21:03.215289 41289 solver.cpp:244]     Train net output #0: accuracy = 0.979751
I0824 16:21:03.215304 41289 solver.cpp:244]     Train net output #1: loss = 0.055562 (* 1 = 0.055562 loss)
I0824 16:21:03.215318 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.976308
I0824 16:21:03.215324 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984534
I0824 16:21:03.215332 41289 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0824 16:21:19.889998 41289 solver.cpp:228] Iteration 760, loss = 0.0543979
I0824 16:21:19.890108 41289 solver.cpp:244]     Train net output #0: accuracy = 0.977153
I0824 16:21:19.890133 41289 solver.cpp:244]     Train net output #1: loss = 0.054398 (* 1 = 0.054398 loss)
I0824 16:21:19.890142 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972226
I0824 16:21:19.890152 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988923
I0824 16:21:19.890161 41289 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0824 16:21:36.541690 41289 solver.cpp:228] Iteration 780, loss = 0.0702304
I0824 16:21:36.541743 41289 solver.cpp:244]     Train net output #0: accuracy = 0.968903
I0824 16:21:36.541757 41289 solver.cpp:244]     Train net output #1: loss = 0.0702305 (* 1 = 0.0702305 loss)
I0824 16:21:36.541764 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.953981
I0824 16:21:36.541775 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994751
I0824 16:21:36.541785 41289 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0824 16:21:53.204509 41289 solver.cpp:228] Iteration 800, loss = 0.0595254
I0824 16:21:53.204617 41289 solver.cpp:244]     Train net output #0: accuracy = 0.978348
I0824 16:21:53.204632 41289 solver.cpp:244]     Train net output #1: loss = 0.0595255 (* 1 = 0.0595255 loss)
I0824 16:21:53.204640 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977379
I0824 16:21:53.204645 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.97984
I0824 16:21:53.204653 41289 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0824 16:22:09.871536 41289 solver.cpp:228] Iteration 820, loss = 0.0463629
I0824 16:22:09.871585 41289 solver.cpp:244]     Train net output #0: accuracy = 0.98542
I0824 16:22:09.871599 41289 solver.cpp:244]     Train net output #1: loss = 0.046363 (* 1 = 0.046363 loss)
I0824 16:22:09.871606 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994081
I0824 16:22:09.871613 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.957101
I0824 16:22:09.871620 41289 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0824 16:22:26.523237 41289 solver.cpp:228] Iteration 840, loss = 0.0568188
I0824 16:22:26.523406 41289 solver.cpp:244]     Train net output #0: accuracy = 0.979831
I0824 16:22:26.523444 41289 solver.cpp:244]     Train net output #1: loss = 0.056819 (* 1 = 0.056819 loss)
I0824 16:22:26.523454 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980327
I0824 16:22:26.523464 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978928
I0824 16:22:26.523473 41289 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0824 16:22:43.250788 41289 solver.cpp:228] Iteration 860, loss = 0.046233
I0824 16:22:43.250838 41289 solver.cpp:244]     Train net output #0: accuracy = 0.979278
I0824 16:22:43.250867 41289 solver.cpp:244]     Train net output #1: loss = 0.0462331 (* 1 = 0.0462331 loss)
I0824 16:22:43.250879 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.970145
I0824 16:22:43.250890 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993523
I0824 16:22:43.250900 41289 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0824 16:22:59.977134 41289 solver.cpp:228] Iteration 880, loss = 0.0489454
I0824 16:22:59.977283 41289 solver.cpp:244]     Train net output #0: accuracy = 0.98111
I0824 16:22:59.977308 41289 solver.cpp:244]     Train net output #1: loss = 0.0489456 (* 1 = 0.0489456 loss)
I0824 16:22:59.977321 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982051
I0824 16:22:59.977331 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978303
I0824 16:22:59.977339 41289 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0824 16:23:16.708663 41289 solver.cpp:228] Iteration 900, loss = 0.0330191
I0824 16:23:16.708739 41289 solver.cpp:244]     Train net output #0: accuracy = 0.987542
I0824 16:23:16.708758 41289 solver.cpp:244]     Train net output #1: loss = 0.0330193 (* 1 = 0.0330193 loss)
I0824 16:23:16.708772 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986776
I0824 16:23:16.708784 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989844
I0824 16:23:16.708809 41289 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0824 16:23:33.425763 41289 solver.cpp:228] Iteration 920, loss = 0.0585309
I0824 16:23:33.425881 41289 solver.cpp:244]     Train net output #0: accuracy = 0.978614
I0824 16:23:33.425912 41289 solver.cpp:244]     Train net output #1: loss = 0.0585311 (* 1 = 0.0585311 loss)
I0824 16:23:33.425920 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979661
I0824 16:23:33.425926 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.975669
I0824 16:23:33.425933 41289 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0824 16:23:50.096379 41289 solver.cpp:228] Iteration 940, loss = 0.0358045
I0824 16:23:50.096428 41289 solver.cpp:244]     Train net output #0: accuracy = 0.988472
I0824 16:23:50.096444 41289 solver.cpp:244]     Train net output #1: loss = 0.0358047 (* 1 = 0.0358047 loss)
I0824 16:23:50.096451 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992931
I0824 16:23:50.096457 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976998
I0824 16:23:50.096468 41289 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0824 16:24:06.747963 41289 solver.cpp:228] Iteration 960, loss = 0.0439978
I0824 16:24:06.748109 41289 solver.cpp:244]     Train net output #0: accuracy = 0.983385
I0824 16:24:06.748149 41289 solver.cpp:244]     Train net output #1: loss = 0.043998 (* 1 = 0.043998 loss)
I0824 16:24:06.748158 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984577
I0824 16:24:06.748169 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98035
I0824 16:24:06.748178 41289 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0824 16:24:23.475844 41289 solver.cpp:228] Iteration 980, loss = 0.0342946
I0824 16:24:23.475930 41289 solver.cpp:244]     Train net output #0: accuracy = 0.986223
I0824 16:24:23.475951 41289 solver.cpp:244]     Train net output #1: loss = 0.0342948 (* 1 = 0.0342948 loss)
I0824 16:24:23.475965 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982754
I0824 16:24:23.475978 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991502
I0824 16:24:23.475994 41289 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0824 16:24:40.175678 41289 solver.cpp:228] Iteration 1000, loss = 0.0533068
I0824 16:24:40.175832 41289 solver.cpp:244]     Train net output #0: accuracy = 0.978426
I0824 16:24:40.175851 41289 solver.cpp:244]     Train net output #1: loss = 0.053307 (* 1 = 0.053307 loss)
I0824 16:24:40.175864 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975093
I0824 16:24:40.175876 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988765
I0824 16:24:40.175889 41289 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0824 16:24:56.898042 41289 solver.cpp:228] Iteration 1020, loss = 0.0386379
I0824 16:24:56.898130 41289 solver.cpp:244]     Train net output #0: accuracy = 0.983736
I0824 16:24:56.898151 41289 solver.cpp:244]     Train net output #1: loss = 0.038638 (* 1 = 0.038638 loss)
I0824 16:24:56.898161 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981616
I0824 16:24:56.898172 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988087
I0824 16:24:56.898182 41289 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0824 16:25:13.628413 41289 solver.cpp:228] Iteration 1040, loss = 0.0461308
I0824 16:25:13.628593 41289 solver.cpp:244]     Train net output #0: accuracy = 0.982831
I0824 16:25:13.628614 41289 solver.cpp:244]     Train net output #1: loss = 0.0461309 (* 1 = 0.0461309 loss)
I0824 16:25:13.628629 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980955
I0824 16:25:13.628643 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986154
I0824 16:25:13.628651 41289 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0824 16:25:30.360961 41289 solver.cpp:228] Iteration 1060, loss = 0.0383755
I0824 16:25:30.361017 41289 solver.cpp:244]     Train net output #0: accuracy = 0.983665
I0824 16:25:30.361033 41289 solver.cpp:244]     Train net output #1: loss = 0.0383756 (* 1 = 0.0383756 loss)
I0824 16:25:30.361042 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979055
I0824 16:25:30.361048 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993241
I0824 16:25:30.361059 41289 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0824 16:25:47.090334 41289 solver.cpp:228] Iteration 1080, loss = 0.0446982
I0824 16:25:47.090462 41289 solver.cpp:244]     Train net output #0: accuracy = 0.985224
I0824 16:25:47.090478 41289 solver.cpp:244]     Train net output #1: loss = 0.0446984 (* 1 = 0.0446984 loss)
I0824 16:25:47.090487 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988428
I0824 16:25:47.090497 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980423
I0824 16:25:47.090505 41289 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0824 16:26:03.819033 41289 solver.cpp:228] Iteration 1100, loss = 0.0388704
I0824 16:26:03.819089 41289 solver.cpp:244]     Train net output #0: accuracy = 0.988727
I0824 16:26:03.819104 41289 solver.cpp:244]     Train net output #1: loss = 0.0388705 (* 1 = 0.0388705 loss)
I0824 16:26:03.819110 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986207
I0824 16:26:03.819116 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991494
I0824 16:26:03.819123 41289 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0824 16:26:20.519675 41289 solver.cpp:228] Iteration 1120, loss = 0.0235653
I0824 16:26:20.519810 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992108
I0824 16:26:20.519826 41289 solver.cpp:244]     Train net output #1: loss = 0.0235654 (* 1 = 0.0235654 loss)
I0824 16:26:20.519832 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993631
I0824 16:26:20.519837 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988503
I0824 16:26:20.519845 41289 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0824 16:26:37.193831 41289 solver.cpp:228] Iteration 1140, loss = 0.0297989
I0824 16:26:37.193919 41289 solver.cpp:244]     Train net output #0: accuracy = 0.988556
I0824 16:26:37.193941 41289 solver.cpp:244]     Train net output #1: loss = 0.029799 (* 1 = 0.029799 loss)
I0824 16:26:37.193953 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98869
I0824 16:26:37.193970 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988173
I0824 16:26:37.193982 41289 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0824 16:26:53.838861 41289 solver.cpp:228] Iteration 1160, loss = 0.0286152
I0824 16:26:53.839059 41289 solver.cpp:244]     Train net output #0: accuracy = 0.990247
I0824 16:26:53.839077 41289 solver.cpp:244]     Train net output #1: loss = 0.0286154 (* 1 = 0.0286154 loss)
I0824 16:26:53.839089 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99282
I0824 16:26:53.839099 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983342
I0824 16:26:53.839110 41289 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0824 16:27:10.503815 41289 solver.cpp:228] Iteration 1180, loss = 0.0312959
I0824 16:27:10.503865 41289 solver.cpp:244]     Train net output #0: accuracy = 0.987948
I0824 16:27:10.503880 41289 solver.cpp:244]     Train net output #1: loss = 0.031296 (* 1 = 0.031296 loss)
I0824 16:27:10.503886 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988912
I0824 16:27:10.503893 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986136
I0824 16:27:10.503901 41289 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0824 16:27:27.151262 41289 solver.cpp:228] Iteration 1200, loss = 0.0275664
I0824 16:27:27.151372 41289 solver.cpp:244]     Train net output #0: accuracy = 0.989495
I0824 16:27:27.151388 41289 solver.cpp:244]     Train net output #1: loss = 0.0275665 (* 1 = 0.0275665 loss)
I0824 16:27:27.151396 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988093
I0824 16:27:27.151401 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991552
I0824 16:27:27.151408 41289 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0824 16:27:43.819243 41289 solver.cpp:228] Iteration 1220, loss = 0.0228586
I0824 16:27:43.819288 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991952
I0824 16:27:43.819303 41289 solver.cpp:244]     Train net output #1: loss = 0.0228587 (* 1 = 0.0228587 loss)
I0824 16:27:43.819315 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991561
I0824 16:27:43.819320 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992562
I0824 16:27:43.819329 41289 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0824 16:28:00.474987 41289 solver.cpp:228] Iteration 1240, loss = 0.0230529
I0824 16:28:00.475101 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991149
I0824 16:28:00.475131 41289 solver.cpp:244]     Train net output #1: loss = 0.023053 (* 1 = 0.023053 loss)
I0824 16:28:00.475139 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991034
I0824 16:28:00.475144 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991404
I0824 16:28:00.475152 41289 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0824 16:28:17.134009 41289 solver.cpp:228] Iteration 1260, loss = 0.0366698
I0824 16:28:17.134058 41289 solver.cpp:244]     Train net output #0: accuracy = 0.986713
I0824 16:28:17.134073 41289 solver.cpp:244]     Train net output #1: loss = 0.03667 (* 1 = 0.03667 loss)
I0824 16:28:17.134084 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983647
I0824 16:28:17.134089 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990433
I0824 16:28:17.134097 41289 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0824 16:28:33.807188 41289 solver.cpp:228] Iteration 1280, loss = 0.0208137
I0824 16:28:33.807334 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991853
I0824 16:28:33.807363 41289 solver.cpp:244]     Train net output #1: loss = 0.0208138 (* 1 = 0.0208138 loss)
I0824 16:28:33.807374 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991002
I0824 16:28:33.807379 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993383
I0824 16:28:33.807387 41289 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0824 16:28:50.458739 41289 solver.cpp:228] Iteration 1300, loss = 0.0387914
I0824 16:28:50.458784 41289 solver.cpp:244]     Train net output #0: accuracy = 0.984016
I0824 16:28:50.458798 41289 solver.cpp:244]     Train net output #1: loss = 0.0387915 (* 1 = 0.0387915 loss)
I0824 16:28:50.458806 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978495
I0824 16:28:50.458811 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990976
I0824 16:28:50.458819 41289 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0824 16:29:07.119854 41289 solver.cpp:228] Iteration 1320, loss = 0.0251598
I0824 16:29:07.120016 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991253
I0824 16:29:07.120033 41289 solver.cpp:244]     Train net output #1: loss = 0.0251599 (* 1 = 0.0251599 loss)
I0824 16:29:07.120043 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99182
I0824 16:29:07.120048 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989779
I0824 16:29:07.120056 41289 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0824 16:29:23.791575 41289 solver.cpp:228] Iteration 1340, loss = 0.0289424
I0824 16:29:23.791615 41289 solver.cpp:244]     Train net output #0: accuracy = 0.989774
I0824 16:29:23.791628 41289 solver.cpp:244]     Train net output #1: loss = 0.0289425 (* 1 = 0.0289425 loss)
I0824 16:29:23.791635 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992005
I0824 16:29:23.791640 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984471
I0824 16:29:23.791648 41289 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0824 16:29:40.458915 41289 solver.cpp:228] Iteration 1360, loss = 0.0271531
I0824 16:29:40.459033 41289 solver.cpp:244]     Train net output #0: accuracy = 0.990745
I0824 16:29:40.459049 41289 solver.cpp:244]     Train net output #1: loss = 0.0271533 (* 1 = 0.0271533 loss)
I0824 16:29:40.459062 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990689
I0824 16:29:40.459067 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990988
I0824 16:29:40.459074 41289 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0824 16:29:57.121628 41289 solver.cpp:228] Iteration 1380, loss = 0.028879
I0824 16:29:57.121670 41289 solver.cpp:244]     Train net output #0: accuracy = 0.987935
I0824 16:29:57.121682 41289 solver.cpp:244]     Train net output #1: loss = 0.0288791 (* 1 = 0.0288791 loss)
I0824 16:29:57.121688 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986768
I0824 16:29:57.121695 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990063
I0824 16:29:57.121701 41289 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0824 16:30:13.835244 41289 solver.cpp:228] Iteration 1400, loss = 0.0286115
I0824 16:30:13.835376 41289 solver.cpp:244]     Train net output #0: accuracy = 0.990164
I0824 16:30:13.835409 41289 solver.cpp:244]     Train net output #1: loss = 0.0286117 (* 1 = 0.0286117 loss)
I0824 16:30:13.835417 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990887
I0824 16:30:13.835429 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988952
I0824 16:30:13.835435 41289 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0824 16:30:30.524541 41289 solver.cpp:228] Iteration 1420, loss = 0.0330491
I0824 16:30:30.524591 41289 solver.cpp:244]     Train net output #0: accuracy = 0.990977
I0824 16:30:30.524607 41289 solver.cpp:244]     Train net output #1: loss = 0.0330492 (* 1 = 0.0330492 loss)
I0824 16:30:30.524616 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993061
I0824 16:30:30.524621 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988911
I0824 16:30:30.524631 41289 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0824 16:30:47.258065 41289 solver.cpp:228] Iteration 1440, loss = 0.0230964
I0824 16:30:47.258191 41289 solver.cpp:244]     Train net output #0: accuracy = 0.990799
I0824 16:30:47.258209 41289 solver.cpp:244]     Train net output #1: loss = 0.0230965 (* 1 = 0.0230965 loss)
I0824 16:30:47.258219 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99026
I0824 16:30:47.258224 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99183
I0824 16:30:47.258235 41289 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0824 16:31:03.939900 41289 solver.cpp:228] Iteration 1460, loss = 0.0309283
I0824 16:31:03.939955 41289 solver.cpp:244]     Train net output #0: accuracy = 0.988539
I0824 16:31:03.939970 41289 solver.cpp:244]     Train net output #1: loss = 0.0309284 (* 1 = 0.0309284 loss)
I0824 16:31:03.939978 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98888
I0824 16:31:03.939985 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987591
I0824 16:31:03.939996 41289 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0824 16:31:20.612977 41289 solver.cpp:228] Iteration 1480, loss = 0.0231251
I0824 16:31:20.613157 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994139
I0824 16:31:20.613181 41289 solver.cpp:244]     Train net output #1: loss = 0.0231253 (* 1 = 0.0231253 loss)
I0824 16:31:20.613190 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996291
I0824 16:31:20.613203 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982826
I0824 16:31:20.613210 41289 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0824 16:31:37.280547 41289 solver.cpp:228] Iteration 1500, loss = 0.0280499
I0824 16:31:37.280598 41289 solver.cpp:244]     Train net output #0: accuracy = 0.9885
I0824 16:31:37.280614 41289 solver.cpp:244]     Train net output #1: loss = 0.0280501 (* 1 = 0.0280501 loss)
I0824 16:31:37.280625 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983835
I0824 16:31:37.280638 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99451
I0824 16:31:37.280647 41289 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0824 16:31:53.955602 41289 solver.cpp:228] Iteration 1520, loss = 0.0183412
I0824 16:31:53.955751 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992368
I0824 16:31:53.955793 41289 solver.cpp:244]     Train net output #1: loss = 0.0183413 (* 1 = 0.0183413 loss)
I0824 16:31:53.955802 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989811
I0824 16:31:53.955813 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996061
I0824 16:31:53.955824 41289 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0824 16:32:10.648670 41289 solver.cpp:228] Iteration 1540, loss = 0.026849
I0824 16:32:10.648725 41289 solver.cpp:244]     Train net output #0: accuracy = 0.989795
I0824 16:32:10.648741 41289 solver.cpp:244]     Train net output #1: loss = 0.0268492 (* 1 = 0.0268492 loss)
I0824 16:32:10.648748 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988461
I0824 16:32:10.648754 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991663
I0824 16:32:10.648766 41289 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0824 16:32:27.334614 41289 solver.cpp:228] Iteration 1560, loss = 0.0295378
I0824 16:32:27.334756 41289 solver.cpp:244]     Train net output #0: accuracy = 0.988777
I0824 16:32:27.334796 41289 solver.cpp:244]     Train net output #1: loss = 0.029538 (* 1 = 0.029538 loss)
I0824 16:32:27.334805 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984968
I0824 16:32:27.334816 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993451
I0824 16:32:27.334825 41289 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0824 16:32:44.041759 41289 solver.cpp:228] Iteration 1580, loss = 0.0216065
I0824 16:32:44.041813 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991777
I0824 16:32:44.041829 41289 solver.cpp:244]     Train net output #1: loss = 0.0216067 (* 1 = 0.0216067 loss)
I0824 16:32:44.041837 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993212
I0824 16:32:44.041846 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987309
I0824 16:32:44.041854 41289 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0824 16:33:00.723178 41289 solver.cpp:228] Iteration 1600, loss = 0.026362
I0824 16:33:00.723302 41289 solver.cpp:244]     Train net output #0: accuracy = 0.990059
I0824 16:33:00.723328 41289 solver.cpp:244]     Train net output #1: loss = 0.0263622 (* 1 = 0.0263622 loss)
I0824 16:33:00.723337 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990385
I0824 16:33:00.723345 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989528
I0824 16:33:00.723353 41289 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0824 16:33:17.382370 41289 solver.cpp:228] Iteration 1620, loss = 0.146179
I0824 16:33:17.382423 41289 solver.cpp:244]     Train net output #0: accuracy = 0.946392
I0824 16:33:17.382438 41289 solver.cpp:244]     Train net output #1: loss = 0.146179 (* 1 = 0.146179 loss)
I0824 16:33:17.382450 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.941979
I0824 16:33:17.382462 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988513
I0824 16:33:17.382472 41289 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0824 16:33:34.093796 41289 solver.cpp:228] Iteration 1640, loss = 0.0346364
I0824 16:33:34.093960 41289 solver.cpp:244]     Train net output #0: accuracy = 0.990451
I0824 16:33:34.093982 41289 solver.cpp:244]     Train net output #1: loss = 0.0346366 (* 1 = 0.0346366 loss)
I0824 16:33:34.093991 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993434
I0824 16:33:34.094002 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976455
I0824 16:33:34.094012 41289 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0824 16:33:50.746249 41289 solver.cpp:228] Iteration 1660, loss = 0.050028
I0824 16:33:50.746304 41289 solver.cpp:244]     Train net output #0: accuracy = 0.982509
I0824 16:33:50.746320 41289 solver.cpp:244]     Train net output #1: loss = 0.0500281 (* 1 = 0.0500281 loss)
I0824 16:33:50.746333 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981188
I0824 16:33:50.746345 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984554
I0824 16:33:50.746356 41289 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0824 16:34:07.427170 41289 solver.cpp:228] Iteration 1680, loss = 0.0235296
I0824 16:34:07.427320 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991034
I0824 16:34:07.427361 41289 solver.cpp:244]     Train net output #1: loss = 0.0235297 (* 1 = 0.0235297 loss)
I0824 16:34:07.427371 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992405
I0824 16:34:07.427381 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986309
I0824 16:34:07.427392 41289 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0824 16:34:24.139628 41289 solver.cpp:228] Iteration 1700, loss = 0.0443383
I0824 16:34:24.139688 41289 solver.cpp:244]     Train net output #0: accuracy = 0.981712
I0824 16:34:24.139715 41289 solver.cpp:244]     Train net output #1: loss = 0.0443385 (* 1 = 0.0443385 loss)
I0824 16:34:24.139729 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.971409
I0824 16:34:24.139740 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995936
I0824 16:34:24.139755 41289 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0824 16:34:40.871628 41289 solver.cpp:228] Iteration 1720, loss = 0.0457859
I0824 16:34:40.871798 41289 solver.cpp:244]     Train net output #0: accuracy = 0.985106
I0824 16:34:40.871820 41289 solver.cpp:244]     Train net output #1: loss = 0.045786 (* 1 = 0.045786 loss)
I0824 16:34:40.871834 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986783
I0824 16:34:40.871845 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980017
I0824 16:34:40.871852 41289 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0824 16:34:57.538311 41289 solver.cpp:228] Iteration 1740, loss = 0.0232793
I0824 16:34:57.538370 41289 solver.cpp:244]     Train net output #0: accuracy = 0.99193
I0824 16:34:57.538396 41289 solver.cpp:244]     Train net output #1: loss = 0.0232795 (* 1 = 0.0232795 loss)
I0824 16:34:57.538410 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989504
I0824 16:34:57.538424 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995177
I0824 16:34:57.538439 41289 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0824 16:35:14.192265 41289 solver.cpp:228] Iteration 1760, loss = 0.034847
I0824 16:35:14.192452 41289 solver.cpp:244]     Train net output #0: accuracy = 0.984437
I0824 16:35:14.192478 41289 solver.cpp:244]     Train net output #1: loss = 0.0348472 (* 1 = 0.0348472 loss)
I0824 16:35:14.192494 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981748
I0824 16:35:14.192507 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991626
I0824 16:35:14.192528 41289 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0824 16:35:30.855578 41289 solver.cpp:228] Iteration 1780, loss = 0.0240365
I0824 16:35:30.855646 41289 solver.cpp:244]     Train net output #0: accuracy = 0.988801
I0824 16:35:30.855661 41289 solver.cpp:244]     Train net output #1: loss = 0.0240367 (* 1 = 0.0240367 loss)
I0824 16:35:30.855674 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984955
I0824 16:35:30.855679 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996543
I0824 16:35:30.855686 41289 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0824 16:35:47.526443 41289 solver.cpp:228] Iteration 1800, loss = 0.025369
I0824 16:35:47.526540 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992245
I0824 16:35:47.526556 41289 solver.cpp:244]     Train net output #1: loss = 0.0253692 (* 1 = 0.0253692 loss)
I0824 16:35:47.526568 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994748
I0824 16:35:47.526581 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980225
I0824 16:35:47.526589 41289 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0824 16:36:04.187487 41289 solver.cpp:228] Iteration 1820, loss = 0.0283065
I0824 16:36:04.187538 41289 solver.cpp:244]     Train net output #0: accuracy = 0.98704
I0824 16:36:04.187554 41289 solver.cpp:244]     Train net output #1: loss = 0.0283067 (* 1 = 0.0283067 loss)
I0824 16:36:04.187566 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983222
I0824 16:36:04.187578 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99514
I0824 16:36:04.187587 41289 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0824 16:36:20.862287 41289 solver.cpp:228] Iteration 1840, loss = 0.0192862
I0824 16:36:20.862409 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992633
I0824 16:36:20.862432 41289 solver.cpp:244]     Train net output #1: loss = 0.0192864 (* 1 = 0.0192864 loss)
I0824 16:36:20.862442 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993074
I0824 16:36:20.862452 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991588
I0824 16:36:20.862462 41289 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0824 16:36:37.527513 41289 solver.cpp:228] Iteration 1860, loss = 0.0250603
I0824 16:36:37.527566 41289 solver.cpp:244]     Train net output #0: accuracy = 0.988728
I0824 16:36:37.527581 41289 solver.cpp:244]     Train net output #1: loss = 0.0250605 (* 1 = 0.0250605 loss)
I0824 16:36:37.527595 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985002
I0824 16:36:37.527608 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995136
I0824 16:36:37.527616 41289 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0824 16:36:54.172075 41289 solver.cpp:228] Iteration 1880, loss = 0.0308378
I0824 16:36:54.172191 41289 solver.cpp:244]     Train net output #0: accuracy = 0.988108
I0824 16:36:54.172215 41289 solver.cpp:244]     Train net output #1: loss = 0.0308379 (* 1 = 0.0308379 loss)
I0824 16:36:54.172224 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988209
I0824 16:36:54.172235 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987933
I0824 16:36:54.172245 41289 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0824 16:37:10.834398 41289 solver.cpp:228] Iteration 1900, loss = 0.0257076
I0824 16:37:10.834450 41289 solver.cpp:244]     Train net output #0: accuracy = 0.989416
I0824 16:37:10.834466 41289 solver.cpp:244]     Train net output #1: loss = 0.0257078 (* 1 = 0.0257078 loss)
I0824 16:37:10.834492 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985345
I0824 16:37:10.834501 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995545
I0824 16:37:10.834511 41289 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0824 16:37:27.489253 41289 solver.cpp:228] Iteration 1920, loss = 0.0315668
I0824 16:37:27.489451 41289 solver.cpp:244]     Train net output #0: accuracy = 0.987237
I0824 16:37:27.489492 41289 solver.cpp:244]     Train net output #1: loss = 0.031567 (* 1 = 0.031567 loss)
I0824 16:37:27.489502 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986671
I0824 16:37:27.489509 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988329
I0824 16:37:27.489521 41289 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0824 16:37:44.186203 41289 solver.cpp:228] Iteration 1940, loss = 0.0213284
I0824 16:37:44.186257 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991853
I0824 16:37:44.186272 41289 solver.cpp:244]     Train net output #1: loss = 0.0213285 (* 1 = 0.0213285 loss)
I0824 16:37:44.186280 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990335
I0824 16:37:44.186291 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995441
I0824 16:37:44.186300 41289 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0824 16:38:00.862046 41289 solver.cpp:228] Iteration 1960, loss = 0.0245902
I0824 16:38:00.862196 41289 solver.cpp:244]     Train net output #0: accuracy = 0.989789
I0824 16:38:00.862237 41289 solver.cpp:244]     Train net output #1: loss = 0.0245904 (* 1 = 0.0245904 loss)
I0824 16:38:00.862246 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989465
I0824 16:38:00.862257 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990686
I0824 16:38:00.862268 41289 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0824 16:38:17.547765 41289 solver.cpp:228] Iteration 1980, loss = 0.0313437
I0824 16:38:17.547821 41289 solver.cpp:244]     Train net output #0: accuracy = 0.988814
I0824 16:38:17.547838 41289 solver.cpp:244]     Train net output #1: loss = 0.0313439 (* 1 = 0.0313439 loss)
I0824 16:38:17.547845 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987576
I0824 16:38:17.547852 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990443
I0824 16:38:17.547860 41289 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0824 16:38:34.225607 41289 solver.cpp:228] Iteration 2000, loss = 0.0221882
I0824 16:38:34.225720 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991259
I0824 16:38:34.225746 41289 solver.cpp:244]     Train net output #1: loss = 0.0221884 (* 1 = 0.0221884 loss)
I0824 16:38:34.225755 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990868
I0824 16:38:34.225767 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992081
I0824 16:38:34.225776 41289 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0824 16:38:50.897766 41289 solver.cpp:228] Iteration 2020, loss = 0.0199703
I0824 16:38:50.897821 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992423
I0824 16:38:50.897837 41289 solver.cpp:244]     Train net output #1: loss = 0.0199705 (* 1 = 0.0199705 loss)
I0824 16:38:50.897845 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992577
I0824 16:38:50.897852 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99194
I0824 16:38:50.897862 41289 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0824 16:39:07.599772 41289 solver.cpp:228] Iteration 2040, loss = 0.0259764
I0824 16:39:07.599934 41289 solver.cpp:244]     Train net output #0: accuracy = 0.98931
I0824 16:39:07.599978 41289 solver.cpp:244]     Train net output #1: loss = 0.0259766 (* 1 = 0.0259766 loss)
I0824 16:39:07.599989 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989282
I0824 16:39:07.599999 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989388
I0824 16:39:07.600013 41289 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0824 16:39:24.314630 41289 solver.cpp:228] Iteration 2060, loss = 0.0264941
I0824 16:39:24.314683 41289 solver.cpp:244]     Train net output #0: accuracy = 0.9877
I0824 16:39:24.314700 41289 solver.cpp:244]     Train net output #1: loss = 0.0264942 (* 1 = 0.0264942 loss)
I0824 16:39:24.314707 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982357
I0824 16:39:24.314723 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995624
I0824 16:39:24.314733 41289 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0824 16:39:40.990417 41289 solver.cpp:228] Iteration 2080, loss = 0.0307651
I0824 16:39:40.990604 41289 solver.cpp:244]     Train net output #0: accuracy = 0.986804
I0824 16:39:40.990646 41289 solver.cpp:244]     Train net output #1: loss = 0.0307653 (* 1 = 0.0307653 loss)
I0824 16:39:40.990658 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982153
I0824 16:39:40.990667 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994825
I0824 16:39:40.990681 41289 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0824 16:39:57.698961 41289 solver.cpp:228] Iteration 2100, loss = 0.0196486
I0824 16:39:57.699018 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991549
I0824 16:39:57.699033 41289 solver.cpp:244]     Train net output #1: loss = 0.0196488 (* 1 = 0.0196488 loss)
I0824 16:39:57.699041 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988824
I0824 16:39:57.699048 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995913
I0824 16:39:57.699067 41289 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0824 16:40:14.378911 41289 solver.cpp:228] Iteration 2120, loss = 0.0259183
I0824 16:40:14.379042 41289 solver.cpp:244]     Train net output #0: accuracy = 0.989675
I0824 16:40:14.379062 41289 solver.cpp:244]     Train net output #1: loss = 0.0259185 (* 1 = 0.0259185 loss)
I0824 16:40:14.379071 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98627
I0824 16:40:14.379082 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99529
I0824 16:40:14.379093 41289 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0824 16:40:31.077728 41289 solver.cpp:228] Iteration 2140, loss = 0.0239916
I0824 16:40:31.077780 41289 solver.cpp:244]     Train net output #0: accuracy = 0.990611
I0824 16:40:31.077796 41289 solver.cpp:244]     Train net output #1: loss = 0.0239918 (* 1 = 0.0239918 loss)
I0824 16:40:31.077811 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988452
I0824 16:40:31.077822 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993361
I0824 16:40:31.077836 41289 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0824 16:40:47.762145 41289 solver.cpp:228] Iteration 2160, loss = 0.0203942
I0824 16:40:47.762284 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991421
I0824 16:40:47.762300 41289 solver.cpp:244]     Train net output #1: loss = 0.0203943 (* 1 = 0.0203943 loss)
I0824 16:40:47.762315 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989656
I0824 16:40:47.762327 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994952
I0824 16:40:47.762337 41289 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0824 16:41:04.446615 41289 solver.cpp:228] Iteration 2180, loss = 0.0223717
I0824 16:41:04.446667 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991628
I0824 16:41:04.446682 41289 solver.cpp:244]     Train net output #1: loss = 0.0223719 (* 1 = 0.0223719 loss)
I0824 16:41:04.446694 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992953
I0824 16:41:04.446707 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989026
I0824 16:41:04.446717 41289 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0824 16:41:21.138193 41289 solver.cpp:228] Iteration 2200, loss = 0.0180746
I0824 16:41:21.138368 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993258
I0824 16:41:21.138392 41289 solver.cpp:244]     Train net output #1: loss = 0.0180748 (* 1 = 0.0180748 loss)
I0824 16:41:21.138401 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992986
I0824 16:41:21.138408 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993816
I0824 16:41:21.138418 41289 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0824 16:41:37.822835 41289 solver.cpp:228] Iteration 2220, loss = 0.0196355
I0824 16:41:37.822887 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992442
I0824 16:41:37.822902 41289 solver.cpp:244]     Train net output #1: loss = 0.0196357 (* 1 = 0.0196357 loss)
I0824 16:41:37.822917 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993175
I0824 16:41:37.822929 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990166
I0824 16:41:37.822939 41289 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0824 16:41:54.554190 41289 solver.cpp:228] Iteration 2240, loss = 0.0202297
I0824 16:41:54.554356 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993348
I0824 16:41:54.554391 41289 solver.cpp:244]     Train net output #1: loss = 0.0202299 (* 1 = 0.0202299 loss)
I0824 16:41:54.554401 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994822
I0824 16:41:54.554411 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988965
I0824 16:41:54.554426 41289 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0824 16:42:11.271643 41289 solver.cpp:228] Iteration 2260, loss = 0.0269679
I0824 16:42:11.271697 41289 solver.cpp:244]     Train net output #0: accuracy = 0.990773
I0824 16:42:11.271713 41289 solver.cpp:244]     Train net output #1: loss = 0.0269681 (* 1 = 0.0269681 loss)
I0824 16:42:11.271720 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98889
I0824 16:42:11.271728 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993392
I0824 16:42:11.271737 41289 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0824 16:42:27.960904 41289 solver.cpp:228] Iteration 2280, loss = 0.0243858
I0824 16:42:27.961046 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991348
I0824 16:42:27.961071 41289 solver.cpp:244]     Train net output #1: loss = 0.024386 (* 1 = 0.024386 loss)
I0824 16:42:27.961081 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99253
I0824 16:42:27.961091 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987052
I0824 16:42:27.961102 41289 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0824 16:42:44.634210 41289 solver.cpp:228] Iteration 2300, loss = 0.0227524
I0824 16:42:44.634260 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992354
I0824 16:42:44.634276 41289 solver.cpp:244]     Train net output #1: loss = 0.0227526 (* 1 = 0.0227526 loss)
I0824 16:42:44.634292 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992782
I0824 16:42:44.634304 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991619
I0824 16:42:44.634313 41289 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0824 16:43:01.296988 41289 solver.cpp:228] Iteration 2320, loss = 0.0246183
I0824 16:43:01.297133 41289 solver.cpp:244]     Train net output #0: accuracy = 0.989452
I0824 16:43:01.297168 41289 solver.cpp:244]     Train net output #1: loss = 0.0246185 (* 1 = 0.0246185 loss)
I0824 16:43:01.297178 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989316
I0824 16:43:01.297190 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989729
I0824 16:43:01.297202 41289 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0824 16:43:18.003625 41289 solver.cpp:228] Iteration 2340, loss = 0.0252588
I0824 16:43:18.003679 41289 solver.cpp:244]     Train net output #0: accuracy = 0.989308
I0824 16:43:18.003695 41289 solver.cpp:244]     Train net output #1: loss = 0.025259 (* 1 = 0.025259 loss)
I0824 16:43:18.003702 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988525
I0824 16:43:18.003715 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991627
I0824 16:43:18.003724 41289 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0824 16:43:34.691426 41289 solver.cpp:228] Iteration 2360, loss = 0.013748
I0824 16:43:34.691633 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995104
I0824 16:43:34.691655 41289 solver.cpp:244]     Train net output #1: loss = 0.0137482 (* 1 = 0.0137482 loss)
I0824 16:43:34.691665 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994099
I0824 16:43:34.691676 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996711
I0824 16:43:34.691694 41289 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0824 16:43:51.410454 41289 solver.cpp:228] Iteration 2380, loss = 0.0306866
I0824 16:43:51.410506 41289 solver.cpp:244]     Train net output #0: accuracy = 0.987664
I0824 16:43:51.410521 41289 solver.cpp:244]     Train net output #1: loss = 0.0306867 (* 1 = 0.0306867 loss)
I0824 16:43:51.410534 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98326
I0824 16:43:51.410547 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993755
I0824 16:43:51.410557 41289 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0824 16:44:08.083910 41289 solver.cpp:228] Iteration 2400, loss = 0.0188858
I0824 16:44:08.084043 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992043
I0824 16:44:08.084065 41289 solver.cpp:244]     Train net output #1: loss = 0.018886 (* 1 = 0.018886 loss)
I0824 16:44:08.084074 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990838
I0824 16:44:08.084087 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994077
I0824 16:44:08.084098 41289 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0824 16:44:24.769687 41289 solver.cpp:228] Iteration 2420, loss = 0.0185139
I0824 16:44:24.769738 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992993
I0824 16:44:24.769754 41289 solver.cpp:244]     Train net output #1: loss = 0.0185141 (* 1 = 0.0185141 loss)
I0824 16:44:24.769765 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992549
I0824 16:44:24.769776 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993951
I0824 16:44:24.769788 41289 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0824 16:44:41.459419 41289 solver.cpp:228] Iteration 2440, loss = 0.0233424
I0824 16:44:41.459571 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991233
I0824 16:44:41.459614 41289 solver.cpp:244]     Train net output #1: loss = 0.0233425 (* 1 = 0.0233425 loss)
I0824 16:44:41.459623 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989191
I0824 16:44:41.459635 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993963
I0824 16:44:41.459648 41289 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0824 16:44:58.170615 41289 solver.cpp:228] Iteration 2460, loss = 0.0190681
I0824 16:44:58.170667 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991279
I0824 16:44:58.170684 41289 solver.cpp:244]     Train net output #1: loss = 0.0190683 (* 1 = 0.0190683 loss)
I0824 16:44:58.170692 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989061
I0824 16:44:58.170698 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996276
I0824 16:44:58.170707 41289 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0824 16:45:14.850353 41289 solver.cpp:228] Iteration 2480, loss = 0.0216129
I0824 16:45:14.850469 41289 solver.cpp:244]     Train net output #0: accuracy = 0.989376
I0824 16:45:14.850492 41289 solver.cpp:244]     Train net output #1: loss = 0.021613 (* 1 = 0.021613 loss)
I0824 16:45:14.850502 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986645
I0824 16:45:14.850512 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995268
I0824 16:45:14.850523 41289 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0824 16:45:31.559098 41289 solver.cpp:228] Iteration 2500, loss = 0.0226952
I0824 16:45:31.559149 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991597
I0824 16:45:31.559165 41289 solver.cpp:244]     Train net output #1: loss = 0.0226954 (* 1 = 0.0226954 loss)
I0824 16:45:31.559180 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989576
I0824 16:45:31.559186 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994601
I0824 16:45:31.559197 41289 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0824 16:45:48.252274 41289 solver.cpp:228] Iteration 2520, loss = 0.0201114
I0824 16:45:48.252435 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991837
I0824 16:45:48.252459 41289 solver.cpp:244]     Train net output #1: loss = 0.0201116 (* 1 = 0.0201116 loss)
I0824 16:45:48.252468 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99259
I0824 16:45:48.252480 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98963
I0824 16:45:48.252491 41289 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0824 16:46:04.951979 41289 solver.cpp:228] Iteration 2540, loss = 0.0138441
I0824 16:46:04.952035 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993929
I0824 16:46:04.952051 41289 solver.cpp:244]     Train net output #1: loss = 0.0138443 (* 1 = 0.0138443 loss)
I0824 16:46:04.952087 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9926
I0824 16:46:04.952098 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996528
I0824 16:46:04.952121 41289 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0824 16:46:21.664177 41289 solver.cpp:228] Iteration 2560, loss = 0.0307173
I0824 16:46:21.664331 41289 solver.cpp:244]     Train net output #0: accuracy = 0.987499
I0824 16:46:21.664373 41289 solver.cpp:244]     Train net output #1: loss = 0.0307175 (* 1 = 0.0307175 loss)
I0824 16:46:21.664382 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989425
I0824 16:46:21.664393 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98113
I0824 16:46:21.664407 41289 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0824 16:46:38.371388 41289 solver.cpp:228] Iteration 2580, loss = 0.014747
I0824 16:46:38.371444 41289 solver.cpp:244]     Train net output #0: accuracy = 0.99362
I0824 16:46:38.371461 41289 solver.cpp:244]     Train net output #1: loss = 0.0147472 (* 1 = 0.0147472 loss)
I0824 16:46:38.371469 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99141
I0824 16:46:38.371481 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997633
I0824 16:46:38.371490 41289 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0824 16:46:55.051986 41289 solver.cpp:228] Iteration 2600, loss = 0.0208523
I0824 16:46:55.052103 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992446
I0824 16:46:55.052121 41289 solver.cpp:244]     Train net output #1: loss = 0.0208525 (* 1 = 0.0208525 loss)
I0824 16:46:55.052130 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991595
I0824 16:46:55.052141 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993566
I0824 16:46:55.052151 41289 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0824 16:47:11.734594 41289 solver.cpp:228] Iteration 2620, loss = 0.0282102
I0824 16:47:11.734647 41289 solver.cpp:244]     Train net output #0: accuracy = 0.987497
I0824 16:47:11.734661 41289 solver.cpp:244]     Train net output #1: loss = 0.0282104 (* 1 = 0.0282104 loss)
I0824 16:47:11.734673 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986407
I0824 16:47:11.734685 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990065
I0824 16:47:11.734696 41289 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0824 16:47:28.421396 41289 solver.cpp:228] Iteration 2640, loss = 0.0301502
I0824 16:47:28.421536 41289 solver.cpp:244]     Train net output #0: accuracy = 0.989469
I0824 16:47:28.421577 41289 solver.cpp:244]     Train net output #1: loss = 0.0301504 (* 1 = 0.0301504 loss)
I0824 16:47:28.421586 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992265
I0824 16:47:28.421597 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982908
I0824 16:47:28.421609 41289 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0824 16:47:45.152655 41289 solver.cpp:228] Iteration 2660, loss = 0.0163704
I0824 16:47:45.152714 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993006
I0824 16:47:45.152729 41289 solver.cpp:244]     Train net output #1: loss = 0.0163706 (* 1 = 0.0163706 loss)
I0824 16:47:45.152746 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991793
I0824 16:47:45.152757 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99527
I0824 16:47:45.152768 41289 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0824 16:48:01.834667 41289 solver.cpp:228] Iteration 2680, loss = 0.0113079
I0824 16:48:01.834842 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995914
I0824 16:48:01.834861 41289 solver.cpp:244]     Train net output #1: loss = 0.0113081 (* 1 = 0.0113081 loss)
I0824 16:48:01.834872 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996485
I0824 16:48:01.834884 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994562
I0824 16:48:01.834895 41289 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0824 16:48:18.548194 41289 solver.cpp:228] Iteration 2700, loss = 0.020018
I0824 16:48:18.548246 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991301
I0824 16:48:18.548262 41289 solver.cpp:244]     Train net output #1: loss = 0.0200182 (* 1 = 0.0200182 loss)
I0824 16:48:18.548270 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986711
I0824 16:48:18.548285 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997609
I0824 16:48:18.548295 41289 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0824 16:48:35.232280 41289 solver.cpp:228] Iteration 2720, loss = 0.0213809
I0824 16:48:35.232420 41289 solver.cpp:244]     Train net output #0: accuracy = 0.99226
I0824 16:48:35.232444 41289 solver.cpp:244]     Train net output #1: loss = 0.0213811 (* 1 = 0.0213811 loss)
I0824 16:48:35.232453 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993006
I0824 16:48:35.232465 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990713
I0824 16:48:35.232476 41289 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0824 16:48:51.935451 41289 solver.cpp:228] Iteration 2740, loss = 0.0118076
I0824 16:48:51.935503 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995298
I0824 16:48:51.935519 41289 solver.cpp:244]     Train net output #1: loss = 0.0118077 (* 1 = 0.0118077 loss)
I0824 16:48:51.935534 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995237
I0824 16:48:51.935545 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995432
I0824 16:48:51.935556 41289 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0824 16:49:08.650914 41289 solver.cpp:228] Iteration 2760, loss = 0.0167166
I0824 16:49:08.651058 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993584
I0824 16:49:08.651083 41289 solver.cpp:244]     Train net output #1: loss = 0.0167168 (* 1 = 0.0167168 loss)
I0824 16:49:08.651094 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992391
I0824 16:49:08.651105 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995576
I0824 16:49:08.651116 41289 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0824 16:49:25.381260 41289 solver.cpp:228] Iteration 2780, loss = 0.02293
I0824 16:49:25.381311 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994316
I0824 16:49:25.381327 41289 solver.cpp:244]     Train net output #1: loss = 0.0229302 (* 1 = 0.0229302 loss)
I0824 16:49:25.381340 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992839
I0824 16:49:25.381363 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995528
I0824 16:49:25.381389 41289 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0824 16:49:42.100327 41289 solver.cpp:228] Iteration 2800, loss = 0.012256
I0824 16:49:42.100534 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995048
I0824 16:49:42.100576 41289 solver.cpp:244]     Train net output #1: loss = 0.0122562 (* 1 = 0.0122562 loss)
I0824 16:49:42.100586 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994371
I0824 16:49:42.100592 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997246
I0824 16:49:42.100605 41289 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0824 16:49:58.843000 41289 solver.cpp:228] Iteration 2820, loss = 0.0246078
I0824 16:49:58.843056 41289 solver.cpp:244]     Train net output #0: accuracy = 0.989285
I0824 16:49:58.843072 41289 solver.cpp:244]     Train net output #1: loss = 0.024608 (* 1 = 0.024608 loss)
I0824 16:49:58.843080 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984357
I0824 16:49:58.843087 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996425
I0824 16:49:58.843098 41289 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0824 16:50:15.556860 41289 solver.cpp:228] Iteration 2840, loss = 0.0136325
I0824 16:50:15.557005 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994295
I0824 16:50:15.557030 41289 solver.cpp:244]     Train net output #1: loss = 0.0136327 (* 1 = 0.0136327 loss)
I0824 16:50:15.557039 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993342
I0824 16:50:15.557051 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996087
I0824 16:50:15.557060 41289 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0824 16:50:32.227550 41289 solver.cpp:228] Iteration 2860, loss = 0.0142771
I0824 16:50:32.227603 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993977
I0824 16:50:32.227619 41289 solver.cpp:244]     Train net output #1: loss = 0.0142773 (* 1 = 0.0142773 loss)
I0824 16:50:32.227632 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992368
I0824 16:50:32.227644 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997004
I0824 16:50:32.227658 41289 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0824 16:50:48.922791 41289 solver.cpp:228] Iteration 2880, loss = 0.0158458
I0824 16:50:48.922931 41289 solver.cpp:244]     Train net output #0: accuracy = 0.99444
I0824 16:50:48.922950 41289 solver.cpp:244]     Train net output #1: loss = 0.015846 (* 1 = 0.015846 loss)
I0824 16:50:48.922963 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992514
I0824 16:50:48.922974 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997396
I0824 16:50:48.922983 41289 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0824 16:51:05.589901 41289 solver.cpp:228] Iteration 2900, loss = 0.0120185
I0824 16:51:05.589953 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995593
I0824 16:51:05.589970 41289 solver.cpp:244]     Train net output #1: loss = 0.0120187 (* 1 = 0.0120187 loss)
I0824 16:51:05.589977 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996316
I0824 16:51:05.589990 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993655
I0824 16:51:05.590000 41289 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0824 16:51:22.293565 41289 solver.cpp:228] Iteration 2920, loss = 0.0144864
I0824 16:51:22.293711 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994566
I0824 16:51:22.293748 41289 solver.cpp:244]     Train net output #1: loss = 0.0144866 (* 1 = 0.0144866 loss)
I0824 16:51:22.293759 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994745
I0824 16:51:22.293771 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994129
I0824 16:51:22.293781 41289 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0824 16:51:38.982650 41289 solver.cpp:228] Iteration 2940, loss = 0.0305186
I0824 16:51:38.982700 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991807
I0824 16:51:38.982714 41289 solver.cpp:244]     Train net output #1: loss = 0.0305188 (* 1 = 0.0305188 loss)
I0824 16:51:38.982728 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992404
I0824 16:51:38.982734 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991296
I0824 16:51:38.982744 41289 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0824 16:51:55.709260 41289 solver.cpp:228] Iteration 2960, loss = 0.015614
I0824 16:51:55.709441 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994149
I0824 16:51:55.709468 41289 solver.cpp:244]     Train net output #1: loss = 0.0156142 (* 1 = 0.0156142 loss)
I0824 16:51:55.709476 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995165
I0824 16:51:55.709489 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991147
I0824 16:51:55.709501 41289 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0824 16:52:12.382374 41289 solver.cpp:228] Iteration 2980, loss = 0.0125866
I0824 16:52:12.382426 41289 solver.cpp:244]     Train net output #0: accuracy = 0.99553
I0824 16:52:12.382458 41289 solver.cpp:244]     Train net output #1: loss = 0.0125868 (* 1 = 0.0125868 loss)
I0824 16:52:12.382468 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995831
I0824 16:52:12.382479 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994502
I0824 16:52:12.382490 41289 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0824 16:52:29.105818 41289 solver.cpp:228] Iteration 3000, loss = 0.0187285
I0824 16:52:29.105971 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994845
I0824 16:52:29.106001 41289 solver.cpp:244]     Train net output #1: loss = 0.0187287 (* 1 = 0.0187287 loss)
I0824 16:52:29.106020 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994512
I0824 16:52:29.106029 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99517
I0824 16:52:29.106048 41289 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0824 16:52:45.815352 41289 solver.cpp:228] Iteration 3020, loss = 0.0191045
I0824 16:52:45.815405 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992306
I0824 16:52:45.815421 41289 solver.cpp:244]     Train net output #1: loss = 0.0191047 (* 1 = 0.0191047 loss)
I0824 16:52:45.815429 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990896
I0824 16:52:45.815435 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995976
I0824 16:52:45.815448 41289 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0824 16:53:02.549996 41289 solver.cpp:228] Iteration 3040, loss = 0.0114496
I0824 16:53:02.550117 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995843
I0824 16:53:02.550143 41289 solver.cpp:244]     Train net output #1: loss = 0.0114498 (* 1 = 0.0114498 loss)
I0824 16:53:02.550151 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996671
I0824 16:53:02.550163 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993629
I0824 16:53:02.550174 41289 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0824 16:53:19.241560 41289 solver.cpp:228] Iteration 3060, loss = 0.019103
I0824 16:53:19.241612 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993183
I0824 16:53:19.241628 41289 solver.cpp:244]     Train net output #1: loss = 0.0191031 (* 1 = 0.0191031 loss)
I0824 16:53:19.241637 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99296
I0824 16:53:19.241649 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993848
I0824 16:53:19.241660 41289 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0824 16:53:35.935979 41289 solver.cpp:228] Iteration 3080, loss = 0.0110988
I0824 16:53:35.936100 41289 solver.cpp:244]     Train net output #0: accuracy = 0.996343
I0824 16:53:35.936127 41289 solver.cpp:244]     Train net output #1: loss = 0.011099 (* 1 = 0.011099 loss)
I0824 16:53:35.936136 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997032
I0824 16:53:35.936148 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99259
I0824 16:53:35.936159 41289 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0824 16:53:52.632287 41289 solver.cpp:228] Iteration 3100, loss = 0.0150523
I0824 16:53:52.632339 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994044
I0824 16:53:52.632355 41289 solver.cpp:244]     Train net output #1: loss = 0.0150525 (* 1 = 0.0150525 loss)
I0824 16:53:52.632366 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994668
I0824 16:53:52.632374 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991229
I0824 16:53:52.632385 41289 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0824 16:54:09.355027 41289 solver.cpp:228] Iteration 3120, loss = 0.0178804
I0824 16:54:09.355229 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993426
I0824 16:54:09.355248 41289 solver.cpp:244]     Train net output #1: loss = 0.0178805 (* 1 = 0.0178805 loss)
I0824 16:54:09.355258 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993268
I0824 16:54:09.355270 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99382
I0824 16:54:09.355281 41289 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0824 16:54:26.033888 41289 solver.cpp:228] Iteration 3140, loss = 0.024315
I0824 16:54:26.033939 41289 solver.cpp:244]     Train net output #0: accuracy = 0.990411
I0824 16:54:26.033956 41289 solver.cpp:244]     Train net output #1: loss = 0.0243152 (* 1 = 0.0243152 loss)
I0824 16:54:26.033967 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989279
I0824 16:54:26.033980 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993245
I0824 16:54:26.033991 41289 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0824 16:54:42.730753 41289 solver.cpp:228] Iteration 3160, loss = 0.0211418
I0824 16:54:42.730887 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992512
I0824 16:54:42.730911 41289 solver.cpp:244]     Train net output #1: loss = 0.021142 (* 1 = 0.021142 loss)
I0824 16:54:42.730921 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993035
I0824 16:54:42.730931 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991355
I0824 16:54:42.730947 41289 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0824 16:54:59.417119 41289 solver.cpp:228] Iteration 3180, loss = 0.0157015
I0824 16:54:59.417171 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993325
I0824 16:54:59.417186 41289 solver.cpp:244]     Train net output #1: loss = 0.0157016 (* 1 = 0.0157016 loss)
I0824 16:54:59.417207 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991902
I0824 16:54:59.417217 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995879
I0824 16:54:59.417228 41289 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0824 16:55:16.097663 41289 solver.cpp:228] Iteration 3200, loss = 0.0113913
I0824 16:55:16.097797 41289 solver.cpp:244]     Train net output #0: accuracy = 0.996117
I0824 16:55:16.097821 41289 solver.cpp:244]     Train net output #1: loss = 0.0113914 (* 1 = 0.0113914 loss)
I0824 16:55:16.097831 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995284
I0824 16:55:16.097842 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997254
I0824 16:55:16.097854 41289 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0824 16:55:32.775246 41289 solver.cpp:228] Iteration 3220, loss = 0.0165116
I0824 16:55:32.775300 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993144
I0824 16:55:32.775316 41289 solver.cpp:244]     Train net output #1: loss = 0.0165118 (* 1 = 0.0165118 loss)
I0824 16:55:32.775324 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989546
I0824 16:55:32.775331 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998362
I0824 16:55:32.775341 41289 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0824 16:55:49.462285 41289 solver.cpp:228] Iteration 3240, loss = 0.0192578
I0824 16:55:49.462414 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993111
I0824 16:55:49.462432 41289 solver.cpp:244]     Train net output #1: loss = 0.019258 (* 1 = 0.019258 loss)
I0824 16:55:49.462443 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992749
I0824 16:55:49.462455 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99428
I0824 16:55:49.462466 41289 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0824 16:56:06.164615 41289 solver.cpp:228] Iteration 3260, loss = 0.0168459
I0824 16:56:06.164665 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993139
I0824 16:56:06.164682 41289 solver.cpp:244]     Train net output #1: loss = 0.0168461 (* 1 = 0.0168461 loss)
I0824 16:56:06.164695 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994138
I0824 16:56:06.164705 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989631
I0824 16:56:06.164716 41289 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0824 16:56:22.887238 41289 solver.cpp:228] Iteration 3280, loss = 0.0156829
I0824 16:56:22.887406 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994698
I0824 16:56:22.887425 41289 solver.cpp:244]     Train net output #1: loss = 0.0156831 (* 1 = 0.0156831 loss)
I0824 16:56:22.887434 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9961
I0824 16:56:22.887450 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989961
I0824 16:56:22.887462 41289 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0824 16:56:39.579542 41289 solver.cpp:228] Iteration 3300, loss = 0.0210129
I0824 16:56:39.579596 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992765
I0824 16:56:39.579612 41289 solver.cpp:244]     Train net output #1: loss = 0.0210131 (* 1 = 0.0210131 loss)
I0824 16:56:39.579620 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99327
I0824 16:56:39.579627 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991586
I0824 16:56:39.579637 41289 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0824 16:56:56.251621 41289 solver.cpp:228] Iteration 3320, loss = 0.0127415
I0824 16:56:56.251765 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995195
I0824 16:56:56.251791 41289 solver.cpp:244]     Train net output #1: loss = 0.0127417 (* 1 = 0.0127417 loss)
I0824 16:56:56.251801 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99468
I0824 16:56:56.251812 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996132
I0824 16:56:56.251821 41289 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0824 16:57:12.928949 41289 solver.cpp:228] Iteration 3340, loss = 0.012401
I0824 16:57:12.929003 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995574
I0824 16:57:12.929019 41289 solver.cpp:244]     Train net output #1: loss = 0.0124012 (* 1 = 0.0124012 loss)
I0824 16:57:12.929029 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994849
I0824 16:57:12.929041 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996796
I0824 16:57:12.929050 41289 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0824 16:57:29.614694 41289 solver.cpp:228] Iteration 3360, loss = 0.0195667
I0824 16:57:29.614841 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991829
I0824 16:57:29.614884 41289 solver.cpp:244]     Train net output #1: loss = 0.0195669 (* 1 = 0.0195669 loss)
I0824 16:57:29.614894 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992349
I0824 16:57:29.614905 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990583
I0824 16:57:29.614917 41289 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0824 16:57:46.293884 41289 solver.cpp:228] Iteration 3380, loss = 0.0166033
I0824 16:57:46.293941 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993105
I0824 16:57:46.293958 41289 solver.cpp:244]     Train net output #1: loss = 0.0166035 (* 1 = 0.0166035 loss)
I0824 16:57:46.293974 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990609
I0824 16:57:46.293987 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996517
I0824 16:57:46.293998 41289 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0824 16:58:02.983641 41289 solver.cpp:228] Iteration 3400, loss = 0.0112481
I0824 16:58:02.983834 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994954
I0824 16:58:02.983875 41289 solver.cpp:244]     Train net output #1: loss = 0.0112483 (* 1 = 0.0112483 loss)
I0824 16:58:02.983887 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993838
I0824 16:58:02.983898 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997218
I0824 16:58:02.983917 41289 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0824 16:58:19.713738 41289 solver.cpp:228] Iteration 3420, loss = 0.015323
I0824 16:58:19.713793 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993876
I0824 16:58:19.713809 41289 solver.cpp:244]     Train net output #1: loss = 0.0153232 (* 1 = 0.0153232 loss)
I0824 16:58:19.713815 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992575
I0824 16:58:19.713822 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996373
I0824 16:58:19.713834 41289 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0824 16:58:36.424407 41289 solver.cpp:228] Iteration 3440, loss = 0.0119426
I0824 16:58:36.424535 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995042
I0824 16:58:36.424557 41289 solver.cpp:244]     Train net output #1: loss = 0.0119428 (* 1 = 0.0119428 loss)
I0824 16:58:36.424567 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994989
I0824 16:58:36.424578 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995209
I0824 16:58:36.424588 41289 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0824 16:58:53.127071 41289 solver.cpp:228] Iteration 3460, loss = 0.0162344
I0824 16:58:53.127123 41289 solver.cpp:244]     Train net output #0: accuracy = 0.99284
I0824 16:58:53.127140 41289 solver.cpp:244]     Train net output #1: loss = 0.0162346 (* 1 = 0.0162346 loss)
I0824 16:58:53.127154 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990731
I0824 16:58:53.127167 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995995
I0824 16:58:53.127178 41289 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0824 16:59:09.812204 41289 solver.cpp:228] Iteration 3480, loss = 0.0169177
I0824 16:59:09.812361 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993993
I0824 16:59:09.812403 41289 solver.cpp:244]     Train net output #1: loss = 0.0169178 (* 1 = 0.0169178 loss)
I0824 16:59:09.812414 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993351
I0824 16:59:09.812438 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995181
I0824 16:59:09.812454 41289 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0824 16:59:26.540652 41289 solver.cpp:228] Iteration 3500, loss = 0.0139591
I0824 16:59:26.540711 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994725
I0824 16:59:26.540733 41289 solver.cpp:244]     Train net output #1: loss = 0.0139593 (* 1 = 0.0139593 loss)
I0824 16:59:26.540743 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994344
I0824 16:59:26.540755 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995294
I0824 16:59:26.540765 41289 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0824 16:59:43.261046 41289 solver.cpp:228] Iteration 3520, loss = 0.0209552
I0824 16:59:43.261196 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992577
I0824 16:59:43.261220 41289 solver.cpp:244]     Train net output #1: loss = 0.0209554 (* 1 = 0.0209554 loss)
I0824 16:59:43.261229 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989994
I0824 16:59:43.261241 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995797
I0824 16:59:43.261250 41289 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0824 16:59:59.996328 41289 solver.cpp:228] Iteration 3540, loss = 0.0141406
I0824 16:59:59.996382 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994255
I0824 16:59:59.996403 41289 solver.cpp:244]     Train net output #1: loss = 0.0141408 (* 1 = 0.0141408 loss)
I0824 16:59:59.996414 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993788
I0824 16:59:59.996426 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995257
I0824 16:59:59.996435 41289 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0824 17:00:16.679222 41289 solver.cpp:228] Iteration 3560, loss = 0.0143271
I0824 17:00:16.679376 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993957
I0824 17:00:16.679397 41289 solver.cpp:244]     Train net output #1: loss = 0.0143273 (* 1 = 0.0143273 loss)
I0824 17:00:16.679407 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994204
I0824 17:00:16.679419 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993004
I0824 17:00:16.679427 41289 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0824 17:00:33.328063 41289 solver.cpp:228] Iteration 3580, loss = 0.0123605
I0824 17:00:33.328114 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995365
I0824 17:00:33.328130 41289 solver.cpp:244]     Train net output #1: loss = 0.0123606 (* 1 = 0.0123606 loss)
I0824 17:00:33.328137 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993062
I0824 17:00:33.328143 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998374
I0824 17:00:33.328152 41289 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0824 17:00:49.983976 41289 solver.cpp:228] Iteration 3600, loss = 0.0172575
I0824 17:00:49.984109 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993662
I0824 17:00:49.984131 41289 solver.cpp:244]     Train net output #1: loss = 0.0172577 (* 1 = 0.0172577 loss)
I0824 17:00:49.984141 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99381
I0824 17:00:49.984153 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993082
I0824 17:00:49.984161 41289 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0824 17:01:06.659766 41289 solver.cpp:228] Iteration 3620, loss = 0.0181408
I0824 17:01:06.659827 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992134
I0824 17:01:06.659842 41289 solver.cpp:244]     Train net output #1: loss = 0.018141 (* 1 = 0.018141 loss)
I0824 17:01:06.659853 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990396
I0824 17:01:06.659865 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995599
I0824 17:01:06.659874 41289 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0824 17:01:23.325502 41289 solver.cpp:228] Iteration 3640, loss = 0.017056
I0824 17:01:23.325613 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992151
I0824 17:01:23.325631 41289 solver.cpp:244]     Train net output #1: loss = 0.0170562 (* 1 = 0.0170562 loss)
I0824 17:01:23.325640 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989047
I0824 17:01:23.325652 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997707
I0824 17:01:23.325661 41289 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0824 17:01:40.008872 41289 solver.cpp:228] Iteration 3660, loss = 0.0154492
I0824 17:01:40.008924 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993315
I0824 17:01:40.008941 41289 solver.cpp:244]     Train net output #1: loss = 0.0154494 (* 1 = 0.0154494 loss)
I0824 17:01:40.008952 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990802
I0824 17:01:40.008965 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996921
I0824 17:01:40.008975 41289 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0824 17:01:56.700834 41289 solver.cpp:228] Iteration 3680, loss = 0.0171377
I0824 17:01:56.700981 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994294
I0824 17:01:56.701022 41289 solver.cpp:244]     Train net output #1: loss = 0.0171379 (* 1 = 0.0171379 loss)
I0824 17:01:56.701033 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994304
I0824 17:01:56.701042 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994271
I0824 17:01:56.701068 41289 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0824 17:02:13.430013 41289 solver.cpp:228] Iteration 3700, loss = 0.0261232
I0824 17:02:13.430079 41289 solver.cpp:244]     Train net output #0: accuracy = 0.98911
I0824 17:02:13.430104 41289 solver.cpp:244]     Train net output #1: loss = 0.0261234 (* 1 = 0.0261234 loss)
I0824 17:02:13.430111 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987147
I0824 17:02:13.430120 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992071
I0824 17:02:13.430136 41289 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0824 17:02:30.112933 41289 solver.cpp:228] Iteration 3720, loss = 0.0137253
I0824 17:02:30.113085 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994251
I0824 17:02:30.113106 41289 solver.cpp:244]     Train net output #1: loss = 0.0137255 (* 1 = 0.0137255 loss)
I0824 17:02:30.113116 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994792
I0824 17:02:30.113128 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992946
I0824 17:02:30.113137 41289 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0824 17:02:46.778960 41289 solver.cpp:228] Iteration 3740, loss = 0.0150617
I0824 17:02:46.779012 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993882
I0824 17:02:46.779028 41289 solver.cpp:244]     Train net output #1: loss = 0.0150619 (* 1 = 0.0150619 loss)
I0824 17:02:46.779042 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992732
I0824 17:02:46.779052 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995931
I0824 17:02:46.779062 41289 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0824 17:03:03.442680 41289 solver.cpp:228] Iteration 3760, loss = 0.0187809
I0824 17:03:03.442831 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992216
I0824 17:03:03.442873 41289 solver.cpp:244]     Train net output #1: loss = 0.0187811 (* 1 = 0.0187811 loss)
I0824 17:03:03.442883 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991608
I0824 17:03:03.442893 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993213
I0824 17:03:03.442904 41289 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0824 17:03:20.113275 41289 solver.cpp:228] Iteration 3780, loss = 0.0246959
I0824 17:03:20.113328 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992024
I0824 17:03:20.113345 41289 solver.cpp:244]     Train net output #1: loss = 0.0246961 (* 1 = 0.0246961 loss)
I0824 17:03:20.113353 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991576
I0824 17:03:20.113358 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992477
I0824 17:03:20.113373 41289 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0824 17:03:36.782840 41289 solver.cpp:228] Iteration 3800, loss = 0.0129494
I0824 17:03:36.782984 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994624
I0824 17:03:36.783025 41289 solver.cpp:244]     Train net output #1: loss = 0.0129496 (* 1 = 0.0129496 loss)
I0824 17:03:36.783035 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994496
I0824 17:03:36.783046 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994913
I0824 17:03:36.783054 41289 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0824 17:03:53.468722 41289 solver.cpp:228] Iteration 3820, loss = 0.0108982
I0824 17:03:53.468770 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994931
I0824 17:03:53.468786 41289 solver.cpp:244]     Train net output #1: loss = 0.0108984 (* 1 = 0.0108984 loss)
I0824 17:03:53.468793 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993441
I0824 17:03:53.468806 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997914
I0824 17:03:53.468816 41289 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0824 17:04:10.137783 41289 solver.cpp:228] Iteration 3840, loss = 0.0220743
I0824 17:04:10.137879 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991917
I0824 17:04:10.137898 41289 solver.cpp:244]     Train net output #1: loss = 0.0220745 (* 1 = 0.0220745 loss)
I0824 17:04:10.137908 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99156
I0824 17:04:10.137919 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992581
I0824 17:04:10.137928 41289 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0824 17:04:26.804782 41289 solver.cpp:228] Iteration 3860, loss = 0.0168877
I0824 17:04:26.804850 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994439
I0824 17:04:26.804868 41289 solver.cpp:244]     Train net output #1: loss = 0.0168879 (* 1 = 0.0168879 loss)
I0824 17:04:26.804878 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991375
I0824 17:04:26.804889 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997592
I0824 17:04:26.804898 41289 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0824 17:04:43.488724 41289 solver.cpp:228] Iteration 3880, loss = 0.0128492
I0824 17:04:43.488893 41289 solver.cpp:244]     Train net output #0: accuracy = 0.99515
I0824 17:04:43.488915 41289 solver.cpp:244]     Train net output #1: loss = 0.0128494 (* 1 = 0.0128494 loss)
I0824 17:04:43.488924 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994905
I0824 17:04:43.488936 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995664
I0824 17:04:43.488945 41289 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0824 17:05:00.154428 41289 solver.cpp:228] Iteration 3900, loss = 0.0103226
I0824 17:05:00.154479 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995799
I0824 17:05:00.154496 41289 solver.cpp:244]     Train net output #1: loss = 0.0103228 (* 1 = 0.0103228 loss)
I0824 17:05:00.154507 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996131
I0824 17:05:00.154520 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994962
I0824 17:05:00.154528 41289 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0824 17:05:16.826902 41289 solver.cpp:228] Iteration 3920, loss = 0.014194
I0824 17:05:16.827023 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994786
I0824 17:05:16.827046 41289 solver.cpp:244]     Train net output #1: loss = 0.0141942 (* 1 = 0.0141942 loss)
I0824 17:05:16.827056 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994137
I0824 17:05:16.827069 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99676
I0824 17:05:16.827077 41289 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0824 17:05:33.502333 41289 solver.cpp:228] Iteration 3940, loss = 0.0118654
I0824 17:05:33.502388 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995839
I0824 17:05:33.502403 41289 solver.cpp:244]     Train net output #1: loss = 0.0118656 (* 1 = 0.0118656 loss)
I0824 17:05:33.502409 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994518
I0824 17:05:33.502416 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997405
I0824 17:05:33.502425 41289 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0824 17:05:50.166465 41289 solver.cpp:228] Iteration 3960, loss = 0.0117135
I0824 17:05:50.166620 41289 solver.cpp:244]     Train net output #0: accuracy = 0.996396
I0824 17:05:50.166664 41289 solver.cpp:244]     Train net output #1: loss = 0.0117137 (* 1 = 0.0117137 loss)
I0824 17:05:50.166674 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995389
I0824 17:05:50.166685 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997415
I0824 17:05:50.166712 41289 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0824 17:06:06.896360 41289 solver.cpp:228] Iteration 3980, loss = 0.0221327
I0824 17:06:06.896427 41289 solver.cpp:244]     Train net output #0: accuracy = 0.991481
I0824 17:06:06.896452 41289 solver.cpp:244]     Train net output #1: loss = 0.0221329 (* 1 = 0.0221329 loss)
I0824 17:06:06.896461 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987832
I0824 17:06:06.896473 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997266
I0824 17:06:06.896482 41289 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0824 17:06:23.570777 41289 solver.cpp:228] Iteration 4000, loss = 0.0157901
I0824 17:06:23.570952 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993779
I0824 17:06:23.570991 41289 solver.cpp:244]     Train net output #1: loss = 0.0157903 (* 1 = 0.0157903 loss)
I0824 17:06:23.571002 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990833
I0824 17:06:23.571013 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99708
I0824 17:06:23.571027 41289 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0824 17:06:40.250464 41289 solver.cpp:228] Iteration 4020, loss = 0.0178144
I0824 17:06:40.250519 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992238
I0824 17:06:40.250535 41289 solver.cpp:244]     Train net output #1: loss = 0.0178146 (* 1 = 0.0178146 loss)
I0824 17:06:40.250543 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990314
I0824 17:06:40.250550 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995617
I0824 17:06:40.250560 41289 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0824 17:06:56.929975 41289 solver.cpp:228] Iteration 4040, loss = 0.0104864
I0824 17:06:56.930127 41289 solver.cpp:244]     Train net output #0: accuracy = 0.9956
I0824 17:06:56.930147 41289 solver.cpp:244]     Train net output #1: loss = 0.0104866 (* 1 = 0.0104866 loss)
I0824 17:06:56.930157 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995443
I0824 17:06:56.930168 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996043
I0824 17:06:56.930178 41289 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0824 17:07:13.602006 41289 solver.cpp:228] Iteration 4060, loss = 0.0151684
I0824 17:07:13.602057 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994245
I0824 17:07:13.602074 41289 solver.cpp:244]     Train net output #1: loss = 0.0151686 (* 1 = 0.0151686 loss)
I0824 17:07:13.602087 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993074
I0824 17:07:13.602098 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996742
I0824 17:07:13.602108 41289 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0824 17:07:31.339970 41289 solver.cpp:228] Iteration 4080, loss = 0.0139104
I0824 17:07:31.340104 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994673
I0824 17:07:31.340124 41289 solver.cpp:244]     Train net output #1: loss = 0.0139106 (* 1 = 0.0139106 loss)
I0824 17:07:31.340131 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994923
I0824 17:07:31.340138 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994153
I0824 17:07:31.340149 41289 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0824 17:07:48.052382 41289 solver.cpp:228] Iteration 4100, loss = 0.0178376
I0824 17:07:48.052438 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994378
I0824 17:07:48.052455 41289 solver.cpp:244]     Train net output #1: loss = 0.0178378 (* 1 = 0.0178378 loss)
I0824 17:07:48.052464 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993112
I0824 17:07:48.052476 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995459
I0824 17:07:48.052486 41289 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0824 17:08:04.738361 41289 solver.cpp:228] Iteration 4120, loss = 0.0128489
I0824 17:08:04.738520 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994196
I0824 17:08:04.738561 41289 solver.cpp:244]     Train net output #1: loss = 0.0128491 (* 1 = 0.0128491 loss)
I0824 17:08:04.738570 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991959
I0824 17:08:04.738581 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997465
I0824 17:08:04.738591 41289 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0824 17:08:21.463372 41289 solver.cpp:228] Iteration 4140, loss = 0.0110395
I0824 17:08:21.463428 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995353
I0824 17:08:21.463449 41289 solver.cpp:244]     Train net output #1: loss = 0.0110397 (* 1 = 0.0110397 loss)
I0824 17:08:21.463459 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994829
I0824 17:08:21.463469 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996422
I0824 17:08:21.463480 41289 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0824 17:08:38.212376 41289 solver.cpp:228] Iteration 4160, loss = 0.0186181
I0824 17:08:38.212571 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992367
I0824 17:08:38.212599 41289 solver.cpp:244]     Train net output #1: loss = 0.0186183 (* 1 = 0.0186183 loss)
I0824 17:08:38.212610 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990156
I0824 17:08:38.212620 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995116
I0824 17:08:38.212630 41289 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0824 17:08:54.924026 41289 solver.cpp:228] Iteration 4180, loss = 0.010796
I0824 17:08:54.924087 41289 solver.cpp:244]     Train net output #0: accuracy = 0.996107
I0824 17:08:54.924111 41289 solver.cpp:244]     Train net output #1: loss = 0.0107962 (* 1 = 0.0107962 loss)
I0824 17:08:54.924120 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997248
I0824 17:08:54.924137 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991974
I0824 17:08:54.924150 41289 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0824 17:09:11.616569 41289 solver.cpp:228] Iteration 4200, loss = 0.0183541
I0824 17:09:11.616694 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992182
I0824 17:09:11.616708 41289 solver.cpp:244]     Train net output #1: loss = 0.0183543 (* 1 = 0.0183543 loss)
I0824 17:09:11.616720 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988039
I0824 17:09:11.616726 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998407
I0824 17:09:11.616734 41289 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0824 17:09:28.270289 41289 solver.cpp:228] Iteration 4220, loss = 0.0218605
I0824 17:09:28.270341 41289 solver.cpp:244]     Train net output #0: accuracy = 0.992276
I0824 17:09:28.270354 41289 solver.cpp:244]     Train net output #1: loss = 0.0218607 (* 1 = 0.0218607 loss)
I0824 17:09:28.270360 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991562
I0824 17:09:28.270365 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993685
I0824 17:09:28.270373 41289 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0824 17:09:44.948904 41289 solver.cpp:228] Iteration 4240, loss = 0.0133469
I0824 17:09:44.949023 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995184
I0824 17:09:44.949039 41289 solver.cpp:244]     Train net output #1: loss = 0.013347 (* 1 = 0.013347 loss)
I0824 17:09:44.949053 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994469
I0824 17:09:44.949059 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996202
I0824 17:09:44.949065 41289 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0824 17:10:01.624857 41289 solver.cpp:228] Iteration 4260, loss = 0.017831
I0824 17:10:01.624905 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993847
I0824 17:10:01.624920 41289 solver.cpp:244]     Train net output #1: loss = 0.0178312 (* 1 = 0.0178312 loss)
I0824 17:10:01.624933 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989254
I0824 17:10:01.624938 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998065
I0824 17:10:01.624945 41289 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0824 17:10:18.284384 41289 solver.cpp:228] Iteration 4280, loss = 0.0190817
I0824 17:10:18.284474 41289 solver.cpp:244]     Train net output #0: accuracy = 0.99327
I0824 17:10:18.284489 41289 solver.cpp:244]     Train net output #1: loss = 0.0190819 (* 1 = 0.0190819 loss)
I0824 17:10:18.284499 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992664
I0824 17:10:18.284505 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994174
I0824 17:10:18.284512 41289 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0824 17:10:34.945860 41289 solver.cpp:228] Iteration 4300, loss = 0.0100988
I0824 17:10:34.945906 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995806
I0824 17:10:34.945919 41289 solver.cpp:244]     Train net output #1: loss = 0.010099 (* 1 = 0.010099 loss)
I0824 17:10:34.945926 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996225
I0824 17:10:34.945931 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994046
I0824 17:10:34.945938 41289 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0824 17:10:51.614531 41289 solver.cpp:228] Iteration 4320, loss = 0.0144879
I0824 17:10:51.614673 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993585
I0824 17:10:51.614691 41289 solver.cpp:244]     Train net output #1: loss = 0.0144881 (* 1 = 0.0144881 loss)
I0824 17:10:51.614699 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993152
I0824 17:10:51.614706 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995125
I0824 17:10:51.614713 41289 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0824 17:11:08.288957 41289 solver.cpp:228] Iteration 4340, loss = 0.0126697
I0824 17:11:08.289003 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995637
I0824 17:11:08.289016 41289 solver.cpp:244]     Train net output #1: loss = 0.0126699 (* 1 = 0.0126699 loss)
I0824 17:11:08.289021 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99615
I0824 17:11:08.289026 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994559
I0824 17:11:08.289034 41289 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0824 17:11:24.962570 41289 solver.cpp:228] Iteration 4360, loss = 0.0132318
I0824 17:11:24.962719 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994319
I0824 17:11:24.962757 41289 solver.cpp:244]     Train net output #1: loss = 0.013232 (* 1 = 0.013232 loss)
I0824 17:11:24.962765 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991228
I0824 17:11:24.962771 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998696
I0824 17:11:24.962779 41289 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0824 17:11:41.679251 41289 solver.cpp:228] Iteration 4380, loss = 0.0115837
I0824 17:11:41.679301 41289 solver.cpp:244]     Train net output #0: accuracy = 0.99627
I0824 17:11:41.679313 41289 solver.cpp:244]     Train net output #1: loss = 0.0115839 (* 1 = 0.0115839 loss)
I0824 17:11:41.679319 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998003
I0824 17:11:41.679324 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989013
I0824 17:11:41.679332 41289 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0824 17:11:58.352730 41289 solver.cpp:228] Iteration 4400, loss = 0.0160415
I0824 17:11:58.352829 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994154
I0824 17:11:58.352843 41289 solver.cpp:244]     Train net output #1: loss = 0.0160417 (* 1 = 0.0160417 loss)
I0824 17:11:58.352850 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994021
I0824 17:11:58.352854 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994343
I0824 17:11:58.352861 41289 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0824 17:12:14.982831 41289 solver.cpp:228] Iteration 4420, loss = 0.0151773
I0824 17:12:14.982873 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994602
I0824 17:12:14.982884 41289 solver.cpp:244]     Train net output #1: loss = 0.0151775 (* 1 = 0.0151775 loss)
I0824 17:12:14.982890 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995187
I0824 17:12:14.982895 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992895
I0824 17:12:14.982903 41289 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0824 17:12:31.623383 41289 solver.cpp:228] Iteration 4440, loss = 0.0120764
I0824 17:12:31.623523 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995797
I0824 17:12:31.623562 41289 solver.cpp:244]     Train net output #1: loss = 0.0120766 (* 1 = 0.0120766 loss)
I0824 17:12:31.623570 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993612
I0824 17:12:31.623575 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998252
I0824 17:12:31.623584 41289 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0824 17:12:48.342264 41289 solver.cpp:228] Iteration 4460, loss = 0.0109263
I0824 17:12:48.342314 41289 solver.cpp:244]     Train net output #0: accuracy = 0.996205
I0824 17:12:48.342329 41289 solver.cpp:244]     Train net output #1: loss = 0.0109265 (* 1 = 0.0109265 loss)
I0824 17:12:48.342335 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995037
I0824 17:12:48.342341 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997817
I0824 17:12:48.342357 41289 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0824 17:13:05.053292 41289 solver.cpp:228] Iteration 4480, loss = 0.0115737
I0824 17:13:05.053483 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995448
I0824 17:13:05.053499 41289 solver.cpp:244]     Train net output #1: loss = 0.0115739 (* 1 = 0.0115739 loss)
I0824 17:13:05.053505 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99498
I0824 17:13:05.053510 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996914
I0824 17:13:05.053517 41289 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0824 17:13:21.721400 41289 solver.cpp:228] Iteration 4500, loss = 0.0109486
I0824 17:13:21.721446 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995933
I0824 17:13:21.721457 41289 solver.cpp:244]     Train net output #1: loss = 0.0109488 (* 1 = 0.0109488 loss)
I0824 17:13:21.721463 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995103
I0824 17:13:21.721468 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997925
I0824 17:13:21.721475 41289 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0824 17:13:38.389833 41289 solver.cpp:228] Iteration 4520, loss = 0.0159479
I0824 17:13:38.389935 41289 solver.cpp:244]     Train net output #0: accuracy = 0.99349
I0824 17:13:38.389948 41289 solver.cpp:244]     Train net output #1: loss = 0.0159481 (* 1 = 0.0159481 loss)
I0824 17:13:38.389955 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992739
I0824 17:13:38.389961 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995477
I0824 17:13:38.389967 41289 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0824 17:13:55.042093 41289 solver.cpp:228] Iteration 4540, loss = 0.0176445
I0824 17:13:55.042140 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993442
I0824 17:13:55.042150 41289 solver.cpp:244]     Train net output #1: loss = 0.0176447 (* 1 = 0.0176447 loss)
I0824 17:13:55.042157 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993015
I0824 17:13:55.042161 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994474
I0824 17:13:55.042170 41289 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0824 17:14:11.687578 41289 solver.cpp:228] Iteration 4560, loss = 0.0145145
I0824 17:14:11.687664 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994761
I0824 17:14:11.687678 41289 solver.cpp:244]     Train net output #1: loss = 0.0145147 (* 1 = 0.0145147 loss)
I0824 17:14:11.687683 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99432
I0824 17:14:11.687688 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99549
I0824 17:14:11.687696 41289 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0824 17:14:28.330000 41289 solver.cpp:228] Iteration 4580, loss = 0.0135093
I0824 17:14:28.330046 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994201
I0824 17:14:28.330058 41289 solver.cpp:244]     Train net output #1: loss = 0.0135095 (* 1 = 0.0135095 loss)
I0824 17:14:28.330065 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992059
I0824 17:14:28.330068 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998065
I0824 17:14:28.330076 41289 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0824 17:14:44.995117 41289 solver.cpp:228] Iteration 4600, loss = 0.0197783
I0824 17:14:44.995291 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994155
I0824 17:14:44.995306 41289 solver.cpp:244]     Train net output #1: loss = 0.0197785 (* 1 = 0.0197785 loss)
I0824 17:14:44.995312 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991394
I0824 17:14:44.995317 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996447
I0824 17:14:44.995326 41289 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0824 17:15:01.664255 41289 solver.cpp:228] Iteration 4620, loss = 0.0128072
I0824 17:15:01.664301 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994497
I0824 17:15:01.664314 41289 solver.cpp:244]     Train net output #1: loss = 0.0128074 (* 1 = 0.0128074 loss)
I0824 17:15:01.664319 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993627
I0824 17:15:01.664332 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996757
I0824 17:15:01.664340 41289 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0824 17:15:18.323051 41289 solver.cpp:228] Iteration 4640, loss = 0.011613
I0824 17:15:18.323195 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995438
I0824 17:15:18.323233 41289 solver.cpp:244]     Train net output #1: loss = 0.0116132 (* 1 = 0.0116132 loss)
I0824 17:15:18.323241 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993655
I0824 17:15:18.323247 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998276
I0824 17:15:18.323256 41289 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0824 17:15:35.025341 41289 solver.cpp:228] Iteration 4660, loss = 0.00990288
I0824 17:15:35.025395 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995835
I0824 17:15:35.025408 41289 solver.cpp:244]     Train net output #1: loss = 0.00990308 (* 1 = 0.00990308 loss)
I0824 17:15:35.025413 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995855
I0824 17:15:35.025418 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99577
I0824 17:15:35.025426 41289 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0824 17:15:51.670707 41289 solver.cpp:228] Iteration 4680, loss = 0.0125601
I0824 17:15:51.670825 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995229
I0824 17:15:51.670840 41289 solver.cpp:244]     Train net output #1: loss = 0.0125603 (* 1 = 0.0125603 loss)
I0824 17:15:51.670845 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99395
I0824 17:15:51.670850 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997326
I0824 17:15:51.670857 41289 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0824 17:16:08.313971 41289 solver.cpp:228] Iteration 4700, loss = 0.0124286
I0824 17:16:08.314013 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995259
I0824 17:16:08.314024 41289 solver.cpp:244]     Train net output #1: loss = 0.0124288 (* 1 = 0.0124288 loss)
I0824 17:16:08.314030 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994141
I0824 17:16:08.314035 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997266
I0824 17:16:08.314043 41289 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0824 17:16:24.955108 41289 solver.cpp:228] Iteration 4720, loss = 0.00936111
I0824 17:16:24.955243 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995909
I0824 17:16:24.955257 41289 solver.cpp:244]     Train net output #1: loss = 0.0093613 (* 1 = 0.0093613 loss)
I0824 17:16:24.955263 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994729
I0824 17:16:24.955268 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998436
I0824 17:16:24.955276 41289 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0824 17:16:41.595923 41289 solver.cpp:228] Iteration 4740, loss = 0.00858209
I0824 17:16:41.595965 41289 solver.cpp:244]     Train net output #0: accuracy = 0.996304
I0824 17:16:41.595976 41289 solver.cpp:244]     Train net output #1: loss = 0.00858229 (* 1 = 0.00858229 loss)
I0824 17:16:41.595983 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996108
I0824 17:16:41.595988 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99699
I0824 17:16:41.595994 41289 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0824 17:16:58.234755 41289 solver.cpp:228] Iteration 4760, loss = 0.0146331
I0824 17:16:58.234939 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994249
I0824 17:16:58.234977 41289 solver.cpp:244]     Train net output #1: loss = 0.0146333 (* 1 = 0.0146333 loss)
I0824 17:16:58.234984 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993466
I0824 17:16:58.234989 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995661
I0824 17:16:58.234997 41289 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0824 17:17:14.894785 41289 solver.cpp:228] Iteration 4780, loss = 0.0154101
I0824 17:17:14.894831 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994083
I0824 17:17:14.894843 41289 solver.cpp:244]     Train net output #1: loss = 0.0154103 (* 1 = 0.0154103 loss)
I0824 17:17:14.894850 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993261
I0824 17:17:14.894855 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995664
I0824 17:17:14.894862 41289 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0824 17:17:31.552554 41289 solver.cpp:228] Iteration 4800, loss = 0.0142532
I0824 17:17:31.552712 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995299
I0824 17:17:31.552727 41289 solver.cpp:244]     Train net output #1: loss = 0.0142534 (* 1 = 0.0142534 loss)
I0824 17:17:31.552732 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994191
I0824 17:17:31.552738 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99676
I0824 17:17:31.552745 41289 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0824 17:17:48.188787 41289 solver.cpp:228] Iteration 4820, loss = 0.00839983
I0824 17:17:48.188830 41289 solver.cpp:244]     Train net output #0: accuracy = 0.996023
I0824 17:17:48.188843 41289 solver.cpp:244]     Train net output #1: loss = 0.00840002 (* 1 = 0.00840002 loss)
I0824 17:17:48.188848 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994835
I0824 17:17:48.188853 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998478
I0824 17:17:48.188861 41289 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0824 17:18:04.835402 41289 solver.cpp:228] Iteration 4840, loss = 0.00918337
I0824 17:18:04.835546 41289 solver.cpp:244]     Train net output #0: accuracy = 0.99553
I0824 17:18:04.835583 41289 solver.cpp:244]     Train net output #1: loss = 0.00918357 (* 1 = 0.00918357 loss)
I0824 17:18:04.835590 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993737
I0824 17:18:04.835595 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998542
I0824 17:18:04.835603 41289 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0824 17:18:21.537852 41289 solver.cpp:228] Iteration 4860, loss = 0.0128355
I0824 17:18:21.537900 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995545
I0824 17:18:21.537914 41289 solver.cpp:244]     Train net output #1: loss = 0.0128357 (* 1 = 0.0128357 loss)
I0824 17:18:21.537920 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995476
I0824 17:18:21.537925 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995657
I0824 17:18:21.537932 41289 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0824 17:18:38.261543 41289 solver.cpp:228] Iteration 4880, loss = 0.0163014
I0824 17:18:38.261646 41289 solver.cpp:244]     Train net output #0: accuracy = 0.994073
I0824 17:18:38.261662 41289 solver.cpp:244]     Train net output #1: loss = 0.0163016 (* 1 = 0.0163016 loss)
I0824 17:18:38.261673 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993666
I0824 17:18:38.261678 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994732
I0824 17:18:38.261687 41289 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0824 17:18:54.974493 41289 solver.cpp:228] Iteration 4900, loss = 0.0111407
I0824 17:18:54.974558 41289 solver.cpp:244]     Train net output #0: accuracy = 0.995009
I0824 17:18:54.974571 41289 solver.cpp:244]     Train net output #1: loss = 0.0111409 (* 1 = 0.0111409 loss)
I0824 17:18:54.974577 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993739
I0824 17:18:54.974582 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99697
I0824 17:18:54.974591 41289 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0824 17:19:11.688786 41289 solver.cpp:228] Iteration 4920, loss = 0.0110187
I0824 17:19:11.688930 41289 solver.cpp:244]     Train net output #0: accuracy = 0.996448
I0824 17:19:11.688966 41289 solver.cpp:244]     Train net output #1: loss = 0.0110189 (* 1 = 0.0110189 loss)
I0824 17:19:11.688973 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99499
I0824 17:19:11.688978 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997994
I0824 17:19:11.688987 41289 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0824 17:19:28.369621 41289 solver.cpp:228] Iteration 4940, loss = 0.00984608
I0824 17:19:28.369673 41289 solver.cpp:244]     Train net output #0: accuracy = 0.996107
I0824 17:19:28.369684 41289 solver.cpp:244]     Train net output #1: loss = 0.00984627 (* 1 = 0.00984627 loss)
I0824 17:19:28.369690 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995474
I0824 17:19:28.369695 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99707
I0824 17:19:28.369702 41289 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0824 17:19:45.035825 41289 solver.cpp:228] Iteration 4960, loss = 0.00923654
I0824 17:19:45.036020 41289 solver.cpp:244]     Train net output #0: accuracy = 0.996257
I0824 17:19:45.036033 41289 solver.cpp:244]     Train net output #1: loss = 0.00923674 (* 1 = 0.00923674 loss)
I0824 17:19:45.036039 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9964
I0824 17:19:45.036044 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995904
I0824 17:19:45.036052 41289 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0824 17:20:01.718267 41289 solver.cpp:228] Iteration 4980, loss = 0.0182439
I0824 17:20:01.718314 41289 solver.cpp:244]     Train net output #0: accuracy = 0.993657
I0824 17:20:01.718327 41289 solver.cpp:244]     Train net output #1: loss = 0.0182441 (* 1 = 0.0182441 loss)
I0824 17:20:01.718333 41289 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993499
I0824 17:20:01.718338 41289 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993962
I0824 17:20:01.718345 41289 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0824 17:20:18.001812 41289 solver.cpp:454] Snapshotting to binary proto file pocwisc1/training_iter_5000.caffemodel
I0824 17:20:18.873145 41289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc1/training_iter_5000.solverstate
I0824 17:20:19.459105 41289 solver.cpp:317] Iteration 5000, loss = 0.0136245
I0824 17:20:19.459152 41289 solver.cpp:322] Optimization Done.
I0824 17:20:19.459157 41289 caffe.cpp:254] Optimization Done.

2017-08-24 17:20:19,863 log.framework MainThread  INFO       caffe models found
pocwisc1/training_iter_5000.caffemodel
2017-08-24 17:20:19,863 log.framework MainThread  INFO       Caffe model found: pocwisc1/training_iter_5000.caffemodel
2017-08-24 17:20:22,603 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 17:20:22,840 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 17:20:23,047 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 17:20:23,257 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 17:20:23,460 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 17:20:23,660 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 17:20:23,814 log.framework MainThread  INFO       train file number: 35
2017-08-24 17:20:23,814 log.framework MainThread  INFO       test file number: 20
2017-08-24 17:20:23,814 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 17:20:23,814 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 17:20:23,815 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-08-24 17:20:23,815 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-08-24 17:20:23,815 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-08-24 17:20:23,816 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc2/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc2/training"
solver_mode: GPU

2017-08-24 17:20:23,816 log.framework MainThread  INFO       caffe training step
2017-08-24 17:20:23,817 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc2/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-08-24 18:29:48,874 log.framework MainThread  INFO       I0824 17:20:23.879555 41887 caffe.cpp:217] Using GPUs 0
I0824 17:20:23.891150 41887 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0824 17:20:24.419245 41887 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc2/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc2/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0824 17:20:24.419414 41887 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc2/caffe/model_segnet_final/train.prototxt
I0824 17:20:24.422224 41887 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc2/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 17:20:24.422731 41887 layer_factory.hpp:77] Creating layer data
I0824 17:20:24.422750 41887 net.cpp:100] Creating Layer data
I0824 17:20:24.422760 41887 net.cpp:408] data -> data
I0824 17:20:24.422791 41887 net.cpp:408] data -> label
I0824 17:20:24.422809 41887 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc2/HDF5Files/train_combined.txt
I0824 17:20:24.440610 41887 hdf5_data_layer.cpp:93] Number of HDF5 files: 35
I0824 17:20:24.441813 41887 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0824 17:20:24.533136 41887 net.cpp:150] Setting up data
I0824 17:20:24.533164 41887 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 17:20:24.533177 41887 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 17:20:24.533181 41887 net.cpp:165] Memory required for data: 24883200
I0824 17:20:24.533190 41887 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 17:20:24.533207 41887 net.cpp:100] Creating Layer label_data_1_split
I0824 17:20:24.533215 41887 net.cpp:434] label_data_1_split <- label
I0824 17:20:24.533232 41887 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 17:20:24.533244 41887 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 17:20:24.533285 41887 net.cpp:150] Setting up label_data_1_split
I0824 17:20:24.533293 41887 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 17:20:24.533299 41887 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 17:20:24.533303 41887 net.cpp:165] Memory required for data: 30412800
I0824 17:20:24.533306 41887 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 17:20:24.533325 41887 net.cpp:100] Creating Layer conv1_1_1
I0824 17:20:24.533331 41887 net.cpp:434] conv1_1_1 <- data
I0824 17:20:24.533337 41887 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 17:20:25.048282 41887 net.cpp:150] Setting up conv1_1_1
I0824 17:20:25.048321 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:25.048326 41887 net.cpp:165] Memory required for data: 207360000
I0824 17:20:25.048357 41887 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 17:20:25.048375 41887 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 17:20:25.048382 41887 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 17:20:25.048391 41887 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 17:20:25.048789 41887 net.cpp:150] Setting up conv1_1_1_bn
I0824 17:20:25.048799 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:25.048810 41887 net.cpp:165] Memory required for data: 384307200
I0824 17:20:25.048821 41887 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 17:20:25.048837 41887 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 17:20:25.048842 41887 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 17:20:25.048847 41887 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 17:20:25.048897 41887 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 17:20:25.050608 41887 net.cpp:150] Setting up conv1_1_1_scale
I0824 17:20:25.050624 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:25.050634 41887 net.cpp:165] Memory required for data: 561254400
I0824 17:20:25.050642 41887 layer_factory.hpp:77] Creating layer relu1_1
I0824 17:20:25.050655 41887 net.cpp:100] Creating Layer relu1_1
I0824 17:20:25.050660 41887 net.cpp:434] relu1_1 <- conv1_1_1
I0824 17:20:25.050667 41887 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 17:20:25.050891 41887 net.cpp:150] Setting up relu1_1
I0824 17:20:25.050901 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:25.050907 41887 net.cpp:165] Memory required for data: 738201600
I0824 17:20:25.050911 41887 layer_factory.hpp:77] Creating layer conv1_2
I0824 17:20:25.050925 41887 net.cpp:100] Creating Layer conv1_2
I0824 17:20:25.050930 41887 net.cpp:434] conv1_2 <- conv1_1_1
I0824 17:20:25.050936 41887 net.cpp:408] conv1_2 -> conv1_2
I0824 17:20:25.055200 41887 net.cpp:150] Setting up conv1_2
I0824 17:20:25.055217 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:25.055230 41887 net.cpp:165] Memory required for data: 915148800
I0824 17:20:25.055241 41887 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 17:20:25.055254 41887 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 17:20:25.055263 41887 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 17:20:25.055270 41887 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 17:20:25.056819 41887 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 17:20:25.056834 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:25.056843 41887 net.cpp:165] Memory required for data: 1092096000
I0824 17:20:25.056852 41887 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 17:20:25.056862 41887 net.cpp:100] Creating Layer conv1_2_scale
I0824 17:20:25.056867 41887 net.cpp:434] conv1_2_scale <- conv1_2
I0824 17:20:25.056874 41887 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 17:20:25.056915 41887 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 17:20:25.057286 41887 net.cpp:150] Setting up conv1_2_scale
I0824 17:20:25.057296 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:25.057298 41887 net.cpp:165] Memory required for data: 1269043200
I0824 17:20:25.057305 41887 layer_factory.hpp:77] Creating layer relu1_2
I0824 17:20:25.057317 41887 net.cpp:100] Creating Layer relu1_2
I0824 17:20:25.057320 41887 net.cpp:434] relu1_2 <- conv1_2
I0824 17:20:25.057325 41887 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 17:20:25.057528 41887 net.cpp:150] Setting up relu1_2
I0824 17:20:25.057538 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:25.057541 41887 net.cpp:165] Memory required for data: 1445990400
I0824 17:20:25.057544 41887 layer_factory.hpp:77] Creating layer pool1
I0824 17:20:25.057549 41887 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 17:20:25.057556 41887 net.cpp:100] Creating Layer pool1
I0824 17:20:25.057561 41887 net.cpp:434] pool1 <- conv1_2
I0824 17:20:25.057567 41887 net.cpp:408] pool1 -> pool1
I0824 17:20:25.057575 41887 net.cpp:408] pool1 -> pool1_mask
I0824 17:20:25.057629 41887 net.cpp:150] Setting up pool1
I0824 17:20:25.057636 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:25.057641 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:25.057643 41887 net.cpp:165] Memory required for data: 1534464000
I0824 17:20:25.057647 41887 layer_factory.hpp:77] Creating layer conv2_1
I0824 17:20:25.057657 41887 net.cpp:100] Creating Layer conv2_1
I0824 17:20:25.057662 41887 net.cpp:434] conv2_1 <- pool1
I0824 17:20:25.057668 41887 net.cpp:408] conv2_1 -> conv2_1
I0824 17:20:25.063761 41887 net.cpp:150] Setting up conv2_1
I0824 17:20:25.063778 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:25.063787 41887 net.cpp:165] Memory required for data: 1622937600
I0824 17:20:25.063796 41887 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 17:20:25.063807 41887 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 17:20:25.063814 41887 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 17:20:25.063820 41887 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 17:20:25.064047 41887 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 17:20:25.064056 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:25.064060 41887 net.cpp:165] Memory required for data: 1711411200
I0824 17:20:25.064074 41887 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 17:20:25.064095 41887 net.cpp:100] Creating Layer conv2_1_scale
I0824 17:20:25.064100 41887 net.cpp:434] conv2_1_scale <- conv2_1
I0824 17:20:25.064105 41887 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 17:20:25.064146 41887 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 17:20:25.064317 41887 net.cpp:150] Setting up conv2_1_scale
I0824 17:20:25.064327 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:25.064329 41887 net.cpp:165] Memory required for data: 1799884800
I0824 17:20:25.064337 41887 layer_factory.hpp:77] Creating layer relu2_1
I0824 17:20:25.064343 41887 net.cpp:100] Creating Layer relu2_1
I0824 17:20:25.064348 41887 net.cpp:434] relu2_1 <- conv2_1
I0824 17:20:25.064353 41887 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 17:20:25.065377 41887 net.cpp:150] Setting up relu2_1
I0824 17:20:25.065392 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:25.065397 41887 net.cpp:165] Memory required for data: 1888358400
I0824 17:20:25.065402 41887 layer_factory.hpp:77] Creating layer conv2_2
I0824 17:20:25.065414 41887 net.cpp:100] Creating Layer conv2_2
I0824 17:20:25.065421 41887 net.cpp:434] conv2_2 <- conv2_1
I0824 17:20:25.065428 41887 net.cpp:408] conv2_2 -> conv2_2
I0824 17:20:25.072736 41887 net.cpp:150] Setting up conv2_2
I0824 17:20:25.072752 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:25.072763 41887 net.cpp:165] Memory required for data: 1976832000
I0824 17:20:25.072772 41887 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 17:20:25.072783 41887 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 17:20:25.072790 41887 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 17:20:25.072796 41887 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 17:20:25.073027 41887 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 17:20:25.073035 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:25.073038 41887 net.cpp:165] Memory required for data: 2065305600
I0824 17:20:25.073048 41887 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 17:20:25.073060 41887 net.cpp:100] Creating Layer conv2_2_scale
I0824 17:20:25.073065 41887 net.cpp:434] conv2_2_scale <- conv2_2
I0824 17:20:25.073070 41887 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 17:20:25.073109 41887 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 17:20:25.073283 41887 net.cpp:150] Setting up conv2_2_scale
I0824 17:20:25.073292 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:25.073294 41887 net.cpp:165] Memory required for data: 2153779200
I0824 17:20:25.073302 41887 layer_factory.hpp:77] Creating layer relu2_2
I0824 17:20:25.073308 41887 net.cpp:100] Creating Layer relu2_2
I0824 17:20:25.073313 41887 net.cpp:434] relu2_2 <- conv2_2
I0824 17:20:25.073318 41887 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 17:20:25.073518 41887 net.cpp:150] Setting up relu2_2
I0824 17:20:25.073527 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:25.073531 41887 net.cpp:165] Memory required for data: 2242252800
I0824 17:20:25.073534 41887 layer_factory.hpp:77] Creating layer pool2
I0824 17:20:25.073542 41887 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 17:20:25.073547 41887 net.cpp:100] Creating Layer pool2
I0824 17:20:25.073552 41887 net.cpp:434] pool2 <- conv2_2
I0824 17:20:25.073557 41887 net.cpp:408] pool2 -> pool2
I0824 17:20:25.073565 41887 net.cpp:408] pool2 -> pool2_mask
I0824 17:20:25.073607 41887 net.cpp:150] Setting up pool2
I0824 17:20:25.073614 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:25.073618 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:25.073622 41887 net.cpp:165] Memory required for data: 2286489600
I0824 17:20:25.073626 41887 layer_factory.hpp:77] Creating layer conv3_1
I0824 17:20:25.073634 41887 net.cpp:100] Creating Layer conv3_1
I0824 17:20:25.073639 41887 net.cpp:434] conv3_1 <- pool2
I0824 17:20:25.073645 41887 net.cpp:408] conv3_1 -> conv3_1
I0824 17:20:25.085777 41887 net.cpp:150] Setting up conv3_1
I0824 17:20:25.085808 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.085816 41887 net.cpp:165] Memory required for data: 2330726400
I0824 17:20:25.085826 41887 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 17:20:25.085834 41887 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 17:20:25.085844 41887 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 17:20:25.085850 41887 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 17:20:25.086062 41887 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 17:20:25.086071 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.086073 41887 net.cpp:165] Memory required for data: 2374963200
I0824 17:20:25.086086 41887 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 17:20:25.086097 41887 net.cpp:100] Creating Layer conv3_1_scale
I0824 17:20:25.086100 41887 net.cpp:434] conv3_1_scale <- conv3_1
I0824 17:20:25.086105 41887 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 17:20:25.086145 41887 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 17:20:25.086277 41887 net.cpp:150] Setting up conv3_1_scale
I0824 17:20:25.086283 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.086287 41887 net.cpp:165] Memory required for data: 2419200000
I0824 17:20:25.086293 41887 layer_factory.hpp:77] Creating layer relu3_1
I0824 17:20:25.086300 41887 net.cpp:100] Creating Layer relu3_1
I0824 17:20:25.086307 41887 net.cpp:434] relu3_1 <- conv3_1
I0824 17:20:25.086311 41887 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 17:20:25.086501 41887 net.cpp:150] Setting up relu3_1
I0824 17:20:25.086509 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.086513 41887 net.cpp:165] Memory required for data: 2463436800
I0824 17:20:25.086518 41887 layer_factory.hpp:77] Creating layer conv3_2
I0824 17:20:25.086529 41887 net.cpp:100] Creating Layer conv3_2
I0824 17:20:25.086534 41887 net.cpp:434] conv3_2 <- conv3_1
I0824 17:20:25.086539 41887 net.cpp:408] conv3_2 -> conv3_2
I0824 17:20:25.109702 41887 net.cpp:150] Setting up conv3_2
I0824 17:20:25.109719 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.109730 41887 net.cpp:165] Memory required for data: 2507673600
I0824 17:20:25.109740 41887 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 17:20:25.109750 41887 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 17:20:25.109757 41887 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 17:20:25.109764 41887 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 17:20:25.109969 41887 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 17:20:25.109977 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.109982 41887 net.cpp:165] Memory required for data: 2551910400
I0824 17:20:25.109989 41887 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 17:20:25.109998 41887 net.cpp:100] Creating Layer conv3_2_scale
I0824 17:20:25.110008 41887 net.cpp:434] conv3_2_scale <- conv3_2
I0824 17:20:25.110013 41887 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 17:20:25.110050 41887 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 17:20:25.110184 41887 net.cpp:150] Setting up conv3_2_scale
I0824 17:20:25.110193 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.110195 41887 net.cpp:165] Memory required for data: 2596147200
I0824 17:20:25.110201 41887 layer_factory.hpp:77] Creating layer relu3_2
I0824 17:20:25.110208 41887 net.cpp:100] Creating Layer relu3_2
I0824 17:20:25.110213 41887 net.cpp:434] relu3_2 <- conv3_2
I0824 17:20:25.110216 41887 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 17:20:25.110410 41887 net.cpp:150] Setting up relu3_2
I0824 17:20:25.110420 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.110424 41887 net.cpp:165] Memory required for data: 2640384000
I0824 17:20:25.110427 41887 layer_factory.hpp:77] Creating layer conv3_3
I0824 17:20:25.110440 41887 net.cpp:100] Creating Layer conv3_3
I0824 17:20:25.110445 41887 net.cpp:434] conv3_3 <- conv3_2
I0824 17:20:25.110451 41887 net.cpp:408] conv3_3 -> conv3_3
I0824 17:20:25.133618 41887 net.cpp:150] Setting up conv3_3
I0824 17:20:25.133647 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.133657 41887 net.cpp:165] Memory required for data: 2684620800
I0824 17:20:25.133667 41887 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 17:20:25.133677 41887 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 17:20:25.133684 41887 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 17:20:25.133690 41887 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 17:20:25.133905 41887 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 17:20:25.133914 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.133918 41887 net.cpp:165] Memory required for data: 2728857600
I0824 17:20:25.133925 41887 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 17:20:25.133937 41887 net.cpp:100] Creating Layer conv3_3_scale
I0824 17:20:25.133942 41887 net.cpp:434] conv3_3_scale <- conv3_3
I0824 17:20:25.133947 41887 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 17:20:25.133986 41887 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 17:20:25.134121 41887 net.cpp:150] Setting up conv3_3_scale
I0824 17:20:25.134129 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.134131 41887 net.cpp:165] Memory required for data: 2773094400
I0824 17:20:25.134138 41887 layer_factory.hpp:77] Creating layer relu3_3
I0824 17:20:25.134145 41887 net.cpp:100] Creating Layer relu3_3
I0824 17:20:25.134150 41887 net.cpp:434] relu3_3 <- conv3_3
I0824 17:20:25.134155 41887 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 17:20:25.134352 41887 net.cpp:150] Setting up relu3_3
I0824 17:20:25.134361 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:25.134366 41887 net.cpp:165] Memory required for data: 2817331200
I0824 17:20:25.134368 41887 layer_factory.hpp:77] Creating layer pool3
I0824 17:20:25.134376 41887 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 17:20:25.134384 41887 net.cpp:100] Creating Layer pool3
I0824 17:20:25.134389 41887 net.cpp:434] pool3 <- conv3_3
I0824 17:20:25.134395 41887 net.cpp:408] pool3 -> pool3
I0824 17:20:25.134403 41887 net.cpp:408] pool3 -> pool3_mask
I0824 17:20:25.134449 41887 net.cpp:150] Setting up pool3
I0824 17:20:25.134455 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:25.134460 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:25.134465 41887 net.cpp:165] Memory required for data: 2839449600
I0824 17:20:25.134469 41887 layer_factory.hpp:77] Creating layer conv4_1
I0824 17:20:25.134479 41887 net.cpp:100] Creating Layer conv4_1
I0824 17:20:25.134483 41887 net.cpp:434] conv4_1 <- pool3
I0824 17:20:25.134490 41887 net.cpp:408] conv4_1 -> conv4_1
I0824 17:20:25.180536 41887 net.cpp:150] Setting up conv4_1
I0824 17:20:25.180554 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.180563 41887 net.cpp:165] Memory required for data: 2861568000
I0824 17:20:25.180572 41887 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 17:20:25.180583 41887 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 17:20:25.180590 41887 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 17:20:25.180596 41887 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 17:20:25.180814 41887 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 17:20:25.180822 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.180826 41887 net.cpp:165] Memory required for data: 2883686400
I0824 17:20:25.180835 41887 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 17:20:25.180845 41887 net.cpp:100] Creating Layer conv4_1_scale
I0824 17:20:25.180850 41887 net.cpp:434] conv4_1_scale <- conv4_1
I0824 17:20:25.180855 41887 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 17:20:25.180896 41887 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 17:20:25.181025 41887 net.cpp:150] Setting up conv4_1_scale
I0824 17:20:25.181033 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.181036 41887 net.cpp:165] Memory required for data: 2905804800
I0824 17:20:25.181042 41887 layer_factory.hpp:77] Creating layer relu4_1
I0824 17:20:25.181066 41887 net.cpp:100] Creating Layer relu4_1
I0824 17:20:25.181071 41887 net.cpp:434] relu4_1 <- conv4_1
I0824 17:20:25.181076 41887 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 17:20:25.181293 41887 net.cpp:150] Setting up relu4_1
I0824 17:20:25.181303 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.181309 41887 net.cpp:165] Memory required for data: 2927923200
I0824 17:20:25.181314 41887 layer_factory.hpp:77] Creating layer conv4_2
I0824 17:20:25.181325 41887 net.cpp:100] Creating Layer conv4_2
I0824 17:20:25.181330 41887 net.cpp:434] conv4_2 <- conv4_1
I0824 17:20:25.181339 41887 net.cpp:408] conv4_2 -> conv4_2
I0824 17:20:25.264746 41887 net.cpp:150] Setting up conv4_2
I0824 17:20:25.264765 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.264768 41887 net.cpp:165] Memory required for data: 2950041600
I0824 17:20:25.264776 41887 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 17:20:25.264788 41887 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 17:20:25.264798 41887 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 17:20:25.264804 41887 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 17:20:25.265022 41887 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 17:20:25.265029 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.265033 41887 net.cpp:165] Memory required for data: 2972160000
I0824 17:20:25.265040 41887 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 17:20:25.265048 41887 net.cpp:100] Creating Layer conv4_2_scale
I0824 17:20:25.265055 41887 net.cpp:434] conv4_2_scale <- conv4_2
I0824 17:20:25.265063 41887 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 17:20:25.265102 41887 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 17:20:25.265229 41887 net.cpp:150] Setting up conv4_2_scale
I0824 17:20:25.265238 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.265240 41887 net.cpp:165] Memory required for data: 2994278400
I0824 17:20:25.265247 41887 layer_factory.hpp:77] Creating layer relu4_2
I0824 17:20:25.265256 41887 net.cpp:100] Creating Layer relu4_2
I0824 17:20:25.265260 41887 net.cpp:434] relu4_2 <- conv4_2
I0824 17:20:25.265265 41887 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 17:20:25.266320 41887 net.cpp:150] Setting up relu4_2
I0824 17:20:25.266336 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.266340 41887 net.cpp:165] Memory required for data: 3016396800
I0824 17:20:25.266346 41887 layer_factory.hpp:77] Creating layer conv4_3
I0824 17:20:25.266366 41887 net.cpp:100] Creating Layer conv4_3
I0824 17:20:25.266372 41887 net.cpp:434] conv4_3 <- conv4_2
I0824 17:20:25.266379 41887 net.cpp:408] conv4_3 -> conv4_3
I0824 17:20:25.349755 41887 net.cpp:150] Setting up conv4_3
I0824 17:20:25.349773 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.349777 41887 net.cpp:165] Memory required for data: 3038515200
I0824 17:20:25.349802 41887 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 17:20:25.349810 41887 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 17:20:25.349819 41887 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 17:20:25.349828 41887 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 17:20:25.350047 41887 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 17:20:25.350055 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.350059 41887 net.cpp:165] Memory required for data: 3060633600
I0824 17:20:25.350067 41887 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 17:20:25.350073 41887 net.cpp:100] Creating Layer conv4_3_scale
I0824 17:20:25.350080 41887 net.cpp:434] conv4_3_scale <- conv4_3
I0824 17:20:25.350085 41887 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 17:20:25.350132 41887 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 17:20:25.350265 41887 net.cpp:150] Setting up conv4_3_scale
I0824 17:20:25.350271 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.350275 41887 net.cpp:165] Memory required for data: 3082752000
I0824 17:20:25.350281 41887 layer_factory.hpp:77] Creating layer relu4_3
I0824 17:20:25.350307 41887 net.cpp:100] Creating Layer relu4_3
I0824 17:20:25.350312 41887 net.cpp:434] relu4_3 <- conv4_3
I0824 17:20:25.350319 41887 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 17:20:25.350524 41887 net.cpp:150] Setting up relu4_3
I0824 17:20:25.350534 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.350538 41887 net.cpp:165] Memory required for data: 3104870400
I0824 17:20:25.350543 41887 layer_factory.hpp:77] Creating layer pool4
I0824 17:20:25.350549 41887 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 17:20:25.350555 41887 net.cpp:100] Creating Layer pool4
I0824 17:20:25.350560 41887 net.cpp:434] pool4 <- conv4_3
I0824 17:20:25.350567 41887 net.cpp:408] pool4 -> pool4
I0824 17:20:25.350576 41887 net.cpp:408] pool4 -> pool4_mask
I0824 17:20:25.350625 41887 net.cpp:150] Setting up pool4
I0824 17:20:25.350632 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.350636 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.350641 41887 net.cpp:165] Memory required for data: 3116175360
I0824 17:20:25.350643 41887 layer_factory.hpp:77] Creating layer conv5_1
I0824 17:20:25.350654 41887 net.cpp:100] Creating Layer conv5_1
I0824 17:20:25.350659 41887 net.cpp:434] conv5_1 <- pool4
I0824 17:20:25.350666 41887 net.cpp:408] conv5_1 -> conv5_1
I0824 17:20:25.434186 41887 net.cpp:150] Setting up conv5_1
I0824 17:20:25.434203 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.434208 41887 net.cpp:165] Memory required for data: 3121827840
I0824 17:20:25.434216 41887 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 17:20:25.434227 41887 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 17:20:25.434238 41887 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 17:20:25.434247 41887 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 17:20:25.434468 41887 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 17:20:25.434476 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.434480 41887 net.cpp:165] Memory required for data: 3127480320
I0824 17:20:25.434489 41887 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 17:20:25.434501 41887 net.cpp:100] Creating Layer conv5_1_scale
I0824 17:20:25.434509 41887 net.cpp:434] conv5_1_scale <- conv5_1
I0824 17:20:25.434514 41887 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 17:20:25.434558 41887 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 17:20:25.434681 41887 net.cpp:150] Setting up conv5_1_scale
I0824 17:20:25.434689 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.434691 41887 net.cpp:165] Memory required for data: 3133132800
I0824 17:20:25.434700 41887 layer_factory.hpp:77] Creating layer relu5_1
I0824 17:20:25.434706 41887 net.cpp:100] Creating Layer relu5_1
I0824 17:20:25.434711 41887 net.cpp:434] relu5_1 <- conv5_1
I0824 17:20:25.434716 41887 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 17:20:25.434922 41887 net.cpp:150] Setting up relu5_1
I0824 17:20:25.434931 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.434937 41887 net.cpp:165] Memory required for data: 3138785280
I0824 17:20:25.434940 41887 layer_factory.hpp:77] Creating layer conv5_2
I0824 17:20:25.434952 41887 net.cpp:100] Creating Layer conv5_2
I0824 17:20:25.434957 41887 net.cpp:434] conv5_2 <- conv5_1
I0824 17:20:25.434965 41887 net.cpp:408] conv5_2 -> conv5_2
I0824 17:20:25.518677 41887 net.cpp:150] Setting up conv5_2
I0824 17:20:25.518697 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.518702 41887 net.cpp:165] Memory required for data: 3144437760
I0824 17:20:25.518709 41887 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 17:20:25.518721 41887 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 17:20:25.518725 41887 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 17:20:25.518731 41887 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 17:20:25.518945 41887 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 17:20:25.518954 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.518975 41887 net.cpp:165] Memory required for data: 3150090240
I0824 17:20:25.518983 41887 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 17:20:25.518995 41887 net.cpp:100] Creating Layer conv5_2_scale
I0824 17:20:25.519001 41887 net.cpp:434] conv5_2_scale <- conv5_2
I0824 17:20:25.519006 41887 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 17:20:25.519059 41887 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 17:20:25.519183 41887 net.cpp:150] Setting up conv5_2_scale
I0824 17:20:25.519191 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.519194 41887 net.cpp:165] Memory required for data: 3155742720
I0824 17:20:25.519201 41887 layer_factory.hpp:77] Creating layer relu5_2
I0824 17:20:25.519208 41887 net.cpp:100] Creating Layer relu5_2
I0824 17:20:25.519213 41887 net.cpp:434] relu5_2 <- conv5_2
I0824 17:20:25.519220 41887 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 17:20:25.519421 41887 net.cpp:150] Setting up relu5_2
I0824 17:20:25.519431 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.519434 41887 net.cpp:165] Memory required for data: 3161395200
I0824 17:20:25.519438 41887 layer_factory.hpp:77] Creating layer conv5_3
I0824 17:20:25.519454 41887 net.cpp:100] Creating Layer conv5_3
I0824 17:20:25.519460 41887 net.cpp:434] conv5_3 <- conv5_2
I0824 17:20:25.519466 41887 net.cpp:408] conv5_3 -> conv5_3
I0824 17:20:25.603282 41887 net.cpp:150] Setting up conv5_3
I0824 17:20:25.603307 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.603315 41887 net.cpp:165] Memory required for data: 3167047680
I0824 17:20:25.603328 41887 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 17:20:25.603341 41887 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 17:20:25.603349 41887 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 17:20:25.603365 41887 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 17:20:25.603644 41887 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 17:20:25.603657 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.603664 41887 net.cpp:165] Memory required for data: 3172700160
I0824 17:20:25.603677 41887 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 17:20:25.603690 41887 net.cpp:100] Creating Layer conv5_3_scale
I0824 17:20:25.603698 41887 net.cpp:434] conv5_3_scale <- conv5_3
I0824 17:20:25.603708 41887 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 17:20:25.603770 41887 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 17:20:25.603924 41887 net.cpp:150] Setting up conv5_3_scale
I0824 17:20:25.603934 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.603940 41887 net.cpp:165] Memory required for data: 3178352640
I0824 17:20:25.603950 41887 layer_factory.hpp:77] Creating layer relu5_3
I0824 17:20:25.603963 41887 net.cpp:100] Creating Layer relu5_3
I0824 17:20:25.603971 41887 net.cpp:434] relu5_3 <- conv5_3
I0824 17:20:25.603981 41887 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 17:20:25.604240 41887 net.cpp:150] Setting up relu5_3
I0824 17:20:25.604252 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.604259 41887 net.cpp:165] Memory required for data: 3184005120
I0824 17:20:25.604265 41887 layer_factory.hpp:77] Creating layer pool5
I0824 17:20:25.604274 41887 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 17:20:25.604285 41887 net.cpp:100] Creating Layer pool5
I0824 17:20:25.604291 41887 net.cpp:434] pool5 <- conv5_3
I0824 17:20:25.604303 41887 net.cpp:408] pool5 -> pool5
I0824 17:20:25.604315 41887 net.cpp:408] pool5 -> pool5_mask
I0824 17:20:25.604380 41887 net.cpp:150] Setting up pool5
I0824 17:20:25.604393 41887 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 17:20:25.604401 41887 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 17:20:25.604408 41887 net.cpp:165] Memory required for data: 3186954240
I0824 17:20:25.604415 41887 layer_factory.hpp:77] Creating layer upsample5
I0824 17:20:25.604431 41887 net.cpp:100] Creating Layer upsample5
I0824 17:20:25.604439 41887 net.cpp:434] upsample5 <- pool5
I0824 17:20:25.604463 41887 net.cpp:434] upsample5 <- pool5_mask
I0824 17:20:25.604473 41887 net.cpp:408] upsample5 -> pool5_D
I0824 17:20:25.604522 41887 net.cpp:150] Setting up upsample5
I0824 17:20:25.604532 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.604539 41887 net.cpp:165] Memory required for data: 3192606720
I0824 17:20:25.604547 41887 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 17:20:25.604563 41887 net.cpp:100] Creating Layer conv5_3_D
I0824 17:20:25.604571 41887 net.cpp:434] conv5_3_D <- pool5_D
I0824 17:20:25.604584 41887 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 17:20:25.688968 41887 net.cpp:150] Setting up conv5_3_D
I0824 17:20:25.688987 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.688997 41887 net.cpp:165] Memory required for data: 3198259200
I0824 17:20:25.689005 41887 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 17:20:25.689016 41887 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 17:20:25.689024 41887 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 17:20:25.689033 41887 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 17:20:25.689260 41887 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 17:20:25.689268 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.689271 41887 net.cpp:165] Memory required for data: 3203911680
I0824 17:20:25.689280 41887 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 17:20:25.689286 41887 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 17:20:25.689293 41887 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 17:20:25.689298 41887 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 17:20:25.689345 41887 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 17:20:25.689481 41887 net.cpp:150] Setting up conv5_3_D_scale
I0824 17:20:25.689489 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.689492 41887 net.cpp:165] Memory required for data: 3209564160
I0824 17:20:25.689499 41887 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 17:20:25.689507 41887 net.cpp:100] Creating Layer relu5_3_D
I0824 17:20:25.689512 41887 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 17:20:25.689518 41887 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 17:20:25.689729 41887 net.cpp:150] Setting up relu5_3_D
I0824 17:20:25.689738 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.689743 41887 net.cpp:165] Memory required for data: 3215216640
I0824 17:20:25.689749 41887 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 17:20:25.689771 41887 net.cpp:100] Creating Layer conv5_2_D
I0824 17:20:25.689776 41887 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 17:20:25.689786 41887 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 17:20:25.773411 41887 net.cpp:150] Setting up conv5_2_D
I0824 17:20:25.773427 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.773432 41887 net.cpp:165] Memory required for data: 3220869120
I0824 17:20:25.773440 41887 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 17:20:25.773449 41887 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 17:20:25.773461 41887 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 17:20:25.773468 41887 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 17:20:25.773694 41887 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 17:20:25.773702 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.773705 41887 net.cpp:165] Memory required for data: 3226521600
I0824 17:20:25.773720 41887 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 17:20:25.773731 41887 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 17:20:25.773739 41887 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 17:20:25.773744 41887 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 17:20:25.773792 41887 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 17:20:25.773918 41887 net.cpp:150] Setting up conv5_2_D_scale
I0824 17:20:25.773926 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.773929 41887 net.cpp:165] Memory required for data: 3232174080
I0824 17:20:25.773952 41887 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 17:20:25.773959 41887 net.cpp:100] Creating Layer relu5_2_D
I0824 17:20:25.773963 41887 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 17:20:25.773969 41887 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 17:20:25.775048 41887 net.cpp:150] Setting up relu5_2_D
I0824 17:20:25.775063 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.775068 41887 net.cpp:165] Memory required for data: 3237826560
I0824 17:20:25.775072 41887 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 17:20:25.775087 41887 net.cpp:100] Creating Layer conv5_1_D
I0824 17:20:25.775094 41887 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 17:20:25.775102 41887 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 17:20:25.858642 41887 net.cpp:150] Setting up conv5_1_D
I0824 17:20:25.858660 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.858664 41887 net.cpp:165] Memory required for data: 3243479040
I0824 17:20:25.858672 41887 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 17:20:25.858681 41887 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 17:20:25.858686 41887 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 17:20:25.858695 41887 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 17:20:25.858922 41887 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 17:20:25.858932 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.858934 41887 net.cpp:165] Memory required for data: 3249131520
I0824 17:20:25.858942 41887 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 17:20:25.858952 41887 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 17:20:25.858959 41887 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 17:20:25.858966 41887 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 17:20:25.859017 41887 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 17:20:25.859146 41887 net.cpp:150] Setting up conv5_1_D_scale
I0824 17:20:25.859153 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.859158 41887 net.cpp:165] Memory required for data: 3254784000
I0824 17:20:25.859163 41887 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 17:20:25.859170 41887 net.cpp:100] Creating Layer relu5_1_D
I0824 17:20:25.859174 41887 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 17:20:25.859179 41887 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 17:20:25.859385 41887 net.cpp:150] Setting up relu5_1_D
I0824 17:20:25.859395 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:25.859400 41887 net.cpp:165] Memory required for data: 3260436480
I0824 17:20:25.859402 41887 layer_factory.hpp:77] Creating layer upsample4
I0824 17:20:25.859411 41887 net.cpp:100] Creating Layer upsample4
I0824 17:20:25.859416 41887 net.cpp:434] upsample4 <- conv5_1_D
I0824 17:20:25.859422 41887 net.cpp:434] upsample4 <- pool4_mask
I0824 17:20:25.859431 41887 net.cpp:408] upsample4 -> pool4_D
I0824 17:20:25.859463 41887 net.cpp:150] Setting up upsample4
I0824 17:20:25.859472 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.859477 41887 net.cpp:165] Memory required for data: 3282554880
I0824 17:20:25.859480 41887 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 17:20:25.859493 41887 net.cpp:100] Creating Layer conv4_3_D
I0824 17:20:25.859498 41887 net.cpp:434] conv4_3_D <- pool4_D
I0824 17:20:25.859503 41887 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 17:20:25.943089 41887 net.cpp:150] Setting up conv4_3_D
I0824 17:20:25.943107 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.943111 41887 net.cpp:165] Memory required for data: 3304673280
I0824 17:20:25.943120 41887 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 17:20:25.943130 41887 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 17:20:25.943135 41887 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 17:20:25.943140 41887 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 17:20:25.943374 41887 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 17:20:25.943383 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.943403 41887 net.cpp:165] Memory required for data: 3326791680
I0824 17:20:25.943413 41887 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 17:20:25.943428 41887 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 17:20:25.943434 41887 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 17:20:25.943440 41887 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 17:20:25.943490 41887 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 17:20:25.943634 41887 net.cpp:150] Setting up conv4_3_D_scale
I0824 17:20:25.943641 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.943645 41887 net.cpp:165] Memory required for data: 3348910080
I0824 17:20:25.943650 41887 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 17:20:25.943665 41887 net.cpp:100] Creating Layer relu4_3_D
I0824 17:20:25.943670 41887 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 17:20:25.943675 41887 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 17:20:25.943874 41887 net.cpp:150] Setting up relu4_3_D
I0824 17:20:25.943884 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:25.943889 41887 net.cpp:165] Memory required for data: 3371028480
I0824 17:20:25.943892 41887 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 17:20:25.943907 41887 net.cpp:100] Creating Layer conv4_2_D
I0824 17:20:25.943912 41887 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 17:20:25.943919 41887 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 17:20:26.029198 41887 net.cpp:150] Setting up conv4_2_D
I0824 17:20:26.029219 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.029232 41887 net.cpp:165] Memory required for data: 3393146880
I0824 17:20:26.029244 41887 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 17:20:26.029256 41887 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 17:20:26.029268 41887 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 17:20:26.029278 41887 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 17:20:26.029523 41887 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 17:20:26.029531 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.029536 41887 net.cpp:165] Memory required for data: 3415265280
I0824 17:20:26.029543 41887 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 17:20:26.029553 41887 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 17:20:26.029558 41887 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 17:20:26.029564 41887 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 17:20:26.029610 41887 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 17:20:26.029753 41887 net.cpp:150] Setting up conv4_2_D_scale
I0824 17:20:26.029760 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.029764 41887 net.cpp:165] Memory required for data: 3437383680
I0824 17:20:26.029770 41887 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 17:20:26.029779 41887 net.cpp:100] Creating Layer relu4_2_D
I0824 17:20:26.029784 41887 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 17:20:26.029791 41887 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 17:20:26.029997 41887 net.cpp:150] Setting up relu4_2_D
I0824 17:20:26.030006 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.030010 41887 net.cpp:165] Memory required for data: 3459502080
I0824 17:20:26.030014 41887 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 17:20:26.030027 41887 net.cpp:100] Creating Layer conv4_1_D
I0824 17:20:26.030033 41887 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 17:20:26.030041 41887 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 17:20:26.073791 41887 net.cpp:150] Setting up conv4_1_D
I0824 17:20:26.073808 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:26.073819 41887 net.cpp:165] Memory required for data: 3470561280
I0824 17:20:26.073829 41887 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 17:20:26.073838 41887 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 17:20:26.073848 41887 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 17:20:26.073853 41887 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 17:20:26.074103 41887 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 17:20:26.074126 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:26.074136 41887 net.cpp:165] Memory required for data: 3481620480
I0824 17:20:26.074170 41887 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 17:20:26.074180 41887 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 17:20:26.074185 41887 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 17:20:26.074192 41887 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 17:20:26.074244 41887 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 17:20:26.074383 41887 net.cpp:150] Setting up conv4_1_D_scale
I0824 17:20:26.074389 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:26.074393 41887 net.cpp:165] Memory required for data: 3492679680
I0824 17:20:26.074403 41887 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 17:20:26.074409 41887 net.cpp:100] Creating Layer relu4_1_D
I0824 17:20:26.074414 41887 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 17:20:26.074420 41887 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 17:20:26.074637 41887 net.cpp:150] Setting up relu4_1_D
I0824 17:20:26.074646 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:26.074651 41887 net.cpp:165] Memory required for data: 3503738880
I0824 17:20:26.074656 41887 layer_factory.hpp:77] Creating layer upsample3
I0824 17:20:26.074666 41887 net.cpp:100] Creating Layer upsample3
I0824 17:20:26.074671 41887 net.cpp:434] upsample3 <- conv4_1_D
I0824 17:20:26.074677 41887 net.cpp:434] upsample3 <- pool3_mask
I0824 17:20:26.074684 41887 net.cpp:408] upsample3 -> pool3_D
I0824 17:20:26.074692 41887 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 17:20:26.074725 41887 net.cpp:150] Setting up upsample3
I0824 17:20:26.074733 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.074735 41887 net.cpp:165] Memory required for data: 3547975680
I0824 17:20:26.074738 41887 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 17:20:26.074751 41887 net.cpp:100] Creating Layer conv3_3_D
I0824 17:20:26.074756 41887 net.cpp:434] conv3_3_D <- pool3_D
I0824 17:20:26.074767 41887 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 17:20:26.098162 41887 net.cpp:150] Setting up conv3_3_D
I0824 17:20:26.098179 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.098189 41887 net.cpp:165] Memory required for data: 3592212480
I0824 17:20:26.098198 41887 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 17:20:26.098207 41887 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 17:20:26.098217 41887 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 17:20:26.098224 41887 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 17:20:26.098482 41887 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 17:20:26.098490 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.098495 41887 net.cpp:165] Memory required for data: 3636449280
I0824 17:20:26.098510 41887 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 17:20:26.098516 41887 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 17:20:26.098521 41887 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 17:20:26.098526 41887 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 17:20:26.098575 41887 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 17:20:26.098737 41887 net.cpp:150] Setting up conv3_3_D_scale
I0824 17:20:26.098744 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.098747 41887 net.cpp:165] Memory required for data: 3680686080
I0824 17:20:26.098754 41887 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 17:20:26.098762 41887 net.cpp:100] Creating Layer relu3_3_D
I0824 17:20:26.098768 41887 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 17:20:26.098773 41887 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 17:20:26.098989 41887 net.cpp:150] Setting up relu3_3_D
I0824 17:20:26.098999 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.099004 41887 net.cpp:165] Memory required for data: 3724922880
I0824 17:20:26.099022 41887 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 17:20:26.099037 41887 net.cpp:100] Creating Layer conv3_2_D
I0824 17:20:26.099043 41887 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 17:20:26.099051 41887 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 17:20:26.122453 41887 net.cpp:150] Setting up conv3_2_D
I0824 17:20:26.122470 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.122480 41887 net.cpp:165] Memory required for data: 3769159680
I0824 17:20:26.122491 41887 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 17:20:26.122500 41887 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 17:20:26.122509 41887 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 17:20:26.122514 41887 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 17:20:26.122776 41887 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 17:20:26.122786 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.122788 41887 net.cpp:165] Memory required for data: 3813396480
I0824 17:20:26.122798 41887 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 17:20:26.122810 41887 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 17:20:26.122815 41887 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 17:20:26.122820 41887 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 17:20:26.122870 41887 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 17:20:26.123030 41887 net.cpp:150] Setting up conv3_2_D_scale
I0824 17:20:26.123039 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.123041 41887 net.cpp:165] Memory required for data: 3857633280
I0824 17:20:26.123049 41887 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 17:20:26.123059 41887 net.cpp:100] Creating Layer relu3_2_D
I0824 17:20:26.123064 41887 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 17:20:26.123067 41887 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 17:20:26.124156 41887 net.cpp:150] Setting up relu3_2_D
I0824 17:20:26.124172 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.124177 41887 net.cpp:165] Memory required for data: 3901870080
I0824 17:20:26.124182 41887 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 17:20:26.124197 41887 net.cpp:100] Creating Layer conv3_1_D
I0824 17:20:26.124202 41887 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 17:20:26.124209 41887 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 17:20:26.137903 41887 net.cpp:150] Setting up conv3_1_D
I0824 17:20:26.137920 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:26.137930 41887 net.cpp:165] Memory required for data: 3923988480
I0824 17:20:26.137938 41887 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 17:20:26.137948 41887 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 17:20:26.137958 41887 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 17:20:26.137965 41887 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 17:20:26.138226 41887 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 17:20:26.138234 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:26.138237 41887 net.cpp:165] Memory required for data: 3946106880
I0824 17:20:26.138247 41887 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 17:20:26.138259 41887 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 17:20:26.138264 41887 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 17:20:26.138269 41887 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 17:20:26.138319 41887 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 17:20:26.138483 41887 net.cpp:150] Setting up conv3_1_D_scale
I0824 17:20:26.138490 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:26.138494 41887 net.cpp:165] Memory required for data: 3968225280
I0824 17:20:26.138500 41887 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 17:20:26.138509 41887 net.cpp:100] Creating Layer relu3_1_D
I0824 17:20:26.138514 41887 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 17:20:26.138520 41887 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 17:20:26.138738 41887 net.cpp:150] Setting up relu3_1_D
I0824 17:20:26.138766 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:26.138770 41887 net.cpp:165] Memory required for data: 3990343680
I0824 17:20:26.138774 41887 layer_factory.hpp:77] Creating layer upsample2
I0824 17:20:26.138783 41887 net.cpp:100] Creating Layer upsample2
I0824 17:20:26.138788 41887 net.cpp:434] upsample2 <- conv3_1_D
I0824 17:20:26.138794 41887 net.cpp:434] upsample2 <- pool2_mask
I0824 17:20:26.138801 41887 net.cpp:408] upsample2 -> pool2_D
I0824 17:20:26.138808 41887 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 17:20:26.138842 41887 net.cpp:150] Setting up upsample2
I0824 17:20:26.138850 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.138854 41887 net.cpp:165] Memory required for data: 4078817280
I0824 17:20:26.138857 41887 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 17:20:26.138870 41887 net.cpp:100] Creating Layer conv2_2_D
I0824 17:20:26.138875 41887 net.cpp:434] conv2_2_D <- pool2_D
I0824 17:20:26.138883 41887 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 17:20:26.146515 41887 net.cpp:150] Setting up conv2_2_D
I0824 17:20:26.146534 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.146543 41887 net.cpp:165] Memory required for data: 4167290880
I0824 17:20:26.146553 41887 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 17:20:26.146561 41887 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 17:20:26.146569 41887 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 17:20:26.146577 41887 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 17:20:26.146878 41887 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 17:20:26.146888 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.146890 41887 net.cpp:165] Memory required for data: 4255764480
I0824 17:20:26.146898 41887 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 17:20:26.146905 41887 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 17:20:26.146914 41887 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 17:20:26.146919 41887 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 17:20:26.146968 41887 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 17:20:26.148448 41887 net.cpp:150] Setting up conv2_2_D_scale
I0824 17:20:26.148463 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.148471 41887 net.cpp:165] Memory required for data: 4344238080
I0824 17:20:26.148478 41887 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 17:20:26.148488 41887 net.cpp:100] Creating Layer relu2_2_D
I0824 17:20:26.148492 41887 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 17:20:26.148500 41887 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 17:20:26.148732 41887 net.cpp:150] Setting up relu2_2_D
I0824 17:20:26.148742 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.148746 41887 net.cpp:165] Memory required for data: 4432711680
I0824 17:20:26.148751 41887 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 17:20:26.148764 41887 net.cpp:100] Creating Layer conv2_1_D
I0824 17:20:26.148771 41887 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 17:20:26.148780 41887 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 17:20:26.154008 41887 net.cpp:150] Setting up conv2_1_D
I0824 17:20:26.154026 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:26.154034 41887 net.cpp:165] Memory required for data: 4476948480
I0824 17:20:26.154045 41887 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 17:20:26.154058 41887 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 17:20:26.154067 41887 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 17:20:26.154073 41887 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 17:20:26.154371 41887 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 17:20:26.154379 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:26.154384 41887 net.cpp:165] Memory required for data: 4521185280
I0824 17:20:26.154392 41887 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 17:20:26.154413 41887 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 17:20:26.154419 41887 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 17:20:26.154424 41887 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 17:20:26.154481 41887 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 17:20:26.154700 41887 net.cpp:150] Setting up conv2_1_D_scale
I0824 17:20:26.154708 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:26.154711 41887 net.cpp:165] Memory required for data: 4565422080
I0824 17:20:26.154718 41887 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 17:20:26.154726 41887 net.cpp:100] Creating Layer relu2_1_D
I0824 17:20:26.154731 41887 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 17:20:26.154738 41887 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 17:20:26.154968 41887 net.cpp:150] Setting up relu2_1_D
I0824 17:20:26.154978 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:26.154983 41887 net.cpp:165] Memory required for data: 4609658880
I0824 17:20:26.154985 41887 layer_factory.hpp:77] Creating layer upsample1
I0824 17:20:26.154992 41887 net.cpp:100] Creating Layer upsample1
I0824 17:20:26.154997 41887 net.cpp:434] upsample1 <- conv2_1_D
I0824 17:20:26.155002 41887 net.cpp:434] upsample1 <- pool1_mask
I0824 17:20:26.155010 41887 net.cpp:408] upsample1 -> pool1_D
I0824 17:20:26.155019 41887 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 17:20:26.155053 41887 net.cpp:150] Setting up upsample1
I0824 17:20:26.155061 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.155063 41887 net.cpp:165] Memory required for data: 4786606080
I0824 17:20:26.155068 41887 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 17:20:26.155079 41887 net.cpp:100] Creating Layer conv1_2_D
I0824 17:20:26.155084 41887 net.cpp:434] conv1_2_D <- pool1_D
I0824 17:20:26.155092 41887 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 17:20:26.159597 41887 net.cpp:150] Setting up conv1_2_D
I0824 17:20:26.159615 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.159623 41887 net.cpp:165] Memory required for data: 4963553280
I0824 17:20:26.159631 41887 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 17:20:26.159643 41887 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 17:20:26.159649 41887 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 17:20:26.159656 41887 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 17:20:26.160048 41887 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 17:20:26.160058 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.160060 41887 net.cpp:165] Memory required for data: 5140500480
I0824 17:20:26.160071 41887 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 17:20:26.160079 41887 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 17:20:26.160084 41887 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 17:20:26.160089 41887 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 17:20:26.160140 41887 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 17:20:26.161867 41887 net.cpp:150] Setting up conv1_2_D_scale
I0824 17:20:26.161883 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.161888 41887 net.cpp:165] Memory required for data: 5317447680
I0824 17:20:26.161896 41887 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 17:20:26.161905 41887 net.cpp:100] Creating Layer relu1_2_D
I0824 17:20:26.161909 41887 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 17:20:26.161916 41887 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 17:20:26.162151 41887 net.cpp:150] Setting up relu1_2_D
I0824 17:20:26.162161 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.162166 41887 net.cpp:165] Memory required for data: 5494394880
I0824 17:20:26.162173 41887 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 17:20:26.162186 41887 net.cpp:100] Creating Layer conv1_1_1_D
I0824 17:20:26.162191 41887 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 17:20:26.162214 41887 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 17:20:26.164268 41887 net.cpp:150] Setting up conv1_1_1_D
I0824 17:20:26.164283 41887 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 17:20:26.164288 41887 net.cpp:165] Memory required for data: 5499924480
I0824 17:20:26.164295 41887 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 17:20:26.164304 41887 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 17:20:26.164309 41887 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 17:20:26.164317 41887 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 17:20:26.164327 41887 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 17:20:26.164381 41887 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 17:20:26.164388 41887 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 17:20:26.164392 41887 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 17:20:26.164396 41887 net.cpp:165] Memory required for data: 5510983680
I0824 17:20:26.164400 41887 layer_factory.hpp:77] Creating layer loss
I0824 17:20:26.164415 41887 net.cpp:100] Creating Layer loss
I0824 17:20:26.164422 41887 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 17:20:26.164427 41887 net.cpp:434] loss <- label_data_1_split_0
I0824 17:20:26.164433 41887 net.cpp:408] loss -> loss
I0824 17:20:26.164450 41887 layer_factory.hpp:77] Creating layer loss
I0824 17:20:26.168560 41887 net.cpp:150] Setting up loss
I0824 17:20:26.168575 41887 net.cpp:157] Top shape: (1)
I0824 17:20:26.168584 41887 net.cpp:160]     with loss weight 1
I0824 17:20:26.168622 41887 net.cpp:165] Memory required for data: 5510983684
I0824 17:20:26.168627 41887 layer_factory.hpp:77] Creating layer accuracy
I0824 17:20:26.168635 41887 net.cpp:100] Creating Layer accuracy
I0824 17:20:26.168642 41887 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 17:20:26.168647 41887 net.cpp:434] accuracy <- label_data_1_split_1
I0824 17:20:26.168655 41887 net.cpp:408] accuracy -> accuracy
I0824 17:20:26.168664 41887 net.cpp:408] accuracy -> per_class_accuracy
I0824 17:20:26.168720 41887 net.cpp:150] Setting up accuracy
I0824 17:20:26.168727 41887 net.cpp:157] Top shape: (1)
I0824 17:20:26.168731 41887 net.cpp:157] Top shape: 2 (2)
I0824 17:20:26.168736 41887 net.cpp:165] Memory required for data: 5510983696
I0824 17:20:26.168740 41887 net.cpp:228] accuracy does not need backward computation.
I0824 17:20:26.168745 41887 net.cpp:226] loss needs backward computation.
I0824 17:20:26.168748 41887 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 17:20:26.168752 41887 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 17:20:26.168756 41887 net.cpp:226] relu1_2_D needs backward computation.
I0824 17:20:26.168759 41887 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 17:20:26.168762 41887 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 17:20:26.168766 41887 net.cpp:226] conv1_2_D needs backward computation.
I0824 17:20:26.168769 41887 net.cpp:226] upsample1 needs backward computation.
I0824 17:20:26.168772 41887 net.cpp:226] relu2_1_D needs backward computation.
I0824 17:20:26.168776 41887 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 17:20:26.168779 41887 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 17:20:26.168781 41887 net.cpp:226] conv2_1_D needs backward computation.
I0824 17:20:26.168786 41887 net.cpp:226] relu2_2_D needs backward computation.
I0824 17:20:26.168788 41887 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 17:20:26.168792 41887 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 17:20:26.168794 41887 net.cpp:226] conv2_2_D needs backward computation.
I0824 17:20:26.168797 41887 net.cpp:226] upsample2 needs backward computation.
I0824 17:20:26.168802 41887 net.cpp:226] relu3_1_D needs backward computation.
I0824 17:20:26.168804 41887 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 17:20:26.168823 41887 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 17:20:26.168825 41887 net.cpp:226] conv3_1_D needs backward computation.
I0824 17:20:26.168829 41887 net.cpp:226] relu3_2_D needs backward computation.
I0824 17:20:26.168833 41887 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 17:20:26.168835 41887 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 17:20:26.168838 41887 net.cpp:226] conv3_2_D needs backward computation.
I0824 17:20:26.168841 41887 net.cpp:226] relu3_3_D needs backward computation.
I0824 17:20:26.168844 41887 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 17:20:26.168848 41887 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 17:20:26.168850 41887 net.cpp:226] conv3_3_D needs backward computation.
I0824 17:20:26.168854 41887 net.cpp:226] upsample3 needs backward computation.
I0824 17:20:26.168859 41887 net.cpp:226] relu4_1_D needs backward computation.
I0824 17:20:26.168861 41887 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 17:20:26.168866 41887 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 17:20:26.168869 41887 net.cpp:226] conv4_1_D needs backward computation.
I0824 17:20:26.168874 41887 net.cpp:226] relu4_2_D needs backward computation.
I0824 17:20:26.168876 41887 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 17:20:26.168880 41887 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 17:20:26.168884 41887 net.cpp:226] conv4_2_D needs backward computation.
I0824 17:20:26.168889 41887 net.cpp:226] relu4_3_D needs backward computation.
I0824 17:20:26.168891 41887 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 17:20:26.168895 41887 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 17:20:26.168900 41887 net.cpp:226] conv4_3_D needs backward computation.
I0824 17:20:26.168903 41887 net.cpp:226] upsample4 needs backward computation.
I0824 17:20:26.168908 41887 net.cpp:226] relu5_1_D needs backward computation.
I0824 17:20:26.168913 41887 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 17:20:26.168916 41887 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 17:20:26.168920 41887 net.cpp:226] conv5_1_D needs backward computation.
I0824 17:20:26.168925 41887 net.cpp:226] relu5_2_D needs backward computation.
I0824 17:20:26.168928 41887 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 17:20:26.168933 41887 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 17:20:26.168936 41887 net.cpp:226] conv5_2_D needs backward computation.
I0824 17:20:26.168941 41887 net.cpp:226] relu5_3_D needs backward computation.
I0824 17:20:26.168944 41887 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 17:20:26.168948 41887 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 17:20:26.168951 41887 net.cpp:226] conv5_3_D needs backward computation.
I0824 17:20:26.168956 41887 net.cpp:226] upsample5 needs backward computation.
I0824 17:20:26.168962 41887 net.cpp:226] pool5 needs backward computation.
I0824 17:20:26.168968 41887 net.cpp:226] relu5_3 needs backward computation.
I0824 17:20:26.168972 41887 net.cpp:226] conv5_3_scale needs backward computation.
I0824 17:20:26.168975 41887 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 17:20:26.168979 41887 net.cpp:226] conv5_3 needs backward computation.
I0824 17:20:26.168982 41887 net.cpp:226] relu5_2 needs backward computation.
I0824 17:20:26.168987 41887 net.cpp:226] conv5_2_scale needs backward computation.
I0824 17:20:26.168990 41887 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 17:20:26.168993 41887 net.cpp:226] conv5_2 needs backward computation.
I0824 17:20:26.168998 41887 net.cpp:226] relu5_1 needs backward computation.
I0824 17:20:26.169000 41887 net.cpp:226] conv5_1_scale needs backward computation.
I0824 17:20:26.169003 41887 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 17:20:26.169008 41887 net.cpp:226] conv5_1 needs backward computation.
I0824 17:20:26.169011 41887 net.cpp:226] pool4 needs backward computation.
I0824 17:20:26.169023 41887 net.cpp:226] relu4_3 needs backward computation.
I0824 17:20:26.169028 41887 net.cpp:226] conv4_3_scale needs backward computation.
I0824 17:20:26.169030 41887 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 17:20:26.169034 41887 net.cpp:226] conv4_3 needs backward computation.
I0824 17:20:26.169037 41887 net.cpp:226] relu4_2 needs backward computation.
I0824 17:20:26.169040 41887 net.cpp:226] conv4_2_scale needs backward computation.
I0824 17:20:26.169044 41887 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 17:20:26.169046 41887 net.cpp:226] conv4_2 needs backward computation.
I0824 17:20:26.169050 41887 net.cpp:226] relu4_1 needs backward computation.
I0824 17:20:26.169055 41887 net.cpp:226] conv4_1_scale needs backward computation.
I0824 17:20:26.169059 41887 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 17:20:26.169061 41887 net.cpp:226] conv4_1 needs backward computation.
I0824 17:20:26.169065 41887 net.cpp:226] pool3 needs backward computation.
I0824 17:20:26.169068 41887 net.cpp:226] relu3_3 needs backward computation.
I0824 17:20:26.169071 41887 net.cpp:226] conv3_3_scale needs backward computation.
I0824 17:20:26.169075 41887 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 17:20:26.169078 41887 net.cpp:226] conv3_3 needs backward computation.
I0824 17:20:26.169081 41887 net.cpp:226] relu3_2 needs backward computation.
I0824 17:20:26.169085 41887 net.cpp:226] conv3_2_scale needs backward computation.
I0824 17:20:26.169088 41887 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 17:20:26.169091 41887 net.cpp:226] conv3_2 needs backward computation.
I0824 17:20:26.169095 41887 net.cpp:226] relu3_1 needs backward computation.
I0824 17:20:26.169098 41887 net.cpp:226] conv3_1_scale needs backward computation.
I0824 17:20:26.169103 41887 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 17:20:26.169106 41887 net.cpp:226] conv3_1 needs backward computation.
I0824 17:20:26.169109 41887 net.cpp:226] pool2 needs backward computation.
I0824 17:20:26.169113 41887 net.cpp:226] relu2_2 needs backward computation.
I0824 17:20:26.169117 41887 net.cpp:226] conv2_2_scale needs backward computation.
I0824 17:20:26.169121 41887 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 17:20:26.169123 41887 net.cpp:226] conv2_2 needs backward computation.
I0824 17:20:26.169127 41887 net.cpp:226] relu2_1 needs backward computation.
I0824 17:20:26.169131 41887 net.cpp:226] conv2_1_scale needs backward computation.
I0824 17:20:26.169136 41887 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 17:20:26.169138 41887 net.cpp:226] conv2_1 needs backward computation.
I0824 17:20:26.169142 41887 net.cpp:226] pool1 needs backward computation.
I0824 17:20:26.169145 41887 net.cpp:226] relu1_2 needs backward computation.
I0824 17:20:26.169149 41887 net.cpp:226] conv1_2_scale needs backward computation.
I0824 17:20:26.169152 41887 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 17:20:26.169157 41887 net.cpp:226] conv1_2 needs backward computation.
I0824 17:20:26.169159 41887 net.cpp:226] relu1_1 needs backward computation.
I0824 17:20:26.169163 41887 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 17:20:26.169167 41887 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 17:20:26.169169 41887 net.cpp:226] conv1_1_1 needs backward computation.
I0824 17:20:26.169173 41887 net.cpp:228] label_data_1_split does not need backward computation.
I0824 17:20:26.169178 41887 net.cpp:228] data does not need backward computation.
I0824 17:20:26.169183 41887 net.cpp:270] This network produces output accuracy
I0824 17:20:26.169188 41887 net.cpp:270] This network produces output loss
I0824 17:20:26.169191 41887 net.cpp:270] This network produces output per_class_accuracy
I0824 17:20:26.169255 41887 net.cpp:283] Network initialization done.
I0824 17:20:26.171612 41887 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc2/caffe/model_segnet_final/train.prototxt
I0824 17:20:26.172298 41887 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc2/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 17:20:26.172713 41887 layer_factory.hpp:77] Creating layer data
I0824 17:20:26.172724 41887 net.cpp:100] Creating Layer data
I0824 17:20:26.172730 41887 net.cpp:408] data -> data
I0824 17:20:26.172739 41887 net.cpp:408] data -> label
I0824 17:20:26.172747 41887 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc2/HDF5Files/train_combined.txt
I0824 17:20:26.172791 41887 hdf5_data_layer.cpp:93] Number of HDF5 files: 35
I0824 17:20:26.260179 41887 net.cpp:150] Setting up data
I0824 17:20:26.260197 41887 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 17:20:26.260203 41887 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 17:20:26.260206 41887 net.cpp:165] Memory required for data: 24883200
I0824 17:20:26.260211 41887 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 17:20:26.260226 41887 net.cpp:100] Creating Layer label_data_1_split
I0824 17:20:26.260232 41887 net.cpp:434] label_data_1_split <- label
I0824 17:20:26.260239 41887 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 17:20:26.260252 41887 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 17:20:26.260299 41887 net.cpp:150] Setting up label_data_1_split
I0824 17:20:26.260308 41887 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 17:20:26.260311 41887 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 17:20:26.260314 41887 net.cpp:165] Memory required for data: 30412800
I0824 17:20:26.260318 41887 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 17:20:26.260329 41887 net.cpp:100] Creating Layer conv1_1_1
I0824 17:20:26.260334 41887 net.cpp:434] conv1_1_1 <- data
I0824 17:20:26.260339 41887 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 17:20:26.263810 41887 net.cpp:150] Setting up conv1_1_1
I0824 17:20:26.263828 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.263836 41887 net.cpp:165] Memory required for data: 207360000
I0824 17:20:26.263849 41887 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 17:20:26.263857 41887 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 17:20:26.263865 41887 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 17:20:26.263871 41887 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 17:20:26.264257 41887 net.cpp:150] Setting up conv1_1_1_bn
I0824 17:20:26.264266 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.264271 41887 net.cpp:165] Memory required for data: 384307200
I0824 17:20:26.264282 41887 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 17:20:26.264292 41887 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 17:20:26.264295 41887 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 17:20:26.264300 41887 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 17:20:26.264351 41887 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 17:20:26.266032 41887 net.cpp:150] Setting up conv1_1_1_scale
I0824 17:20:26.266047 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.266052 41887 net.cpp:165] Memory required for data: 561254400
I0824 17:20:26.266062 41887 layer_factory.hpp:77] Creating layer relu1_1
I0824 17:20:26.266069 41887 net.cpp:100] Creating Layer relu1_1
I0824 17:20:26.266074 41887 net.cpp:434] relu1_1 <- conv1_1_1
I0824 17:20:26.266080 41887 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 17:20:26.266299 41887 net.cpp:150] Setting up relu1_1
I0824 17:20:26.266309 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.266314 41887 net.cpp:165] Memory required for data: 738201600
I0824 17:20:26.266317 41887 layer_factory.hpp:77] Creating layer conv1_2
I0824 17:20:26.266327 41887 net.cpp:100] Creating Layer conv1_2
I0824 17:20:26.266332 41887 net.cpp:434] conv1_2 <- conv1_1_1
I0824 17:20:26.266338 41887 net.cpp:408] conv1_2 -> conv1_2
I0824 17:20:26.270436 41887 net.cpp:150] Setting up conv1_2
I0824 17:20:26.270452 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.270459 41887 net.cpp:165] Memory required for data: 915148800
I0824 17:20:26.270488 41887 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 17:20:26.270499 41887 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 17:20:26.270504 41887 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 17:20:26.270510 41887 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 17:20:26.270891 41887 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 17:20:26.270900 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.270903 41887 net.cpp:165] Memory required for data: 1092096000
I0824 17:20:26.270911 41887 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 17:20:26.270920 41887 net.cpp:100] Creating Layer conv1_2_scale
I0824 17:20:26.270925 41887 net.cpp:434] conv1_2_scale <- conv1_2
I0824 17:20:26.270929 41887 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 17:20:26.270979 41887 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 17:20:26.272677 41887 net.cpp:150] Setting up conv1_2_scale
I0824 17:20:26.272692 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.272696 41887 net.cpp:165] Memory required for data: 1269043200
I0824 17:20:26.272704 41887 layer_factory.hpp:77] Creating layer relu1_2
I0824 17:20:26.272712 41887 net.cpp:100] Creating Layer relu1_2
I0824 17:20:26.272717 41887 net.cpp:434] relu1_2 <- conv1_2
I0824 17:20:26.272722 41887 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 17:20:26.273846 41887 net.cpp:150] Setting up relu1_2
I0824 17:20:26.273861 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:26.273866 41887 net.cpp:165] Memory required for data: 1445990400
I0824 17:20:26.273870 41887 layer_factory.hpp:77] Creating layer pool1
I0824 17:20:26.273875 41887 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 17:20:26.273882 41887 net.cpp:100] Creating Layer pool1
I0824 17:20:26.273887 41887 net.cpp:434] pool1 <- conv1_2
I0824 17:20:26.273896 41887 net.cpp:408] pool1 -> pool1
I0824 17:20:26.273905 41887 net.cpp:408] pool1 -> pool1_mask
I0824 17:20:26.273963 41887 net.cpp:150] Setting up pool1
I0824 17:20:26.273970 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:26.273975 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:26.273979 41887 net.cpp:165] Memory required for data: 1534464000
I0824 17:20:26.273983 41887 layer_factory.hpp:77] Creating layer conv2_1
I0824 17:20:26.273994 41887 net.cpp:100] Creating Layer conv2_1
I0824 17:20:26.273999 41887 net.cpp:434] conv2_1 <- pool1
I0824 17:20:26.274005 41887 net.cpp:408] conv2_1 -> conv2_1
I0824 17:20:26.278343 41887 net.cpp:150] Setting up conv2_1
I0824 17:20:26.278360 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.278369 41887 net.cpp:165] Memory required for data: 1622937600
I0824 17:20:26.278378 41887 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 17:20:26.278388 41887 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 17:20:26.278394 41887 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 17:20:26.278403 41887 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 17:20:26.278714 41887 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 17:20:26.278723 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.278726 41887 net.cpp:165] Memory required for data: 1711411200
I0824 17:20:26.278740 41887 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 17:20:26.278748 41887 net.cpp:100] Creating Layer conv2_1_scale
I0824 17:20:26.278753 41887 net.cpp:434] conv2_1_scale <- conv2_1
I0824 17:20:26.278759 41887 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 17:20:26.278810 41887 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 17:20:26.279050 41887 net.cpp:150] Setting up conv2_1_scale
I0824 17:20:26.279058 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.279062 41887 net.cpp:165] Memory required for data: 1799884800
I0824 17:20:26.279068 41887 layer_factory.hpp:77] Creating layer relu2_1
I0824 17:20:26.279078 41887 net.cpp:100] Creating Layer relu2_1
I0824 17:20:26.279083 41887 net.cpp:434] relu2_1 <- conv2_1
I0824 17:20:26.279088 41887 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 17:20:26.280222 41887 net.cpp:150] Setting up relu2_1
I0824 17:20:26.280239 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.280244 41887 net.cpp:165] Memory required for data: 1888358400
I0824 17:20:26.280248 41887 layer_factory.hpp:77] Creating layer conv2_2
I0824 17:20:26.280261 41887 net.cpp:100] Creating Layer conv2_2
I0824 17:20:26.280267 41887 net.cpp:434] conv2_2 <- conv2_1
I0824 17:20:26.280273 41887 net.cpp:408] conv2_2 -> conv2_2
I0824 17:20:26.289340 41887 net.cpp:150] Setting up conv2_2
I0824 17:20:26.289356 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.289373 41887 net.cpp:165] Memory required for data: 1976832000
I0824 17:20:26.289387 41887 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 17:20:26.289403 41887 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 17:20:26.289408 41887 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 17:20:26.289414 41887 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 17:20:26.291004 41887 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 17:20:26.291019 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.291028 41887 net.cpp:165] Memory required for data: 2065305600
I0824 17:20:26.291038 41887 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 17:20:26.291049 41887 net.cpp:100] Creating Layer conv2_2_scale
I0824 17:20:26.291055 41887 net.cpp:434] conv2_2_scale <- conv2_2
I0824 17:20:26.291060 41887 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 17:20:26.291117 41887 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 17:20:26.291333 41887 net.cpp:150] Setting up conv2_2_scale
I0824 17:20:26.291342 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.291345 41887 net.cpp:165] Memory required for data: 2153779200
I0824 17:20:26.291352 41887 layer_factory.hpp:77] Creating layer relu2_2
I0824 17:20:26.291362 41887 net.cpp:100] Creating Layer relu2_2
I0824 17:20:26.291366 41887 net.cpp:434] relu2_2 <- conv2_2
I0824 17:20:26.291371 41887 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 17:20:26.291599 41887 net.cpp:150] Setting up relu2_2
I0824 17:20:26.291609 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:26.291613 41887 net.cpp:165] Memory required for data: 2242252800
I0824 17:20:26.291617 41887 layer_factory.hpp:77] Creating layer pool2
I0824 17:20:26.291621 41887 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 17:20:26.291628 41887 net.cpp:100] Creating Layer pool2
I0824 17:20:26.291633 41887 net.cpp:434] pool2 <- conv2_2
I0824 17:20:26.291638 41887 net.cpp:408] pool2 -> pool2
I0824 17:20:26.291649 41887 net.cpp:408] pool2 -> pool2_mask
I0824 17:20:26.291705 41887 net.cpp:150] Setting up pool2
I0824 17:20:26.291712 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:26.291718 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:26.291721 41887 net.cpp:165] Memory required for data: 2286489600
I0824 17:20:26.291724 41887 layer_factory.hpp:77] Creating layer conv3_1
I0824 17:20:26.291736 41887 net.cpp:100] Creating Layer conv3_1
I0824 17:20:26.291740 41887 net.cpp:434] conv3_1 <- pool2
I0824 17:20:26.291749 41887 net.cpp:408] conv3_1 -> conv3_1
I0824 17:20:26.304268 41887 net.cpp:150] Setting up conv3_1
I0824 17:20:26.304285 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.304293 41887 net.cpp:165] Memory required for data: 2330726400
I0824 17:20:26.304301 41887 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 17:20:26.304311 41887 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 17:20:26.304321 41887 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 17:20:26.304328 41887 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 17:20:26.304616 41887 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 17:20:26.304625 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.304628 41887 net.cpp:165] Memory required for data: 2374963200
I0824 17:20:26.304641 41887 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 17:20:26.304664 41887 net.cpp:100] Creating Layer conv3_1_scale
I0824 17:20:26.304669 41887 net.cpp:434] conv3_1_scale <- conv3_1
I0824 17:20:26.304675 41887 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 17:20:26.304729 41887 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 17:20:26.304906 41887 net.cpp:150] Setting up conv3_1_scale
I0824 17:20:26.304914 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.304918 41887 net.cpp:165] Memory required for data: 2419200000
I0824 17:20:26.304924 41887 layer_factory.hpp:77] Creating layer relu3_1
I0824 17:20:26.304931 41887 net.cpp:100] Creating Layer relu3_1
I0824 17:20:26.304935 41887 net.cpp:434] relu3_1 <- conv3_1
I0824 17:20:26.304942 41887 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 17:20:26.305171 41887 net.cpp:150] Setting up relu3_1
I0824 17:20:26.305179 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.305184 41887 net.cpp:165] Memory required for data: 2463436800
I0824 17:20:26.305188 41887 layer_factory.hpp:77] Creating layer conv3_2
I0824 17:20:26.305199 41887 net.cpp:100] Creating Layer conv3_2
I0824 17:20:26.305203 41887 net.cpp:434] conv3_2 <- conv3_1
I0824 17:20:26.305212 41887 net.cpp:408] conv3_2 -> conv3_2
I0824 17:20:26.328819 41887 net.cpp:150] Setting up conv3_2
I0824 17:20:26.328836 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.328847 41887 net.cpp:165] Memory required for data: 2507673600
I0824 17:20:26.328855 41887 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 17:20:26.328866 41887 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 17:20:26.328874 41887 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 17:20:26.328881 41887 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 17:20:26.329169 41887 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 17:20:26.329177 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.329180 41887 net.cpp:165] Memory required for data: 2551910400
I0824 17:20:26.329195 41887 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 17:20:26.329202 41887 net.cpp:100] Creating Layer conv3_2_scale
I0824 17:20:26.329207 41887 net.cpp:434] conv3_2_scale <- conv3_2
I0824 17:20:26.329215 41887 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 17:20:26.329265 41887 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 17:20:26.329453 41887 net.cpp:150] Setting up conv3_2_scale
I0824 17:20:26.329464 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.329468 41887 net.cpp:165] Memory required for data: 2596147200
I0824 17:20:26.329475 41887 layer_factory.hpp:77] Creating layer relu3_2
I0824 17:20:26.329483 41887 net.cpp:100] Creating Layer relu3_2
I0824 17:20:26.329488 41887 net.cpp:434] relu3_2 <- conv3_2
I0824 17:20:26.329493 41887 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 17:20:26.329720 41887 net.cpp:150] Setting up relu3_2
I0824 17:20:26.329732 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.329736 41887 net.cpp:165] Memory required for data: 2640384000
I0824 17:20:26.329741 41887 layer_factory.hpp:77] Creating layer conv3_3
I0824 17:20:26.329752 41887 net.cpp:100] Creating Layer conv3_3
I0824 17:20:26.329757 41887 net.cpp:434] conv3_3 <- conv3_2
I0824 17:20:26.329763 41887 net.cpp:408] conv3_3 -> conv3_3
I0824 17:20:26.353305 41887 net.cpp:150] Setting up conv3_3
I0824 17:20:26.353322 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.353332 41887 net.cpp:165] Memory required for data: 2684620800
I0824 17:20:26.353343 41887 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 17:20:26.353351 41887 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 17:20:26.353359 41887 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 17:20:26.353371 41887 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 17:20:26.353652 41887 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 17:20:26.353662 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.353664 41887 net.cpp:165] Memory required for data: 2728857600
I0824 17:20:26.353673 41887 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 17:20:26.353695 41887 net.cpp:100] Creating Layer conv3_3_scale
I0824 17:20:26.353704 41887 net.cpp:434] conv3_3_scale <- conv3_3
I0824 17:20:26.353709 41887 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 17:20:26.353765 41887 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 17:20:26.353943 41887 net.cpp:150] Setting up conv3_3_scale
I0824 17:20:26.353951 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.353955 41887 net.cpp:165] Memory required for data: 2773094400
I0824 17:20:26.353961 41887 layer_factory.hpp:77] Creating layer relu3_3
I0824 17:20:26.353971 41887 net.cpp:100] Creating Layer relu3_3
I0824 17:20:26.353976 41887 net.cpp:434] relu3_3 <- conv3_3
I0824 17:20:26.353981 41887 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 17:20:26.354208 41887 net.cpp:150] Setting up relu3_3
I0824 17:20:26.354218 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:26.354223 41887 net.cpp:165] Memory required for data: 2817331200
I0824 17:20:26.354226 41887 layer_factory.hpp:77] Creating layer pool3
I0824 17:20:26.354230 41887 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 17:20:26.354240 41887 net.cpp:100] Creating Layer pool3
I0824 17:20:26.354245 41887 net.cpp:434] pool3 <- conv3_3
I0824 17:20:26.354251 41887 net.cpp:408] pool3 -> pool3
I0824 17:20:26.354260 41887 net.cpp:408] pool3 -> pool3_mask
I0824 17:20:26.354318 41887 net.cpp:150] Setting up pool3
I0824 17:20:26.354326 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:26.354331 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:26.354334 41887 net.cpp:165] Memory required for data: 2839449600
I0824 17:20:26.354337 41887 layer_factory.hpp:77] Creating layer conv4_1
I0824 17:20:26.354349 41887 net.cpp:100] Creating Layer conv4_1
I0824 17:20:26.354354 41887 net.cpp:434] conv4_1 <- pool3
I0824 17:20:26.354363 41887 net.cpp:408] conv4_1 -> conv4_1
I0824 17:20:26.398283 41887 net.cpp:150] Setting up conv4_1
I0824 17:20:26.398300 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.398310 41887 net.cpp:165] Memory required for data: 2861568000
I0824 17:20:26.398319 41887 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 17:20:26.398330 41887 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 17:20:26.398337 41887 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 17:20:26.398344 41887 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 17:20:26.398624 41887 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 17:20:26.398633 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.398643 41887 net.cpp:165] Memory required for data: 2883686400
I0824 17:20:26.398651 41887 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 17:20:26.398659 41887 net.cpp:100] Creating Layer conv4_1_scale
I0824 17:20:26.398664 41887 net.cpp:434] conv4_1_scale <- conv4_1
I0824 17:20:26.398669 41887 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 17:20:26.398718 41887 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 17:20:26.398881 41887 net.cpp:150] Setting up conv4_1_scale
I0824 17:20:26.398890 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.398892 41887 net.cpp:165] Memory required for data: 2905804800
I0824 17:20:26.398900 41887 layer_factory.hpp:77] Creating layer relu4_1
I0824 17:20:26.398908 41887 net.cpp:100] Creating Layer relu4_1
I0824 17:20:26.398913 41887 net.cpp:434] relu4_1 <- conv4_1
I0824 17:20:26.398917 41887 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 17:20:26.400056 41887 net.cpp:150] Setting up relu4_1
I0824 17:20:26.400071 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.400075 41887 net.cpp:165] Memory required for data: 2927923200
I0824 17:20:26.400080 41887 layer_factory.hpp:77] Creating layer conv4_2
I0824 17:20:26.400092 41887 net.cpp:100] Creating Layer conv4_2
I0824 17:20:26.400099 41887 net.cpp:434] conv4_2 <- conv4_1
I0824 17:20:26.400107 41887 net.cpp:408] conv4_2 -> conv4_2
I0824 17:20:26.482910 41887 net.cpp:150] Setting up conv4_2
I0824 17:20:26.482941 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.482946 41887 net.cpp:165] Memory required for data: 2950041600
I0824 17:20:26.482954 41887 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 17:20:26.482964 41887 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 17:20:26.482972 41887 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 17:20:26.482978 41887 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 17:20:26.483254 41887 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 17:20:26.483263 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.483266 41887 net.cpp:165] Memory required for data: 2972160000
I0824 17:20:26.483274 41887 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 17:20:26.483286 41887 net.cpp:100] Creating Layer conv4_2_scale
I0824 17:20:26.483290 41887 net.cpp:434] conv4_2_scale <- conv4_2
I0824 17:20:26.483297 41887 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 17:20:26.483346 41887 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 17:20:26.483511 41887 net.cpp:150] Setting up conv4_2_scale
I0824 17:20:26.483518 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.483522 41887 net.cpp:165] Memory required for data: 2994278400
I0824 17:20:26.483528 41887 layer_factory.hpp:77] Creating layer relu4_2
I0824 17:20:26.483536 41887 net.cpp:100] Creating Layer relu4_2
I0824 17:20:26.483541 41887 net.cpp:434] relu4_2 <- conv4_2
I0824 17:20:26.483544 41887 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 17:20:26.484709 41887 net.cpp:150] Setting up relu4_2
I0824 17:20:26.484722 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.484727 41887 net.cpp:165] Memory required for data: 3016396800
I0824 17:20:26.484731 41887 layer_factory.hpp:77] Creating layer conv4_3
I0824 17:20:26.484745 41887 net.cpp:100] Creating Layer conv4_3
I0824 17:20:26.484750 41887 net.cpp:434] conv4_3 <- conv4_2
I0824 17:20:26.484760 41887 net.cpp:408] conv4_3 -> conv4_3
I0824 17:20:26.568521 41887 net.cpp:150] Setting up conv4_3
I0824 17:20:26.568537 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.568542 41887 net.cpp:165] Memory required for data: 3038515200
I0824 17:20:26.568565 41887 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 17:20:26.568574 41887 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 17:20:26.568583 41887 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 17:20:26.568591 41887 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 17:20:26.568868 41887 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 17:20:26.568876 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.568879 41887 net.cpp:165] Memory required for data: 3060633600
I0824 17:20:26.568888 41887 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 17:20:26.568897 41887 net.cpp:100] Creating Layer conv4_3_scale
I0824 17:20:26.568907 41887 net.cpp:434] conv4_3_scale <- conv4_3
I0824 17:20:26.568912 41887 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 17:20:26.568969 41887 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 17:20:26.569133 41887 net.cpp:150] Setting up conv4_3_scale
I0824 17:20:26.569140 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.569144 41887 net.cpp:165] Memory required for data: 3082752000
I0824 17:20:26.569149 41887 layer_factory.hpp:77] Creating layer relu4_3
I0824 17:20:26.569156 41887 net.cpp:100] Creating Layer relu4_3
I0824 17:20:26.569161 41887 net.cpp:434] relu4_3 <- conv4_3
I0824 17:20:26.569169 41887 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 17:20:26.569396 41887 net.cpp:150] Setting up relu4_3
I0824 17:20:26.569406 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:26.569409 41887 net.cpp:165] Memory required for data: 3104870400
I0824 17:20:26.569413 41887 layer_factory.hpp:77] Creating layer pool4
I0824 17:20:26.569418 41887 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 17:20:26.569424 41887 net.cpp:100] Creating Layer pool4
I0824 17:20:26.569429 41887 net.cpp:434] pool4 <- conv4_3
I0824 17:20:26.569452 41887 net.cpp:408] pool4 -> pool4
I0824 17:20:26.569460 41887 net.cpp:408] pool4 -> pool4_mask
I0824 17:20:26.569521 41887 net.cpp:150] Setting up pool4
I0824 17:20:26.569528 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.569533 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.569537 41887 net.cpp:165] Memory required for data: 3116175360
I0824 17:20:26.569540 41887 layer_factory.hpp:77] Creating layer conv5_1
I0824 17:20:26.569551 41887 net.cpp:100] Creating Layer conv5_1
I0824 17:20:26.569556 41887 net.cpp:434] conv5_1 <- pool4
I0824 17:20:26.569566 41887 net.cpp:408] conv5_1 -> conv5_1
I0824 17:20:26.653252 41887 net.cpp:150] Setting up conv5_1
I0824 17:20:26.653270 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.653273 41887 net.cpp:165] Memory required for data: 3121827840
I0824 17:20:26.653281 41887 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 17:20:26.653290 41887 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 17:20:26.653302 41887 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 17:20:26.653311 41887 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 17:20:26.653594 41887 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 17:20:26.653604 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.653606 41887 net.cpp:165] Memory required for data: 3127480320
I0824 17:20:26.653615 41887 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 17:20:26.653623 41887 net.cpp:100] Creating Layer conv5_1_scale
I0824 17:20:26.653631 41887 net.cpp:434] conv5_1_scale <- conv5_1
I0824 17:20:26.653636 41887 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 17:20:26.653698 41887 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 17:20:26.653851 41887 net.cpp:150] Setting up conv5_1_scale
I0824 17:20:26.653857 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.653861 41887 net.cpp:165] Memory required for data: 3133132800
I0824 17:20:26.653867 41887 layer_factory.hpp:77] Creating layer relu5_1
I0824 17:20:26.653874 41887 net.cpp:100] Creating Layer relu5_1
I0824 17:20:26.653879 41887 net.cpp:434] relu5_1 <- conv5_1
I0824 17:20:26.653887 41887 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 17:20:26.654103 41887 net.cpp:150] Setting up relu5_1
I0824 17:20:26.654112 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.654116 41887 net.cpp:165] Memory required for data: 3138785280
I0824 17:20:26.654120 41887 layer_factory.hpp:77] Creating layer conv5_2
I0824 17:20:26.654131 41887 net.cpp:100] Creating Layer conv5_2
I0824 17:20:26.654136 41887 net.cpp:434] conv5_2 <- conv5_1
I0824 17:20:26.654145 41887 net.cpp:408] conv5_2 -> conv5_2
I0824 17:20:26.737975 41887 net.cpp:150] Setting up conv5_2
I0824 17:20:26.737993 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.737998 41887 net.cpp:165] Memory required for data: 3144437760
I0824 17:20:26.738004 41887 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 17:20:26.738014 41887 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 17:20:26.738023 41887 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 17:20:26.738029 41887 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 17:20:26.738304 41887 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 17:20:26.738312 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.738315 41887 net.cpp:165] Memory required for data: 3150090240
I0824 17:20:26.738327 41887 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 17:20:26.738334 41887 net.cpp:100] Creating Layer conv5_2_scale
I0824 17:20:26.738343 41887 net.cpp:434] conv5_2_scale <- conv5_2
I0824 17:20:26.738348 41887 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 17:20:26.738411 41887 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 17:20:26.738564 41887 net.cpp:150] Setting up conv5_2_scale
I0824 17:20:26.738571 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.738574 41887 net.cpp:165] Memory required for data: 3155742720
I0824 17:20:26.738581 41887 layer_factory.hpp:77] Creating layer relu5_2
I0824 17:20:26.738605 41887 net.cpp:100] Creating Layer relu5_2
I0824 17:20:26.738610 41887 net.cpp:434] relu5_2 <- conv5_2
I0824 17:20:26.738615 41887 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 17:20:26.738836 41887 net.cpp:150] Setting up relu5_2
I0824 17:20:26.738844 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.738849 41887 net.cpp:165] Memory required for data: 3161395200
I0824 17:20:26.738853 41887 layer_factory.hpp:77] Creating layer conv5_3
I0824 17:20:26.738867 41887 net.cpp:100] Creating Layer conv5_3
I0824 17:20:26.738873 41887 net.cpp:434] conv5_3 <- conv5_2
I0824 17:20:26.738879 41887 net.cpp:408] conv5_3 -> conv5_3
I0824 17:20:26.824134 41887 net.cpp:150] Setting up conv5_3
I0824 17:20:26.824159 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.824168 41887 net.cpp:165] Memory required for data: 3167047680
I0824 17:20:26.824182 41887 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 17:20:26.824192 41887 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 17:20:26.824203 41887 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 17:20:26.824213 41887 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 17:20:26.824491 41887 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 17:20:26.824501 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.824503 41887 net.cpp:165] Memory required for data: 3172700160
I0824 17:20:26.824512 41887 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 17:20:26.824520 41887 net.cpp:100] Creating Layer conv5_3_scale
I0824 17:20:26.824525 41887 net.cpp:434] conv5_3_scale <- conv5_3
I0824 17:20:26.824530 41887 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 17:20:26.824589 41887 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 17:20:26.824743 41887 net.cpp:150] Setting up conv5_3_scale
I0824 17:20:26.824751 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.824754 41887 net.cpp:165] Memory required for data: 3178352640
I0824 17:20:26.824761 41887 layer_factory.hpp:77] Creating layer relu5_3
I0824 17:20:26.824769 41887 net.cpp:100] Creating Layer relu5_3
I0824 17:20:26.824774 41887 net.cpp:434] relu5_3 <- conv5_3
I0824 17:20:26.824780 41887 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 17:20:26.825004 41887 net.cpp:150] Setting up relu5_3
I0824 17:20:26.825014 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.825018 41887 net.cpp:165] Memory required for data: 3184005120
I0824 17:20:26.825022 41887 layer_factory.hpp:77] Creating layer pool5
I0824 17:20:26.825026 41887 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 17:20:26.825032 41887 net.cpp:100] Creating Layer pool5
I0824 17:20:26.825039 41887 net.cpp:434] pool5 <- conv5_3
I0824 17:20:26.825048 41887 net.cpp:408] pool5 -> pool5
I0824 17:20:26.825057 41887 net.cpp:408] pool5 -> pool5_mask
I0824 17:20:26.825119 41887 net.cpp:150] Setting up pool5
I0824 17:20:26.825125 41887 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 17:20:26.825130 41887 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 17:20:26.825134 41887 net.cpp:165] Memory required for data: 3186954240
I0824 17:20:26.825139 41887 layer_factory.hpp:77] Creating layer upsample5
I0824 17:20:26.825145 41887 net.cpp:100] Creating Layer upsample5
I0824 17:20:26.825150 41887 net.cpp:434] upsample5 <- pool5
I0824 17:20:26.825155 41887 net.cpp:434] upsample5 <- pool5_mask
I0824 17:20:26.825162 41887 net.cpp:408] upsample5 -> pool5_D
I0824 17:20:26.825196 41887 net.cpp:150] Setting up upsample5
I0824 17:20:26.825202 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.825206 41887 net.cpp:165] Memory required for data: 3192606720
I0824 17:20:26.825208 41887 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 17:20:26.825219 41887 net.cpp:100] Creating Layer conv5_3_D
I0824 17:20:26.825224 41887 net.cpp:434] conv5_3_D <- pool5_D
I0824 17:20:26.825233 41887 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 17:20:26.909025 41887 net.cpp:150] Setting up conv5_3_D
I0824 17:20:26.909042 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.909063 41887 net.cpp:165] Memory required for data: 3198259200
I0824 17:20:26.909072 41887 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 17:20:26.909082 41887 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 17:20:26.909087 41887 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 17:20:26.909096 41887 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 17:20:26.909381 41887 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 17:20:26.909389 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.909394 41887 net.cpp:165] Memory required for data: 3203911680
I0824 17:20:26.909401 41887 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 17:20:26.909410 41887 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 17:20:26.909416 41887 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 17:20:26.909421 41887 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 17:20:26.909478 41887 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 17:20:26.909633 41887 net.cpp:150] Setting up conv5_3_D_scale
I0824 17:20:26.909641 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.909646 41887 net.cpp:165] Memory required for data: 3209564160
I0824 17:20:26.909651 41887 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 17:20:26.909658 41887 net.cpp:100] Creating Layer relu5_3_D
I0824 17:20:26.909663 41887 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 17:20:26.909668 41887 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 17:20:26.910817 41887 net.cpp:150] Setting up relu5_3_D
I0824 17:20:26.910833 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.910837 41887 net.cpp:165] Memory required for data: 3215216640
I0824 17:20:26.910841 41887 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 17:20:26.910889 41887 net.cpp:100] Creating Layer conv5_2_D
I0824 17:20:26.910894 41887 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 17:20:26.910904 41887 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 17:20:26.994700 41887 net.cpp:150] Setting up conv5_2_D
I0824 17:20:26.994717 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.994721 41887 net.cpp:165] Memory required for data: 3220869120
I0824 17:20:26.994732 41887 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 17:20:26.994741 41887 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 17:20:26.994750 41887 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 17:20:26.994756 41887 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 17:20:26.995041 41887 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 17:20:26.995049 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.995054 41887 net.cpp:165] Memory required for data: 3226521600
I0824 17:20:26.995061 41887 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 17:20:26.995075 41887 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 17:20:26.995082 41887 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 17:20:26.995087 41887 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 17:20:26.995151 41887 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 17:20:26.995307 41887 net.cpp:150] Setting up conv5_2_D_scale
I0824 17:20:26.995314 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.995318 41887 net.cpp:165] Memory required for data: 3232174080
I0824 17:20:26.995324 41887 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 17:20:26.995332 41887 net.cpp:100] Creating Layer relu5_2_D
I0824 17:20:26.995337 41887 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 17:20:26.995345 41887 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 17:20:26.996500 41887 net.cpp:150] Setting up relu5_2_D
I0824 17:20:26.996513 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:26.996518 41887 net.cpp:165] Memory required for data: 3237826560
I0824 17:20:26.996522 41887 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 17:20:26.996536 41887 net.cpp:100] Creating Layer conv5_1_D
I0824 17:20:26.996541 41887 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 17:20:26.996551 41887 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 17:20:27.080358 41887 net.cpp:150] Setting up conv5_1_D
I0824 17:20:27.080376 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:27.080380 41887 net.cpp:165] Memory required for data: 3243479040
I0824 17:20:27.080389 41887 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 17:20:27.080399 41887 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 17:20:27.080409 41887 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 17:20:27.080416 41887 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 17:20:27.080695 41887 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 17:20:27.080703 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:27.080708 41887 net.cpp:165] Memory required for data: 3249131520
I0824 17:20:27.080716 41887 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 17:20:27.080729 41887 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 17:20:27.080737 41887 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 17:20:27.080745 41887 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 17:20:27.080803 41887 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 17:20:27.080960 41887 net.cpp:150] Setting up conv5_1_D_scale
I0824 17:20:27.080967 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:27.080971 41887 net.cpp:165] Memory required for data: 3254784000
I0824 17:20:27.080977 41887 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 17:20:27.080984 41887 net.cpp:100] Creating Layer relu5_1_D
I0824 17:20:27.080989 41887 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 17:20:27.080994 41887 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 17:20:27.081219 41887 net.cpp:150] Setting up relu5_1_D
I0824 17:20:27.081228 41887 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 17:20:27.081233 41887 net.cpp:165] Memory required for data: 3260436480
I0824 17:20:27.081238 41887 layer_factory.hpp:77] Creating layer upsample4
I0824 17:20:27.081243 41887 net.cpp:100] Creating Layer upsample4
I0824 17:20:27.081248 41887 net.cpp:434] upsample4 <- conv5_1_D
I0824 17:20:27.081254 41887 net.cpp:434] upsample4 <- pool4_mask
I0824 17:20:27.081265 41887 net.cpp:408] upsample4 -> pool4_D
I0824 17:20:27.081305 41887 net.cpp:150] Setting up upsample4
I0824 17:20:27.081315 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:27.081318 41887 net.cpp:165] Memory required for data: 3282554880
I0824 17:20:27.081321 41887 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 17:20:27.081332 41887 net.cpp:100] Creating Layer conv4_3_D
I0824 17:20:27.081337 41887 net.cpp:434] conv4_3_D <- pool4_D
I0824 17:20:27.081344 41887 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 17:20:27.165225 41887 net.cpp:150] Setting up conv4_3_D
I0824 17:20:27.165242 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:27.165246 41887 net.cpp:165] Memory required for data: 3304673280
I0824 17:20:27.165254 41887 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 17:20:27.165263 41887 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 17:20:27.165274 41887 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 17:20:27.165280 41887 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 17:20:27.165581 41887 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 17:20:27.165591 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:27.165594 41887 net.cpp:165] Memory required for data: 3326791680
I0824 17:20:27.165602 41887 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 17:20:27.165609 41887 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 17:20:27.165617 41887 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 17:20:27.165623 41887 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 17:20:27.165680 41887 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 17:20:27.165854 41887 net.cpp:150] Setting up conv4_3_D_scale
I0824 17:20:27.165863 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:27.165866 41887 net.cpp:165] Memory required for data: 3348910080
I0824 17:20:27.165873 41887 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 17:20:27.165899 41887 net.cpp:100] Creating Layer relu4_3_D
I0824 17:20:27.165904 41887 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 17:20:27.165910 41887 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 17:20:27.166129 41887 net.cpp:150] Setting up relu4_3_D
I0824 17:20:27.166138 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:27.166144 41887 net.cpp:165] Memory required for data: 3371028480
I0824 17:20:27.166147 41887 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 17:20:27.166159 41887 net.cpp:100] Creating Layer conv4_2_D
I0824 17:20:27.166165 41887 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 17:20:27.166173 41887 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 17:20:27.250051 41887 net.cpp:150] Setting up conv4_2_D
I0824 17:20:27.250067 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:27.250072 41887 net.cpp:165] Memory required for data: 3393146880
I0824 17:20:27.250087 41887 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 17:20:27.250097 41887 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 17:20:27.250108 41887 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 17:20:27.250115 41887 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 17:20:27.250411 41887 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 17:20:27.250418 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:27.250422 41887 net.cpp:165] Memory required for data: 3415265280
I0824 17:20:27.250432 41887 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 17:20:27.250442 41887 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 17:20:27.250447 41887 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 17:20:27.250452 41887 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 17:20:27.250507 41887 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 17:20:27.250679 41887 net.cpp:150] Setting up conv4_2_D_scale
I0824 17:20:27.250686 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:27.250690 41887 net.cpp:165] Memory required for data: 3437383680
I0824 17:20:27.250696 41887 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 17:20:27.250704 41887 net.cpp:100] Creating Layer relu4_2_D
I0824 17:20:27.250708 41887 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 17:20:27.250715 41887 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 17:20:27.250936 41887 net.cpp:150] Setting up relu4_2_D
I0824 17:20:27.250944 41887 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 17:20:27.250949 41887 net.cpp:165] Memory required for data: 3459502080
I0824 17:20:27.250953 41887 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 17:20:27.250967 41887 net.cpp:100] Creating Layer conv4_1_D
I0824 17:20:27.250972 41887 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 17:20:27.250980 41887 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 17:20:27.295002 41887 net.cpp:150] Setting up conv4_1_D
I0824 17:20:27.295019 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:27.295030 41887 net.cpp:165] Memory required for data: 3470561280
I0824 17:20:27.295042 41887 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 17:20:27.295050 41887 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 17:20:27.295059 41887 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 17:20:27.295065 41887 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 17:20:27.295366 41887 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 17:20:27.295374 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:27.295385 41887 net.cpp:165] Memory required for data: 3481620480
I0824 17:20:27.295439 41887 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 17:20:27.295449 41887 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 17:20:27.295454 41887 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 17:20:27.295459 41887 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 17:20:27.295519 41887 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 17:20:27.295689 41887 net.cpp:150] Setting up conv4_1_D_scale
I0824 17:20:27.295697 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:27.295717 41887 net.cpp:165] Memory required for data: 3492679680
I0824 17:20:27.295724 41887 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 17:20:27.295730 41887 net.cpp:100] Creating Layer relu4_1_D
I0824 17:20:27.295735 41887 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 17:20:27.295744 41887 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 17:20:27.295979 41887 net.cpp:150] Setting up relu4_1_D
I0824 17:20:27.295987 41887 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 17:20:27.295992 41887 net.cpp:165] Memory required for data: 3503738880
I0824 17:20:27.295996 41887 layer_factory.hpp:77] Creating layer upsample3
I0824 17:20:27.296005 41887 net.cpp:100] Creating Layer upsample3
I0824 17:20:27.296010 41887 net.cpp:434] upsample3 <- conv4_1_D
I0824 17:20:27.296015 41887 net.cpp:434] upsample3 <- pool3_mask
I0824 17:20:27.296022 41887 net.cpp:408] upsample3 -> pool3_D
I0824 17:20:27.296032 41887 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 17:20:27.296070 41887 net.cpp:150] Setting up upsample3
I0824 17:20:27.296077 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:27.296082 41887 net.cpp:165] Memory required for data: 3547975680
I0824 17:20:27.296087 41887 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 17:20:27.296098 41887 net.cpp:100] Creating Layer conv3_3_D
I0824 17:20:27.296103 41887 net.cpp:434] conv3_3_D <- pool3_D
I0824 17:20:27.296113 41887 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 17:20:27.319813 41887 net.cpp:150] Setting up conv3_3_D
I0824 17:20:27.319830 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:27.319840 41887 net.cpp:165] Memory required for data: 3592212480
I0824 17:20:27.319849 41887 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 17:20:27.319860 41887 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 17:20:27.319867 41887 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 17:20:27.319874 41887 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 17:20:27.320184 41887 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 17:20:27.320192 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:27.320196 41887 net.cpp:165] Memory required for data: 3636449280
I0824 17:20:27.320204 41887 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 17:20:27.320216 41887 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 17:20:27.320221 41887 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 17:20:27.320228 41887 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 17:20:27.320284 41887 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 17:20:27.320474 41887 net.cpp:150] Setting up conv3_3_D_scale
I0824 17:20:27.320485 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:27.320489 41887 net.cpp:165] Memory required for data: 3680686080
I0824 17:20:27.320497 41887 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 17:20:27.320503 41887 net.cpp:100] Creating Layer relu3_3_D
I0824 17:20:27.320508 41887 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 17:20:27.320513 41887 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 17:20:27.321696 41887 net.cpp:150] Setting up relu3_3_D
I0824 17:20:27.321712 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:27.321717 41887 net.cpp:165] Memory required for data: 3724922880
I0824 17:20:27.321720 41887 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 17:20:27.321734 41887 net.cpp:100] Creating Layer conv3_2_D
I0824 17:20:27.321740 41887 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 17:20:27.321748 41887 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 17:20:27.344514 41887 net.cpp:150] Setting up conv3_2_D
I0824 17:20:27.344530 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:27.344542 41887 net.cpp:165] Memory required for data: 3769159680
I0824 17:20:27.344552 41887 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 17:20:27.344561 41887 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 17:20:27.344570 41887 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 17:20:27.344594 41887 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 17:20:27.344907 41887 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 17:20:27.344916 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:27.344920 41887 net.cpp:165] Memory required for data: 3813396480
I0824 17:20:27.344928 41887 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 17:20:27.344936 41887 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 17:20:27.344941 41887 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 17:20:27.344946 41887 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 17:20:27.345005 41887 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 17:20:27.345194 41887 net.cpp:150] Setting up conv3_2_D_scale
I0824 17:20:27.345202 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:27.345206 41887 net.cpp:165] Memory required for data: 3857633280
I0824 17:20:27.345212 41887 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 17:20:27.345221 41887 net.cpp:100] Creating Layer relu3_2_D
I0824 17:20:27.345227 41887 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 17:20:27.345230 41887 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 17:20:27.346395 41887 net.cpp:150] Setting up relu3_2_D
I0824 17:20:27.346411 41887 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 17:20:27.346416 41887 net.cpp:165] Memory required for data: 3901870080
I0824 17:20:27.346421 41887 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 17:20:27.346433 41887 net.cpp:100] Creating Layer conv3_1_D
I0824 17:20:27.346439 41887 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 17:20:27.346446 41887 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 17:20:27.360415 41887 net.cpp:150] Setting up conv3_1_D
I0824 17:20:27.360432 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:27.360442 41887 net.cpp:165] Memory required for data: 3923988480
I0824 17:20:27.360450 41887 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 17:20:27.360460 41887 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 17:20:27.360468 41887 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 17:20:27.360477 41887 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 17:20:27.360786 41887 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 17:20:27.360795 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:27.360800 41887 net.cpp:165] Memory required for data: 3946106880
I0824 17:20:27.360807 41887 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 17:20:27.360819 41887 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 17:20:27.360824 41887 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 17:20:27.360829 41887 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 17:20:27.360887 41887 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 17:20:27.362401 41887 net.cpp:150] Setting up conv3_1_D_scale
I0824 17:20:27.362416 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:27.362421 41887 net.cpp:165] Memory required for data: 3968225280
I0824 17:20:27.362429 41887 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 17:20:27.362439 41887 net.cpp:100] Creating Layer relu3_1_D
I0824 17:20:27.362444 41887 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 17:20:27.362452 41887 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 17:20:27.362696 41887 net.cpp:150] Setting up relu3_1_D
I0824 17:20:27.362705 41887 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 17:20:27.362709 41887 net.cpp:165] Memory required for data: 3990343680
I0824 17:20:27.362713 41887 layer_factory.hpp:77] Creating layer upsample2
I0824 17:20:27.362721 41887 net.cpp:100] Creating Layer upsample2
I0824 17:20:27.362726 41887 net.cpp:434] upsample2 <- conv3_1_D
I0824 17:20:27.362731 41887 net.cpp:434] upsample2 <- pool2_mask
I0824 17:20:27.362740 41887 net.cpp:408] upsample2 -> pool2_D
I0824 17:20:27.362748 41887 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 17:20:27.362788 41887 net.cpp:150] Setting up upsample2
I0824 17:20:27.362809 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:27.362814 41887 net.cpp:165] Memory required for data: 4078817280
I0824 17:20:27.362818 41887 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 17:20:27.362829 41887 net.cpp:100] Creating Layer conv2_2_D
I0824 17:20:27.362834 41887 net.cpp:434] conv2_2_D <- pool2_D
I0824 17:20:27.362843 41887 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 17:20:27.370748 41887 net.cpp:150] Setting up conv2_2_D
I0824 17:20:27.370764 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:27.370774 41887 net.cpp:165] Memory required for data: 4167290880
I0824 17:20:27.370781 41887 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 17:20:27.370793 41887 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 17:20:27.370800 41887 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 17:20:27.370807 41887 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 17:20:27.371151 41887 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 17:20:27.371160 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:27.371163 41887 net.cpp:165] Memory required for data: 4255764480
I0824 17:20:27.371171 41887 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 17:20:27.371182 41887 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 17:20:27.371191 41887 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 17:20:27.371196 41887 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 17:20:27.371253 41887 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 17:20:27.371512 41887 net.cpp:150] Setting up conv2_2_D_scale
I0824 17:20:27.371521 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:27.371525 41887 net.cpp:165] Memory required for data: 4344238080
I0824 17:20:27.371531 41887 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 17:20:27.371538 41887 net.cpp:100] Creating Layer relu2_2_D
I0824 17:20:27.371543 41887 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 17:20:27.371552 41887 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 17:20:27.371788 41887 net.cpp:150] Setting up relu2_2_D
I0824 17:20:27.371796 41887 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 17:20:27.371801 41887 net.cpp:165] Memory required for data: 4432711680
I0824 17:20:27.371805 41887 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 17:20:27.371817 41887 net.cpp:100] Creating Layer conv2_1_D
I0824 17:20:27.371822 41887 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 17:20:27.371831 41887 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 17:20:27.377305 41887 net.cpp:150] Setting up conv2_1_D
I0824 17:20:27.377321 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:27.377331 41887 net.cpp:165] Memory required for data: 4476948480
I0824 17:20:27.377338 41887 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 17:20:27.377348 41887 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 17:20:27.377357 41887 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 17:20:27.377363 41887 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 17:20:27.377727 41887 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 17:20:27.377737 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:27.377740 41887 net.cpp:165] Memory required for data: 4521185280
I0824 17:20:27.377749 41887 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 17:20:27.377763 41887 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 17:20:27.377768 41887 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 17:20:27.377774 41887 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 17:20:27.377835 41887 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 17:20:27.378109 41887 net.cpp:150] Setting up conv2_1_D_scale
I0824 17:20:27.378118 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:27.378120 41887 net.cpp:165] Memory required for data: 4565422080
I0824 17:20:27.378127 41887 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 17:20:27.378134 41887 net.cpp:100] Creating Layer relu2_1_D
I0824 17:20:27.378139 41887 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 17:20:27.378160 41887 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 17:20:27.378401 41887 net.cpp:150] Setting up relu2_1_D
I0824 17:20:27.378412 41887 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 17:20:27.378415 41887 net.cpp:165] Memory required for data: 4609658880
I0824 17:20:27.378419 41887 layer_factory.hpp:77] Creating layer upsample1
I0824 17:20:27.378427 41887 net.cpp:100] Creating Layer upsample1
I0824 17:20:27.378430 41887 net.cpp:434] upsample1 <- conv2_1_D
I0824 17:20:27.378435 41887 net.cpp:434] upsample1 <- pool1_mask
I0824 17:20:27.378444 41887 net.cpp:408] upsample1 -> pool1_D
I0824 17:20:27.378453 41887 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 17:20:27.378492 41887 net.cpp:150] Setting up upsample1
I0824 17:20:27.378499 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:27.378502 41887 net.cpp:165] Memory required for data: 4786606080
I0824 17:20:27.378505 41887 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 17:20:27.378518 41887 net.cpp:100] Creating Layer conv1_2_D
I0824 17:20:27.378523 41887 net.cpp:434] conv1_2_D <- pool1_D
I0824 17:20:27.378532 41887 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 17:20:27.383275 41887 net.cpp:150] Setting up conv1_2_D
I0824 17:20:27.383291 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:27.383301 41887 net.cpp:165] Memory required for data: 4963553280
I0824 17:20:27.383309 41887 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 17:20:27.383322 41887 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 17:20:27.383328 41887 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 17:20:27.383334 41887 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 17:20:27.383776 41887 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 17:20:27.383785 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:27.383788 41887 net.cpp:165] Memory required for data: 5140500480
I0824 17:20:27.383797 41887 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 17:20:27.383805 41887 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 17:20:27.383810 41887 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 17:20:27.383815 41887 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 17:20:27.383875 41887 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 17:20:27.385660 41887 net.cpp:150] Setting up conv1_2_D_scale
I0824 17:20:27.385676 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:27.385681 41887 net.cpp:165] Memory required for data: 5317447680
I0824 17:20:27.385689 41887 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 17:20:27.385697 41887 net.cpp:100] Creating Layer relu1_2_D
I0824 17:20:27.385704 41887 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 17:20:27.385710 41887 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 17:20:27.385957 41887 net.cpp:150] Setting up relu1_2_D
I0824 17:20:27.385967 41887 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 17:20:27.385972 41887 net.cpp:165] Memory required for data: 5494394880
I0824 17:20:27.385977 41887 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 17:20:27.385987 41887 net.cpp:100] Creating Layer conv1_1_1_D
I0824 17:20:27.385993 41887 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 17:20:27.386001 41887 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 17:20:27.388212 41887 net.cpp:150] Setting up conv1_1_1_D
I0824 17:20:27.388228 41887 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 17:20:27.388233 41887 net.cpp:165] Memory required for data: 5499924480
I0824 17:20:27.388242 41887 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 17:20:27.388249 41887 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 17:20:27.388255 41887 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 17:20:27.388263 41887 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 17:20:27.388273 41887 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 17:20:27.388348 41887 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 17:20:27.388356 41887 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 17:20:27.388361 41887 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 17:20:27.388365 41887 net.cpp:165] Memory required for data: 5510983680
I0824 17:20:27.388367 41887 layer_factory.hpp:77] Creating layer loss
I0824 17:20:27.388381 41887 net.cpp:100] Creating Layer loss
I0824 17:20:27.388386 41887 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 17:20:27.388391 41887 net.cpp:434] loss <- label_data_1_split_0
I0824 17:20:27.388401 41887 net.cpp:408] loss -> loss
I0824 17:20:27.388411 41887 layer_factory.hpp:77] Creating layer loss
I0824 17:20:27.392596 41887 net.cpp:150] Setting up loss
I0824 17:20:27.392611 41887 net.cpp:157] Top shape: (1)
I0824 17:20:27.392614 41887 net.cpp:160]     with loss weight 1
I0824 17:20:27.392630 41887 net.cpp:165] Memory required for data: 5510983684
I0824 17:20:27.392634 41887 layer_factory.hpp:77] Creating layer accuracy
I0824 17:20:27.392642 41887 net.cpp:100] Creating Layer accuracy
I0824 17:20:27.392648 41887 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 17:20:27.392653 41887 net.cpp:434] accuracy <- label_data_1_split_1
I0824 17:20:27.392663 41887 net.cpp:408] accuracy -> accuracy
I0824 17:20:27.392671 41887 net.cpp:408] accuracy -> per_class_accuracy
I0824 17:20:27.392729 41887 net.cpp:150] Setting up accuracy
I0824 17:20:27.392736 41887 net.cpp:157] Top shape: (1)
I0824 17:20:27.392740 41887 net.cpp:157] Top shape: 2 (2)
I0824 17:20:27.392745 41887 net.cpp:165] Memory required for data: 5510983696
I0824 17:20:27.392748 41887 net.cpp:228] accuracy does not need backward computation.
I0824 17:20:27.392753 41887 net.cpp:226] loss needs backward computation.
I0824 17:20:27.392757 41887 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 17:20:27.392760 41887 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 17:20:27.392765 41887 net.cpp:226] relu1_2_D needs backward computation.
I0824 17:20:27.392767 41887 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 17:20:27.392771 41887 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 17:20:27.392773 41887 net.cpp:226] conv1_2_D needs backward computation.
I0824 17:20:27.392776 41887 net.cpp:226] upsample1 needs backward computation.
I0824 17:20:27.392781 41887 net.cpp:226] relu2_1_D needs backward computation.
I0824 17:20:27.392784 41887 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 17:20:27.392787 41887 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 17:20:27.392791 41887 net.cpp:226] conv2_1_D needs backward computation.
I0824 17:20:27.392794 41887 net.cpp:226] relu2_2_D needs backward computation.
I0824 17:20:27.392797 41887 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 17:20:27.392799 41887 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 17:20:27.392802 41887 net.cpp:226] conv2_2_D needs backward computation.
I0824 17:20:27.392807 41887 net.cpp:226] upsample2 needs backward computation.
I0824 17:20:27.392810 41887 net.cpp:226] relu3_1_D needs backward computation.
I0824 17:20:27.392813 41887 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 17:20:27.392817 41887 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 17:20:27.392819 41887 net.cpp:226] conv3_1_D needs backward computation.
I0824 17:20:27.392822 41887 net.cpp:226] relu3_2_D needs backward computation.
I0824 17:20:27.392825 41887 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 17:20:27.392828 41887 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 17:20:27.392832 41887 net.cpp:226] conv3_2_D needs backward computation.
I0824 17:20:27.392835 41887 net.cpp:226] relu3_3_D needs backward computation.
I0824 17:20:27.392838 41887 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 17:20:27.392841 41887 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 17:20:27.392858 41887 net.cpp:226] conv3_3_D needs backward computation.
I0824 17:20:27.392863 41887 net.cpp:226] upsample3 needs backward computation.
I0824 17:20:27.392866 41887 net.cpp:226] relu4_1_D needs backward computation.
I0824 17:20:27.392869 41887 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 17:20:27.392873 41887 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 17:20:27.392875 41887 net.cpp:226] conv4_1_D needs backward computation.
I0824 17:20:27.392879 41887 net.cpp:226] relu4_2_D needs backward computation.
I0824 17:20:27.392882 41887 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 17:20:27.392885 41887 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 17:20:27.392889 41887 net.cpp:226] conv4_2_D needs backward computation.
I0824 17:20:27.392892 41887 net.cpp:226] relu4_3_D needs backward computation.
I0824 17:20:27.392895 41887 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 17:20:27.392899 41887 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 17:20:27.392901 41887 net.cpp:226] conv4_3_D needs backward computation.
I0824 17:20:27.392905 41887 net.cpp:226] upsample4 needs backward computation.
I0824 17:20:27.392910 41887 net.cpp:226] relu5_1_D needs backward computation.
I0824 17:20:27.392912 41887 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 17:20:27.392916 41887 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 17:20:27.392920 41887 net.cpp:226] conv5_1_D needs backward computation.
I0824 17:20:27.392922 41887 net.cpp:226] relu5_2_D needs backward computation.
I0824 17:20:27.392925 41887 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 17:20:27.392930 41887 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 17:20:27.392933 41887 net.cpp:226] conv5_2_D needs backward computation.
I0824 17:20:27.392937 41887 net.cpp:226] relu5_3_D needs backward computation.
I0824 17:20:27.392940 41887 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 17:20:27.392943 41887 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 17:20:27.392947 41887 net.cpp:226] conv5_3_D needs backward computation.
I0824 17:20:27.392951 41887 net.cpp:226] upsample5 needs backward computation.
I0824 17:20:27.392954 41887 net.cpp:226] pool5 needs backward computation.
I0824 17:20:27.392959 41887 net.cpp:226] relu5_3 needs backward computation.
I0824 17:20:27.392963 41887 net.cpp:226] conv5_3_scale needs backward computation.
I0824 17:20:27.392966 41887 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 17:20:27.392969 41887 net.cpp:226] conv5_3 needs backward computation.
I0824 17:20:27.392973 41887 net.cpp:226] relu5_2 needs backward computation.
I0824 17:20:27.392977 41887 net.cpp:226] conv5_2_scale needs backward computation.
I0824 17:20:27.392980 41887 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 17:20:27.392983 41887 net.cpp:226] conv5_2 needs backward computation.
I0824 17:20:27.392987 41887 net.cpp:226] relu5_1 needs backward computation.
I0824 17:20:27.392990 41887 net.cpp:226] conv5_1_scale needs backward computation.
I0824 17:20:27.392994 41887 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 17:20:27.392997 41887 net.cpp:226] conv5_1 needs backward computation.
I0824 17:20:27.393002 41887 net.cpp:226] pool4 needs backward computation.
I0824 17:20:27.393007 41887 net.cpp:226] relu4_3 needs backward computation.
I0824 17:20:27.393010 41887 net.cpp:226] conv4_3_scale needs backward computation.
I0824 17:20:27.393014 41887 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 17:20:27.393019 41887 net.cpp:226] conv4_3 needs backward computation.
I0824 17:20:27.393023 41887 net.cpp:226] relu4_2 needs backward computation.
I0824 17:20:27.393028 41887 net.cpp:226] conv4_2_scale needs backward computation.
I0824 17:20:27.393030 41887 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 17:20:27.393033 41887 net.cpp:226] conv4_2 needs backward computation.
I0824 17:20:27.393038 41887 net.cpp:226] relu4_1 needs backward computation.
I0824 17:20:27.393049 41887 net.cpp:226] conv4_1_scale needs backward computation.
I0824 17:20:27.393051 41887 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 17:20:27.393054 41887 net.cpp:226] conv4_1 needs backward computation.
I0824 17:20:27.393059 41887 net.cpp:226] pool3 needs backward computation.
I0824 17:20:27.393062 41887 net.cpp:226] relu3_3 needs backward computation.
I0824 17:20:27.393065 41887 net.cpp:226] conv3_3_scale needs backward computation.
I0824 17:20:27.393069 41887 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 17:20:27.393071 41887 net.cpp:226] conv3_3 needs backward computation.
I0824 17:20:27.393075 41887 net.cpp:226] relu3_2 needs backward computation.
I0824 17:20:27.393080 41887 net.cpp:226] conv3_2_scale needs backward computation.
I0824 17:20:27.393084 41887 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 17:20:27.393087 41887 net.cpp:226] conv3_2 needs backward computation.
I0824 17:20:27.393090 41887 net.cpp:226] relu3_1 needs backward computation.
I0824 17:20:27.393093 41887 net.cpp:226] conv3_1_scale needs backward computation.
I0824 17:20:27.393097 41887 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 17:20:27.393100 41887 net.cpp:226] conv3_1 needs backward computation.
I0824 17:20:27.393105 41887 net.cpp:226] pool2 needs backward computation.
I0824 17:20:27.393108 41887 net.cpp:226] relu2_2 needs backward computation.
I0824 17:20:27.393112 41887 net.cpp:226] conv2_2_scale needs backward computation.
I0824 17:20:27.393115 41887 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 17:20:27.393118 41887 net.cpp:226] conv2_2 needs backward computation.
I0824 17:20:27.393123 41887 net.cpp:226] relu2_1 needs backward computation.
I0824 17:20:27.393126 41887 net.cpp:226] conv2_1_scale needs backward computation.
I0824 17:20:27.393129 41887 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 17:20:27.393133 41887 net.cpp:226] conv2_1 needs backward computation.
I0824 17:20:27.393136 41887 net.cpp:226] pool1 needs backward computation.
I0824 17:20:27.393141 41887 net.cpp:226] relu1_2 needs backward computation.
I0824 17:20:27.393146 41887 net.cpp:226] conv1_2_scale needs backward computation.
I0824 17:20:27.393148 41887 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 17:20:27.393153 41887 net.cpp:226] conv1_2 needs backward computation.
I0824 17:20:27.393157 41887 net.cpp:226] relu1_1 needs backward computation.
I0824 17:20:27.393160 41887 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 17:20:27.393163 41887 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 17:20:27.393167 41887 net.cpp:226] conv1_1_1 needs backward computation.
I0824 17:20:27.393172 41887 net.cpp:228] label_data_1_split does not need backward computation.
I0824 17:20:27.393177 41887 net.cpp:228] data does not need backward computation.
I0824 17:20:27.393182 41887 net.cpp:270] This network produces output accuracy
I0824 17:20:27.393185 41887 net.cpp:270] This network produces output loss
I0824 17:20:27.393189 41887 net.cpp:270] This network produces output per_class_accuracy
I0824 17:20:27.393252 41887 net.cpp:283] Network initialization done.
I0824 17:20:27.393630 41887 solver.cpp:60] Solver scaffolding done.
I0824 17:20:27.402892 41887 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0824 17:20:27.629227 41887 net.cpp:761] Ignoring source layer conv1_1
I0824 17:20:27.629252 41887 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 17:20:27.629304 41887 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 17:20:27.629312 41887 net.cpp:761] Ignoring source layer pool1_drop
I0824 17:20:27.629402 41887 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 17:20:27.629550 41887 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 17:20:27.629557 41887 net.cpp:761] Ignoring source layer pool2_drop
I0824 17:20:27.629833 41887 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 17:20:27.630378 41887 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 17:20:27.630901 41887 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 17:20:27.630931 41887 net.cpp:761] Ignoring source layer pool3_drop
I0824 17:20:27.631938 41887 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 17:20:27.633960 41887 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 17:20:27.635972 41887 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 17:20:27.635979 41887 net.cpp:761] Ignoring source layer pool4_drop
I0824 17:20:27.637994 41887 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 17:20:27.640003 41887 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 17:20:27.642026 41887 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 17:20:27.642035 41887 net.cpp:761] Ignoring source layer pool5_drop
I0824 17:20:27.642040 41887 net.cpp:761] Ignoring source layer upsample5_drop
I0824 17:20:27.644035 41887 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 17:20:27.646052 41887 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 17:20:27.648059 41887 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 17:20:27.648069 41887 net.cpp:761] Ignoring source layer upsample4_drop
I0824 17:20:27.650079 41887 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 17:20:27.652087 41887 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 17:20:27.653092 41887 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 17:20:27.653100 41887 net.cpp:761] Ignoring source layer upsample3_drop
I0824 17:20:27.655115 41887 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 17:20:27.655652 41887 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 17:20:27.655913 41887 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 17:20:27.655920 41887 net.cpp:761] Ignoring source layer upsample2_drop
I0824 17:20:27.656059 41887 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 17:20:27.656136 41887 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 17:20:27.656143 41887 net.cpp:761] Ignoring source layer upsample1_drop
I0824 17:20:27.656189 41887 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 17:20:27.656198 41887 net.cpp:761] Ignoring source layer conv1_1_D
I0824 17:20:27.656200 41887 net.cpp:761] Ignoring source layer prob
I0824 17:20:27.879820 41887 net.cpp:761] Ignoring source layer conv1_1
I0824 17:20:27.879844 41887 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 17:20:27.879892 41887 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 17:20:27.879899 41887 net.cpp:761] Ignoring source layer pool1_drop
I0824 17:20:27.879976 41887 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 17:20:27.880120 41887 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 17:20:27.880125 41887 net.cpp:761] Ignoring source layer pool2_drop
I0824 17:20:27.880404 41887 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 17:20:27.880934 41887 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 17:20:27.881454 41887 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 17:20:27.881461 41887 net.cpp:761] Ignoring source layer pool3_drop
I0824 17:20:27.882464 41887 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 17:20:27.884455 41887 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 17:20:27.886458 41887 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 17:20:27.886467 41887 net.cpp:761] Ignoring source layer pool4_drop
I0824 17:20:27.888448 41887 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 17:20:27.890442 41887 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 17:20:27.892422 41887 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 17:20:27.892431 41887 net.cpp:761] Ignoring source layer pool5_drop
I0824 17:20:27.892436 41887 net.cpp:761] Ignoring source layer upsample5_drop
I0824 17:20:27.894425 41887 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 17:20:27.896411 41887 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 17:20:27.898404 41887 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 17:20:27.898413 41887 net.cpp:761] Ignoring source layer upsample4_drop
I0824 17:20:27.900393 41887 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 17:20:27.902385 41887 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 17:20:27.903420 41887 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 17:20:27.903429 41887 net.cpp:761] Ignoring source layer upsample3_drop
I0824 17:20:27.903933 41887 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 17:20:27.904441 41887 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 17:20:27.904700 41887 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 17:20:27.904707 41887 net.cpp:761] Ignoring source layer upsample2_drop
I0824 17:20:27.904842 41887 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 17:20:27.904916 41887 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 17:20:27.904922 41887 net.cpp:761] Ignoring source layer upsample1_drop
I0824 17:20:27.904963 41887 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 17:20:27.904970 41887 net.cpp:761] Ignoring source layer conv1_1_D
I0824 17:20:27.904973 41887 net.cpp:761] Ignoring source layer prob
I0824 17:20:27.908013 41887 caffe.cpp:251] Starting Optimization
I0824 17:20:27.908035 41887 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0824 17:20:27.908040 41887 solver.cpp:280] Learning Rate Policy: step
I0824 17:20:29.266939 41887 solver.cpp:228] Iteration 0, loss = 1.04889
I0824 17:20:29.266983 41887 solver.cpp:244]     Train net output #0: accuracy = 0.529935
I0824 17:20:29.266996 41887 solver.cpp:244]     Train net output #1: loss = 1.04889 (* 1 = 1.04889 loss)
I0824 17:20:29.267002 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.647114
I0824 17:20:29.267014 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.37398
I0824 17:20:29.267042 41887 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0824 17:20:47.657999 41887 solver.cpp:228] Iteration 20, loss = 0.574436
I0824 17:20:47.658046 41887 solver.cpp:244]     Train net output #0: accuracy = 0.663626
I0824 17:20:47.658056 41887 solver.cpp:244]     Train net output #1: loss = 0.574436 (* 1 = 0.574436 loss)
I0824 17:20:47.658062 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.656281
I0824 17:20:47.658066 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.682759
I0824 17:20:47.658073 41887 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0824 17:21:04.255208 41887 solver.cpp:228] Iteration 40, loss = 0.4096
I0824 17:21:04.255348 41887 solver.cpp:244]     Train net output #0: accuracy = 0.810871
I0824 17:21:04.255362 41887 solver.cpp:244]     Train net output #1: loss = 0.4096 (* 1 = 0.4096 loss)
I0824 17:21:04.255367 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.781141
I0824 17:21:04.255373 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.888173
I0824 17:21:04.255380 41887 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0824 17:21:20.864872 41887 solver.cpp:228] Iteration 60, loss = 0.271838
I0824 17:21:20.864913 41887 solver.cpp:244]     Train net output #0: accuracy = 0.900502
I0824 17:21:20.864924 41887 solver.cpp:244]     Train net output #1: loss = 0.271838 (* 1 = 0.271838 loss)
I0824 17:21:20.864929 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.87993
I0824 17:21:20.864934 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.943187
I0824 17:21:20.864941 41887 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0824 17:21:37.464761 41887 solver.cpp:228] Iteration 80, loss = 0.434402
I0824 17:21:37.464908 41887 solver.cpp:244]     Train net output #0: accuracy = 0.856759
I0824 17:21:37.464921 41887 solver.cpp:244]     Train net output #1: loss = 0.434402 (* 1 = 0.434402 loss)
I0824 17:21:37.464927 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.870736
I0824 17:21:37.464931 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.837458
I0824 17:21:37.464938 41887 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0824 17:21:54.084527 41887 solver.cpp:228] Iteration 100, loss = 0.411694
I0824 17:21:54.084566 41887 solver.cpp:244]     Train net output #0: accuracy = 0.719598
I0824 17:21:54.084578 41887 solver.cpp:244]     Train net output #1: loss = 0.411694 (* 1 = 0.411694 loss)
I0824 17:21:54.084583 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.687458
I0824 17:21:54.084588 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.969481
I0824 17:21:54.084595 41887 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0824 17:22:10.708600 41887 solver.cpp:228] Iteration 120, loss = 0.364881
I0824 17:22:10.708796 41887 solver.cpp:244]     Train net output #0: accuracy = 0.899339
I0824 17:22:10.708811 41887 solver.cpp:244]     Train net output #1: loss = 0.364881 (* 1 = 0.364881 loss)
I0824 17:22:10.708815 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.950137
I0824 17:22:10.708820 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.821539
I0824 17:22:10.708827 41887 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0824 17:22:27.349169 41887 solver.cpp:228] Iteration 140, loss = 0.273158
I0824 17:22:27.349208 41887 solver.cpp:244]     Train net output #0: accuracy = 0.861043
I0824 17:22:27.349220 41887 solver.cpp:244]     Train net output #1: loss = 0.273158 (* 1 = 0.273158 loss)
I0824 17:22:27.349226 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.846199
I0824 17:22:27.349231 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.921447
I0824 17:22:27.349237 41887 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0824 17:22:43.964295 41887 solver.cpp:228] Iteration 160, loss = 0.278365
I0824 17:22:43.964417 41887 solver.cpp:244]     Train net output #0: accuracy = 0.860773
I0824 17:22:43.964432 41887 solver.cpp:244]     Train net output #1: loss = 0.278365 (* 1 = 0.278365 loss)
I0824 17:22:43.964438 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.852516
I0824 17:22:43.964442 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.894222
I0824 17:22:43.964450 41887 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0824 17:23:00.571817 41887 solver.cpp:228] Iteration 180, loss = 0.159619
I0824 17:23:00.571856 41887 solver.cpp:244]     Train net output #0: accuracy = 0.933341
I0824 17:23:00.571866 41887 solver.cpp:244]     Train net output #1: loss = 0.159619 (* 1 = 0.159619 loss)
I0824 17:23:00.571871 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.926239
I0824 17:23:00.571877 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.954556
I0824 17:23:00.571884 41887 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0824 17:23:17.192946 41887 solver.cpp:228] Iteration 200, loss = 0.18369
I0824 17:23:17.193069 41887 solver.cpp:244]     Train net output #0: accuracy = 0.905897
I0824 17:23:17.193084 41887 solver.cpp:244]     Train net output #1: loss = 0.18369 (* 1 = 0.18369 loss)
I0824 17:23:17.193089 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.889897
I0824 17:23:17.193094 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.970026
I0824 17:23:17.193100 41887 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0824 17:23:33.794534 41887 solver.cpp:228] Iteration 220, loss = 0.211179
I0824 17:23:33.794579 41887 solver.cpp:244]     Train net output #0: accuracy = 0.901649
I0824 17:23:33.794590 41887 solver.cpp:244]     Train net output #1: loss = 0.211179 (* 1 = 0.211179 loss)
I0824 17:23:33.794595 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.893005
I0824 17:23:33.794600 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.924841
I0824 17:23:33.794607 41887 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0824 17:23:50.399569 41887 solver.cpp:228] Iteration 240, loss = 0.114507
I0824 17:23:50.399689 41887 solver.cpp:244]     Train net output #0: accuracy = 0.975676
I0824 17:23:50.399704 41887 solver.cpp:244]     Train net output #1: loss = 0.114507 (* 1 = 0.114507 loss)
I0824 17:23:50.399709 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.976189
I0824 17:23:50.399714 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.974623
I0824 17:23:50.399721 41887 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0824 17:24:06.997759 41887 solver.cpp:228] Iteration 260, loss = 0.173754
I0824 17:24:06.997805 41887 solver.cpp:244]     Train net output #0: accuracy = 0.94042
I0824 17:24:06.997818 41887 solver.cpp:244]     Train net output #1: loss = 0.173754 (* 1 = 0.173754 loss)
I0824 17:24:06.997823 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.952068
I0824 17:24:06.997828 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.917829
I0824 17:24:06.997834 41887 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0824 17:24:23.604797 41887 solver.cpp:228] Iteration 280, loss = 0.0871043
I0824 17:24:23.604964 41887 solver.cpp:244]     Train net output #0: accuracy = 0.962507
I0824 17:24:23.604981 41887 solver.cpp:244]     Train net output #1: loss = 0.0871043 (* 1 = 0.0871043 loss)
I0824 17:24:23.604987 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.954651
I0824 17:24:23.604991 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997686
I0824 17:24:23.604998 41887 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0824 17:24:40.227921 41887 solver.cpp:228] Iteration 300, loss = 0.107931
I0824 17:24:40.227962 41887 solver.cpp:244]     Train net output #0: accuracy = 0.963831
I0824 17:24:40.227973 41887 solver.cpp:244]     Train net output #1: loss = 0.107931 (* 1 = 0.107931 loss)
I0824 17:24:40.227979 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9591
I0824 17:24:40.227984 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.975307
I0824 17:24:40.227991 41887 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0824 17:24:56.859340 41887 solver.cpp:228] Iteration 320, loss = 0.0837821
I0824 17:24:56.859460 41887 solver.cpp:244]     Train net output #0: accuracy = 0.964265
I0824 17:24:56.859477 41887 solver.cpp:244]     Train net output #1: loss = 0.0837821 (* 1 = 0.0837821 loss)
I0824 17:24:56.859488 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.956035
I0824 17:24:56.859493 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993811
I0824 17:24:56.859499 41887 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0824 17:25:13.471295 41887 solver.cpp:228] Iteration 340, loss = 0.101082
I0824 17:25:13.471338 41887 solver.cpp:244]     Train net output #0: accuracy = 0.950642
I0824 17:25:13.471349 41887 solver.cpp:244]     Train net output #1: loss = 0.101082 (* 1 = 0.101082 loss)
I0824 17:25:13.471355 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.94254
I0824 17:25:13.471359 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993959
I0824 17:25:13.471366 41887 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0824 17:25:30.098552 41887 solver.cpp:228] Iteration 360, loss = 0.179655
I0824 17:25:30.098661 41887 solver.cpp:244]     Train net output #0: accuracy = 0.895035
I0824 17:25:30.098676 41887 solver.cpp:244]     Train net output #1: loss = 0.179655 (* 1 = 0.179655 loss)
I0824 17:25:30.098687 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.878641
I0824 17:25:30.098692 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.967935
I0824 17:25:30.098698 41887 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0824 17:25:46.698962 41887 solver.cpp:228] Iteration 380, loss = 0.121967
I0824 17:25:46.699004 41887 solver.cpp:244]     Train net output #0: accuracy = 0.946363
I0824 17:25:46.699015 41887 solver.cpp:244]     Train net output #1: loss = 0.121967 (* 1 = 0.121967 loss)
I0824 17:25:46.699020 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.939234
I0824 17:25:46.699025 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980583
I0824 17:25:46.699033 41887 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0824 17:26:03.330884 41887 solver.cpp:228] Iteration 400, loss = 0.127803
I0824 17:26:03.330994 41887 solver.cpp:244]     Train net output #0: accuracy = 0.942147
I0824 17:26:03.331007 41887 solver.cpp:244]     Train net output #1: loss = 0.127803 (* 1 = 0.127803 loss)
I0824 17:26:03.331014 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.918427
I0824 17:26:03.331019 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998712
I0824 17:26:03.331027 41887 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0824 17:26:19.942750 41887 solver.cpp:228] Iteration 420, loss = 0.078355
I0824 17:26:19.942793 41887 solver.cpp:244]     Train net output #0: accuracy = 0.974145
I0824 17:26:19.942806 41887 solver.cpp:244]     Train net output #1: loss = 0.078355 (* 1 = 0.078355 loss)
I0824 17:26:19.942811 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.971406
I0824 17:26:19.942816 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978963
I0824 17:26:19.942823 41887 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0824 17:26:36.563758 41887 solver.cpp:228] Iteration 440, loss = 0.0701622
I0824 17:26:36.563932 41887 solver.cpp:244]     Train net output #0: accuracy = 0.971913
I0824 17:26:36.563947 41887 solver.cpp:244]     Train net output #1: loss = 0.0701622 (* 1 = 0.0701622 loss)
I0824 17:26:36.563953 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974357
I0824 17:26:36.563958 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.965476
I0824 17:26:36.563966 41887 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0824 17:26:53.169994 41887 solver.cpp:228] Iteration 460, loss = 0.0622962
I0824 17:26:53.170038 41887 solver.cpp:244]     Train net output #0: accuracy = 0.975593
I0824 17:26:53.170051 41887 solver.cpp:244]     Train net output #1: loss = 0.0622962 (* 1 = 0.0622962 loss)
I0824 17:26:53.170058 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972513
I0824 17:26:53.170063 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983853
I0824 17:26:53.170069 41887 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0824 17:27:09.799510 41887 solver.cpp:228] Iteration 480, loss = 0.0459912
I0824 17:27:09.799626 41887 solver.cpp:244]     Train net output #0: accuracy = 0.98263
I0824 17:27:09.799640 41887 solver.cpp:244]     Train net output #1: loss = 0.0459912 (* 1 = 0.0459912 loss)
I0824 17:27:09.799646 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978906
I0824 17:27:09.799651 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996679
I0824 17:27:09.799657 41887 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0824 17:27:26.413455 41887 solver.cpp:228] Iteration 500, loss = 0.0795743
I0824 17:27:26.413497 41887 solver.cpp:244]     Train net output #0: accuracy = 0.966869
I0824 17:27:26.413509 41887 solver.cpp:244]     Train net output #1: loss = 0.0795743 (* 1 = 0.0795743 loss)
I0824 17:27:26.413516 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.961042
I0824 17:27:26.413522 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990123
I0824 17:27:26.413528 41887 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0824 17:27:43.035634 41887 solver.cpp:228] Iteration 520, loss = 0.210676
I0824 17:27:43.035737 41887 solver.cpp:244]     Train net output #0: accuracy = 0.881988
I0824 17:27:43.035753 41887 solver.cpp:244]     Train net output #1: loss = 0.210676 (* 1 = 0.210676 loss)
I0824 17:27:43.035758 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.863601
I0824 17:27:43.035763 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980991
I0824 17:27:43.035770 41887 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0824 17:27:59.641024 41887 solver.cpp:228] Iteration 540, loss = 0.0918484
I0824 17:27:59.641063 41887 solver.cpp:244]     Train net output #0: accuracy = 0.964755
I0824 17:27:59.641077 41887 solver.cpp:244]     Train net output #1: loss = 0.0918484 (* 1 = 0.0918484 loss)
I0824 17:27:59.641083 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.961604
I0824 17:27:59.641088 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979948
I0824 17:27:59.641094 41887 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0824 17:28:16.266364 41887 solver.cpp:228] Iteration 560, loss = 0.0417323
I0824 17:28:16.266542 41887 solver.cpp:244]     Train net output #0: accuracy = 0.985739
I0824 17:28:16.266559 41887 solver.cpp:244]     Train net output #1: loss = 0.0417323 (* 1 = 0.0417323 loss)
I0824 17:28:16.266571 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984955
I0824 17:28:16.266575 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988515
I0824 17:28:16.266582 41887 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0824 17:28:32.877185 41887 solver.cpp:228] Iteration 580, loss = 0.0668613
I0824 17:28:32.877226 41887 solver.cpp:244]     Train net output #0: accuracy = 0.971777
I0824 17:28:32.877238 41887 solver.cpp:244]     Train net output #1: loss = 0.0668613 (* 1 = 0.0668613 loss)
I0824 17:28:32.877244 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.964776
I0824 17:28:32.877249 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987433
I0824 17:28:32.877257 41887 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0824 17:28:49.495816 41887 solver.cpp:228] Iteration 600, loss = 0.0705382
I0824 17:28:49.495929 41887 solver.cpp:244]     Train net output #0: accuracy = 0.968022
I0824 17:28:49.495945 41887 solver.cpp:244]     Train net output #1: loss = 0.0705382 (* 1 = 0.0705382 loss)
I0824 17:28:49.495956 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.955366
I0824 17:28:49.495960 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993654
I0824 17:28:49.495968 41887 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0824 17:29:06.111754 41887 solver.cpp:228] Iteration 620, loss = 0.0573502
I0824 17:29:06.111795 41887 solver.cpp:244]     Train net output #0: accuracy = 0.97647
I0824 17:29:06.111807 41887 solver.cpp:244]     Train net output #1: loss = 0.0573502 (* 1 = 0.0573502 loss)
I0824 17:29:06.111812 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969509
I0824 17:29:06.111819 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989443
I0824 17:29:06.111825 41887 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0824 17:29:22.741833 41887 solver.cpp:228] Iteration 640, loss = 0.0814508
I0824 17:29:22.741925 41887 solver.cpp:244]     Train net output #0: accuracy = 0.96611
I0824 17:29:22.741943 41887 solver.cpp:244]     Train net output #1: loss = 0.0814508 (* 1 = 0.0814508 loss)
I0824 17:29:22.741952 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.964917
I0824 17:29:22.741957 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98905
I0824 17:29:22.741964 41887 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0824 17:29:39.387331 41887 solver.cpp:228] Iteration 660, loss = 0.0427124
I0824 17:29:39.387382 41887 solver.cpp:244]     Train net output #0: accuracy = 0.984754
I0824 17:29:39.387397 41887 solver.cpp:244]     Train net output #1: loss = 0.0427124 (* 1 = 0.0427124 loss)
I0824 17:29:39.387403 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986063
I0824 17:29:39.387408 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980445
I0824 17:29:39.387416 41887 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0824 17:29:56.017879 41887 solver.cpp:228] Iteration 680, loss = 0.0915906
I0824 17:29:56.018007 41887 solver.cpp:244]     Train net output #0: accuracy = 0.95236
I0824 17:29:56.018023 41887 solver.cpp:244]     Train net output #1: loss = 0.0915907 (* 1 = 0.0915907 loss)
I0824 17:29:56.018035 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.935497
I0824 17:29:56.018041 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998052
I0824 17:29:56.018049 41887 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0824 17:30:12.632189 41887 solver.cpp:228] Iteration 700, loss = 0.0479769
I0824 17:30:12.632237 41887 solver.cpp:244]     Train net output #0: accuracy = 0.978197
I0824 17:30:12.632251 41887 solver.cpp:244]     Train net output #1: loss = 0.0479769 (* 1 = 0.0479769 loss)
I0824 17:30:12.632257 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974431
I0824 17:30:12.632262 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991773
I0824 17:30:12.632268 41887 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0824 17:30:29.256008 41887 solver.cpp:228] Iteration 720, loss = 0.0650192
I0824 17:30:29.256191 41887 solver.cpp:244]     Train net output #0: accuracy = 0.974573
I0824 17:30:29.256213 41887 solver.cpp:244]     Train net output #1: loss = 0.0650192 (* 1 = 0.0650192 loss)
I0824 17:30:29.256222 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.967191
I0824 17:30:29.256233 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988505
I0824 17:30:29.256239 41887 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0824 17:30:45.877424 41887 solver.cpp:228] Iteration 740, loss = 0.0348673
I0824 17:30:45.877471 41887 solver.cpp:244]     Train net output #0: accuracy = 0.987407
I0824 17:30:45.877485 41887 solver.cpp:244]     Train net output #1: loss = 0.0348673 (* 1 = 0.0348673 loss)
I0824 17:30:45.877491 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986923
I0824 17:30:45.877496 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9902
I0824 17:30:45.877503 41887 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0824 17:31:02.498329 41887 solver.cpp:228] Iteration 760, loss = 0.0428733
I0824 17:31:02.498453 41887 solver.cpp:244]     Train net output #0: accuracy = 0.98531
I0824 17:31:02.498469 41887 solver.cpp:244]     Train net output #1: loss = 0.0428733 (* 1 = 0.0428733 loss)
I0824 17:31:02.498478 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985446
I0824 17:31:02.498483 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984926
I0824 17:31:02.498491 41887 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0824 17:31:19.108515 41887 solver.cpp:228] Iteration 780, loss = 0.0296504
I0824 17:31:19.108563 41887 solver.cpp:244]     Train net output #0: accuracy = 0.989465
I0824 17:31:19.108577 41887 solver.cpp:244]     Train net output #1: loss = 0.0296504 (* 1 = 0.0296504 loss)
I0824 17:31:19.108592 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988994
I0824 17:31:19.108604 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990374
I0824 17:31:19.108618 41887 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0824 17:31:35.731354 41887 solver.cpp:228] Iteration 800, loss = 0.0412103
I0824 17:31:35.731462 41887 solver.cpp:244]     Train net output #0: accuracy = 0.983359
I0824 17:31:35.731477 41887 solver.cpp:244]     Train net output #1: loss = 0.0412103 (* 1 = 0.0412103 loss)
I0824 17:31:35.731482 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981799
I0824 17:31:35.731487 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988407
I0824 17:31:35.731493 41887 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0824 17:31:52.345299 41887 solver.cpp:228] Iteration 820, loss = 0.0210984
I0824 17:31:52.345335 41887 solver.cpp:244]     Train net output #0: accuracy = 0.992882
I0824 17:31:52.345346 41887 solver.cpp:244]     Train net output #1: loss = 0.0210984 (* 1 = 0.0210984 loss)
I0824 17:31:52.345352 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994043
I0824 17:31:52.345357 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987952
I0824 17:31:52.345371 41887 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0824 17:32:08.970511 41887 solver.cpp:228] Iteration 840, loss = 0.0341367
I0824 17:32:08.970633 41887 solver.cpp:244]     Train net output #0: accuracy = 0.988069
I0824 17:32:08.970648 41887 solver.cpp:244]     Train net output #1: loss = 0.0341367 (* 1 = 0.0341367 loss)
I0824 17:32:08.970662 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988101
I0824 17:32:08.970667 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98789
I0824 17:32:08.970674 41887 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0824 17:32:25.585624 41887 solver.cpp:228] Iteration 860, loss = 0.0306508
I0824 17:32:25.585667 41887 solver.cpp:244]     Train net output #0: accuracy = 0.986794
I0824 17:32:25.585678 41887 solver.cpp:244]     Train net output #1: loss = 0.0306508 (* 1 = 0.0306508 loss)
I0824 17:32:25.585685 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9852
I0824 17:32:25.585690 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9919
I0824 17:32:25.585696 41887 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0824 17:32:42.196413 41887 solver.cpp:228] Iteration 880, loss = 0.0513646
I0824 17:32:42.196583 41887 solver.cpp:244]     Train net output #0: accuracy = 0.979578
I0824 17:32:42.196604 41887 solver.cpp:244]     Train net output #1: loss = 0.0513646 (* 1 = 0.0513646 loss)
I0824 17:32:42.196611 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.966523
I0824 17:32:42.196616 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994299
I0824 17:32:42.196622 41887 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0824 17:32:58.814802 41887 solver.cpp:228] Iteration 900, loss = 0.0398457
I0824 17:32:58.814844 41887 solver.cpp:244]     Train net output #0: accuracy = 0.983294
I0824 17:32:58.814855 41887 solver.cpp:244]     Train net output #1: loss = 0.0398457 (* 1 = 0.0398457 loss)
I0824 17:32:58.814862 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980144
I0824 17:32:58.814867 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992418
I0824 17:32:58.814875 41887 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0824 17:33:15.433917 41887 solver.cpp:228] Iteration 920, loss = 0.041996
I0824 17:33:15.434027 41887 solver.cpp:244]     Train net output #0: accuracy = 0.988265
I0824 17:33:15.434048 41887 solver.cpp:244]     Train net output #1: loss = 0.041996 (* 1 = 0.041996 loss)
I0824 17:33:15.434056 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990009
I0824 17:33:15.434061 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986085
I0824 17:33:15.434067 41887 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0824 17:33:32.045227 41887 solver.cpp:228] Iteration 940, loss = 0.0252559
I0824 17:33:32.045264 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991309
I0824 17:33:32.045276 41887 solver.cpp:244]     Train net output #1: loss = 0.0252559 (* 1 = 0.0252559 loss)
I0824 17:33:32.045284 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994202
I0824 17:33:32.045289 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.977795
I0824 17:33:32.045296 41887 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0824 17:33:48.664566 41887 solver.cpp:228] Iteration 960, loss = 0.0348362
I0824 17:33:48.664671 41887 solver.cpp:244]     Train net output #0: accuracy = 0.986429
I0824 17:33:48.664686 41887 solver.cpp:244]     Train net output #1: loss = 0.0348362 (* 1 = 0.0348362 loss)
I0824 17:33:48.664692 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983895
I0824 17:33:48.664696 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990647
I0824 17:33:48.664703 41887 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0824 17:34:05.263731 41887 solver.cpp:228] Iteration 980, loss = 0.0349655
I0824 17:34:05.263774 41887 solver.cpp:244]     Train net output #0: accuracy = 0.989342
I0824 17:34:05.263787 41887 solver.cpp:244]     Train net output #1: loss = 0.0349655 (* 1 = 0.0349655 loss)
I0824 17:34:05.263793 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993662
I0824 17:34:05.263798 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.969608
I0824 17:34:05.263806 41887 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0824 17:34:21.886261 41887 solver.cpp:228] Iteration 1000, loss = 0.0208522
I0824 17:34:21.886368 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991523
I0824 17:34:21.886381 41887 solver.cpp:244]     Train net output #1: loss = 0.0208522 (* 1 = 0.0208522 loss)
I0824 17:34:21.886387 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991131
I0824 17:34:21.886391 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993706
I0824 17:34:21.886399 41887 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0824 17:34:38.509464 41887 solver.cpp:228] Iteration 1020, loss = 0.051135
I0824 17:34:38.509507 41887 solver.cpp:244]     Train net output #0: accuracy = 0.979362
I0824 17:34:38.509519 41887 solver.cpp:244]     Train net output #1: loss = 0.051135 (* 1 = 0.051135 loss)
I0824 17:34:38.509526 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97764
I0824 17:34:38.509531 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98499
I0824 17:34:38.509537 41887 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0824 17:34:55.113603 41887 solver.cpp:228] Iteration 1040, loss = 0.02602
I0824 17:34:55.113773 41887 solver.cpp:244]     Train net output #0: accuracy = 0.989104
I0824 17:34:55.113816 41887 solver.cpp:244]     Train net output #1: loss = 0.02602 (* 1 = 0.02602 loss)
I0824 17:34:55.113823 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988732
I0824 17:34:55.113829 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990476
I0824 17:34:55.113838 41887 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0824 17:35:11.719975 41887 solver.cpp:228] Iteration 1060, loss = 0.0226046
I0824 17:35:11.720019 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991885
I0824 17:35:11.720036 41887 solver.cpp:244]     Train net output #1: loss = 0.0226046 (* 1 = 0.0226046 loss)
I0824 17:35:11.720043 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992013
I0824 17:35:11.720049 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991534
I0824 17:35:11.720057 41887 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0824 17:35:28.336585 41887 solver.cpp:228] Iteration 1080, loss = 0.0237818
I0824 17:35:28.336721 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991771
I0824 17:35:28.336738 41887 solver.cpp:244]     Train net output #1: loss = 0.0237818 (* 1 = 0.0237818 loss)
I0824 17:35:28.336750 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992532
I0824 17:35:28.336755 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989631
I0824 17:35:28.336762 41887 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0824 17:35:44.964898 41887 solver.cpp:228] Iteration 1100, loss = 0.0237284
I0824 17:35:44.964943 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99168
I0824 17:35:44.964957 41887 solver.cpp:244]     Train net output #1: loss = 0.0237284 (* 1 = 0.0237284 loss)
I0824 17:35:44.964964 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990769
I0824 17:35:44.964970 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993149
I0824 17:35:44.964977 41887 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0824 17:36:01.609035 41887 solver.cpp:228] Iteration 1120, loss = 0.0179096
I0824 17:36:01.609159 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994777
I0824 17:36:01.609174 41887 solver.cpp:244]     Train net output #1: loss = 0.0179096 (* 1 = 0.0179096 loss)
I0824 17:36:01.609187 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996904
I0824 17:36:01.609194 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985702
I0824 17:36:01.609201 41887 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0824 17:36:18.252534 41887 solver.cpp:228] Iteration 1140, loss = 0.0225087
I0824 17:36:18.252578 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991165
I0824 17:36:18.252591 41887 solver.cpp:244]     Train net output #1: loss = 0.0225087 (* 1 = 0.0225087 loss)
I0824 17:36:18.252599 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986494
I0824 17:36:18.252604 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99738
I0824 17:36:18.252611 41887 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0824 17:36:34.878228 41887 solver.cpp:228] Iteration 1160, loss = 0.0367528
I0824 17:36:34.878406 41887 solver.cpp:244]     Train net output #0: accuracy = 0.984055
I0824 17:36:34.878424 41887 solver.cpp:244]     Train net output #1: loss = 0.0367528 (* 1 = 0.0367528 loss)
I0824 17:36:34.878435 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979578
I0824 17:36:34.878446 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993282
I0824 17:36:34.878461 41887 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0824 17:36:51.522752 41887 solver.cpp:228] Iteration 1180, loss = 0.0274351
I0824 17:36:51.522792 41887 solver.cpp:244]     Train net output #0: accuracy = 0.988461
I0824 17:36:51.522807 41887 solver.cpp:244]     Train net output #1: loss = 0.0274351 (* 1 = 0.0274351 loss)
I0824 17:36:51.522814 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986208
I0824 17:36:51.522819 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994256
I0824 17:36:51.522826 41887 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0824 17:37:08.163944 41887 solver.cpp:228] Iteration 1200, loss = 0.0474852
I0824 17:37:08.164065 41887 solver.cpp:244]     Train net output #0: accuracy = 0.980236
I0824 17:37:08.164082 41887 solver.cpp:244]     Train net output #1: loss = 0.0474852 (* 1 = 0.0474852 loss)
I0824 17:37:08.164088 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975067
I0824 17:37:08.164093 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99381
I0824 17:37:08.164101 41887 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0824 17:37:24.783641 41887 solver.cpp:228] Iteration 1220, loss = 0.0175352
I0824 17:37:24.783689 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993183
I0824 17:37:24.783702 41887 solver.cpp:244]     Train net output #1: loss = 0.0175352 (* 1 = 0.0175352 loss)
I0824 17:37:24.783710 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992857
I0824 17:37:24.783715 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99407
I0824 17:37:24.783722 41887 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0824 17:37:41.420660 41887 solver.cpp:228] Iteration 1240, loss = 0.0254331
I0824 17:37:41.420768 41887 solver.cpp:244]     Train net output #0: accuracy = 0.989494
I0824 17:37:41.420783 41887 solver.cpp:244]     Train net output #1: loss = 0.0254331 (* 1 = 0.0254331 loss)
I0824 17:37:41.420792 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987872
I0824 17:37:41.420799 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993149
I0824 17:37:41.420805 41887 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0824 17:37:58.040463 41887 solver.cpp:228] Iteration 1260, loss = 0.020202
I0824 17:37:58.040511 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991224
I0824 17:37:58.040526 41887 solver.cpp:244]     Train net output #1: loss = 0.020202 (* 1 = 0.020202 loss)
I0824 17:37:58.040534 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989301
I0824 17:37:58.040539 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996472
I0824 17:37:58.040547 41887 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0824 17:38:14.672144 41887 solver.cpp:228] Iteration 1280, loss = 0.0246895
I0824 17:38:14.672256 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991466
I0824 17:38:14.672272 41887 solver.cpp:244]     Train net output #1: loss = 0.0246895 (* 1 = 0.0246895 loss)
I0824 17:38:14.672282 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988453
I0824 17:38:14.672287 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995256
I0824 17:38:14.672294 41887 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0824 17:38:31.303575 41887 solver.cpp:228] Iteration 1300, loss = 0.0238105
I0824 17:38:31.303614 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991494
I0824 17:38:31.303627 41887 solver.cpp:244]     Train net output #1: loss = 0.0238105 (* 1 = 0.0238105 loss)
I0824 17:38:31.303634 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987631
I0824 17:38:31.303639 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996266
I0824 17:38:31.303647 41887 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0824 17:38:47.932904 41887 solver.cpp:228] Iteration 1320, loss = 0.0160913
I0824 17:38:47.933091 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994336
I0824 17:38:47.933115 41887 solver.cpp:244]     Train net output #1: loss = 0.0160913 (* 1 = 0.0160913 loss)
I0824 17:38:47.933123 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994644
I0824 17:38:47.933128 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993624
I0824 17:38:47.933136 41887 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0824 17:39:04.551900 41887 solver.cpp:228] Iteration 1340, loss = 0.0395123
I0824 17:39:04.551945 41887 solver.cpp:244]     Train net output #0: accuracy = 0.985741
I0824 17:39:04.551959 41887 solver.cpp:244]     Train net output #1: loss = 0.0395123 (* 1 = 0.0395123 loss)
I0824 17:39:04.551965 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985789
I0824 17:39:04.551971 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985665
I0824 17:39:04.551978 41887 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0824 17:39:21.164412 41887 solver.cpp:228] Iteration 1360, loss = 0.020373
I0824 17:39:21.164535 41887 solver.cpp:244]     Train net output #0: accuracy = 0.992378
I0824 17:39:21.164551 41887 solver.cpp:244]     Train net output #1: loss = 0.020373 (* 1 = 0.020373 loss)
I0824 17:39:21.164561 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992507
I0824 17:39:21.164567 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991973
I0824 17:39:21.164575 41887 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0824 17:39:37.788472 41887 solver.cpp:228] Iteration 1380, loss = 0.016409
I0824 17:39:37.788516 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994187
I0824 17:39:37.788532 41887 solver.cpp:244]     Train net output #1: loss = 0.016409 (* 1 = 0.016409 loss)
I0824 17:39:37.788537 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995274
I0824 17:39:37.788542 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989895
I0824 17:39:37.788550 41887 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0824 17:39:54.416810 41887 solver.cpp:228] Iteration 1400, loss = 0.025198
I0824 17:39:54.416915 41887 solver.cpp:244]     Train net output #0: accuracy = 0.990609
I0824 17:39:54.416931 41887 solver.cpp:244]     Train net output #1: loss = 0.025198 (* 1 = 0.025198 loss)
I0824 17:39:54.416947 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990031
I0824 17:39:54.416961 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99279
I0824 17:39:54.416971 41887 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0824 17:40:11.043678 41887 solver.cpp:228] Iteration 1420, loss = 0.0257945
I0824 17:40:11.043715 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991403
I0824 17:40:11.043730 41887 solver.cpp:244]     Train net output #1: loss = 0.0257945 (* 1 = 0.0257945 loss)
I0824 17:40:11.043736 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991798
I0824 17:40:11.043743 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990748
I0824 17:40:11.043751 41887 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0824 17:40:27.669374 41887 solver.cpp:228] Iteration 1440, loss = 0.0206088
I0824 17:40:27.669492 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991173
I0824 17:40:27.669508 41887 solver.cpp:244]     Train net output #1: loss = 0.0206088 (* 1 = 0.0206088 loss)
I0824 17:40:27.669514 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987756
I0824 17:40:27.669519 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998253
I0824 17:40:27.669528 41887 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0824 17:40:44.298264 41887 solver.cpp:228] Iteration 1460, loss = 0.0325069
I0824 17:40:44.298310 41887 solver.cpp:244]     Train net output #0: accuracy = 0.986625
I0824 17:40:44.298326 41887 solver.cpp:244]     Train net output #1: loss = 0.0325069 (* 1 = 0.0325069 loss)
I0824 17:40:44.298332 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983004
I0824 17:40:44.298338 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9966
I0824 17:40:44.298346 41887 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0824 17:41:00.923399 41887 solver.cpp:228] Iteration 1480, loss = 0.110157
I0824 17:41:00.923569 41887 solver.cpp:244]     Train net output #0: accuracy = 0.976318
I0824 17:41:00.923593 41887 solver.cpp:244]     Train net output #1: loss = 0.110157 (* 1 = 0.110157 loss)
I0824 17:41:00.923601 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992523
I0824 17:41:00.923607 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.922906
I0824 17:41:00.923615 41887 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0824 17:41:17.555274 41887 solver.cpp:228] Iteration 1500, loss = 0.0312094
I0824 17:41:17.555321 41887 solver.cpp:244]     Train net output #0: accuracy = 0.985975
I0824 17:41:17.555336 41887 solver.cpp:244]     Train net output #1: loss = 0.0312094 (* 1 = 0.0312094 loss)
I0824 17:41:17.555351 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983506
I0824 17:41:17.555362 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996297
I0824 17:41:17.555371 41887 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0824 17:41:34.185113 41887 solver.cpp:228] Iteration 1520, loss = 0.131739
I0824 17:41:34.185233 41887 solver.cpp:244]     Train net output #0: accuracy = 0.961021
I0824 17:41:34.185250 41887 solver.cpp:244]     Train net output #1: loss = 0.131739 (* 1 = 0.131739 loss)
I0824 17:41:34.185264 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991448
I0824 17:41:34.185269 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.892044
I0824 17:41:34.185277 41887 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0824 17:41:50.819264 41887 solver.cpp:228] Iteration 1540, loss = 0.0390893
I0824 17:41:50.819304 41887 solver.cpp:244]     Train net output #0: accuracy = 0.984638
I0824 17:41:50.819317 41887 solver.cpp:244]     Train net output #1: loss = 0.0390893 (* 1 = 0.0390893 loss)
I0824 17:41:50.819324 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977299
I0824 17:41:50.819329 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99587
I0824 17:41:50.819337 41887 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0824 17:42:07.443882 41887 solver.cpp:228] Iteration 1560, loss = 0.0408701
I0824 17:42:07.444015 41887 solver.cpp:244]     Train net output #0: accuracy = 0.981632
I0824 17:42:07.444031 41887 solver.cpp:244]     Train net output #1: loss = 0.0408701 (* 1 = 0.0408701 loss)
I0824 17:42:07.444037 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97901
I0824 17:42:07.444043 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990456
I0824 17:42:07.444051 41887 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0824 17:42:24.073597 41887 solver.cpp:228] Iteration 1580, loss = 0.0381071
I0824 17:42:24.073642 41887 solver.cpp:244]     Train net output #0: accuracy = 0.986464
I0824 17:42:24.073654 41887 solver.cpp:244]     Train net output #1: loss = 0.0381071 (* 1 = 0.0381071 loss)
I0824 17:42:24.073662 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987524
I0824 17:42:24.073667 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98314
I0824 17:42:24.073675 41887 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0824 17:42:40.700956 41887 solver.cpp:228] Iteration 1600, loss = 0.0261009
I0824 17:42:40.701061 41887 solver.cpp:244]     Train net output #0: accuracy = 0.992196
I0824 17:42:40.701078 41887 solver.cpp:244]     Train net output #1: loss = 0.0261009 (* 1 = 0.0261009 loss)
I0824 17:42:40.701092 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993214
I0824 17:42:40.701097 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980796
I0824 17:42:40.701104 41887 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0824 17:42:57.334761 41887 solver.cpp:228] Iteration 1620, loss = 0.0186657
I0824 17:42:57.334805 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993621
I0824 17:42:57.334820 41887 solver.cpp:244]     Train net output #1: loss = 0.0186657 (* 1 = 0.0186657 loss)
I0824 17:42:57.334826 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994169
I0824 17:42:57.334832 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991987
I0824 17:42:57.334841 41887 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0824 17:43:13.959185 41887 solver.cpp:228] Iteration 1640, loss = 0.0318089
I0824 17:43:13.959358 41887 solver.cpp:244]     Train net output #0: accuracy = 0.985969
I0824 17:43:13.959380 41887 solver.cpp:244]     Train net output #1: loss = 0.0318089 (* 1 = 0.0318089 loss)
I0824 17:43:13.959390 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984117
I0824 17:43:13.959401 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992961
I0824 17:43:13.959410 41887 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0824 17:43:30.567817 41887 solver.cpp:228] Iteration 1660, loss = 0.044107
I0824 17:43:30.567857 41887 solver.cpp:244]     Train net output #0: accuracy = 0.980935
I0824 17:43:30.567870 41887 solver.cpp:244]     Train net output #1: loss = 0.044107 (* 1 = 0.044107 loss)
I0824 17:43:30.567876 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980647
I0824 17:43:30.567881 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984916
I0824 17:43:30.567888 41887 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0824 17:43:47.189060 41887 solver.cpp:228] Iteration 1680, loss = 0.0265362
I0824 17:43:47.189193 41887 solver.cpp:244]     Train net output #0: accuracy = 0.989763
I0824 17:43:47.189215 41887 solver.cpp:244]     Train net output #1: loss = 0.0265362 (* 1 = 0.0265362 loss)
I0824 17:43:47.189229 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98194
I0824 17:43:47.189234 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998615
I0824 17:43:47.189241 41887 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0824 17:44:03.810122 41887 solver.cpp:228] Iteration 1700, loss = 0.0174396
I0824 17:44:03.810169 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993562
I0824 17:44:03.810183 41887 solver.cpp:244]     Train net output #1: loss = 0.0174395 (* 1 = 0.0174395 loss)
I0824 17:44:03.810187 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994158
I0824 17:44:03.810194 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99114
I0824 17:44:03.810200 41887 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0824 17:44:20.419726 41887 solver.cpp:228] Iteration 1720, loss = 0.0219901
I0824 17:44:20.419839 41887 solver.cpp:244]     Train net output #0: accuracy = 0.990861
I0824 17:44:20.419855 41887 solver.cpp:244]     Train net output #1: loss = 0.0219901 (* 1 = 0.0219901 loss)
I0824 17:44:20.419867 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989153
I0824 17:44:20.419872 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995296
I0824 17:44:20.419880 41887 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0824 17:44:37.030586 41887 solver.cpp:228] Iteration 1740, loss = 0.0249129
I0824 17:44:37.030632 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991403
I0824 17:44:37.030645 41887 solver.cpp:244]     Train net output #1: loss = 0.0249129 (* 1 = 0.0249129 loss)
I0824 17:44:37.030653 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993048
I0824 17:44:37.030659 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986424
I0824 17:44:37.030668 41887 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0824 17:44:53.643539 41887 solver.cpp:228] Iteration 1760, loss = 0.0254514
I0824 17:44:53.643708 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991542
I0824 17:44:53.643724 41887 solver.cpp:244]     Train net output #1: loss = 0.0254514 (* 1 = 0.0254514 loss)
I0824 17:44:53.643731 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992673
I0824 17:44:53.643740 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987707
I0824 17:44:53.643748 41887 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0824 17:45:10.266343 41887 solver.cpp:228] Iteration 1780, loss = 0.0171669
I0824 17:45:10.266386 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994444
I0824 17:45:10.266398 41887 solver.cpp:244]     Train net output #1: loss = 0.0171669 (* 1 = 0.0171669 loss)
I0824 17:45:10.266404 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995326
I0824 17:45:10.266410 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987001
I0824 17:45:10.266417 41887 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0824 17:45:26.893069 41887 solver.cpp:228] Iteration 1800, loss = 0.0178497
I0824 17:45:26.893196 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993895
I0824 17:45:26.893211 41887 solver.cpp:244]     Train net output #1: loss = 0.0178497 (* 1 = 0.0178497 loss)
I0824 17:45:26.893218 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99434
I0824 17:45:26.893224 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992836
I0824 17:45:26.893230 41887 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0824 17:45:43.663527 41887 solver.cpp:228] Iteration 1820, loss = 0.0256897
I0824 17:45:43.663585 41887 solver.cpp:244]     Train net output #0: accuracy = 0.990405
I0824 17:45:43.663599 41887 solver.cpp:244]     Train net output #1: loss = 0.0256897 (* 1 = 0.0256897 loss)
I0824 17:45:43.663605 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990341
I0824 17:45:43.663612 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990588
I0824 17:45:43.663621 41887 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0824 17:46:00.682488 41887 solver.cpp:228] Iteration 1840, loss = 0.0255374
I0824 17:46:00.682636 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99001
I0824 17:46:00.682652 41887 solver.cpp:244]     Train net output #1: loss = 0.0255374 (* 1 = 0.0255374 loss)
I0824 17:46:00.682658 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989534
I0824 17:46:00.682664 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992012
I0824 17:46:00.682672 41887 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0824 17:46:17.303886 41887 solver.cpp:228] Iteration 1860, loss = 0.0171991
I0824 17:46:17.303928 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993597
I0824 17:46:17.303941 41887 solver.cpp:244]     Train net output #1: loss = 0.0171991 (* 1 = 0.0171991 loss)
I0824 17:46:17.303948 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993459
I0824 17:46:17.303953 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994749
I0824 17:46:17.303961 41887 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0824 17:46:33.940004 41887 solver.cpp:228] Iteration 1880, loss = 0.0198345
I0824 17:46:33.940124 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991866
I0824 17:46:33.940140 41887 solver.cpp:244]     Train net output #1: loss = 0.0198345 (* 1 = 0.0198345 loss)
I0824 17:46:33.940155 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99152
I0824 17:46:33.940160 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992723
I0824 17:46:33.940170 41887 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0824 17:46:50.563454 41887 solver.cpp:228] Iteration 1900, loss = 0.0111024
I0824 17:46:50.563503 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995635
I0824 17:46:50.563515 41887 solver.cpp:244]     Train net output #1: loss = 0.0111024 (* 1 = 0.0111024 loss)
I0824 17:46:50.563522 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995007
I0824 17:46:50.563529 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996947
I0824 17:46:50.563536 41887 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0824 17:47:07.183606 41887 solver.cpp:228] Iteration 1920, loss = 0.0221496
I0824 17:47:07.183774 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991762
I0824 17:47:07.183791 41887 solver.cpp:244]     Train net output #1: loss = 0.0221496 (* 1 = 0.0221496 loss)
I0824 17:47:07.183797 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992426
I0824 17:47:07.183802 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989032
I0824 17:47:07.183809 41887 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0824 17:47:23.815354 41887 solver.cpp:228] Iteration 1940, loss = 0.0127195
I0824 17:47:23.815404 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995221
I0824 17:47:23.815420 41887 solver.cpp:244]     Train net output #1: loss = 0.0127195 (* 1 = 0.0127195 loss)
I0824 17:47:23.815428 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99584
I0824 17:47:23.815433 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992048
I0824 17:47:23.815439 41887 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0824 17:47:40.439486 41887 solver.cpp:228] Iteration 1960, loss = 0.0164871
I0824 17:47:40.439621 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993126
I0824 17:47:40.439640 41887 solver.cpp:244]     Train net output #1: loss = 0.0164871 (* 1 = 0.0164871 loss)
I0824 17:47:40.439651 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991397
I0824 17:47:40.439657 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996872
I0824 17:47:40.439666 41887 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0824 17:47:57.066634 41887 solver.cpp:228] Iteration 1980, loss = 0.0187117
I0824 17:47:57.066679 41887 solver.cpp:244]     Train net output #0: accuracy = 0.992733
I0824 17:47:57.066692 41887 solver.cpp:244]     Train net output #1: loss = 0.0187117 (* 1 = 0.0187117 loss)
I0824 17:47:57.066699 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993041
I0824 17:47:57.066705 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990037
I0824 17:47:57.066714 41887 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0824 17:48:13.696632 41887 solver.cpp:228] Iteration 2000, loss = 0.0161611
I0824 17:48:13.696763 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993234
I0824 17:48:13.696779 41887 solver.cpp:244]     Train net output #1: loss = 0.0161611 (* 1 = 0.0161611 loss)
I0824 17:48:13.696792 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993403
I0824 17:48:13.696804 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992614
I0824 17:48:13.696812 41887 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0824 17:48:30.339257 41887 solver.cpp:228] Iteration 2020, loss = 0.0174599
I0824 17:48:30.339303 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993547
I0824 17:48:30.339316 41887 solver.cpp:244]     Train net output #1: loss = 0.0174599 (* 1 = 0.0174599 loss)
I0824 17:48:30.339323 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992338
I0824 17:48:30.339329 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995707
I0824 17:48:30.339336 41887 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0824 17:48:46.977309 41887 solver.cpp:228] Iteration 2040, loss = 0.0295811
I0824 17:48:46.977475 41887 solver.cpp:244]     Train net output #0: accuracy = 0.989604
I0824 17:48:46.977517 41887 solver.cpp:244]     Train net output #1: loss = 0.0295811 (* 1 = 0.0295811 loss)
I0824 17:48:46.977527 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991096
I0824 17:48:46.977535 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984296
I0824 17:48:46.977543 41887 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0824 17:49:03.620635 41887 solver.cpp:228] Iteration 2060, loss = 0.0113181
I0824 17:49:03.620682 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995285
I0824 17:49:03.620697 41887 solver.cpp:244]     Train net output #1: loss = 0.0113181 (* 1 = 0.0113181 loss)
I0824 17:49:03.620704 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994638
I0824 17:49:03.620710 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997835
I0824 17:49:03.620718 41887 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0824 17:49:20.268864 41887 solver.cpp:228] Iteration 2080, loss = 0.0129631
I0824 17:49:20.269055 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994792
I0824 17:49:20.269073 41887 solver.cpp:244]     Train net output #1: loss = 0.0129631 (* 1 = 0.0129631 loss)
I0824 17:49:20.269079 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994477
I0824 17:49:20.269084 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995966
I0824 17:49:20.269091 41887 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0824 17:49:36.877056 41887 solver.cpp:228] Iteration 2100, loss = 0.0280939
I0824 17:49:36.877102 41887 solver.cpp:244]     Train net output #0: accuracy = 0.989789
I0824 17:49:36.877118 41887 solver.cpp:244]     Train net output #1: loss = 0.0280938 (* 1 = 0.0280938 loss)
I0824 17:49:36.877125 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987837
I0824 17:49:36.877131 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992978
I0824 17:49:36.877138 41887 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0824 17:49:53.508355 41887 solver.cpp:228] Iteration 2120, loss = 0.0291416
I0824 17:49:53.508474 41887 solver.cpp:244]     Train net output #0: accuracy = 0.990544
I0824 17:49:53.508491 41887 solver.cpp:244]     Train net output #1: loss = 0.0291416 (* 1 = 0.0291416 loss)
I0824 17:49:53.508503 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987819
I0824 17:49:53.508508 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993768
I0824 17:49:53.508517 41887 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0824 17:50:10.155719 41887 solver.cpp:228] Iteration 2140, loss = 0.0220771
I0824 17:50:10.155766 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991561
I0824 17:50:10.155781 41887 solver.cpp:244]     Train net output #1: loss = 0.0220771 (* 1 = 0.0220771 loss)
I0824 17:50:10.155788 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990286
I0824 17:50:10.155794 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994055
I0824 17:50:10.155803 41887 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0824 17:50:26.791569 41887 solver.cpp:228] Iteration 2160, loss = 0.0133304
I0824 17:50:26.791678 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995108
I0824 17:50:26.791697 41887 solver.cpp:244]     Train net output #1: loss = 0.0133303 (* 1 = 0.0133303 loss)
I0824 17:50:26.791702 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994764
I0824 17:50:26.791708 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996193
I0824 17:50:26.791716 41887 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0824 17:50:43.406031 41887 solver.cpp:228] Iteration 2180, loss = 0.0229598
I0824 17:50:43.406075 41887 solver.cpp:244]     Train net output #0: accuracy = 0.992302
I0824 17:50:43.406090 41887 solver.cpp:244]     Train net output #1: loss = 0.0229598 (* 1 = 0.0229598 loss)
I0824 17:50:43.406095 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989848
I0824 17:50:43.406101 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995519
I0824 17:50:43.406108 41887 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0824 17:51:00.034386 41887 solver.cpp:228] Iteration 2200, loss = 0.0221693
I0824 17:51:00.034559 41887 solver.cpp:244]     Train net output #0: accuracy = 0.991725
I0824 17:51:00.034579 41887 solver.cpp:244]     Train net output #1: loss = 0.0221693 (* 1 = 0.0221693 loss)
I0824 17:51:00.034590 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993008
I0824 17:51:00.034595 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983782
I0824 17:51:00.034603 41887 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0824 17:51:16.647891 41887 solver.cpp:228] Iteration 2220, loss = 0.0147452
I0824 17:51:16.647936 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993857
I0824 17:51:16.647950 41887 solver.cpp:244]     Train net output #1: loss = 0.0147452 (* 1 = 0.0147452 loss)
I0824 17:51:16.647956 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992712
I0824 17:51:16.647963 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996764
I0824 17:51:16.647970 41887 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0824 17:51:33.269264 41887 solver.cpp:228] Iteration 2240, loss = 0.014268
I0824 17:51:33.269384 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99435
I0824 17:51:33.269402 41887 solver.cpp:244]     Train net output #1: loss = 0.0142679 (* 1 = 0.0142679 loss)
I0824 17:51:33.269418 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993581
I0824 17:51:33.269424 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996273
I0824 17:51:33.269433 41887 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0824 17:51:49.891939 41887 solver.cpp:228] Iteration 2260, loss = 0.0168036
I0824 17:51:49.891979 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994071
I0824 17:51:49.891993 41887 solver.cpp:244]     Train net output #1: loss = 0.0168036 (* 1 = 0.0168036 loss)
I0824 17:51:49.892000 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995029
I0824 17:51:49.892005 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990592
I0824 17:51:49.892012 41887 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0824 17:52:06.512907 41887 solver.cpp:228] Iteration 2280, loss = 0.0175976
I0824 17:52:06.513041 41887 solver.cpp:244]     Train net output #0: accuracy = 0.992898
I0824 17:52:06.513084 41887 solver.cpp:244]     Train net output #1: loss = 0.0175976 (* 1 = 0.0175976 loss)
I0824 17:52:06.513093 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99247
I0824 17:52:06.513098 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995862
I0824 17:52:06.513108 41887 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0824 17:52:23.143651 41887 solver.cpp:228] Iteration 2300, loss = 0.0114392
I0824 17:52:23.143699 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995738
I0824 17:52:23.143714 41887 solver.cpp:244]     Train net output #1: loss = 0.0114392 (* 1 = 0.0114392 loss)
I0824 17:52:23.143728 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996116
I0824 17:52:23.143734 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992738
I0824 17:52:23.143741 41887 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0824 17:52:39.766546 41887 solver.cpp:228] Iteration 2320, loss = 0.0202885
I0824 17:52:39.766664 41887 solver.cpp:244]     Train net output #0: accuracy = 0.992147
I0824 17:52:39.766680 41887 solver.cpp:244]     Train net output #1: loss = 0.0202885 (* 1 = 0.0202885 loss)
I0824 17:52:39.766687 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991122
I0824 17:52:39.766692 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994146
I0824 17:52:39.766700 41887 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0824 17:52:56.397982 41887 solver.cpp:228] Iteration 2340, loss = 0.0130387
I0824 17:52:56.398030 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994864
I0824 17:52:56.398043 41887 solver.cpp:244]     Train net output #1: loss = 0.0130387 (* 1 = 0.0130387 loss)
I0824 17:52:56.398051 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995225
I0824 17:52:56.398056 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993834
I0824 17:52:56.398066 41887 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0824 17:53:13.025970 41887 solver.cpp:228] Iteration 2360, loss = 0.0103431
I0824 17:53:13.026144 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996115
I0824 17:53:13.026160 41887 solver.cpp:244]     Train net output #1: loss = 0.0103431 (* 1 = 0.0103431 loss)
I0824 17:53:13.026171 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995897
I0824 17:53:13.026177 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996499
I0824 17:53:13.026185 41887 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0824 17:53:29.651468 41887 solver.cpp:228] Iteration 2380, loss = 0.0167122
I0824 17:53:29.651509 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994384
I0824 17:53:29.651525 41887 solver.cpp:244]     Train net output #1: loss = 0.0167121 (* 1 = 0.0167121 loss)
I0824 17:53:29.651531 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995992
I0824 17:53:29.651536 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988483
I0824 17:53:29.651543 41887 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0824 17:53:46.292670 41887 solver.cpp:228] Iteration 2400, loss = 0.0145021
I0824 17:53:46.292810 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994984
I0824 17:53:46.292829 41887 solver.cpp:244]     Train net output #1: loss = 0.0145021 (* 1 = 0.0145021 loss)
I0824 17:53:46.292841 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995232
I0824 17:53:46.292847 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994416
I0824 17:53:46.292855 41887 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0824 17:54:02.913110 41887 solver.cpp:228] Iteration 2420, loss = 0.0115141
I0824 17:54:02.913153 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995195
I0824 17:54:02.913166 41887 solver.cpp:244]     Train net output #1: loss = 0.0115141 (* 1 = 0.0115141 loss)
I0824 17:54:02.913172 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994329
I0824 17:54:02.913177 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996879
I0824 17:54:02.913185 41887 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0824 17:54:19.548686 41887 solver.cpp:228] Iteration 2440, loss = 0.0121601
I0824 17:54:19.548805 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995663
I0824 17:54:19.548823 41887 solver.cpp:244]     Train net output #1: loss = 0.0121601 (* 1 = 0.0121601 loss)
I0824 17:54:19.548832 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995863
I0824 17:54:19.548844 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994048
I0824 17:54:19.548853 41887 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0824 17:54:36.170850 41887 solver.cpp:228] Iteration 2460, loss = 0.0246793
I0824 17:54:36.170894 41887 solver.cpp:244]     Train net output #0: accuracy = 0.990746
I0824 17:54:36.170907 41887 solver.cpp:244]     Train net output #1: loss = 0.0246793 (* 1 = 0.0246793 loss)
I0824 17:54:36.170914 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984627
I0824 17:54:36.170919 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996959
I0824 17:54:36.170928 41887 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0824 17:54:52.809372 41887 solver.cpp:228] Iteration 2480, loss = 0.0226478
I0824 17:54:52.809497 41887 solver.cpp:244]     Train net output #0: accuracy = 0.9911
I0824 17:54:52.809515 41887 solver.cpp:244]     Train net output #1: loss = 0.0226478 (* 1 = 0.0226478 loss)
I0824 17:54:52.809522 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991718
I0824 17:54:52.809528 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989565
I0824 17:54:52.809537 41887 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0824 17:55:09.434425 41887 solver.cpp:228] Iteration 2500, loss = 0.0153181
I0824 17:55:09.434464 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993974
I0824 17:55:09.434480 41887 solver.cpp:244]     Train net output #1: loss = 0.0153181 (* 1 = 0.0153181 loss)
I0824 17:55:09.434486 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993048
I0824 17:55:09.434494 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996013
I0824 17:55:09.434500 41887 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0824 17:55:26.059211 41887 solver.cpp:228] Iteration 2520, loss = 0.0100723
I0824 17:55:26.059362 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995687
I0824 17:55:26.059379 41887 solver.cpp:244]     Train net output #1: loss = 0.0100723 (* 1 = 0.0100723 loss)
I0824 17:55:26.059386 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995807
I0824 17:55:26.059391 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995108
I0824 17:55:26.059399 41887 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0824 17:55:42.695147 41887 solver.cpp:228] Iteration 2540, loss = 0.0163692
I0824 17:55:42.695194 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993675
I0824 17:55:42.695209 41887 solver.cpp:244]     Train net output #1: loss = 0.0163692 (* 1 = 0.0163692 loss)
I0824 17:55:42.695215 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992061
I0824 17:55:42.695221 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996539
I0824 17:55:42.695230 41887 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0824 17:55:59.317625 41887 solver.cpp:228] Iteration 2560, loss = 0.0144115
I0824 17:55:59.317728 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995667
I0824 17:55:59.317744 41887 solver.cpp:244]     Train net output #1: loss = 0.0144115 (* 1 = 0.0144115 loss)
I0824 17:55:59.317752 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996799
I0824 17:55:59.317757 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.973039
I0824 17:55:59.317765 41887 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0824 17:56:15.951597 41887 solver.cpp:228] Iteration 2580, loss = 0.0156458
I0824 17:56:15.951644 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99452
I0824 17:56:15.951659 41887 solver.cpp:244]     Train net output #1: loss = 0.0156458 (* 1 = 0.0156458 loss)
I0824 17:56:15.951668 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994935
I0824 17:56:15.951673 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993675
I0824 17:56:15.951681 41887 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0824 17:56:32.593979 41887 solver.cpp:228] Iteration 2600, loss = 0.0191994
I0824 17:56:32.594089 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99394
I0824 17:56:32.594105 41887 solver.cpp:244]     Train net output #1: loss = 0.0191994 (* 1 = 0.0191994 loss)
I0824 17:56:32.594111 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990003
I0824 17:56:32.594117 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998048
I0824 17:56:32.594125 41887 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0824 17:56:49.230842 41887 solver.cpp:228] Iteration 2620, loss = 0.0196671
I0824 17:56:49.230882 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993912
I0824 17:56:49.230896 41887 solver.cpp:244]     Train net output #1: loss = 0.0196671 (* 1 = 0.0196671 loss)
I0824 17:56:49.230903 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995242
I0824 17:56:49.230909 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987568
I0824 17:56:49.230916 41887 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0824 17:57:05.852638 41887 solver.cpp:228] Iteration 2640, loss = 0.0118194
I0824 17:57:05.852744 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995715
I0824 17:57:05.852762 41887 solver.cpp:244]     Train net output #1: loss = 0.0118194 (* 1 = 0.0118194 loss)
I0824 17:57:05.852777 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995588
I0824 17:57:05.852782 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996048
I0824 17:57:05.852790 41887 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0824 17:57:22.486686 41887 solver.cpp:228] Iteration 2660, loss = 0.0147773
I0824 17:57:22.486729 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994232
I0824 17:57:22.486744 41887 solver.cpp:244]     Train net output #1: loss = 0.0147773 (* 1 = 0.0147773 loss)
I0824 17:57:22.486750 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992683
I0824 17:57:22.486757 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996955
I0824 17:57:22.486763 41887 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0824 17:57:39.125236 41887 solver.cpp:228] Iteration 2680, loss = 0.0155413
I0824 17:57:39.125417 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994871
I0824 17:57:39.125447 41887 solver.cpp:244]     Train net output #1: loss = 0.0155413 (* 1 = 0.0155413 loss)
I0824 17:57:39.125457 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996314
I0824 17:57:39.125463 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990307
I0824 17:57:39.125473 41887 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0824 17:57:55.770112 41887 solver.cpp:228] Iteration 2700, loss = 0.016305
I0824 17:57:55.770156 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994028
I0824 17:57:55.770170 41887 solver.cpp:244]     Train net output #1: loss = 0.016305 (* 1 = 0.016305 loss)
I0824 17:57:55.770176 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994342
I0824 17:57:55.770184 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993186
I0824 17:57:55.770190 41887 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0824 17:58:12.393086 41887 solver.cpp:228] Iteration 2720, loss = 0.00895889
I0824 17:58:12.393208 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996244
I0824 17:58:12.393224 41887 solver.cpp:244]     Train net output #1: loss = 0.00895888 (* 1 = 0.00895888 loss)
I0824 17:58:12.393231 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996307
I0824 17:58:12.393237 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995895
I0824 17:58:12.393246 41887 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0824 17:58:29.004870 41887 solver.cpp:228] Iteration 2740, loss = 0.0150319
I0824 17:58:29.004912 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994288
I0824 17:58:29.004926 41887 solver.cpp:244]     Train net output #1: loss = 0.0150319 (* 1 = 0.0150319 loss)
I0824 17:58:29.004933 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991836
I0824 17:58:29.004938 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998098
I0824 17:58:29.004946 41887 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0824 17:58:45.654940 41887 solver.cpp:228] Iteration 2760, loss = 0.0147976
I0824 17:58:45.655058 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995336
I0824 17:58:45.655074 41887 solver.cpp:244]     Train net output #1: loss = 0.0147976 (* 1 = 0.0147976 loss)
I0824 17:58:45.655086 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993946
I0824 17:58:45.655092 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99699
I0824 17:58:45.655100 41887 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0824 17:59:02.286640 41887 solver.cpp:228] Iteration 2780, loss = 0.0128973
I0824 17:59:02.286687 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995237
I0824 17:59:02.286701 41887 solver.cpp:244]     Train net output #1: loss = 0.0128973 (* 1 = 0.0128973 loss)
I0824 17:59:02.286708 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994938
I0824 17:59:02.286713 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996347
I0824 17:59:02.286721 41887 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0824 17:59:18.928395 41887 solver.cpp:228] Iteration 2800, loss = 0.0131079
I0824 17:59:18.928576 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995145
I0824 17:59:18.928593 41887 solver.cpp:244]     Train net output #1: loss = 0.0131079 (* 1 = 0.0131079 loss)
I0824 17:59:18.928603 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996451
I0824 17:59:18.928609 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988189
I0824 17:59:18.928617 41887 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0824 17:59:35.555591 41887 solver.cpp:228] Iteration 2820, loss = 0.0164718
I0824 17:59:35.555639 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995216
I0824 17:59:35.555655 41887 solver.cpp:244]     Train net output #1: loss = 0.0164718 (* 1 = 0.0164718 loss)
I0824 17:59:35.555661 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997139
I0824 17:59:35.555667 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985659
I0824 17:59:35.555675 41887 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0824 17:59:52.197163 41887 solver.cpp:228] Iteration 2840, loss = 0.0107557
I0824 17:59:52.197271 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995865
I0824 17:59:52.197288 41887 solver.cpp:244]     Train net output #1: loss = 0.0107557 (* 1 = 0.0107557 loss)
I0824 17:59:52.197294 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9952
I0824 17:59:52.197306 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997312
I0824 17:59:52.197319 41887 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0824 18:00:08.826313 41887 solver.cpp:228] Iteration 2860, loss = 0.0136233
I0824 18:00:08.826352 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99589
I0824 18:00:08.826369 41887 solver.cpp:244]     Train net output #1: loss = 0.0136233 (* 1 = 0.0136233 loss)
I0824 18:00:08.826375 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995048
I0824 18:00:08.826381 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996899
I0824 18:00:08.826390 41887 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0824 18:00:25.469347 41887 solver.cpp:228] Iteration 2880, loss = 0.0156172
I0824 18:00:25.469485 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994363
I0824 18:00:25.469502 41887 solver.cpp:244]     Train net output #1: loss = 0.0156172 (* 1 = 0.0156172 loss)
I0824 18:00:25.469513 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993391
I0824 18:00:25.469518 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997052
I0824 18:00:25.469527 41887 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0824 18:00:42.098429 41887 solver.cpp:228] Iteration 2900, loss = 0.0166732
I0824 18:00:42.098474 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993248
I0824 18:00:42.098487 41887 solver.cpp:244]     Train net output #1: loss = 0.0166732 (* 1 = 0.0166732 loss)
I0824 18:00:42.098495 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992876
I0824 18:00:42.098500 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994327
I0824 18:00:42.098510 41887 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0824 18:00:58.704558 41887 solver.cpp:228] Iteration 2920, loss = 0.0139028
I0824 18:00:58.704699 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995137
I0824 18:00:58.704716 41887 solver.cpp:244]     Train net output #1: loss = 0.0139028 (* 1 = 0.0139028 loss)
I0824 18:00:58.704723 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995833
I0824 18:00:58.704728 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992342
I0824 18:00:58.704736 41887 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0824 18:01:15.306917 41887 solver.cpp:228] Iteration 2940, loss = 0.0115276
I0824 18:01:15.306959 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995828
I0824 18:01:15.306973 41887 solver.cpp:244]     Train net output #1: loss = 0.0115276 (* 1 = 0.0115276 loss)
I0824 18:01:15.306979 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995647
I0824 18:01:15.306984 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996294
I0824 18:01:15.306991 41887 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0824 18:01:31.915953 41887 solver.cpp:228] Iteration 2960, loss = 0.0168231
I0824 18:01:31.916127 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993323
I0824 18:01:31.916146 41887 solver.cpp:244]     Train net output #1: loss = 0.0168231 (* 1 = 0.0168231 loss)
I0824 18:01:31.916152 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991628
I0824 18:01:31.916158 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997181
I0824 18:01:31.916167 41887 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0824 18:01:48.526574 41887 solver.cpp:228] Iteration 2980, loss = 0.0141976
I0824 18:01:48.526612 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994867
I0824 18:01:48.526625 41887 solver.cpp:244]     Train net output #1: loss = 0.0141976 (* 1 = 0.0141976 loss)
I0824 18:01:48.526631 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994403
I0824 18:01:48.526636 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995835
I0824 18:01:48.526643 41887 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0824 18:02:05.154222 41887 solver.cpp:228] Iteration 3000, loss = 0.0172457
I0824 18:02:05.154335 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993302
I0824 18:02:05.154350 41887 solver.cpp:244]     Train net output #1: loss = 0.0172457 (* 1 = 0.0172457 loss)
I0824 18:02:05.154356 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993703
I0824 18:02:05.154361 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991031
I0824 18:02:05.154368 41887 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0824 18:02:21.771322 41887 solver.cpp:228] Iteration 3020, loss = 0.0114376
I0824 18:02:21.771366 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996178
I0824 18:02:21.771380 41887 solver.cpp:244]     Train net output #1: loss = 0.0114376 (* 1 = 0.0114376 loss)
I0824 18:02:21.771389 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994823
I0824 18:02:21.771394 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997888
I0824 18:02:21.771402 41887 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0824 18:02:38.374699 41887 solver.cpp:228] Iteration 3040, loss = 0.0107916
I0824 18:02:38.374809 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99606
I0824 18:02:38.374825 41887 solver.cpp:244]     Train net output #1: loss = 0.0107916 (* 1 = 0.0107916 loss)
I0824 18:02:38.374830 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996435
I0824 18:02:38.374835 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995413
I0824 18:02:38.374842 41887 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0824 18:02:54.987952 41887 solver.cpp:228] Iteration 3060, loss = 0.0125225
I0824 18:02:54.987996 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994617
I0824 18:02:54.988010 41887 solver.cpp:244]     Train net output #1: loss = 0.0125225 (* 1 = 0.0125225 loss)
I0824 18:02:54.988018 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993794
I0824 18:02:54.988024 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99867
I0824 18:02:54.988040 41887 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0824 18:03:11.600214 41887 solver.cpp:228] Iteration 3080, loss = 0.00978682
I0824 18:03:11.600335 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995703
I0824 18:03:11.600348 41887 solver.cpp:244]     Train net output #1: loss = 0.00978681 (* 1 = 0.00978681 loss)
I0824 18:03:11.600354 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995601
I0824 18:03:11.600358 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996246
I0824 18:03:11.600366 41887 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0824 18:03:28.225601 41887 solver.cpp:228] Iteration 3100, loss = 0.0179314
I0824 18:03:28.225639 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993666
I0824 18:03:28.225653 41887 solver.cpp:244]     Train net output #1: loss = 0.0179314 (* 1 = 0.0179314 loss)
I0824 18:03:28.225659 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993459
I0824 18:03:28.225664 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994243
I0824 18:03:28.225672 41887 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0824 18:03:44.836941 41887 solver.cpp:228] Iteration 3120, loss = 0.00889603
I0824 18:03:44.837100 41887 solver.cpp:244]     Train net output #0: accuracy = 0.9964
I0824 18:03:44.837116 41887 solver.cpp:244]     Train net output #1: loss = 0.00889602 (* 1 = 0.00889602 loss)
I0824 18:03:44.837129 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99593
I0824 18:03:44.837134 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997617
I0824 18:03:44.837142 41887 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0824 18:04:01.423022 41887 solver.cpp:228] Iteration 3140, loss = 0.0126383
I0824 18:04:01.423065 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995386
I0824 18:04:01.423079 41887 solver.cpp:244]     Train net output #1: loss = 0.0126383 (* 1 = 0.0126383 loss)
I0824 18:04:01.423084 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995241
I0824 18:04:01.423089 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995892
I0824 18:04:01.423096 41887 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0824 18:04:18.048126 41887 solver.cpp:228] Iteration 3160, loss = 0.0181622
I0824 18:04:18.048235 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993514
I0824 18:04:18.048251 41887 solver.cpp:244]     Train net output #1: loss = 0.0181622 (* 1 = 0.0181622 loss)
I0824 18:04:18.048264 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994064
I0824 18:04:18.048275 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991765
I0824 18:04:18.048283 41887 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0824 18:04:34.652979 41887 solver.cpp:228] Iteration 3180, loss = 0.0135788
I0824 18:04:34.653023 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995344
I0824 18:04:34.653034 41887 solver.cpp:244]     Train net output #1: loss = 0.0135788 (* 1 = 0.0135788 loss)
I0824 18:04:34.653041 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996334
I0824 18:04:34.653045 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992466
I0824 18:04:34.653053 41887 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0824 18:04:51.259423 41887 solver.cpp:228] Iteration 3200, loss = 0.0136296
I0824 18:04:51.259536 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995213
I0824 18:04:51.259552 41887 solver.cpp:244]     Train net output #1: loss = 0.0136296 (* 1 = 0.0136296 loss)
I0824 18:04:51.259564 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994247
I0824 18:04:51.259572 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997189
I0824 18:04:51.259579 41887 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0824 18:05:07.869333 41887 solver.cpp:228] Iteration 3220, loss = 0.011598
I0824 18:05:07.869377 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996373
I0824 18:05:07.869391 41887 solver.cpp:244]     Train net output #1: loss = 0.011598 (* 1 = 0.011598 loss)
I0824 18:05:07.869396 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99706
I0824 18:05:07.869401 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990641
I0824 18:05:07.869408 41887 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0824 18:05:24.477020 41887 solver.cpp:228] Iteration 3240, loss = 0.0274151
I0824 18:05:24.477129 41887 solver.cpp:244]     Train net output #0: accuracy = 0.989559
I0824 18:05:24.477144 41887 solver.cpp:244]     Train net output #1: loss = 0.0274151 (* 1 = 0.0274151 loss)
I0824 18:05:24.477150 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989187
I0824 18:05:24.477155 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990814
I0824 18:05:24.477162 41887 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0824 18:05:41.083240 41887 solver.cpp:228] Iteration 3260, loss = 0.0226074
I0824 18:05:41.083287 41887 solver.cpp:244]     Train net output #0: accuracy = 0.992397
I0824 18:05:41.083302 41887 solver.cpp:244]     Train net output #1: loss = 0.0226073 (* 1 = 0.0226073 loss)
I0824 18:05:41.083308 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986749
I0824 18:05:41.083314 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997672
I0824 18:05:41.083323 41887 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0824 18:05:57.684034 41887 solver.cpp:228] Iteration 3280, loss = 0.016636
I0824 18:05:57.684186 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994566
I0824 18:05:57.684201 41887 solver.cpp:244]     Train net output #1: loss = 0.016636 (* 1 = 0.016636 loss)
I0824 18:05:57.684207 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99555
I0824 18:05:57.684212 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991778
I0824 18:05:57.684219 41887 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0824 18:06:14.289865 41887 solver.cpp:228] Iteration 3300, loss = 0.0554422
I0824 18:06:14.289911 41887 solver.cpp:244]     Train net output #0: accuracy = 0.982373
I0824 18:06:14.289927 41887 solver.cpp:244]     Train net output #1: loss = 0.0554422 (* 1 = 0.0554422 loss)
I0824 18:06:14.289933 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977302
I0824 18:06:14.289940 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993332
I0824 18:06:14.289948 41887 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0824 18:06:30.889786 41887 solver.cpp:228] Iteration 3320, loss = 0.018589
I0824 18:06:30.889922 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994719
I0824 18:06:30.889963 41887 solver.cpp:244]     Train net output #1: loss = 0.018589 (* 1 = 0.018589 loss)
I0824 18:06:30.889973 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9959
I0824 18:06:30.889979 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992948
I0824 18:06:30.889988 41887 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0824 18:06:47.508973 41887 solver.cpp:228] Iteration 3340, loss = 0.0146538
I0824 18:06:47.509016 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994044
I0824 18:06:47.509033 41887 solver.cpp:244]     Train net output #1: loss = 0.0146538 (* 1 = 0.0146538 loss)
I0824 18:06:47.509040 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9936
I0824 18:06:47.509045 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995014
I0824 18:06:47.509053 41887 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0824 18:07:04.149468 41887 solver.cpp:228] Iteration 3360, loss = 0.0158638
I0824 18:07:04.149596 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995071
I0824 18:07:04.149615 41887 solver.cpp:244]     Train net output #1: loss = 0.0158638 (* 1 = 0.0158638 loss)
I0824 18:07:04.149626 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994218
I0824 18:07:04.149637 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996203
I0824 18:07:04.149646 41887 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0824 18:07:20.784342 41887 solver.cpp:228] Iteration 3380, loss = 0.0132143
I0824 18:07:20.784385 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99499
I0824 18:07:20.784399 41887 solver.cpp:244]     Train net output #1: loss = 0.0132143 (* 1 = 0.0132143 loss)
I0824 18:07:20.784406 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99375
I0824 18:07:20.784411 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998025
I0824 18:07:20.784420 41887 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0824 18:07:37.417817 41887 solver.cpp:228] Iteration 3400, loss = 0.00706512
I0824 18:07:37.417995 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996826
I0824 18:07:37.418014 41887 solver.cpp:244]     Train net output #1: loss = 0.00706512 (* 1 = 0.00706512 loss)
I0824 18:07:37.418021 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996648
I0824 18:07:37.418028 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997835
I0824 18:07:37.418036 41887 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0824 18:07:54.048888 41887 solver.cpp:228] Iteration 3420, loss = 0.0149677
I0824 18:07:54.048931 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994155
I0824 18:07:54.048946 41887 solver.cpp:244]     Train net output #1: loss = 0.0149677 (* 1 = 0.0149677 loss)
I0824 18:07:54.048952 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994299
I0824 18:07:54.048959 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993489
I0824 18:07:54.048965 41887 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0824 18:08:10.684588 41887 solver.cpp:228] Iteration 3440, loss = 0.0120336
I0824 18:08:10.684711 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995966
I0824 18:08:10.684728 41887 solver.cpp:244]     Train net output #1: loss = 0.0120336 (* 1 = 0.0120336 loss)
I0824 18:08:10.684743 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996785
I0824 18:08:10.684749 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993102
I0824 18:08:10.684759 41887 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0824 18:08:27.297931 41887 solver.cpp:228] Iteration 3460, loss = 0.0138664
I0824 18:08:27.297973 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99534
I0824 18:08:27.297988 41887 solver.cpp:244]     Train net output #1: loss = 0.0138664 (* 1 = 0.0138664 loss)
I0824 18:08:27.297996 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994648
I0824 18:08:27.298012 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996881
I0824 18:08:27.298020 41887 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0824 18:08:43.943001 41887 solver.cpp:228] Iteration 3480, loss = 0.0106988
I0824 18:08:43.943128 41887 solver.cpp:244]     Train net output #0: accuracy = 0.9958
I0824 18:08:43.943145 41887 solver.cpp:244]     Train net output #1: loss = 0.0106988 (* 1 = 0.0106988 loss)
I0824 18:08:43.943158 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996618
I0824 18:08:43.943163 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991876
I0824 18:08:43.943171 41887 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0824 18:09:00.579305 41887 solver.cpp:228] Iteration 3500, loss = 0.00927148
I0824 18:09:00.579352 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997063
I0824 18:09:00.579368 41887 solver.cpp:244]     Train net output #1: loss = 0.00927148 (* 1 = 0.00927148 loss)
I0824 18:09:00.579375 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99765
I0824 18:09:00.579382 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992225
I0824 18:09:00.579391 41887 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0824 18:09:17.203723 41887 solver.cpp:228] Iteration 3520, loss = 0.0103233
I0824 18:09:17.203831 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996262
I0824 18:09:17.203860 41887 solver.cpp:244]     Train net output #1: loss = 0.0103233 (* 1 = 0.0103233 loss)
I0824 18:09:17.203867 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996622
I0824 18:09:17.203873 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994784
I0824 18:09:17.203881 41887 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0824 18:09:33.842876 41887 solver.cpp:228] Iteration 3540, loss = 0.0137363
I0824 18:09:33.842922 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995339
I0824 18:09:33.842937 41887 solver.cpp:244]     Train net output #1: loss = 0.0137363 (* 1 = 0.0137363 loss)
I0824 18:09:33.842944 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994818
I0824 18:09:33.842950 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996407
I0824 18:09:33.842958 41887 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0824 18:09:50.450657 41887 solver.cpp:228] Iteration 3560, loss = 0.00999059
I0824 18:09:50.450831 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996528
I0824 18:09:50.450848 41887 solver.cpp:244]     Train net output #1: loss = 0.00999059 (* 1 = 0.00999059 loss)
I0824 18:09:50.450855 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997533
I0824 18:09:50.450860 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993059
I0824 18:09:50.450867 41887 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0824 18:10:07.075639 41887 solver.cpp:228] Iteration 3580, loss = 0.0145829
I0824 18:10:07.075677 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994446
I0824 18:10:07.075691 41887 solver.cpp:244]     Train net output #1: loss = 0.0145829 (* 1 = 0.0145829 loss)
I0824 18:10:07.075698 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994727
I0824 18:10:07.075702 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993576
I0824 18:10:07.075709 41887 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0824 18:10:23.699015 41887 solver.cpp:228] Iteration 3600, loss = 0.0167101
I0824 18:10:23.699179 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993792
I0824 18:10:23.699221 41887 solver.cpp:244]     Train net output #1: loss = 0.0167101 (* 1 = 0.0167101 loss)
I0824 18:10:23.699235 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992646
I0824 18:10:23.699246 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996009
I0824 18:10:23.699257 41887 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0824 18:10:40.332368 41887 solver.cpp:228] Iteration 3620, loss = 0.00615595
I0824 18:10:40.332414 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997442
I0824 18:10:40.332428 41887 solver.cpp:244]     Train net output #1: loss = 0.00615595 (* 1 = 0.00615595 loss)
I0824 18:10:40.332435 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997342
I0824 18:10:40.332440 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997968
I0824 18:10:40.332449 41887 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0824 18:10:56.977948 41887 solver.cpp:228] Iteration 3640, loss = 0.0130986
I0824 18:10:56.978071 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994677
I0824 18:10:56.978088 41887 solver.cpp:244]     Train net output #1: loss = 0.0130986 (* 1 = 0.0130986 loss)
I0824 18:10:56.978101 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99447
I0824 18:10:56.978112 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995287
I0824 18:10:56.978121 41887 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0824 18:11:13.601320 41887 solver.cpp:228] Iteration 3660, loss = 0.0117489
I0824 18:11:13.601372 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995558
I0824 18:11:13.601387 41887 solver.cpp:244]     Train net output #1: loss = 0.0117489 (* 1 = 0.0117489 loss)
I0824 18:11:13.601394 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994743
I0824 18:11:13.601399 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998181
I0824 18:11:13.601408 41887 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0824 18:11:30.225003 41887 solver.cpp:228] Iteration 3680, loss = 0.0120282
I0824 18:11:30.225136 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99466
I0824 18:11:30.225162 41887 solver.cpp:244]     Train net output #1: loss = 0.0120282 (* 1 = 0.0120282 loss)
I0824 18:11:30.225170 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993596
I0824 18:11:30.225183 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997187
I0824 18:11:30.225191 41887 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0824 18:11:46.842093 41887 solver.cpp:228] Iteration 3700, loss = 0.0111957
I0824 18:11:46.842137 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99524
I0824 18:11:46.842151 41887 solver.cpp:244]     Train net output #1: loss = 0.0111957 (* 1 = 0.0111957 loss)
I0824 18:11:46.842159 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995432
I0824 18:11:46.842164 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994186
I0824 18:11:46.842171 41887 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0824 18:12:03.482810 41887 solver.cpp:228] Iteration 3720, loss = 0.0153655
I0824 18:12:03.482975 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994637
I0824 18:12:03.482998 41887 solver.cpp:244]     Train net output #1: loss = 0.0153655 (* 1 = 0.0153655 loss)
I0824 18:12:03.483007 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994867
I0824 18:12:03.483018 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99354
I0824 18:12:03.483034 41887 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0824 18:12:20.131289 41887 solver.cpp:228] Iteration 3740, loss = 0.00969163
I0824 18:12:20.131333 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99589
I0824 18:12:20.131347 41887 solver.cpp:244]     Train net output #1: loss = 0.00969164 (* 1 = 0.00969164 loss)
I0824 18:12:20.131355 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995894
I0824 18:12:20.131361 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995876
I0824 18:12:20.131376 41887 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0824 18:12:36.771436 41887 solver.cpp:228] Iteration 3760, loss = 0.0161493
I0824 18:12:36.771589 41887 solver.cpp:244]     Train net output #0: accuracy = 0.9949
I0824 18:12:36.771608 41887 solver.cpp:244]     Train net output #1: loss = 0.0161493 (* 1 = 0.0161493 loss)
I0824 18:12:36.771615 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994986
I0824 18:12:36.771622 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994694
I0824 18:12:36.771631 41887 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0824 18:12:53.396095 41887 solver.cpp:228] Iteration 3780, loss = 0.0131572
I0824 18:12:53.396140 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995534
I0824 18:12:53.396155 41887 solver.cpp:244]     Train net output #1: loss = 0.0131572 (* 1 = 0.0131572 loss)
I0824 18:12:53.396162 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995568
I0824 18:12:53.396168 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995486
I0824 18:12:53.396175 41887 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0824 18:13:10.028820 41887 solver.cpp:228] Iteration 3800, loss = 0.0131933
I0824 18:13:10.028991 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994475
I0824 18:13:10.029036 41887 solver.cpp:244]     Train net output #1: loss = 0.0131933 (* 1 = 0.0131933 loss)
I0824 18:13:10.029044 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994127
I0824 18:13:10.029055 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995394
I0824 18:13:10.029065 41887 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0824 18:13:26.669227 41887 solver.cpp:228] Iteration 3820, loss = 0.0139137
I0824 18:13:26.669275 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994828
I0824 18:13:26.669291 41887 solver.cpp:244]     Train net output #1: loss = 0.0139138 (* 1 = 0.0139138 loss)
I0824 18:13:26.669299 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993382
I0824 18:13:26.669306 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997456
I0824 18:13:26.669313 41887 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0824 18:13:43.302629 41887 solver.cpp:228] Iteration 3840, loss = 0.0110125
I0824 18:13:43.302745 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995838
I0824 18:13:43.302762 41887 solver.cpp:244]     Train net output #1: loss = 0.0110125 (* 1 = 0.0110125 loss)
I0824 18:13:43.302767 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995874
I0824 18:13:43.302778 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995718
I0824 18:13:43.302786 41887 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0824 18:13:59.930712 41887 solver.cpp:228] Iteration 3860, loss = 0.00728305
I0824 18:13:59.930760 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997284
I0824 18:13:59.930776 41887 solver.cpp:244]     Train net output #1: loss = 0.00728306 (* 1 = 0.00728306 loss)
I0824 18:13:59.930783 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99721
I0824 18:13:59.930790 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997571
I0824 18:13:59.930800 41887 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0824 18:14:16.559332 41887 solver.cpp:228] Iteration 3880, loss = 0.0151721
I0824 18:14:16.559506 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993653
I0824 18:14:16.559525 41887 solver.cpp:244]     Train net output #1: loss = 0.0151721 (* 1 = 0.0151721 loss)
I0824 18:14:16.559535 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992487
I0824 18:14:16.559540 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996666
I0824 18:14:16.559547 41887 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0824 18:14:33.198696 41887 solver.cpp:228] Iteration 3900, loss = 0.00977319
I0824 18:14:33.198742 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996628
I0824 18:14:33.198758 41887 solver.cpp:244]     Train net output #1: loss = 0.0097732 (* 1 = 0.0097732 loss)
I0824 18:14:33.198765 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99691
I0824 18:14:33.198772 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993504
I0824 18:14:33.198781 41887 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0824 18:14:49.819895 41887 solver.cpp:228] Iteration 3920, loss = 0.0128531
I0824 18:14:49.820011 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994933
I0824 18:14:49.820029 41887 solver.cpp:244]     Train net output #1: loss = 0.0128531 (* 1 = 0.0128531 loss)
I0824 18:14:49.820040 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99256
I0824 18:14:49.820046 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998132
I0824 18:14:49.820053 41887 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0824 18:15:06.427459 41887 solver.cpp:228] Iteration 3940, loss = 0.00862439
I0824 18:15:06.427506 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996606
I0824 18:15:06.427521 41887 solver.cpp:244]     Train net output #1: loss = 0.00862439 (* 1 = 0.00862439 loss)
I0824 18:15:06.427530 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996863
I0824 18:15:06.427536 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995943
I0824 18:15:06.427544 41887 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0824 18:15:23.051853 41887 solver.cpp:228] Iteration 3960, loss = 0.0108413
I0824 18:15:23.051961 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996144
I0824 18:15:23.051977 41887 solver.cpp:244]     Train net output #1: loss = 0.0108413 (* 1 = 0.0108413 loss)
I0824 18:15:23.051985 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995233
I0824 18:15:23.051990 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997494
I0824 18:15:23.051996 41887 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0824 18:15:39.666400 41887 solver.cpp:228] Iteration 3980, loss = 0.0144158
I0824 18:15:39.666445 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99554
I0824 18:15:39.666461 41887 solver.cpp:244]     Train net output #1: loss = 0.0144158 (* 1 = 0.0144158 loss)
I0824 18:15:39.666468 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993477
I0824 18:15:39.666476 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997755
I0824 18:15:39.666483 41887 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0824 18:15:56.284082 41887 solver.cpp:228] Iteration 4000, loss = 0.0170678
I0824 18:15:56.284270 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994272
I0824 18:15:56.284287 41887 solver.cpp:244]     Train net output #1: loss = 0.0170678 (* 1 = 0.0170678 loss)
I0824 18:15:56.284298 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992446
I0824 18:15:56.284310 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997288
I0824 18:15:56.284319 41887 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0824 18:16:12.903448 41887 solver.cpp:228] Iteration 4020, loss = 0.00865131
I0824 18:16:12.903491 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99628
I0824 18:16:12.903506 41887 solver.cpp:244]     Train net output #1: loss = 0.00865131 (* 1 = 0.00865131 loss)
I0824 18:16:12.903512 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99607
I0824 18:16:12.903517 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996951
I0824 18:16:12.903524 41887 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0824 18:16:29.527884 41887 solver.cpp:228] Iteration 4040, loss = 0.00685831
I0824 18:16:29.527997 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997711
I0824 18:16:29.528013 41887 solver.cpp:244]     Train net output #1: loss = 0.00685831 (* 1 = 0.00685831 loss)
I0824 18:16:29.528028 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998216
I0824 18:16:29.528040 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991745
I0824 18:16:29.528049 41887 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0824 18:16:46.148471 41887 solver.cpp:228] Iteration 4060, loss = 0.00735092
I0824 18:16:46.148515 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997309
I0824 18:16:46.148530 41887 solver.cpp:244]     Train net output #1: loss = 0.00735092 (* 1 = 0.00735092 loss)
I0824 18:16:46.148537 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996641
I0824 18:16:46.148542 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998845
I0824 18:16:46.148550 41887 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0824 18:17:02.768059 41887 solver.cpp:228] Iteration 4080, loss = 0.0104652
I0824 18:17:02.768174 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996241
I0824 18:17:02.768191 41887 solver.cpp:244]     Train net output #1: loss = 0.0104652 (* 1 = 0.0104652 loss)
I0824 18:17:02.768203 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997304
I0824 18:17:02.768209 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989028
I0824 18:17:02.768218 41887 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0824 18:17:19.389125 41887 solver.cpp:228] Iteration 4100, loss = 0.0122495
I0824 18:17:19.389170 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995819
I0824 18:17:19.389184 41887 solver.cpp:244]     Train net output #1: loss = 0.0122495 (* 1 = 0.0122495 loss)
I0824 18:17:19.389190 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99663
I0824 18:17:19.389197 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992446
I0824 18:17:19.389204 41887 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0824 18:17:36.030391 41887 solver.cpp:228] Iteration 4120, loss = 0.00932164
I0824 18:17:36.030495 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996926
I0824 18:17:36.030513 41887 solver.cpp:244]     Train net output #1: loss = 0.00932164 (* 1 = 0.00932164 loss)
I0824 18:17:36.030519 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99709
I0824 18:17:36.030535 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995505
I0824 18:17:36.030549 41887 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0824 18:17:52.646100 41887 solver.cpp:228] Iteration 4140, loss = 0.00856799
I0824 18:17:52.646138 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99718
I0824 18:17:52.646152 41887 solver.cpp:244]     Train net output #1: loss = 0.00856799 (* 1 = 0.00856799 loss)
I0824 18:17:52.646157 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997564
I0824 18:17:52.646175 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99616
I0824 18:17:52.646181 41887 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0824 18:18:09.282058 41887 solver.cpp:228] Iteration 4160, loss = 0.0103871
I0824 18:18:09.282229 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995574
I0824 18:18:09.282246 41887 solver.cpp:244]     Train net output #1: loss = 0.0103871 (* 1 = 0.0103871 loss)
I0824 18:18:09.282256 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994041
I0824 18:18:09.282263 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998751
I0824 18:18:09.282271 41887 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0824 18:18:25.908991 41887 solver.cpp:228] Iteration 4180, loss = 0.0152652
I0824 18:18:25.909039 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994654
I0824 18:18:25.909054 41887 solver.cpp:244]     Train net output #1: loss = 0.0152652 (* 1 = 0.0152652 loss)
I0824 18:18:25.909060 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995515
I0824 18:18:25.909066 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990784
I0824 18:18:25.909075 41887 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0824 18:18:42.522323 41887 solver.cpp:228] Iteration 4200, loss = 0.0136433
I0824 18:18:42.522423 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995064
I0824 18:18:42.522438 41887 solver.cpp:244]     Train net output #1: loss = 0.0136433 (* 1 = 0.0136433 loss)
I0824 18:18:42.522451 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994674
I0824 18:18:42.522464 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996232
I0824 18:18:42.522471 41887 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0824 18:18:59.118180 41887 solver.cpp:228] Iteration 4220, loss = 0.0157872
I0824 18:18:59.118225 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994317
I0824 18:18:59.118240 41887 solver.cpp:244]     Train net output #1: loss = 0.0157872 (* 1 = 0.0157872 loss)
I0824 18:18:59.118247 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994021
I0824 18:18:59.118253 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995203
I0824 18:18:59.118261 41887 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0824 18:19:15.761270 41887 solver.cpp:228] Iteration 4240, loss = 0.0100673
I0824 18:19:15.761423 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996288
I0824 18:19:15.761441 41887 solver.cpp:244]     Train net output #1: loss = 0.0100673 (* 1 = 0.0100673 loss)
I0824 18:19:15.761446 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996892
I0824 18:19:15.761451 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987837
I0824 18:19:15.761458 41887 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0824 18:19:32.359387 41887 solver.cpp:228] Iteration 4260, loss = 0.00723149
I0824 18:19:32.359432 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997312
I0824 18:19:32.359447 41887 solver.cpp:244]     Train net output #1: loss = 0.0072315 (* 1 = 0.0072315 loss)
I0824 18:19:32.359454 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997106
I0824 18:19:32.359462 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997728
I0824 18:19:32.359469 41887 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0824 18:19:49.001049 41887 solver.cpp:228] Iteration 4280, loss = 0.0135895
I0824 18:19:49.001164 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994815
I0824 18:19:49.001180 41887 solver.cpp:244]     Train net output #1: loss = 0.0135895 (* 1 = 0.0135895 loss)
I0824 18:19:49.001186 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994577
I0824 18:19:49.001191 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995629
I0824 18:19:49.001199 41887 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0824 18:20:05.617205 41887 solver.cpp:228] Iteration 4300, loss = 0.00942805
I0824 18:20:05.617249 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996364
I0824 18:20:05.617264 41887 solver.cpp:244]     Train net output #1: loss = 0.00942805 (* 1 = 0.00942805 loss)
I0824 18:20:05.617270 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995967
I0824 18:20:05.617276 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997215
I0824 18:20:05.617285 41887 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0824 18:20:22.243355 41887 solver.cpp:228] Iteration 4320, loss = 0.00909875
I0824 18:20:22.243533 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99724
I0824 18:20:22.243551 41887 solver.cpp:244]     Train net output #1: loss = 0.00909875 (* 1 = 0.00909875 loss)
I0824 18:20:22.243559 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997751
I0824 18:20:22.243564 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991858
I0824 18:20:22.243571 41887 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0824 18:20:38.863240 41887 solver.cpp:228] Iteration 4340, loss = 0.00496731
I0824 18:20:38.863286 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997921
I0824 18:20:38.863301 41887 solver.cpp:244]     Train net output #1: loss = 0.00496732 (* 1 = 0.00496732 loss)
I0824 18:20:38.863308 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998013
I0824 18:20:38.863314 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997398
I0824 18:20:38.863322 41887 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0824 18:20:55.481134 41887 solver.cpp:228] Iteration 4360, loss = 0.0190576
I0824 18:20:55.481245 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993912
I0824 18:20:55.481261 41887 solver.cpp:244]     Train net output #1: loss = 0.0190576 (* 1 = 0.0190576 loss)
I0824 18:20:55.481276 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994007
I0824 18:20:55.481282 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993714
I0824 18:20:55.481292 41887 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0824 18:21:12.105958 41887 solver.cpp:228] Iteration 4380, loss = 0.0213972
I0824 18:21:12.105999 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993284
I0824 18:21:12.106014 41887 solver.cpp:244]     Train net output #1: loss = 0.0213972 (* 1 = 0.0213972 loss)
I0824 18:21:12.106020 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990544
I0824 18:21:12.106026 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996202
I0824 18:21:12.106034 41887 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0824 18:21:28.707792 41887 solver.cpp:228] Iteration 4400, loss = 0.00772733
I0824 18:21:28.707901 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997422
I0824 18:21:28.707916 41887 solver.cpp:244]     Train net output #1: loss = 0.00772734 (* 1 = 0.00772734 loss)
I0824 18:21:28.707933 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997711
I0824 18:21:28.707944 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996336
I0824 18:21:28.707952 41887 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0824 18:21:45.329676 41887 solver.cpp:228] Iteration 4420, loss = 0.00644084
I0824 18:21:45.329718 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997881
I0824 18:21:45.329730 41887 solver.cpp:244]     Train net output #1: loss = 0.00644084 (* 1 = 0.00644084 loss)
I0824 18:21:45.329736 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997933
I0824 18:21:45.329741 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997682
I0824 18:21:45.329748 41887 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0824 18:22:01.941269 41887 solver.cpp:228] Iteration 4440, loss = 0.0127957
I0824 18:22:01.941387 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995629
I0824 18:22:01.941407 41887 solver.cpp:244]     Train net output #1: loss = 0.0127957 (* 1 = 0.0127957 loss)
I0824 18:22:01.941416 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995938
I0824 18:22:01.941421 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994215
I0824 18:22:01.941431 41887 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0824 18:22:18.556680 41887 solver.cpp:228] Iteration 4460, loss = 0.00863078
I0824 18:22:18.556722 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996713
I0824 18:22:18.556735 41887 solver.cpp:244]     Train net output #1: loss = 0.00863079 (* 1 = 0.00863079 loss)
I0824 18:22:18.556741 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996608
I0824 18:22:18.556746 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996919
I0824 18:22:18.556753 41887 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0824 18:22:35.173327 41887 solver.cpp:228] Iteration 4480, loss = 0.0106075
I0824 18:22:35.173493 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996327
I0824 18:22:35.173518 41887 solver.cpp:244]     Train net output #1: loss = 0.0106075 (* 1 = 0.0106075 loss)
I0824 18:22:35.173527 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997474
I0824 18:22:35.173533 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990826
I0824 18:22:35.173542 41887 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0824 18:22:51.779587 41887 solver.cpp:228] Iteration 4500, loss = 0.0146567
I0824 18:22:51.779629 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994582
I0824 18:22:51.779641 41887 solver.cpp:244]     Train net output #1: loss = 0.0146567 (* 1 = 0.0146567 loss)
I0824 18:22:51.779647 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992043
I0824 18:22:51.779652 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997379
I0824 18:22:51.779660 41887 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0824 18:23:08.412292 41887 solver.cpp:228] Iteration 4520, loss = 0.0149214
I0824 18:23:08.412402 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994902
I0824 18:23:08.412417 41887 solver.cpp:244]     Train net output #1: loss = 0.0149214 (* 1 = 0.0149214 loss)
I0824 18:23:08.412432 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992464
I0824 18:23:08.412442 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997705
I0824 18:23:08.412451 41887 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0824 18:23:25.035658 41887 solver.cpp:228] Iteration 4540, loss = 0.0155458
I0824 18:23:25.035703 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995122
I0824 18:23:25.035717 41887 solver.cpp:244]     Train net output #1: loss = 0.0155458 (* 1 = 0.0155458 loss)
I0824 18:23:25.035724 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995204
I0824 18:23:25.035729 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994884
I0824 18:23:25.035738 41887 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0824 18:23:41.645443 41887 solver.cpp:228] Iteration 4560, loss = 0.0169798
I0824 18:23:41.645557 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994013
I0824 18:23:41.645572 41887 solver.cpp:244]     Train net output #1: loss = 0.0169798 (* 1 = 0.0169798 loss)
I0824 18:23:41.645579 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991969
I0824 18:23:41.645586 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997062
I0824 18:23:41.645594 41887 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0824 18:23:58.248296 41887 solver.cpp:228] Iteration 4580, loss = 0.00807277
I0824 18:23:58.248342 41887 solver.cpp:244]     Train net output #0: accuracy = 0.9974
I0824 18:23:58.248355 41887 solver.cpp:244]     Train net output #1: loss = 0.00807278 (* 1 = 0.00807278 loss)
I0824 18:23:58.248363 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998061
I0824 18:23:58.248368 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990349
I0824 18:23:58.248376 41887 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0824 18:24:14.868652 41887 solver.cpp:228] Iteration 4600, loss = 0.00848778
I0824 18:24:14.868826 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997279
I0824 18:24:14.868842 41887 solver.cpp:244]     Train net output #1: loss = 0.00848779 (* 1 = 0.00848779 loss)
I0824 18:24:14.868854 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997536
I0824 18:24:14.868858 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996792
I0824 18:24:14.868865 41887 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0824 18:24:31.480883 41887 solver.cpp:228] Iteration 4620, loss = 0.00929753
I0824 18:24:31.480926 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996709
I0824 18:24:31.480940 41887 solver.cpp:244]     Train net output #1: loss = 0.00929754 (* 1 = 0.00929754 loss)
I0824 18:24:31.480947 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996494
I0824 18:24:31.480953 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997384
I0824 18:24:31.480962 41887 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0824 18:24:48.102677 41887 solver.cpp:228] Iteration 4640, loss = 0.0189244
I0824 18:24:48.102792 41887 solver.cpp:244]     Train net output #0: accuracy = 0.993345
I0824 18:24:48.102807 41887 solver.cpp:244]     Train net output #1: loss = 0.0189244 (* 1 = 0.0189244 loss)
I0824 18:24:48.102813 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992598
I0824 18:24:48.102818 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994583
I0824 18:24:48.102825 41887 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0824 18:25:04.719983 41887 solver.cpp:228] Iteration 4660, loss = 0.00688874
I0824 18:25:04.720029 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997015
I0824 18:25:04.720043 41887 solver.cpp:244]     Train net output #1: loss = 0.00688875 (* 1 = 0.00688875 loss)
I0824 18:25:04.720051 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996979
I0824 18:25:04.720057 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997151
I0824 18:25:04.720065 41887 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0824 18:25:21.317003 41887 solver.cpp:228] Iteration 4680, loss = 0.0256693
I0824 18:25:21.317127 41887 solver.cpp:244]     Train net output #0: accuracy = 0.990299
I0824 18:25:21.317142 41887 solver.cpp:244]     Train net output #1: loss = 0.0256693 (* 1 = 0.0256693 loss)
I0824 18:25:21.317147 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988961
I0824 18:25:21.317153 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994741
I0824 18:25:21.317160 41887 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0824 18:25:37.938683 41887 solver.cpp:228] Iteration 4700, loss = 0.00784799
I0824 18:25:37.938727 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997163
I0824 18:25:37.938742 41887 solver.cpp:244]     Train net output #1: loss = 0.007848 (* 1 = 0.007848 loss)
I0824 18:25:37.938750 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997674
I0824 18:25:37.938755 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995821
I0824 18:25:37.938765 41887 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0824 18:25:54.559499 41887 solver.cpp:228] Iteration 4720, loss = 0.0121224
I0824 18:25:54.559615 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996168
I0824 18:25:54.559631 41887 solver.cpp:244]     Train net output #1: loss = 0.0121224 (* 1 = 0.0121224 loss)
I0824 18:25:54.559644 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997236
I0824 18:25:54.559649 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989021
I0824 18:25:54.559656 41887 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0824 18:26:11.189327 41887 solver.cpp:228] Iteration 4740, loss = 0.0173778
I0824 18:26:11.189381 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994455
I0824 18:26:11.189396 41887 solver.cpp:244]     Train net output #1: loss = 0.0173778 (* 1 = 0.0173778 loss)
I0824 18:26:11.189410 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992913
I0824 18:26:11.189416 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997166
I0824 18:26:11.189424 41887 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0824 18:26:27.816187 41887 solver.cpp:228] Iteration 4760, loss = 0.0165041
I0824 18:26:27.816346 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994404
I0824 18:26:27.816380 41887 solver.cpp:244]     Train net output #1: loss = 0.0165041 (* 1 = 0.0165041 loss)
I0824 18:26:27.816390 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992825
I0824 18:26:27.816402 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996522
I0824 18:26:27.816409 41887 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0824 18:26:44.434382 41887 solver.cpp:228] Iteration 4780, loss = 0.0129752
I0824 18:26:44.434424 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995677
I0824 18:26:44.434437 41887 solver.cpp:244]     Train net output #1: loss = 0.0129752 (* 1 = 0.0129752 loss)
I0824 18:26:44.434443 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996094
I0824 18:26:44.434449 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994417
I0824 18:26:44.434458 41887 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0824 18:27:01.067447 41887 solver.cpp:228] Iteration 4800, loss = 0.0186197
I0824 18:27:01.067584 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99376
I0824 18:27:01.067601 41887 solver.cpp:244]     Train net output #1: loss = 0.0186197 (* 1 = 0.0186197 loss)
I0824 18:27:01.067615 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992395
I0824 18:27:01.067627 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996595
I0824 18:27:01.067641 41887 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0824 18:27:17.716398 41887 solver.cpp:228] Iteration 4820, loss = 0.00897689
I0824 18:27:17.716439 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996835
I0824 18:27:17.716454 41887 solver.cpp:244]     Train net output #1: loss = 0.0089769 (* 1 = 0.0089769 loss)
I0824 18:27:17.716459 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996416
I0824 18:27:17.716465 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997532
I0824 18:27:17.716472 41887 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0824 18:27:34.348480 41887 solver.cpp:228] Iteration 4840, loss = 0.00942386
I0824 18:27:34.348603 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99593
I0824 18:27:34.348618 41887 solver.cpp:244]     Train net output #1: loss = 0.00942387 (* 1 = 0.00942387 loss)
I0824 18:27:34.348630 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995576
I0824 18:27:34.348642 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997256
I0824 18:27:34.348650 41887 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0824 18:27:50.982094 41887 solver.cpp:228] Iteration 4860, loss = 0.0153764
I0824 18:27:50.982136 41887 solver.cpp:244]     Train net output #0: accuracy = 0.99431
I0824 18:27:50.982148 41887 solver.cpp:244]     Train net output #1: loss = 0.0153764 (* 1 = 0.0153764 loss)
I0824 18:27:50.982154 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99239
I0824 18:27:50.982161 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997372
I0824 18:27:50.982167 41887 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0824 18:28:07.601896 41887 solver.cpp:228] Iteration 4880, loss = 0.0132101
I0824 18:28:07.602018 41887 solver.cpp:244]     Train net output #0: accuracy = 0.995132
I0824 18:28:07.602035 41887 solver.cpp:244]     Train net output #1: loss = 0.0132101 (* 1 = 0.0132101 loss)
I0824 18:28:07.602049 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995203
I0824 18:28:07.602056 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994794
I0824 18:28:07.602064 41887 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0824 18:28:24.221254 41887 solver.cpp:228] Iteration 4900, loss = 0.0087712
I0824 18:28:24.221297 41887 solver.cpp:244]     Train net output #0: accuracy = 0.996266
I0824 18:28:24.221309 41887 solver.cpp:244]     Train net output #1: loss = 0.00877121 (* 1 = 0.00877121 loss)
I0824 18:28:24.221315 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996397
I0824 18:28:24.221320 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995455
I0824 18:28:24.221328 41887 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0824 18:28:40.845612 41887 solver.cpp:228] Iteration 4920, loss = 0.0131979
I0824 18:28:40.845778 41887 solver.cpp:244]     Train net output #0: accuracy = 0.994142
I0824 18:28:40.845804 41887 solver.cpp:244]     Train net output #1: loss = 0.0131979 (* 1 = 0.0131979 loss)
I0824 18:28:40.845813 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990162
I0824 18:28:40.845818 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998892
I0824 18:28:40.845826 41887 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0824 18:28:57.465435 41887 solver.cpp:228] Iteration 4940, loss = 0.00639484
I0824 18:28:57.465481 41887 solver.cpp:244]     Train net output #0: accuracy = 0.998064
I0824 18:28:57.465495 41887 solver.cpp:244]     Train net output #1: loss = 0.00639485 (* 1 = 0.00639485 loss)
I0824 18:28:57.465502 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998242
I0824 18:28:57.465507 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997598
I0824 18:28:57.465515 41887 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0824 18:29:14.097787 41887 solver.cpp:228] Iteration 4960, loss = 0.00688883
I0824 18:29:14.097904 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997921
I0824 18:29:14.097919 41887 solver.cpp:244]     Train net output #1: loss = 0.00688884 (* 1 = 0.00688884 loss)
I0824 18:29:14.097934 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998506
I0824 18:29:14.097945 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993131
I0824 18:29:14.097954 41887 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0824 18:29:30.740298 41887 solver.cpp:228] Iteration 4980, loss = 0.00914543
I0824 18:29:30.740341 41887 solver.cpp:244]     Train net output #0: accuracy = 0.997108
I0824 18:29:30.740355 41887 solver.cpp:244]     Train net output #1: loss = 0.00914545 (* 1 = 0.00914545 loss)
I0824 18:29:30.740362 41887 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996917
I0824 18:29:30.740370 41887 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997622
I0824 18:29:30.740377 41887 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0824 18:29:46.975374 41887 solver.cpp:454] Snapshotting to binary proto file pocwisc2/training_iter_5000.caffemodel
I0824 18:29:47.887367 41887 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc2/training_iter_5000.solverstate
I0824 18:29:48.480258 41887 solver.cpp:317] Iteration 5000, loss = 0.00886309
I0824 18:29:48.480304 41887 solver.cpp:322] Optimization Done.
I0824 18:29:48.480309 41887 caffe.cpp:254] Optimization Done.

2017-08-24 18:29:48,875 log.framework MainThread  INFO       caffe models found
pocwisc2/training_iter_5000.caffemodel
2017-08-24 18:29:48,875 log.framework MainThread  INFO       Caffe model found: pocwisc2/training_iter_5000.caffemodel
2017-08-24 18:29:50,526 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:50,750 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:50,970 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:51,175 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:51,383 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:51,596 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:51,797 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:52,001 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:52,204 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:52,411 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:52,618 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:52,831 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:53,053 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:54,775 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:54,977 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:55,183 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:55,392 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:55,591 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:55,795 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:55,995 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 18:29:56,144 log.framework MainThread  INFO       train file number: 46
2017-08-24 18:29:56,144 log.framework MainThread  INFO       test file number: 9
2017-08-24 18:29:56,144 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 18:29:56,145 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 18:29:56,145 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-08-24 18:29:56,146 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-08-24 18:29:56,146 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-08-24 18:29:56,147 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc3/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc3/training"
solver_mode: GPU

2017-08-24 18:29:56,147 log.framework MainThread  INFO       caffe training step
2017-08-24 18:29:56,147 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc3/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-08-24 19:39:32,719 log.framework MainThread  INFO       I0824 18:29:56.194751 42792 caffe.cpp:217] Using GPUs 0
I0824 18:29:56.204659 42792 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0824 18:29:56.730996 42792 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc3/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc3/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0824 18:29:56.731178 42792 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc3/caffe/model_segnet_final/train.prototxt
I0824 18:29:56.733983 42792 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc3/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 18:29:56.734524 42792 layer_factory.hpp:77] Creating layer data
I0824 18:29:56.734549 42792 net.cpp:100] Creating Layer data
I0824 18:29:56.734565 42792 net.cpp:408] data -> data
I0824 18:29:56.734601 42792 net.cpp:408] data -> label
I0824 18:29:56.734627 42792 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc3/HDF5Files/train_combined.txt
I0824 18:29:56.743666 42792 hdf5_data_layer.cpp:93] Number of HDF5 files: 46
I0824 18:29:56.744870 42792 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0824 18:29:56.827649 42792 net.cpp:150] Setting up data
I0824 18:29:56.827679 42792 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 18:29:56.827689 42792 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 18:29:56.827695 42792 net.cpp:165] Memory required for data: 24883200
I0824 18:29:56.827721 42792 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 18:29:56.827745 42792 net.cpp:100] Creating Layer label_data_1_split
I0824 18:29:56.827755 42792 net.cpp:434] label_data_1_split <- label
I0824 18:29:56.827780 42792 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 18:29:56.827797 42792 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 18:29:56.827844 42792 net.cpp:150] Setting up label_data_1_split
I0824 18:29:56.827855 42792 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 18:29:56.827864 42792 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 18:29:56.827872 42792 net.cpp:165] Memory required for data: 30412800
I0824 18:29:56.827878 42792 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 18:29:56.827903 42792 net.cpp:100] Creating Layer conv1_1_1
I0824 18:29:56.827910 42792 net.cpp:434] conv1_1_1 <- data
I0824 18:29:56.827920 42792 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 18:29:57.343791 42792 net.cpp:150] Setting up conv1_1_1
I0824 18:29:57.343833 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:57.343840 42792 net.cpp:165] Memory required for data: 207360000
I0824 18:29:57.343878 42792 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 18:29:57.343904 42792 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 18:29:57.343914 42792 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 18:29:57.343935 42792 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 18:29:57.344329 42792 net.cpp:150] Setting up conv1_1_1_bn
I0824 18:29:57.344341 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:57.344347 42792 net.cpp:165] Memory required for data: 384307200
I0824 18:29:57.344367 42792 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 18:29:57.344388 42792 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 18:29:57.344394 42792 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 18:29:57.344403 42792 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 18:29:57.344458 42792 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 18:29:57.346098 42792 net.cpp:150] Setting up conv1_1_1_scale
I0824 18:29:57.346117 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:57.346123 42792 net.cpp:165] Memory required for data: 561254400
I0824 18:29:57.346137 42792 layer_factory.hpp:77] Creating layer relu1_1
I0824 18:29:57.346168 42792 net.cpp:100] Creating Layer relu1_1
I0824 18:29:57.346175 42792 net.cpp:434] relu1_1 <- conv1_1_1
I0824 18:29:57.346184 42792 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 18:29:57.346415 42792 net.cpp:150] Setting up relu1_1
I0824 18:29:57.346427 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:57.346433 42792 net.cpp:165] Memory required for data: 738201600
I0824 18:29:57.346442 42792 layer_factory.hpp:77] Creating layer conv1_2
I0824 18:29:57.346462 42792 net.cpp:100] Creating Layer conv1_2
I0824 18:29:57.346467 42792 net.cpp:434] conv1_2 <- conv1_1_1
I0824 18:29:57.346478 42792 net.cpp:408] conv1_2 -> conv1_2
I0824 18:29:57.350718 42792 net.cpp:150] Setting up conv1_2
I0824 18:29:57.350738 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:57.350744 42792 net.cpp:165] Memory required for data: 915148800
I0824 18:29:57.350761 42792 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 18:29:57.350782 42792 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 18:29:57.350796 42792 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 18:29:57.350817 42792 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 18:29:57.352366 42792 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 18:29:57.352383 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:57.352390 42792 net.cpp:165] Memory required for data: 1092096000
I0824 18:29:57.352404 42792 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 18:29:57.352422 42792 net.cpp:100] Creating Layer conv1_2_scale
I0824 18:29:57.352429 42792 net.cpp:434] conv1_2_scale <- conv1_2
I0824 18:29:57.352439 42792 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 18:29:57.352489 42792 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 18:29:57.352867 42792 net.cpp:150] Setting up conv1_2_scale
I0824 18:29:57.352880 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:57.352885 42792 net.cpp:165] Memory required for data: 1269043200
I0824 18:29:57.352896 42792 layer_factory.hpp:77] Creating layer relu1_2
I0824 18:29:57.352908 42792 net.cpp:100] Creating Layer relu1_2
I0824 18:29:57.352916 42792 net.cpp:434] relu1_2 <- conv1_2
I0824 18:29:57.352924 42792 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 18:29:57.353121 42792 net.cpp:150] Setting up relu1_2
I0824 18:29:57.353132 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:57.353138 42792 net.cpp:165] Memory required for data: 1445990400
I0824 18:29:57.353147 42792 layer_factory.hpp:77] Creating layer pool1
I0824 18:29:57.353154 42792 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 18:29:57.353166 42792 net.cpp:100] Creating Layer pool1
I0824 18:29:57.353173 42792 net.cpp:434] pool1 <- conv1_2
I0824 18:29:57.353183 42792 net.cpp:408] pool1 -> pool1
I0824 18:29:57.353196 42792 net.cpp:408] pool1 -> pool1_mask
I0824 18:29:57.353255 42792 net.cpp:150] Setting up pool1
I0824 18:29:57.353265 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:57.353274 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:57.353281 42792 net.cpp:165] Memory required for data: 1534464000
I0824 18:29:57.353286 42792 layer_factory.hpp:77] Creating layer conv2_1
I0824 18:29:57.353301 42792 net.cpp:100] Creating Layer conv2_1
I0824 18:29:57.353307 42792 net.cpp:434] conv2_1 <- pool1
I0824 18:29:57.353317 42792 net.cpp:408] conv2_1 -> conv2_1
I0824 18:29:57.359524 42792 net.cpp:150] Setting up conv2_1
I0824 18:29:57.359545 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:57.359552 42792 net.cpp:165] Memory required for data: 1622937600
I0824 18:29:57.359565 42792 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 18:29:57.359591 42792 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 18:29:57.359603 42792 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 18:29:57.359622 42792 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 18:29:57.359858 42792 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 18:29:57.359869 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:57.359875 42792 net.cpp:165] Memory required for data: 1711411200
I0824 18:29:57.359892 42792 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 18:29:57.359915 42792 net.cpp:100] Creating Layer conv2_1_scale
I0824 18:29:57.359922 42792 net.cpp:434] conv2_1_scale <- conv2_1
I0824 18:29:57.359931 42792 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 18:29:57.359980 42792 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 18:29:57.360157 42792 net.cpp:150] Setting up conv2_1_scale
I0824 18:29:57.360169 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:57.360175 42792 net.cpp:165] Memory required for data: 1799884800
I0824 18:29:57.360189 42792 layer_factory.hpp:77] Creating layer relu2_1
I0824 18:29:57.360198 42792 net.cpp:100] Creating Layer relu2_1
I0824 18:29:57.360206 42792 net.cpp:434] relu2_1 <- conv2_1
I0824 18:29:57.360219 42792 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 18:29:57.361254 42792 net.cpp:150] Setting up relu2_1
I0824 18:29:57.361271 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:57.361279 42792 net.cpp:165] Memory required for data: 1888358400
I0824 18:29:57.361284 42792 layer_factory.hpp:77] Creating layer conv2_2
I0824 18:29:57.361300 42792 net.cpp:100] Creating Layer conv2_2
I0824 18:29:57.361307 42792 net.cpp:434] conv2_2 <- conv2_1
I0824 18:29:57.361320 42792 net.cpp:408] conv2_2 -> conv2_2
I0824 18:29:57.368881 42792 net.cpp:150] Setting up conv2_2
I0824 18:29:57.368901 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:57.368907 42792 net.cpp:165] Memory required for data: 1976832000
I0824 18:29:57.368921 42792 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 18:29:57.368949 42792 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 18:29:57.368959 42792 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 18:29:57.368980 42792 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 18:29:57.369217 42792 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 18:29:57.369230 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:57.369235 42792 net.cpp:165] Memory required for data: 2065305600
I0824 18:29:57.369249 42792 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 18:29:57.369261 42792 net.cpp:100] Creating Layer conv2_2_scale
I0824 18:29:57.369268 42792 net.cpp:434] conv2_2_scale <- conv2_2
I0824 18:29:57.369277 42792 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 18:29:57.369323 42792 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 18:29:57.369509 42792 net.cpp:150] Setting up conv2_2_scale
I0824 18:29:57.369523 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:57.369527 42792 net.cpp:165] Memory required for data: 2153779200
I0824 18:29:57.369540 42792 layer_factory.hpp:77] Creating layer relu2_2
I0824 18:29:57.369551 42792 net.cpp:100] Creating Layer relu2_2
I0824 18:29:57.369559 42792 net.cpp:434] relu2_2 <- conv2_2
I0824 18:29:57.369567 42792 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 18:29:57.369766 42792 net.cpp:150] Setting up relu2_2
I0824 18:29:57.369778 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:57.369784 42792 net.cpp:165] Memory required for data: 2242252800
I0824 18:29:57.369791 42792 layer_factory.hpp:77] Creating layer pool2
I0824 18:29:57.369801 42792 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 18:29:57.369812 42792 net.cpp:100] Creating Layer pool2
I0824 18:29:57.369818 42792 net.cpp:434] pool2 <- conv2_2
I0824 18:29:57.369828 42792 net.cpp:408] pool2 -> pool2
I0824 18:29:57.369841 42792 net.cpp:408] pool2 -> pool2_mask
I0824 18:29:57.369889 42792 net.cpp:150] Setting up pool2
I0824 18:29:57.369899 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:57.369907 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:57.369913 42792 net.cpp:165] Memory required for data: 2286489600
I0824 18:29:57.369920 42792 layer_factory.hpp:77] Creating layer conv3_1
I0824 18:29:57.369936 42792 net.cpp:100] Creating Layer conv3_1
I0824 18:29:57.369943 42792 net.cpp:434] conv3_1 <- pool2
I0824 18:29:57.369953 42792 net.cpp:408] conv3_1 -> conv3_1
I0824 18:29:57.382570 42792 net.cpp:150] Setting up conv3_1
I0824 18:29:57.382602 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.382611 42792 net.cpp:165] Memory required for data: 2330726400
I0824 18:29:57.382622 42792 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 18:29:57.382635 42792 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 18:29:57.382642 42792 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 18:29:57.382652 42792 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 18:29:57.382870 42792 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 18:29:57.382881 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.382887 42792 net.cpp:165] Memory required for data: 2374963200
I0824 18:29:57.382907 42792 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 18:29:57.382920 42792 net.cpp:100] Creating Layer conv3_1_scale
I0824 18:29:57.382932 42792 net.cpp:434] conv3_1_scale <- conv3_1
I0824 18:29:57.382951 42792 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 18:29:57.383007 42792 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 18:29:57.383144 42792 net.cpp:150] Setting up conv3_1_scale
I0824 18:29:57.383154 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.383160 42792 net.cpp:165] Memory required for data: 2419200000
I0824 18:29:57.383173 42792 layer_factory.hpp:77] Creating layer relu3_1
I0824 18:29:57.383183 42792 net.cpp:100] Creating Layer relu3_1
I0824 18:29:57.383190 42792 net.cpp:434] relu3_1 <- conv3_1
I0824 18:29:57.383199 42792 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 18:29:57.383401 42792 net.cpp:150] Setting up relu3_1
I0824 18:29:57.383414 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.383419 42792 net.cpp:165] Memory required for data: 2463436800
I0824 18:29:57.383427 42792 layer_factory.hpp:77] Creating layer conv3_2
I0824 18:29:57.383442 42792 net.cpp:100] Creating Layer conv3_2
I0824 18:29:57.383448 42792 net.cpp:434] conv3_2 <- conv3_1
I0824 18:29:57.383460 42792 net.cpp:408] conv3_2 -> conv3_2
I0824 18:29:57.407492 42792 net.cpp:150] Setting up conv3_2
I0824 18:29:57.407512 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.407518 42792 net.cpp:165] Memory required for data: 2507673600
I0824 18:29:57.407531 42792 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 18:29:57.407553 42792 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 18:29:57.407567 42792 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 18:29:57.407585 42792 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 18:29:57.407802 42792 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 18:29:57.407814 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.407819 42792 net.cpp:165] Memory required for data: 2551910400
I0824 18:29:57.407832 42792 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 18:29:57.407845 42792 net.cpp:100] Creating Layer conv3_2_scale
I0824 18:29:57.407852 42792 net.cpp:434] conv3_2_scale <- conv3_2
I0824 18:29:57.407860 42792 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 18:29:57.407907 42792 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 18:29:57.408047 42792 net.cpp:150] Setting up conv3_2_scale
I0824 18:29:57.408057 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.408063 42792 net.cpp:165] Memory required for data: 2596147200
I0824 18:29:57.408073 42792 layer_factory.hpp:77] Creating layer relu3_2
I0824 18:29:57.408083 42792 net.cpp:100] Creating Layer relu3_2
I0824 18:29:57.408090 42792 net.cpp:434] relu3_2 <- conv3_2
I0824 18:29:57.408099 42792 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 18:29:57.408298 42792 net.cpp:150] Setting up relu3_2
I0824 18:29:57.408310 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.408316 42792 net.cpp:165] Memory required for data: 2640384000
I0824 18:29:57.408321 42792 layer_factory.hpp:77] Creating layer conv3_3
I0824 18:29:57.408339 42792 net.cpp:100] Creating Layer conv3_3
I0824 18:29:57.408345 42792 net.cpp:434] conv3_3 <- conv3_2
I0824 18:29:57.408356 42792 net.cpp:408] conv3_3 -> conv3_3
I0824 18:29:57.432390 42792 net.cpp:150] Setting up conv3_3
I0824 18:29:57.432425 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.432431 42792 net.cpp:165] Memory required for data: 2684620800
I0824 18:29:57.432446 42792 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 18:29:57.432473 42792 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 18:29:57.432485 42792 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 18:29:57.432504 42792 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 18:29:57.432727 42792 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 18:29:57.432739 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.432744 42792 net.cpp:165] Memory required for data: 2728857600
I0824 18:29:57.432759 42792 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 18:29:57.432770 42792 net.cpp:100] Creating Layer conv3_3_scale
I0824 18:29:57.432776 42792 net.cpp:434] conv3_3_scale <- conv3_3
I0824 18:29:57.432785 42792 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 18:29:57.432832 42792 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 18:29:57.432973 42792 net.cpp:150] Setting up conv3_3_scale
I0824 18:29:57.432983 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.432989 42792 net.cpp:165] Memory required for data: 2773094400
I0824 18:29:57.432999 42792 layer_factory.hpp:77] Creating layer relu3_3
I0824 18:29:57.433008 42792 net.cpp:100] Creating Layer relu3_3
I0824 18:29:57.433015 42792 net.cpp:434] relu3_3 <- conv3_3
I0824 18:29:57.433023 42792 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 18:29:57.433225 42792 net.cpp:150] Setting up relu3_3
I0824 18:29:57.433236 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:57.433243 42792 net.cpp:165] Memory required for data: 2817331200
I0824 18:29:57.433248 42792 layer_factory.hpp:77] Creating layer pool3
I0824 18:29:57.433259 42792 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 18:29:57.433272 42792 net.cpp:100] Creating Layer pool3
I0824 18:29:57.433279 42792 net.cpp:434] pool3 <- conv3_3
I0824 18:29:57.433289 42792 net.cpp:408] pool3 -> pool3
I0824 18:29:57.433300 42792 net.cpp:408] pool3 -> pool3_mask
I0824 18:29:57.433351 42792 net.cpp:150] Setting up pool3
I0824 18:29:57.433362 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:57.433377 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:57.433382 42792 net.cpp:165] Memory required for data: 2839449600
I0824 18:29:57.433389 42792 layer_factory.hpp:77] Creating layer conv4_1
I0824 18:29:57.433405 42792 net.cpp:100] Creating Layer conv4_1
I0824 18:29:57.433413 42792 net.cpp:434] conv4_1 <- pool3
I0824 18:29:57.433423 42792 net.cpp:408] conv4_1 -> conv4_1
I0824 18:29:57.481204 42792 net.cpp:150] Setting up conv4_1
I0824 18:29:57.481225 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.481231 42792 net.cpp:165] Memory required for data: 2861568000
I0824 18:29:57.481243 42792 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 18:29:57.481254 42792 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 18:29:57.481276 42792 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 18:29:57.481286 42792 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 18:29:57.481524 42792 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 18:29:57.481536 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.481542 42792 net.cpp:165] Memory required for data: 2883686400
I0824 18:29:57.481555 42792 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 18:29:57.481572 42792 net.cpp:100] Creating Layer conv4_1_scale
I0824 18:29:57.481585 42792 net.cpp:434] conv4_1_scale <- conv4_1
I0824 18:29:57.481593 42792 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 18:29:57.481644 42792 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 18:29:57.481775 42792 net.cpp:150] Setting up conv4_1_scale
I0824 18:29:57.481786 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.481791 42792 net.cpp:165] Memory required for data: 2905804800
I0824 18:29:57.481801 42792 layer_factory.hpp:77] Creating layer relu4_1
I0824 18:29:57.481824 42792 net.cpp:100] Creating Layer relu4_1
I0824 18:29:57.481832 42792 net.cpp:434] relu4_1 <- conv4_1
I0824 18:29:57.481840 42792 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 18:29:57.482051 42792 net.cpp:150] Setting up relu4_1
I0824 18:29:57.482064 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.482069 42792 net.cpp:165] Memory required for data: 2927923200
I0824 18:29:57.482079 42792 layer_factory.hpp:77] Creating layer conv4_2
I0824 18:29:57.482095 42792 net.cpp:100] Creating Layer conv4_2
I0824 18:29:57.482101 42792 net.cpp:434] conv4_2 <- conv4_1
I0824 18:29:57.482112 42792 net.cpp:408] conv4_2 -> conv4_2
I0824 18:29:57.569015 42792 net.cpp:150] Setting up conv4_2
I0824 18:29:57.569036 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.569042 42792 net.cpp:165] Memory required for data: 2950041600
I0824 18:29:57.569056 42792 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 18:29:57.569079 42792 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 18:29:57.569092 42792 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 18:29:57.569111 42792 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 18:29:57.569335 42792 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 18:29:57.569346 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.569351 42792 net.cpp:165] Memory required for data: 2972160000
I0824 18:29:57.569372 42792 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 18:29:57.569384 42792 net.cpp:100] Creating Layer conv4_2_scale
I0824 18:29:57.569392 42792 net.cpp:434] conv4_2_scale <- conv4_2
I0824 18:29:57.569401 42792 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 18:29:57.569452 42792 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 18:29:57.569589 42792 net.cpp:150] Setting up conv4_2_scale
I0824 18:29:57.569599 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.569605 42792 net.cpp:165] Memory required for data: 2994278400
I0824 18:29:57.569615 42792 layer_factory.hpp:77] Creating layer relu4_2
I0824 18:29:57.569625 42792 net.cpp:100] Creating Layer relu4_2
I0824 18:29:57.569633 42792 net.cpp:434] relu4_2 <- conv4_2
I0824 18:29:57.569641 42792 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 18:29:57.570695 42792 net.cpp:150] Setting up relu4_2
I0824 18:29:57.570711 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.570718 42792 net.cpp:165] Memory required for data: 3016396800
I0824 18:29:57.570726 42792 layer_factory.hpp:77] Creating layer conv4_3
I0824 18:29:57.570745 42792 net.cpp:100] Creating Layer conv4_3
I0824 18:29:57.570752 42792 net.cpp:434] conv4_3 <- conv4_2
I0824 18:29:57.570765 42792 net.cpp:408] conv4_3 -> conv4_3
I0824 18:29:57.657805 42792 net.cpp:150] Setting up conv4_3
I0824 18:29:57.657825 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.657832 42792 net.cpp:165] Memory required for data: 3038515200
I0824 18:29:57.657860 42792 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 18:29:57.657876 42792 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 18:29:57.657891 42792 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 18:29:57.657909 42792 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 18:29:57.658133 42792 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 18:29:57.658143 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.658149 42792 net.cpp:165] Memory required for data: 3060633600
I0824 18:29:57.658162 42792 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 18:29:57.658176 42792 net.cpp:100] Creating Layer conv4_3_scale
I0824 18:29:57.658183 42792 net.cpp:434] conv4_3_scale <- conv4_3
I0824 18:29:57.658192 42792 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 18:29:57.658241 42792 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 18:29:57.658377 42792 net.cpp:150] Setting up conv4_3_scale
I0824 18:29:57.658387 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.658392 42792 net.cpp:165] Memory required for data: 3082752000
I0824 18:29:57.658403 42792 layer_factory.hpp:77] Creating layer relu4_3
I0824 18:29:57.658427 42792 net.cpp:100] Creating Layer relu4_3
I0824 18:29:57.658435 42792 net.cpp:434] relu4_3 <- conv4_3
I0824 18:29:57.658444 42792 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 18:29:57.658646 42792 net.cpp:150] Setting up relu4_3
I0824 18:29:57.658658 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:57.658664 42792 net.cpp:165] Memory required for data: 3104870400
I0824 18:29:57.658670 42792 layer_factory.hpp:77] Creating layer pool4
I0824 18:29:57.658681 42792 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 18:29:57.658690 42792 net.cpp:100] Creating Layer pool4
I0824 18:29:57.658697 42792 net.cpp:434] pool4 <- conv4_3
I0824 18:29:57.658707 42792 net.cpp:408] pool4 -> pool4
I0824 18:29:57.658720 42792 net.cpp:408] pool4 -> pool4_mask
I0824 18:29:57.658772 42792 net.cpp:150] Setting up pool4
I0824 18:29:57.658782 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.658788 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.658795 42792 net.cpp:165] Memory required for data: 3116175360
I0824 18:29:57.658800 42792 layer_factory.hpp:77] Creating layer conv5_1
I0824 18:29:57.658815 42792 net.cpp:100] Creating Layer conv5_1
I0824 18:29:57.658823 42792 net.cpp:434] conv5_1 <- pool4
I0824 18:29:57.658833 42792 net.cpp:408] conv5_1 -> conv5_1
I0824 18:29:57.746551 42792 net.cpp:150] Setting up conv5_1
I0824 18:29:57.746577 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.746583 42792 net.cpp:165] Memory required for data: 3121827840
I0824 18:29:57.746600 42792 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 18:29:57.746625 42792 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 18:29:57.746639 42792 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 18:29:57.746656 42792 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 18:29:57.746892 42792 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 18:29:57.746902 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.746908 42792 net.cpp:165] Memory required for data: 3127480320
I0824 18:29:57.746922 42792 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 18:29:57.746937 42792 net.cpp:100] Creating Layer conv5_1_scale
I0824 18:29:57.746943 42792 net.cpp:434] conv5_1_scale <- conv5_1
I0824 18:29:57.746953 42792 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 18:29:57.747006 42792 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 18:29:57.747138 42792 net.cpp:150] Setting up conv5_1_scale
I0824 18:29:57.747149 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.747154 42792 net.cpp:165] Memory required for data: 3133132800
I0824 18:29:57.747166 42792 layer_factory.hpp:77] Creating layer relu5_1
I0824 18:29:57.747175 42792 net.cpp:100] Creating Layer relu5_1
I0824 18:29:57.747184 42792 net.cpp:434] relu5_1 <- conv5_1
I0824 18:29:57.747193 42792 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 18:29:57.747403 42792 net.cpp:150] Setting up relu5_1
I0824 18:29:57.747416 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.747421 42792 net.cpp:165] Memory required for data: 3138785280
I0824 18:29:57.747427 42792 layer_factory.hpp:77] Creating layer conv5_2
I0824 18:29:57.747444 42792 net.cpp:100] Creating Layer conv5_2
I0824 18:29:57.747452 42792 net.cpp:434] conv5_2 <- conv5_1
I0824 18:29:57.747462 42792 net.cpp:408] conv5_2 -> conv5_2
I0824 18:29:57.834384 42792 net.cpp:150] Setting up conv5_2
I0824 18:29:57.834405 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.834411 42792 net.cpp:165] Memory required for data: 3144437760
I0824 18:29:57.834424 42792 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 18:29:57.834446 42792 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 18:29:57.834460 42792 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 18:29:57.834478 42792 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 18:29:57.834709 42792 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 18:29:57.834722 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.834748 42792 net.cpp:165] Memory required for data: 3150090240
I0824 18:29:57.834764 42792 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 18:29:57.834775 42792 net.cpp:100] Creating Layer conv5_2_scale
I0824 18:29:57.834782 42792 net.cpp:434] conv5_2_scale <- conv5_2
I0824 18:29:57.834792 42792 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 18:29:57.834847 42792 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 18:29:57.834981 42792 net.cpp:150] Setting up conv5_2_scale
I0824 18:29:57.834991 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.834997 42792 net.cpp:165] Memory required for data: 3155742720
I0824 18:29:57.835009 42792 layer_factory.hpp:77] Creating layer relu5_2
I0824 18:29:57.835019 42792 net.cpp:100] Creating Layer relu5_2
I0824 18:29:57.835027 42792 net.cpp:434] relu5_2 <- conv5_2
I0824 18:29:57.835036 42792 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 18:29:57.835243 42792 net.cpp:150] Setting up relu5_2
I0824 18:29:57.835255 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.835261 42792 net.cpp:165] Memory required for data: 3161395200
I0824 18:29:57.835268 42792 layer_factory.hpp:77] Creating layer conv5_3
I0824 18:29:57.835285 42792 net.cpp:100] Creating Layer conv5_3
I0824 18:29:57.835292 42792 net.cpp:434] conv5_3 <- conv5_2
I0824 18:29:57.835304 42792 net.cpp:408] conv5_3 -> conv5_3
I0824 18:29:57.922319 42792 net.cpp:150] Setting up conv5_3
I0824 18:29:57.922340 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.922348 42792 net.cpp:165] Memory required for data: 3167047680
I0824 18:29:57.922359 42792 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 18:29:57.922386 42792 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 18:29:57.922399 42792 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 18:29:57.922420 42792 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 18:29:57.922652 42792 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 18:29:57.922662 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.922667 42792 net.cpp:165] Memory required for data: 3172700160
I0824 18:29:57.922680 42792 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 18:29:57.922693 42792 net.cpp:100] Creating Layer conv5_3_scale
I0824 18:29:57.922700 42792 net.cpp:434] conv5_3_scale <- conv5_3
I0824 18:29:57.922709 42792 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 18:29:57.922763 42792 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 18:29:57.922894 42792 net.cpp:150] Setting up conv5_3_scale
I0824 18:29:57.922904 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.922909 42792 net.cpp:165] Memory required for data: 3178352640
I0824 18:29:57.922921 42792 layer_factory.hpp:77] Creating layer relu5_3
I0824 18:29:57.922932 42792 net.cpp:100] Creating Layer relu5_3
I0824 18:29:57.922940 42792 net.cpp:434] relu5_3 <- conv5_3
I0824 18:29:57.922947 42792 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 18:29:57.923159 42792 net.cpp:150] Setting up relu5_3
I0824 18:29:57.923171 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.923177 42792 net.cpp:165] Memory required for data: 3184005120
I0824 18:29:57.923185 42792 layer_factory.hpp:77] Creating layer pool5
I0824 18:29:57.923194 42792 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 18:29:57.923207 42792 net.cpp:100] Creating Layer pool5
I0824 18:29:57.923213 42792 net.cpp:434] pool5 <- conv5_3
I0824 18:29:57.923225 42792 net.cpp:408] pool5 -> pool5
I0824 18:29:57.923238 42792 net.cpp:408] pool5 -> pool5_mask
I0824 18:29:57.923293 42792 net.cpp:150] Setting up pool5
I0824 18:29:57.923302 42792 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 18:29:57.923310 42792 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 18:29:57.923316 42792 net.cpp:165] Memory required for data: 3186954240
I0824 18:29:57.923322 42792 layer_factory.hpp:77] Creating layer upsample5
I0824 18:29:57.923337 42792 net.cpp:100] Creating Layer upsample5
I0824 18:29:57.923343 42792 net.cpp:434] upsample5 <- pool5
I0824 18:29:57.923367 42792 net.cpp:434] upsample5 <- pool5_mask
I0824 18:29:57.923380 42792 net.cpp:408] upsample5 -> pool5_D
I0824 18:29:57.923427 42792 net.cpp:150] Setting up upsample5
I0824 18:29:57.923437 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:57.923442 42792 net.cpp:165] Memory required for data: 3192606720
I0824 18:29:57.923449 42792 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 18:29:57.923467 42792 net.cpp:100] Creating Layer conv5_3_D
I0824 18:29:57.923473 42792 net.cpp:434] conv5_3_D <- pool5_D
I0824 18:29:57.923485 42792 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 18:29:58.011392 42792 net.cpp:150] Setting up conv5_3_D
I0824 18:29:58.011412 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.011420 42792 net.cpp:165] Memory required for data: 3198259200
I0824 18:29:58.011432 42792 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 18:29:58.011461 42792 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 18:29:58.011473 42792 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 18:29:58.011492 42792 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 18:29:58.011729 42792 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 18:29:58.011739 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.011745 42792 net.cpp:165] Memory required for data: 3203911680
I0824 18:29:58.011759 42792 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 18:29:58.011770 42792 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 18:29:58.011778 42792 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 18:29:58.011790 42792 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 18:29:58.011842 42792 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 18:29:58.011975 42792 net.cpp:150] Setting up conv5_3_D_scale
I0824 18:29:58.011984 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.011989 42792 net.cpp:165] Memory required for data: 3209564160
I0824 18:29:58.012001 42792 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 18:29:58.012012 42792 net.cpp:100] Creating Layer relu5_3_D
I0824 18:29:58.012019 42792 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 18:29:58.012027 42792 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 18:29:58.012248 42792 net.cpp:150] Setting up relu5_3_D
I0824 18:29:58.012262 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.012271 42792 net.cpp:165] Memory required for data: 3215216640
I0824 18:29:58.012277 42792 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 18:29:58.012320 42792 net.cpp:100] Creating Layer conv5_2_D
I0824 18:29:58.012328 42792 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 18:29:58.012341 42792 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 18:29:58.099433 42792 net.cpp:150] Setting up conv5_2_D
I0824 18:29:58.099453 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.099459 42792 net.cpp:165] Memory required for data: 3220869120
I0824 18:29:58.099474 42792 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 18:29:58.099498 42792 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 18:29:58.099509 42792 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 18:29:58.099527 42792 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 18:29:58.099771 42792 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 18:29:58.099781 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.099786 42792 net.cpp:165] Memory required for data: 3226521600
I0824 18:29:58.099803 42792 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 18:29:58.099817 42792 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 18:29:58.099823 42792 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 18:29:58.099833 42792 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 18:29:58.099889 42792 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 18:29:58.100025 42792 net.cpp:150] Setting up conv5_2_D_scale
I0824 18:29:58.100036 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.100041 42792 net.cpp:165] Memory required for data: 3232174080
I0824 18:29:58.100069 42792 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 18:29:58.100085 42792 net.cpp:100] Creating Layer relu5_2_D
I0824 18:29:58.100091 42792 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 18:29:58.100100 42792 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 18:29:58.101186 42792 net.cpp:150] Setting up relu5_2_D
I0824 18:29:58.101205 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.101212 42792 net.cpp:165] Memory required for data: 3237826560
I0824 18:29:58.101218 42792 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 18:29:58.101238 42792 net.cpp:100] Creating Layer conv5_1_D
I0824 18:29:58.101245 42792 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 18:29:58.101258 42792 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 18:29:58.188282 42792 net.cpp:150] Setting up conv5_1_D
I0824 18:29:58.188302 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.188308 42792 net.cpp:165] Memory required for data: 3243479040
I0824 18:29:58.188323 42792 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 18:29:58.188345 42792 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 18:29:58.188357 42792 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 18:29:58.188375 42792 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 18:29:58.188621 42792 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 18:29:58.188632 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.188637 42792 net.cpp:165] Memory required for data: 3249131520
I0824 18:29:58.188652 42792 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 18:29:58.188666 42792 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 18:29:58.188673 42792 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 18:29:58.188681 42792 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 18:29:58.188738 42792 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 18:29:58.188876 42792 net.cpp:150] Setting up conv5_1_D_scale
I0824 18:29:58.188887 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.188892 42792 net.cpp:165] Memory required for data: 3254784000
I0824 18:29:58.188902 42792 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 18:29:58.188911 42792 net.cpp:100] Creating Layer relu5_1_D
I0824 18:29:58.188920 42792 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 18:29:58.188930 42792 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 18:29:58.189141 42792 net.cpp:150] Setting up relu5_1_D
I0824 18:29:58.189152 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.189158 42792 net.cpp:165] Memory required for data: 3260436480
I0824 18:29:58.189164 42792 layer_factory.hpp:77] Creating layer upsample4
I0824 18:29:58.189177 42792 net.cpp:100] Creating Layer upsample4
I0824 18:29:58.189184 42792 net.cpp:434] upsample4 <- conv5_1_D
I0824 18:29:58.189196 42792 net.cpp:434] upsample4 <- pool4_mask
I0824 18:29:58.189204 42792 net.cpp:408] upsample4 -> pool4_D
I0824 18:29:58.189246 42792 net.cpp:150] Setting up upsample4
I0824 18:29:58.189256 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.189261 42792 net.cpp:165] Memory required for data: 3282554880
I0824 18:29:58.189270 42792 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 18:29:58.189288 42792 net.cpp:100] Creating Layer conv4_3_D
I0824 18:29:58.189296 42792 net.cpp:434] conv4_3_D <- pool4_D
I0824 18:29:58.189308 42792 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 18:29:58.278177 42792 net.cpp:150] Setting up conv4_3_D
I0824 18:29:58.278204 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.278211 42792 net.cpp:165] Memory required for data: 3304673280
I0824 18:29:58.278228 42792 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 18:29:58.278251 42792 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 18:29:58.278270 42792 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 18:29:58.278282 42792 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 18:29:58.278534 42792 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 18:29:58.278545 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.278586 42792 net.cpp:165] Memory required for data: 3326791680
I0824 18:29:58.278601 42792 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 18:29:58.278617 42792 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 18:29:58.278623 42792 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 18:29:58.278632 42792 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 18:29:58.278686 42792 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 18:29:58.278838 42792 net.cpp:150] Setting up conv4_3_D_scale
I0824 18:29:58.278851 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.278856 42792 net.cpp:165] Memory required for data: 3348910080
I0824 18:29:58.278867 42792 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 18:29:58.278880 42792 net.cpp:100] Creating Layer relu4_3_D
I0824 18:29:58.278887 42792 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 18:29:58.278898 42792 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 18:29:58.279109 42792 net.cpp:150] Setting up relu4_3_D
I0824 18:29:58.279120 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.279125 42792 net.cpp:165] Memory required for data: 3371028480
I0824 18:29:58.279134 42792 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 18:29:58.279151 42792 net.cpp:100] Creating Layer conv4_2_D
I0824 18:29:58.279158 42792 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 18:29:58.279172 42792 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 18:29:58.366202 42792 net.cpp:150] Setting up conv4_2_D
I0824 18:29:58.366221 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.366227 42792 net.cpp:165] Memory required for data: 3393146880
I0824 18:29:58.366240 42792 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 18:29:58.366253 42792 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 18:29:58.366273 42792 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 18:29:58.366283 42792 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 18:29:58.366525 42792 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 18:29:58.366536 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.366542 42792 net.cpp:165] Memory required for data: 3415265280
I0824 18:29:58.366555 42792 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 18:29:58.366569 42792 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 18:29:58.366581 42792 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 18:29:58.366602 42792 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 18:29:58.366652 42792 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 18:29:58.366801 42792 net.cpp:150] Setting up conv4_2_D_scale
I0824 18:29:58.366811 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.366817 42792 net.cpp:165] Memory required for data: 3437383680
I0824 18:29:58.366828 42792 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 18:29:58.366842 42792 net.cpp:100] Creating Layer relu4_2_D
I0824 18:29:58.366848 42792 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 18:29:58.366856 42792 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 18:29:58.367067 42792 net.cpp:150] Setting up relu4_2_D
I0824 18:29:58.367082 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.367090 42792 net.cpp:165] Memory required for data: 3459502080
I0824 18:29:58.367097 42792 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 18:29:58.367115 42792 net.cpp:100] Creating Layer conv4_1_D
I0824 18:29:58.367122 42792 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 18:29:58.367133 42792 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 18:29:58.412616 42792 net.cpp:150] Setting up conv4_1_D
I0824 18:29:58.412636 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:58.412642 42792 net.cpp:165] Memory required for data: 3470561280
I0824 18:29:58.412654 42792 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 18:29:58.412674 42792 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 18:29:58.412689 42792 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 18:29:58.412710 42792 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 18:29:58.412967 42792 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 18:29:58.412993 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:58.413010 42792 net.cpp:165] Memory required for data: 3481620480
I0824 18:29:58.413071 42792 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 18:29:58.413084 42792 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 18:29:58.413091 42792 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 18:29:58.413101 42792 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 18:29:58.413163 42792 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 18:29:58.413312 42792 net.cpp:150] Setting up conv4_1_D_scale
I0824 18:29:58.413322 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:58.413328 42792 net.cpp:165] Memory required for data: 3492679680
I0824 18:29:58.413339 42792 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 18:29:58.413352 42792 net.cpp:100] Creating Layer relu4_1_D
I0824 18:29:58.413358 42792 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 18:29:58.413373 42792 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 18:29:58.413596 42792 net.cpp:150] Setting up relu4_1_D
I0824 18:29:58.413612 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:58.413619 42792 net.cpp:165] Memory required for data: 3503738880
I0824 18:29:58.413627 42792 layer_factory.hpp:77] Creating layer upsample3
I0824 18:29:58.413641 42792 net.cpp:100] Creating Layer upsample3
I0824 18:29:58.413647 42792 net.cpp:434] upsample3 <- conv4_1_D
I0824 18:29:58.413658 42792 net.cpp:434] upsample3 <- pool3_mask
I0824 18:29:58.413671 42792 net.cpp:408] upsample3 -> pool3_D
I0824 18:29:58.413683 42792 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 18:29:58.413718 42792 net.cpp:150] Setting up upsample3
I0824 18:29:58.413727 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.413734 42792 net.cpp:165] Memory required for data: 3547975680
I0824 18:29:58.413740 42792 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 18:29:58.413759 42792 net.cpp:100] Creating Layer conv3_3_D
I0824 18:29:58.413766 42792 net.cpp:434] conv3_3_D <- pool3_D
I0824 18:29:58.413779 42792 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 18:29:58.438081 42792 net.cpp:150] Setting up conv3_3_D
I0824 18:29:58.438102 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.438107 42792 net.cpp:165] Memory required for data: 3592212480
I0824 18:29:58.438120 42792 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 18:29:58.438146 42792 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 18:29:58.438158 42792 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 18:29:58.438166 42792 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 18:29:58.438436 42792 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 18:29:58.438446 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.438452 42792 net.cpp:165] Memory required for data: 3636449280
I0824 18:29:58.438467 42792 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 18:29:58.438480 42792 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 18:29:58.438491 42792 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 18:29:58.438503 42792 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 18:29:58.438555 42792 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 18:29:58.438726 42792 net.cpp:150] Setting up conv3_3_D_scale
I0824 18:29:58.438740 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.438746 42792 net.cpp:165] Memory required for data: 3680686080
I0824 18:29:58.438757 42792 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 18:29:58.438766 42792 net.cpp:100] Creating Layer relu3_3_D
I0824 18:29:58.438773 42792 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 18:29:58.438781 42792 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 18:29:58.439002 42792 net.cpp:150] Setting up relu3_3_D
I0824 18:29:58.439014 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.439020 42792 net.cpp:165] Memory required for data: 3724922880
I0824 18:29:58.439041 42792 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 18:29:58.439061 42792 net.cpp:100] Creating Layer conv3_2_D
I0824 18:29:58.439069 42792 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 18:29:58.439081 42792 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 18:29:58.463361 42792 net.cpp:150] Setting up conv3_2_D
I0824 18:29:58.463379 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.463385 42792 net.cpp:165] Memory required for data: 3769159680
I0824 18:29:58.463397 42792 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 18:29:58.463423 42792 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 18:29:58.463435 42792 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 18:29:58.463449 42792 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 18:29:58.463718 42792 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 18:29:58.463729 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.463735 42792 net.cpp:165] Memory required for data: 3813396480
I0824 18:29:58.463748 42792 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 18:29:58.463762 42792 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 18:29:58.463773 42792 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 18:29:58.463784 42792 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 18:29:58.463840 42792 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 18:29:58.464012 42792 net.cpp:150] Setting up conv3_2_D_scale
I0824 18:29:58.464022 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.464028 42792 net.cpp:165] Memory required for data: 3857633280
I0824 18:29:58.464041 42792 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 18:29:58.464052 42792 net.cpp:100] Creating Layer relu3_2_D
I0824 18:29:58.464059 42792 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 18:29:58.464071 42792 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 18:29:58.465171 42792 net.cpp:150] Setting up relu3_2_D
I0824 18:29:58.465188 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.465194 42792 net.cpp:165] Memory required for data: 3901870080
I0824 18:29:58.465201 42792 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 18:29:58.465219 42792 net.cpp:100] Creating Layer conv3_1_D
I0824 18:29:58.465225 42792 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 18:29:58.465240 42792 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 18:29:58.479400 42792 net.cpp:150] Setting up conv3_1_D
I0824 18:29:58.479420 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:58.479426 42792 net.cpp:165] Memory required for data: 3923988480
I0824 18:29:58.479439 42792 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 18:29:58.479452 42792 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 18:29:58.479471 42792 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 18:29:58.479480 42792 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 18:29:58.479755 42792 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 18:29:58.479768 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:58.479773 42792 net.cpp:165] Memory required for data: 3946106880
I0824 18:29:58.479786 42792 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 18:29:58.479801 42792 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 18:29:58.479812 42792 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 18:29:58.479825 42792 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 18:29:58.479879 42792 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 18:29:58.480053 42792 net.cpp:150] Setting up conv3_1_D_scale
I0824 18:29:58.480064 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:58.480070 42792 net.cpp:165] Memory required for data: 3968225280
I0824 18:29:58.480080 42792 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 18:29:58.480090 42792 net.cpp:100] Creating Layer relu3_1_D
I0824 18:29:58.480098 42792 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 18:29:58.480106 42792 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 18:29:58.480335 42792 net.cpp:150] Setting up relu3_1_D
I0824 18:29:58.480360 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:58.480366 42792 net.cpp:165] Memory required for data: 3990343680
I0824 18:29:58.480372 42792 layer_factory.hpp:77] Creating layer upsample2
I0824 18:29:58.480383 42792 net.cpp:100] Creating Layer upsample2
I0824 18:29:58.480391 42792 net.cpp:434] upsample2 <- conv3_1_D
I0824 18:29:58.480401 42792 net.cpp:434] upsample2 <- pool2_mask
I0824 18:29:58.480410 42792 net.cpp:408] upsample2 -> pool2_D
I0824 18:29:58.480423 42792 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 18:29:58.480463 42792 net.cpp:150] Setting up upsample2
I0824 18:29:58.480471 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.480480 42792 net.cpp:165] Memory required for data: 4078817280
I0824 18:29:58.480486 42792 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 18:29:58.480501 42792 net.cpp:100] Creating Layer conv2_2_D
I0824 18:29:58.480509 42792 net.cpp:434] conv2_2_D <- pool2_D
I0824 18:29:58.480521 42792 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 18:29:58.488396 42792 net.cpp:150] Setting up conv2_2_D
I0824 18:29:58.488416 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.488422 42792 net.cpp:165] Memory required for data: 4167290880
I0824 18:29:58.488436 42792 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 18:29:58.488464 42792 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 18:29:58.488476 42792 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 18:29:58.488493 42792 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 18:29:58.488807 42792 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 18:29:58.488818 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.488824 42792 net.cpp:165] Memory required for data: 4255764480
I0824 18:29:58.488838 42792 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 18:29:58.488850 42792 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 18:29:58.488857 42792 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 18:29:58.488867 42792 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 18:29:58.488924 42792 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 18:29:58.490416 42792 net.cpp:150] Setting up conv2_2_D_scale
I0824 18:29:58.490434 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.490440 42792 net.cpp:165] Memory required for data: 4344238080
I0824 18:29:58.490453 42792 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 18:29:58.490470 42792 net.cpp:100] Creating Layer relu2_2_D
I0824 18:29:58.490478 42792 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 18:29:58.490486 42792 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 18:29:58.490722 42792 net.cpp:150] Setting up relu2_2_D
I0824 18:29:58.490736 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.490741 42792 net.cpp:165] Memory required for data: 4432711680
I0824 18:29:58.490747 42792 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 18:29:58.490768 42792 net.cpp:100] Creating Layer conv2_1_D
I0824 18:29:58.490775 42792 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 18:29:58.490787 42792 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 18:29:58.496127 42792 net.cpp:150] Setting up conv2_1_D
I0824 18:29:58.496146 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:58.496152 42792 net.cpp:165] Memory required for data: 4476948480
I0824 18:29:58.496166 42792 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 18:29:58.496186 42792 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 18:29:58.496201 42792 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 18:29:58.496212 42792 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 18:29:58.496517 42792 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 18:29:58.496528 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:58.496534 42792 net.cpp:165] Memory required for data: 4521185280
I0824 18:29:58.496547 42792 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 18:29:58.496572 42792 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 18:29:58.496580 42792 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 18:29:58.496592 42792 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 18:29:58.496649 42792 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 18:29:58.496877 42792 net.cpp:150] Setting up conv2_1_D_scale
I0824 18:29:58.496888 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:58.496893 42792 net.cpp:165] Memory required for data: 4565422080
I0824 18:29:58.496904 42792 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 18:29:58.496915 42792 net.cpp:100] Creating Layer relu2_1_D
I0824 18:29:58.496922 42792 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 18:29:58.496934 42792 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 18:29:58.497167 42792 net.cpp:150] Setting up relu2_1_D
I0824 18:29:58.497179 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:58.497184 42792 net.cpp:165] Memory required for data: 4609658880
I0824 18:29:58.497190 42792 layer_factory.hpp:77] Creating layer upsample1
I0824 18:29:58.497202 42792 net.cpp:100] Creating Layer upsample1
I0824 18:29:58.497210 42792 net.cpp:434] upsample1 <- conv2_1_D
I0824 18:29:58.497216 42792 net.cpp:434] upsample1 <- pool1_mask
I0824 18:29:58.497226 42792 net.cpp:408] upsample1 -> pool1_D
I0824 18:29:58.497238 42792 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 18:29:58.497278 42792 net.cpp:150] Setting up upsample1
I0824 18:29:58.497287 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.497292 42792 net.cpp:165] Memory required for data: 4786606080
I0824 18:29:58.497303 42792 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 18:29:58.497319 42792 net.cpp:100] Creating Layer conv1_2_D
I0824 18:29:58.497326 42792 net.cpp:434] conv1_2_D <- pool1_D
I0824 18:29:58.497339 42792 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 18:29:58.501888 42792 net.cpp:150] Setting up conv1_2_D
I0824 18:29:58.501909 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.501914 42792 net.cpp:165] Memory required for data: 4963553280
I0824 18:29:58.501926 42792 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 18:29:58.501958 42792 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 18:29:58.501969 42792 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 18:29:58.501979 42792 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 18:29:58.502382 42792 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 18:29:58.502393 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.502399 42792 net.cpp:165] Memory required for data: 5140500480
I0824 18:29:58.502413 42792 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 18:29:58.502423 42792 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 18:29:58.502430 42792 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 18:29:58.502439 42792 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 18:29:58.502498 42792 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 18:29:58.504176 42792 net.cpp:150] Setting up conv1_2_D_scale
I0824 18:29:58.504194 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.504199 42792 net.cpp:165] Memory required for data: 5317447680
I0824 18:29:58.504210 42792 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 18:29:58.504221 42792 net.cpp:100] Creating Layer relu1_2_D
I0824 18:29:58.504230 42792 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 18:29:58.504241 42792 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 18:29:58.504485 42792 net.cpp:150] Setting up relu1_2_D
I0824 18:29:58.504498 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.504503 42792 net.cpp:165] Memory required for data: 5494394880
I0824 18:29:58.504511 42792 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 18:29:58.504530 42792 net.cpp:100] Creating Layer conv1_1_1_D
I0824 18:29:58.504539 42792 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 18:29:58.504565 42792 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 18:29:58.506631 42792 net.cpp:150] Setting up conv1_1_1_D
I0824 18:29:58.506651 42792 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 18:29:58.506657 42792 net.cpp:165] Memory required for data: 5499924480
I0824 18:29:58.506669 42792 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 18:29:58.506685 42792 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 18:29:58.506692 42792 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 18:29:58.506702 42792 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 18:29:58.506716 42792 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 18:29:58.506775 42792 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 18:29:58.506785 42792 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 18:29:58.506793 42792 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 18:29:58.506799 42792 net.cpp:165] Memory required for data: 5510983680
I0824 18:29:58.506808 42792 layer_factory.hpp:77] Creating layer loss
I0824 18:29:58.506825 42792 net.cpp:100] Creating Layer loss
I0824 18:29:58.506831 42792 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 18:29:58.506840 42792 net.cpp:434] loss <- label_data_1_split_0
I0824 18:29:58.506850 42792 net.cpp:408] loss -> loss
I0824 18:29:58.506871 42792 layer_factory.hpp:77] Creating layer loss
I0824 18:29:58.510928 42792 net.cpp:150] Setting up loss
I0824 18:29:58.510946 42792 net.cpp:157] Top shape: (1)
I0824 18:29:58.510951 42792 net.cpp:160]     with loss weight 1
I0824 18:29:58.510998 42792 net.cpp:165] Memory required for data: 5510983684
I0824 18:29:58.511004 42792 layer_factory.hpp:77] Creating layer accuracy
I0824 18:29:58.511029 42792 net.cpp:100] Creating Layer accuracy
I0824 18:29:58.511036 42792 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 18:29:58.511045 42792 net.cpp:434] accuracy <- label_data_1_split_1
I0824 18:29:58.511055 42792 net.cpp:408] accuracy -> accuracy
I0824 18:29:58.511068 42792 net.cpp:408] accuracy -> per_class_accuracy
I0824 18:29:58.511127 42792 net.cpp:150] Setting up accuracy
I0824 18:29:58.511137 42792 net.cpp:157] Top shape: (1)
I0824 18:29:58.511144 42792 net.cpp:157] Top shape: 2 (2)
I0824 18:29:58.511150 42792 net.cpp:165] Memory required for data: 5510983696
I0824 18:29:58.511157 42792 net.cpp:228] accuracy does not need backward computation.
I0824 18:29:58.511164 42792 net.cpp:226] loss needs backward computation.
I0824 18:29:58.511173 42792 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 18:29:58.511179 42792 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 18:29:58.511185 42792 net.cpp:226] relu1_2_D needs backward computation.
I0824 18:29:58.511193 42792 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 18:29:58.511198 42792 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 18:29:58.511203 42792 net.cpp:226] conv1_2_D needs backward computation.
I0824 18:29:58.511207 42792 net.cpp:226] upsample1 needs backward computation.
I0824 18:29:58.511215 42792 net.cpp:226] relu2_1_D needs backward computation.
I0824 18:29:58.511222 42792 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 18:29:58.511227 42792 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 18:29:58.511232 42792 net.cpp:226] conv2_1_D needs backward computation.
I0824 18:29:58.511238 42792 net.cpp:226] relu2_2_D needs backward computation.
I0824 18:29:58.511243 42792 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 18:29:58.511250 42792 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 18:29:58.511255 42792 net.cpp:226] conv2_2_D needs backward computation.
I0824 18:29:58.511260 42792 net.cpp:226] upsample2 needs backward computation.
I0824 18:29:58.511266 42792 net.cpp:226] relu3_1_D needs backward computation.
I0824 18:29:58.511272 42792 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 18:29:58.511292 42792 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 18:29:58.511298 42792 net.cpp:226] conv3_1_D needs backward computation.
I0824 18:29:58.511304 42792 net.cpp:226] relu3_2_D needs backward computation.
I0824 18:29:58.511309 42792 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 18:29:58.511314 42792 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 18:29:58.511319 42792 net.cpp:226] conv3_2_D needs backward computation.
I0824 18:29:58.511324 42792 net.cpp:226] relu3_3_D needs backward computation.
I0824 18:29:58.511332 42792 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 18:29:58.511337 42792 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 18:29:58.511343 42792 net.cpp:226] conv3_3_D needs backward computation.
I0824 18:29:58.511348 42792 net.cpp:226] upsample3 needs backward computation.
I0824 18:29:58.511354 42792 net.cpp:226] relu4_1_D needs backward computation.
I0824 18:29:58.511360 42792 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 18:29:58.511366 42792 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 18:29:58.511371 42792 net.cpp:226] conv4_1_D needs backward computation.
I0824 18:29:58.511378 42792 net.cpp:226] relu4_2_D needs backward computation.
I0824 18:29:58.511382 42792 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 18:29:58.511389 42792 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 18:29:58.511395 42792 net.cpp:226] conv4_2_D needs backward computation.
I0824 18:29:58.511400 42792 net.cpp:226] relu4_3_D needs backward computation.
I0824 18:29:58.511407 42792 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 18:29:58.511414 42792 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 18:29:58.511418 42792 net.cpp:226] conv4_3_D needs backward computation.
I0824 18:29:58.511425 42792 net.cpp:226] upsample4 needs backward computation.
I0824 18:29:58.511433 42792 net.cpp:226] relu5_1_D needs backward computation.
I0824 18:29:58.511440 42792 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 18:29:58.511446 42792 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 18:29:58.511451 42792 net.cpp:226] conv5_1_D needs backward computation.
I0824 18:29:58.511458 42792 net.cpp:226] relu5_2_D needs backward computation.
I0824 18:29:58.511466 42792 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 18:29:58.511474 42792 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 18:29:58.511481 42792 net.cpp:226] conv5_2_D needs backward computation.
I0824 18:29:58.511488 42792 net.cpp:226] relu5_3_D needs backward computation.
I0824 18:29:58.511495 42792 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 18:29:58.511502 42792 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 18:29:58.511507 42792 net.cpp:226] conv5_3_D needs backward computation.
I0824 18:29:58.511513 42792 net.cpp:226] upsample5 needs backward computation.
I0824 18:29:58.511523 42792 net.cpp:226] pool5 needs backward computation.
I0824 18:29:58.511530 42792 net.cpp:226] relu5_3 needs backward computation.
I0824 18:29:58.511538 42792 net.cpp:226] conv5_3_scale needs backward computation.
I0824 18:29:58.511543 42792 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 18:29:58.511550 42792 net.cpp:226] conv5_3 needs backward computation.
I0824 18:29:58.511556 42792 net.cpp:226] relu5_2 needs backward computation.
I0824 18:29:58.511564 42792 net.cpp:226] conv5_2_scale needs backward computation.
I0824 18:29:58.511569 42792 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 18:29:58.511574 42792 net.cpp:226] conv5_2 needs backward computation.
I0824 18:29:58.511581 42792 net.cpp:226] relu5_1 needs backward computation.
I0824 18:29:58.511589 42792 net.cpp:226] conv5_1_scale needs backward computation.
I0824 18:29:58.511593 42792 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 18:29:58.511601 42792 net.cpp:226] conv5_1 needs backward computation.
I0824 18:29:58.511610 42792 net.cpp:226] pool4 needs backward computation.
I0824 18:29:58.511626 42792 net.cpp:226] relu4_3 needs backward computation.
I0824 18:29:58.511633 42792 net.cpp:226] conv4_3_scale needs backward computation.
I0824 18:29:58.511639 42792 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 18:29:58.511646 42792 net.cpp:226] conv4_3 needs backward computation.
I0824 18:29:58.511652 42792 net.cpp:226] relu4_2 needs backward computation.
I0824 18:29:58.511658 42792 net.cpp:226] conv4_2_scale needs backward computation.
I0824 18:29:58.511663 42792 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 18:29:58.511670 42792 net.cpp:226] conv4_2 needs backward computation.
I0824 18:29:58.511677 42792 net.cpp:226] relu4_1 needs backward computation.
I0824 18:29:58.511683 42792 net.cpp:226] conv4_1_scale needs backward computation.
I0824 18:29:58.511689 42792 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 18:29:58.511694 42792 net.cpp:226] conv4_1 needs backward computation.
I0824 18:29:58.511701 42792 net.cpp:226] pool3 needs backward computation.
I0824 18:29:58.511708 42792 net.cpp:226] relu3_3 needs backward computation.
I0824 18:29:58.511714 42792 net.cpp:226] conv3_3_scale needs backward computation.
I0824 18:29:58.511719 42792 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 18:29:58.511726 42792 net.cpp:226] conv3_3 needs backward computation.
I0824 18:29:58.511734 42792 net.cpp:226] relu3_2 needs backward computation.
I0824 18:29:58.511739 42792 net.cpp:226] conv3_2_scale needs backward computation.
I0824 18:29:58.511745 42792 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 18:29:58.511751 42792 net.cpp:226] conv3_2 needs backward computation.
I0824 18:29:58.511759 42792 net.cpp:226] relu3_1 needs backward computation.
I0824 18:29:58.511765 42792 net.cpp:226] conv3_1_scale needs backward computation.
I0824 18:29:58.511771 42792 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 18:29:58.511776 42792 net.cpp:226] conv3_1 needs backward computation.
I0824 18:29:58.511782 42792 net.cpp:226] pool2 needs backward computation.
I0824 18:29:58.511790 42792 net.cpp:226] relu2_2 needs backward computation.
I0824 18:29:58.511795 42792 net.cpp:226] conv2_2_scale needs backward computation.
I0824 18:29:58.511802 42792 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 18:29:58.511807 42792 net.cpp:226] conv2_2 needs backward computation.
I0824 18:29:58.511816 42792 net.cpp:226] relu2_1 needs backward computation.
I0824 18:29:58.511822 42792 net.cpp:226] conv2_1_scale needs backward computation.
I0824 18:29:58.511827 42792 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 18:29:58.511834 42792 net.cpp:226] conv2_1 needs backward computation.
I0824 18:29:58.511842 42792 net.cpp:226] pool1 needs backward computation.
I0824 18:29:58.511848 42792 net.cpp:226] relu1_2 needs backward computation.
I0824 18:29:58.511857 42792 net.cpp:226] conv1_2_scale needs backward computation.
I0824 18:29:58.511862 42792 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 18:29:58.511870 42792 net.cpp:226] conv1_2 needs backward computation.
I0824 18:29:58.511878 42792 net.cpp:226] relu1_1 needs backward computation.
I0824 18:29:58.511883 42792 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 18:29:58.511889 42792 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 18:29:58.511895 42792 net.cpp:226] conv1_1_1 needs backward computation.
I0824 18:29:58.511903 42792 net.cpp:228] label_data_1_split does not need backward computation.
I0824 18:29:58.511910 42792 net.cpp:228] data does not need backward computation.
I0824 18:29:58.511917 42792 net.cpp:270] This network produces output accuracy
I0824 18:29:58.511924 42792 net.cpp:270] This network produces output loss
I0824 18:29:58.511931 42792 net.cpp:270] This network produces output per_class_accuracy
I0824 18:29:58.512006 42792 net.cpp:283] Network initialization done.
I0824 18:29:58.514364 42792 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc3/caffe/model_segnet_final/train.prototxt
I0824 18:29:58.515065 42792 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc3/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 18:29:58.515504 42792 layer_factory.hpp:77] Creating layer data
I0824 18:29:58.515519 42792 net.cpp:100] Creating Layer data
I0824 18:29:58.515529 42792 net.cpp:408] data -> data
I0824 18:29:58.515542 42792 net.cpp:408] data -> label
I0824 18:29:58.515553 42792 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc3/HDF5Files/train_combined.txt
I0824 18:29:58.515605 42792 hdf5_data_layer.cpp:93] Number of HDF5 files: 46
I0824 18:29:58.603618 42792 net.cpp:150] Setting up data
I0824 18:29:58.603639 42792 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 18:29:58.603648 42792 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 18:29:58.603654 42792 net.cpp:165] Memory required for data: 24883200
I0824 18:29:58.603662 42792 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 18:29:58.603674 42792 net.cpp:100] Creating Layer label_data_1_split
I0824 18:29:58.603693 42792 net.cpp:434] label_data_1_split <- label
I0824 18:29:58.603703 42792 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 18:29:58.603725 42792 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 18:29:58.603781 42792 net.cpp:150] Setting up label_data_1_split
I0824 18:29:58.603791 42792 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 18:29:58.603799 42792 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 18:29:58.603812 42792 net.cpp:165] Memory required for data: 30412800
I0824 18:29:58.603818 42792 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 18:29:58.603842 42792 net.cpp:100] Creating Layer conv1_1_1
I0824 18:29:58.603847 42792 net.cpp:434] conv1_1_1 <- data
I0824 18:29:58.603857 42792 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 18:29:58.607334 42792 net.cpp:150] Setting up conv1_1_1
I0824 18:29:58.607354 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.607362 42792 net.cpp:165] Memory required for data: 207360000
I0824 18:29:58.607378 42792 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 18:29:58.607399 42792 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 18:29:58.607412 42792 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 18:29:58.607422 42792 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 18:29:58.607815 42792 net.cpp:150] Setting up conv1_1_1_bn
I0824 18:29:58.607825 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.607831 42792 net.cpp:165] Memory required for data: 384307200
I0824 18:29:58.607848 42792 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 18:29:58.607858 42792 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 18:29:58.607866 42792 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 18:29:58.607873 42792 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 18:29:58.607931 42792 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 18:29:58.609616 42792 net.cpp:150] Setting up conv1_1_1_scale
I0824 18:29:58.609634 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.609640 42792 net.cpp:165] Memory required for data: 561254400
I0824 18:29:58.609653 42792 layer_factory.hpp:77] Creating layer relu1_1
I0824 18:29:58.609664 42792 net.cpp:100] Creating Layer relu1_1
I0824 18:29:58.609671 42792 net.cpp:434] relu1_1 <- conv1_1_1
I0824 18:29:58.609680 42792 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 18:29:58.609905 42792 net.cpp:150] Setting up relu1_1
I0824 18:29:58.609915 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.609921 42792 net.cpp:165] Memory required for data: 738201600
I0824 18:29:58.609927 42792 layer_factory.hpp:77] Creating layer conv1_2
I0824 18:29:58.609944 42792 net.cpp:100] Creating Layer conv1_2
I0824 18:29:58.609951 42792 net.cpp:434] conv1_2 <- conv1_1_1
I0824 18:29:58.609961 42792 net.cpp:408] conv1_2 -> conv1_2
I0824 18:29:58.614050 42792 net.cpp:150] Setting up conv1_2
I0824 18:29:58.614070 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.614076 42792 net.cpp:165] Memory required for data: 915148800
I0824 18:29:58.614122 42792 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 18:29:58.614140 42792 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 18:29:58.614151 42792 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 18:29:58.614161 42792 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 18:29:58.614544 42792 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 18:29:58.614555 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.614562 42792 net.cpp:165] Memory required for data: 1092096000
I0824 18:29:58.614574 42792 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 18:29:58.614585 42792 net.cpp:100] Creating Layer conv1_2_scale
I0824 18:29:58.614591 42792 net.cpp:434] conv1_2_scale <- conv1_2
I0824 18:29:58.614601 42792 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 18:29:58.614656 42792 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 18:29:58.616348 42792 net.cpp:150] Setting up conv1_2_scale
I0824 18:29:58.616366 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.616372 42792 net.cpp:165] Memory required for data: 1269043200
I0824 18:29:58.616384 42792 layer_factory.hpp:77] Creating layer relu1_2
I0824 18:29:58.616394 42792 net.cpp:100] Creating Layer relu1_2
I0824 18:29:58.616402 42792 net.cpp:434] relu1_2 <- conv1_2
I0824 18:29:58.616410 42792 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 18:29:58.617542 42792 net.cpp:150] Setting up relu1_2
I0824 18:29:58.617560 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:58.617566 42792 net.cpp:165] Memory required for data: 1445990400
I0824 18:29:58.617573 42792 layer_factory.hpp:77] Creating layer pool1
I0824 18:29:58.617579 42792 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 18:29:58.617590 42792 net.cpp:100] Creating Layer pool1
I0824 18:29:58.617597 42792 net.cpp:434] pool1 <- conv1_2
I0824 18:29:58.617607 42792 net.cpp:408] pool1 -> pool1
I0824 18:29:58.617619 42792 net.cpp:408] pool1 -> pool1_mask
I0824 18:29:58.617682 42792 net.cpp:150] Setting up pool1
I0824 18:29:58.617692 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:58.617700 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:58.617707 42792 net.cpp:165] Memory required for data: 1534464000
I0824 18:29:58.617712 42792 layer_factory.hpp:77] Creating layer conv2_1
I0824 18:29:58.617729 42792 net.cpp:100] Creating Layer conv2_1
I0824 18:29:58.617736 42792 net.cpp:434] conv2_1 <- pool1
I0824 18:29:58.617746 42792 net.cpp:408] conv2_1 -> conv2_1
I0824 18:29:58.622076 42792 net.cpp:150] Setting up conv2_1
I0824 18:29:58.622094 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.622100 42792 net.cpp:165] Memory required for data: 1622937600
I0824 18:29:58.622112 42792 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 18:29:58.622123 42792 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 18:29:58.622138 42792 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 18:29:58.622151 42792 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 18:29:58.622472 42792 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 18:29:58.622483 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.622488 42792 net.cpp:165] Memory required for data: 1711411200
I0824 18:29:58.622505 42792 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 18:29:58.622514 42792 net.cpp:100] Creating Layer conv2_1_scale
I0824 18:29:58.622522 42792 net.cpp:434] conv2_1_scale <- conv2_1
I0824 18:29:58.622534 42792 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 18:29:58.622591 42792 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 18:29:58.622836 42792 net.cpp:150] Setting up conv2_1_scale
I0824 18:29:58.622855 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.622860 42792 net.cpp:165] Memory required for data: 1799884800
I0824 18:29:58.622870 42792 layer_factory.hpp:77] Creating layer relu2_1
I0824 18:29:58.622880 42792 net.cpp:100] Creating Layer relu2_1
I0824 18:29:58.622887 42792 net.cpp:434] relu2_1 <- conv2_1
I0824 18:29:58.622895 42792 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 18:29:58.624042 42792 net.cpp:150] Setting up relu2_1
I0824 18:29:58.624058 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.624064 42792 net.cpp:165] Memory required for data: 1888358400
I0824 18:29:58.624071 42792 layer_factory.hpp:77] Creating layer conv2_2
I0824 18:29:58.624090 42792 net.cpp:100] Creating Layer conv2_2
I0824 18:29:58.624097 42792 net.cpp:434] conv2_2 <- conv2_1
I0824 18:29:58.624109 42792 net.cpp:408] conv2_2 -> conv2_2
I0824 18:29:58.633113 42792 net.cpp:150] Setting up conv2_2
I0824 18:29:58.633133 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.633139 42792 net.cpp:165] Memory required for data: 1976832000
I0824 18:29:58.633152 42792 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 18:29:58.633182 42792 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 18:29:58.633189 42792 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 18:29:58.633199 42792 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 18:29:58.634778 42792 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 18:29:58.634796 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.634802 42792 net.cpp:165] Memory required for data: 2065305600
I0824 18:29:58.634816 42792 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 18:29:58.634836 42792 net.cpp:100] Creating Layer conv2_2_scale
I0824 18:29:58.634850 42792 net.cpp:434] conv2_2_scale <- conv2_2
I0824 18:29:58.634869 42792 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 18:29:58.634933 42792 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 18:29:58.635154 42792 net.cpp:150] Setting up conv2_2_scale
I0824 18:29:58.635167 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.635174 42792 net.cpp:165] Memory required for data: 2153779200
I0824 18:29:58.635185 42792 layer_factory.hpp:77] Creating layer relu2_2
I0824 18:29:58.635195 42792 net.cpp:100] Creating Layer relu2_2
I0824 18:29:58.635201 42792 net.cpp:434] relu2_2 <- conv2_2
I0824 18:29:58.635210 42792 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 18:29:58.635444 42792 net.cpp:150] Setting up relu2_2
I0824 18:29:58.635458 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:58.635466 42792 net.cpp:165] Memory required for data: 2242252800
I0824 18:29:58.635473 42792 layer_factory.hpp:77] Creating layer pool2
I0824 18:29:58.635480 42792 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 18:29:58.635490 42792 net.cpp:100] Creating Layer pool2
I0824 18:29:58.635498 42792 net.cpp:434] pool2 <- conv2_2
I0824 18:29:58.635507 42792 net.cpp:408] pool2 -> pool2
I0824 18:29:58.635522 42792 net.cpp:408] pool2 -> pool2_mask
I0824 18:29:58.635584 42792 net.cpp:150] Setting up pool2
I0824 18:29:58.635594 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:58.635601 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:58.635608 42792 net.cpp:165] Memory required for data: 2286489600
I0824 18:29:58.635613 42792 layer_factory.hpp:77] Creating layer conv3_1
I0824 18:29:58.635632 42792 net.cpp:100] Creating Layer conv3_1
I0824 18:29:58.635638 42792 net.cpp:434] conv3_1 <- pool2
I0824 18:29:58.635648 42792 net.cpp:408] conv3_1 -> conv3_1
I0824 18:29:58.648161 42792 net.cpp:150] Setting up conv3_1
I0824 18:29:58.648183 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.648190 42792 net.cpp:165] Memory required for data: 2330726400
I0824 18:29:58.648202 42792 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 18:29:58.648216 42792 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 18:29:58.648236 42792 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 18:29:58.648247 42792 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 18:29:58.648542 42792 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 18:29:58.648553 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.648560 42792 net.cpp:165] Memory required for data: 2374963200
I0824 18:29:58.648582 42792 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 18:29:58.648607 42792 net.cpp:100] Creating Layer conv3_1_scale
I0824 18:29:58.648618 42792 net.cpp:434] conv3_1_scale <- conv3_1
I0824 18:29:58.648627 42792 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 18:29:58.648695 42792 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 18:29:58.648880 42792 net.cpp:150] Setting up conv3_1_scale
I0824 18:29:58.648890 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.648895 42792 net.cpp:165] Memory required for data: 2419200000
I0824 18:29:58.648906 42792 layer_factory.hpp:77] Creating layer relu3_1
I0824 18:29:58.648916 42792 net.cpp:100] Creating Layer relu3_1
I0824 18:29:58.648923 42792 net.cpp:434] relu3_1 <- conv3_1
I0824 18:29:58.648934 42792 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 18:29:58.649164 42792 net.cpp:150] Setting up relu3_1
I0824 18:29:58.649176 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.649183 42792 net.cpp:165] Memory required for data: 2463436800
I0824 18:29:58.649188 42792 layer_factory.hpp:77] Creating layer conv3_2
I0824 18:29:58.649206 42792 net.cpp:100] Creating Layer conv3_2
I0824 18:29:58.649214 42792 net.cpp:434] conv3_2 <- conv3_1
I0824 18:29:58.649226 42792 net.cpp:408] conv3_2 -> conv3_2
I0824 18:29:58.672817 42792 net.cpp:150] Setting up conv3_2
I0824 18:29:58.672837 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.672843 42792 net.cpp:165] Memory required for data: 2507673600
I0824 18:29:58.672858 42792 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 18:29:58.672883 42792 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 18:29:58.672895 42792 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 18:29:58.672914 42792 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 18:29:58.673211 42792 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 18:29:58.673225 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.673239 42792 net.cpp:165] Memory required for data: 2551910400
I0824 18:29:58.673252 42792 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 18:29:58.673262 42792 net.cpp:100] Creating Layer conv3_2_scale
I0824 18:29:58.673269 42792 net.cpp:434] conv3_2_scale <- conv3_2
I0824 18:29:58.673279 42792 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 18:29:58.673341 42792 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 18:29:58.673534 42792 net.cpp:150] Setting up conv3_2_scale
I0824 18:29:58.673547 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.673552 42792 net.cpp:165] Memory required for data: 2596147200
I0824 18:29:58.673563 42792 layer_factory.hpp:77] Creating layer relu3_2
I0824 18:29:58.673576 42792 net.cpp:100] Creating Layer relu3_2
I0824 18:29:58.673583 42792 net.cpp:434] relu3_2 <- conv3_2
I0824 18:29:58.673590 42792 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 18:29:58.673820 42792 net.cpp:150] Setting up relu3_2
I0824 18:29:58.673832 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.673838 42792 net.cpp:165] Memory required for data: 2640384000
I0824 18:29:58.673844 42792 layer_factory.hpp:77] Creating layer conv3_3
I0824 18:29:58.673867 42792 net.cpp:100] Creating Layer conv3_3
I0824 18:29:58.673874 42792 net.cpp:434] conv3_3 <- conv3_2
I0824 18:29:58.673885 42792 net.cpp:408] conv3_3 -> conv3_3
I0824 18:29:58.697448 42792 net.cpp:150] Setting up conv3_3
I0824 18:29:58.697466 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.697474 42792 net.cpp:165] Memory required for data: 2684620800
I0824 18:29:58.697485 42792 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 18:29:58.697511 42792 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 18:29:58.697521 42792 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 18:29:58.697541 42792 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 18:29:58.697835 42792 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 18:29:58.697846 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.697852 42792 net.cpp:165] Memory required for data: 2728857600
I0824 18:29:58.697865 42792 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 18:29:58.697893 42792 net.cpp:100] Creating Layer conv3_3_scale
I0824 18:29:58.697901 42792 net.cpp:434] conv3_3_scale <- conv3_3
I0824 18:29:58.697908 42792 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 18:29:58.697970 42792 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 18:29:58.698158 42792 net.cpp:150] Setting up conv3_3_scale
I0824 18:29:58.698169 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.698174 42792 net.cpp:165] Memory required for data: 2773094400
I0824 18:29:58.698185 42792 layer_factory.hpp:77] Creating layer relu3_3
I0824 18:29:58.698195 42792 net.cpp:100] Creating Layer relu3_3
I0824 18:29:58.698202 42792 net.cpp:434] relu3_3 <- conv3_3
I0824 18:29:58.698210 42792 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 18:29:58.698444 42792 net.cpp:150] Setting up relu3_3
I0824 18:29:58.698457 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:58.698462 42792 net.cpp:165] Memory required for data: 2817331200
I0824 18:29:58.698468 42792 layer_factory.hpp:77] Creating layer pool3
I0824 18:29:58.698477 42792 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 18:29:58.698492 42792 net.cpp:100] Creating Layer pool3
I0824 18:29:58.698498 42792 net.cpp:434] pool3 <- conv3_3
I0824 18:29:58.698508 42792 net.cpp:408] pool3 -> pool3
I0824 18:29:58.698518 42792 net.cpp:408] pool3 -> pool3_mask
I0824 18:29:58.698585 42792 net.cpp:150] Setting up pool3
I0824 18:29:58.698595 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:58.698602 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:58.698608 42792 net.cpp:165] Memory required for data: 2839449600
I0824 18:29:58.698614 42792 layer_factory.hpp:77] Creating layer conv4_1
I0824 18:29:58.698629 42792 net.cpp:100] Creating Layer conv4_1
I0824 18:29:58.698637 42792 net.cpp:434] conv4_1 <- pool3
I0824 18:29:58.698649 42792 net.cpp:408] conv4_1 -> conv4_1
I0824 18:29:58.742517 42792 net.cpp:150] Setting up conv4_1
I0824 18:29:58.742537 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.742543 42792 net.cpp:165] Memory required for data: 2861568000
I0824 18:29:58.742555 42792 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 18:29:58.742585 42792 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 18:29:58.742596 42792 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 18:29:58.742614 42792 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 18:29:58.742908 42792 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 18:29:58.742918 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.742924 42792 net.cpp:165] Memory required for data: 2883686400
I0824 18:29:58.742940 42792 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 18:29:58.742951 42792 net.cpp:100] Creating Layer conv4_1_scale
I0824 18:29:58.742959 42792 net.cpp:434] conv4_1_scale <- conv4_1
I0824 18:29:58.742967 42792 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 18:29:58.743026 42792 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 18:29:58.743198 42792 net.cpp:150] Setting up conv4_1_scale
I0824 18:29:58.743208 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.743214 42792 net.cpp:165] Memory required for data: 2905804800
I0824 18:29:58.743224 42792 layer_factory.hpp:77] Creating layer relu4_1
I0824 18:29:58.743238 42792 net.cpp:100] Creating Layer relu4_1
I0824 18:29:58.743245 42792 net.cpp:434] relu4_1 <- conv4_1
I0824 18:29:58.743253 42792 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 18:29:58.744397 42792 net.cpp:150] Setting up relu4_1
I0824 18:29:58.744415 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.744421 42792 net.cpp:165] Memory required for data: 2927923200
I0824 18:29:58.744427 42792 layer_factory.hpp:77] Creating layer conv4_2
I0824 18:29:58.744444 42792 net.cpp:100] Creating Layer conv4_2
I0824 18:29:58.744451 42792 net.cpp:434] conv4_2 <- conv4_1
I0824 18:29:58.744465 42792 net.cpp:408] conv4_2 -> conv4_2
I0824 18:29:58.827193 42792 net.cpp:150] Setting up conv4_2
I0824 18:29:58.827230 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.827237 42792 net.cpp:165] Memory required for data: 2950041600
I0824 18:29:58.827249 42792 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 18:29:58.827258 42792 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 18:29:58.827265 42792 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 18:29:58.827275 42792 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 18:29:58.827560 42792 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 18:29:58.827571 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.827577 42792 net.cpp:165] Memory required for data: 2972160000
I0824 18:29:58.827590 42792 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 18:29:58.827605 42792 net.cpp:100] Creating Layer conv4_2_scale
I0824 18:29:58.827617 42792 net.cpp:434] conv4_2_scale <- conv4_2
I0824 18:29:58.827636 42792 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 18:29:58.827699 42792 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 18:29:58.827874 42792 net.cpp:150] Setting up conv4_2_scale
I0824 18:29:58.827885 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.827891 42792 net.cpp:165] Memory required for data: 2994278400
I0824 18:29:58.827901 42792 layer_factory.hpp:77] Creating layer relu4_2
I0824 18:29:58.827911 42792 net.cpp:100] Creating Layer relu4_2
I0824 18:29:58.827919 42792 net.cpp:434] relu4_2 <- conv4_2
I0824 18:29:58.827930 42792 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 18:29:58.829090 42792 net.cpp:150] Setting up relu4_2
I0824 18:29:58.829107 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.829113 42792 net.cpp:165] Memory required for data: 3016396800
I0824 18:29:58.829119 42792 layer_factory.hpp:77] Creating layer conv4_3
I0824 18:29:58.829138 42792 net.cpp:100] Creating Layer conv4_3
I0824 18:29:58.829144 42792 net.cpp:434] conv4_3 <- conv4_2
I0824 18:29:58.829159 42792 net.cpp:408] conv4_3 -> conv4_3
I0824 18:29:58.912799 42792 net.cpp:150] Setting up conv4_3
I0824 18:29:58.912818 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.912824 42792 net.cpp:165] Memory required for data: 3038515200
I0824 18:29:58.912856 42792 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 18:29:58.912870 42792 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 18:29:58.912883 42792 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 18:29:58.912902 42792 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 18:29:58.913192 42792 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 18:29:58.913203 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.913208 42792 net.cpp:165] Memory required for data: 3060633600
I0824 18:29:58.913221 42792 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 18:29:58.913236 42792 net.cpp:100] Creating Layer conv4_3_scale
I0824 18:29:58.913244 42792 net.cpp:434] conv4_3_scale <- conv4_3
I0824 18:29:58.913252 42792 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 18:29:58.913310 42792 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 18:29:58.913493 42792 net.cpp:150] Setting up conv4_3_scale
I0824 18:29:58.913506 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.913511 42792 net.cpp:165] Memory required for data: 3082752000
I0824 18:29:58.913522 42792 layer_factory.hpp:77] Creating layer relu4_3
I0824 18:29:58.913532 42792 net.cpp:100] Creating Layer relu4_3
I0824 18:29:58.913539 42792 net.cpp:434] relu4_3 <- conv4_3
I0824 18:29:58.913550 42792 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 18:29:58.913779 42792 net.cpp:150] Setting up relu4_3
I0824 18:29:58.913790 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:58.913796 42792 net.cpp:165] Memory required for data: 3104870400
I0824 18:29:58.913802 42792 layer_factory.hpp:77] Creating layer pool4
I0824 18:29:58.913810 42792 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 18:29:58.913820 42792 net.cpp:100] Creating Layer pool4
I0824 18:29:58.913826 42792 net.cpp:434] pool4 <- conv4_3
I0824 18:29:58.913853 42792 net.cpp:408] pool4 -> pool4
I0824 18:29:58.913866 42792 net.cpp:408] pool4 -> pool4_mask
I0824 18:29:58.913933 42792 net.cpp:150] Setting up pool4
I0824 18:29:58.913942 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.913949 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.913955 42792 net.cpp:165] Memory required for data: 3116175360
I0824 18:29:58.913961 42792 layer_factory.hpp:77] Creating layer conv5_1
I0824 18:29:58.913978 42792 net.cpp:100] Creating Layer conv5_1
I0824 18:29:58.913985 42792 net.cpp:434] conv5_1 <- pool4
I0824 18:29:58.913998 42792 net.cpp:408] conv5_1 -> conv5_1
I0824 18:29:58.997581 42792 net.cpp:150] Setting up conv5_1
I0824 18:29:58.997601 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.997606 42792 net.cpp:165] Memory required for data: 3121827840
I0824 18:29:58.997618 42792 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 18:29:58.997643 42792 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 18:29:58.997658 42792 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 18:29:58.997681 42792 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 18:29:58.997970 42792 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 18:29:58.997982 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.997987 42792 net.cpp:165] Memory required for data: 3127480320
I0824 18:29:58.998000 42792 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 18:29:58.998013 42792 net.cpp:100] Creating Layer conv5_1_scale
I0824 18:29:58.998020 42792 net.cpp:434] conv5_1_scale <- conv5_1
I0824 18:29:58.998029 42792 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 18:29:58.998096 42792 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 18:29:58.998257 42792 net.cpp:150] Setting up conv5_1_scale
I0824 18:29:58.998268 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.998273 42792 net.cpp:165] Memory required for data: 3133132800
I0824 18:29:58.998284 42792 layer_factory.hpp:77] Creating layer relu5_1
I0824 18:29:58.998293 42792 net.cpp:100] Creating Layer relu5_1
I0824 18:29:58.998301 42792 net.cpp:434] relu5_1 <- conv5_1
I0824 18:29:58.998311 42792 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 18:29:58.998535 42792 net.cpp:150] Setting up relu5_1
I0824 18:29:58.998548 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:58.998553 42792 net.cpp:165] Memory required for data: 3138785280
I0824 18:29:58.998559 42792 layer_factory.hpp:77] Creating layer conv5_2
I0824 18:29:58.998575 42792 net.cpp:100] Creating Layer conv5_2
I0824 18:29:58.998581 42792 net.cpp:434] conv5_2 <- conv5_1
I0824 18:29:58.998595 42792 net.cpp:408] conv5_2 -> conv5_2
I0824 18:29:59.082207 42792 net.cpp:150] Setting up conv5_2
I0824 18:29:59.082227 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.082233 42792 net.cpp:165] Memory required for data: 3144437760
I0824 18:29:59.082245 42792 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 18:29:59.082258 42792 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 18:29:59.082279 42792 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 18:29:59.082289 42792 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 18:29:59.082582 42792 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 18:29:59.082593 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.082598 42792 net.cpp:165] Memory required for data: 3150090240
I0824 18:29:59.082612 42792 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 18:29:59.082625 42792 net.cpp:100] Creating Layer conv5_2_scale
I0824 18:29:59.082638 42792 net.cpp:434] conv5_2_scale <- conv5_2
I0824 18:29:59.082651 42792 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 18:29:59.082715 42792 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 18:29:59.082878 42792 net.cpp:150] Setting up conv5_2_scale
I0824 18:29:59.082888 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.082895 42792 net.cpp:165] Memory required for data: 3155742720
I0824 18:29:59.082904 42792 layer_factory.hpp:77] Creating layer relu5_2
I0824 18:29:59.082931 42792 net.cpp:100] Creating Layer relu5_2
I0824 18:29:59.082938 42792 net.cpp:434] relu5_2 <- conv5_2
I0824 18:29:59.082947 42792 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 18:29:59.083176 42792 net.cpp:150] Setting up relu5_2
I0824 18:29:59.083189 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.083195 42792 net.cpp:165] Memory required for data: 3161395200
I0824 18:29:59.083201 42792 layer_factory.hpp:77] Creating layer conv5_3
I0824 18:29:59.083218 42792 net.cpp:100] Creating Layer conv5_3
I0824 18:29:59.083225 42792 net.cpp:434] conv5_3 <- conv5_2
I0824 18:29:59.083238 42792 net.cpp:408] conv5_3 -> conv5_3
I0824 18:29:59.167986 42792 net.cpp:150] Setting up conv5_3
I0824 18:29:59.168012 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.168018 42792 net.cpp:165] Memory required for data: 3167047680
I0824 18:29:59.168037 42792 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 18:29:59.168056 42792 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 18:29:59.168071 42792 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 18:29:59.168089 42792 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 18:29:59.168377 42792 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 18:29:59.168387 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.168393 42792 net.cpp:165] Memory required for data: 3172700160
I0824 18:29:59.168406 42792 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 18:29:59.168423 42792 net.cpp:100] Creating Layer conv5_3_scale
I0824 18:29:59.168429 42792 net.cpp:434] conv5_3_scale <- conv5_3
I0824 18:29:59.168438 42792 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 18:29:59.168504 42792 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 18:29:59.168669 42792 net.cpp:150] Setting up conv5_3_scale
I0824 18:29:59.168679 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.168684 42792 net.cpp:165] Memory required for data: 3178352640
I0824 18:29:59.168695 42792 layer_factory.hpp:77] Creating layer relu5_3
I0824 18:29:59.168705 42792 net.cpp:100] Creating Layer relu5_3
I0824 18:29:59.168712 42792 net.cpp:434] relu5_3 <- conv5_3
I0824 18:29:59.168725 42792 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 18:29:59.168952 42792 net.cpp:150] Setting up relu5_3
I0824 18:29:59.168964 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.168970 42792 net.cpp:165] Memory required for data: 3184005120
I0824 18:29:59.168977 42792 layer_factory.hpp:77] Creating layer pool5
I0824 18:29:59.168982 42792 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 18:29:59.168993 42792 net.cpp:100] Creating Layer pool5
I0824 18:29:59.169000 42792 net.cpp:434] pool5 <- conv5_3
I0824 18:29:59.169015 42792 net.cpp:408] pool5 -> pool5
I0824 18:29:59.169028 42792 net.cpp:408] pool5 -> pool5_mask
I0824 18:29:59.169096 42792 net.cpp:150] Setting up pool5
I0824 18:29:59.169106 42792 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 18:29:59.169113 42792 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 18:29:59.169119 42792 net.cpp:165] Memory required for data: 3186954240
I0824 18:29:59.169126 42792 layer_factory.hpp:77] Creating layer upsample5
I0824 18:29:59.169136 42792 net.cpp:100] Creating Layer upsample5
I0824 18:29:59.169142 42792 net.cpp:434] upsample5 <- pool5
I0824 18:29:59.169149 42792 net.cpp:434] upsample5 <- pool5_mask
I0824 18:29:59.169162 42792 net.cpp:408] upsample5 -> pool5_D
I0824 18:29:59.169201 42792 net.cpp:150] Setting up upsample5
I0824 18:29:59.169210 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.169215 42792 net.cpp:165] Memory required for data: 3192606720
I0824 18:29:59.169221 42792 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 18:29:59.169244 42792 net.cpp:100] Creating Layer conv5_3_D
I0824 18:29:59.169250 42792 net.cpp:434] conv5_3_D <- pool5_D
I0824 18:29:59.169260 42792 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 18:29:59.252993 42792 net.cpp:150] Setting up conv5_3_D
I0824 18:29:59.253013 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.253053 42792 net.cpp:165] Memory required for data: 3198259200
I0824 18:29:59.253067 42792 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 18:29:59.253083 42792 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 18:29:59.253096 42792 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 18:29:59.253118 42792 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 18:29:59.253419 42792 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 18:29:59.253432 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.253437 42792 net.cpp:165] Memory required for data: 3203911680
I0824 18:29:59.253451 42792 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 18:29:59.253461 42792 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 18:29:59.253469 42792 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 18:29:59.253479 42792 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 18:29:59.253545 42792 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 18:29:59.253711 42792 net.cpp:150] Setting up conv5_3_D_scale
I0824 18:29:59.253721 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.253726 42792 net.cpp:165] Memory required for data: 3209564160
I0824 18:29:59.253737 42792 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 18:29:59.253747 42792 net.cpp:100] Creating Layer relu5_3_D
I0824 18:29:59.253754 42792 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 18:29:59.253765 42792 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 18:29:59.254933 42792 net.cpp:150] Setting up relu5_3_D
I0824 18:29:59.254951 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.254956 42792 net.cpp:165] Memory required for data: 3215216640
I0824 18:29:59.254963 42792 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 18:29:59.255010 42792 net.cpp:100] Creating Layer conv5_2_D
I0824 18:29:59.255018 42792 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 18:29:59.255033 42792 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 18:29:59.339393 42792 net.cpp:150] Setting up conv5_2_D
I0824 18:29:59.339413 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.339421 42792 net.cpp:165] Memory required for data: 3220869120
I0824 18:29:59.339433 42792 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 18:29:59.339455 42792 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 18:29:59.339470 42792 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 18:29:59.339491 42792 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 18:29:59.339793 42792 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 18:29:59.339804 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.339810 42792 net.cpp:165] Memory required for data: 3226521600
I0824 18:29:59.339825 42792 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 18:29:59.339836 42792 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 18:29:59.339844 42792 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 18:29:59.339854 42792 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 18:29:59.339921 42792 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 18:29:59.340088 42792 net.cpp:150] Setting up conv5_2_D_scale
I0824 18:29:59.340098 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.340104 42792 net.cpp:165] Memory required for data: 3232174080
I0824 18:29:59.340116 42792 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 18:29:59.340128 42792 net.cpp:100] Creating Layer relu5_2_D
I0824 18:29:59.340135 42792 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 18:29:59.340145 42792 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 18:29:59.341310 42792 net.cpp:150] Setting up relu5_2_D
I0824 18:29:59.341326 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.341333 42792 net.cpp:165] Memory required for data: 3237826560
I0824 18:29:59.341339 42792 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 18:29:59.341359 42792 net.cpp:100] Creating Layer conv5_1_D
I0824 18:29:59.341373 42792 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 18:29:59.341385 42792 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 18:29:59.425523 42792 net.cpp:150] Setting up conv5_1_D
I0824 18:29:59.425546 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.425552 42792 net.cpp:165] Memory required for data: 3243479040
I0824 18:29:59.425565 42792 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 18:29:59.425590 42792 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 18:29:59.425603 42792 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 18:29:59.425622 42792 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 18:29:59.425921 42792 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 18:29:59.425932 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.425937 42792 net.cpp:165] Memory required for data: 3249131520
I0824 18:29:59.425951 42792 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 18:29:59.425963 42792 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 18:29:59.425971 42792 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 18:29:59.425981 42792 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 18:29:59.426048 42792 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 18:29:59.426216 42792 net.cpp:150] Setting up conv5_1_D_scale
I0824 18:29:59.426228 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.426232 42792 net.cpp:165] Memory required for data: 3254784000
I0824 18:29:59.426244 42792 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 18:29:59.426252 42792 net.cpp:100] Creating Layer relu5_1_D
I0824 18:29:59.426260 42792 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 18:29:59.426271 42792 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 18:29:59.426499 42792 net.cpp:150] Setting up relu5_1_D
I0824 18:29:59.426512 42792 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 18:29:59.426517 42792 net.cpp:165] Memory required for data: 3260436480
I0824 18:29:59.426522 42792 layer_factory.hpp:77] Creating layer upsample4
I0824 18:29:59.426533 42792 net.cpp:100] Creating Layer upsample4
I0824 18:29:59.426540 42792 net.cpp:434] upsample4 <- conv5_1_D
I0824 18:29:59.426548 42792 net.cpp:434] upsample4 <- pool4_mask
I0824 18:29:59.426563 42792 net.cpp:408] upsample4 -> pool4_D
I0824 18:29:59.426606 42792 net.cpp:150] Setting up upsample4
I0824 18:29:59.426616 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:59.426621 42792 net.cpp:165] Memory required for data: 3282554880
I0824 18:29:59.426627 42792 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 18:29:59.426653 42792 net.cpp:100] Creating Layer conv4_3_D
I0824 18:29:59.426661 42792 net.cpp:434] conv4_3_D <- pool4_D
I0824 18:29:59.426671 42792 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 18:29:59.510815 42792 net.cpp:150] Setting up conv4_3_D
I0824 18:29:59.510836 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:59.510843 42792 net.cpp:165] Memory required for data: 3304673280
I0824 18:29:59.510854 42792 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 18:29:59.510882 42792 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 18:29:59.510891 42792 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 18:29:59.510903 42792 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 18:29:59.511201 42792 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 18:29:59.511212 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:59.511219 42792 net.cpp:165] Memory required for data: 3326791680
I0824 18:29:59.511231 42792 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 18:29:59.511248 42792 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 18:29:59.511258 42792 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 18:29:59.511267 42792 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 18:29:59.511327 42792 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 18:29:59.511508 42792 net.cpp:150] Setting up conv4_3_D_scale
I0824 18:29:59.511519 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:59.511524 42792 net.cpp:165] Memory required for data: 3348910080
I0824 18:29:59.511535 42792 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 18:29:59.511569 42792 net.cpp:100] Creating Layer relu4_3_D
I0824 18:29:59.511576 42792 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 18:29:59.511584 42792 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 18:29:59.511814 42792 net.cpp:150] Setting up relu4_3_D
I0824 18:29:59.511826 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:59.511832 42792 net.cpp:165] Memory required for data: 3371028480
I0824 18:29:59.511838 42792 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 18:29:59.511857 42792 net.cpp:100] Creating Layer conv4_2_D
I0824 18:29:59.511863 42792 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 18:29:59.511878 42792 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 18:29:59.595948 42792 net.cpp:150] Setting up conv4_2_D
I0824 18:29:59.595970 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:59.595978 42792 net.cpp:165] Memory required for data: 3393146880
I0824 18:29:59.595989 42792 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 18:29:59.596012 42792 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 18:29:59.596024 42792 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 18:29:59.596034 42792 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 18:29:59.596349 42792 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 18:29:59.596359 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:59.596364 42792 net.cpp:165] Memory required for data: 3415265280
I0824 18:29:59.596379 42792 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 18:29:59.596397 42792 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 18:29:59.596405 42792 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 18:29:59.596415 42792 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 18:29:59.596477 42792 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 18:29:59.596660 42792 net.cpp:150] Setting up conv4_2_D_scale
I0824 18:29:59.596670 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:59.596676 42792 net.cpp:165] Memory required for data: 3437383680
I0824 18:29:59.596686 42792 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 18:29:59.596696 42792 net.cpp:100] Creating Layer relu4_2_D
I0824 18:29:59.596704 42792 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 18:29:59.596715 42792 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 18:29:59.596941 42792 net.cpp:150] Setting up relu4_2_D
I0824 18:29:59.596952 42792 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 18:29:59.596958 42792 net.cpp:165] Memory required for data: 3459502080
I0824 18:29:59.596964 42792 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 18:29:59.596984 42792 net.cpp:100] Creating Layer conv4_1_D
I0824 18:29:59.596992 42792 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 18:29:59.597002 42792 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 18:29:59.641240 42792 net.cpp:150] Setting up conv4_1_D
I0824 18:29:59.641260 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:59.641266 42792 net.cpp:165] Memory required for data: 3470561280
I0824 18:29:59.641279 42792 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 18:29:59.641305 42792 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 18:29:59.641316 42792 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 18:29:59.641337 42792 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 18:29:59.641675 42792 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 18:29:59.641688 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:59.641693 42792 net.cpp:165] Memory required for data: 3481620480
I0824 18:29:59.641757 42792 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 18:29:59.641770 42792 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 18:29:59.641778 42792 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 18:29:59.641790 42792 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 18:29:59.641855 42792 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 18:29:59.642040 42792 net.cpp:150] Setting up conv4_1_D_scale
I0824 18:29:59.642051 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:59.642073 42792 net.cpp:165] Memory required for data: 3492679680
I0824 18:29:59.642086 42792 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 18:29:59.642094 42792 net.cpp:100] Creating Layer relu4_1_D
I0824 18:29:59.642102 42792 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 18:29:59.642110 42792 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 18:29:59.642354 42792 net.cpp:150] Setting up relu4_1_D
I0824 18:29:59.642369 42792 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 18:29:59.642377 42792 net.cpp:165] Memory required for data: 3503738880
I0824 18:29:59.642383 42792 layer_factory.hpp:77] Creating layer upsample3
I0824 18:29:59.642395 42792 net.cpp:100] Creating Layer upsample3
I0824 18:29:59.642402 42792 net.cpp:434] upsample3 <- conv4_1_D
I0824 18:29:59.642410 42792 net.cpp:434] upsample3 <- pool3_mask
I0824 18:29:59.642421 42792 net.cpp:408] upsample3 -> pool3_D
I0824 18:29:59.642434 42792 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 18:29:59.642479 42792 net.cpp:150] Setting up upsample3
I0824 18:29:59.642488 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:59.642493 42792 net.cpp:165] Memory required for data: 3547975680
I0824 18:29:59.642499 42792 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 18:29:59.642518 42792 net.cpp:100] Creating Layer conv3_3_D
I0824 18:29:59.642524 42792 net.cpp:434] conv3_3_D <- pool3_D
I0824 18:29:59.642539 42792 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 18:29:59.666412 42792 net.cpp:150] Setting up conv3_3_D
I0824 18:29:59.666432 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:59.666440 42792 net.cpp:165] Memory required for data: 3592212480
I0824 18:29:59.666455 42792 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 18:29:59.666479 42792 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 18:29:59.666493 42792 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 18:29:59.666503 42792 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 18:29:59.666828 42792 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 18:29:59.666842 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:59.666858 42792 net.cpp:165] Memory required for data: 3636449280
I0824 18:29:59.666872 42792 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 18:29:59.666885 42792 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 18:29:59.666893 42792 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 18:29:59.666901 42792 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 18:29:59.666975 42792 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 18:29:59.667176 42792 net.cpp:150] Setting up conv3_3_D_scale
I0824 18:29:59.667187 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:59.667192 42792 net.cpp:165] Memory required for data: 3680686080
I0824 18:29:59.667203 42792 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 18:29:59.667217 42792 net.cpp:100] Creating Layer relu3_3_D
I0824 18:29:59.667222 42792 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 18:29:59.667230 42792 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 18:29:59.668409 42792 net.cpp:150] Setting up relu3_3_D
I0824 18:29:59.668429 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:59.668436 42792 net.cpp:165] Memory required for data: 3724922880
I0824 18:29:59.668442 42792 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 18:29:59.668459 42792 net.cpp:100] Creating Layer conv3_2_D
I0824 18:29:59.668467 42792 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 18:29:59.668478 42792 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 18:29:59.691395 42792 net.cpp:150] Setting up conv3_2_D
I0824 18:29:59.691414 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:59.691421 42792 net.cpp:165] Memory required for data: 3769159680
I0824 18:29:59.691433 42792 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 18:29:59.691457 42792 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 18:29:59.691470 42792 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 18:29:59.691501 42792 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 18:29:59.691817 42792 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 18:29:59.691829 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:59.691834 42792 net.cpp:165] Memory required for data: 3813396480
I0824 18:29:59.691848 42792 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 18:29:59.691864 42792 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 18:29:59.691871 42792 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 18:29:59.691879 42792 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 18:29:59.691946 42792 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 18:29:59.692147 42792 net.cpp:150] Setting up conv3_2_D_scale
I0824 18:29:59.692158 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:59.692163 42792 net.cpp:165] Memory required for data: 3857633280
I0824 18:29:59.692174 42792 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 18:29:59.692184 42792 net.cpp:100] Creating Layer relu3_2_D
I0824 18:29:59.692191 42792 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 18:29:59.692199 42792 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 18:29:59.693387 42792 net.cpp:150] Setting up relu3_2_D
I0824 18:29:59.693404 42792 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 18:29:59.693410 42792 net.cpp:165] Memory required for data: 3901870080
I0824 18:29:59.693418 42792 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 18:29:59.693437 42792 net.cpp:100] Creating Layer conv3_1_D
I0824 18:29:59.693444 42792 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 18:29:59.693456 42792 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 18:29:59.707527 42792 net.cpp:150] Setting up conv3_1_D
I0824 18:29:59.707546 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:59.707552 42792 net.cpp:165] Memory required for data: 3923988480
I0824 18:29:59.707566 42792 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 18:29:59.707590 42792 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 18:29:59.707602 42792 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 18:29:59.707620 42792 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 18:29:59.707948 42792 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 18:29:59.707959 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:59.707965 42792 net.cpp:165] Memory required for data: 3946106880
I0824 18:29:59.707979 42792 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 18:29:59.707995 42792 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 18:29:59.708003 42792 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 18:29:59.708011 42792 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 18:29:59.708076 42792 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 18:29:59.709672 42792 net.cpp:150] Setting up conv3_1_D_scale
I0824 18:29:59.709691 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:59.709697 42792 net.cpp:165] Memory required for data: 3968225280
I0824 18:29:59.709708 42792 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 18:29:59.709722 42792 net.cpp:100] Creating Layer relu3_1_D
I0824 18:29:59.709733 42792 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 18:29:59.709743 42792 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 18:29:59.709991 42792 net.cpp:150] Setting up relu3_1_D
I0824 18:29:59.710003 42792 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 18:29:59.710009 42792 net.cpp:165] Memory required for data: 3990343680
I0824 18:29:59.710016 42792 layer_factory.hpp:77] Creating layer upsample2
I0824 18:29:59.710028 42792 net.cpp:100] Creating Layer upsample2
I0824 18:29:59.710034 42792 net.cpp:434] upsample2 <- conv3_1_D
I0824 18:29:59.710043 42792 net.cpp:434] upsample2 <- pool2_mask
I0824 18:29:59.710053 42792 net.cpp:408] upsample2 -> pool2_D
I0824 18:29:59.710067 42792 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 18:29:59.710116 42792 net.cpp:150] Setting up upsample2
I0824 18:29:59.710139 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:59.710147 42792 net.cpp:165] Memory required for data: 4078817280
I0824 18:29:59.710152 42792 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 18:29:59.710168 42792 net.cpp:100] Creating Layer conv2_2_D
I0824 18:29:59.710175 42792 net.cpp:434] conv2_2_D <- pool2_D
I0824 18:29:59.710188 42792 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 18:29:59.718150 42792 net.cpp:150] Setting up conv2_2_D
I0824 18:29:59.718170 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:59.718176 42792 net.cpp:165] Memory required for data: 4167290880
I0824 18:29:59.718189 42792 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 18:29:59.718215 42792 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 18:29:59.718228 42792 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 18:29:59.718250 42792 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 18:29:59.718605 42792 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 18:29:59.718616 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:59.718621 42792 net.cpp:165] Memory required for data: 4255764480
I0824 18:29:59.718634 42792 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 18:29:59.718648 42792 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 18:29:59.718657 42792 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 18:29:59.718664 42792 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 18:29:59.718731 42792 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 18:29:59.719004 42792 net.cpp:150] Setting up conv2_2_D_scale
I0824 18:29:59.719015 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:59.719022 42792 net.cpp:165] Memory required for data: 4344238080
I0824 18:29:59.719032 42792 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 18:29:59.719041 42792 net.cpp:100] Creating Layer relu2_2_D
I0824 18:29:59.719049 42792 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 18:29:59.719061 42792 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 18:29:59.719307 42792 net.cpp:150] Setting up relu2_2_D
I0824 18:29:59.719321 42792 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 18:29:59.719326 42792 net.cpp:165] Memory required for data: 4432711680
I0824 18:29:59.719331 42792 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 18:29:59.719348 42792 net.cpp:100] Creating Layer conv2_1_D
I0824 18:29:59.719354 42792 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 18:29:59.719368 42792 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 18:29:59.724862 42792 net.cpp:150] Setting up conv2_1_D
I0824 18:29:59.724882 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:59.724889 42792 net.cpp:165] Memory required for data: 4476948480
I0824 18:29:59.724900 42792 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 18:29:59.724915 42792 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 18:29:59.724933 42792 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 18:29:59.724946 42792 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 18:29:59.725317 42792 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 18:29:59.725329 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:59.725334 42792 net.cpp:165] Memory required for data: 4521185280
I0824 18:29:59.725350 42792 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 18:29:59.725379 42792 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 18:29:59.725392 42792 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 18:29:59.725401 42792 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 18:29:59.725472 42792 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 18:29:59.725759 42792 net.cpp:150] Setting up conv2_1_D_scale
I0824 18:29:59.725769 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:59.725775 42792 net.cpp:165] Memory required for data: 4565422080
I0824 18:29:59.725785 42792 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 18:29:59.725795 42792 net.cpp:100] Creating Layer relu2_1_D
I0824 18:29:59.725802 42792 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 18:29:59.725828 42792 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 18:29:59.726075 42792 net.cpp:150] Setting up relu2_1_D
I0824 18:29:59.726088 42792 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 18:29:59.726094 42792 net.cpp:165] Memory required for data: 4609658880
I0824 18:29:59.726099 42792 layer_factory.hpp:77] Creating layer upsample1
I0824 18:29:59.726111 42792 net.cpp:100] Creating Layer upsample1
I0824 18:29:59.726119 42792 net.cpp:434] upsample1 <- conv2_1_D
I0824 18:29:59.726126 42792 net.cpp:434] upsample1 <- pool1_mask
I0824 18:29:59.726135 42792 net.cpp:408] upsample1 -> pool1_D
I0824 18:29:59.726148 42792 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 18:29:59.726193 42792 net.cpp:150] Setting up upsample1
I0824 18:29:59.726202 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:59.726207 42792 net.cpp:165] Memory required for data: 4786606080
I0824 18:29:59.726213 42792 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 18:29:59.726231 42792 net.cpp:100] Creating Layer conv1_2_D
I0824 18:29:59.726238 42792 net.cpp:434] conv1_2_D <- pool1_D
I0824 18:29:59.726248 42792 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 18:29:59.731084 42792 net.cpp:150] Setting up conv1_2_D
I0824 18:29:59.731104 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:59.731111 42792 net.cpp:165] Memory required for data: 4963553280
I0824 18:29:59.731122 42792 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 18:29:59.731158 42792 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 18:29:59.731168 42792 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 18:29:59.731176 42792 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 18:29:59.731632 42792 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 18:29:59.731644 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:59.731650 42792 net.cpp:165] Memory required for data: 5140500480
I0824 18:29:59.731663 42792 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 18:29:59.731676 42792 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 18:29:59.731683 42792 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 18:29:59.731691 42792 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 18:29:59.731760 42792 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 18:29:59.733620 42792 net.cpp:150] Setting up conv1_2_D_scale
I0824 18:29:59.733639 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:59.733644 42792 net.cpp:165] Memory required for data: 5317447680
I0824 18:29:59.733656 42792 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 18:29:59.733671 42792 net.cpp:100] Creating Layer relu1_2_D
I0824 18:29:59.733678 42792 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 18:29:59.733687 42792 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 18:29:59.733937 42792 net.cpp:150] Setting up relu1_2_D
I0824 18:29:59.733949 42792 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 18:29:59.733955 42792 net.cpp:165] Memory required for data: 5494394880
I0824 18:29:59.733961 42792 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 18:29:59.733978 42792 net.cpp:100] Creating Layer conv1_1_1_D
I0824 18:29:59.733984 42792 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 18:29:59.733997 42792 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 18:29:59.736227 42792 net.cpp:150] Setting up conv1_1_1_D
I0824 18:29:59.736244 42792 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 18:29:59.736250 42792 net.cpp:165] Memory required for data: 5499924480
I0824 18:29:59.736263 42792 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 18:29:59.736277 42792 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 18:29:59.736284 42792 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 18:29:59.736294 42792 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 18:29:59.736306 42792 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 18:29:59.736390 42792 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 18:29:59.736400 42792 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 18:29:59.736408 42792 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 18:29:59.736414 42792 net.cpp:165] Memory required for data: 5510983680
I0824 18:29:59.736420 42792 layer_factory.hpp:77] Creating layer loss
I0824 18:29:59.736435 42792 net.cpp:100] Creating Layer loss
I0824 18:29:59.736441 42792 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 18:29:59.736449 42792 net.cpp:434] loss <- label_data_1_split_0
I0824 18:29:59.736462 42792 net.cpp:408] loss -> loss
I0824 18:29:59.736477 42792 layer_factory.hpp:77] Creating layer loss
I0824 18:29:59.741190 42792 net.cpp:150] Setting up loss
I0824 18:29:59.741209 42792 net.cpp:157] Top shape: (1)
I0824 18:29:59.741214 42792 net.cpp:160]     with loss weight 1
I0824 18:29:59.741250 42792 net.cpp:165] Memory required for data: 5510983684
I0824 18:29:59.741256 42792 layer_factory.hpp:77] Creating layer accuracy
I0824 18:29:59.741281 42792 net.cpp:100] Creating Layer accuracy
I0824 18:29:59.741291 42792 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 18:29:59.741299 42792 net.cpp:434] accuracy <- label_data_1_split_1
I0824 18:29:59.741309 42792 net.cpp:408] accuracy -> accuracy
I0824 18:29:59.741322 42792 net.cpp:408] accuracy -> per_class_accuracy
I0824 18:29:59.741407 42792 net.cpp:150] Setting up accuracy
I0824 18:29:59.741420 42792 net.cpp:157] Top shape: (1)
I0824 18:29:59.741427 42792 net.cpp:157] Top shape: 2 (2)
I0824 18:29:59.741432 42792 net.cpp:165] Memory required for data: 5510983696
I0824 18:29:59.741438 42792 net.cpp:228] accuracy does not need backward computation.
I0824 18:29:59.741447 42792 net.cpp:226] loss needs backward computation.
I0824 18:29:59.741454 42792 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 18:29:59.741462 42792 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 18:29:59.741468 42792 net.cpp:226] relu1_2_D needs backward computation.
I0824 18:29:59.741474 42792 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 18:29:59.741480 42792 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 18:29:59.741485 42792 net.cpp:226] conv1_2_D needs backward computation.
I0824 18:29:59.741492 42792 net.cpp:226] upsample1 needs backward computation.
I0824 18:29:59.741497 42792 net.cpp:226] relu2_1_D needs backward computation.
I0824 18:29:59.741504 42792 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 18:29:59.741509 42792 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 18:29:59.741514 42792 net.cpp:226] conv2_1_D needs backward computation.
I0824 18:29:59.741519 42792 net.cpp:226] relu2_2_D needs backward computation.
I0824 18:29:59.741524 42792 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 18:29:59.741529 42792 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 18:29:59.741534 42792 net.cpp:226] conv2_2_D needs backward computation.
I0824 18:29:59.741540 42792 net.cpp:226] upsample2 needs backward computation.
I0824 18:29:59.741549 42792 net.cpp:226] relu3_1_D needs backward computation.
I0824 18:29:59.741554 42792 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 18:29:59.741559 42792 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 18:29:59.741564 42792 net.cpp:226] conv3_1_D needs backward computation.
I0824 18:29:59.741569 42792 net.cpp:226] relu3_2_D needs backward computation.
I0824 18:29:59.741575 42792 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 18:29:59.741580 42792 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 18:29:59.741585 42792 net.cpp:226] conv3_2_D needs backward computation.
I0824 18:29:59.741591 42792 net.cpp:226] relu3_3_D needs backward computation.
I0824 18:29:59.741598 42792 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 18:29:59.741603 42792 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 18:29:59.741623 42792 net.cpp:226] conv3_3_D needs backward computation.
I0824 18:29:59.741631 42792 net.cpp:226] upsample3 needs backward computation.
I0824 18:29:59.741636 42792 net.cpp:226] relu4_1_D needs backward computation.
I0824 18:29:59.741641 42792 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 18:29:59.741647 42792 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 18:29:59.741652 42792 net.cpp:226] conv4_1_D needs backward computation.
I0824 18:29:59.741657 42792 net.cpp:226] relu4_2_D needs backward computation.
I0824 18:29:59.741662 42792 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 18:29:59.741669 42792 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 18:29:59.741674 42792 net.cpp:226] conv4_2_D needs backward computation.
I0824 18:29:59.741680 42792 net.cpp:226] relu4_3_D needs backward computation.
I0824 18:29:59.741686 42792 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 18:29:59.741691 42792 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 18:29:59.741698 42792 net.cpp:226] conv4_3_D needs backward computation.
I0824 18:29:59.741704 42792 net.cpp:226] upsample4 needs backward computation.
I0824 18:29:59.741713 42792 net.cpp:226] relu5_1_D needs backward computation.
I0824 18:29:59.741719 42792 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 18:29:59.741724 42792 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 18:29:59.741730 42792 net.cpp:226] conv5_1_D needs backward computation.
I0824 18:29:59.741737 42792 net.cpp:226] relu5_2_D needs backward computation.
I0824 18:29:59.741742 42792 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 18:29:59.741749 42792 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 18:29:59.741755 42792 net.cpp:226] conv5_2_D needs backward computation.
I0824 18:29:59.741761 42792 net.cpp:226] relu5_3_D needs backward computation.
I0824 18:29:59.741766 42792 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 18:29:59.741773 42792 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 18:29:59.741780 42792 net.cpp:226] conv5_3_D needs backward computation.
I0824 18:29:59.741786 42792 net.cpp:226] upsample5 needs backward computation.
I0824 18:29:59.741793 42792 net.cpp:226] pool5 needs backward computation.
I0824 18:29:59.741801 42792 net.cpp:226] relu5_3 needs backward computation.
I0824 18:29:59.741808 42792 net.cpp:226] conv5_3_scale needs backward computation.
I0824 18:29:59.741813 42792 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 18:29:59.741822 42792 net.cpp:226] conv5_3 needs backward computation.
I0824 18:29:59.741827 42792 net.cpp:226] relu5_2 needs backward computation.
I0824 18:29:59.741834 42792 net.cpp:226] conv5_2_scale needs backward computation.
I0824 18:29:59.741839 42792 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 18:29:59.741847 42792 net.cpp:226] conv5_2 needs backward computation.
I0824 18:29:59.741854 42792 net.cpp:226] relu5_1 needs backward computation.
I0824 18:29:59.741861 42792 net.cpp:226] conv5_1_scale needs backward computation.
I0824 18:29:59.741868 42792 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 18:29:59.741874 42792 net.cpp:226] conv5_1 needs backward computation.
I0824 18:29:59.741881 42792 net.cpp:226] pool4 needs backward computation.
I0824 18:29:59.741888 42792 net.cpp:226] relu4_3 needs backward computation.
I0824 18:29:59.741892 42792 net.cpp:226] conv4_3_scale needs backward computation.
I0824 18:29:59.741899 42792 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 18:29:59.741904 42792 net.cpp:226] conv4_3 needs backward computation.
I0824 18:29:59.741914 42792 net.cpp:226] relu4_2 needs backward computation.
I0824 18:29:59.741921 42792 net.cpp:226] conv4_2_scale needs backward computation.
I0824 18:29:59.741926 42792 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 18:29:59.741931 42792 net.cpp:226] conv4_2 needs backward computation.
I0824 18:29:59.741940 42792 net.cpp:226] relu4_1 needs backward computation.
I0824 18:29:59.741955 42792 net.cpp:226] conv4_1_scale needs backward computation.
I0824 18:29:59.741961 42792 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 18:29:59.741969 42792 net.cpp:226] conv4_1 needs backward computation.
I0824 18:29:59.741974 42792 net.cpp:226] pool3 needs backward computation.
I0824 18:29:59.741981 42792 net.cpp:226] relu3_3 needs backward computation.
I0824 18:29:59.741987 42792 net.cpp:226] conv3_3_scale needs backward computation.
I0824 18:29:59.741992 42792 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 18:29:59.741999 42792 net.cpp:226] conv3_3 needs backward computation.
I0824 18:29:59.742007 42792 net.cpp:226] relu3_2 needs backward computation.
I0824 18:29:59.742012 42792 net.cpp:226] conv3_2_scale needs backward computation.
I0824 18:29:59.742019 42792 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 18:29:59.742027 42792 net.cpp:226] conv3_2 needs backward computation.
I0824 18:29:59.742034 42792 net.cpp:226] relu3_1 needs backward computation.
I0824 18:29:59.742041 42792 net.cpp:226] conv3_1_scale needs backward computation.
I0824 18:29:59.742046 42792 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 18:29:59.742054 42792 net.cpp:226] conv3_1 needs backward computation.
I0824 18:29:59.742063 42792 net.cpp:226] pool2 needs backward computation.
I0824 18:29:59.742069 42792 net.cpp:226] relu2_2 needs backward computation.
I0824 18:29:59.742075 42792 net.cpp:226] conv2_2_scale needs backward computation.
I0824 18:29:59.742080 42792 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 18:29:59.742087 42792 net.cpp:226] conv2_2 needs backward computation.
I0824 18:29:59.742094 42792 net.cpp:226] relu2_1 needs backward computation.
I0824 18:29:59.742100 42792 net.cpp:226] conv2_1_scale needs backward computation.
I0824 18:29:59.742106 42792 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 18:29:59.742112 42792 net.cpp:226] conv2_1 needs backward computation.
I0824 18:29:59.742117 42792 net.cpp:226] pool1 needs backward computation.
I0824 18:29:59.742125 42792 net.cpp:226] relu1_2 needs backward computation.
I0824 18:29:59.742130 42792 net.cpp:226] conv1_2_scale needs backward computation.
I0824 18:29:59.742137 42792 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 18:29:59.742144 42792 net.cpp:226] conv1_2 needs backward computation.
I0824 18:29:59.742149 42792 net.cpp:226] relu1_1 needs backward computation.
I0824 18:29:59.742156 42792 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 18:29:59.742161 42792 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 18:29:59.742167 42792 net.cpp:226] conv1_1_1 needs backward computation.
I0824 18:29:59.742174 42792 net.cpp:228] label_data_1_split does not need backward computation.
I0824 18:29:59.742182 42792 net.cpp:228] data does not need backward computation.
I0824 18:29:59.742187 42792 net.cpp:270] This network produces output accuracy
I0824 18:29:59.742194 42792 net.cpp:270] This network produces output loss
I0824 18:29:59.742202 42792 net.cpp:270] This network produces output per_class_accuracy
I0824 18:29:59.742272 42792 net.cpp:283] Network initialization done.
I0824 18:29:59.742642 42792 solver.cpp:60] Solver scaffolding done.
I0824 18:29:59.752079 42792 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0824 18:30:00.209825 42792 net.cpp:761] Ignoring source layer conv1_1
I0824 18:30:00.209856 42792 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 18:30:00.209924 42792 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 18:30:00.209933 42792 net.cpp:761] Ignoring source layer pool1_drop
I0824 18:30:00.210021 42792 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 18:30:00.210186 42792 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 18:30:00.210194 42792 net.cpp:761] Ignoring source layer pool2_drop
I0824 18:30:00.210502 42792 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 18:30:00.211102 42792 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 18:30:00.211691 42792 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 18:30:00.211722 42792 net.cpp:761] Ignoring source layer pool3_drop
I0824 18:30:00.212847 42792 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 18:30:00.215092 42792 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 18:30:00.217281 42792 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 18:30:00.217290 42792 net.cpp:761] Ignoring source layer pool4_drop
I0824 18:30:00.219544 42792 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 18:30:00.221627 42792 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 18:30:00.223718 42792 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 18:30:00.223727 42792 net.cpp:761] Ignoring source layer pool5_drop
I0824 18:30:00.223737 42792 net.cpp:761] Ignoring source layer upsample5_drop
I0824 18:30:00.225986 42792 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 18:30:00.228092 42792 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 18:30:00.230156 42792 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 18:30:00.230167 42792 net.cpp:761] Ignoring source layer upsample4_drop
I0824 18:30:00.232221 42792 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 18:30:00.234284 42792 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 18:30:00.235359 42792 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 18:30:00.235368 42792 net.cpp:761] Ignoring source layer upsample3_drop
I0824 18:30:00.235954 42792 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 18:30:00.236498 42792 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 18:30:00.236801 42792 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 18:30:00.236811 42792 net.cpp:761] Ignoring source layer upsample2_drop
I0824 18:30:00.236976 42792 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 18:30:00.237064 42792 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 18:30:00.237072 42792 net.cpp:761] Ignoring source layer upsample1_drop
I0824 18:30:00.237124 42792 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 18:30:00.237133 42792 net.cpp:761] Ignoring source layer conv1_1_D
I0824 18:30:00.237138 42792 net.cpp:761] Ignoring source layer prob
I0824 18:30:00.919559 42792 net.cpp:761] Ignoring source layer conv1_1
I0824 18:30:00.919589 42792 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 18:30:00.919646 42792 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 18:30:00.919658 42792 net.cpp:761] Ignoring source layer pool1_drop
I0824 18:30:00.919741 42792 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 18:30:00.919893 42792 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 18:30:00.919900 42792 net.cpp:761] Ignoring source layer pool2_drop
I0824 18:30:00.920189 42792 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 18:30:00.920768 42792 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 18:30:00.921401 42792 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 18:30:00.921409 42792 net.cpp:761] Ignoring source layer pool3_drop
I0824 18:30:00.922526 42792 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 18:30:00.924641 42792 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 18:30:00.926869 42792 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 18:30:00.926880 42792 net.cpp:761] Ignoring source layer pool4_drop
I0824 18:30:00.928998 42792 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 18:30:00.931154 42792 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 18:30:00.933269 42792 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 18:30:00.933279 42792 net.cpp:761] Ignoring source layer pool5_drop
I0824 18:30:00.933285 42792 net.cpp:761] Ignoring source layer upsample5_drop
I0824 18:30:00.935415 42792 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 18:30:00.937716 42792 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 18:30:00.940125 42792 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 18:30:00.940135 42792 net.cpp:761] Ignoring source layer upsample4_drop
I0824 18:30:00.942425 42792 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 18:30:00.944784 42792 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 18:30:00.945907 42792 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 18:30:00.945919 42792 net.cpp:761] Ignoring source layer upsample3_drop
I0824 18:30:00.946461 42792 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 18:30:00.947013 42792 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 18:30:00.947291 42792 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 18:30:00.947300 42792 net.cpp:761] Ignoring source layer upsample2_drop
I0824 18:30:00.947448 42792 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 18:30:00.947535 42792 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 18:30:00.947542 42792 net.cpp:761] Ignoring source layer upsample1_drop
I0824 18:30:00.947590 42792 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 18:30:00.947598 42792 net.cpp:761] Ignoring source layer conv1_1_D
I0824 18:30:00.947603 42792 net.cpp:761] Ignoring source layer prob
I0824 18:30:00.957254 42792 caffe.cpp:251] Starting Optimization
I0824 18:30:00.957283 42792 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0824 18:30:00.957295 42792 solver.cpp:280] Learning Rate Policy: step
I0824 18:30:02.161728 42792 solver.cpp:228] Iteration 0, loss = 0.841395
I0824 18:30:02.161774 42792 solver.cpp:244]     Train net output #0: accuracy = 0.74263
I0824 18:30:02.161790 42792 solver.cpp:244]     Train net output #1: loss = 0.841395 (* 1 = 0.841395 loss)
I0824 18:30:02.161798 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.927365
I0824 18:30:02.161806 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.0609844
I0824 18:30:02.161835 42792 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0824 18:30:21.565110 42792 solver.cpp:228] Iteration 20, loss = 0.594729
I0824 18:30:21.565160 42792 solver.cpp:244]     Train net output #0: accuracy = 0.609887
I0824 18:30:21.565176 42792 solver.cpp:244]     Train net output #1: loss = 0.594729 (* 1 = 0.594729 loss)
I0824 18:30:21.565186 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.513932
I0824 18:30:21.565193 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.920983
I0824 18:30:21.565203 42792 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0824 18:30:38.203353 42792 solver.cpp:228] Iteration 40, loss = 0.500946
I0824 18:30:38.203495 42792 solver.cpp:244]     Train net output #0: accuracy = 0.721421
I0824 18:30:38.203514 42792 solver.cpp:244]     Train net output #1: loss = 0.500946 (* 1 = 0.500946 loss)
I0824 18:30:38.203523 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.714665
I0824 18:30:38.203531 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.750292
I0824 18:30:38.203541 42792 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0824 18:30:54.857144 42792 solver.cpp:228] Iteration 60, loss = 0.37156
I0824 18:30:54.857188 42792 solver.cpp:244]     Train net output #0: accuracy = 0.83031
I0824 18:30:54.857204 42792 solver.cpp:244]     Train net output #1: loss = 0.37156 (* 1 = 0.37156 loss)
I0824 18:30:54.857213 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.817596
I0824 18:30:54.857219 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.873354
I0824 18:30:54.857230 42792 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0824 18:31:11.508267 42792 solver.cpp:228] Iteration 80, loss = 0.321433
I0824 18:31:11.508399 42792 solver.cpp:244]     Train net output #0: accuracy = 0.892004
I0824 18:31:11.508419 42792 solver.cpp:244]     Train net output #1: loss = 0.321433 (* 1 = 0.321433 loss)
I0824 18:31:11.508436 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.913703
I0824 18:31:11.508452 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.862668
I0824 18:31:11.508471 42792 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0824 18:31:28.158190 42792 solver.cpp:228] Iteration 100, loss = 0.221119
I0824 18:31:28.158236 42792 solver.cpp:244]     Train net output #0: accuracy = 0.916665
I0824 18:31:28.158252 42792 solver.cpp:244]     Train net output #1: loss = 0.221119 (* 1 = 0.221119 loss)
I0824 18:31:28.158262 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.906183
I0824 18:31:28.158268 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.943514
I0824 18:31:28.158278 42792 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0824 18:31:44.812819 42792 solver.cpp:228] Iteration 120, loss = 0.399488
I0824 18:31:44.812997 42792 solver.cpp:244]     Train net output #0: accuracy = 0.786813
I0824 18:31:44.813019 42792 solver.cpp:244]     Train net output #1: loss = 0.399488 (* 1 = 0.399488 loss)
I0824 18:31:44.813037 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.758198
I0824 18:31:44.813053 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.916818
I0824 18:31:44.813073 42792 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0824 18:32:01.460924 42792 solver.cpp:228] Iteration 140, loss = 0.178127
I0824 18:32:01.460966 42792 solver.cpp:244]     Train net output #0: accuracy = 0.932367
I0824 18:32:01.460983 42792 solver.cpp:244]     Train net output #1: loss = 0.178127 (* 1 = 0.178127 loss)
I0824 18:32:01.460992 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.933822
I0824 18:32:01.460999 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.928607
I0824 18:32:01.461009 42792 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0824 18:32:18.098381 42792 solver.cpp:228] Iteration 160, loss = 0.11701
I0824 18:32:18.098500 42792 solver.cpp:244]     Train net output #0: accuracy = 0.957334
I0824 18:32:18.098522 42792 solver.cpp:244]     Train net output #1: loss = 0.11701 (* 1 = 0.11701 loss)
I0824 18:32:18.098546 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.954743
I0824 18:32:18.098563 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.963988
I0824 18:32:18.098582 42792 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0824 18:32:34.736487 42792 solver.cpp:228] Iteration 180, loss = 0.139488
I0824 18:32:34.736526 42792 solver.cpp:244]     Train net output #0: accuracy = 0.950111
I0824 18:32:34.736541 42792 solver.cpp:244]     Train net output #1: loss = 0.139488 (* 1 = 0.139488 loss)
I0824 18:32:34.736551 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.950532
I0824 18:32:34.736557 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.948851
I0824 18:32:34.736567 42792 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0824 18:32:51.391057 42792 solver.cpp:228] Iteration 200, loss = 0.139781
I0824 18:32:51.391182 42792 solver.cpp:244]     Train net output #0: accuracy = 0.954447
I0824 18:32:51.391201 42792 solver.cpp:244]     Train net output #1: loss = 0.139781 (* 1 = 0.139781 loss)
I0824 18:32:51.391209 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.956349
I0824 18:32:51.391232 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.950292
I0824 18:32:51.391243 42792 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0824 18:33:08.055461 42792 solver.cpp:228] Iteration 220, loss = 0.204539
I0824 18:33:08.055510 42792 solver.cpp:244]     Train net output #0: accuracy = 0.891586
I0824 18:33:08.055526 42792 solver.cpp:244]     Train net output #1: loss = 0.204539 (* 1 = 0.204539 loss)
I0824 18:33:08.055532 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.865066
I0824 18:33:08.055538 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.955177
I0824 18:33:08.055546 42792 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0824 18:33:24.725178 42792 solver.cpp:228] Iteration 240, loss = 0.205649
I0824 18:33:24.725320 42792 solver.cpp:244]     Train net output #0: accuracy = 0.94931
I0824 18:33:24.725347 42792 solver.cpp:244]     Train net output #1: loss = 0.205649 (* 1 = 0.205649 loss)
I0824 18:33:24.725355 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981786
I0824 18:33:24.725361 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.91295
I0824 18:33:24.725376 42792 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0824 18:33:41.384747 42792 solver.cpp:228] Iteration 260, loss = 0.0956675
I0824 18:33:41.384798 42792 solver.cpp:244]     Train net output #0: accuracy = 0.968766
I0824 18:33:41.384812 42792 solver.cpp:244]     Train net output #1: loss = 0.0956675 (* 1 = 0.0956675 loss)
I0824 18:33:41.384819 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9641
I0824 18:33:41.384824 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980669
I0824 18:33:41.384831 42792 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0824 18:33:58.056442 42792 solver.cpp:228] Iteration 280, loss = 0.118881
I0824 18:33:58.056617 42792 solver.cpp:244]     Train net output #0: accuracy = 0.959083
I0824 18:33:58.056634 42792 solver.cpp:244]     Train net output #1: loss = 0.118881 (* 1 = 0.118881 loss)
I0824 18:33:58.056645 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.95961
I0824 18:33:58.056658 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.957789
I0824 18:33:58.056666 42792 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0824 18:34:14.708463 42792 solver.cpp:228] Iteration 300, loss = 0.111461
I0824 18:34:14.708508 42792 solver.cpp:244]     Train net output #0: accuracy = 0.96308
I0824 18:34:14.708523 42792 solver.cpp:244]     Train net output #1: loss = 0.111461 (* 1 = 0.111461 loss)
I0824 18:34:14.708529 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.967048
I0824 18:34:14.708534 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.954496
I0824 18:34:14.708541 42792 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0824 18:34:31.365885 42792 solver.cpp:228] Iteration 320, loss = 0.0924103
I0824 18:34:31.366004 42792 solver.cpp:244]     Train net output #0: accuracy = 0.965723
I0824 18:34:31.366020 42792 solver.cpp:244]     Train net output #1: loss = 0.0924103 (* 1 = 0.0924103 loss)
I0824 18:34:31.366029 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.95833
I0824 18:34:31.366035 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98472
I0824 18:34:31.366042 42792 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0824 18:34:48.021601 42792 solver.cpp:228] Iteration 340, loss = 0.149902
I0824 18:34:48.021646 42792 solver.cpp:244]     Train net output #0: accuracy = 0.954359
I0824 18:34:48.021659 42792 solver.cpp:244]     Train net output #1: loss = 0.149902 (* 1 = 0.149902 loss)
I0824 18:34:48.021666 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973444
I0824 18:34:48.021670 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.926846
I0824 18:34:48.021678 42792 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0824 18:35:04.700356 42792 solver.cpp:228] Iteration 360, loss = 0.103077
I0824 18:35:04.700496 42792 solver.cpp:244]     Train net output #0: accuracy = 0.960775
I0824 18:35:04.700513 42792 solver.cpp:244]     Train net output #1: loss = 0.103077 (* 1 = 0.103077 loss)
I0824 18:35:04.700526 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.960493
I0824 18:35:04.700531 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.961503
I0824 18:35:04.700538 42792 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0824 18:35:21.361709 42792 solver.cpp:228] Iteration 380, loss = 0.0624036
I0824 18:35:21.361754 42792 solver.cpp:244]     Train net output #0: accuracy = 0.975842
I0824 18:35:21.361768 42792 solver.cpp:244]     Train net output #1: loss = 0.0624036 (* 1 = 0.0624036 loss)
I0824 18:35:21.361774 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975606
I0824 18:35:21.361779 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976452
I0824 18:35:21.361788 42792 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0824 18:35:38.040099 42792 solver.cpp:228] Iteration 400, loss = 0.139207
I0824 18:35:38.040223 42792 solver.cpp:244]     Train net output #0: accuracy = 0.964387
I0824 18:35:38.040241 42792 solver.cpp:244]     Train net output #1: loss = 0.139207 (* 1 = 0.139207 loss)
I0824 18:35:38.040251 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977498
I0824 18:35:38.040256 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.95035
I0824 18:35:38.040264 42792 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0824 18:35:54.707484 42792 solver.cpp:228] Iteration 420, loss = 0.0769469
I0824 18:35:54.707530 42792 solver.cpp:244]     Train net output #0: accuracy = 0.962571
I0824 18:35:54.707542 42792 solver.cpp:244]     Train net output #1: loss = 0.076947 (* 1 = 0.076947 loss)
I0824 18:35:54.707548 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.957133
I0824 18:35:54.707554 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979026
I0824 18:35:54.707562 42792 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0824 18:36:11.366721 42792 solver.cpp:228] Iteration 440, loss = 0.0697079
I0824 18:36:11.366869 42792 solver.cpp:244]     Train net output #0: accuracy = 0.971897
I0824 18:36:11.366885 42792 solver.cpp:244]     Train net output #1: loss = 0.0697079 (* 1 = 0.0697079 loss)
I0824 18:36:11.366899 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969766
I0824 18:36:11.366904 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979317
I0824 18:36:11.366912 42792 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0824 18:36:28.035131 42792 solver.cpp:228] Iteration 460, loss = 0.1004
I0824 18:36:28.035178 42792 solver.cpp:244]     Train net output #0: accuracy = 0.966188
I0824 18:36:28.035193 42792 solver.cpp:244]     Train net output #1: loss = 0.1004 (* 1 = 0.1004 loss)
I0824 18:36:28.035200 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.967776
I0824 18:36:28.035205 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.964312
I0824 18:36:28.035213 42792 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0824 18:36:44.701272 42792 solver.cpp:228] Iteration 480, loss = 0.0640012
I0824 18:36:44.701387 42792 solver.cpp:244]     Train net output #0: accuracy = 0.974104
I0824 18:36:44.701403 42792 solver.cpp:244]     Train net output #1: loss = 0.0640013 (* 1 = 0.0640013 loss)
I0824 18:36:44.701417 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9713
I0824 18:36:44.701422 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988268
I0824 18:36:44.701431 42792 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0824 18:37:01.369345 42792 solver.cpp:228] Iteration 500, loss = 0.0598262
I0824 18:37:01.369400 42792 solver.cpp:244]     Train net output #0: accuracy = 0.975168
I0824 18:37:01.369413 42792 solver.cpp:244]     Train net output #1: loss = 0.0598263 (* 1 = 0.0598263 loss)
I0824 18:37:01.369419 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972668
I0824 18:37:01.369426 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982152
I0824 18:37:01.369432 42792 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0824 18:37:18.050318 42792 solver.cpp:228] Iteration 520, loss = 0.105637
I0824 18:37:18.050427 42792 solver.cpp:244]     Train net output #0: accuracy = 0.94809
I0824 18:37:18.050442 42792 solver.cpp:244]     Train net output #1: loss = 0.105637 (* 1 = 0.105637 loss)
I0824 18:37:18.050458 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.936794
I0824 18:37:18.050469 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989803
I0824 18:37:18.050477 42792 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0824 18:37:34.685084 42792 solver.cpp:228] Iteration 540, loss = 0.0679205
I0824 18:37:34.685132 42792 solver.cpp:244]     Train net output #0: accuracy = 0.968964
I0824 18:37:34.685148 42792 solver.cpp:244]     Train net output #1: loss = 0.0679206 (* 1 = 0.0679206 loss)
I0824 18:37:34.685153 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.957803
I0824 18:37:34.685159 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991309
I0824 18:37:34.685168 42792 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0824 18:37:51.354977 42792 solver.cpp:228] Iteration 560, loss = 0.0696352
I0824 18:37:51.355134 42792 solver.cpp:244]     Train net output #0: accuracy = 0.976117
I0824 18:37:51.355150 42792 solver.cpp:244]     Train net output #1: loss = 0.0696352 (* 1 = 0.0696352 loss)
I0824 18:37:51.355157 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.968204
I0824 18:37:51.355164 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986631
I0824 18:37:51.355170 42792 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0824 18:38:08.015324 42792 solver.cpp:228] Iteration 580, loss = 0.0383684
I0824 18:38:08.015372 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987221
I0824 18:38:08.015386 42792 solver.cpp:244]     Train net output #1: loss = 0.0383684 (* 1 = 0.0383684 loss)
I0824 18:38:08.015393 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987489
I0824 18:38:08.015399 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986706
I0824 18:38:08.015408 42792 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0824 18:38:24.683826 42792 solver.cpp:228] Iteration 600, loss = 0.0483099
I0824 18:38:24.683950 42792 solver.cpp:244]     Train net output #0: accuracy = 0.97922
I0824 18:38:24.683966 42792 solver.cpp:244]     Train net output #1: loss = 0.04831 (* 1 = 0.04831 loss)
I0824 18:38:24.683972 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975437
I0824 18:38:24.683979 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992778
I0824 18:38:24.683985 42792 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0824 18:38:41.358178 42792 solver.cpp:228] Iteration 620, loss = 0.0588732
I0824 18:38:41.358223 42792 solver.cpp:244]     Train net output #0: accuracy = 0.976641
I0824 18:38:41.358237 42792 solver.cpp:244]     Train net output #1: loss = 0.0588733 (* 1 = 0.0588733 loss)
I0824 18:38:41.358242 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.971773
I0824 18:38:41.358247 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98392
I0824 18:38:41.358256 42792 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0824 18:38:58.035776 42792 solver.cpp:228] Iteration 640, loss = 0.0532171
I0824 18:38:58.035887 42792 solver.cpp:244]     Train net output #0: accuracy = 0.975161
I0824 18:38:58.035904 42792 solver.cpp:244]     Train net output #1: loss = 0.0532172 (* 1 = 0.0532172 loss)
I0824 18:38:58.035917 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.96441
I0824 18:38:58.035928 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996266
I0824 18:38:58.035935 42792 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0824 18:39:14.735873 42792 solver.cpp:228] Iteration 660, loss = 0.0426615
I0824 18:39:14.735914 42792 solver.cpp:244]     Train net output #0: accuracy = 0.979935
I0824 18:39:14.735926 42792 solver.cpp:244]     Train net output #1: loss = 0.0426616 (* 1 = 0.0426616 loss)
I0824 18:39:14.735932 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974648
I0824 18:39:14.735939 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996287
I0824 18:39:14.735946 42792 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0824 18:39:31.383091 42792 solver.cpp:228] Iteration 680, loss = 0.0497417
I0824 18:39:31.383219 42792 solver.cpp:244]     Train net output #0: accuracy = 0.98014
I0824 18:39:31.383235 42792 solver.cpp:244]     Train net output #1: loss = 0.0497417 (* 1 = 0.0497417 loss)
I0824 18:39:31.383241 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977509
I0824 18:39:31.383246 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986082
I0824 18:39:31.383253 42792 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0824 18:39:48.055727 42792 solver.cpp:228] Iteration 700, loss = 0.0396857
I0824 18:39:48.055770 42792 solver.cpp:244]     Train net output #0: accuracy = 0.984942
I0824 18:39:48.055785 42792 solver.cpp:244]     Train net output #1: loss = 0.0396858 (* 1 = 0.0396858 loss)
I0824 18:39:48.055791 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986371
I0824 18:39:48.055797 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979153
I0824 18:39:48.055805 42792 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0824 18:40:04.717689 42792 solver.cpp:228] Iteration 720, loss = 0.0459635
I0824 18:40:04.717866 42792 solver.cpp:244]     Train net output #0: accuracy = 0.984062
I0824 18:40:04.717882 42792 solver.cpp:244]     Train net output #1: loss = 0.0459635 (* 1 = 0.0459635 loss)
I0824 18:40:04.717888 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983424
I0824 18:40:04.717893 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985261
I0824 18:40:04.717900 42792 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0824 18:40:21.361917 42792 solver.cpp:228] Iteration 740, loss = 0.0518076
I0824 18:40:21.361963 42792 solver.cpp:244]     Train net output #0: accuracy = 0.977493
I0824 18:40:21.361977 42792 solver.cpp:244]     Train net output #1: loss = 0.0518076 (* 1 = 0.0518076 loss)
I0824 18:40:21.361984 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972587
I0824 18:40:21.361989 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989693
I0824 18:40:21.361996 42792 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0824 18:40:38.002625 42792 solver.cpp:228] Iteration 760, loss = 0.0269764
I0824 18:40:38.002738 42792 solver.cpp:244]     Train net output #0: accuracy = 0.989067
I0824 18:40:38.002753 42792 solver.cpp:244]     Train net output #1: loss = 0.0269765 (* 1 = 0.0269765 loss)
I0824 18:40:38.002759 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984998
I0824 18:40:38.002764 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99581
I0824 18:40:38.002773 42792 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0824 18:40:54.661922 42792 solver.cpp:228] Iteration 780, loss = 0.0301475
I0824 18:40:54.661962 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987833
I0824 18:40:54.661976 42792 solver.cpp:244]     Train net output #1: loss = 0.0301476 (* 1 = 0.0301476 loss)
I0824 18:40:54.661983 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987649
I0824 18:40:54.661988 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988326
I0824 18:40:54.661994 42792 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0824 18:41:11.309119 42792 solver.cpp:228] Iteration 800, loss = 0.0228476
I0824 18:41:11.309232 42792 solver.cpp:244]     Train net output #0: accuracy = 0.990658
I0824 18:41:11.309249 42792 solver.cpp:244]     Train net output #1: loss = 0.0228477 (* 1 = 0.0228477 loss)
I0824 18:41:11.309255 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988935
I0824 18:41:11.309260 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994702
I0824 18:41:11.309267 42792 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0824 18:41:27.952744 42792 solver.cpp:228] Iteration 820, loss = 0.0395782
I0824 18:41:27.952787 42792 solver.cpp:244]     Train net output #0: accuracy = 0.981968
I0824 18:41:27.952800 42792 solver.cpp:244]     Train net output #1: loss = 0.0395783 (* 1 = 0.0395783 loss)
I0824 18:41:27.952806 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975837
I0824 18:41:27.952811 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994136
I0824 18:41:27.952818 42792 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0824 18:41:44.607096 42792 solver.cpp:228] Iteration 840, loss = 0.0412356
I0824 18:41:44.607208 42792 solver.cpp:244]     Train net output #0: accuracy = 0.986827
I0824 18:41:44.607223 42792 solver.cpp:244]     Train net output #1: loss = 0.0412357 (* 1 = 0.0412357 loss)
I0824 18:41:44.607230 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989189
I0824 18:41:44.607235 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.967776
I0824 18:41:44.607242 42792 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0824 18:42:01.257586 42792 solver.cpp:228] Iteration 860, loss = 0.0287491
I0824 18:42:01.257627 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987432
I0824 18:42:01.257640 42792 solver.cpp:244]     Train net output #1: loss = 0.0287491 (* 1 = 0.0287491 loss)
I0824 18:42:01.257647 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986373
I0824 18:42:01.257652 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99097
I0824 18:42:01.257660 42792 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0824 18:42:17.901780 42792 solver.cpp:228] Iteration 880, loss = 0.032652
I0824 18:42:17.901952 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987377
I0824 18:42:17.901968 42792 solver.cpp:244]     Train net output #1: loss = 0.0326521 (* 1 = 0.0326521 loss)
I0824 18:42:17.901974 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986838
I0824 18:42:17.901979 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988612
I0824 18:42:17.901986 42792 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0824 18:42:34.550235 42792 solver.cpp:228] Iteration 900, loss = 0.074713
I0824 18:42:34.550282 42792 solver.cpp:244]     Train net output #0: accuracy = 0.966801
I0824 18:42:34.550294 42792 solver.cpp:244]     Train net output #1: loss = 0.0747131 (* 1 = 0.0747131 loss)
I0824 18:42:34.550300 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.956875
I0824 18:42:34.550305 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989152
I0824 18:42:34.550313 42792 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0824 18:42:51.202018 42792 solver.cpp:228] Iteration 920, loss = 0.0305014
I0824 18:42:51.202138 42792 solver.cpp:244]     Train net output #0: accuracy = 0.989721
I0824 18:42:51.202181 42792 solver.cpp:244]     Train net output #1: loss = 0.0305015 (* 1 = 0.0305015 loss)
I0824 18:42:51.202190 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991058
I0824 18:42:51.202200 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986117
I0824 18:42:51.202208 42792 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0824 18:43:07.993927 42792 solver.cpp:228] Iteration 940, loss = 0.0787695
I0824 18:43:07.993989 42792 solver.cpp:244]     Train net output #0: accuracy = 0.978417
I0824 18:43:07.994004 42792 solver.cpp:244]     Train net output #1: loss = 0.0787696 (* 1 = 0.0787696 loss)
I0824 18:43:07.994009 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987005
I0824 18:43:07.994015 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.967223
I0824 18:43:07.994024 42792 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0824 18:43:24.666784 42792 solver.cpp:228] Iteration 960, loss = 0.0509802
I0824 18:43:24.666901 42792 solver.cpp:244]     Train net output #0: accuracy = 0.983717
I0824 18:43:24.666924 42792 solver.cpp:244]     Train net output #1: loss = 0.0509803 (* 1 = 0.0509803 loss)
I0824 18:43:24.666932 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981857
I0824 18:43:24.666944 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98595
I0824 18:43:24.666951 42792 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0824 18:43:41.340592 42792 solver.cpp:228] Iteration 980, loss = 0.036598
I0824 18:43:41.340636 42792 solver.cpp:244]     Train net output #0: accuracy = 0.986677
I0824 18:43:41.340647 42792 solver.cpp:244]     Train net output #1: loss = 0.0365981 (* 1 = 0.0365981 loss)
I0824 18:43:41.340653 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989004
I0824 18:43:41.340658 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978644
I0824 18:43:41.340667 42792 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0824 18:43:57.996661 42792 solver.cpp:228] Iteration 1000, loss = 0.0455621
I0824 18:43:57.996785 42792 solver.cpp:244]     Train net output #0: accuracy = 0.979479
I0824 18:43:57.996801 42792 solver.cpp:244]     Train net output #1: loss = 0.0455622 (* 1 = 0.0455622 loss)
I0824 18:43:57.996811 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972307
I0824 18:43:57.996816 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99363
I0824 18:43:57.996824 42792 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0824 18:44:14.662014 42792 solver.cpp:228] Iteration 1020, loss = 0.0477184
I0824 18:44:14.662055 42792 solver.cpp:244]     Train net output #0: accuracy = 0.978588
I0824 18:44:14.662067 42792 solver.cpp:244]     Train net output #1: loss = 0.0477185 (* 1 = 0.0477185 loss)
I0824 18:44:14.662075 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.971637
I0824 18:44:14.662080 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993575
I0824 18:44:14.662087 42792 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0824 18:44:31.317998 42792 solver.cpp:228] Iteration 1040, loss = 0.032967
I0824 18:44:31.318161 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987053
I0824 18:44:31.318174 42792 solver.cpp:244]     Train net output #1: loss = 0.0329671 (* 1 = 0.0329671 loss)
I0824 18:44:31.318186 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987037
I0824 18:44:31.318193 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98709
I0824 18:44:31.318202 42792 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0824 18:44:47.969969 42792 solver.cpp:228] Iteration 1060, loss = 0.0256344
I0824 18:44:47.970013 42792 solver.cpp:244]     Train net output #0: accuracy = 0.990372
I0824 18:44:47.970027 42792 solver.cpp:244]     Train net output #1: loss = 0.0256345 (* 1 = 0.0256345 loss)
I0824 18:44:47.970033 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990119
I0824 18:44:47.970038 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991044
I0824 18:44:47.970046 42792 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0824 18:45:04.619518 42792 solver.cpp:228] Iteration 1080, loss = 0.0376011
I0824 18:45:04.619643 42792 solver.cpp:244]     Train net output #0: accuracy = 0.984161
I0824 18:45:04.619657 42792 solver.cpp:244]     Train net output #1: loss = 0.0376012 (* 1 = 0.0376012 loss)
I0824 18:45:04.619663 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.976789
I0824 18:45:04.619669 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994966
I0824 18:45:04.619676 42792 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0824 18:45:21.272498 42792 solver.cpp:228] Iteration 1100, loss = 0.0527879
I0824 18:45:21.272543 42792 solver.cpp:244]     Train net output #0: accuracy = 0.980794
I0824 18:45:21.272557 42792 solver.cpp:244]     Train net output #1: loss = 0.052788 (* 1 = 0.052788 loss)
I0824 18:45:21.272563 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975886
I0824 18:45:21.272568 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987943
I0824 18:45:21.272575 42792 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0824 18:45:37.930179 42792 solver.cpp:228] Iteration 1120, loss = 0.0284874
I0824 18:45:37.930299 42792 solver.cpp:244]     Train net output #0: accuracy = 0.990182
I0824 18:45:37.930313 42792 solver.cpp:244]     Train net output #1: loss = 0.0284874 (* 1 = 0.0284874 loss)
I0824 18:45:37.930318 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989666
I0824 18:45:37.930325 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991194
I0824 18:45:37.930332 42792 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0824 18:45:54.579267 42792 solver.cpp:228] Iteration 1140, loss = 0.109362
I0824 18:45:54.579313 42792 solver.cpp:244]     Train net output #0: accuracy = 0.957523
I0824 18:45:54.579329 42792 solver.cpp:244]     Train net output #1: loss = 0.109363 (* 1 = 0.109363 loss)
I0824 18:45:54.579335 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.948725
I0824 18:45:54.579341 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.972317
I0824 18:45:54.579349 42792 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0824 18:46:11.230459 42792 solver.cpp:228] Iteration 1160, loss = 0.0749398
I0824 18:46:11.230630 42792 solver.cpp:244]     Train net output #0: accuracy = 0.965
I0824 18:46:11.230648 42792 solver.cpp:244]     Train net output #1: loss = 0.0749399 (* 1 = 0.0749399 loss)
I0824 18:46:11.230654 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.955294
I0824 18:46:11.230660 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988579
I0824 18:46:11.230667 42792 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0824 18:46:27.886899 42792 solver.cpp:228] Iteration 1180, loss = 0.0483574
I0824 18:46:27.886942 42792 solver.cpp:244]     Train net output #0: accuracy = 0.983459
I0824 18:46:27.886955 42792 solver.cpp:244]     Train net output #1: loss = 0.0483575 (* 1 = 0.0483575 loss)
I0824 18:46:27.886961 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97997
I0824 18:46:27.886966 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988386
I0824 18:46:27.886975 42792 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0824 18:46:44.535202 42792 solver.cpp:228] Iteration 1200, loss = 0.0531352
I0824 18:46:44.535325 42792 solver.cpp:244]     Train net output #0: accuracy = 0.97717
I0824 18:46:44.535339 42792 solver.cpp:244]     Train net output #1: loss = 0.0531354 (* 1 = 0.0531354 loss)
I0824 18:46:44.535346 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.967643
I0824 18:46:44.535351 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998099
I0824 18:46:44.535357 42792 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0824 18:47:01.177692 42792 solver.cpp:228] Iteration 1220, loss = 0.0907467
I0824 18:47:01.177733 42792 solver.cpp:244]     Train net output #0: accuracy = 0.956209
I0824 18:47:01.177747 42792 solver.cpp:244]     Train net output #1: loss = 0.0907469 (* 1 = 0.0907469 loss)
I0824 18:47:01.177753 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.941754
I0824 18:47:01.177758 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99314
I0824 18:47:01.177765 42792 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0824 18:47:17.846879 42792 solver.cpp:228] Iteration 1240, loss = 0.0328106
I0824 18:47:17.847033 42792 solver.cpp:244]     Train net output #0: accuracy = 0.986876
I0824 18:47:17.847049 42792 solver.cpp:244]     Train net output #1: loss = 0.0328107 (* 1 = 0.0328107 loss)
I0824 18:47:17.847061 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984117
I0824 18:47:17.847067 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99617
I0824 18:47:17.847077 42792 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0824 18:47:34.517695 42792 solver.cpp:228] Iteration 1260, loss = 0.0319681
I0824 18:47:34.517746 42792 solver.cpp:244]     Train net output #0: accuracy = 0.989944
I0824 18:47:34.517761 42792 solver.cpp:244]     Train net output #1: loss = 0.0319682 (* 1 = 0.0319682 loss)
I0824 18:47:34.517768 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992707
I0824 18:47:34.517773 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978504
I0824 18:47:34.517781 42792 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0824 18:47:51.179409 42792 solver.cpp:228] Iteration 1280, loss = 0.0216612
I0824 18:47:51.179545 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992293
I0824 18:47:51.179563 42792 solver.cpp:244]     Train net output #1: loss = 0.0216614 (* 1 = 0.0216614 loss)
I0824 18:47:51.179575 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992684
I0824 18:47:51.179589 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991048
I0824 18:47:51.179596 42792 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0824 18:48:07.840768 42792 solver.cpp:228] Iteration 1300, loss = 0.0334195
I0824 18:48:07.840814 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987277
I0824 18:48:07.840828 42792 solver.cpp:244]     Train net output #1: loss = 0.0334196 (* 1 = 0.0334196 loss)
I0824 18:48:07.840834 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98927
I0824 18:48:07.840842 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978769
I0824 18:48:07.840849 42792 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0824 18:48:24.500365 42792 solver.cpp:228] Iteration 1320, loss = 0.0346954
I0824 18:48:24.500543 42792 solver.cpp:244]     Train net output #0: accuracy = 0.983911
I0824 18:48:24.500566 42792 solver.cpp:244]     Train net output #1: loss = 0.0346955 (* 1 = 0.0346955 loss)
I0824 18:48:24.500573 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978285
I0824 18:48:24.500586 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996588
I0824 18:48:24.500593 42792 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0824 18:48:41.182492 42792 solver.cpp:228] Iteration 1340, loss = 0.0409334
I0824 18:48:41.182538 42792 solver.cpp:244]     Train net output #0: accuracy = 0.985667
I0824 18:48:41.182551 42792 solver.cpp:244]     Train net output #1: loss = 0.0409335 (* 1 = 0.0409335 loss)
I0824 18:48:41.182557 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980352
I0824 18:48:41.182564 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992337
I0824 18:48:41.182570 42792 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0824 18:48:57.846596 42792 solver.cpp:228] Iteration 1360, loss = 0.0440408
I0824 18:48:57.846709 42792 solver.cpp:244]     Train net output #0: accuracy = 0.981461
I0824 18:48:57.846735 42792 solver.cpp:244]     Train net output #1: loss = 0.0440409 (* 1 = 0.0440409 loss)
I0824 18:48:57.846742 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978516
I0824 18:48:57.846747 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987904
I0824 18:48:57.846755 42792 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0824 18:49:14.509404 42792 solver.cpp:228] Iteration 1380, loss = 0.0347129
I0824 18:49:14.509449 42792 solver.cpp:244]     Train net output #0: accuracy = 0.98704
I0824 18:49:14.509464 42792 solver.cpp:244]     Train net output #1: loss = 0.034713 (* 1 = 0.034713 loss)
I0824 18:49:14.509470 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985298
I0824 18:49:14.509475 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990322
I0824 18:49:14.509483 42792 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0824 18:49:31.184759 42792 solver.cpp:228] Iteration 1400, loss = 0.0282984
I0824 18:49:31.184872 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987679
I0824 18:49:31.184890 42792 solver.cpp:244]     Train net output #1: loss = 0.0282985 (* 1 = 0.0282985 loss)
I0824 18:49:31.184902 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983506
I0824 18:49:31.184916 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996065
I0824 18:49:31.184924 42792 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0824 18:49:47.855860 42792 solver.cpp:228] Iteration 1420, loss = 0.0457218
I0824 18:49:47.855906 42792 solver.cpp:244]     Train net output #0: accuracy = 0.980285
I0824 18:49:47.855921 42792 solver.cpp:244]     Train net output #1: loss = 0.0457219 (* 1 = 0.0457219 loss)
I0824 18:49:47.855927 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972274
I0824 18:49:47.855932 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992334
I0824 18:49:47.855942 42792 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0824 18:50:04.516963 42792 solver.cpp:228] Iteration 1440, loss = 0.0299617
I0824 18:50:04.517068 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987072
I0824 18:50:04.517086 42792 solver.cpp:244]     Train net output #1: loss = 0.0299618 (* 1 = 0.0299618 loss)
I0824 18:50:04.517093 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985735
I0824 18:50:04.517098 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99004
I0824 18:50:04.517107 42792 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0824 18:50:21.200466 42792 solver.cpp:228] Iteration 1460, loss = 0.0405249
I0824 18:50:21.200512 42792 solver.cpp:244]     Train net output #0: accuracy = 0.985389
I0824 18:50:21.200527 42792 solver.cpp:244]     Train net output #1: loss = 0.0405251 (* 1 = 0.0405251 loss)
I0824 18:50:21.200534 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98894
I0824 18:50:21.200539 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976902
I0824 18:50:21.200547 42792 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0824 18:50:37.886052 42792 solver.cpp:228] Iteration 1480, loss = 0.0309989
I0824 18:50:37.886214 42792 solver.cpp:244]     Train net output #0: accuracy = 0.988994
I0824 18:50:37.886230 42792 solver.cpp:244]     Train net output #1: loss = 0.030999 (* 1 = 0.030999 loss)
I0824 18:50:37.886237 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989694
I0824 18:50:37.886242 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983339
I0824 18:50:37.886250 42792 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0824 18:50:54.550951 42792 solver.cpp:228] Iteration 1500, loss = 0.0248224
I0824 18:50:54.550997 42792 solver.cpp:244]     Train net output #0: accuracy = 0.990823
I0824 18:50:54.551009 42792 solver.cpp:244]     Train net output #1: loss = 0.0248225 (* 1 = 0.0248225 loss)
I0824 18:50:54.551017 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990186
I0824 18:50:54.551023 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992195
I0824 18:50:54.551030 42792 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0824 18:51:11.206012 42792 solver.cpp:228] Iteration 1520, loss = 0.0220432
I0824 18:51:11.206138 42792 solver.cpp:244]     Train net output #0: accuracy = 0.990725
I0824 18:51:11.206151 42792 solver.cpp:244]     Train net output #1: loss = 0.0220434 (* 1 = 0.0220434 loss)
I0824 18:51:11.206157 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989483
I0824 18:51:11.206163 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994606
I0824 18:51:11.206171 42792 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0824 18:51:27.856389 42792 solver.cpp:228] Iteration 1540, loss = 0.0203346
I0824 18:51:27.856432 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992675
I0824 18:51:27.856447 42792 solver.cpp:244]     Train net output #1: loss = 0.0203348 (* 1 = 0.0203348 loss)
I0824 18:51:27.856456 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994017
I0824 18:51:27.856462 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989696
I0824 18:51:27.856470 42792 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0824 18:51:44.509189 42792 solver.cpp:228] Iteration 1560, loss = 0.0305545
I0824 18:51:44.509302 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987368
I0824 18:51:44.509320 42792 solver.cpp:244]     Train net output #1: loss = 0.0305547 (* 1 = 0.0305547 loss)
I0824 18:51:44.509325 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98425
I0824 18:51:44.509330 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993758
I0824 18:51:44.509338 42792 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0824 18:52:01.162012 42792 solver.cpp:228] Iteration 1580, loss = 0.0305477
I0824 18:52:01.162053 42792 solver.cpp:244]     Train net output #0: accuracy = 0.986638
I0824 18:52:01.162067 42792 solver.cpp:244]     Train net output #1: loss = 0.0305478 (* 1 = 0.0305478 loss)
I0824 18:52:01.162073 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983026
I0824 18:52:01.162077 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993892
I0824 18:52:01.162084 42792 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0824 18:52:17.816351 42792 solver.cpp:228] Iteration 1600, loss = 0.0295049
I0824 18:52:17.816463 42792 solver.cpp:244]     Train net output #0: accuracy = 0.990457
I0824 18:52:17.816479 42792 solver.cpp:244]     Train net output #1: loss = 0.029505 (* 1 = 0.029505 loss)
I0824 18:52:17.816485 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987328
I0824 18:52:17.816489 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994106
I0824 18:52:17.816496 42792 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0824 18:52:34.465140 42792 solver.cpp:228] Iteration 1620, loss = 0.0188597
I0824 18:52:34.465181 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992572
I0824 18:52:34.465194 42792 solver.cpp:244]     Train net output #1: loss = 0.0188598 (* 1 = 0.0188598 loss)
I0824 18:52:34.465200 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993227
I0824 18:52:34.465205 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990533
I0824 18:52:34.465212 42792 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0824 18:52:51.119488 42792 solver.cpp:228] Iteration 1640, loss = 0.0290518
I0824 18:52:51.119658 42792 solver.cpp:244]     Train net output #0: accuracy = 0.98887
I0824 18:52:51.119678 42792 solver.cpp:244]     Train net output #1: loss = 0.0290519 (* 1 = 0.0290519 loss)
I0824 18:52:51.119689 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989553
I0824 18:52:51.119701 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984588
I0824 18:52:51.119710 42792 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0824 18:53:07.787713 42792 solver.cpp:228] Iteration 1660, loss = 0.0341631
I0824 18:53:07.787756 42792 solver.cpp:244]     Train net output #0: accuracy = 0.986855
I0824 18:53:07.787771 42792 solver.cpp:244]     Train net output #1: loss = 0.0341633 (* 1 = 0.0341633 loss)
I0824 18:53:07.787778 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98744
I0824 18:53:07.787783 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985745
I0824 18:53:07.787792 42792 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0824 18:53:24.569917 42792 solver.cpp:228] Iteration 1680, loss = 0.0333079
I0824 18:53:24.570055 42792 solver.cpp:244]     Train net output #0: accuracy = 0.985573
I0824 18:53:24.570073 42792 solver.cpp:244]     Train net output #1: loss = 0.033308 (* 1 = 0.033308 loss)
I0824 18:53:24.570080 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982294
I0824 18:53:24.570086 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992611
I0824 18:53:24.570092 42792 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0824 18:53:41.246278 42792 solver.cpp:228] Iteration 1700, loss = 0.0483964
I0824 18:53:41.246322 42792 solver.cpp:244]     Train net output #0: accuracy = 0.983597
I0824 18:53:41.246337 42792 solver.cpp:244]     Train net output #1: loss = 0.0483966 (* 1 = 0.0483966 loss)
I0824 18:53:41.246343 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98107
I0824 18:53:41.246350 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986828
I0824 18:53:41.246357 42792 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0824 18:53:57.931936 42792 solver.cpp:228] Iteration 1720, loss = 0.145405
I0824 18:53:57.932060 42792 solver.cpp:244]     Train net output #0: accuracy = 0.960107
I0824 18:53:57.932077 42792 solver.cpp:244]     Train net output #1: loss = 0.145405 (* 1 = 0.145405 loss)
I0824 18:53:57.932085 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969062
I0824 18:53:57.932090 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.901027
I0824 18:53:57.932096 42792 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0824 18:54:14.620175 42792 solver.cpp:228] Iteration 1740, loss = 0.0614118
I0824 18:54:14.620223 42792 solver.cpp:244]     Train net output #0: accuracy = 0.982779
I0824 18:54:14.620239 42792 solver.cpp:244]     Train net output #1: loss = 0.0614119 (* 1 = 0.0614119 loss)
I0824 18:54:14.620246 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991116
I0824 18:54:14.620252 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.94702
I0824 18:54:14.620260 42792 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0824 18:54:31.321096 42792 solver.cpp:228] Iteration 1760, loss = 0.0606792
I0824 18:54:31.321264 42792 solver.cpp:244]     Train net output #0: accuracy = 0.973979
I0824 18:54:31.321280 42792 solver.cpp:244]     Train net output #1: loss = 0.0606793 (* 1 = 0.0606793 loss)
I0824 18:54:31.321292 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.963192
I0824 18:54:31.321300 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992209
I0824 18:54:31.321306 42792 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0824 18:54:48.000885 42792 solver.cpp:228] Iteration 1780, loss = 0.0547917
I0824 18:54:48.000929 42792 solver.cpp:244]     Train net output #0: accuracy = 0.97258
I0824 18:54:48.000944 42792 solver.cpp:244]     Train net output #1: loss = 0.0547919 (* 1 = 0.0547919 loss)
I0824 18:54:48.000952 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.956892
I0824 18:54:48.000958 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998085
I0824 18:54:48.000968 42792 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0824 18:55:04.694548 42792 solver.cpp:228] Iteration 1800, loss = 0.0217502
I0824 18:55:04.694664 42792 solver.cpp:244]     Train net output #0: accuracy = 0.991914
I0824 18:55:04.694682 42792 solver.cpp:244]     Train net output #1: loss = 0.0217503 (* 1 = 0.0217503 loss)
I0824 18:55:04.694694 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99133
I0824 18:55:04.694700 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993349
I0824 18:55:04.694706 42792 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0824 18:55:21.359131 42792 solver.cpp:228] Iteration 1820, loss = 0.0369583
I0824 18:55:21.359177 42792 solver.cpp:244]     Train net output #0: accuracy = 0.988341
I0824 18:55:21.359190 42792 solver.cpp:244]     Train net output #1: loss = 0.0369584 (* 1 = 0.0369584 loss)
I0824 18:55:21.359197 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989373
I0824 18:55:21.359202 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980899
I0824 18:55:21.359210 42792 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0824 18:55:38.041299 42792 solver.cpp:228] Iteration 1840, loss = 0.0304794
I0824 18:55:38.041411 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987758
I0824 18:55:38.041429 42792 solver.cpp:244]     Train net output #1: loss = 0.0304795 (* 1 = 0.0304795 loss)
I0824 18:55:38.041435 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988777
I0824 18:55:38.041451 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983672
I0824 18:55:38.041460 42792 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0824 18:55:54.729892 42792 solver.cpp:228] Iteration 1860, loss = 0.0243199
I0824 18:55:54.729936 42792 solver.cpp:244]     Train net output #0: accuracy = 0.989741
I0824 18:55:54.729950 42792 solver.cpp:244]     Train net output #1: loss = 0.02432 (* 1 = 0.02432 loss)
I0824 18:55:54.729956 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988248
I0824 18:55:54.729962 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993735
I0824 18:55:54.729969 42792 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0824 18:56:11.415858 42792 solver.cpp:228] Iteration 1880, loss = 0.0267531
I0824 18:56:11.415968 42792 solver.cpp:244]     Train net output #0: accuracy = 0.989661
I0824 18:56:11.415987 42792 solver.cpp:244]     Train net output #1: loss = 0.0267533 (* 1 = 0.0267533 loss)
I0824 18:56:11.415997 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986555
I0824 18:56:11.416004 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99411
I0824 18:56:11.416013 42792 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0824 18:56:28.103274 42792 solver.cpp:228] Iteration 1900, loss = 0.0422322
I0824 18:56:28.103319 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987231
I0824 18:56:28.103334 42792 solver.cpp:244]     Train net output #1: loss = 0.0422323 (* 1 = 0.0422323 loss)
I0824 18:56:28.103341 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986715
I0824 18:56:28.103348 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99471
I0824 18:56:28.103355 42792 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0824 18:56:44.817978 42792 solver.cpp:228] Iteration 1920, loss = 0.0304675
I0824 18:56:44.818161 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987888
I0824 18:56:44.818186 42792 solver.cpp:244]     Train net output #1: loss = 0.0304676 (* 1 = 0.0304676 loss)
I0824 18:56:44.818195 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987927
I0824 18:56:44.818207 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987723
I0824 18:56:44.818213 42792 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0824 18:57:01.492676 42792 solver.cpp:228] Iteration 1940, loss = 0.0316736
I0824 18:57:01.492722 42792 solver.cpp:244]     Train net output #0: accuracy = 0.985399
I0824 18:57:01.492738 42792 solver.cpp:244]     Train net output #1: loss = 0.0316737 (* 1 = 0.0316737 loss)
I0824 18:57:01.492744 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980029
I0824 18:57:01.492749 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996943
I0824 18:57:01.492756 42792 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0824 18:57:18.158773 42792 solver.cpp:228] Iteration 1960, loss = 0.0199976
I0824 18:57:18.158890 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992661
I0824 18:57:18.158907 42792 solver.cpp:244]     Train net output #1: loss = 0.0199977 (* 1 = 0.0199977 loss)
I0824 18:57:18.158913 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993592
I0824 18:57:18.158918 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987527
I0824 18:57:18.158926 42792 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0824 18:57:34.837996 42792 solver.cpp:228] Iteration 1980, loss = 0.025705
I0824 18:57:34.838043 42792 solver.cpp:244]     Train net output #0: accuracy = 0.988948
I0824 18:57:34.838059 42792 solver.cpp:244]     Train net output #1: loss = 0.0257051 (* 1 = 0.0257051 loss)
I0824 18:57:34.838068 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987059
I0824 18:57:34.838073 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994208
I0824 18:57:34.838080 42792 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0824 18:57:51.527021 42792 solver.cpp:228] Iteration 2000, loss = 0.017645
I0824 18:57:51.527123 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993199
I0824 18:57:51.527139 42792 solver.cpp:244]     Train net output #1: loss = 0.0176451 (* 1 = 0.0176451 loss)
I0824 18:57:51.527153 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99321
I0824 18:57:51.527165 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993162
I0824 18:57:51.527173 42792 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0824 18:58:08.218675 42792 solver.cpp:228] Iteration 2020, loss = 0.0210882
I0824 18:58:08.218725 42792 solver.cpp:244]     Train net output #0: accuracy = 0.991328
I0824 18:58:08.218741 42792 solver.cpp:244]     Train net output #1: loss = 0.0210883 (* 1 = 0.0210883 loss)
I0824 18:58:08.218749 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989867
I0824 18:58:08.218755 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994435
I0824 18:58:08.218765 42792 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0824 18:58:24.920886 42792 solver.cpp:228] Iteration 2040, loss = 0.0292637
I0824 18:58:24.920994 42792 solver.cpp:244]     Train net output #0: accuracy = 0.985216
I0824 18:58:24.921010 42792 solver.cpp:244]     Train net output #1: loss = 0.0292639 (* 1 = 0.0292639 loss)
I0824 18:58:24.921025 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980336
I0824 18:58:24.921030 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995601
I0824 18:58:24.921037 42792 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0824 18:58:41.605063 42792 solver.cpp:228] Iteration 2060, loss = 0.0255879
I0824 18:58:41.605104 42792 solver.cpp:244]     Train net output #0: accuracy = 0.988401
I0824 18:58:41.605118 42792 solver.cpp:244]     Train net output #1: loss = 0.025588 (* 1 = 0.025588 loss)
I0824 18:58:41.605125 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983986
I0824 18:58:41.605130 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996039
I0824 18:58:41.605137 42792 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0824 18:58:58.262513 42792 solver.cpp:228] Iteration 2080, loss = 0.0185417
I0824 18:58:58.262682 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992072
I0824 18:58:58.262708 42792 solver.cpp:244]     Train net output #1: loss = 0.0185418 (* 1 = 0.0185418 loss)
I0824 18:58:58.262717 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990663
I0824 18:58:58.262728 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995109
I0824 18:58:58.262737 42792 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0824 18:59:14.917454 42792 solver.cpp:228] Iteration 2100, loss = 0.0175122
I0824 18:59:14.917497 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993449
I0824 18:59:14.917511 42792 solver.cpp:244]     Train net output #1: loss = 0.0175123 (* 1 = 0.0175123 loss)
I0824 18:59:14.917517 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993706
I0824 18:59:14.917523 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991406
I0824 18:59:14.917531 42792 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0824 18:59:31.608621 42792 solver.cpp:228] Iteration 2120, loss = 0.0172671
I0824 18:59:31.608745 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993319
I0824 18:59:31.608762 42792 solver.cpp:244]     Train net output #1: loss = 0.0172672 (* 1 = 0.0172672 loss)
I0824 18:59:31.608769 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99207
I0824 18:59:31.608777 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995716
I0824 18:59:31.608783 42792 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0824 18:59:48.294857 42792 solver.cpp:228] Iteration 2140, loss = 0.0317013
I0824 18:59:48.294900 42792 solver.cpp:244]     Train net output #0: accuracy = 0.987629
I0824 18:59:48.294914 42792 solver.cpp:244]     Train net output #1: loss = 0.0317015 (* 1 = 0.0317015 loss)
I0824 18:59:48.294920 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988839
I0824 18:59:48.294926 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984525
I0824 18:59:48.294934 42792 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0824 19:00:04.991092 42792 solver.cpp:228] Iteration 2160, loss = 0.0215941
I0824 19:00:04.991204 42792 solver.cpp:244]     Train net output #0: accuracy = 0.990589
I0824 19:00:04.991219 42792 solver.cpp:244]     Train net output #1: loss = 0.0215942 (* 1 = 0.0215942 loss)
I0824 19:00:04.991225 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990553
I0824 19:00:04.991230 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990745
I0824 19:00:04.991237 42792 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0824 19:00:21.677831 42792 solver.cpp:228] Iteration 2180, loss = 0.0176268
I0824 19:00:21.677881 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992687
I0824 19:00:21.677894 42792 solver.cpp:244]     Train net output #1: loss = 0.017627 (* 1 = 0.017627 loss)
I0824 19:00:21.677901 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991776
I0824 19:00:21.677907 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994937
I0824 19:00:21.677914 42792 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0824 19:00:38.363085 42792 solver.cpp:228] Iteration 2200, loss = 0.0236582
I0824 19:00:38.363209 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99103
I0824 19:00:38.363225 42792 solver.cpp:244]     Train net output #1: loss = 0.0236584 (* 1 = 0.0236584 loss)
I0824 19:00:38.363231 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98942
I0824 19:00:38.363236 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995281
I0824 19:00:38.363245 42792 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0824 19:00:55.033931 42792 solver.cpp:228] Iteration 2220, loss = 0.0262672
I0824 19:00:55.033977 42792 solver.cpp:244]     Train net output #0: accuracy = 0.991282
I0824 19:00:55.033993 42792 solver.cpp:244]     Train net output #1: loss = 0.0262673 (* 1 = 0.0262673 loss)
I0824 19:00:55.034000 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98911
I0824 19:00:55.034006 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994013
I0824 19:00:55.034014 42792 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0824 19:01:11.724195 42792 solver.cpp:228] Iteration 2240, loss = 0.0584774
I0824 19:01:11.724351 42792 solver.cpp:244]     Train net output #0: accuracy = 0.985404
I0824 19:01:11.724369 42792 solver.cpp:244]     Train net output #1: loss = 0.0584775 (* 1 = 0.0584775 loss)
I0824 19:01:11.724376 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988283
I0824 19:01:11.724382 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983005
I0824 19:01:11.724396 42792 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0824 19:01:28.402446 42792 solver.cpp:228] Iteration 2260, loss = 0.0217875
I0824 19:01:28.402493 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99113
I0824 19:01:28.402509 42792 solver.cpp:244]     Train net output #1: loss = 0.0217877 (* 1 = 0.0217877 loss)
I0824 19:01:28.402516 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991304
I0824 19:01:28.402523 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990432
I0824 19:01:28.402531 42792 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0824 19:01:45.097272 42792 solver.cpp:228] Iteration 2280, loss = 0.0139376
I0824 19:01:45.097376 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995579
I0824 19:01:45.097391 42792 solver.cpp:244]     Train net output #1: loss = 0.0139377 (* 1 = 0.0139377 loss)
I0824 19:01:45.097400 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995766
I0824 19:01:45.097406 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99495
I0824 19:01:45.097414 42792 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0824 19:02:01.761963 42792 solver.cpp:228] Iteration 2300, loss = 0.0155768
I0824 19:02:01.762006 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993414
I0824 19:02:01.762019 42792 solver.cpp:244]     Train net output #1: loss = 0.0155769 (* 1 = 0.0155769 loss)
I0824 19:02:01.762027 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991503
I0824 19:02:01.762033 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997545
I0824 19:02:01.762042 42792 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0824 19:02:18.426401 42792 solver.cpp:228] Iteration 2320, loss = 0.0158404
I0824 19:02:18.426491 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994239
I0824 19:02:18.426508 42792 solver.cpp:244]     Train net output #1: loss = 0.0158406 (* 1 = 0.0158406 loss)
I0824 19:02:18.426515 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994475
I0824 19:02:18.426522 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993166
I0824 19:02:18.426532 42792 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0824 19:02:35.099544 42792 solver.cpp:228] Iteration 2340, loss = 0.0202613
I0824 19:02:35.099588 42792 solver.cpp:244]     Train net output #0: accuracy = 0.991751
I0824 19:02:35.099601 42792 solver.cpp:244]     Train net output #1: loss = 0.0202615 (* 1 = 0.0202615 loss)
I0824 19:02:35.099608 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989585
I0824 19:02:35.099614 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996287
I0824 19:02:35.099622 42792 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0824 19:02:51.774034 42792 solver.cpp:228] Iteration 2360, loss = 0.0162789
I0824 19:02:51.774195 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993913
I0824 19:02:51.774214 42792 solver.cpp:244]     Train net output #1: loss = 0.0162791 (* 1 = 0.0162791 loss)
I0824 19:02:51.774225 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994528
I0824 19:02:51.774237 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989496
I0824 19:02:51.774251 42792 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0824 19:03:08.455245 42792 solver.cpp:228] Iteration 2380, loss = 0.0242854
I0824 19:03:08.455291 42792 solver.cpp:244]     Train net output #0: accuracy = 0.988848
I0824 19:03:08.455307 42792 solver.cpp:244]     Train net output #1: loss = 0.0242856 (* 1 = 0.0242856 loss)
I0824 19:03:08.455313 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982904
I0824 19:03:08.455327 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99806
I0824 19:03:08.455335 42792 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0824 19:03:25.153949 42792 solver.cpp:228] Iteration 2400, loss = 0.0295947
I0824 19:03:25.154047 42792 solver.cpp:244]     Train net output #0: accuracy = 0.988624
I0824 19:03:25.154062 42792 solver.cpp:244]     Train net output #1: loss = 0.0295949 (* 1 = 0.0295949 loss)
I0824 19:03:25.154069 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989077
I0824 19:03:25.154075 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987655
I0824 19:03:25.154083 42792 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0824 19:03:41.861258 42792 solver.cpp:228] Iteration 2420, loss = 0.0148033
I0824 19:03:41.861302 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994559
I0824 19:03:41.861317 42792 solver.cpp:244]     Train net output #1: loss = 0.0148034 (* 1 = 0.0148034 loss)
I0824 19:03:41.861325 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995986
I0824 19:03:41.861331 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9894
I0824 19:03:41.861340 42792 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0824 19:03:58.545771 42792 solver.cpp:228] Iteration 2440, loss = 0.0187415
I0824 19:03:58.545888 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992581
I0824 19:03:58.545905 42792 solver.cpp:244]     Train net output #1: loss = 0.0187416 (* 1 = 0.0187416 loss)
I0824 19:03:58.545912 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992205
I0824 19:03:58.545917 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993593
I0824 19:03:58.545924 42792 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0824 19:04:15.251778 42792 solver.cpp:228] Iteration 2460, loss = 0.0209896
I0824 19:04:15.251827 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992361
I0824 19:04:15.251842 42792 solver.cpp:244]     Train net output #1: loss = 0.0209897 (* 1 = 0.0209897 loss)
I0824 19:04:15.251849 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991979
I0824 19:04:15.251857 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993164
I0824 19:04:15.251864 42792 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0824 19:04:31.953577 42792 solver.cpp:228] Iteration 2480, loss = 0.0176139
I0824 19:04:31.953687 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993135
I0824 19:04:31.953703 42792 solver.cpp:244]     Train net output #1: loss = 0.017614 (* 1 = 0.017614 loss)
I0824 19:04:31.953711 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992759
I0824 19:04:31.953716 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994049
I0824 19:04:31.953722 42792 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0824 19:04:48.649720 42792 solver.cpp:228] Iteration 2500, loss = 0.0188679
I0824 19:04:48.649768 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992611
I0824 19:04:48.649785 42792 solver.cpp:244]     Train net output #1: loss = 0.018868 (* 1 = 0.018868 loss)
I0824 19:04:48.649791 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99173
I0824 19:04:48.649798 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994662
I0824 19:04:48.649807 42792 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0824 19:05:05.370985 42792 solver.cpp:228] Iteration 2520, loss = 0.0198512
I0824 19:05:05.371148 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992804
I0824 19:05:05.371175 42792 solver.cpp:244]     Train net output #1: loss = 0.0198513 (* 1 = 0.0198513 loss)
I0824 19:05:05.371183 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990089
I0824 19:05:05.371189 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996418
I0824 19:05:05.371197 42792 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0824 19:05:22.054857 42792 solver.cpp:228] Iteration 2540, loss = 0.0217824
I0824 19:05:22.054901 42792 solver.cpp:244]     Train net output #0: accuracy = 0.991544
I0824 19:05:22.054916 42792 solver.cpp:244]     Train net output #1: loss = 0.0217825 (* 1 = 0.0217825 loss)
I0824 19:05:22.054924 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987513
I0824 19:05:22.054929 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996877
I0824 19:05:22.054937 42792 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0824 19:05:38.749605 42792 solver.cpp:228] Iteration 2560, loss = 0.0177771
I0824 19:05:38.749711 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993999
I0824 19:05:38.749728 42792 solver.cpp:244]     Train net output #1: loss = 0.0177772 (* 1 = 0.0177772 loss)
I0824 19:05:38.749739 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995954
I0824 19:05:38.749750 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987994
I0824 19:05:38.749758 42792 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0824 19:05:55.451074 42792 solver.cpp:228] Iteration 2580, loss = 0.023362
I0824 19:05:55.451119 42792 solver.cpp:244]     Train net output #0: accuracy = 0.989427
I0824 19:05:55.451133 42792 solver.cpp:244]     Train net output #1: loss = 0.0233621 (* 1 = 0.0233621 loss)
I0824 19:05:55.451140 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986593
I0824 19:05:55.451145 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994492
I0824 19:05:55.451153 42792 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0824 19:06:12.142927 42792 solver.cpp:228] Iteration 2600, loss = 0.0159796
I0824 19:06:12.143046 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993681
I0824 19:06:12.143070 42792 solver.cpp:244]     Train net output #1: loss = 0.0159797 (* 1 = 0.0159797 loss)
I0824 19:06:12.143079 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992322
I0824 19:06:12.143091 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996176
I0824 19:06:12.143100 42792 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0824 19:06:28.845414 42792 solver.cpp:228] Iteration 2620, loss = 0.0149439
I0824 19:06:28.845461 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994277
I0824 19:06:28.845475 42792 solver.cpp:244]     Train net output #1: loss = 0.014944 (* 1 = 0.014944 loss)
I0824 19:06:28.845481 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995002
I0824 19:06:28.845487 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990953
I0824 19:06:28.845495 42792 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0824 19:06:45.588141 42792 solver.cpp:228] Iteration 2640, loss = 0.0339496
I0824 19:06:45.588243 42792 solver.cpp:244]     Train net output #0: accuracy = 0.989142
I0824 19:06:45.588261 42792 solver.cpp:244]     Train net output #1: loss = 0.0339498 (* 1 = 0.0339498 loss)
I0824 19:06:45.588269 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987733
I0824 19:06:45.588274 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990748
I0824 19:06:45.588282 42792 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0824 19:07:02.243605 42792 solver.cpp:228] Iteration 2660, loss = 0.0167983
I0824 19:07:02.243654 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993267
I0824 19:07:02.243669 42792 solver.cpp:244]     Train net output #1: loss = 0.0167985 (* 1 = 0.0167985 loss)
I0824 19:07:02.243676 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994089
I0824 19:07:02.243682 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990201
I0824 19:07:02.243692 42792 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0824 19:07:18.913723 42792 solver.cpp:228] Iteration 2680, loss = 0.016029
I0824 19:07:18.913882 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992962
I0824 19:07:18.913908 42792 solver.cpp:244]     Train net output #1: loss = 0.0160291 (* 1 = 0.0160291 loss)
I0824 19:07:18.913916 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992363
I0824 19:07:18.913921 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994594
I0824 19:07:18.913928 42792 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0824 19:07:35.570924 42792 solver.cpp:228] Iteration 2700, loss = 0.0188957
I0824 19:07:35.570973 42792 solver.cpp:244]     Train net output #0: accuracy = 0.991173
I0824 19:07:35.570989 42792 solver.cpp:244]     Train net output #1: loss = 0.0188958 (* 1 = 0.0188958 loss)
I0824 19:07:35.570996 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988524
I0824 19:07:35.571002 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996833
I0824 19:07:35.571012 42792 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0824 19:07:52.261807 42792 solver.cpp:228] Iteration 2720, loss = 0.0107314
I0824 19:07:52.261915 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995943
I0824 19:07:52.261931 42792 solver.cpp:244]     Train net output #1: loss = 0.0107316 (* 1 = 0.0107316 loss)
I0824 19:07:52.261940 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996602
I0824 19:07:52.261945 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993972
I0824 19:07:52.261953 42792 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0824 19:08:08.953651 42792 solver.cpp:228] Iteration 2740, loss = 0.015721
I0824 19:08:08.953699 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994358
I0824 19:08:08.953716 42792 solver.cpp:244]     Train net output #1: loss = 0.0157212 (* 1 = 0.0157212 loss)
I0824 19:08:08.953722 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995327
I0824 19:08:08.953728 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989138
I0824 19:08:08.953737 42792 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0824 19:08:25.612201 42792 solver.cpp:228] Iteration 2760, loss = 0.0194502
I0824 19:08:25.612318 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993964
I0824 19:08:25.612336 42792 solver.cpp:244]     Train net output #1: loss = 0.0194503 (* 1 = 0.0194503 loss)
I0824 19:08:25.612347 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993764
I0824 19:08:25.612360 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994207
I0824 19:08:25.612366 42792 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0824 19:08:42.267653 42792 solver.cpp:228] Iteration 2780, loss = 0.0221987
I0824 19:08:42.267699 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992295
I0824 19:08:42.267712 42792 solver.cpp:244]     Train net output #1: loss = 0.0221988 (* 1 = 0.0221988 loss)
I0824 19:08:42.267720 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992525
I0824 19:08:42.267725 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991401
I0824 19:08:42.267734 42792 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0824 19:08:58.937772 42792 solver.cpp:228] Iteration 2800, loss = 0.0117569
I0824 19:08:58.937940 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995558
I0824 19:08:58.937968 42792 solver.cpp:244]     Train net output #1: loss = 0.0117571 (* 1 = 0.0117571 loss)
I0824 19:08:58.937978 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995893
I0824 19:08:58.937983 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994755
I0824 19:08:58.937993 42792 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0824 19:09:15.609139 42792 solver.cpp:228] Iteration 2820, loss = 0.0117654
I0824 19:09:15.609184 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996192
I0824 19:09:15.609199 42792 solver.cpp:244]     Train net output #1: loss = 0.0117655 (* 1 = 0.0117655 loss)
I0824 19:09:15.609205 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995882
I0824 19:09:15.609210 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99683
I0824 19:09:15.609218 42792 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0824 19:09:32.281065 42792 solver.cpp:228] Iteration 2840, loss = 0.0139214
I0824 19:09:32.281184 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994983
I0824 19:09:32.281203 42792 solver.cpp:244]     Train net output #1: loss = 0.0139215 (* 1 = 0.0139215 loss)
I0824 19:09:32.281213 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995445
I0824 19:09:32.281225 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993421
I0824 19:09:32.281234 42792 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0824 19:09:48.946895 42792 solver.cpp:228] Iteration 2860, loss = 0.0199159
I0824 19:09:48.946940 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99337
I0824 19:09:48.946955 42792 solver.cpp:244]     Train net output #1: loss = 0.019916 (* 1 = 0.019916 loss)
I0824 19:09:48.946962 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990174
I0824 19:09:48.946967 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996632
I0824 19:09:48.946975 42792 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0824 19:10:05.614181 42792 solver.cpp:228] Iteration 2880, loss = 0.0121675
I0824 19:10:05.614287 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995058
I0824 19:10:05.614305 42792 solver.cpp:244]     Train net output #1: loss = 0.0121676 (* 1 = 0.0121676 loss)
I0824 19:10:05.614311 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995408
I0824 19:10:05.614316 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993467
I0824 19:10:05.614325 42792 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0824 19:10:22.279072 42792 solver.cpp:228] Iteration 2900, loss = 0.00981272
I0824 19:10:22.279121 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996195
I0824 19:10:22.279136 42792 solver.cpp:244]     Train net output #1: loss = 0.00981287 (* 1 = 0.00981287 loss)
I0824 19:10:22.279145 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996258
I0824 19:10:22.279150 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996053
I0824 19:10:22.279158 42792 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0824 19:10:38.946177 42792 solver.cpp:228] Iteration 2920, loss = 0.0203387
I0824 19:10:38.946285 42792 solver.cpp:244]     Train net output #0: accuracy = 0.990893
I0824 19:10:38.946303 42792 solver.cpp:244]     Train net output #1: loss = 0.0203388 (* 1 = 0.0203388 loss)
I0824 19:10:38.946317 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98716
I0824 19:10:38.946328 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9977
I0824 19:10:38.946336 42792 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0824 19:10:55.614923 42792 solver.cpp:228] Iteration 2940, loss = 0.0294373
I0824 19:10:55.614969 42792 solver.cpp:244]     Train net output #0: accuracy = 0.988261
I0824 19:10:55.614984 42792 solver.cpp:244]     Train net output #1: loss = 0.0294374 (* 1 = 0.0294374 loss)
I0824 19:10:55.614998 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987228
I0824 19:10:55.615005 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991844
I0824 19:10:55.615012 42792 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0824 19:11:12.256036 42792 solver.cpp:228] Iteration 2960, loss = 0.0161097
I0824 19:11:12.256196 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993882
I0824 19:11:12.256217 42792 solver.cpp:244]     Train net output #1: loss = 0.0161098 (* 1 = 0.0161098 loss)
I0824 19:11:12.256224 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993689
I0824 19:11:12.256229 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994347
I0824 19:11:12.256235 42792 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0824 19:11:28.901758 42792 solver.cpp:228] Iteration 2980, loss = 0.0162109
I0824 19:11:28.901804 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993034
I0824 19:11:28.901819 42792 solver.cpp:244]     Train net output #1: loss = 0.016211 (* 1 = 0.016211 loss)
I0824 19:11:28.901826 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992049
I0824 19:11:28.901831 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995035
I0824 19:11:28.901840 42792 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0824 19:11:45.540381 42792 solver.cpp:228] Iteration 3000, loss = 0.0146545
I0824 19:11:45.540490 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99401
I0824 19:11:45.540506 42792 solver.cpp:244]     Train net output #1: loss = 0.0146546 (* 1 = 0.0146546 loss)
I0824 19:11:45.540513 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993597
I0824 19:11:45.540519 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995365
I0824 19:11:45.540527 42792 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0824 19:12:02.184995 42792 solver.cpp:228] Iteration 3020, loss = 0.0145066
I0824 19:12:02.185036 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994197
I0824 19:12:02.185050 42792 solver.cpp:244]     Train net output #1: loss = 0.0145068 (* 1 = 0.0145068 loss)
I0824 19:12:02.185055 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992979
I0824 19:12:02.185060 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997972
I0824 19:12:02.185067 42792 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0824 19:12:18.847338 42792 solver.cpp:228] Iteration 3040, loss = 0.0215585
I0824 19:12:18.847460 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99031
I0824 19:12:18.847477 42792 solver.cpp:244]     Train net output #1: loss = 0.0215586 (* 1 = 0.0215586 loss)
I0824 19:12:18.847491 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988899
I0824 19:12:18.847501 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993859
I0824 19:12:18.847509 42792 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0824 19:12:35.482815 42792 solver.cpp:228] Iteration 3060, loss = 0.0152867
I0824 19:12:35.482856 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993996
I0824 19:12:35.482869 42792 solver.cpp:244]     Train net output #1: loss = 0.0152868 (* 1 = 0.0152868 loss)
I0824 19:12:35.482875 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995566
I0824 19:12:35.482880 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989041
I0824 19:12:35.482887 42792 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0824 19:12:52.131120 42792 solver.cpp:228] Iteration 3080, loss = 0.0457701
I0824 19:12:52.131232 42792 solver.cpp:244]     Train net output #0: accuracy = 0.982506
I0824 19:12:52.131247 42792 solver.cpp:244]     Train net output #1: loss = 0.0457702 (* 1 = 0.0457702 loss)
I0824 19:12:52.131254 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979182
I0824 19:12:52.131260 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991856
I0824 19:12:52.131268 42792 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0824 19:13:08.770491 42792 solver.cpp:228] Iteration 3100, loss = 0.0223365
I0824 19:13:08.770532 42792 solver.cpp:244]     Train net output #0: accuracy = 0.98935
I0824 19:13:08.770545 42792 solver.cpp:244]     Train net output #1: loss = 0.0223366 (* 1 = 0.0223366 loss)
I0824 19:13:08.770551 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983494
I0824 19:13:08.770556 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998752
I0824 19:13:08.770563 42792 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0824 19:13:25.436442 42792 solver.cpp:228] Iteration 3120, loss = 0.0150892
I0824 19:13:25.436607 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994784
I0824 19:13:25.436624 42792 solver.cpp:244]     Train net output #1: loss = 0.0150893 (* 1 = 0.0150893 loss)
I0824 19:13:25.436635 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996163
I0824 19:13:25.436640 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990559
I0824 19:13:25.436647 42792 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0824 19:13:42.088407 42792 solver.cpp:228] Iteration 3140, loss = 0.0198124
I0824 19:13:42.088454 42792 solver.cpp:244]     Train net output #0: accuracy = 0.990492
I0824 19:13:42.088469 42792 solver.cpp:244]     Train net output #1: loss = 0.0198125 (* 1 = 0.0198125 loss)
I0824 19:13:42.088476 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988683
I0824 19:13:42.088490 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995642
I0824 19:13:42.088498 42792 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0824 19:13:58.746641 42792 solver.cpp:228] Iteration 3160, loss = 0.0224468
I0824 19:13:58.746748 42792 solver.cpp:244]     Train net output #0: accuracy = 0.991311
I0824 19:13:58.746762 42792 solver.cpp:244]     Train net output #1: loss = 0.0224469 (* 1 = 0.0224469 loss)
I0824 19:13:58.746768 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986051
I0824 19:13:58.746773 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998397
I0824 19:13:58.746780 42792 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0824 19:14:15.389871 42792 solver.cpp:228] Iteration 3180, loss = 0.022445
I0824 19:14:15.389916 42792 solver.cpp:244]     Train net output #0: accuracy = 0.990647
I0824 19:14:15.389931 42792 solver.cpp:244]     Train net output #1: loss = 0.0224452 (* 1 = 0.0224452 loss)
I0824 19:14:15.389940 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986224
I0824 19:14:15.389945 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996843
I0824 19:14:15.389953 42792 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0824 19:14:32.036053 42792 solver.cpp:228] Iteration 3200, loss = 0.0145115
I0824 19:14:32.036166 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994758
I0824 19:14:32.036181 42792 solver.cpp:244]     Train net output #1: loss = 0.0145116 (* 1 = 0.0145116 loss)
I0824 19:14:32.036187 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995621
I0824 19:14:32.036192 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992239
I0824 19:14:32.036201 42792 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0824 19:14:48.685865 42792 solver.cpp:228] Iteration 3220, loss = 0.0104958
I0824 19:14:48.685910 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996434
I0824 19:14:48.685925 42792 solver.cpp:244]     Train net output #1: loss = 0.010496 (* 1 = 0.010496 loss)
I0824 19:14:48.685932 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996876
I0824 19:14:48.685946 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992901
I0824 19:14:48.685956 42792 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0824 19:15:05.338676 42792 solver.cpp:228] Iteration 3240, loss = 0.0246046
I0824 19:15:05.338773 42792 solver.cpp:244]     Train net output #0: accuracy = 0.991586
I0824 19:15:05.338788 42792 solver.cpp:244]     Train net output #1: loss = 0.0246047 (* 1 = 0.0246047 loss)
I0824 19:15:05.338795 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990734
I0824 19:15:05.338801 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994257
I0824 19:15:05.338809 42792 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0824 19:15:21.989418 42792 solver.cpp:228] Iteration 3260, loss = 0.015194
I0824 19:15:21.989459 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994975
I0824 19:15:21.989472 42792 solver.cpp:244]     Train net output #1: loss = 0.0151941 (* 1 = 0.0151941 loss)
I0824 19:15:21.989478 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994705
I0824 19:15:21.989483 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995389
I0824 19:15:21.989490 42792 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0824 19:15:38.636077 42792 solver.cpp:228] Iteration 3280, loss = 0.017811
I0824 19:15:38.636237 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993371
I0824 19:15:38.636255 42792 solver.cpp:244]     Train net output #1: loss = 0.0178112 (* 1 = 0.0178112 loss)
I0824 19:15:38.636266 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994017
I0824 19:15:38.636277 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991708
I0824 19:15:38.636286 42792 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0824 19:15:55.273519 42792 solver.cpp:228] Iteration 3300, loss = 0.0140992
I0824 19:15:55.273561 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994547
I0824 19:15:55.273573 42792 solver.cpp:244]     Train net output #1: loss = 0.0140994 (* 1 = 0.0140994 loss)
I0824 19:15:55.273579 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993256
I0824 19:15:55.273584 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996405
I0824 19:15:55.273591 42792 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0824 19:16:11.913051 42792 solver.cpp:228] Iteration 3320, loss = 0.0150702
I0824 19:16:11.913168 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994465
I0824 19:16:11.913184 42792 solver.cpp:244]     Train net output #1: loss = 0.0150703 (* 1 = 0.0150703 loss)
I0824 19:16:11.913190 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995689
I0824 19:16:11.913197 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991196
I0824 19:16:11.913204 42792 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0824 19:16:28.558563 42792 solver.cpp:228] Iteration 3340, loss = 0.00879739
I0824 19:16:28.558606 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996373
I0824 19:16:28.558620 42792 solver.cpp:244]     Train net output #1: loss = 0.00879753 (* 1 = 0.00879753 loss)
I0824 19:16:28.558626 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996072
I0824 19:16:28.558632 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997095
I0824 19:16:28.558640 42792 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0824 19:16:45.205317 42792 solver.cpp:228] Iteration 3360, loss = 0.0133707
I0824 19:16:45.205430 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99556
I0824 19:16:45.205446 42792 solver.cpp:244]     Train net output #1: loss = 0.0133709 (* 1 = 0.0133709 loss)
I0824 19:16:45.205452 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99593
I0824 19:16:45.205457 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994613
I0824 19:16:45.205464 42792 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0824 19:17:01.848767 42792 solver.cpp:228] Iteration 3380, loss = 0.0196709
I0824 19:17:01.848814 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992778
I0824 19:17:01.848830 42792 solver.cpp:244]     Train net output #1: loss = 0.0196711 (* 1 = 0.0196711 loss)
I0824 19:17:01.848836 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991975
I0824 19:17:01.848842 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994324
I0824 19:17:01.848850 42792 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0824 19:17:18.497123 42792 solver.cpp:228] Iteration 3400, loss = 0.0214901
I0824 19:17:18.497299 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993937
I0824 19:17:18.497316 42792 solver.cpp:244]     Train net output #1: loss = 0.0214902 (* 1 = 0.0214902 loss)
I0824 19:17:18.497323 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990232
I0824 19:17:18.497328 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997198
I0824 19:17:18.497334 42792 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0824 19:17:35.150868 42792 solver.cpp:228] Iteration 3420, loss = 0.0144861
I0824 19:17:35.150914 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994682
I0824 19:17:35.150929 42792 solver.cpp:244]     Train net output #1: loss = 0.0144863 (* 1 = 0.0144863 loss)
I0824 19:17:35.150938 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995215
I0824 19:17:35.150944 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992986
I0824 19:17:35.150952 42792 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0824 19:17:51.813374 42792 solver.cpp:228] Iteration 3440, loss = 0.0128362
I0824 19:17:51.813490 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994175
I0824 19:17:51.813505 42792 solver.cpp:244]     Train net output #1: loss = 0.0128364 (* 1 = 0.0128364 loss)
I0824 19:17:51.813511 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993848
I0824 19:17:51.813518 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995484
I0824 19:17:51.813524 42792 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0824 19:18:08.470741 42792 solver.cpp:228] Iteration 3460, loss = 0.0138258
I0824 19:18:08.470784 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995094
I0824 19:18:08.470799 42792 solver.cpp:244]     Train net output #1: loss = 0.0138259 (* 1 = 0.0138259 loss)
I0824 19:18:08.470806 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996482
I0824 19:18:08.470813 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990252
I0824 19:18:08.470821 42792 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0824 19:18:25.121183 42792 solver.cpp:228] Iteration 3480, loss = 0.0100588
I0824 19:18:25.121296 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996238
I0824 19:18:25.121311 42792 solver.cpp:244]     Train net output #1: loss = 0.010059 (* 1 = 0.010059 loss)
I0824 19:18:25.121318 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996701
I0824 19:18:25.121325 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99517
I0824 19:18:25.121332 42792 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0824 19:18:41.780563 42792 solver.cpp:228] Iteration 3500, loss = 0.0192541
I0824 19:18:41.780601 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992998
I0824 19:18:41.780614 42792 solver.cpp:244]     Train net output #1: loss = 0.0192542 (* 1 = 0.0192542 loss)
I0824 19:18:41.780622 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992285
I0824 19:18:41.780627 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99404
I0824 19:18:41.780633 42792 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0824 19:18:58.455768 42792 solver.cpp:228] Iteration 3520, loss = 0.0136851
I0824 19:18:58.455893 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994436
I0824 19:18:58.455910 42792 solver.cpp:244]     Train net output #1: loss = 0.0136852 (* 1 = 0.0136852 loss)
I0824 19:18:58.455924 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993396
I0824 19:18:58.455935 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996534
I0824 19:18:58.455950 42792 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0824 19:19:15.130874 42792 solver.cpp:228] Iteration 3540, loss = 0.015175
I0824 19:19:15.130925 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993981
I0824 19:19:15.130941 42792 solver.cpp:244]     Train net output #1: loss = 0.0151751 (* 1 = 0.0151751 loss)
I0824 19:19:15.130949 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991169
I0824 19:19:15.130956 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997821
I0824 19:19:15.130964 42792 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0824 19:19:31.801820 42792 solver.cpp:228] Iteration 3560, loss = 0.0117055
I0824 19:19:31.802003 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995148
I0824 19:19:31.802023 42792 solver.cpp:244]     Train net output #1: loss = 0.0117056 (* 1 = 0.0117056 loss)
I0824 19:19:31.802032 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9947
I0824 19:19:31.802043 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996469
I0824 19:19:31.802052 42792 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0824 19:19:48.474221 42792 solver.cpp:228] Iteration 3580, loss = 0.0126757
I0824 19:19:48.474268 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995681
I0824 19:19:48.474282 42792 solver.cpp:244]     Train net output #1: loss = 0.0126759 (* 1 = 0.0126759 loss)
I0824 19:19:48.474289 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995655
I0824 19:19:48.474294 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995825
I0824 19:19:48.474303 42792 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0824 19:20:05.157363 42792 solver.cpp:228] Iteration 3600, loss = 0.014247
I0824 19:20:05.157493 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99446
I0824 19:20:05.157511 42792 solver.cpp:244]     Train net output #1: loss = 0.0142471 (* 1 = 0.0142471 loss)
I0824 19:20:05.157526 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994344
I0824 19:20:05.157536 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994778
I0824 19:20:05.157544 42792 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0824 19:20:21.816318 42792 solver.cpp:228] Iteration 3620, loss = 0.0190641
I0824 19:20:21.816361 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992128
I0824 19:20:21.816376 42792 solver.cpp:244]     Train net output #1: loss = 0.0190642 (* 1 = 0.0190642 loss)
I0824 19:20:21.816383 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991498
I0824 19:20:21.816390 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993871
I0824 19:20:21.816396 42792 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0824 19:20:38.485456 42792 solver.cpp:228] Iteration 3640, loss = 0.0152045
I0824 19:20:38.485580 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996746
I0824 19:20:38.485599 42792 solver.cpp:244]     Train net output #1: loss = 0.0152046 (* 1 = 0.0152046 loss)
I0824 19:20:38.485610 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996788
I0824 19:20:38.485621 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995906
I0824 19:20:38.485630 42792 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0824 19:20:55.146736 42792 solver.cpp:228] Iteration 3660, loss = 0.015583
I0824 19:20:55.146781 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994611
I0824 19:20:55.146795 42792 solver.cpp:244]     Train net output #1: loss = 0.0155831 (* 1 = 0.0155831 loss)
I0824 19:20:55.146802 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995966
I0824 19:20:55.146816 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99046
I0824 19:20:55.146823 42792 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0824 19:21:11.812815 42792 solver.cpp:228] Iteration 3680, loss = 0.0223632
I0824 19:21:11.812937 42792 solver.cpp:244]     Train net output #0: accuracy = 0.991769
I0824 19:21:11.812954 42792 solver.cpp:244]     Train net output #1: loss = 0.0223634 (* 1 = 0.0223634 loss)
I0824 19:21:11.812969 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98914
I0824 19:21:11.812981 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996125
I0824 19:21:11.812990 42792 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0824 19:21:28.464293 42792 solver.cpp:228] Iteration 3700, loss = 0.0178125
I0824 19:21:28.464336 42792 solver.cpp:244]     Train net output #0: accuracy = 0.991887
I0824 19:21:28.464350 42792 solver.cpp:244]     Train net output #1: loss = 0.0178126 (* 1 = 0.0178126 loss)
I0824 19:21:28.464356 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989597
I0824 19:21:28.464361 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996359
I0824 19:21:28.464368 42792 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0824 19:21:45.119434 42792 solver.cpp:228] Iteration 3720, loss = 0.011046
I0824 19:21:45.119614 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995775
I0824 19:21:45.119632 42792 solver.cpp:244]     Train net output #1: loss = 0.0110461 (* 1 = 0.0110461 loss)
I0824 19:21:45.119642 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996068
I0824 19:21:45.119654 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994919
I0824 19:21:45.119663 42792 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0824 19:22:01.770370 42792 solver.cpp:228] Iteration 3740, loss = 0.00903373
I0824 19:22:01.770414 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996029
I0824 19:22:01.770428 42792 solver.cpp:244]     Train net output #1: loss = 0.00903387 (* 1 = 0.00903387 loss)
I0824 19:22:01.770436 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99558
I0824 19:22:01.770442 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997261
I0824 19:22:01.770448 42792 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0824 19:22:18.435886 42792 solver.cpp:228] Iteration 3760, loss = 0.012199
I0824 19:22:18.436005 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994983
I0824 19:22:18.436020 42792 solver.cpp:244]     Train net output #1: loss = 0.0121991 (* 1 = 0.0121991 loss)
I0824 19:22:18.436028 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995195
I0824 19:22:18.436033 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994202
I0824 19:22:18.436041 42792 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0824 19:22:35.089088 42792 solver.cpp:228] Iteration 3780, loss = 0.00727848
I0824 19:22:35.089134 42792 solver.cpp:244]     Train net output #0: accuracy = 0.997151
I0824 19:22:35.089148 42792 solver.cpp:244]     Train net output #1: loss = 0.00727863 (* 1 = 0.00727863 loss)
I0824 19:22:35.089156 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997555
I0824 19:22:35.089169 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995649
I0824 19:22:35.089176 42792 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0824 19:22:51.745625 42792 solver.cpp:228] Iteration 3800, loss = 0.00799836
I0824 19:22:51.745730 42792 solver.cpp:244]     Train net output #0: accuracy = 0.9968
I0824 19:22:51.745745 42792 solver.cpp:244]     Train net output #1: loss = 0.0079985 (* 1 = 0.0079985 loss)
I0824 19:22:51.745751 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996956
I0824 19:22:51.745756 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995867
I0824 19:22:51.745764 42792 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0824 19:23:08.405819 42792 solver.cpp:228] Iteration 3820, loss = 0.0121045
I0824 19:23:08.405864 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995006
I0824 19:23:08.405879 42792 solver.cpp:244]     Train net output #1: loss = 0.0121047 (* 1 = 0.0121047 loss)
I0824 19:23:08.405887 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993703
I0824 19:23:08.405894 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998267
I0824 19:23:08.405901 42792 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0824 19:23:25.061825 42792 solver.cpp:228] Iteration 3840, loss = 0.0122462
I0824 19:23:25.061929 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995482
I0824 19:23:25.061945 42792 solver.cpp:244]     Train net output #1: loss = 0.0122463 (* 1 = 0.0122463 loss)
I0824 19:23:25.061951 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99547
I0824 19:23:25.061956 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995553
I0824 19:23:25.061964 42792 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0824 19:23:41.713322 42792 solver.cpp:228] Iteration 3860, loss = 0.0182978
I0824 19:23:41.713374 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992569
I0824 19:23:41.713389 42792 solver.cpp:244]     Train net output #1: loss = 0.0182979 (* 1 = 0.0182979 loss)
I0824 19:23:41.713398 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991884
I0824 19:23:41.713403 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994326
I0824 19:23:41.713413 42792 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0824 19:23:58.363236 42792 solver.cpp:228] Iteration 3880, loss = 0.0137682
I0824 19:23:58.363404 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994842
I0824 19:23:58.363420 42792 solver.cpp:244]     Train net output #1: loss = 0.0137684 (* 1 = 0.0137684 loss)
I0824 19:23:58.363426 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993262
I0824 19:23:58.363431 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99773
I0824 19:23:58.363440 42792 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0824 19:24:15.021894 42792 solver.cpp:228] Iteration 3900, loss = 0.0166576
I0824 19:24:15.021944 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993503
I0824 19:24:15.021957 42792 solver.cpp:244]     Train net output #1: loss = 0.0166577 (* 1 = 0.0166577 loss)
I0824 19:24:15.021965 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992422
I0824 19:24:15.021978 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99592
I0824 19:24:15.021986 42792 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0824 19:24:31.690145 42792 solver.cpp:228] Iteration 3920, loss = 0.0100806
I0824 19:24:31.690249 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995661
I0824 19:24:31.690265 42792 solver.cpp:244]     Train net output #1: loss = 0.0100807 (* 1 = 0.0100807 loss)
I0824 19:24:31.690274 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995828
I0824 19:24:31.690279 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99503
I0824 19:24:31.690287 42792 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0824 19:24:48.339305 42792 solver.cpp:228] Iteration 3940, loss = 0.0174893
I0824 19:24:48.339347 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994178
I0824 19:24:48.339362 42792 solver.cpp:244]     Train net output #1: loss = 0.0174895 (* 1 = 0.0174895 loss)
I0824 19:24:48.339370 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991501
I0824 19:24:48.339375 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997109
I0824 19:24:48.339382 42792 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0824 19:25:04.997464 42792 solver.cpp:228] Iteration 3960, loss = 0.0151307
I0824 19:25:04.997586 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99569
I0824 19:25:04.997603 42792 solver.cpp:244]     Train net output #1: loss = 0.0151308 (* 1 = 0.0151308 loss)
I0824 19:25:04.997611 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993686
I0824 19:25:04.997617 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997616
I0824 19:25:04.997632 42792 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0824 19:25:21.658280 42792 solver.cpp:228] Iteration 3980, loss = 0.0166762
I0824 19:25:21.658323 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994679
I0824 19:25:21.658336 42792 solver.cpp:244]     Train net output #1: loss = 0.0166764 (* 1 = 0.0166764 loss)
I0824 19:25:21.658344 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995421
I0824 19:25:21.658349 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991676
I0824 19:25:21.658357 42792 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0824 19:25:38.329613 42792 solver.cpp:228] Iteration 4000, loss = 0.0169918
I0824 19:25:38.329777 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99363
I0824 19:25:38.329794 42792 solver.cpp:244]     Train net output #1: loss = 0.0169919 (* 1 = 0.0169919 loss)
I0824 19:25:38.329802 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992278
I0824 19:25:38.329807 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996329
I0824 19:25:38.329823 42792 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0824 19:25:54.991257 42792 solver.cpp:228] Iteration 4020, loss = 0.0160511
I0824 19:25:54.991298 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994703
I0824 19:25:54.991312 42792 solver.cpp:244]     Train net output #1: loss = 0.0160513 (* 1 = 0.0160513 loss)
I0824 19:25:54.991317 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994765
I0824 19:25:54.991322 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994615
I0824 19:25:54.991330 42792 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0824 19:26:11.657331 42792 solver.cpp:228] Iteration 4040, loss = 0.0110692
I0824 19:26:11.657475 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995535
I0824 19:26:11.657492 42792 solver.cpp:244]     Train net output #1: loss = 0.0110693 (* 1 = 0.0110693 loss)
I0824 19:26:11.657505 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996206
I0824 19:26:11.657516 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992905
I0824 19:26:11.657524 42792 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0824 19:26:28.300073 42792 solver.cpp:228] Iteration 4060, loss = 0.0207452
I0824 19:26:28.300115 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992413
I0824 19:26:28.300128 42792 solver.cpp:244]     Train net output #1: loss = 0.0207453 (* 1 = 0.0207453 loss)
I0824 19:26:28.300134 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990518
I0824 19:26:28.300139 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996263
I0824 19:26:28.300148 42792 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0824 19:26:44.946197 42792 solver.cpp:228] Iteration 4080, loss = 0.0102866
I0824 19:26:44.946318 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996166
I0824 19:26:44.946334 42792 solver.cpp:244]     Train net output #1: loss = 0.0102868 (* 1 = 0.0102868 loss)
I0824 19:26:44.946346 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997091
I0824 19:26:44.946358 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991772
I0824 19:26:44.946367 42792 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0824 19:27:01.597882 42792 solver.cpp:228] Iteration 4100, loss = 0.0138884
I0824 19:27:01.597926 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994667
I0824 19:27:01.597940 42792 solver.cpp:244]     Train net output #1: loss = 0.0138885 (* 1 = 0.0138885 loss)
I0824 19:27:01.597947 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994615
I0824 19:27:01.597954 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994825
I0824 19:27:01.597962 42792 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0824 19:27:18.257568 42792 solver.cpp:228] Iteration 4120, loss = 0.0142864
I0824 19:27:18.257686 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994184
I0824 19:27:18.257701 42792 solver.cpp:244]     Train net output #1: loss = 0.0142865 (* 1 = 0.0142865 loss)
I0824 19:27:18.257709 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991589
I0824 19:27:18.257714 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998084
I0824 19:27:18.257722 42792 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0824 19:27:34.923887 42792 solver.cpp:228] Iteration 4140, loss = 0.0182244
I0824 19:27:34.923930 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992561
I0824 19:27:34.923945 42792 solver.cpp:244]     Train net output #1: loss = 0.0182246 (* 1 = 0.0182246 loss)
I0824 19:27:34.923952 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990683
I0824 19:27:34.923959 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995439
I0824 19:27:34.923966 42792 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0824 19:27:51.583886 42792 solver.cpp:228] Iteration 4160, loss = 0.00779111
I0824 19:27:51.584065 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996836
I0824 19:27:51.584082 42792 solver.cpp:244]     Train net output #1: loss = 0.00779126 (* 1 = 0.00779126 loss)
I0824 19:27:51.584094 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99705
I0824 19:27:51.584105 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995808
I0824 19:27:51.584115 42792 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0824 19:28:08.238880 42792 solver.cpp:228] Iteration 4180, loss = 0.0102225
I0824 19:28:08.238925 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995498
I0824 19:28:08.238940 42792 solver.cpp:244]     Train net output #1: loss = 0.0102226 (* 1 = 0.0102226 loss)
I0824 19:28:08.238947 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99416
I0824 19:28:08.238960 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99838
I0824 19:28:08.238968 42792 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0824 19:28:24.891261 42792 solver.cpp:228] Iteration 4200, loss = 0.0246047
I0824 19:28:24.891377 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99171
I0824 19:28:24.891392 42792 solver.cpp:244]     Train net output #1: loss = 0.0246049 (* 1 = 0.0246049 loss)
I0824 19:28:24.891398 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988841
I0824 19:28:24.891403 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995272
I0824 19:28:24.891410 42792 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0824 19:28:41.552448 42792 solver.cpp:228] Iteration 4220, loss = 0.0131099
I0824 19:28:41.552491 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995932
I0824 19:28:41.552506 42792 solver.cpp:244]     Train net output #1: loss = 0.0131101 (* 1 = 0.0131101 loss)
I0824 19:28:41.552515 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997743
I0824 19:28:41.552528 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988097
I0824 19:28:41.552536 42792 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0824 19:28:58.214366 42792 solver.cpp:228] Iteration 4240, loss = 0.0120307
I0824 19:28:58.214480 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995081
I0824 19:28:58.214495 42792 solver.cpp:244]     Train net output #1: loss = 0.0120309 (* 1 = 0.0120309 loss)
I0824 19:28:58.214501 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994654
I0824 19:28:58.214506 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996452
I0824 19:28:58.214514 42792 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0824 19:29:14.860831 42792 solver.cpp:228] Iteration 4260, loss = 0.0104975
I0824 19:29:14.860878 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995506
I0824 19:29:14.860893 42792 solver.cpp:244]     Train net output #1: loss = 0.0104977 (* 1 = 0.0104977 loss)
I0824 19:29:14.860900 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995267
I0824 19:29:14.860916 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996144
I0824 19:29:14.860929 42792 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0824 19:29:31.521987 42792 solver.cpp:228] Iteration 4280, loss = 0.00886307
I0824 19:29:31.522102 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996505
I0824 19:29:31.522119 42792 solver.cpp:244]     Train net output #1: loss = 0.00886321 (* 1 = 0.00886321 loss)
I0824 19:29:31.522132 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99643
I0824 19:29:31.522138 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99666
I0824 19:29:31.522146 42792 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0824 19:29:48.180030 42792 solver.cpp:228] Iteration 4300, loss = 0.0065707
I0824 19:29:48.180073 42792 solver.cpp:244]     Train net output #0: accuracy = 0.997203
I0824 19:29:48.180086 42792 solver.cpp:244]     Train net output #1: loss = 0.00657084 (* 1 = 0.00657084 loss)
I0824 19:29:48.180093 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996705
I0824 19:29:48.180099 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998398
I0824 19:29:48.180107 42792 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0824 19:30:04.822978 42792 solver.cpp:228] Iteration 4320, loss = 0.0142362
I0824 19:30:04.823144 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994436
I0824 19:30:04.823161 42792 solver.cpp:244]     Train net output #1: loss = 0.0142364 (* 1 = 0.0142364 loss)
I0824 19:30:04.823173 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994283
I0824 19:30:04.823179 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994758
I0824 19:30:04.823187 42792 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0824 19:30:21.465782 42792 solver.cpp:228] Iteration 4340, loss = 0.0100287
I0824 19:30:21.465826 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995596
I0824 19:30:21.465839 42792 solver.cpp:244]     Train net output #1: loss = 0.0100289 (* 1 = 0.0100289 loss)
I0824 19:30:21.465847 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993987
I0824 19:30:21.465860 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998657
I0824 19:30:21.465875 42792 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0824 19:30:38.111662 42792 solver.cpp:228] Iteration 4360, loss = 0.0119328
I0824 19:30:38.111783 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995289
I0824 19:30:38.111799 42792 solver.cpp:244]     Train net output #1: loss = 0.0119329 (* 1 = 0.0119329 loss)
I0824 19:30:38.111812 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995104
I0824 19:30:38.111824 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995773
I0824 19:30:38.111832 42792 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0824 19:30:54.765384 42792 solver.cpp:228] Iteration 4380, loss = 0.0142081
I0824 19:30:54.765427 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995315
I0824 19:30:54.765439 42792 solver.cpp:244]     Train net output #1: loss = 0.0142083 (* 1 = 0.0142083 loss)
I0824 19:30:54.765444 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993893
I0824 19:30:54.765450 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998665
I0824 19:30:54.765456 42792 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0824 19:31:11.411376 42792 solver.cpp:228] Iteration 4400, loss = 0.0133731
I0824 19:31:11.411489 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994928
I0824 19:31:11.411505 42792 solver.cpp:244]     Train net output #1: loss = 0.0133733 (* 1 = 0.0133733 loss)
I0824 19:31:11.411512 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994699
I0824 19:31:11.411519 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995522
I0824 19:31:11.411526 42792 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0824 19:31:28.073621 42792 solver.cpp:228] Iteration 4420, loss = 0.0214383
I0824 19:31:28.073662 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992352
I0824 19:31:28.073676 42792 solver.cpp:244]     Train net output #1: loss = 0.0214384 (* 1 = 0.0214384 loss)
I0824 19:31:28.073683 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990283
I0824 19:31:28.073688 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996537
I0824 19:31:28.073694 42792 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0824 19:31:44.732470 42792 solver.cpp:228] Iteration 4440, loss = 0.0166009
I0824 19:31:44.732597 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993854
I0824 19:31:44.732614 42792 solver.cpp:244]     Train net output #1: loss = 0.0166011 (* 1 = 0.0166011 loss)
I0824 19:31:44.732627 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991368
I0824 19:31:44.732638 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997232
I0824 19:31:44.732647 42792 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0824 19:32:01.404534 42792 solver.cpp:228] Iteration 4460, loss = 0.0121957
I0824 19:32:01.404579 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995564
I0824 19:32:01.404594 42792 solver.cpp:244]     Train net output #1: loss = 0.0121958 (* 1 = 0.0121958 loss)
I0824 19:32:01.404602 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995608
I0824 19:32:01.404608 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995458
I0824 19:32:01.404614 42792 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0824 19:32:18.043340 42792 solver.cpp:228] Iteration 4480, loss = 0.0222223
I0824 19:32:18.043505 42792 solver.cpp:244]     Train net output #0: accuracy = 0.992248
I0824 19:32:18.043522 42792 solver.cpp:244]     Train net output #1: loss = 0.0222224 (* 1 = 0.0222224 loss)
I0824 19:32:18.043534 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990897
I0824 19:32:18.043545 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994576
I0824 19:32:18.043555 42792 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0824 19:32:34.700783 42792 solver.cpp:228] Iteration 4500, loss = 0.0102321
I0824 19:32:34.700829 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996157
I0824 19:32:34.700842 42792 solver.cpp:244]     Train net output #1: loss = 0.0102322 (* 1 = 0.0102322 loss)
I0824 19:32:34.700850 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995444
I0824 19:32:34.700855 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99743
I0824 19:32:34.700863 42792 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0824 19:32:51.349769 42792 solver.cpp:228] Iteration 4520, loss = 0.0131625
I0824 19:32:51.349874 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994945
I0824 19:32:51.349889 42792 solver.cpp:244]     Train net output #1: loss = 0.0131626 (* 1 = 0.0131626 loss)
I0824 19:32:51.349895 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994245
I0824 19:32:51.349902 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996369
I0824 19:32:51.349917 42792 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0824 19:33:08.004676 42792 solver.cpp:228] Iteration 4540, loss = 0.00683906
I0824 19:33:08.004721 42792 solver.cpp:244]     Train net output #0: accuracy = 0.997257
I0824 19:33:08.004736 42792 solver.cpp:244]     Train net output #1: loss = 0.0068392 (* 1 = 0.0068392 loss)
I0824 19:33:08.004743 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997631
I0824 19:33:08.004757 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995735
I0824 19:33:08.004765 42792 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0824 19:33:24.659337 42792 solver.cpp:228] Iteration 4560, loss = 0.0101158
I0824 19:33:24.659445 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996403
I0824 19:33:24.659461 42792 solver.cpp:244]     Train net output #1: loss = 0.010116 (* 1 = 0.010116 loss)
I0824 19:33:24.659468 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997085
I0824 19:33:24.659474 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994267
I0824 19:33:24.659482 42792 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0824 19:33:41.309355 42792 solver.cpp:228] Iteration 4580, loss = 0.00911763
I0824 19:33:41.309407 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996667
I0824 19:33:41.309422 42792 solver.cpp:244]     Train net output #1: loss = 0.00911777 (* 1 = 0.00911777 loss)
I0824 19:33:41.309428 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997289
I0824 19:33:41.309434 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993123
I0824 19:33:41.309443 42792 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0824 19:33:57.946717 42792 solver.cpp:228] Iteration 4600, loss = 0.0100619
I0824 19:33:57.946877 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995881
I0824 19:33:57.946900 42792 solver.cpp:244]     Train net output #1: loss = 0.0100621 (* 1 = 0.0100621 loss)
I0824 19:33:57.946908 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995888
I0824 19:33:57.946913 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995863
I0824 19:33:57.946921 42792 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0824 19:34:14.602043 42792 solver.cpp:228] Iteration 4620, loss = 0.0123787
I0824 19:34:14.602092 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994795
I0824 19:34:14.602108 42792 solver.cpp:244]     Train net output #1: loss = 0.0123789 (* 1 = 0.0123789 loss)
I0824 19:34:14.602114 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994705
I0824 19:34:14.602121 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995025
I0824 19:34:14.602130 42792 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0824 19:34:31.243737 42792 solver.cpp:228] Iteration 4640, loss = 0.00916152
I0824 19:34:31.243844 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996441
I0824 19:34:31.243860 42792 solver.cpp:244]     Train net output #1: loss = 0.00916167 (* 1 = 0.00916167 loss)
I0824 19:34:31.243866 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996506
I0824 19:34:31.243872 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996256
I0824 19:34:31.243881 42792 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0824 19:34:47.890890 42792 solver.cpp:228] Iteration 4660, loss = 0.0113287
I0824 19:34:47.890935 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995185
I0824 19:34:47.890950 42792 solver.cpp:244]     Train net output #1: loss = 0.0113289 (* 1 = 0.0113289 loss)
I0824 19:34:47.890957 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995173
I0824 19:34:47.890964 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995214
I0824 19:34:47.890971 42792 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0824 19:35:04.545264 42792 solver.cpp:228] Iteration 4680, loss = 0.00920871
I0824 19:35:04.545387 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995835
I0824 19:35:04.545403 42792 solver.cpp:244]     Train net output #1: loss = 0.00920885 (* 1 = 0.00920885 loss)
I0824 19:35:04.545410 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995714
I0824 19:35:04.545416 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99621
I0824 19:35:04.545424 42792 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0824 19:35:21.191911 42792 solver.cpp:228] Iteration 4700, loss = 0.00964187
I0824 19:35:21.191956 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996369
I0824 19:35:21.191969 42792 solver.cpp:244]     Train net output #1: loss = 0.00964201 (* 1 = 0.00964201 loss)
I0824 19:35:21.191977 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996877
I0824 19:35:21.191982 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994629
I0824 19:35:21.191990 42792 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0824 19:35:37.849742 42792 solver.cpp:228] Iteration 4720, loss = 0.0149211
I0824 19:35:37.849849 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994929
I0824 19:35:37.849864 42792 solver.cpp:244]     Train net output #1: loss = 0.0149212 (* 1 = 0.0149212 loss)
I0824 19:35:37.849874 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99452
I0824 19:35:37.849886 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995898
I0824 19:35:37.849900 42792 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0824 19:35:54.493944 42792 solver.cpp:228] Iteration 4740, loss = 0.00681469
I0824 19:35:54.493986 42792 solver.cpp:244]     Train net output #0: accuracy = 0.997283
I0824 19:35:54.493999 42792 solver.cpp:244]     Train net output #1: loss = 0.00681483 (* 1 = 0.00681483 loss)
I0824 19:35:54.494006 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997569
I0824 19:35:54.494011 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996032
I0824 19:35:54.494019 42792 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0824 19:36:11.131750 42792 solver.cpp:228] Iteration 4760, loss = 0.0148307
I0824 19:36:11.131899 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993845
I0824 19:36:11.131922 42792 solver.cpp:244]     Train net output #1: loss = 0.0148308 (* 1 = 0.0148308 loss)
I0824 19:36:11.131932 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993615
I0824 19:36:11.131942 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994313
I0824 19:36:11.131949 42792 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0824 19:36:27.770282 42792 solver.cpp:228] Iteration 4780, loss = 0.0114834
I0824 19:36:27.770326 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99531
I0824 19:36:27.770340 42792 solver.cpp:244]     Train net output #1: loss = 0.0114836 (* 1 = 0.0114836 loss)
I0824 19:36:27.770349 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994527
I0824 19:36:27.770361 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997291
I0824 19:36:27.770368 42792 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0824 19:36:44.417330 42792 solver.cpp:228] Iteration 4800, loss = 0.0122567
I0824 19:36:44.417443 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994316
I0824 19:36:44.417459 42792 solver.cpp:244]     Train net output #1: loss = 0.0122569 (* 1 = 0.0122569 loss)
I0824 19:36:44.417465 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993061
I0824 19:36:44.417471 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99696
I0824 19:36:44.417479 42792 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0824 19:37:01.061077 42792 solver.cpp:228] Iteration 4820, loss = 0.0197392
I0824 19:37:01.061121 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99261
I0824 19:37:01.061136 42792 solver.cpp:244]     Train net output #1: loss = 0.0197393 (* 1 = 0.0197393 loss)
I0824 19:37:01.061142 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99165
I0824 19:37:01.061148 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994647
I0824 19:37:01.061156 42792 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0824 19:37:17.711948 42792 solver.cpp:228] Iteration 4840, loss = 0.00933929
I0824 19:37:17.712052 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996179
I0824 19:37:17.712067 42792 solver.cpp:244]     Train net output #1: loss = 0.00933943 (* 1 = 0.00933943 loss)
I0824 19:37:17.712074 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995611
I0824 19:37:17.712080 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997489
I0824 19:37:17.712090 42792 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0824 19:37:34.378787 42792 solver.cpp:228] Iteration 4860, loss = 0.0113733
I0824 19:37:34.378835 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99537
I0824 19:37:34.378850 42792 solver.cpp:244]     Train net output #1: loss = 0.0113734 (* 1 = 0.0113734 loss)
I0824 19:37:34.378859 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995777
I0824 19:37:34.378865 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994129
I0824 19:37:34.378872 42792 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0824 19:37:51.063531 42792 solver.cpp:228] Iteration 4880, loss = 0.0112519
I0824 19:37:51.063690 42792 solver.cpp:244]     Train net output #0: accuracy = 0.995784
I0824 19:37:51.063707 42792 solver.cpp:244]     Train net output #1: loss = 0.011252 (* 1 = 0.011252 loss)
I0824 19:37:51.063721 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99486
I0824 19:37:51.063735 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997425
I0824 19:37:51.063745 42792 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0824 19:38:07.712862 42792 solver.cpp:228] Iteration 4900, loss = 0.0108951
I0824 19:38:07.712913 42792 solver.cpp:244]     Train net output #0: accuracy = 0.99571
I0824 19:38:07.712929 42792 solver.cpp:244]     Train net output #1: loss = 0.0108952 (* 1 = 0.0108952 loss)
I0824 19:38:07.712936 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99313
I0824 19:38:07.712942 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998916
I0824 19:38:07.712950 42792 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0824 19:38:24.387435 42792 solver.cpp:228] Iteration 4920, loss = 0.00913734
I0824 19:38:24.387616 42792 solver.cpp:244]     Train net output #0: accuracy = 0.996523
I0824 19:38:24.387645 42792 solver.cpp:244]     Train net output #1: loss = 0.00913748 (* 1 = 0.00913748 loss)
I0824 19:38:24.387655 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996232
I0824 19:38:24.387661 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997073
I0824 19:38:24.387670 42792 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0824 19:38:41.044457 42792 solver.cpp:228] Iteration 4940, loss = 0.0133462
I0824 19:38:41.044507 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994381
I0824 19:38:41.044523 42792 solver.cpp:244]     Train net output #1: loss = 0.0133464 (* 1 = 0.0133464 loss)
I0824 19:38:41.044531 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992658
I0824 19:38:41.044546 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997973
I0824 19:38:41.044559 42792 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0824 19:38:57.713898 42792 solver.cpp:228] Iteration 4960, loss = 0.0121461
I0824 19:38:57.714004 42792 solver.cpp:244]     Train net output #0: accuracy = 0.994839
I0824 19:38:57.714022 42792 solver.cpp:244]     Train net output #1: loss = 0.0121463 (* 1 = 0.0121463 loss)
I0824 19:38:57.714037 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993132
I0824 19:38:57.714051 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99821
I0824 19:38:57.714058 42792 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0824 19:39:14.402178 42792 solver.cpp:228] Iteration 4980, loss = 0.0149558
I0824 19:39:14.402220 42792 solver.cpp:244]     Train net output #0: accuracy = 0.993711
I0824 19:39:14.402235 42792 solver.cpp:244]     Train net output #1: loss = 0.0149559 (* 1 = 0.0149559 loss)
I0824 19:39:14.402242 42792 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993332
I0824 19:39:14.402248 42792 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994767
I0824 19:39:14.402256 42792 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0824 19:39:30.709915 42792 solver.cpp:454] Snapshotting to binary proto file pocwisc3/training_iter_5000.caffemodel
I0824 19:39:31.719074 42792 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc3/training_iter_5000.solverstate
I0824 19:39:32.315034 42792 solver.cpp:317] Iteration 5000, loss = 0.0103745
I0824 19:39:32.315081 42792 solver.cpp:322] Optimization Done.
I0824 19:39:32.315088 42792 caffe.cpp:254] Optimization Done.

2017-08-24 19:39:32,720 log.framework MainThread  INFO       caffe models found
pocwisc3/training_iter_5000.caffemodel
2017-08-24 19:39:32,720 log.framework MainThread  INFO       Caffe model found: pocwisc3/training_iter_5000.caffemodel
2017-08-24 19:39:34,429 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 19:39:34,651 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 19:39:34,862 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 19:39:35,070 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 19:39:35,285 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 19:39:35,496 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 19:39:35,708 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 19:39:35,917 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 19:39:36,121 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 19:39:36,275 log.framework MainThread  INFO       train file number: 53
2017-08-24 19:39:36,276 log.framework MainThread  INFO       test file number: 2
2017-08-24 19:39:36,276 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 19:39:36,276 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 19:39:36,277 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-08-24 19:39:36,277 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-08-24 19:39:36,277 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-08-24 19:39:36,278 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc4/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc4/training"
solver_mode: GPU

2017-08-24 19:39:36,278 log.framework MainThread  INFO       caffe training step
2017-08-24 19:39:36,278 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc4/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-08-24 20:49:43,130 log.framework MainThread  INFO       I0824 19:39:36.357887 43244 caffe.cpp:217] Using GPUs 0
I0824 19:39:36.367691 43244 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0824 19:39:36.893553 43244 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc4/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc4/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0824 19:39:36.893726 43244 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc4/caffe/model_segnet_final/train.prototxt
I0824 19:39:36.896517 43244 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc4/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 19:39:36.897028 43244 layer_factory.hpp:77] Creating layer data
I0824 19:39:36.897048 43244 net.cpp:100] Creating Layer data
I0824 19:39:36.897058 43244 net.cpp:408] data -> data
I0824 19:39:36.897089 43244 net.cpp:408] data -> label
I0824 19:39:36.897110 43244 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc4/HDF5Files/train_combined.txt
I0824 19:39:36.897183 43244 hdf5_data_layer.cpp:93] Number of HDF5 files: 53
I0824 19:39:36.898398 43244 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0824 19:39:36.996387 43244 net.cpp:150] Setting up data
I0824 19:39:36.996418 43244 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 19:39:36.996430 43244 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 19:39:36.996439 43244 net.cpp:165] Memory required for data: 24883200
I0824 19:39:36.996448 43244 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 19:39:36.996462 43244 net.cpp:100] Creating Layer label_data_1_split
I0824 19:39:36.996470 43244 net.cpp:434] label_data_1_split <- label
I0824 19:39:36.996490 43244 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 19:39:36.996501 43244 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 19:39:36.996544 43244 net.cpp:150] Setting up label_data_1_split
I0824 19:39:36.996552 43244 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 19:39:36.996558 43244 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 19:39:36.996562 43244 net.cpp:165] Memory required for data: 30412800
I0824 19:39:36.996565 43244 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 19:39:36.996587 43244 net.cpp:100] Creating Layer conv1_1_1
I0824 19:39:36.996592 43244 net.cpp:434] conv1_1_1 <- data
I0824 19:39:36.996598 43244 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 19:39:37.513171 43244 net.cpp:150] Setting up conv1_1_1
I0824 19:39:37.513213 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:37.513218 43244 net.cpp:165] Memory required for data: 207360000
I0824 19:39:37.513249 43244 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 19:39:37.513268 43244 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 19:39:37.513276 43244 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 19:39:37.513291 43244 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 19:39:37.513702 43244 net.cpp:150] Setting up conv1_1_1_bn
I0824 19:39:37.513713 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:37.513717 43244 net.cpp:165] Memory required for data: 384307200
I0824 19:39:37.513731 43244 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 19:39:37.513751 43244 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 19:39:37.513756 43244 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 19:39:37.513761 43244 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 19:39:37.513815 43244 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 19:39:37.515451 43244 net.cpp:150] Setting up conv1_1_1_scale
I0824 19:39:37.515468 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:37.515476 43244 net.cpp:165] Memory required for data: 561254400
I0824 19:39:37.515485 43244 layer_factory.hpp:77] Creating layer relu1_1
I0824 19:39:37.515496 43244 net.cpp:100] Creating Layer relu1_1
I0824 19:39:37.515501 43244 net.cpp:434] relu1_1 <- conv1_1_1
I0824 19:39:37.515507 43244 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 19:39:37.515739 43244 net.cpp:150] Setting up relu1_1
I0824 19:39:37.515750 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:37.515755 43244 net.cpp:165] Memory required for data: 738201600
I0824 19:39:37.515759 43244 layer_factory.hpp:77] Creating layer conv1_2
I0824 19:39:37.515772 43244 net.cpp:100] Creating Layer conv1_2
I0824 19:39:37.515779 43244 net.cpp:434] conv1_2 <- conv1_1_1
I0824 19:39:37.515785 43244 net.cpp:408] conv1_2 -> conv1_2
I0824 19:39:37.519986 43244 net.cpp:150] Setting up conv1_2
I0824 19:39:37.520004 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:37.520020 43244 net.cpp:165] Memory required for data: 915148800
I0824 19:39:37.520035 43244 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 19:39:37.520045 43244 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 19:39:37.520053 43244 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 19:39:37.520059 43244 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 19:39:37.521598 43244 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 19:39:37.521615 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:37.521620 43244 net.cpp:165] Memory required for data: 1092096000
I0824 19:39:37.521641 43244 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 19:39:37.521652 43244 net.cpp:100] Creating Layer conv1_2_scale
I0824 19:39:37.521657 43244 net.cpp:434] conv1_2_scale <- conv1_2
I0824 19:39:37.521664 43244 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 19:39:37.521710 43244 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 19:39:37.522086 43244 net.cpp:150] Setting up conv1_2_scale
I0824 19:39:37.522096 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:37.522099 43244 net.cpp:165] Memory required for data: 1269043200
I0824 19:39:37.522107 43244 layer_factory.hpp:77] Creating layer relu1_2
I0824 19:39:37.522114 43244 net.cpp:100] Creating Layer relu1_2
I0824 19:39:37.522120 43244 net.cpp:434] relu1_2 <- conv1_2
I0824 19:39:37.522125 43244 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 19:39:37.522323 43244 net.cpp:150] Setting up relu1_2
I0824 19:39:37.522333 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:37.522338 43244 net.cpp:165] Memory required for data: 1445990400
I0824 19:39:37.522342 43244 layer_factory.hpp:77] Creating layer pool1
I0824 19:39:37.522351 43244 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 19:39:37.522357 43244 net.cpp:100] Creating Layer pool1
I0824 19:39:37.522362 43244 net.cpp:434] pool1 <- conv1_2
I0824 19:39:37.522368 43244 net.cpp:408] pool1 -> pool1
I0824 19:39:37.522379 43244 net.cpp:408] pool1 -> pool1_mask
I0824 19:39:37.522435 43244 net.cpp:150] Setting up pool1
I0824 19:39:37.522444 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:37.522449 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:37.522454 43244 net.cpp:165] Memory required for data: 1534464000
I0824 19:39:37.522457 43244 layer_factory.hpp:77] Creating layer conv2_1
I0824 19:39:37.522469 43244 net.cpp:100] Creating Layer conv2_1
I0824 19:39:37.522474 43244 net.cpp:434] conv2_1 <- pool1
I0824 19:39:37.522480 43244 net.cpp:408] conv2_1 -> conv2_1
I0824 19:39:37.528586 43244 net.cpp:150] Setting up conv2_1
I0824 19:39:37.528605 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:37.528620 43244 net.cpp:165] Memory required for data: 1622937600
I0824 19:39:37.528627 43244 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 19:39:37.528638 43244 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 19:39:37.528647 43244 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 19:39:37.528654 43244 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 19:39:37.528885 43244 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 19:39:37.528894 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:37.528898 43244 net.cpp:165] Memory required for data: 1711411200
I0824 19:39:37.528913 43244 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 19:39:37.528939 43244 net.cpp:100] Creating Layer conv2_1_scale
I0824 19:39:37.528944 43244 net.cpp:434] conv2_1_scale <- conv2_1
I0824 19:39:37.528949 43244 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 19:39:37.528993 43244 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 19:39:37.529170 43244 net.cpp:150] Setting up conv2_1_scale
I0824 19:39:37.529180 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:37.529182 43244 net.cpp:165] Memory required for data: 1799884800
I0824 19:39:37.529189 43244 layer_factory.hpp:77] Creating layer relu2_1
I0824 19:39:37.529197 43244 net.cpp:100] Creating Layer relu2_1
I0824 19:39:37.529202 43244 net.cpp:434] relu2_1 <- conv2_1
I0824 19:39:37.529207 43244 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 19:39:37.530242 43244 net.cpp:150] Setting up relu2_1
I0824 19:39:37.530259 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:37.530263 43244 net.cpp:165] Memory required for data: 1888358400
I0824 19:39:37.530272 43244 layer_factory.hpp:77] Creating layer conv2_2
I0824 19:39:37.530284 43244 net.cpp:100] Creating Layer conv2_2
I0824 19:39:37.530289 43244 net.cpp:434] conv2_2 <- conv2_1
I0824 19:39:37.530297 43244 net.cpp:408] conv2_2 -> conv2_2
I0824 19:39:37.537578 43244 net.cpp:150] Setting up conv2_2
I0824 19:39:37.537596 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:37.537611 43244 net.cpp:165] Memory required for data: 1976832000
I0824 19:39:37.537619 43244 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 19:39:37.537631 43244 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 19:39:37.537637 43244 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 19:39:37.537644 43244 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 19:39:37.537874 43244 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 19:39:37.537884 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:37.537889 43244 net.cpp:165] Memory required for data: 2065305600
I0824 19:39:37.537896 43244 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 19:39:37.537909 43244 net.cpp:100] Creating Layer conv2_2_scale
I0824 19:39:37.537919 43244 net.cpp:434] conv2_2_scale <- conv2_2
I0824 19:39:37.537925 43244 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 19:39:37.537966 43244 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 19:39:37.538143 43244 net.cpp:150] Setting up conv2_2_scale
I0824 19:39:37.538152 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:37.538156 43244 net.cpp:165] Memory required for data: 2153779200
I0824 19:39:37.538162 43244 layer_factory.hpp:77] Creating layer relu2_2
I0824 19:39:37.538170 43244 net.cpp:100] Creating Layer relu2_2
I0824 19:39:37.538175 43244 net.cpp:434] relu2_2 <- conv2_2
I0824 19:39:37.538180 43244 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 19:39:37.538379 43244 net.cpp:150] Setting up relu2_2
I0824 19:39:37.538390 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:37.538395 43244 net.cpp:165] Memory required for data: 2242252800
I0824 19:39:37.538401 43244 layer_factory.hpp:77] Creating layer pool2
I0824 19:39:37.538408 43244 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 19:39:37.538414 43244 net.cpp:100] Creating Layer pool2
I0824 19:39:37.538419 43244 net.cpp:434] pool2 <- conv2_2
I0824 19:39:37.538424 43244 net.cpp:408] pool2 -> pool2
I0824 19:39:37.538434 43244 net.cpp:408] pool2 -> pool2_mask
I0824 19:39:37.538478 43244 net.cpp:150] Setting up pool2
I0824 19:39:37.538486 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:37.538491 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:37.538496 43244 net.cpp:165] Memory required for data: 2286489600
I0824 19:39:37.538501 43244 layer_factory.hpp:77] Creating layer conv3_1
I0824 19:39:37.538511 43244 net.cpp:100] Creating Layer conv3_1
I0824 19:39:37.538516 43244 net.cpp:434] conv3_1 <- pool2
I0824 19:39:37.538522 43244 net.cpp:408] conv3_1 -> conv3_1
I0824 19:39:37.550845 43244 net.cpp:150] Setting up conv3_1
I0824 19:39:37.550878 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.550889 43244 net.cpp:165] Memory required for data: 2330726400
I0824 19:39:37.550897 43244 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 19:39:37.550905 43244 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 19:39:37.550914 43244 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 19:39:37.550920 43244 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 19:39:37.551136 43244 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 19:39:37.551146 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.551149 43244 net.cpp:165] Memory required for data: 2374963200
I0824 19:39:37.551163 43244 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 19:39:37.551172 43244 net.cpp:100] Creating Layer conv3_1_scale
I0824 19:39:37.551180 43244 net.cpp:434] conv3_1_scale <- conv3_1
I0824 19:39:37.551185 43244 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 19:39:37.551229 43244 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 19:39:37.551364 43244 net.cpp:150] Setting up conv3_1_scale
I0824 19:39:37.551373 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.551376 43244 net.cpp:165] Memory required for data: 2419200000
I0824 19:39:37.551386 43244 layer_factory.hpp:77] Creating layer relu3_1
I0824 19:39:37.551395 43244 net.cpp:100] Creating Layer relu3_1
I0824 19:39:37.551400 43244 net.cpp:434] relu3_1 <- conv3_1
I0824 19:39:37.551405 43244 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 19:39:37.551604 43244 net.cpp:150] Setting up relu3_1
I0824 19:39:37.551615 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.551620 43244 net.cpp:165] Memory required for data: 2463436800
I0824 19:39:37.551625 43244 layer_factory.hpp:77] Creating layer conv3_2
I0824 19:39:37.551635 43244 net.cpp:100] Creating Layer conv3_2
I0824 19:39:37.551640 43244 net.cpp:434] conv3_2 <- conv3_1
I0824 19:39:37.551646 43244 net.cpp:408] conv3_2 -> conv3_2
I0824 19:39:37.574793 43244 net.cpp:150] Setting up conv3_2
I0824 19:39:37.574811 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.574823 43244 net.cpp:165] Memory required for data: 2507673600
I0824 19:39:37.574832 43244 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 19:39:37.574841 43244 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 19:39:37.574847 43244 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 19:39:37.574853 43244 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 19:39:37.575063 43244 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 19:39:37.575073 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.575076 43244 net.cpp:165] Memory required for data: 2551910400
I0824 19:39:37.575084 43244 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 19:39:37.575098 43244 net.cpp:100] Creating Layer conv3_2_scale
I0824 19:39:37.575106 43244 net.cpp:434] conv3_2_scale <- conv3_2
I0824 19:39:37.575111 43244 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 19:39:37.575153 43244 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 19:39:37.575289 43244 net.cpp:150] Setting up conv3_2_scale
I0824 19:39:37.575299 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.575302 43244 net.cpp:165] Memory required for data: 2596147200
I0824 19:39:37.575310 43244 layer_factory.hpp:77] Creating layer relu3_2
I0824 19:39:37.575318 43244 net.cpp:100] Creating Layer relu3_2
I0824 19:39:37.575323 43244 net.cpp:434] relu3_2 <- conv3_2
I0824 19:39:37.575328 43244 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 19:39:37.575531 43244 net.cpp:150] Setting up relu3_2
I0824 19:39:37.575542 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.575547 43244 net.cpp:165] Memory required for data: 2640384000
I0824 19:39:37.575551 43244 layer_factory.hpp:77] Creating layer conv3_3
I0824 19:39:37.575562 43244 net.cpp:100] Creating Layer conv3_3
I0824 19:39:37.575567 43244 net.cpp:434] conv3_3 <- conv3_2
I0824 19:39:37.575573 43244 net.cpp:408] conv3_3 -> conv3_3
I0824 19:39:37.598767 43244 net.cpp:150] Setting up conv3_3
I0824 19:39:37.598799 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.598815 43244 net.cpp:165] Memory required for data: 2684620800
I0824 19:39:37.598824 43244 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 19:39:37.598839 43244 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 19:39:37.598848 43244 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 19:39:37.598855 43244 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 19:39:37.599073 43244 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 19:39:37.599082 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.599086 43244 net.cpp:165] Memory required for data: 2728857600
I0824 19:39:37.599094 43244 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 19:39:37.599104 43244 net.cpp:100] Creating Layer conv3_3_scale
I0824 19:39:37.599109 43244 net.cpp:434] conv3_3_scale <- conv3_3
I0824 19:39:37.599115 43244 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 19:39:37.599159 43244 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 19:39:37.599297 43244 net.cpp:150] Setting up conv3_3_scale
I0824 19:39:37.599304 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.599308 43244 net.cpp:165] Memory required for data: 2773094400
I0824 19:39:37.599315 43244 layer_factory.hpp:77] Creating layer relu3_3
I0824 19:39:37.599323 43244 net.cpp:100] Creating Layer relu3_3
I0824 19:39:37.599328 43244 net.cpp:434] relu3_3 <- conv3_3
I0824 19:39:37.599334 43244 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 19:39:37.599534 43244 net.cpp:150] Setting up relu3_3
I0824 19:39:37.599544 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:37.599548 43244 net.cpp:165] Memory required for data: 2817331200
I0824 19:39:37.599552 43244 layer_factory.hpp:77] Creating layer pool3
I0824 19:39:37.599557 43244 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 19:39:37.599566 43244 net.cpp:100] Creating Layer pool3
I0824 19:39:37.599572 43244 net.cpp:434] pool3 <- conv3_3
I0824 19:39:37.599578 43244 net.cpp:408] pool3 -> pool3
I0824 19:39:37.599587 43244 net.cpp:408] pool3 -> pool3_mask
I0824 19:39:37.599635 43244 net.cpp:150] Setting up pool3
I0824 19:39:37.599643 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:37.599648 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:37.599653 43244 net.cpp:165] Memory required for data: 2839449600
I0824 19:39:37.599658 43244 layer_factory.hpp:77] Creating layer conv4_1
I0824 19:39:37.599668 43244 net.cpp:100] Creating Layer conv4_1
I0824 19:39:37.599673 43244 net.cpp:434] conv4_1 <- pool3
I0824 19:39:37.599680 43244 net.cpp:408] conv4_1 -> conv4_1
I0824 19:39:37.645680 43244 net.cpp:150] Setting up conv4_1
I0824 19:39:37.645700 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.645704 43244 net.cpp:165] Memory required for data: 2861568000
I0824 19:39:37.645716 43244 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 19:39:37.645725 43244 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 19:39:37.645737 43244 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 19:39:37.645745 43244 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 19:39:37.645959 43244 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 19:39:37.645968 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.645972 43244 net.cpp:165] Memory required for data: 2883686400
I0824 19:39:37.645980 43244 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 19:39:37.645993 43244 net.cpp:100] Creating Layer conv4_1_scale
I0824 19:39:37.646003 43244 net.cpp:434] conv4_1_scale <- conv4_1
I0824 19:39:37.646008 43244 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 19:39:37.646052 43244 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 19:39:37.646178 43244 net.cpp:150] Setting up conv4_1_scale
I0824 19:39:37.646185 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.646189 43244 net.cpp:165] Memory required for data: 2905804800
I0824 19:39:37.646196 43244 layer_factory.hpp:77] Creating layer relu4_1
I0824 19:39:37.646219 43244 net.cpp:100] Creating Layer relu4_1
I0824 19:39:37.646225 43244 net.cpp:434] relu4_1 <- conv4_1
I0824 19:39:37.646230 43244 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 19:39:37.646445 43244 net.cpp:150] Setting up relu4_1
I0824 19:39:37.646455 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.646459 43244 net.cpp:165] Memory required for data: 2927923200
I0824 19:39:37.646464 43244 layer_factory.hpp:77] Creating layer conv4_2
I0824 19:39:37.646477 43244 net.cpp:100] Creating Layer conv4_2
I0824 19:39:37.646482 43244 net.cpp:434] conv4_2 <- conv4_1
I0824 19:39:37.646489 43244 net.cpp:408] conv4_2 -> conv4_2
I0824 19:39:37.729923 43244 net.cpp:150] Setting up conv4_2
I0824 19:39:37.729941 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.729945 43244 net.cpp:165] Memory required for data: 2950041600
I0824 19:39:37.729956 43244 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 19:39:37.729965 43244 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 19:39:37.729969 43244 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 19:39:37.729985 43244 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 19:39:37.730199 43244 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 19:39:37.730208 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.730211 43244 net.cpp:165] Memory required for data: 2972160000
I0824 19:39:37.730221 43244 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 19:39:37.730232 43244 net.cpp:100] Creating Layer conv4_2_scale
I0824 19:39:37.730242 43244 net.cpp:434] conv4_2_scale <- conv4_2
I0824 19:39:37.730247 43244 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 19:39:37.730288 43244 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 19:39:37.730414 43244 net.cpp:150] Setting up conv4_2_scale
I0824 19:39:37.730422 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.730425 43244 net.cpp:165] Memory required for data: 2994278400
I0824 19:39:37.730432 43244 layer_factory.hpp:77] Creating layer relu4_2
I0824 19:39:37.730439 43244 net.cpp:100] Creating Layer relu4_2
I0824 19:39:37.730444 43244 net.cpp:434] relu4_2 <- conv4_2
I0824 19:39:37.730450 43244 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 19:39:37.731506 43244 net.cpp:150] Setting up relu4_2
I0824 19:39:37.731523 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.731528 43244 net.cpp:165] Memory required for data: 3016396800
I0824 19:39:37.731531 43244 layer_factory.hpp:77] Creating layer conv4_3
I0824 19:39:37.731545 43244 net.cpp:100] Creating Layer conv4_3
I0824 19:39:37.731550 43244 net.cpp:434] conv4_3 <- conv4_2
I0824 19:39:37.731559 43244 net.cpp:408] conv4_3 -> conv4_3
I0824 19:39:37.814941 43244 net.cpp:150] Setting up conv4_3
I0824 19:39:37.814962 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.814966 43244 net.cpp:165] Memory required for data: 3038515200
I0824 19:39:37.814991 43244 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 19:39:37.815003 43244 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 19:39:37.815011 43244 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 19:39:37.815018 43244 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 19:39:37.815234 43244 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 19:39:37.815243 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.815254 43244 net.cpp:165] Memory required for data: 3060633600
I0824 19:39:37.815263 43244 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 19:39:37.815274 43244 net.cpp:100] Creating Layer conv4_3_scale
I0824 19:39:37.815279 43244 net.cpp:434] conv4_3_scale <- conv4_3
I0824 19:39:37.815285 43244 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 19:39:37.815330 43244 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 19:39:37.815462 43244 net.cpp:150] Setting up conv4_3_scale
I0824 19:39:37.815470 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.815474 43244 net.cpp:165] Memory required for data: 3082752000
I0824 19:39:37.815480 43244 layer_factory.hpp:77] Creating layer relu4_3
I0824 19:39:37.815505 43244 net.cpp:100] Creating Layer relu4_3
I0824 19:39:37.815510 43244 net.cpp:434] relu4_3 <- conv4_3
I0824 19:39:37.815515 43244 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 19:39:37.815721 43244 net.cpp:150] Setting up relu4_3
I0824 19:39:37.815732 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:37.815737 43244 net.cpp:165] Memory required for data: 3104870400
I0824 19:39:37.815740 43244 layer_factory.hpp:77] Creating layer pool4
I0824 19:39:37.815744 43244 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 19:39:37.815752 43244 net.cpp:100] Creating Layer pool4
I0824 19:39:37.815757 43244 net.cpp:434] pool4 <- conv4_3
I0824 19:39:37.815763 43244 net.cpp:408] pool4 -> pool4
I0824 19:39:37.815773 43244 net.cpp:408] pool4 -> pool4_mask
I0824 19:39:37.815821 43244 net.cpp:150] Setting up pool4
I0824 19:39:37.815829 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:37.815834 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:37.815838 43244 net.cpp:165] Memory required for data: 3116175360
I0824 19:39:37.815843 43244 layer_factory.hpp:77] Creating layer conv5_1
I0824 19:39:37.815857 43244 net.cpp:100] Creating Layer conv5_1
I0824 19:39:37.815862 43244 net.cpp:434] conv5_1 <- pool4
I0824 19:39:37.815870 43244 net.cpp:408] conv5_1 -> conv5_1
I0824 19:39:37.899472 43244 net.cpp:150] Setting up conv5_1
I0824 19:39:37.899492 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:37.899495 43244 net.cpp:165] Memory required for data: 3121827840
I0824 19:39:37.899503 43244 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 19:39:37.899513 43244 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 19:39:37.899516 43244 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 19:39:37.899530 43244 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 19:39:37.899749 43244 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 19:39:37.899757 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:37.899760 43244 net.cpp:165] Memory required for data: 3127480320
I0824 19:39:37.899770 43244 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 19:39:37.899781 43244 net.cpp:100] Creating Layer conv5_1_scale
I0824 19:39:37.899791 43244 net.cpp:434] conv5_1_scale <- conv5_1
I0824 19:39:37.899796 43244 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 19:39:37.899842 43244 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 19:39:37.899966 43244 net.cpp:150] Setting up conv5_1_scale
I0824 19:39:37.899973 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:37.899976 43244 net.cpp:165] Memory required for data: 3133132800
I0824 19:39:37.899983 43244 layer_factory.hpp:77] Creating layer relu5_1
I0824 19:39:37.899994 43244 net.cpp:100] Creating Layer relu5_1
I0824 19:39:37.899999 43244 net.cpp:434] relu5_1 <- conv5_1
I0824 19:39:37.900004 43244 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 19:39:37.900207 43244 net.cpp:150] Setting up relu5_1
I0824 19:39:37.900218 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:37.900220 43244 net.cpp:165] Memory required for data: 3138785280
I0824 19:39:37.900226 43244 layer_factory.hpp:77] Creating layer conv5_2
I0824 19:39:37.900238 43244 net.cpp:100] Creating Layer conv5_2
I0824 19:39:37.900243 43244 net.cpp:434] conv5_2 <- conv5_1
I0824 19:39:37.900251 43244 net.cpp:408] conv5_2 -> conv5_2
I0824 19:39:37.984344 43244 net.cpp:150] Setting up conv5_2
I0824 19:39:37.984369 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:37.984374 43244 net.cpp:165] Memory required for data: 3144437760
I0824 19:39:37.984385 43244 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 19:39:37.984400 43244 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 19:39:37.984407 43244 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 19:39:37.984416 43244 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 19:39:37.984634 43244 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 19:39:37.984643 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:37.984663 43244 net.cpp:165] Memory required for data: 3150090240
I0824 19:39:37.984673 43244 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 19:39:37.984684 43244 net.cpp:100] Creating Layer conv5_2_scale
I0824 19:39:37.984691 43244 net.cpp:434] conv5_2_scale <- conv5_2
I0824 19:39:37.984697 43244 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 19:39:37.984750 43244 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 19:39:37.984876 43244 net.cpp:150] Setting up conv5_2_scale
I0824 19:39:37.984885 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:37.984889 43244 net.cpp:165] Memory required for data: 3155742720
I0824 19:39:37.984895 43244 layer_factory.hpp:77] Creating layer relu5_2
I0824 19:39:37.984905 43244 net.cpp:100] Creating Layer relu5_2
I0824 19:39:37.984910 43244 net.cpp:434] relu5_2 <- conv5_2
I0824 19:39:37.984915 43244 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 19:39:37.985123 43244 net.cpp:150] Setting up relu5_2
I0824 19:39:37.985133 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:37.985139 43244 net.cpp:165] Memory required for data: 3161395200
I0824 19:39:37.985143 43244 layer_factory.hpp:77] Creating layer conv5_3
I0824 19:39:37.985155 43244 net.cpp:100] Creating Layer conv5_3
I0824 19:39:37.985162 43244 net.cpp:434] conv5_3 <- conv5_2
I0824 19:39:37.985169 43244 net.cpp:408] conv5_3 -> conv5_3
I0824 19:39:38.068830 43244 net.cpp:150] Setting up conv5_3
I0824 19:39:38.068850 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.068855 43244 net.cpp:165] Memory required for data: 3167047680
I0824 19:39:38.068861 43244 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 19:39:38.068872 43244 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 19:39:38.068882 43244 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 19:39:38.068889 43244 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 19:39:38.069116 43244 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 19:39:38.069125 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.069128 43244 net.cpp:165] Memory required for data: 3172700160
I0824 19:39:38.069138 43244 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 19:39:38.069146 43244 net.cpp:100] Creating Layer conv5_3_scale
I0824 19:39:38.069152 43244 net.cpp:434] conv5_3_scale <- conv5_3
I0824 19:39:38.069159 43244 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 19:39:38.069212 43244 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 19:39:38.069344 43244 net.cpp:150] Setting up conv5_3_scale
I0824 19:39:38.069351 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.069355 43244 net.cpp:165] Memory required for data: 3178352640
I0824 19:39:38.069362 43244 layer_factory.hpp:77] Creating layer relu5_3
I0824 19:39:38.069387 43244 net.cpp:100] Creating Layer relu5_3
I0824 19:39:38.069392 43244 net.cpp:434] relu5_3 <- conv5_3
I0824 19:39:38.069398 43244 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 19:39:38.069608 43244 net.cpp:150] Setting up relu5_3
I0824 19:39:38.069622 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.069627 43244 net.cpp:165] Memory required for data: 3184005120
I0824 19:39:38.069631 43244 layer_factory.hpp:77] Creating layer pool5
I0824 19:39:38.069636 43244 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 19:39:38.069646 43244 net.cpp:100] Creating Layer pool5
I0824 19:39:38.069651 43244 net.cpp:434] pool5 <- conv5_3
I0824 19:39:38.069660 43244 net.cpp:408] pool5 -> pool5
I0824 19:39:38.069669 43244 net.cpp:408] pool5 -> pool5_mask
I0824 19:39:38.069723 43244 net.cpp:150] Setting up pool5
I0824 19:39:38.069730 43244 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 19:39:38.069736 43244 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 19:39:38.069741 43244 net.cpp:165] Memory required for data: 3186954240
I0824 19:39:38.069744 43244 layer_factory.hpp:77] Creating layer upsample5
I0824 19:39:38.069758 43244 net.cpp:100] Creating Layer upsample5
I0824 19:39:38.069763 43244 net.cpp:434] upsample5 <- pool5
I0824 19:39:38.069783 43244 net.cpp:434] upsample5 <- pool5_mask
I0824 19:39:38.069792 43244 net.cpp:408] upsample5 -> pool5_D
I0824 19:39:38.069836 43244 net.cpp:150] Setting up upsample5
I0824 19:39:38.069844 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.069847 43244 net.cpp:165] Memory required for data: 3192606720
I0824 19:39:38.069850 43244 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 19:39:38.069864 43244 net.cpp:100] Creating Layer conv5_3_D
I0824 19:39:38.069869 43244 net.cpp:434] conv5_3_D <- pool5_D
I0824 19:39:38.069877 43244 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 19:39:38.154409 43244 net.cpp:150] Setting up conv5_3_D
I0824 19:39:38.154429 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.154433 43244 net.cpp:165] Memory required for data: 3198259200
I0824 19:39:38.154441 43244 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 19:39:38.154453 43244 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 19:39:38.154460 43244 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 19:39:38.154467 43244 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 19:39:38.154693 43244 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 19:39:38.154702 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.154706 43244 net.cpp:165] Memory required for data: 3203911680
I0824 19:39:38.154716 43244 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 19:39:38.154728 43244 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 19:39:38.154736 43244 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 19:39:38.154742 43244 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 19:39:38.154796 43244 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 19:39:38.154925 43244 net.cpp:150] Setting up conv5_3_D_scale
I0824 19:39:38.154934 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.154937 43244 net.cpp:165] Memory required for data: 3209564160
I0824 19:39:38.154944 43244 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 19:39:38.154953 43244 net.cpp:100] Creating Layer relu5_3_D
I0824 19:39:38.154958 43244 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 19:39:38.154964 43244 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 19:39:38.155184 43244 net.cpp:150] Setting up relu5_3_D
I0824 19:39:38.155195 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.155200 43244 net.cpp:165] Memory required for data: 3215216640
I0824 19:39:38.155203 43244 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 19:39:38.155239 43244 net.cpp:100] Creating Layer conv5_2_D
I0824 19:39:38.155244 43244 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 19:39:38.155253 43244 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 19:39:38.238931 43244 net.cpp:150] Setting up conv5_2_D
I0824 19:39:38.238950 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.238955 43244 net.cpp:165] Memory required for data: 3220869120
I0824 19:39:38.238963 43244 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 19:39:38.238972 43244 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 19:39:38.238983 43244 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 19:39:38.238991 43244 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 19:39:38.239218 43244 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 19:39:38.239228 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.239230 43244 net.cpp:165] Memory required for data: 3226521600
I0824 19:39:38.239240 43244 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 19:39:38.239253 43244 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 19:39:38.239261 43244 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 19:39:38.239267 43244 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 19:39:38.239321 43244 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 19:39:38.239450 43244 net.cpp:150] Setting up conv5_2_D_scale
I0824 19:39:38.239459 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.239462 43244 net.cpp:165] Memory required for data: 3232174080
I0824 19:39:38.239486 43244 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 19:39:38.239495 43244 net.cpp:100] Creating Layer relu5_2_D
I0824 19:39:38.239501 43244 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 19:39:38.239507 43244 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 19:39:38.240594 43244 net.cpp:150] Setting up relu5_2_D
I0824 19:39:38.240609 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.240614 43244 net.cpp:165] Memory required for data: 3237826560
I0824 19:39:38.240619 43244 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 19:39:38.240634 43244 net.cpp:100] Creating Layer conv5_1_D
I0824 19:39:38.240640 43244 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 19:39:38.240648 43244 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 19:39:38.324344 43244 net.cpp:150] Setting up conv5_1_D
I0824 19:39:38.324362 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.324368 43244 net.cpp:165] Memory required for data: 3243479040
I0824 19:39:38.324376 43244 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 19:39:38.324385 43244 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 19:39:38.324396 43244 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 19:39:38.324404 43244 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 19:39:38.324636 43244 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 19:39:38.324645 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.324648 43244 net.cpp:165] Memory required for data: 3249131520
I0824 19:39:38.324658 43244 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 19:39:38.324669 43244 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 19:39:38.324676 43244 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 19:39:38.324682 43244 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 19:39:38.324736 43244 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 19:39:38.324872 43244 net.cpp:150] Setting up conv5_1_D_scale
I0824 19:39:38.324879 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.324883 43244 net.cpp:165] Memory required for data: 3254784000
I0824 19:39:38.324889 43244 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 19:39:38.324899 43244 net.cpp:100] Creating Layer relu5_1_D
I0824 19:39:38.324904 43244 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 19:39:38.324910 43244 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 19:39:38.325117 43244 net.cpp:150] Setting up relu5_1_D
I0824 19:39:38.325127 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:38.325132 43244 net.cpp:165] Memory required for data: 3260436480
I0824 19:39:38.325136 43244 layer_factory.hpp:77] Creating layer upsample4
I0824 19:39:38.325145 43244 net.cpp:100] Creating Layer upsample4
I0824 19:39:38.325150 43244 net.cpp:434] upsample4 <- conv5_1_D
I0824 19:39:38.325155 43244 net.cpp:434] upsample4 <- pool4_mask
I0824 19:39:38.325161 43244 net.cpp:408] upsample4 -> pool4_D
I0824 19:39:38.325196 43244 net.cpp:150] Setting up upsample4
I0824 19:39:38.325204 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.325207 43244 net.cpp:165] Memory required for data: 3282554880
I0824 19:39:38.325212 43244 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 19:39:38.325224 43244 net.cpp:100] Creating Layer conv4_3_D
I0824 19:39:38.325229 43244 net.cpp:434] conv4_3_D <- pool4_D
I0824 19:39:38.325237 43244 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 19:39:38.408934 43244 net.cpp:150] Setting up conv4_3_D
I0824 19:39:38.408953 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.408964 43244 net.cpp:165] Memory required for data: 3304673280
I0824 19:39:38.408973 43244 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 19:39:38.408985 43244 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 19:39:38.408993 43244 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 19:39:38.408999 43244 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 19:39:38.409240 43244 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 19:39:38.409250 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.409271 43244 net.cpp:165] Memory required for data: 3326791680
I0824 19:39:38.409281 43244 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 19:39:38.409293 43244 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 19:39:38.409299 43244 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 19:39:38.409307 43244 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 19:39:38.409355 43244 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 19:39:38.409523 43244 net.cpp:150] Setting up conv4_3_D_scale
I0824 19:39:38.409533 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.409535 43244 net.cpp:165] Memory required for data: 3348910080
I0824 19:39:38.409543 43244 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 19:39:38.409551 43244 net.cpp:100] Creating Layer relu4_3_D
I0824 19:39:38.409556 43244 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 19:39:38.409562 43244 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 19:39:38.409771 43244 net.cpp:150] Setting up relu4_3_D
I0824 19:39:38.409783 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.409788 43244 net.cpp:165] Memory required for data: 3371028480
I0824 19:39:38.409792 43244 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 19:39:38.409806 43244 net.cpp:100] Creating Layer conv4_2_D
I0824 19:39:38.409811 43244 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 19:39:38.409819 43244 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 19:39:38.495369 43244 net.cpp:150] Setting up conv4_2_D
I0824 19:39:38.495390 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.495395 43244 net.cpp:165] Memory required for data: 3393146880
I0824 19:39:38.495406 43244 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 19:39:38.495424 43244 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 19:39:38.495436 43244 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 19:39:38.495447 43244 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 19:39:38.495687 43244 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 19:39:38.495697 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.495699 43244 net.cpp:165] Memory required for data: 3415265280
I0824 19:39:38.495708 43244 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 19:39:38.495720 43244 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 19:39:38.495725 43244 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 19:39:38.495731 43244 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 19:39:38.495777 43244 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 19:39:38.495924 43244 net.cpp:150] Setting up conv4_2_D_scale
I0824 19:39:38.495934 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.495937 43244 net.cpp:165] Memory required for data: 3437383680
I0824 19:39:38.495944 43244 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 19:39:38.495952 43244 net.cpp:100] Creating Layer relu4_2_D
I0824 19:39:38.495957 43244 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 19:39:38.495964 43244 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 19:39:38.496171 43244 net.cpp:150] Setting up relu4_2_D
I0824 19:39:38.496182 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.496187 43244 net.cpp:165] Memory required for data: 3459502080
I0824 19:39:38.496191 43244 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 19:39:38.496207 43244 net.cpp:100] Creating Layer conv4_1_D
I0824 19:39:38.496212 43244 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 19:39:38.496220 43244 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 19:39:38.540088 43244 net.cpp:150] Setting up conv4_1_D
I0824 19:39:38.540107 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:38.540119 43244 net.cpp:165] Memory required for data: 3470561280
I0824 19:39:38.540128 43244 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 19:39:38.540138 43244 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 19:39:38.540145 43244 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 19:39:38.540153 43244 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 19:39:38.540398 43244 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 19:39:38.540423 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:38.540432 43244 net.cpp:165] Memory required for data: 3481620480
I0824 19:39:38.540483 43244 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 19:39:38.540493 43244 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 19:39:38.540499 43244 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 19:39:38.540505 43244 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 19:39:38.540561 43244 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 19:39:38.540702 43244 net.cpp:150] Setting up conv4_1_D_scale
I0824 19:39:38.540711 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:38.540715 43244 net.cpp:165] Memory required for data: 3492679680
I0824 19:39:38.540722 43244 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 19:39:38.540731 43244 net.cpp:100] Creating Layer relu4_1_D
I0824 19:39:38.540736 43244 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 19:39:38.540742 43244 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 19:39:38.540962 43244 net.cpp:150] Setting up relu4_1_D
I0824 19:39:38.540973 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:38.540978 43244 net.cpp:165] Memory required for data: 3503738880
I0824 19:39:38.540982 43244 layer_factory.hpp:77] Creating layer upsample3
I0824 19:39:38.540992 43244 net.cpp:100] Creating Layer upsample3
I0824 19:39:38.540997 43244 net.cpp:434] upsample3 <- conv4_1_D
I0824 19:39:38.541004 43244 net.cpp:434] upsample3 <- pool3_mask
I0824 19:39:38.541013 43244 net.cpp:408] upsample3 -> pool3_D
I0824 19:39:38.541021 43244 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 19:39:38.541055 43244 net.cpp:150] Setting up upsample3
I0824 19:39:38.541062 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.541065 43244 net.cpp:165] Memory required for data: 3547975680
I0824 19:39:38.541071 43244 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 19:39:38.541084 43244 net.cpp:100] Creating Layer conv3_3_D
I0824 19:39:38.541088 43244 net.cpp:434] conv3_3_D <- pool3_D
I0824 19:39:38.541098 43244 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 19:39:38.564606 43244 net.cpp:150] Setting up conv3_3_D
I0824 19:39:38.564625 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.564635 43244 net.cpp:165] Memory required for data: 3592212480
I0824 19:39:38.564643 43244 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 19:39:38.564657 43244 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 19:39:38.564663 43244 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 19:39:38.564671 43244 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 19:39:38.564926 43244 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 19:39:38.564935 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.564939 43244 net.cpp:165] Memory required for data: 3636449280
I0824 19:39:38.564947 43244 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 19:39:38.564962 43244 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 19:39:38.564970 43244 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 19:39:38.564975 43244 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 19:39:38.565023 43244 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 19:39:38.565191 43244 net.cpp:150] Setting up conv3_3_D_scale
I0824 19:39:38.565201 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.565203 43244 net.cpp:165] Memory required for data: 3680686080
I0824 19:39:38.565210 43244 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 19:39:38.565218 43244 net.cpp:100] Creating Layer relu3_3_D
I0824 19:39:38.565223 43244 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 19:39:38.565230 43244 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 19:39:38.565470 43244 net.cpp:150] Setting up relu3_3_D
I0824 19:39:38.565484 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.565487 43244 net.cpp:165] Memory required for data: 3724922880
I0824 19:39:38.565506 43244 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 19:39:38.565522 43244 net.cpp:100] Creating Layer conv3_2_D
I0824 19:39:38.565528 43244 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 19:39:38.565536 43244 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 19:39:38.588991 43244 net.cpp:150] Setting up conv3_2_D
I0824 19:39:38.589010 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.589022 43244 net.cpp:165] Memory required for data: 3769159680
I0824 19:39:38.589030 43244 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 19:39:38.589048 43244 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 19:39:38.589054 43244 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 19:39:38.589063 43244 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 19:39:38.589319 43244 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 19:39:38.589329 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.589332 43244 net.cpp:165] Memory required for data: 3813396480
I0824 19:39:38.589341 43244 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 19:39:38.589349 43244 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 19:39:38.589354 43244 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 19:39:38.589361 43244 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 19:39:38.589429 43244 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 19:39:38.589598 43244 net.cpp:150] Setting up conv3_2_D_scale
I0824 19:39:38.589609 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.589612 43244 net.cpp:165] Memory required for data: 3857633280
I0824 19:39:38.589619 43244 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 19:39:38.589628 43244 net.cpp:100] Creating Layer relu3_2_D
I0824 19:39:38.589633 43244 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 19:39:38.589637 43244 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 19:39:38.590739 43244 net.cpp:150] Setting up relu3_2_D
I0824 19:39:38.590754 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.590759 43244 net.cpp:165] Memory required for data: 3901870080
I0824 19:39:38.590764 43244 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 19:39:38.590780 43244 net.cpp:100] Creating Layer conv3_1_D
I0824 19:39:38.590786 43244 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 19:39:38.590793 43244 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 19:39:38.604522 43244 net.cpp:150] Setting up conv3_1_D
I0824 19:39:38.604542 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:38.604555 43244 net.cpp:165] Memory required for data: 3923988480
I0824 19:39:38.604564 43244 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 19:39:38.604574 43244 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 19:39:38.604580 43244 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 19:39:38.604586 43244 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 19:39:38.604846 43244 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 19:39:38.604854 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:38.604857 43244 net.cpp:165] Memory required for data: 3946106880
I0824 19:39:38.604866 43244 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 19:39:38.604882 43244 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 19:39:38.604888 43244 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 19:39:38.604893 43244 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 19:39:38.604943 43244 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 19:39:38.605114 43244 net.cpp:150] Setting up conv3_1_D_scale
I0824 19:39:38.605123 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:38.605128 43244 net.cpp:165] Memory required for data: 3968225280
I0824 19:39:38.605134 43244 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 19:39:38.605144 43244 net.cpp:100] Creating Layer relu3_1_D
I0824 19:39:38.605149 43244 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 19:39:38.605155 43244 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 19:39:38.605394 43244 net.cpp:150] Setting up relu3_1_D
I0824 19:39:38.605420 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:38.605424 43244 net.cpp:165] Memory required for data: 3990343680
I0824 19:39:38.605428 43244 layer_factory.hpp:77] Creating layer upsample2
I0824 19:39:38.605438 43244 net.cpp:100] Creating Layer upsample2
I0824 19:39:38.605444 43244 net.cpp:434] upsample2 <- conv3_1_D
I0824 19:39:38.605449 43244 net.cpp:434] upsample2 <- pool2_mask
I0824 19:39:38.605455 43244 net.cpp:408] upsample2 -> pool2_D
I0824 19:39:38.605466 43244 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 19:39:38.605502 43244 net.cpp:150] Setting up upsample2
I0824 19:39:38.605510 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.605514 43244 net.cpp:165] Memory required for data: 4078817280
I0824 19:39:38.605517 43244 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 19:39:38.605530 43244 net.cpp:100] Creating Layer conv2_2_D
I0824 19:39:38.605535 43244 net.cpp:434] conv2_2_D <- pool2_D
I0824 19:39:38.605543 43244 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 19:39:38.613214 43244 net.cpp:150] Setting up conv2_2_D
I0824 19:39:38.613234 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.613250 43244 net.cpp:165] Memory required for data: 4167290880
I0824 19:39:38.613260 43244 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 19:39:38.613275 43244 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 19:39:38.613283 43244 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 19:39:38.613292 43244 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 19:39:38.613615 43244 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 19:39:38.613627 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.613631 43244 net.cpp:165] Memory required for data: 4255764480
I0824 19:39:38.613639 43244 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 19:39:38.613656 43244 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 19:39:38.613663 43244 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 19:39:38.613669 43244 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 19:39:38.613723 43244 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 19:39:38.615212 43244 net.cpp:150] Setting up conv2_2_D_scale
I0824 19:39:38.615228 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.615237 43244 net.cpp:165] Memory required for data: 4344238080
I0824 19:39:38.615245 43244 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 19:39:38.615253 43244 net.cpp:100] Creating Layer relu2_2_D
I0824 19:39:38.615259 43244 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 19:39:38.615267 43244 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 19:39:38.615496 43244 net.cpp:150] Setting up relu2_2_D
I0824 19:39:38.615507 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.615512 43244 net.cpp:165] Memory required for data: 4432711680
I0824 19:39:38.615516 43244 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 19:39:38.615528 43244 net.cpp:100] Creating Layer conv2_1_D
I0824 19:39:38.615533 43244 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 19:39:38.615545 43244 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 19:39:38.620803 43244 net.cpp:150] Setting up conv2_1_D
I0824 19:39:38.620821 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:38.620832 43244 net.cpp:165] Memory required for data: 4476948480
I0824 19:39:38.620841 43244 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 19:39:38.620857 43244 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 19:39:38.620862 43244 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 19:39:38.620869 43244 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 19:39:38.621168 43244 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 19:39:38.621177 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:38.621181 43244 net.cpp:165] Memory required for data: 4521185280
I0824 19:39:38.621191 43244 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 19:39:38.621214 43244 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 19:39:38.621220 43244 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 19:39:38.621225 43244 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 19:39:38.621284 43244 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 19:39:38.621523 43244 net.cpp:150] Setting up conv2_1_D_scale
I0824 19:39:38.621536 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:38.621539 43244 net.cpp:165] Memory required for data: 4565422080
I0824 19:39:38.621546 43244 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 19:39:38.621554 43244 net.cpp:100] Creating Layer relu2_1_D
I0824 19:39:38.621559 43244 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 19:39:38.621567 43244 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 19:39:38.621793 43244 net.cpp:150] Setting up relu2_1_D
I0824 19:39:38.621804 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:38.621809 43244 net.cpp:165] Memory required for data: 4609658880
I0824 19:39:38.621814 43244 layer_factory.hpp:77] Creating layer upsample1
I0824 19:39:38.621824 43244 net.cpp:100] Creating Layer upsample1
I0824 19:39:38.621829 43244 net.cpp:434] upsample1 <- conv2_1_D
I0824 19:39:38.621834 43244 net.cpp:434] upsample1 <- pool1_mask
I0824 19:39:38.621840 43244 net.cpp:408] upsample1 -> pool1_D
I0824 19:39:38.621848 43244 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 19:39:38.621882 43244 net.cpp:150] Setting up upsample1
I0824 19:39:38.621889 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.621892 43244 net.cpp:165] Memory required for data: 4786606080
I0824 19:39:38.621898 43244 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 19:39:38.621912 43244 net.cpp:100] Creating Layer conv1_2_D
I0824 19:39:38.621917 43244 net.cpp:434] conv1_2_D <- pool1_D
I0824 19:39:38.621923 43244 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 19:39:38.626443 43244 net.cpp:150] Setting up conv1_2_D
I0824 19:39:38.626462 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.626477 43244 net.cpp:165] Memory required for data: 4963553280
I0824 19:39:38.626487 43244 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 19:39:38.626497 43244 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 19:39:38.626502 43244 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 19:39:38.626509 43244 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 19:39:38.626906 43244 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 19:39:38.626916 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.626921 43244 net.cpp:165] Memory required for data: 5140500480
I0824 19:39:38.626930 43244 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 19:39:38.626940 43244 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 19:39:38.626945 43244 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 19:39:38.626952 43244 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 19:39:38.627004 43244 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 19:39:38.628676 43244 net.cpp:150] Setting up conv1_2_D_scale
I0824 19:39:38.628691 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.628696 43244 net.cpp:165] Memory required for data: 5317447680
I0824 19:39:38.628705 43244 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 19:39:38.628715 43244 net.cpp:100] Creating Layer relu1_2_D
I0824 19:39:38.628721 43244 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 19:39:38.628728 43244 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 19:39:38.628965 43244 net.cpp:150] Setting up relu1_2_D
I0824 19:39:38.628976 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.628981 43244 net.cpp:165] Memory required for data: 5494394880
I0824 19:39:38.628985 43244 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 19:39:38.628998 43244 net.cpp:100] Creating Layer conv1_1_1_D
I0824 19:39:38.629004 43244 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 19:39:38.629027 43244 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 19:39:38.631116 43244 net.cpp:150] Setting up conv1_1_1_D
I0824 19:39:38.631134 43244 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 19:39:38.631140 43244 net.cpp:165] Memory required for data: 5499924480
I0824 19:39:38.631150 43244 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 19:39:38.631160 43244 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 19:39:38.631166 43244 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 19:39:38.631172 43244 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 19:39:38.631182 43244 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 19:39:38.631242 43244 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 19:39:38.631249 43244 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 19:39:38.631254 43244 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 19:39:38.631258 43244 net.cpp:165] Memory required for data: 5510983680
I0824 19:39:38.631264 43244 layer_factory.hpp:77] Creating layer loss
I0824 19:39:38.631278 43244 net.cpp:100] Creating Layer loss
I0824 19:39:38.631283 43244 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 19:39:38.631287 43244 net.cpp:434] loss <- label_data_1_split_0
I0824 19:39:38.631296 43244 net.cpp:408] loss -> loss
I0824 19:39:38.631315 43244 layer_factory.hpp:77] Creating layer loss
I0824 19:39:38.635404 43244 net.cpp:150] Setting up loss
I0824 19:39:38.635421 43244 net.cpp:157] Top shape: (1)
I0824 19:39:38.635424 43244 net.cpp:160]     with loss weight 1
I0824 19:39:38.635464 43244 net.cpp:165] Memory required for data: 5510983684
I0824 19:39:38.635470 43244 layer_factory.hpp:77] Creating layer accuracy
I0824 19:39:38.635488 43244 net.cpp:100] Creating Layer accuracy
I0824 19:39:38.635493 43244 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 19:39:38.635499 43244 net.cpp:434] accuracy <- label_data_1_split_1
I0824 19:39:38.635505 43244 net.cpp:408] accuracy -> accuracy
I0824 19:39:38.635514 43244 net.cpp:408] accuracy -> per_class_accuracy
I0824 19:39:38.635571 43244 net.cpp:150] Setting up accuracy
I0824 19:39:38.635578 43244 net.cpp:157] Top shape: (1)
I0824 19:39:38.635582 43244 net.cpp:157] Top shape: 2 (2)
I0824 19:39:38.635586 43244 net.cpp:165] Memory required for data: 5510983696
I0824 19:39:38.635589 43244 net.cpp:228] accuracy does not need backward computation.
I0824 19:39:38.635593 43244 net.cpp:226] loss needs backward computation.
I0824 19:39:38.635599 43244 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 19:39:38.635602 43244 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 19:39:38.635607 43244 net.cpp:226] relu1_2_D needs backward computation.
I0824 19:39:38.635609 43244 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 19:39:38.635612 43244 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 19:39:38.635615 43244 net.cpp:226] conv1_2_D needs backward computation.
I0824 19:39:38.635619 43244 net.cpp:226] upsample1 needs backward computation.
I0824 19:39:38.635623 43244 net.cpp:226] relu2_1_D needs backward computation.
I0824 19:39:38.635628 43244 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 19:39:38.635632 43244 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 19:39:38.635634 43244 net.cpp:226] conv2_1_D needs backward computation.
I0824 19:39:38.635637 43244 net.cpp:226] relu2_2_D needs backward computation.
I0824 19:39:38.635641 43244 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 19:39:38.635644 43244 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 19:39:38.635648 43244 net.cpp:226] conv2_2_D needs backward computation.
I0824 19:39:38.635650 43244 net.cpp:226] upsample2 needs backward computation.
I0824 19:39:38.635654 43244 net.cpp:226] relu3_1_D needs backward computation.
I0824 19:39:38.635658 43244 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 19:39:38.635675 43244 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 19:39:38.635679 43244 net.cpp:226] conv3_1_D needs backward computation.
I0824 19:39:38.635682 43244 net.cpp:226] relu3_2_D needs backward computation.
I0824 19:39:38.635685 43244 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 19:39:38.635689 43244 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 19:39:38.635692 43244 net.cpp:226] conv3_2_D needs backward computation.
I0824 19:39:38.635695 43244 net.cpp:226] relu3_3_D needs backward computation.
I0824 19:39:38.635699 43244 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 19:39:38.635701 43244 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 19:39:38.635705 43244 net.cpp:226] conv3_3_D needs backward computation.
I0824 19:39:38.635709 43244 net.cpp:226] upsample3 needs backward computation.
I0824 19:39:38.635712 43244 net.cpp:226] relu4_1_D needs backward computation.
I0824 19:39:38.635717 43244 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 19:39:38.635720 43244 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 19:39:38.635723 43244 net.cpp:226] conv4_1_D needs backward computation.
I0824 19:39:38.635727 43244 net.cpp:226] relu4_2_D needs backward computation.
I0824 19:39:38.635730 43244 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 19:39:38.635733 43244 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 19:39:38.635737 43244 net.cpp:226] conv4_2_D needs backward computation.
I0824 19:39:38.635742 43244 net.cpp:226] relu4_3_D needs backward computation.
I0824 19:39:38.635746 43244 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 19:39:38.635751 43244 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 19:39:38.635753 43244 net.cpp:226] conv4_3_D needs backward computation.
I0824 19:39:38.635757 43244 net.cpp:226] upsample4 needs backward computation.
I0824 19:39:38.635764 43244 net.cpp:226] relu5_1_D needs backward computation.
I0824 19:39:38.635768 43244 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 19:39:38.635772 43244 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 19:39:38.635776 43244 net.cpp:226] conv5_1_D needs backward computation.
I0824 19:39:38.635781 43244 net.cpp:226] relu5_2_D needs backward computation.
I0824 19:39:38.635784 43244 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 19:39:38.635789 43244 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 19:39:38.635794 43244 net.cpp:226] conv5_2_D needs backward computation.
I0824 19:39:38.635799 43244 net.cpp:226] relu5_3_D needs backward computation.
I0824 19:39:38.635803 43244 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 19:39:38.635808 43244 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 19:39:38.635812 43244 net.cpp:226] conv5_3_D needs backward computation.
I0824 19:39:38.635815 43244 net.cpp:226] upsample5 needs backward computation.
I0824 19:39:38.635820 43244 net.cpp:226] pool5 needs backward computation.
I0824 19:39:38.635826 43244 net.cpp:226] relu5_3 needs backward computation.
I0824 19:39:38.635830 43244 net.cpp:226] conv5_3_scale needs backward computation.
I0824 19:39:38.635833 43244 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 19:39:38.635838 43244 net.cpp:226] conv5_3 needs backward computation.
I0824 19:39:38.635841 43244 net.cpp:226] relu5_2 needs backward computation.
I0824 19:39:38.635846 43244 net.cpp:226] conv5_2_scale needs backward computation.
I0824 19:39:38.635849 43244 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 19:39:38.635852 43244 net.cpp:226] conv5_2 needs backward computation.
I0824 19:39:38.635856 43244 net.cpp:226] relu5_1 needs backward computation.
I0824 19:39:38.635862 43244 net.cpp:226] conv5_1_scale needs backward computation.
I0824 19:39:38.635865 43244 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 19:39:38.635870 43244 net.cpp:226] conv5_1 needs backward computation.
I0824 19:39:38.635874 43244 net.cpp:226] pool4 needs backward computation.
I0824 19:39:38.635885 43244 net.cpp:226] relu4_3 needs backward computation.
I0824 19:39:38.635890 43244 net.cpp:226] conv4_3_scale needs backward computation.
I0824 19:39:38.635892 43244 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 19:39:38.635896 43244 net.cpp:226] conv4_3 needs backward computation.
I0824 19:39:38.635900 43244 net.cpp:226] relu4_2 needs backward computation.
I0824 19:39:38.635906 43244 net.cpp:226] conv4_2_scale needs backward computation.
I0824 19:39:38.635910 43244 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 19:39:38.635912 43244 net.cpp:226] conv4_2 needs backward computation.
I0824 19:39:38.635916 43244 net.cpp:226] relu4_1 needs backward computation.
I0824 19:39:38.635920 43244 net.cpp:226] conv4_1_scale needs backward computation.
I0824 19:39:38.635923 43244 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 19:39:38.635926 43244 net.cpp:226] conv4_1 needs backward computation.
I0824 19:39:38.635931 43244 net.cpp:226] pool3 needs backward computation.
I0824 19:39:38.635936 43244 net.cpp:226] relu3_3 needs backward computation.
I0824 19:39:38.635941 43244 net.cpp:226] conv3_3_scale needs backward computation.
I0824 19:39:38.635944 43244 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 19:39:38.635947 43244 net.cpp:226] conv3_3 needs backward computation.
I0824 19:39:38.635951 43244 net.cpp:226] relu3_2 needs backward computation.
I0824 19:39:38.635954 43244 net.cpp:226] conv3_2_scale needs backward computation.
I0824 19:39:38.635958 43244 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 19:39:38.635963 43244 net.cpp:226] conv3_2 needs backward computation.
I0824 19:39:38.635967 43244 net.cpp:226] relu3_1 needs backward computation.
I0824 19:39:38.635972 43244 net.cpp:226] conv3_1_scale needs backward computation.
I0824 19:39:38.635977 43244 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 19:39:38.635979 43244 net.cpp:226] conv3_1 needs backward computation.
I0824 19:39:38.635983 43244 net.cpp:226] pool2 needs backward computation.
I0824 19:39:38.635987 43244 net.cpp:226] relu2_2 needs backward computation.
I0824 19:39:38.635992 43244 net.cpp:226] conv2_2_scale needs backward computation.
I0824 19:39:38.635994 43244 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 19:39:38.635998 43244 net.cpp:226] conv2_2 needs backward computation.
I0824 19:39:38.636001 43244 net.cpp:226] relu2_1 needs backward computation.
I0824 19:39:38.636005 43244 net.cpp:226] conv2_1_scale needs backward computation.
I0824 19:39:38.636008 43244 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 19:39:38.636014 43244 net.cpp:226] conv2_1 needs backward computation.
I0824 19:39:38.636018 43244 net.cpp:226] pool1 needs backward computation.
I0824 19:39:38.636023 43244 net.cpp:226] relu1_2 needs backward computation.
I0824 19:39:38.636025 43244 net.cpp:226] conv1_2_scale needs backward computation.
I0824 19:39:38.636030 43244 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 19:39:38.636035 43244 net.cpp:226] conv1_2 needs backward computation.
I0824 19:39:38.636039 43244 net.cpp:226] relu1_1 needs backward computation.
I0824 19:39:38.636044 43244 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 19:39:38.636049 43244 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 19:39:38.636051 43244 net.cpp:226] conv1_1_1 needs backward computation.
I0824 19:39:38.636056 43244 net.cpp:228] label_data_1_split does not need backward computation.
I0824 19:39:38.636063 43244 net.cpp:228] data does not need backward computation.
I0824 19:39:38.636067 43244 net.cpp:270] This network produces output accuracy
I0824 19:39:38.636072 43244 net.cpp:270] This network produces output loss
I0824 19:39:38.636076 43244 net.cpp:270] This network produces output per_class_accuracy
I0824 19:39:38.636142 43244 net.cpp:283] Network initialization done.
I0824 19:39:38.638509 43244 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc4/caffe/model_segnet_final/train.prototxt
I0824 19:39:38.639204 43244 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc4/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 19:39:38.639621 43244 layer_factory.hpp:77] Creating layer data
I0824 19:39:38.639633 43244 net.cpp:100] Creating Layer data
I0824 19:39:38.639639 43244 net.cpp:408] data -> data
I0824 19:39:38.639647 43244 net.cpp:408] data -> label
I0824 19:39:38.639657 43244 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc4/HDF5Files/train_combined.txt
I0824 19:39:38.639709 43244 hdf5_data_layer.cpp:93] Number of HDF5 files: 53
I0824 19:39:38.702630 43244 net.cpp:150] Setting up data
I0824 19:39:38.702651 43244 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 19:39:38.702657 43244 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 19:39:38.702661 43244 net.cpp:165] Memory required for data: 24883200
I0824 19:39:38.702666 43244 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 19:39:38.702684 43244 net.cpp:100] Creating Layer label_data_1_split
I0824 19:39:38.702690 43244 net.cpp:434] label_data_1_split <- label
I0824 19:39:38.702697 43244 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 19:39:38.702705 43244 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 19:39:38.702756 43244 net.cpp:150] Setting up label_data_1_split
I0824 19:39:38.702764 43244 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 19:39:38.702769 43244 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 19:39:38.702778 43244 net.cpp:165] Memory required for data: 30412800
I0824 19:39:38.702781 43244 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 19:39:38.702792 43244 net.cpp:100] Creating Layer conv1_1_1
I0824 19:39:38.702798 43244 net.cpp:434] conv1_1_1 <- data
I0824 19:39:38.702805 43244 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 19:39:38.706323 43244 net.cpp:150] Setting up conv1_1_1
I0824 19:39:38.706342 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.706356 43244 net.cpp:165] Memory required for data: 207360000
I0824 19:39:38.706368 43244 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 19:39:38.706379 43244 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 19:39:38.706387 43244 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 19:39:38.706393 43244 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 19:39:38.706781 43244 net.cpp:150] Setting up conv1_1_1_bn
I0824 19:39:38.706791 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.706795 43244 net.cpp:165] Memory required for data: 384307200
I0824 19:39:38.706809 43244 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 19:39:38.706816 43244 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 19:39:38.706821 43244 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 19:39:38.706827 43244 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 19:39:38.706878 43244 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 19:39:38.708577 43244 net.cpp:150] Setting up conv1_1_1_scale
I0824 19:39:38.708593 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.708598 43244 net.cpp:165] Memory required for data: 561254400
I0824 19:39:38.708606 43244 layer_factory.hpp:77] Creating layer relu1_1
I0824 19:39:38.708616 43244 net.cpp:100] Creating Layer relu1_1
I0824 19:39:38.708621 43244 net.cpp:434] relu1_1 <- conv1_1_1
I0824 19:39:38.708626 43244 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 19:39:38.708847 43244 net.cpp:150] Setting up relu1_1
I0824 19:39:38.708858 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.708863 43244 net.cpp:165] Memory required for data: 738201600
I0824 19:39:38.708866 43244 layer_factory.hpp:77] Creating layer conv1_2
I0824 19:39:38.708876 43244 net.cpp:100] Creating Layer conv1_2
I0824 19:39:38.708880 43244 net.cpp:434] conv1_2 <- conv1_1_1
I0824 19:39:38.708887 43244 net.cpp:408] conv1_2 -> conv1_2
I0824 19:39:38.712999 43244 net.cpp:150] Setting up conv1_2
I0824 19:39:38.713016 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.713029 43244 net.cpp:165] Memory required for data: 915148800
I0824 19:39:38.713063 43244 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 19:39:38.713073 43244 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 19:39:38.713078 43244 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 19:39:38.713083 43244 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 19:39:38.713472 43244 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 19:39:38.713484 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.713486 43244 net.cpp:165] Memory required for data: 1092096000
I0824 19:39:38.713495 43244 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 19:39:38.713505 43244 net.cpp:100] Creating Layer conv1_2_scale
I0824 19:39:38.713510 43244 net.cpp:434] conv1_2_scale <- conv1_2
I0824 19:39:38.713515 43244 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 19:39:38.713568 43244 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 19:39:38.715275 43244 net.cpp:150] Setting up conv1_2_scale
I0824 19:39:38.715291 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.715294 43244 net.cpp:165] Memory required for data: 1269043200
I0824 19:39:38.715302 43244 layer_factory.hpp:77] Creating layer relu1_2
I0824 19:39:38.715311 43244 net.cpp:100] Creating Layer relu1_2
I0824 19:39:38.715315 43244 net.cpp:434] relu1_2 <- conv1_2
I0824 19:39:38.715322 43244 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 19:39:38.716442 43244 net.cpp:150] Setting up relu1_2
I0824 19:39:38.716457 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:38.716462 43244 net.cpp:165] Memory required for data: 1445990400
I0824 19:39:38.716466 43244 layer_factory.hpp:77] Creating layer pool1
I0824 19:39:38.716471 43244 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 19:39:38.716482 43244 net.cpp:100] Creating Layer pool1
I0824 19:39:38.716487 43244 net.cpp:434] pool1 <- conv1_2
I0824 19:39:38.716493 43244 net.cpp:408] pool1 -> pool1
I0824 19:39:38.716502 43244 net.cpp:408] pool1 -> pool1_mask
I0824 19:39:38.716563 43244 net.cpp:150] Setting up pool1
I0824 19:39:38.716572 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:38.716576 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:38.716580 43244 net.cpp:165] Memory required for data: 1534464000
I0824 19:39:38.716583 43244 layer_factory.hpp:77] Creating layer conv2_1
I0824 19:39:38.716593 43244 net.cpp:100] Creating Layer conv2_1
I0824 19:39:38.716598 43244 net.cpp:434] conv2_1 <- pool1
I0824 19:39:38.716606 43244 net.cpp:408] conv2_1 -> conv2_1
I0824 19:39:38.720954 43244 net.cpp:150] Setting up conv2_1
I0824 19:39:38.720971 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.720983 43244 net.cpp:165] Memory required for data: 1622937600
I0824 19:39:38.720989 43244 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 19:39:38.721002 43244 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 19:39:38.721009 43244 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 19:39:38.721015 43244 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 19:39:38.721330 43244 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 19:39:38.721340 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.721345 43244 net.cpp:165] Memory required for data: 1711411200
I0824 19:39:38.721360 43244 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 19:39:38.721376 43244 net.cpp:100] Creating Layer conv2_1_scale
I0824 19:39:38.721381 43244 net.cpp:434] conv2_1_scale <- conv2_1
I0824 19:39:38.721386 43244 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 19:39:38.721444 43244 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 19:39:38.721683 43244 net.cpp:150] Setting up conv2_1_scale
I0824 19:39:38.721694 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.721699 43244 net.cpp:165] Memory required for data: 1799884800
I0824 19:39:38.721706 43244 layer_factory.hpp:77] Creating layer relu2_1
I0824 19:39:38.721715 43244 net.cpp:100] Creating Layer relu2_1
I0824 19:39:38.721720 43244 net.cpp:434] relu2_1 <- conv2_1
I0824 19:39:38.721725 43244 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 19:39:38.722868 43244 net.cpp:150] Setting up relu2_1
I0824 19:39:38.722883 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.722888 43244 net.cpp:165] Memory required for data: 1888358400
I0824 19:39:38.722892 43244 layer_factory.hpp:77] Creating layer conv2_2
I0824 19:39:38.722905 43244 net.cpp:100] Creating Layer conv2_2
I0824 19:39:38.722910 43244 net.cpp:434] conv2_2 <- conv2_1
I0824 19:39:38.722919 43244 net.cpp:408] conv2_2 -> conv2_2
I0824 19:39:38.731973 43244 net.cpp:150] Setting up conv2_2
I0824 19:39:38.731992 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.732005 43244 net.cpp:165] Memory required for data: 1976832000
I0824 19:39:38.732014 43244 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 19:39:38.732028 43244 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 19:39:38.732034 43244 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 19:39:38.732041 43244 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 19:39:38.733633 43244 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 19:39:38.733650 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.733654 43244 net.cpp:165] Memory required for data: 2065305600
I0824 19:39:38.733664 43244 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 19:39:38.733672 43244 net.cpp:100] Creating Layer conv2_2_scale
I0824 19:39:38.733675 43244 net.cpp:434] conv2_2_scale <- conv2_2
I0824 19:39:38.733681 43244 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 19:39:38.733741 43244 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 19:39:38.733958 43244 net.cpp:150] Setting up conv2_2_scale
I0824 19:39:38.733966 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.733970 43244 net.cpp:165] Memory required for data: 2153779200
I0824 19:39:38.733978 43244 layer_factory.hpp:77] Creating layer relu2_2
I0824 19:39:38.733988 43244 net.cpp:100] Creating Layer relu2_2
I0824 19:39:38.733995 43244 net.cpp:434] relu2_2 <- conv2_2
I0824 19:39:38.734000 43244 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 19:39:38.734226 43244 net.cpp:150] Setting up relu2_2
I0824 19:39:38.734236 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:38.734241 43244 net.cpp:165] Memory required for data: 2242252800
I0824 19:39:38.734246 43244 layer_factory.hpp:77] Creating layer pool2
I0824 19:39:38.734249 43244 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 19:39:38.734256 43244 net.cpp:100] Creating Layer pool2
I0824 19:39:38.734261 43244 net.cpp:434] pool2 <- conv2_2
I0824 19:39:38.734268 43244 net.cpp:408] pool2 -> pool2
I0824 19:39:38.734277 43244 net.cpp:408] pool2 -> pool2_mask
I0824 19:39:38.734334 43244 net.cpp:150] Setting up pool2
I0824 19:39:38.734344 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:38.734349 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:38.734352 43244 net.cpp:165] Memory required for data: 2286489600
I0824 19:39:38.734357 43244 layer_factory.hpp:77] Creating layer conv3_1
I0824 19:39:38.734370 43244 net.cpp:100] Creating Layer conv3_1
I0824 19:39:38.734375 43244 net.cpp:434] conv3_1 <- pool2
I0824 19:39:38.734381 43244 net.cpp:408] conv3_1 -> conv3_1
I0824 19:39:38.746919 43244 net.cpp:150] Setting up conv3_1
I0824 19:39:38.746938 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.746953 43244 net.cpp:165] Memory required for data: 2330726400
I0824 19:39:38.746963 43244 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 19:39:38.746971 43244 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 19:39:38.746978 43244 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 19:39:38.746984 43244 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 19:39:38.747270 43244 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 19:39:38.747279 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.747282 43244 net.cpp:165] Memory required for data: 2374963200
I0824 19:39:38.747298 43244 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 19:39:38.747321 43244 net.cpp:100] Creating Layer conv3_1_scale
I0824 19:39:38.747329 43244 net.cpp:434] conv3_1_scale <- conv3_1
I0824 19:39:38.747335 43244 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 19:39:38.747393 43244 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 19:39:38.747575 43244 net.cpp:150] Setting up conv3_1_scale
I0824 19:39:38.747584 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.747588 43244 net.cpp:165] Memory required for data: 2419200000
I0824 19:39:38.747596 43244 layer_factory.hpp:77] Creating layer relu3_1
I0824 19:39:38.747602 43244 net.cpp:100] Creating Layer relu3_1
I0824 19:39:38.747607 43244 net.cpp:434] relu3_1 <- conv3_1
I0824 19:39:38.747614 43244 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 19:39:38.747841 43244 net.cpp:150] Setting up relu3_1
I0824 19:39:38.747853 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.747856 43244 net.cpp:165] Memory required for data: 2463436800
I0824 19:39:38.747860 43244 layer_factory.hpp:77] Creating layer conv3_2
I0824 19:39:38.747874 43244 net.cpp:100] Creating Layer conv3_2
I0824 19:39:38.747879 43244 net.cpp:434] conv3_2 <- conv3_1
I0824 19:39:38.747886 43244 net.cpp:408] conv3_2 -> conv3_2
I0824 19:39:38.771538 43244 net.cpp:150] Setting up conv3_2
I0824 19:39:38.771558 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.771572 43244 net.cpp:165] Memory required for data: 2507673600
I0824 19:39:38.771580 43244 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 19:39:38.771592 43244 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 19:39:38.771600 43244 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 19:39:38.771607 43244 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 19:39:38.771895 43244 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 19:39:38.771904 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.771908 43244 net.cpp:165] Memory required for data: 2551910400
I0824 19:39:38.771916 43244 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 19:39:38.771930 43244 net.cpp:100] Creating Layer conv3_2_scale
I0824 19:39:38.771936 43244 net.cpp:434] conv3_2_scale <- conv3_2
I0824 19:39:38.771941 43244 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 19:39:38.771996 43244 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 19:39:38.772178 43244 net.cpp:150] Setting up conv3_2_scale
I0824 19:39:38.772187 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.772192 43244 net.cpp:165] Memory required for data: 2596147200
I0824 19:39:38.772197 43244 layer_factory.hpp:77] Creating layer relu3_2
I0824 19:39:38.772205 43244 net.cpp:100] Creating Layer relu3_2
I0824 19:39:38.772210 43244 net.cpp:434] relu3_2 <- conv3_2
I0824 19:39:38.772214 43244 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 19:39:38.772446 43244 net.cpp:150] Setting up relu3_2
I0824 19:39:38.772457 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.772462 43244 net.cpp:165] Memory required for data: 2640384000
I0824 19:39:38.772466 43244 layer_factory.hpp:77] Creating layer conv3_3
I0824 19:39:38.772477 43244 net.cpp:100] Creating Layer conv3_3
I0824 19:39:38.772482 43244 net.cpp:434] conv3_3 <- conv3_2
I0824 19:39:38.772491 43244 net.cpp:408] conv3_3 -> conv3_3
I0824 19:39:38.796066 43244 net.cpp:150] Setting up conv3_3
I0824 19:39:38.796083 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.796099 43244 net.cpp:165] Memory required for data: 2684620800
I0824 19:39:38.796108 43244 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 19:39:38.796115 43244 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 19:39:38.796123 43244 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 19:39:38.796131 43244 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 19:39:38.796416 43244 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 19:39:38.796424 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.796428 43244 net.cpp:165] Memory required for data: 2728857600
I0824 19:39:38.796437 43244 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 19:39:38.796459 43244 net.cpp:100] Creating Layer conv3_3_scale
I0824 19:39:38.796468 43244 net.cpp:434] conv3_3_scale <- conv3_3
I0824 19:39:38.796473 43244 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 19:39:38.796528 43244 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 19:39:38.796708 43244 net.cpp:150] Setting up conv3_3_scale
I0824 19:39:38.796717 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.796722 43244 net.cpp:165] Memory required for data: 2773094400
I0824 19:39:38.796730 43244 layer_factory.hpp:77] Creating layer relu3_3
I0824 19:39:38.796736 43244 net.cpp:100] Creating Layer relu3_3
I0824 19:39:38.796741 43244 net.cpp:434] relu3_3 <- conv3_3
I0824 19:39:38.796748 43244 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 19:39:38.796983 43244 net.cpp:150] Setting up relu3_3
I0824 19:39:38.796993 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:38.796998 43244 net.cpp:165] Memory required for data: 2817331200
I0824 19:39:38.797003 43244 layer_factory.hpp:77] Creating layer pool3
I0824 19:39:38.797006 43244 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 19:39:38.797019 43244 net.cpp:100] Creating Layer pool3
I0824 19:39:38.797024 43244 net.cpp:434] pool3 <- conv3_3
I0824 19:39:38.797030 43244 net.cpp:408] pool3 -> pool3
I0824 19:39:38.797041 43244 net.cpp:408] pool3 -> pool3_mask
I0824 19:39:38.797101 43244 net.cpp:150] Setting up pool3
I0824 19:39:38.797109 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:38.797114 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:38.797118 43244 net.cpp:165] Memory required for data: 2839449600
I0824 19:39:38.797122 43244 layer_factory.hpp:77] Creating layer conv4_1
I0824 19:39:38.797137 43244 net.cpp:100] Creating Layer conv4_1
I0824 19:39:38.797142 43244 net.cpp:434] conv4_1 <- pool3
I0824 19:39:38.797149 43244 net.cpp:408] conv4_1 -> conv4_1
I0824 19:39:38.841130 43244 net.cpp:150] Setting up conv4_1
I0824 19:39:38.841147 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.841158 43244 net.cpp:165] Memory required for data: 2861568000
I0824 19:39:38.841167 43244 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 19:39:38.841177 43244 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 19:39:38.841183 43244 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 19:39:38.841189 43244 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 19:39:38.841478 43244 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 19:39:38.841490 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.841493 43244 net.cpp:165] Memory required for data: 2883686400
I0824 19:39:38.841501 43244 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 19:39:38.841508 43244 net.cpp:100] Creating Layer conv4_1_scale
I0824 19:39:38.841512 43244 net.cpp:434] conv4_1_scale <- conv4_1
I0824 19:39:38.841519 43244 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 19:39:38.841574 43244 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 19:39:38.841742 43244 net.cpp:150] Setting up conv4_1_scale
I0824 19:39:38.841750 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.841754 43244 net.cpp:165] Memory required for data: 2905804800
I0824 19:39:38.841761 43244 layer_factory.hpp:77] Creating layer relu4_1
I0824 19:39:38.841769 43244 net.cpp:100] Creating Layer relu4_1
I0824 19:39:38.841773 43244 net.cpp:434] relu4_1 <- conv4_1
I0824 19:39:38.841778 43244 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 19:39:38.842926 43244 net.cpp:150] Setting up relu4_1
I0824 19:39:38.842941 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.842947 43244 net.cpp:165] Memory required for data: 2927923200
I0824 19:39:38.842950 43244 layer_factory.hpp:77] Creating layer conv4_2
I0824 19:39:38.842970 43244 net.cpp:100] Creating Layer conv4_2
I0824 19:39:38.842975 43244 net.cpp:434] conv4_2 <- conv4_1
I0824 19:39:38.842983 43244 net.cpp:408] conv4_2 -> conv4_2
I0824 19:39:38.925825 43244 net.cpp:150] Setting up conv4_2
I0824 19:39:38.925858 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.925873 43244 net.cpp:165] Memory required for data: 2950041600
I0824 19:39:38.925880 43244 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 19:39:38.925890 43244 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 19:39:38.925896 43244 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 19:39:38.925904 43244 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 19:39:38.926182 43244 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 19:39:38.926190 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.926193 43244 net.cpp:165] Memory required for data: 2972160000
I0824 19:39:38.926203 43244 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 19:39:38.926216 43244 net.cpp:100] Creating Layer conv4_2_scale
I0824 19:39:38.926223 43244 net.cpp:434] conv4_2_scale <- conv4_2
I0824 19:39:38.926228 43244 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 19:39:38.926276 43244 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 19:39:38.926442 43244 net.cpp:150] Setting up conv4_2_scale
I0824 19:39:38.926451 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.926455 43244 net.cpp:165] Memory required for data: 2994278400
I0824 19:39:38.926461 43244 layer_factory.hpp:77] Creating layer relu4_2
I0824 19:39:38.926470 43244 net.cpp:100] Creating Layer relu4_2
I0824 19:39:38.926475 43244 net.cpp:434] relu4_2 <- conv4_2
I0824 19:39:38.926484 43244 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 19:39:38.927646 43244 net.cpp:150] Setting up relu4_2
I0824 19:39:38.927661 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:38.927667 43244 net.cpp:165] Memory required for data: 3016396800
I0824 19:39:38.927671 43244 layer_factory.hpp:77] Creating layer conv4_3
I0824 19:39:38.927685 43244 net.cpp:100] Creating Layer conv4_3
I0824 19:39:38.927690 43244 net.cpp:434] conv4_3 <- conv4_2
I0824 19:39:38.927700 43244 net.cpp:408] conv4_3 -> conv4_3
I0824 19:39:39.011358 43244 net.cpp:150] Setting up conv4_3
I0824 19:39:39.011375 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.011379 43244 net.cpp:165] Memory required for data: 3038515200
I0824 19:39:39.011404 43244 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 19:39:39.011415 43244 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 19:39:39.011423 43244 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 19:39:39.011431 43244 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 19:39:39.011709 43244 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 19:39:39.011718 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.011723 43244 net.cpp:165] Memory required for data: 3060633600
I0824 19:39:39.011730 43244 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 19:39:39.011744 43244 net.cpp:100] Creating Layer conv4_3_scale
I0824 19:39:39.011752 43244 net.cpp:434] conv4_3_scale <- conv4_3
I0824 19:39:39.011757 43244 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 19:39:39.011814 43244 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 19:39:39.011981 43244 net.cpp:150] Setting up conv4_3_scale
I0824 19:39:39.011988 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.011992 43244 net.cpp:165] Memory required for data: 3082752000
I0824 19:39:39.011999 43244 layer_factory.hpp:77] Creating layer relu4_3
I0824 19:39:39.012006 43244 net.cpp:100] Creating Layer relu4_3
I0824 19:39:39.012013 43244 net.cpp:434] relu4_3 <- conv4_3
I0824 19:39:39.012018 43244 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 19:39:39.012240 43244 net.cpp:150] Setting up relu4_3
I0824 19:39:39.012251 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.012255 43244 net.cpp:165] Memory required for data: 3104870400
I0824 19:39:39.012259 43244 layer_factory.hpp:77] Creating layer pool4
I0824 19:39:39.012264 43244 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 19:39:39.012271 43244 net.cpp:100] Creating Layer pool4
I0824 19:39:39.012276 43244 net.cpp:434] pool4 <- conv4_3
I0824 19:39:39.012298 43244 net.cpp:408] pool4 -> pool4
I0824 19:39:39.012307 43244 net.cpp:408] pool4 -> pool4_mask
I0824 19:39:39.012370 43244 net.cpp:150] Setting up pool4
I0824 19:39:39.012378 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.012383 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.012387 43244 net.cpp:165] Memory required for data: 3116175360
I0824 19:39:39.012392 43244 layer_factory.hpp:77] Creating layer conv5_1
I0824 19:39:39.012403 43244 net.cpp:100] Creating Layer conv5_1
I0824 19:39:39.012408 43244 net.cpp:434] conv5_1 <- pool4
I0824 19:39:39.012415 43244 net.cpp:408] conv5_1 -> conv5_1
I0824 19:39:39.096113 43244 net.cpp:150] Setting up conv5_1
I0824 19:39:39.096132 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.096135 43244 net.cpp:165] Memory required for data: 3121827840
I0824 19:39:39.096143 43244 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 19:39:39.096154 43244 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 19:39:39.096163 43244 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 19:39:39.096169 43244 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 19:39:39.096446 43244 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 19:39:39.096456 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.096459 43244 net.cpp:165] Memory required for data: 3127480320
I0824 19:39:39.096467 43244 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 19:39:39.096482 43244 net.cpp:100] Creating Layer conv5_1_scale
I0824 19:39:39.096487 43244 net.cpp:434] conv5_1_scale <- conv5_1
I0824 19:39:39.096493 43244 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 19:39:39.096556 43244 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 19:39:39.096711 43244 net.cpp:150] Setting up conv5_1_scale
I0824 19:39:39.096720 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.096724 43244 net.cpp:165] Memory required for data: 3133132800
I0824 19:39:39.096730 43244 layer_factory.hpp:77] Creating layer relu5_1
I0824 19:39:39.096738 43244 net.cpp:100] Creating Layer relu5_1
I0824 19:39:39.096743 43244 net.cpp:434] relu5_1 <- conv5_1
I0824 19:39:39.096751 43244 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 19:39:39.096971 43244 net.cpp:150] Setting up relu5_1
I0824 19:39:39.096982 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.096987 43244 net.cpp:165] Memory required for data: 3138785280
I0824 19:39:39.096990 43244 layer_factory.hpp:77] Creating layer conv5_2
I0824 19:39:39.097004 43244 net.cpp:100] Creating Layer conv5_2
I0824 19:39:39.097009 43244 net.cpp:434] conv5_2 <- conv5_1
I0824 19:39:39.097017 43244 net.cpp:408] conv5_2 -> conv5_2
I0824 19:39:39.180728 43244 net.cpp:150] Setting up conv5_2
I0824 19:39:39.180748 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.180760 43244 net.cpp:165] Memory required for data: 3144437760
I0824 19:39:39.180768 43244 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 19:39:39.180778 43244 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 19:39:39.180788 43244 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 19:39:39.180796 43244 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 19:39:39.181068 43244 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 19:39:39.181077 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.181080 43244 net.cpp:165] Memory required for data: 3150090240
I0824 19:39:39.181089 43244 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 19:39:39.181102 43244 net.cpp:100] Creating Layer conv5_2_scale
I0824 19:39:39.181110 43244 net.cpp:434] conv5_2_scale <- conv5_2
I0824 19:39:39.181116 43244 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 19:39:39.181175 43244 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 19:39:39.181331 43244 net.cpp:150] Setting up conv5_2_scale
I0824 19:39:39.181340 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.181344 43244 net.cpp:165] Memory required for data: 3155742720
I0824 19:39:39.181350 43244 layer_factory.hpp:77] Creating layer relu5_2
I0824 19:39:39.181383 43244 net.cpp:100] Creating Layer relu5_2
I0824 19:39:39.181388 43244 net.cpp:434] relu5_2 <- conv5_2
I0824 19:39:39.181396 43244 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 19:39:39.181617 43244 net.cpp:150] Setting up relu5_2
I0824 19:39:39.181629 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.181633 43244 net.cpp:165] Memory required for data: 3161395200
I0824 19:39:39.181638 43244 layer_factory.hpp:77] Creating layer conv5_3
I0824 19:39:39.181653 43244 net.cpp:100] Creating Layer conv5_3
I0824 19:39:39.181658 43244 net.cpp:434] conv5_3 <- conv5_2
I0824 19:39:39.181668 43244 net.cpp:408] conv5_3 -> conv5_3
I0824 19:39:39.265290 43244 net.cpp:150] Setting up conv5_3
I0824 19:39:39.265308 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.265312 43244 net.cpp:165] Memory required for data: 3167047680
I0824 19:39:39.265321 43244 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 19:39:39.265328 43244 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 19:39:39.265333 43244 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 19:39:39.265348 43244 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 19:39:39.265642 43244 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 19:39:39.265655 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.265657 43244 net.cpp:165] Memory required for data: 3172700160
I0824 19:39:39.265666 43244 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 19:39:39.265684 43244 net.cpp:100] Creating Layer conv5_3_scale
I0824 19:39:39.265693 43244 net.cpp:434] conv5_3_scale <- conv5_3
I0824 19:39:39.265698 43244 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 19:39:39.265758 43244 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 19:39:39.265915 43244 net.cpp:150] Setting up conv5_3_scale
I0824 19:39:39.265923 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.265926 43244 net.cpp:165] Memory required for data: 3178352640
I0824 19:39:39.265933 43244 layer_factory.hpp:77] Creating layer relu5_3
I0824 19:39:39.265945 43244 net.cpp:100] Creating Layer relu5_3
I0824 19:39:39.265950 43244 net.cpp:434] relu5_3 <- conv5_3
I0824 19:39:39.265955 43244 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 19:39:39.266176 43244 net.cpp:150] Setting up relu5_3
I0824 19:39:39.266186 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.266191 43244 net.cpp:165] Memory required for data: 3184005120
I0824 19:39:39.266196 43244 layer_factory.hpp:77] Creating layer pool5
I0824 19:39:39.266199 43244 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 19:39:39.266207 43244 net.cpp:100] Creating Layer pool5
I0824 19:39:39.266212 43244 net.cpp:434] pool5 <- conv5_3
I0824 19:39:39.266218 43244 net.cpp:408] pool5 -> pool5
I0824 19:39:39.266227 43244 net.cpp:408] pool5 -> pool5_mask
I0824 19:39:39.266291 43244 net.cpp:150] Setting up pool5
I0824 19:39:39.266299 43244 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 19:39:39.266304 43244 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 19:39:39.266307 43244 net.cpp:165] Memory required for data: 3186954240
I0824 19:39:39.266312 43244 layer_factory.hpp:77] Creating layer upsample5
I0824 19:39:39.266320 43244 net.cpp:100] Creating Layer upsample5
I0824 19:39:39.266324 43244 net.cpp:434] upsample5 <- pool5
I0824 19:39:39.266330 43244 net.cpp:434] upsample5 <- pool5_mask
I0824 19:39:39.266337 43244 net.cpp:408] upsample5 -> pool5_D
I0824 19:39:39.266373 43244 net.cpp:150] Setting up upsample5
I0824 19:39:39.266381 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.266384 43244 net.cpp:165] Memory required for data: 3192606720
I0824 19:39:39.266387 43244 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 19:39:39.266399 43244 net.cpp:100] Creating Layer conv5_3_D
I0824 19:39:39.266404 43244 net.cpp:434] conv5_3_D <- pool5_D
I0824 19:39:39.266413 43244 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 19:39:39.350775 43244 net.cpp:150] Setting up conv5_3_D
I0824 19:39:39.350800 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.350822 43244 net.cpp:165] Memory required for data: 3198259200
I0824 19:39:39.350837 43244 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 19:39:39.350850 43244 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 19:39:39.350860 43244 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 19:39:39.350872 43244 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 19:39:39.351152 43244 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 19:39:39.351161 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.351166 43244 net.cpp:165] Memory required for data: 3203911680
I0824 19:39:39.351174 43244 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 19:39:39.351184 43244 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 19:39:39.351189 43244 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 19:39:39.351196 43244 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 19:39:39.351256 43244 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 19:39:39.351414 43244 net.cpp:150] Setting up conv5_3_D_scale
I0824 19:39:39.351423 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.351428 43244 net.cpp:165] Memory required for data: 3209564160
I0824 19:39:39.351434 43244 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 19:39:39.351441 43244 net.cpp:100] Creating Layer relu5_3_D
I0824 19:39:39.351445 43244 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 19:39:39.351454 43244 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 19:39:39.352607 43244 net.cpp:150] Setting up relu5_3_D
I0824 19:39:39.352623 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.352628 43244 net.cpp:165] Memory required for data: 3215216640
I0824 19:39:39.352632 43244 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 19:39:39.352680 43244 net.cpp:100] Creating Layer conv5_2_D
I0824 19:39:39.352689 43244 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 19:39:39.352696 43244 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 19:39:39.436388 43244 net.cpp:150] Setting up conv5_2_D
I0824 19:39:39.436405 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.436410 43244 net.cpp:165] Memory required for data: 3220869120
I0824 19:39:39.436419 43244 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 19:39:39.436435 43244 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 19:39:39.436441 43244 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 19:39:39.436449 43244 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 19:39:39.436738 43244 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 19:39:39.436746 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.436750 43244 net.cpp:165] Memory required for data: 3226521600
I0824 19:39:39.436760 43244 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 19:39:39.436774 43244 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 19:39:39.436780 43244 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 19:39:39.436785 43244 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 19:39:39.436846 43244 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 19:39:39.437007 43244 net.cpp:150] Setting up conv5_2_D_scale
I0824 19:39:39.437016 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.437019 43244 net.cpp:165] Memory required for data: 3232174080
I0824 19:39:39.437026 43244 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 19:39:39.437036 43244 net.cpp:100] Creating Layer relu5_2_D
I0824 19:39:39.437041 43244 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 19:39:39.437046 43244 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 19:39:39.438237 43244 net.cpp:150] Setting up relu5_2_D
I0824 19:39:39.438256 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.438261 43244 net.cpp:165] Memory required for data: 3237826560
I0824 19:39:39.438266 43244 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 19:39:39.438279 43244 net.cpp:100] Creating Layer conv5_1_D
I0824 19:39:39.438285 43244 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 19:39:39.438292 43244 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 19:39:39.522253 43244 net.cpp:150] Setting up conv5_1_D
I0824 19:39:39.522271 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.522286 43244 net.cpp:165] Memory required for data: 3243479040
I0824 19:39:39.522294 43244 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 19:39:39.522306 43244 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 19:39:39.522315 43244 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 19:39:39.522321 43244 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 19:39:39.522603 43244 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 19:39:39.522613 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.522615 43244 net.cpp:165] Memory required for data: 3249131520
I0824 19:39:39.522624 43244 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 19:39:39.522639 43244 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 19:39:39.522646 43244 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 19:39:39.522651 43244 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 19:39:39.522712 43244 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 19:39:39.522876 43244 net.cpp:150] Setting up conv5_1_D_scale
I0824 19:39:39.522884 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.522888 43244 net.cpp:165] Memory required for data: 3254784000
I0824 19:39:39.522897 43244 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 19:39:39.522904 43244 net.cpp:100] Creating Layer relu5_1_D
I0824 19:39:39.522909 43244 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 19:39:39.522918 43244 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 19:39:39.523150 43244 net.cpp:150] Setting up relu5_1_D
I0824 19:39:39.523160 43244 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 19:39:39.523165 43244 net.cpp:165] Memory required for data: 3260436480
I0824 19:39:39.523169 43244 layer_factory.hpp:77] Creating layer upsample4
I0824 19:39:39.523177 43244 net.cpp:100] Creating Layer upsample4
I0824 19:39:39.523182 43244 net.cpp:434] upsample4 <- conv5_1_D
I0824 19:39:39.523191 43244 net.cpp:434] upsample4 <- pool4_mask
I0824 19:39:39.523198 43244 net.cpp:408] upsample4 -> pool4_D
I0824 19:39:39.523242 43244 net.cpp:150] Setting up upsample4
I0824 19:39:39.523250 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.523253 43244 net.cpp:165] Memory required for data: 3282554880
I0824 19:39:39.523257 43244 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 19:39:39.523272 43244 net.cpp:100] Creating Layer conv4_3_D
I0824 19:39:39.523277 43244 net.cpp:434] conv4_3_D <- pool4_D
I0824 19:39:39.523284 43244 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 19:39:39.608006 43244 net.cpp:150] Setting up conv4_3_D
I0824 19:39:39.608026 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.608038 43244 net.cpp:165] Memory required for data: 3304673280
I0824 19:39:39.608047 43244 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 19:39:39.608057 43244 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 19:39:39.608067 43244 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 19:39:39.608075 43244 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 19:39:39.608368 43244 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 19:39:39.608377 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.608381 43244 net.cpp:165] Memory required for data: 3326791680
I0824 19:39:39.608391 43244 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 19:39:39.608402 43244 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 19:39:39.608407 43244 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 19:39:39.608412 43244 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 19:39:39.608475 43244 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 19:39:39.608650 43244 net.cpp:150] Setting up conv4_3_D_scale
I0824 19:39:39.608659 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.608664 43244 net.cpp:165] Memory required for data: 3348910080
I0824 19:39:39.608670 43244 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 19:39:39.608695 43244 net.cpp:100] Creating Layer relu4_3_D
I0824 19:39:39.608700 43244 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 19:39:39.608708 43244 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 19:39:39.608934 43244 net.cpp:150] Setting up relu4_3_D
I0824 19:39:39.608944 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.608949 43244 net.cpp:165] Memory required for data: 3371028480
I0824 19:39:39.608953 43244 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 19:39:39.608965 43244 net.cpp:100] Creating Layer conv4_2_D
I0824 19:39:39.608971 43244 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 19:39:39.608979 43244 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 19:39:39.693228 43244 net.cpp:150] Setting up conv4_2_D
I0824 19:39:39.693245 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.693249 43244 net.cpp:165] Memory required for data: 3393146880
I0824 19:39:39.693258 43244 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 19:39:39.693276 43244 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 19:39:39.693282 43244 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 19:39:39.693289 43244 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 19:39:39.693609 43244 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 19:39:39.693621 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.693624 43244 net.cpp:165] Memory required for data: 3415265280
I0824 19:39:39.693634 43244 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 19:39:39.693640 43244 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 19:39:39.693645 43244 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 19:39:39.693652 43244 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 19:39:39.693711 43244 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 19:39:39.693884 43244 net.cpp:150] Setting up conv4_2_D_scale
I0824 19:39:39.693893 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.693897 43244 net.cpp:165] Memory required for data: 3437383680
I0824 19:39:39.693904 43244 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 19:39:39.693913 43244 net.cpp:100] Creating Layer relu4_2_D
I0824 19:39:39.693918 43244 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 19:39:39.693923 43244 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 19:39:39.694151 43244 net.cpp:150] Setting up relu4_2_D
I0824 19:39:39.694164 43244 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 19:39:39.694169 43244 net.cpp:165] Memory required for data: 3459502080
I0824 19:39:39.694172 43244 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 19:39:39.694185 43244 net.cpp:100] Creating Layer conv4_1_D
I0824 19:39:39.694190 43244 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 19:39:39.694197 43244 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 19:39:39.738435 43244 net.cpp:150] Setting up conv4_1_D
I0824 19:39:39.738453 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:39.738469 43244 net.cpp:165] Memory required for data: 3470561280
I0824 19:39:39.738478 43244 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 19:39:39.738489 43244 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 19:39:39.738498 43244 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 19:39:39.738507 43244 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 19:39:39.738803 43244 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 19:39:39.738812 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:39.738816 43244 net.cpp:165] Memory required for data: 3481620480
I0824 19:39:39.738883 43244 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 19:39:39.738893 43244 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 19:39:39.738898 43244 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 19:39:39.738904 43244 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 19:39:39.738968 43244 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 19:39:39.739143 43244 net.cpp:150] Setting up conv4_1_D_scale
I0824 19:39:39.739152 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:39.739172 43244 net.cpp:165] Memory required for data: 3492679680
I0824 19:39:39.739181 43244 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 19:39:39.739188 43244 net.cpp:100] Creating Layer relu4_1_D
I0824 19:39:39.739193 43244 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 19:39:39.739198 43244 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 19:39:39.739433 43244 net.cpp:150] Setting up relu4_1_D
I0824 19:39:39.739445 43244 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 19:39:39.739450 43244 net.cpp:165] Memory required for data: 3503738880
I0824 19:39:39.739454 43244 layer_factory.hpp:77] Creating layer upsample3
I0824 19:39:39.739461 43244 net.cpp:100] Creating Layer upsample3
I0824 19:39:39.739467 43244 net.cpp:434] upsample3 <- conv4_1_D
I0824 19:39:39.739472 43244 net.cpp:434] upsample3 <- pool3_mask
I0824 19:39:39.739485 43244 net.cpp:408] upsample3 -> pool3_D
I0824 19:39:39.739495 43244 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 19:39:39.739533 43244 net.cpp:150] Setting up upsample3
I0824 19:39:39.739542 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:39.739544 43244 net.cpp:165] Memory required for data: 3547975680
I0824 19:39:39.739547 43244 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 19:39:39.739564 43244 net.cpp:100] Creating Layer conv3_3_D
I0824 19:39:39.739569 43244 net.cpp:434] conv3_3_D <- pool3_D
I0824 19:39:39.739576 43244 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 19:39:39.763443 43244 net.cpp:150] Setting up conv3_3_D
I0824 19:39:39.763463 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:39.763478 43244 net.cpp:165] Memory required for data: 3592212480
I0824 19:39:39.763486 43244 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 19:39:39.763499 43244 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 19:39:39.763505 43244 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 19:39:39.763514 43244 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 19:39:39.763831 43244 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 19:39:39.763841 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:39.763845 43244 net.cpp:165] Memory required for data: 3636449280
I0824 19:39:39.763854 43244 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 19:39:39.763867 43244 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 19:39:39.763872 43244 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 19:39:39.763878 43244 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 19:39:39.763939 43244 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 19:39:39.764137 43244 net.cpp:150] Setting up conv3_3_D_scale
I0824 19:39:39.764147 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:39.764150 43244 net.cpp:165] Memory required for data: 3680686080
I0824 19:39:39.764156 43244 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 19:39:39.764164 43244 net.cpp:100] Creating Layer relu3_3_D
I0824 19:39:39.764169 43244 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 19:39:39.764174 43244 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 19:39:39.765347 43244 net.cpp:150] Setting up relu3_3_D
I0824 19:39:39.765362 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:39.765385 43244 net.cpp:165] Memory required for data: 3724922880
I0824 19:39:39.765391 43244 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 19:39:39.765406 43244 net.cpp:100] Creating Layer conv3_2_D
I0824 19:39:39.765413 43244 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 19:39:39.765421 43244 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 19:39:39.788362 43244 net.cpp:150] Setting up conv3_2_D
I0824 19:39:39.788380 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:39.788393 43244 net.cpp:165] Memory required for data: 3769159680
I0824 19:39:39.788401 43244 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 19:39:39.788409 43244 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 19:39:39.788416 43244 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 19:39:39.788440 43244 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 19:39:39.788755 43244 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 19:39:39.788765 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:39.788769 43244 net.cpp:165] Memory required for data: 3813396480
I0824 19:39:39.788777 43244 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 19:39:39.788785 43244 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 19:39:39.788791 43244 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 19:39:39.788796 43244 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 19:39:39.788854 43244 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 19:39:39.789049 43244 net.cpp:150] Setting up conv3_2_D_scale
I0824 19:39:39.789058 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:39.789062 43244 net.cpp:165] Memory required for data: 3857633280
I0824 19:39:39.789070 43244 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 19:39:39.789077 43244 net.cpp:100] Creating Layer relu3_2_D
I0824 19:39:39.789083 43244 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 19:39:39.789089 43244 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 19:39:39.790289 43244 net.cpp:150] Setting up relu3_2_D
I0824 19:39:39.790307 43244 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 19:39:39.790311 43244 net.cpp:165] Memory required for data: 3901870080
I0824 19:39:39.790316 43244 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 19:39:39.790329 43244 net.cpp:100] Creating Layer conv3_1_D
I0824 19:39:39.790334 43244 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 19:39:39.790343 43244 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 19:39:39.804347 43244 net.cpp:150] Setting up conv3_1_D
I0824 19:39:39.804365 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:39.804399 43244 net.cpp:165] Memory required for data: 3923988480
I0824 19:39:39.804409 43244 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 19:39:39.804424 43244 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 19:39:39.804430 43244 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 19:39:39.804436 43244 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 19:39:39.804760 43244 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 19:39:39.804770 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:39.804774 43244 net.cpp:165] Memory required for data: 3946106880
I0824 19:39:39.804782 43244 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 19:39:39.804793 43244 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 19:39:39.804798 43244 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 19:39:39.804805 43244 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 19:39:39.804863 43244 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 19:39:39.806466 43244 net.cpp:150] Setting up conv3_1_D_scale
I0824 19:39:39.806483 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:39.806488 43244 net.cpp:165] Memory required for data: 3968225280
I0824 19:39:39.806496 43244 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 19:39:39.806506 43244 net.cpp:100] Creating Layer relu3_1_D
I0824 19:39:39.806512 43244 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 19:39:39.806517 43244 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 19:39:39.806767 43244 net.cpp:150] Setting up relu3_1_D
I0824 19:39:39.806778 43244 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 19:39:39.806783 43244 net.cpp:165] Memory required for data: 3990343680
I0824 19:39:39.806787 43244 layer_factory.hpp:77] Creating layer upsample2
I0824 19:39:39.806797 43244 net.cpp:100] Creating Layer upsample2
I0824 19:39:39.806802 43244 net.cpp:434] upsample2 <- conv3_1_D
I0824 19:39:39.806807 43244 net.cpp:434] upsample2 <- pool2_mask
I0824 19:39:39.806814 43244 net.cpp:408] upsample2 -> pool2_D
I0824 19:39:39.806823 43244 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 19:39:39.806866 43244 net.cpp:150] Setting up upsample2
I0824 19:39:39.806888 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:39.806892 43244 net.cpp:165] Memory required for data: 4078817280
I0824 19:39:39.806896 43244 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 19:39:39.806908 43244 net.cpp:100] Creating Layer conv2_2_D
I0824 19:39:39.806915 43244 net.cpp:434] conv2_2_D <- pool2_D
I0824 19:39:39.806923 43244 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 19:39:39.814891 43244 net.cpp:150] Setting up conv2_2_D
I0824 19:39:39.814909 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:39.814924 43244 net.cpp:165] Memory required for data: 4167290880
I0824 19:39:39.814932 43244 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 19:39:39.814942 43244 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 19:39:39.814949 43244 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 19:39:39.814954 43244 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 19:39:39.815304 43244 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 19:39:39.815313 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:39.815316 43244 net.cpp:165] Memory required for data: 4255764480
I0824 19:39:39.815325 43244 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 19:39:39.815340 43244 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 19:39:39.815346 43244 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 19:39:39.815351 43244 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 19:39:39.815412 43244 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 19:39:39.815682 43244 net.cpp:150] Setting up conv2_2_D_scale
I0824 19:39:39.815691 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:39.815696 43244 net.cpp:165] Memory required for data: 4344238080
I0824 19:39:39.815703 43244 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 19:39:39.815711 43244 net.cpp:100] Creating Layer relu2_2_D
I0824 19:39:39.815716 43244 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 19:39:39.815723 43244 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 19:39:39.815960 43244 net.cpp:150] Setting up relu2_2_D
I0824 19:39:39.815971 43244 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 19:39:39.815976 43244 net.cpp:165] Memory required for data: 4432711680
I0824 19:39:39.815980 43244 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 19:39:39.815994 43244 net.cpp:100] Creating Layer conv2_1_D
I0824 19:39:39.815999 43244 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 19:39:39.816006 43244 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 19:39:39.821547 43244 net.cpp:150] Setting up conv2_1_D
I0824 19:39:39.821565 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:39.821579 43244 net.cpp:165] Memory required for data: 4476948480
I0824 19:39:39.821588 43244 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 19:39:39.821597 43244 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 19:39:39.821604 43244 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 19:39:39.821611 43244 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 19:39:39.821979 43244 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 19:39:39.821988 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:39.821991 43244 net.cpp:165] Memory required for data: 4521185280
I0824 19:39:39.822000 43244 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 19:39:39.822010 43244 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 19:39:39.822016 43244 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 19:39:39.822022 43244 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 19:39:39.822083 43244 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 19:39:39.822365 43244 net.cpp:150] Setting up conv2_1_D_scale
I0824 19:39:39.822373 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:39.822377 43244 net.cpp:165] Memory required for data: 4565422080
I0824 19:39:39.822384 43244 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 19:39:39.822392 43244 net.cpp:100] Creating Layer relu2_1_D
I0824 19:39:39.822396 43244 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 19:39:39.822419 43244 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 19:39:39.822659 43244 net.cpp:150] Setting up relu2_1_D
I0824 19:39:39.822671 43244 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 19:39:39.822676 43244 net.cpp:165] Memory required for data: 4609658880
I0824 19:39:39.822679 43244 layer_factory.hpp:77] Creating layer upsample1
I0824 19:39:39.822688 43244 net.cpp:100] Creating Layer upsample1
I0824 19:39:39.822695 43244 net.cpp:434] upsample1 <- conv2_1_D
I0824 19:39:39.822700 43244 net.cpp:434] upsample1 <- pool1_mask
I0824 19:39:39.822706 43244 net.cpp:408] upsample1 -> pool1_D
I0824 19:39:39.822715 43244 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 19:39:39.822755 43244 net.cpp:150] Setting up upsample1
I0824 19:39:39.822763 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:39.822767 43244 net.cpp:165] Memory required for data: 4786606080
I0824 19:39:39.822770 43244 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 19:39:39.822782 43244 net.cpp:100] Creating Layer conv1_2_D
I0824 19:39:39.822788 43244 net.cpp:434] conv1_2_D <- pool1_D
I0824 19:39:39.822795 43244 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 19:39:39.827637 43244 net.cpp:150] Setting up conv1_2_D
I0824 19:39:39.827658 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:39.827672 43244 net.cpp:165] Memory required for data: 4963553280
I0824 19:39:39.827680 43244 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 19:39:39.827688 43244 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 19:39:39.827695 43244 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 19:39:39.827704 43244 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 19:39:39.828153 43244 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 19:39:39.828162 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:39.828166 43244 net.cpp:165] Memory required for data: 5140500480
I0824 19:39:39.828176 43244 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 19:39:39.828186 43244 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 19:39:39.828191 43244 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 19:39:39.828196 43244 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 19:39:39.828258 43244 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 19:39:39.830129 43244 net.cpp:150] Setting up conv1_2_D_scale
I0824 19:39:39.830147 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:39.830163 43244 net.cpp:165] Memory required for data: 5317447680
I0824 19:39:39.830170 43244 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 19:39:39.830183 43244 net.cpp:100] Creating Layer relu1_2_D
I0824 19:39:39.830188 43244 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 19:39:39.830193 43244 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 19:39:39.830443 43244 net.cpp:150] Setting up relu1_2_D
I0824 19:39:39.830454 43244 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 19:39:39.830459 43244 net.cpp:165] Memory required for data: 5494394880
I0824 19:39:39.830463 43244 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 19:39:39.830477 43244 net.cpp:100] Creating Layer conv1_1_1_D
I0824 19:39:39.830482 43244 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 19:39:39.830489 43244 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 19:39:39.832718 43244 net.cpp:150] Setting up conv1_1_1_D
I0824 19:39:39.832736 43244 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 19:39:39.832741 43244 net.cpp:165] Memory required for data: 5499924480
I0824 19:39:39.832748 43244 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 19:39:39.832759 43244 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 19:39:39.832764 43244 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 19:39:39.832772 43244 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 19:39:39.832780 43244 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 19:39:39.832861 43244 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 19:39:39.832870 43244 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 19:39:39.832875 43244 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 19:39:39.832880 43244 net.cpp:165] Memory required for data: 5510983680
I0824 19:39:39.832883 43244 layer_factory.hpp:77] Creating layer loss
I0824 19:39:39.832895 43244 net.cpp:100] Creating Layer loss
I0824 19:39:39.832901 43244 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 19:39:39.832906 43244 net.cpp:434] loss <- label_data_1_split_0
I0824 19:39:39.832912 43244 net.cpp:408] loss -> loss
I0824 19:39:39.832923 43244 layer_factory.hpp:77] Creating layer loss
I0824 19:39:39.837256 43244 net.cpp:150] Setting up loss
I0824 19:39:39.837275 43244 net.cpp:157] Top shape: (1)
I0824 19:39:39.837278 43244 net.cpp:160]     with loss weight 1
I0824 19:39:39.837292 43244 net.cpp:165] Memory required for data: 5510983684
I0824 19:39:39.837306 43244 layer_factory.hpp:77] Creating layer accuracy
I0824 19:39:39.837316 43244 net.cpp:100] Creating Layer accuracy
I0824 19:39:39.837321 43244 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 19:39:39.837327 43244 net.cpp:434] accuracy <- label_data_1_split_1
I0824 19:39:39.837333 43244 net.cpp:408] accuracy -> accuracy
I0824 19:39:39.837342 43244 net.cpp:408] accuracy -> per_class_accuracy
I0824 19:39:39.837421 43244 net.cpp:150] Setting up accuracy
I0824 19:39:39.837432 43244 net.cpp:157] Top shape: (1)
I0824 19:39:39.837437 43244 net.cpp:157] Top shape: 2 (2)
I0824 19:39:39.837440 43244 net.cpp:165] Memory required for data: 5510983696
I0824 19:39:39.837445 43244 net.cpp:228] accuracy does not need backward computation.
I0824 19:39:39.837450 43244 net.cpp:226] loss needs backward computation.
I0824 19:39:39.837457 43244 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 19:39:39.837460 43244 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 19:39:39.837465 43244 net.cpp:226] relu1_2_D needs backward computation.
I0824 19:39:39.837468 43244 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 19:39:39.837471 43244 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 19:39:39.837474 43244 net.cpp:226] conv1_2_D needs backward computation.
I0824 19:39:39.837477 43244 net.cpp:226] upsample1 needs backward computation.
I0824 19:39:39.837482 43244 net.cpp:226] relu2_1_D needs backward computation.
I0824 19:39:39.837486 43244 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 19:39:39.837491 43244 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 19:39:39.837494 43244 net.cpp:226] conv2_1_D needs backward computation.
I0824 19:39:39.837498 43244 net.cpp:226] relu2_2_D needs backward computation.
I0824 19:39:39.837502 43244 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 19:39:39.837504 43244 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 19:39:39.837507 43244 net.cpp:226] conv2_2_D needs backward computation.
I0824 19:39:39.837510 43244 net.cpp:226] upsample2 needs backward computation.
I0824 19:39:39.837514 43244 net.cpp:226] relu3_1_D needs backward computation.
I0824 19:39:39.837519 43244 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 19:39:39.837522 43244 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 19:39:39.837525 43244 net.cpp:226] conv3_1_D needs backward computation.
I0824 19:39:39.837529 43244 net.cpp:226] relu3_2_D needs backward computation.
I0824 19:39:39.837532 43244 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 19:39:39.837535 43244 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 19:39:39.837538 43244 net.cpp:226] conv3_2_D needs backward computation.
I0824 19:39:39.837543 43244 net.cpp:226] relu3_3_D needs backward computation.
I0824 19:39:39.837546 43244 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 19:39:39.837549 43244 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 19:39:39.837568 43244 net.cpp:226] conv3_3_D needs backward computation.
I0824 19:39:39.837571 43244 net.cpp:226] upsample3 needs backward computation.
I0824 19:39:39.837575 43244 net.cpp:226] relu4_1_D needs backward computation.
I0824 19:39:39.837579 43244 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 19:39:39.837582 43244 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 19:39:39.837585 43244 net.cpp:226] conv4_1_D needs backward computation.
I0824 19:39:39.837589 43244 net.cpp:226] relu4_2_D needs backward computation.
I0824 19:39:39.837594 43244 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 19:39:39.837599 43244 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 19:39:39.837601 43244 net.cpp:226] conv4_2_D needs backward computation.
I0824 19:39:39.837605 43244 net.cpp:226] relu4_3_D needs backward computation.
I0824 19:39:39.837608 43244 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 19:39:39.837611 43244 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 19:39:39.837615 43244 net.cpp:226] conv4_3_D needs backward computation.
I0824 19:39:39.837618 43244 net.cpp:226] upsample4 needs backward computation.
I0824 19:39:39.837622 43244 net.cpp:226] relu5_1_D needs backward computation.
I0824 19:39:39.837626 43244 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 19:39:39.837631 43244 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 19:39:39.837635 43244 net.cpp:226] conv5_1_D needs backward computation.
I0824 19:39:39.837637 43244 net.cpp:226] relu5_2_D needs backward computation.
I0824 19:39:39.837641 43244 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 19:39:39.837646 43244 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 19:39:39.837649 43244 net.cpp:226] conv5_2_D needs backward computation.
I0824 19:39:39.837653 43244 net.cpp:226] relu5_3_D needs backward computation.
I0824 19:39:39.837656 43244 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 19:39:39.837662 43244 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 19:39:39.837666 43244 net.cpp:226] conv5_3_D needs backward computation.
I0824 19:39:39.837669 43244 net.cpp:226] upsample5 needs backward computation.
I0824 19:39:39.837673 43244 net.cpp:226] pool5 needs backward computation.
I0824 19:39:39.837677 43244 net.cpp:226] relu5_3 needs backward computation.
I0824 19:39:39.837682 43244 net.cpp:226] conv5_3_scale needs backward computation.
I0824 19:39:39.837687 43244 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 19:39:39.837692 43244 net.cpp:226] conv5_3 needs backward computation.
I0824 19:39:39.837697 43244 net.cpp:226] relu5_2 needs backward computation.
I0824 19:39:39.837702 43244 net.cpp:226] conv5_2_scale needs backward computation.
I0824 19:39:39.837705 43244 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 19:39:39.837709 43244 net.cpp:226] conv5_2 needs backward computation.
I0824 19:39:39.837713 43244 net.cpp:226] relu5_1 needs backward computation.
I0824 19:39:39.837716 43244 net.cpp:226] conv5_1_scale needs backward computation.
I0824 19:39:39.837721 43244 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 19:39:39.837724 43244 net.cpp:226] conv5_1 needs backward computation.
I0824 19:39:39.837729 43244 net.cpp:226] pool4 needs backward computation.
I0824 19:39:39.837734 43244 net.cpp:226] relu4_3 needs backward computation.
I0824 19:39:39.837739 43244 net.cpp:226] conv4_3_scale needs backward computation.
I0824 19:39:39.837743 43244 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 19:39:39.837748 43244 net.cpp:226] conv4_3 needs backward computation.
I0824 19:39:39.837752 43244 net.cpp:226] relu4_2 needs backward computation.
I0824 19:39:39.837756 43244 net.cpp:226] conv4_2_scale needs backward computation.
I0824 19:39:39.837759 43244 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 19:39:39.837764 43244 net.cpp:226] conv4_2 needs backward computation.
I0824 19:39:39.837767 43244 net.cpp:226] relu4_1 needs backward computation.
I0824 19:39:39.837779 43244 net.cpp:226] conv4_1_scale needs backward computation.
I0824 19:39:39.837782 43244 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 19:39:39.837785 43244 net.cpp:226] conv4_1 needs backward computation.
I0824 19:39:39.837790 43244 net.cpp:226] pool3 needs backward computation.
I0824 19:39:39.837795 43244 net.cpp:226] relu3_3 needs backward computation.
I0824 19:39:39.837800 43244 net.cpp:226] conv3_3_scale needs backward computation.
I0824 19:39:39.837803 43244 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 19:39:39.837807 43244 net.cpp:226] conv3_3 needs backward computation.
I0824 19:39:39.837810 43244 net.cpp:226] relu3_2 needs backward computation.
I0824 19:39:39.837815 43244 net.cpp:226] conv3_2_scale needs backward computation.
I0824 19:39:39.837817 43244 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 19:39:39.837823 43244 net.cpp:226] conv3_2 needs backward computation.
I0824 19:39:39.837827 43244 net.cpp:226] relu3_1 needs backward computation.
I0824 19:39:39.837831 43244 net.cpp:226] conv3_1_scale needs backward computation.
I0824 19:39:39.837834 43244 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 19:39:39.837839 43244 net.cpp:226] conv3_1 needs backward computation.
I0824 19:39:39.837842 43244 net.cpp:226] pool2 needs backward computation.
I0824 19:39:39.837846 43244 net.cpp:226] relu2_2 needs backward computation.
I0824 19:39:39.837851 43244 net.cpp:226] conv2_2_scale needs backward computation.
I0824 19:39:39.837853 43244 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 19:39:39.837857 43244 net.cpp:226] conv2_2 needs backward computation.
I0824 19:39:39.837862 43244 net.cpp:226] relu2_1 needs backward computation.
I0824 19:39:39.837865 43244 net.cpp:226] conv2_1_scale needs backward computation.
I0824 19:39:39.837869 43244 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 19:39:39.837872 43244 net.cpp:226] conv2_1 needs backward computation.
I0824 19:39:39.837877 43244 net.cpp:226] pool1 needs backward computation.
I0824 19:39:39.837880 43244 net.cpp:226] relu1_2 needs backward computation.
I0824 19:39:39.837885 43244 net.cpp:226] conv1_2_scale needs backward computation.
I0824 19:39:39.837889 43244 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 19:39:39.837893 43244 net.cpp:226] conv1_2 needs backward computation.
I0824 19:39:39.837898 43244 net.cpp:226] relu1_1 needs backward computation.
I0824 19:39:39.837903 43244 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 19:39:39.837908 43244 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 19:39:39.837910 43244 net.cpp:226] conv1_1_1 needs backward computation.
I0824 19:39:39.837915 43244 net.cpp:228] label_data_1_split does not need backward computation.
I0824 19:39:39.837920 43244 net.cpp:228] data does not need backward computation.
I0824 19:39:39.837924 43244 net.cpp:270] This network produces output accuracy
I0824 19:39:39.837929 43244 net.cpp:270] This network produces output loss
I0824 19:39:39.837932 43244 net.cpp:270] This network produces output per_class_accuracy
I0824 19:39:39.837997 43244 net.cpp:283] Network initialization done.
I0824 19:39:39.838371 43244 solver.cpp:60] Solver scaffolding done.
I0824 19:39:39.847862 43244 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0824 19:39:40.286195 43244 net.cpp:761] Ignoring source layer conv1_1
I0824 19:39:40.286223 43244 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 19:39:40.286278 43244 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 19:39:40.286285 43244 net.cpp:761] Ignoring source layer pool1_drop
I0824 19:39:40.286363 43244 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 19:39:40.286510 43244 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 19:39:40.286517 43244 net.cpp:761] Ignoring source layer pool2_drop
I0824 19:39:40.286815 43244 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 19:39:40.287413 43244 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 19:39:40.287984 43244 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 19:39:40.288017 43244 net.cpp:761] Ignoring source layer pool3_drop
I0824 19:39:40.289108 43244 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 19:39:40.291149 43244 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 19:39:40.293220 43244 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 19:39:40.293231 43244 net.cpp:761] Ignoring source layer pool4_drop
I0824 19:39:40.295284 43244 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 19:39:40.297323 43244 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 19:39:40.299427 43244 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 19:39:40.299437 43244 net.cpp:761] Ignoring source layer pool5_drop
I0824 19:39:40.299440 43244 net.cpp:761] Ignoring source layer upsample5_drop
I0824 19:39:40.301673 43244 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 19:39:40.303833 43244 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 19:39:40.305879 43244 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 19:39:40.305891 43244 net.cpp:761] Ignoring source layer upsample4_drop
I0824 19:39:40.307968 43244 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 19:39:40.310148 43244 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 19:39:40.311225 43244 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 19:39:40.311233 43244 net.cpp:761] Ignoring source layer upsample3_drop
I0824 19:39:40.311800 43244 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 19:39:40.312356 43244 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 19:39:40.312652 43244 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 19:39:40.312659 43244 net.cpp:761] Ignoring source layer upsample2_drop
I0824 19:39:40.312813 43244 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 19:39:40.312901 43244 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 19:39:40.312908 43244 net.cpp:761] Ignoring source layer upsample1_drop
I0824 19:39:40.312961 43244 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 19:39:40.312968 43244 net.cpp:761] Ignoring source layer conv1_1_D
I0824 19:39:40.312971 43244 net.cpp:761] Ignoring source layer prob
I0824 19:39:40.574961 43244 net.cpp:761] Ignoring source layer conv1_1
I0824 19:39:40.574988 43244 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 19:39:40.575037 43244 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 19:39:40.575042 43244 net.cpp:761] Ignoring source layer pool1_drop
I0824 19:39:40.575121 43244 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 19:39:40.575265 43244 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 19:39:40.575271 43244 net.cpp:761] Ignoring source layer pool2_drop
I0824 19:39:40.575570 43244 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 19:39:40.576149 43244 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 19:39:40.576720 43244 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 19:39:40.576726 43244 net.cpp:761] Ignoring source layer pool3_drop
I0824 19:39:40.577898 43244 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 19:39:40.579912 43244 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 19:39:40.581953 43244 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 19:39:40.581962 43244 net.cpp:761] Ignoring source layer pool4_drop
I0824 19:39:40.583984 43244 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 19:39:40.586019 43244 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 19:39:40.588040 43244 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 19:39:40.588048 43244 net.cpp:761] Ignoring source layer pool5_drop
I0824 19:39:40.588053 43244 net.cpp:761] Ignoring source layer upsample5_drop
I0824 19:39:40.590080 43244 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 19:39:40.592097 43244 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 19:39:40.594133 43244 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 19:39:40.594143 43244 net.cpp:761] Ignoring source layer upsample4_drop
I0824 19:39:40.596354 43244 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 19:39:40.598641 43244 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 19:39:40.599797 43244 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 19:39:40.599805 43244 net.cpp:761] Ignoring source layer upsample3_drop
I0824 19:39:40.600319 43244 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 19:39:40.600896 43244 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 19:39:40.601163 43244 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 19:39:40.601171 43244 net.cpp:761] Ignoring source layer upsample2_drop
I0824 19:39:40.601308 43244 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 19:39:40.601398 43244 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 19:39:40.601407 43244 net.cpp:761] Ignoring source layer upsample1_drop
I0824 19:39:40.601449 43244 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 19:39:40.601457 43244 net.cpp:761] Ignoring source layer conv1_1_D
I0824 19:39:40.601461 43244 net.cpp:761] Ignoring source layer prob
I0824 19:39:40.611022 43244 caffe.cpp:251] Starting Optimization
I0824 19:39:40.611048 43244 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0824 19:39:40.611053 43244 solver.cpp:280] Learning Rate Policy: step
I0824 19:39:41.713913 43244 solver.cpp:228] Iteration 0, loss = 0.947977
I0824 19:39:41.713958 43244 solver.cpp:244]     Train net output #0: accuracy = 0.458523
I0824 19:39:41.713980 43244 solver.cpp:244]     Train net output #1: loss = 0.947977 (* 1 = 0.947977 loss)
I0824 19:39:41.713987 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.557211
I0824 19:39:41.713992 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.167038
I0824 19:39:41.714027 43244 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0824 19:40:00.878579 43244 solver.cpp:228] Iteration 20, loss = 0.578926
I0824 19:40:00.878628 43244 solver.cpp:244]     Train net output #0: accuracy = 0.714813
I0824 19:40:00.878640 43244 solver.cpp:244]     Train net output #1: loss = 0.578926 (* 1 = 0.578926 loss)
I0824 19:40:00.878646 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.704746
I0824 19:40:00.878651 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.739496
I0824 19:40:00.878659 43244 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0824 19:40:17.633708 43244 solver.cpp:228] Iteration 40, loss = 0.470488
I0824 19:40:17.633853 43244 solver.cpp:244]     Train net output #0: accuracy = 0.786882
I0824 19:40:17.633869 43244 solver.cpp:244]     Train net output #1: loss = 0.470488 (* 1 = 0.470488 loss)
I0824 19:40:17.633877 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.79712
I0824 19:40:17.633882 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.763751
I0824 19:40:17.633891 43244 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0824 19:40:34.388845 43244 solver.cpp:228] Iteration 60, loss = 0.766463
I0824 19:40:34.388890 43244 solver.cpp:244]     Train net output #0: accuracy = 0.697047
I0824 19:40:34.388901 43244 solver.cpp:244]     Train net output #1: loss = 0.766463 (* 1 = 0.766463 loss)
I0824 19:40:34.388907 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.759153
I0824 19:40:34.388911 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.623025
I0824 19:40:34.388918 43244 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0824 19:40:51.160765 43244 solver.cpp:228] Iteration 80, loss = 0.293967
I0824 19:40:51.160900 43244 solver.cpp:244]     Train net output #0: accuracy = 0.829359
I0824 19:40:51.160915 43244 solver.cpp:244]     Train net output #1: loss = 0.293967 (* 1 = 0.293967 loss)
I0824 19:40:51.160928 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.795442
I0824 19:40:51.160939 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.945198
I0824 19:40:51.160948 43244 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0824 19:41:07.929631 43244 solver.cpp:228] Iteration 100, loss = 0.386949
I0824 19:41:07.929674 43244 solver.cpp:244]     Train net output #0: accuracy = 0.85401
I0824 19:41:07.929687 43244 solver.cpp:244]     Train net output #1: loss = 0.386949 (* 1 = 0.386949 loss)
I0824 19:41:07.929692 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.864326
I0824 19:41:07.929697 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.838094
I0824 19:41:07.929704 43244 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0824 19:41:24.704416 43244 solver.cpp:228] Iteration 120, loss = 0.424551
I0824 19:41:24.704602 43244 solver.cpp:244]     Train net output #0: accuracy = 0.857588
I0824 19:41:24.704619 43244 solver.cpp:244]     Train net output #1: loss = 0.424551 (* 1 = 0.424551 loss)
I0824 19:41:24.704630 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.926288
I0824 19:41:24.704635 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.776009
I0824 19:41:24.704643 43244 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0824 19:41:41.475543 43244 solver.cpp:228] Iteration 140, loss = 0.245017
I0824 19:41:41.475585 43244 solver.cpp:244]     Train net output #0: accuracy = 0.894012
I0824 19:41:41.475597 43244 solver.cpp:244]     Train net output #1: loss = 0.245017 (* 1 = 0.245017 loss)
I0824 19:41:41.475603 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.88741
I0824 19:41:41.475608 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.913797
I0824 19:41:41.475615 43244 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0824 19:41:58.308856 43244 solver.cpp:228] Iteration 160, loss = 0.329226
I0824 19:41:58.308996 43244 solver.cpp:244]     Train net output #0: accuracy = 0.836694
I0824 19:41:58.309015 43244 solver.cpp:244]     Train net output #1: loss = 0.329226 (* 1 = 0.329226 loss)
I0824 19:41:58.309021 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.831376
I0824 19:41:58.309026 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.8523
I0824 19:41:58.309034 43244 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0824 19:42:15.092887 43244 solver.cpp:228] Iteration 180, loss = 0.11566
I0824 19:42:15.092926 43244 solver.cpp:244]     Train net output #0: accuracy = 0.971602
I0824 19:42:15.092942 43244 solver.cpp:244]     Train net output #1: loss = 0.11566 (* 1 = 0.11566 loss)
I0824 19:42:15.092948 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973925
I0824 19:42:15.092953 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.966949
I0824 19:42:15.092959 43244 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0824 19:42:31.870334 43244 solver.cpp:228] Iteration 200, loss = 0.152673
I0824 19:42:31.870430 43244 solver.cpp:244]     Train net output #0: accuracy = 0.955719
I0824 19:42:31.870443 43244 solver.cpp:244]     Train net output #1: loss = 0.152673 (* 1 = 0.152673 loss)
I0824 19:42:31.870450 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.952299
I0824 19:42:31.870453 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.96078
I0824 19:42:31.870460 43244 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0824 19:42:48.662220 43244 solver.cpp:228] Iteration 220, loss = 0.234602
I0824 19:42:48.662261 43244 solver.cpp:244]     Train net output #0: accuracy = 0.903518
I0824 19:42:48.662273 43244 solver.cpp:244]     Train net output #1: loss = 0.234602 (* 1 = 0.234602 loss)
I0824 19:42:48.662278 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.888794
I0824 19:42:48.662295 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.930877
I0824 19:42:48.662302 43244 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0824 19:43:05.445358 43244 solver.cpp:228] Iteration 240, loss = 0.303804
I0824 19:43:05.445484 43244 solver.cpp:244]     Train net output #0: accuracy = 0.851684
I0824 19:43:05.445498 43244 solver.cpp:244]     Train net output #1: loss = 0.303804 (* 1 = 0.303804 loss)
I0824 19:43:05.445503 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.837521
I0824 19:43:05.445508 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992315
I0824 19:43:05.445515 43244 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0824 19:43:22.211884 43244 solver.cpp:228] Iteration 260, loss = 0.108116
I0824 19:43:22.211927 43244 solver.cpp:244]     Train net output #0: accuracy = 0.953832
I0824 19:43:22.211941 43244 solver.cpp:244]     Train net output #1: loss = 0.108116 (* 1 = 0.108116 loss)
I0824 19:43:22.211946 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.938803
I0824 19:43:22.211951 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995281
I0824 19:43:22.211958 43244 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0824 19:43:39.002022 43244 solver.cpp:228] Iteration 280, loss = 0.0880319
I0824 19:43:39.002180 43244 solver.cpp:244]     Train net output #0: accuracy = 0.95981
I0824 19:43:39.002197 43244 solver.cpp:244]     Train net output #1: loss = 0.0880319 (* 1 = 0.0880319 loss)
I0824 19:43:39.002203 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.949162
I0824 19:43:39.002207 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984879
I0824 19:43:39.002214 43244 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0824 19:43:55.798626 43244 solver.cpp:228] Iteration 300, loss = 0.109675
I0824 19:43:55.798665 43244 solver.cpp:244]     Train net output #0: accuracy = 0.957658
I0824 19:43:55.798678 43244 solver.cpp:244]     Train net output #1: loss = 0.109675 (* 1 = 0.109675 loss)
I0824 19:43:55.798684 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.954228
I0824 19:43:55.798689 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.966577
I0824 19:43:55.798696 43244 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0824 19:44:12.612608 43244 solver.cpp:228] Iteration 320, loss = 0.0923682
I0824 19:44:12.612738 43244 solver.cpp:244]     Train net output #0: accuracy = 0.966386
I0824 19:44:12.612756 43244 solver.cpp:244]     Train net output #1: loss = 0.0923682 (* 1 = 0.0923682 loss)
I0824 19:44:12.612769 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.962098
I0824 19:44:12.612774 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.97891
I0824 19:44:12.612783 43244 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0824 19:44:29.409056 43244 solver.cpp:228] Iteration 340, loss = 0.119361
I0824 19:44:29.409102 43244 solver.cpp:244]     Train net output #0: accuracy = 0.948724
I0824 19:44:29.409116 43244 solver.cpp:244]     Train net output #1: loss = 0.119361 (* 1 = 0.119361 loss)
I0824 19:44:29.409121 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.945307
I0824 19:44:29.409126 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.959763
I0824 19:44:29.409132 43244 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0824 19:44:46.207322 43244 solver.cpp:228] Iteration 360, loss = 0.132877
I0824 19:44:46.207443 43244 solver.cpp:244]     Train net output #0: accuracy = 0.952875
I0824 19:44:46.207459 43244 solver.cpp:244]     Train net output #1: loss = 0.132877 (* 1 = 0.132877 loss)
I0824 19:44:46.207465 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.950406
I0824 19:44:46.207471 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.966416
I0824 19:44:46.207479 43244 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0824 19:45:02.993415 43244 solver.cpp:228] Iteration 380, loss = 0.091929
I0824 19:45:02.993459 43244 solver.cpp:244]     Train net output #0: accuracy = 0.957245
I0824 19:45:02.993471 43244 solver.cpp:244]     Train net output #1: loss = 0.0919289 (* 1 = 0.0919289 loss)
I0824 19:45:02.993477 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.95087
I0824 19:45:02.993482 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976746
I0824 19:45:02.993489 43244 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0824 19:45:19.775033 43244 solver.cpp:228] Iteration 400, loss = 0.0681986
I0824 19:45:19.775142 43244 solver.cpp:244]     Train net output #0: accuracy = 0.978519
I0824 19:45:19.775156 43244 solver.cpp:244]     Train net output #1: loss = 0.0681986 (* 1 = 0.0681986 loss)
I0824 19:45:19.775163 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984078
I0824 19:45:19.775167 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.966046
I0824 19:45:19.775174 43244 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0824 19:45:36.560806 43244 solver.cpp:228] Iteration 420, loss = 0.077548
I0824 19:45:36.560843 43244 solver.cpp:244]     Train net output #0: accuracy = 0.974774
I0824 19:45:36.560856 43244 solver.cpp:244]     Train net output #1: loss = 0.077548 (* 1 = 0.077548 loss)
I0824 19:45:36.560871 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973955
I0824 19:45:36.560875 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976414
I0824 19:45:36.560883 43244 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0824 19:45:53.333408 43244 solver.cpp:228] Iteration 440, loss = 0.0663377
I0824 19:45:53.333593 43244 solver.cpp:244]     Train net output #0: accuracy = 0.977464
I0824 19:45:53.333611 43244 solver.cpp:244]     Train net output #1: loss = 0.0663377 (* 1 = 0.0663377 loss)
I0824 19:45:53.333622 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974655
I0824 19:45:53.333627 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983162
I0824 19:45:53.333634 43244 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0824 19:46:10.104169 43244 solver.cpp:228] Iteration 460, loss = 0.0864246
I0824 19:46:10.104212 43244 solver.cpp:244]     Train net output #0: accuracy = 0.977368
I0824 19:46:10.104224 43244 solver.cpp:244]     Train net output #1: loss = 0.0864246 (* 1 = 0.0864246 loss)
I0824 19:46:10.104230 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973854
I0824 19:46:10.104235 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980924
I0824 19:46:10.104243 43244 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0824 19:46:26.850188 43244 solver.cpp:228] Iteration 480, loss = 0.0486717
I0824 19:46:26.850363 43244 solver.cpp:244]     Train net output #0: accuracy = 0.985689
I0824 19:46:26.850401 43244 solver.cpp:244]     Train net output #1: loss = 0.0486717 (* 1 = 0.0486717 loss)
I0824 19:46:26.850410 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990912
I0824 19:46:26.850420 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.966108
I0824 19:46:26.850428 43244 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0824 19:46:43.676901 43244 solver.cpp:228] Iteration 500, loss = 0.0835734
I0824 19:46:43.676949 43244 solver.cpp:244]     Train net output #0: accuracy = 0.971681
I0824 19:46:43.676962 43244 solver.cpp:244]     Train net output #1: loss = 0.0835734 (* 1 = 0.0835734 loss)
I0824 19:46:43.676968 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977805
I0824 19:46:43.676973 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.957709
I0824 19:46:43.676980 43244 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0824 19:47:00.448344 43244 solver.cpp:228] Iteration 520, loss = 0.156926
I0824 19:47:00.448484 43244 solver.cpp:244]     Train net output #0: accuracy = 0.932543
I0824 19:47:00.448499 43244 solver.cpp:244]     Train net output #1: loss = 0.156926 (* 1 = 0.156926 loss)
I0824 19:47:00.448511 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.943378
I0824 19:47:00.448515 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.902223
I0824 19:47:00.448523 43244 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0824 19:47:17.225673 43244 solver.cpp:228] Iteration 540, loss = 0.0684215
I0824 19:47:17.225718 43244 solver.cpp:244]     Train net output #0: accuracy = 0.976557
I0824 19:47:17.225731 43244 solver.cpp:244]     Train net output #1: loss = 0.0684215 (* 1 = 0.0684215 loss)
I0824 19:47:17.225736 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980805
I0824 19:47:17.225741 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.968762
I0824 19:47:17.225749 43244 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0824 19:47:33.990238 43244 solver.cpp:228] Iteration 560, loss = 0.0664617
I0824 19:47:33.990406 43244 solver.cpp:244]     Train net output #0: accuracy = 0.970354
I0824 19:47:33.990422 43244 solver.cpp:244]     Train net output #1: loss = 0.0664617 (* 1 = 0.0664617 loss)
I0824 19:47:33.990428 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.959461
I0824 19:47:33.990439 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992137
I0824 19:47:33.990445 43244 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0824 19:47:50.778597 43244 solver.cpp:228] Iteration 580, loss = 0.106004
I0824 19:47:50.778646 43244 solver.cpp:244]     Train net output #0: accuracy = 0.961968
I0824 19:47:50.778661 43244 solver.cpp:244]     Train net output #1: loss = 0.106004 (* 1 = 0.106004 loss)
I0824 19:47:50.778668 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.967513
I0824 19:47:50.778673 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.934821
I0824 19:47:50.778682 43244 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0824 19:48:07.575707 43244 solver.cpp:228] Iteration 600, loss = 0.0569497
I0824 19:48:07.575821 43244 solver.cpp:244]     Train net output #0: accuracy = 0.983351
I0824 19:48:07.575835 43244 solver.cpp:244]     Train net output #1: loss = 0.0569497 (* 1 = 0.0569497 loss)
I0824 19:48:07.575840 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9913
I0824 19:48:07.575845 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.968255
I0824 19:48:07.575852 43244 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0824 19:48:24.349838 43244 solver.cpp:228] Iteration 620, loss = 0.0474969
I0824 19:48:24.349884 43244 solver.cpp:244]     Train net output #0: accuracy = 0.980985
I0824 19:48:24.349897 43244 solver.cpp:244]     Train net output #1: loss = 0.0474969 (* 1 = 0.0474969 loss)
I0824 19:48:24.349905 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974339
I0824 19:48:24.349910 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99079
I0824 19:48:24.349917 43244 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0824 19:48:41.129967 43244 solver.cpp:228] Iteration 640, loss = 0.0593598
I0824 19:48:41.130079 43244 solver.cpp:244]     Train net output #0: accuracy = 0.977636
I0824 19:48:41.130095 43244 solver.cpp:244]     Train net output #1: loss = 0.0593598 (* 1 = 0.0593598 loss)
I0824 19:48:41.130100 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972663
I0824 19:48:41.130105 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985047
I0824 19:48:41.130111 43244 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0824 19:48:57.923959 43244 solver.cpp:228] Iteration 660, loss = 0.0473246
I0824 19:48:57.924003 43244 solver.cpp:244]     Train net output #0: accuracy = 0.981496
I0824 19:48:57.924018 43244 solver.cpp:244]     Train net output #1: loss = 0.0473247 (* 1 = 0.0473247 loss)
I0824 19:48:57.924024 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98177
I0824 19:48:57.924029 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980566
I0824 19:48:57.924036 43244 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0824 19:49:14.736459 43244 solver.cpp:228] Iteration 680, loss = 0.0651928
I0824 19:49:14.736557 43244 solver.cpp:244]     Train net output #0: accuracy = 0.972739
I0824 19:49:14.736570 43244 solver.cpp:244]     Train net output #1: loss = 0.0651928 (* 1 = 0.0651928 loss)
I0824 19:49:14.736577 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.95833
I0824 19:49:14.736582 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99111
I0824 19:49:14.736588 43244 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0824 19:49:31.530973 43244 solver.cpp:228] Iteration 700, loss = 0.0584188
I0824 19:49:31.531018 43244 solver.cpp:244]     Train net output #0: accuracy = 0.977264
I0824 19:49:31.531033 43244 solver.cpp:244]     Train net output #1: loss = 0.0584189 (* 1 = 0.0584189 loss)
I0824 19:49:31.531039 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.963843
I0824 19:49:31.531044 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992754
I0824 19:49:31.531052 43244 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0824 19:49:48.316982 43244 solver.cpp:228] Iteration 720, loss = 0.0578134
I0824 19:49:48.317121 43244 solver.cpp:244]     Train net output #0: accuracy = 0.975017
I0824 19:49:48.317136 43244 solver.cpp:244]     Train net output #1: loss = 0.0578134 (* 1 = 0.0578134 loss)
I0824 19:49:48.317140 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.971418
I0824 19:49:48.317145 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985614
I0824 19:49:48.317152 43244 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0824 19:50:05.091547 43244 solver.cpp:228] Iteration 740, loss = 0.0391448
I0824 19:50:05.091590 43244 solver.cpp:244]     Train net output #0: accuracy = 0.983145
I0824 19:50:05.091601 43244 solver.cpp:244]     Train net output #1: loss = 0.0391449 (* 1 = 0.0391449 loss)
I0824 19:50:05.091608 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979685
I0824 19:50:05.091611 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993045
I0824 19:50:05.091619 43244 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0824 19:50:21.873939 43244 solver.cpp:228] Iteration 760, loss = 0.176243
I0824 19:50:21.874059 43244 solver.cpp:244]     Train net output #0: accuracy = 0.919757
I0824 19:50:21.874075 43244 solver.cpp:244]     Train net output #1: loss = 0.176243 (* 1 = 0.176243 loss)
I0824 19:50:21.874086 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.899009
I0824 19:50:21.874090 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995737
I0824 19:50:21.874099 43244 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0824 19:50:38.643573 43244 solver.cpp:228] Iteration 780, loss = 0.0897962
I0824 19:50:38.643611 43244 solver.cpp:244]     Train net output #0: accuracy = 0.961516
I0824 19:50:38.643622 43244 solver.cpp:244]     Train net output #1: loss = 0.0897962 (* 1 = 0.0897962 loss)
I0824 19:50:38.643642 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.956053
I0824 19:50:38.643652 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983142
I0824 19:50:38.643659 43244 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0824 19:50:55.416231 43244 solver.cpp:228] Iteration 800, loss = 0.0401694
I0824 19:50:55.416358 43244 solver.cpp:244]     Train net output #0: accuracy = 0.983801
I0824 19:50:55.416375 43244 solver.cpp:244]     Train net output #1: loss = 0.0401694 (* 1 = 0.0401694 loss)
I0824 19:50:55.416383 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982154
I0824 19:50:55.416386 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988754
I0824 19:50:55.416394 43244 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0824 19:51:12.181995 43244 solver.cpp:228] Iteration 820, loss = 0.0417308
I0824 19:51:12.182034 43244 solver.cpp:244]     Train net output #0: accuracy = 0.983941
I0824 19:51:12.182046 43244 solver.cpp:244]     Train net output #1: loss = 0.0417308 (* 1 = 0.0417308 loss)
I0824 19:51:12.182054 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97995
I0824 19:51:12.182059 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991287
I0824 19:51:12.182065 43244 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0824 19:51:28.961798 43244 solver.cpp:228] Iteration 840, loss = 0.0741169
I0824 19:51:28.961911 43244 solver.cpp:244]     Train net output #0: accuracy = 0.978443
I0824 19:51:28.961930 43244 solver.cpp:244]     Train net output #1: loss = 0.0741169 (* 1 = 0.0741169 loss)
I0824 19:51:28.961935 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987254
I0824 19:51:28.961941 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.967316
I0824 19:51:28.961947 43244 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0824 19:51:45.788718 43244 solver.cpp:228] Iteration 860, loss = 0.0478056
I0824 19:51:45.788763 43244 solver.cpp:244]     Train net output #0: accuracy = 0.986762
I0824 19:51:45.788776 43244 solver.cpp:244]     Train net output #1: loss = 0.0478056 (* 1 = 0.0478056 loss)
I0824 19:51:45.788782 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988584
I0824 19:51:45.788787 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984628
I0824 19:51:45.788794 43244 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0824 19:52:02.573070 43244 solver.cpp:228] Iteration 880, loss = 0.0396666
I0824 19:52:02.573232 43244 solver.cpp:244]     Train net output #0: accuracy = 0.984753
I0824 19:52:02.573248 43244 solver.cpp:244]     Train net output #1: loss = 0.0396666 (* 1 = 0.0396666 loss)
I0824 19:52:02.573254 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986144
I0824 19:52:02.573259 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981136
I0824 19:52:02.573266 43244 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0824 19:52:19.349644 43244 solver.cpp:228] Iteration 900, loss = 0.0376433
I0824 19:52:19.349684 43244 solver.cpp:244]     Train net output #0: accuracy = 0.984802
I0824 19:52:19.349699 43244 solver.cpp:244]     Train net output #1: loss = 0.0376433 (* 1 = 0.0376433 loss)
I0824 19:52:19.349704 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981988
I0824 19:52:19.349709 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99026
I0824 19:52:19.349716 43244 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0824 19:52:36.140141 43244 solver.cpp:228] Iteration 920, loss = 0.0499546
I0824 19:52:36.140280 43244 solver.cpp:244]     Train net output #0: accuracy = 0.981317
I0824 19:52:36.140295 43244 solver.cpp:244]     Train net output #1: loss = 0.0499546 (* 1 = 0.0499546 loss)
I0824 19:52:36.140310 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975443
I0824 19:52:36.140314 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989267
I0824 19:52:36.140321 43244 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0824 19:52:52.932109 43244 solver.cpp:228] Iteration 940, loss = 0.0258792
I0824 19:52:52.932155 43244 solver.cpp:244]     Train net output #0: accuracy = 0.989327
I0824 19:52:52.932170 43244 solver.cpp:244]     Train net output #1: loss = 0.0258792 (* 1 = 0.0258792 loss)
I0824 19:52:52.932176 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987915
I0824 19:52:52.932181 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992528
I0824 19:52:52.932189 43244 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0824 19:53:09.716831 43244 solver.cpp:228] Iteration 960, loss = 0.0855239
I0824 19:53:09.716976 43244 solver.cpp:244]     Train net output #0: accuracy = 0.968668
I0824 19:53:09.716991 43244 solver.cpp:244]     Train net output #1: loss = 0.0855239 (* 1 = 0.0855239 loss)
I0824 19:53:09.716997 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974663
I0824 19:53:09.717002 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.952658
I0824 19:53:09.717010 43244 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0824 19:53:26.508460 43244 solver.cpp:228] Iteration 980, loss = 0.0450904
I0824 19:53:26.508500 43244 solver.cpp:244]     Train net output #0: accuracy = 0.985198
I0824 19:53:26.508512 43244 solver.cpp:244]     Train net output #1: loss = 0.0450904 (* 1 = 0.0450904 loss)
I0824 19:53:26.508519 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991057
I0824 19:53:26.508524 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.963212
I0824 19:53:26.508532 43244 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0824 19:53:43.289602 43244 solver.cpp:228] Iteration 1000, loss = 0.0346143
I0824 19:53:43.289750 43244 solver.cpp:244]     Train net output #0: accuracy = 0.988944
I0824 19:53:43.289798 43244 solver.cpp:244]     Train net output #1: loss = 0.0346143 (* 1 = 0.0346143 loss)
I0824 19:53:43.289806 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994094
I0824 19:53:43.289813 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.969463
I0824 19:53:43.289820 43244 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0824 19:54:00.114537 43244 solver.cpp:228] Iteration 1020, loss = 0.0423518
I0824 19:54:00.114583 43244 solver.cpp:244]     Train net output #0: accuracy = 0.985459
I0824 19:54:00.114598 43244 solver.cpp:244]     Train net output #1: loss = 0.0423518 (* 1 = 0.0423518 loss)
I0824 19:54:00.114604 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988394
I0824 19:54:00.114609 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.97963
I0824 19:54:00.114616 43244 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0824 19:54:16.946341 43244 solver.cpp:228] Iteration 1040, loss = 0.0445494
I0824 19:54:16.946568 43244 solver.cpp:244]     Train net output #0: accuracy = 0.978822
I0824 19:54:16.946588 43244 solver.cpp:244]     Train net output #1: loss = 0.0445494 (* 1 = 0.0445494 loss)
I0824 19:54:16.946594 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972479
I0824 19:54:16.946599 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99354
I0824 19:54:16.946607 43244 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0824 19:54:33.742107 43244 solver.cpp:228] Iteration 1060, loss = 0.0638805
I0824 19:54:33.742152 43244 solver.cpp:244]     Train net output #0: accuracy = 0.97842
I0824 19:54:33.742166 43244 solver.cpp:244]     Train net output #1: loss = 0.0638805 (* 1 = 0.0638805 loss)
I0824 19:54:33.742172 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977169
I0824 19:54:33.742177 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980184
I0824 19:54:33.742183 43244 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0824 19:54:50.547351 43244 solver.cpp:228] Iteration 1080, loss = 0.0366833
I0824 19:54:50.547504 43244 solver.cpp:244]     Train net output #0: accuracy = 0.987318
I0824 19:54:50.547520 43244 solver.cpp:244]     Train net output #1: loss = 0.0366833 (* 1 = 0.0366833 loss)
I0824 19:54:50.547526 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990439
I0824 19:54:50.547531 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.969871
I0824 19:54:50.547538 43244 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0824 19:55:07.338284 43244 solver.cpp:228] Iteration 1100, loss = 0.203983
I0824 19:55:07.338330 43244 solver.cpp:244]     Train net output #0: accuracy = 0.941874
I0824 19:55:07.338345 43244 solver.cpp:244]     Train net output #1: loss = 0.203983 (* 1 = 0.203983 loss)
I0824 19:55:07.338351 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.939127
I0824 19:55:07.338357 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991668
I0824 19:55:07.338364 43244 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0824 19:55:24.172705 43244 solver.cpp:228] Iteration 1120, loss = 0.0335517
I0824 19:55:24.172852 43244 solver.cpp:244]     Train net output #0: accuracy = 0.985812
I0824 19:55:24.172866 43244 solver.cpp:244]     Train net output #1: loss = 0.0335518 (* 1 = 0.0335518 loss)
I0824 19:55:24.172873 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982972
I0824 19:55:24.172876 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992303
I0824 19:55:24.172883 43244 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0824 19:55:40.979594 43244 solver.cpp:228] Iteration 1140, loss = 0.0445463
I0824 19:55:40.979636 43244 solver.cpp:244]     Train net output #0: accuracy = 0.987377
I0824 19:55:40.979650 43244 solver.cpp:244]     Train net output #1: loss = 0.0445463 (* 1 = 0.0445463 loss)
I0824 19:55:40.979655 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989967
I0824 19:55:40.979660 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984654
I0824 19:55:40.979667 43244 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0824 19:55:57.784317 43244 solver.cpp:228] Iteration 1160, loss = 0.123283
I0824 19:55:57.784500 43244 solver.cpp:244]     Train net output #0: accuracy = 0.965428
I0824 19:55:57.784518 43244 solver.cpp:244]     Train net output #1: loss = 0.123283 (* 1 = 0.123283 loss)
I0824 19:55:57.784523 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987365
I0824 19:55:57.784528 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.939898
I0824 19:55:57.784534 43244 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0824 19:56:14.618733 43244 solver.cpp:228] Iteration 1180, loss = 0.0505515
I0824 19:56:14.618775 43244 solver.cpp:244]     Train net output #0: accuracy = 0.982847
I0824 19:56:14.618788 43244 solver.cpp:244]     Train net output #1: loss = 0.0505515 (* 1 = 0.0505515 loss)
I0824 19:56:14.618794 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977385
I0824 19:56:14.618798 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991541
I0824 19:56:14.618805 43244 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0824 19:56:31.428006 43244 solver.cpp:228] Iteration 1200, loss = 0.0463596
I0824 19:56:31.428117 43244 solver.cpp:244]     Train net output #0: accuracy = 0.980313
I0824 19:56:31.428130 43244 solver.cpp:244]     Train net output #1: loss = 0.0463596 (* 1 = 0.0463596 loss)
I0824 19:56:31.428135 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977513
I0824 19:56:31.428140 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987368
I0824 19:56:31.428148 43244 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0824 19:56:48.355722 43244 solver.cpp:228] Iteration 1220, loss = 0.0380449
I0824 19:56:48.355758 43244 solver.cpp:244]     Train net output #0: accuracy = 0.985103
I0824 19:56:48.355772 43244 solver.cpp:244]     Train net output #1: loss = 0.0380449 (* 1 = 0.0380449 loss)
I0824 19:56:48.355779 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978432
I0824 19:56:48.355783 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993819
I0824 19:56:48.355790 43244 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0824 19:57:05.150725 43244 solver.cpp:228] Iteration 1240, loss = 0.0963199
I0824 19:57:05.150841 43244 solver.cpp:244]     Train net output #0: accuracy = 0.968125
I0824 19:57:05.150856 43244 solver.cpp:244]     Train net output #1: loss = 0.0963199 (* 1 = 0.0963199 loss)
I0824 19:57:05.150862 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975438
I0824 19:57:05.150866 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.940299
I0824 19:57:05.150873 43244 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0824 19:57:21.956795 43244 solver.cpp:228] Iteration 1260, loss = 0.0644459
I0824 19:57:21.956841 43244 solver.cpp:244]     Train net output #0: accuracy = 0.97626
I0824 19:57:21.956854 43244 solver.cpp:244]     Train net output #1: loss = 0.0644459 (* 1 = 0.0644459 loss)
I0824 19:57:21.956861 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969995
I0824 19:57:21.956866 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987687
I0824 19:57:21.956872 43244 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0824 19:57:38.744014 43244 solver.cpp:228] Iteration 1280, loss = 0.0403014
I0824 19:57:38.744119 43244 solver.cpp:244]     Train net output #0: accuracy = 0.984974
I0824 19:57:38.744133 43244 solver.cpp:244]     Train net output #1: loss = 0.0403014 (* 1 = 0.0403014 loss)
I0824 19:57:38.744140 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984017
I0824 19:57:38.744145 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989209
I0824 19:57:38.744153 43244 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0824 19:57:55.527979 43244 solver.cpp:228] Iteration 1300, loss = 0.0381259
I0824 19:57:55.528026 43244 solver.cpp:244]     Train net output #0: accuracy = 0.986463
I0824 19:57:55.528039 43244 solver.cpp:244]     Train net output #1: loss = 0.0381259 (* 1 = 0.0381259 loss)
I0824 19:57:55.528045 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989445
I0824 19:57:55.528050 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.973985
I0824 19:57:55.528057 43244 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0824 19:58:12.315320 43244 solver.cpp:228] Iteration 1320, loss = 0.0233282
I0824 19:58:12.315481 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991419
I0824 19:58:12.315500 43244 solver.cpp:244]     Train net output #1: loss = 0.0233282 (* 1 = 0.0233282 loss)
I0824 19:58:12.315512 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991382
I0824 19:58:12.315517 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991492
I0824 19:58:12.315523 43244 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0824 19:58:29.103435 43244 solver.cpp:228] Iteration 1340, loss = 0.0306902
I0824 19:58:29.103479 43244 solver.cpp:244]     Train net output #0: accuracy = 0.987351
I0824 19:58:29.103492 43244 solver.cpp:244]     Train net output #1: loss = 0.0306902 (* 1 = 0.0306902 loss)
I0824 19:58:29.103498 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985724
I0824 19:58:29.103503 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990768
I0824 19:58:29.103512 43244 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0824 19:58:45.958772 43244 solver.cpp:228] Iteration 1360, loss = 0.043378
I0824 19:58:45.958906 43244 solver.cpp:244]     Train net output #0: accuracy = 0.985153
I0824 19:58:45.958922 43244 solver.cpp:244]     Train net output #1: loss = 0.043378 (* 1 = 0.043378 loss)
I0824 19:58:45.958928 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984599
I0824 19:58:45.958933 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985824
I0824 19:58:45.958941 43244 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0824 19:59:02.723264 43244 solver.cpp:228] Iteration 1380, loss = 0.0636633
I0824 19:59:02.723305 43244 solver.cpp:244]     Train net output #0: accuracy = 0.972989
I0824 19:59:02.723318 43244 solver.cpp:244]     Train net output #1: loss = 0.0636633 (* 1 = 0.0636633 loss)
I0824 19:59:02.723323 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.957098
I0824 19:59:02.723328 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99204
I0824 19:59:02.723335 43244 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0824 19:59:19.494781 43244 solver.cpp:228] Iteration 1400, loss = 0.0315189
I0824 19:59:19.494874 43244 solver.cpp:244]     Train net output #0: accuracy = 0.988041
I0824 19:59:19.494889 43244 solver.cpp:244]     Train net output #1: loss = 0.0315189 (* 1 = 0.0315189 loss)
I0824 19:59:19.494894 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988811
I0824 19:59:19.494899 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985368
I0824 19:59:19.494906 43244 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0824 19:59:36.267720 43244 solver.cpp:228] Iteration 1420, loss = 0.0215971
I0824 19:59:36.267762 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992624
I0824 19:59:36.267774 43244 solver.cpp:244]     Train net output #1: loss = 0.0215971 (* 1 = 0.0215971 loss)
I0824 19:59:36.267781 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994928
I0824 19:59:36.267786 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983675
I0824 19:59:36.267792 43244 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0824 19:59:53.036067 43244 solver.cpp:228] Iteration 1440, loss = 0.0314645
I0824 19:59:53.036175 43244 solver.cpp:244]     Train net output #0: accuracy = 0.986037
I0824 19:59:53.036190 43244 solver.cpp:244]     Train net output #1: loss = 0.0314644 (* 1 = 0.0314644 loss)
I0824 19:59:53.036206 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984143
I0824 19:59:53.036211 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992612
I0824 19:59:53.036218 43244 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0824 20:00:09.793084 43244 solver.cpp:228] Iteration 1460, loss = 0.0541733
I0824 20:00:09.793123 43244 solver.cpp:244]     Train net output #0: accuracy = 0.979317
I0824 20:00:09.793136 43244 solver.cpp:244]     Train net output #1: loss = 0.0541733 (* 1 = 0.0541733 loss)
I0824 20:00:09.793143 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985015
I0824 20:00:09.793156 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.967538
I0824 20:00:09.793164 43244 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0824 20:00:26.565654 43244 solver.cpp:228] Iteration 1480, loss = 0.0322654
I0824 20:00:26.565821 43244 solver.cpp:244]     Train net output #0: accuracy = 0.984754
I0824 20:00:26.565837 43244 solver.cpp:244]     Train net output #1: loss = 0.0322654 (* 1 = 0.0322654 loss)
I0824 20:00:26.565850 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978016
I0824 20:00:26.565855 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99549
I0824 20:00:26.565861 43244 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0824 20:00:43.330560 43244 solver.cpp:228] Iteration 1500, loss = 0.0336202
I0824 20:00:43.330603 43244 solver.cpp:244]     Train net output #0: accuracy = 0.984374
I0824 20:00:43.330617 43244 solver.cpp:244]     Train net output #1: loss = 0.0336202 (* 1 = 0.0336202 loss)
I0824 20:00:43.330624 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981841
I0824 20:00:43.330631 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991184
I0824 20:00:43.330637 43244 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0824 20:01:00.090965 43244 solver.cpp:228] Iteration 1520, loss = 0.0326481
I0824 20:01:00.091073 43244 solver.cpp:244]     Train net output #0: accuracy = 0.988155
I0824 20:01:00.091089 43244 solver.cpp:244]     Train net output #1: loss = 0.032648 (* 1 = 0.032648 loss)
I0824 20:01:00.091101 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984274
I0824 20:01:00.091106 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994671
I0824 20:01:00.091114 43244 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0824 20:01:16.859356 43244 solver.cpp:228] Iteration 1540, loss = 0.0264195
I0824 20:01:16.859400 43244 solver.cpp:244]     Train net output #0: accuracy = 0.990016
I0824 20:01:16.859413 43244 solver.cpp:244]     Train net output #1: loss = 0.0264195 (* 1 = 0.0264195 loss)
I0824 20:01:16.859418 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990185
I0824 20:01:16.859423 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989677
I0824 20:01:16.859431 43244 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0824 20:01:33.635056 43244 solver.cpp:228] Iteration 1560, loss = 0.0205378
I0824 20:01:33.635159 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993459
I0824 20:01:33.635174 43244 solver.cpp:244]     Train net output #1: loss = 0.0205378 (* 1 = 0.0205378 loss)
I0824 20:01:33.635180 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996137
I0824 20:01:33.635185 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984882
I0824 20:01:33.635191 43244 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0824 20:01:50.401618 43244 solver.cpp:228] Iteration 1580, loss = 0.0307037
I0824 20:01:50.401659 43244 solver.cpp:244]     Train net output #0: accuracy = 0.989887
I0824 20:01:50.401674 43244 solver.cpp:244]     Train net output #1: loss = 0.0307037 (* 1 = 0.0307037 loss)
I0824 20:01:50.401688 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994667
I0824 20:01:50.401695 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.971461
I0824 20:01:50.401703 43244 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0824 20:02:07.151545 43244 solver.cpp:228] Iteration 1600, loss = 0.0248316
I0824 20:02:07.151646 43244 solver.cpp:244]     Train net output #0: accuracy = 0.990864
I0824 20:02:07.151660 43244 solver.cpp:244]     Train net output #1: loss = 0.0248316 (* 1 = 0.0248316 loss)
I0824 20:02:07.151671 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992351
I0824 20:02:07.151676 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984906
I0824 20:02:07.151684 43244 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0824 20:02:23.921217 43244 solver.cpp:228] Iteration 1620, loss = 0.021367
I0824 20:02:23.921260 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992872
I0824 20:02:23.921272 43244 solver.cpp:244]     Train net output #1: loss = 0.021367 (* 1 = 0.021367 loss)
I0824 20:02:23.921278 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993987
I0824 20:02:23.921283 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989461
I0824 20:02:23.921290 43244 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0824 20:02:40.685412 43244 solver.cpp:228] Iteration 1640, loss = 0.0296908
I0824 20:02:40.685585 43244 solver.cpp:244]     Train net output #0: accuracy = 0.987895
I0824 20:02:40.685603 43244 solver.cpp:244]     Train net output #1: loss = 0.0296908 (* 1 = 0.0296908 loss)
I0824 20:02:40.685616 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988791
I0824 20:02:40.685621 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982949
I0824 20:02:40.685627 43244 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0824 20:02:57.458694 43244 solver.cpp:228] Iteration 1660, loss = 0.0237343
I0824 20:02:57.458741 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991393
I0824 20:02:57.458755 43244 solver.cpp:244]     Train net output #1: loss = 0.0237343 (* 1 = 0.0237343 loss)
I0824 20:02:57.458762 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992923
I0824 20:02:57.458768 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987432
I0824 20:02:57.458776 43244 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0824 20:03:14.217909 43244 solver.cpp:228] Iteration 1680, loss = 0.0407892
I0824 20:03:14.218035 43244 solver.cpp:244]     Train net output #0: accuracy = 0.987224
I0824 20:03:14.218050 43244 solver.cpp:244]     Train net output #1: loss = 0.0407892 (* 1 = 0.0407892 loss)
I0824 20:03:14.218056 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99132
I0824 20:03:14.218061 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.96695
I0824 20:03:14.218068 43244 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0824 20:03:30.995669 43244 solver.cpp:228] Iteration 1700, loss = 0.0152048
I0824 20:03:30.995717 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994485
I0824 20:03:30.995729 43244 solver.cpp:244]     Train net output #1: loss = 0.0152048 (* 1 = 0.0152048 loss)
I0824 20:03:30.995735 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994919
I0824 20:03:30.995740 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991798
I0824 20:03:30.995748 43244 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0824 20:03:47.776932 43244 solver.cpp:228] Iteration 1720, loss = 0.0291123
I0824 20:03:47.777045 43244 solver.cpp:244]     Train net output #0: accuracy = 0.987034
I0824 20:03:47.777061 43244 solver.cpp:244]     Train net output #1: loss = 0.0291123 (* 1 = 0.0291123 loss)
I0824 20:03:47.777070 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982325
I0824 20:03:47.777076 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996289
I0824 20:03:47.777083 43244 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0824 20:04:04.536717 43244 solver.cpp:228] Iteration 1740, loss = 0.0263247
I0824 20:04:04.536762 43244 solver.cpp:244]     Train net output #0: accuracy = 0.98989
I0824 20:04:04.536777 43244 solver.cpp:244]     Train net output #1: loss = 0.0263247 (* 1 = 0.0263247 loss)
I0824 20:04:04.536782 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988668
I0824 20:04:04.536787 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991787
I0824 20:04:04.536793 43244 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0824 20:04:21.289189 43244 solver.cpp:228] Iteration 1760, loss = 0.0185554
I0824 20:04:21.289342 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992407
I0824 20:04:21.289371 43244 solver.cpp:244]     Train net output #1: loss = 0.0185554 (* 1 = 0.0185554 loss)
I0824 20:04:21.289379 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992113
I0824 20:04:21.289384 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993026
I0824 20:04:21.289391 43244 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0824 20:04:38.053042 43244 solver.cpp:228] Iteration 1780, loss = 0.02087
I0824 20:04:38.053088 43244 solver.cpp:244]     Train net output #0: accuracy = 0.9914
I0824 20:04:38.053102 43244 solver.cpp:244]     Train net output #1: loss = 0.02087 (* 1 = 0.02087 loss)
I0824 20:04:38.053108 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990591
I0824 20:04:38.053120 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99327
I0824 20:04:38.053128 43244 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0824 20:04:54.806216 43244 solver.cpp:228] Iteration 1800, loss = 0.0182412
I0824 20:04:54.806339 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994369
I0824 20:04:54.806354 43244 solver.cpp:244]     Train net output #1: loss = 0.0182412 (* 1 = 0.0182412 loss)
I0824 20:04:54.806365 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995305
I0824 20:04:54.806370 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987839
I0824 20:04:54.806377 43244 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0824 20:05:11.576333 43244 solver.cpp:228] Iteration 1820, loss = 0.0230517
I0824 20:05:11.576380 43244 solver.cpp:244]     Train net output #0: accuracy = 0.989725
I0824 20:05:11.576393 43244 solver.cpp:244]     Train net output #1: loss = 0.0230517 (* 1 = 0.0230517 loss)
I0824 20:05:11.576400 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986873
I0824 20:05:11.576406 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995225
I0824 20:05:11.576414 43244 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0824 20:05:28.353041 43244 solver.cpp:228] Iteration 1840, loss = 0.0226288
I0824 20:05:28.353142 43244 solver.cpp:244]     Train net output #0: accuracy = 0.990488
I0824 20:05:28.353157 43244 solver.cpp:244]     Train net output #1: loss = 0.0226288 (* 1 = 0.0226288 loss)
I0824 20:05:28.353163 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988825
I0824 20:05:28.353168 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994664
I0824 20:05:28.353175 43244 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0824 20:05:45.139546 43244 solver.cpp:228] Iteration 1860, loss = 0.0152583
I0824 20:05:45.139588 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994363
I0824 20:05:45.139601 43244 solver.cpp:244]     Train net output #1: loss = 0.0152582 (* 1 = 0.0152582 loss)
I0824 20:05:45.139608 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993818
I0824 20:05:45.139612 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995615
I0824 20:05:45.139619 43244 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0824 20:06:01.931259 43244 solver.cpp:228] Iteration 1880, loss = 0.0183427
I0824 20:06:01.931362 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99193
I0824 20:06:01.931376 43244 solver.cpp:244]     Train net output #1: loss = 0.0183427 (* 1 = 0.0183427 loss)
I0824 20:06:01.931382 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990009
I0824 20:06:01.931387 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995413
I0824 20:06:01.931396 43244 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0824 20:06:18.688000 43244 solver.cpp:228] Iteration 1900, loss = 0.0172204
I0824 20:06:18.688043 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992295
I0824 20:06:18.688056 43244 solver.cpp:244]     Train net output #1: loss = 0.0172204 (* 1 = 0.0172204 loss)
I0824 20:06:18.688062 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989693
I0824 20:06:18.688067 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997181
I0824 20:06:18.688074 43244 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0824 20:06:35.441732 43244 solver.cpp:228] Iteration 1920, loss = 0.0168836
I0824 20:06:35.441884 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993731
I0824 20:06:35.441900 43244 solver.cpp:244]     Train net output #1: loss = 0.0168836 (* 1 = 0.0168836 loss)
I0824 20:06:35.441910 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994154
I0824 20:06:35.441921 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992554
I0824 20:06:35.441929 43244 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0824 20:06:52.197098 43244 solver.cpp:228] Iteration 1940, loss = 0.0257941
I0824 20:06:52.197141 43244 solver.cpp:244]     Train net output #0: accuracy = 0.988479
I0824 20:06:52.197155 43244 solver.cpp:244]     Train net output #1: loss = 0.0257941 (* 1 = 0.0257941 loss)
I0824 20:06:52.197163 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986876
I0824 20:06:52.197170 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992602
I0824 20:06:52.197180 43244 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0824 20:07:08.961524 43244 solver.cpp:228] Iteration 1960, loss = 0.0223961
I0824 20:07:08.961623 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991457
I0824 20:07:08.961638 43244 solver.cpp:244]     Train net output #1: loss = 0.0223961 (* 1 = 0.0223961 loss)
I0824 20:07:08.961644 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991177
I0824 20:07:08.961649 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992021
I0824 20:07:08.961658 43244 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0824 20:07:25.727391 43244 solver.cpp:228] Iteration 1980, loss = 0.0204516
I0824 20:07:25.727432 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991853
I0824 20:07:25.727444 43244 solver.cpp:244]     Train net output #1: loss = 0.0204516 (* 1 = 0.0204516 loss)
I0824 20:07:25.727450 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99123
I0824 20:07:25.727455 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993092
I0824 20:07:25.727463 43244 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0824 20:07:42.519120 43244 solver.cpp:228] Iteration 2000, loss = 0.0214905
I0824 20:07:42.519248 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992753
I0824 20:07:42.519263 43244 solver.cpp:244]     Train net output #1: loss = 0.0214905 (* 1 = 0.0214905 loss)
I0824 20:07:42.519278 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994205
I0824 20:07:42.519284 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986535
I0824 20:07:42.519294 43244 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0824 20:07:59.294479 43244 solver.cpp:228] Iteration 2020, loss = 0.0215153
I0824 20:07:59.294528 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991013
I0824 20:07:59.294541 43244 solver.cpp:244]     Train net output #1: loss = 0.0215152 (* 1 = 0.0215152 loss)
I0824 20:07:59.294548 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98964
I0824 20:07:59.294562 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993828
I0824 20:07:59.294571 43244 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0824 20:08:16.051771 43244 solver.cpp:228] Iteration 2040, loss = 0.0159301
I0824 20:08:16.051897 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993251
I0824 20:08:16.051913 43244 solver.cpp:244]     Train net output #1: loss = 0.0159301 (* 1 = 0.0159301 loss)
I0824 20:08:16.051923 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9915
I0824 20:08:16.051928 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997072
I0824 20:08:16.051939 43244 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0824 20:08:32.800799 43244 solver.cpp:228] Iteration 2060, loss = 0.0179728
I0824 20:08:32.800844 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99413
I0824 20:08:32.800858 43244 solver.cpp:244]     Train net output #1: loss = 0.0179728 (* 1 = 0.0179728 loss)
I0824 20:08:32.800864 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992345
I0824 20:08:32.800876 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996334
I0824 20:08:32.800884 43244 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0824 20:08:49.560101 43244 solver.cpp:228] Iteration 2080, loss = 0.0167057
I0824 20:08:49.560255 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99365
I0824 20:08:49.560271 43244 solver.cpp:244]     Train net output #1: loss = 0.0167056 (* 1 = 0.0167056 loss)
I0824 20:08:49.560279 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994323
I0824 20:08:49.560284 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990954
I0824 20:08:49.560290 43244 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0824 20:09:06.325311 43244 solver.cpp:228] Iteration 2100, loss = 0.0241228
I0824 20:09:06.325356 43244 solver.cpp:244]     Train net output #0: accuracy = 0.98952
I0824 20:09:06.325376 43244 solver.cpp:244]     Train net output #1: loss = 0.0241227 (* 1 = 0.0241227 loss)
I0824 20:09:06.325384 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987087
I0824 20:09:06.325390 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994399
I0824 20:09:06.325398 43244 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0824 20:09:23.067440 43244 solver.cpp:228] Iteration 2120, loss = 0.0277999
I0824 20:09:23.067551 43244 solver.cpp:244]     Train net output #0: accuracy = 0.98799
I0824 20:09:23.067567 43244 solver.cpp:244]     Train net output #1: loss = 0.0277999 (* 1 = 0.0277999 loss)
I0824 20:09:23.067579 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984942
I0824 20:09:23.067584 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996538
I0824 20:09:23.067589 43244 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0824 20:09:39.810751 43244 solver.cpp:228] Iteration 2140, loss = 0.0404465
I0824 20:09:39.810796 43244 solver.cpp:244]     Train net output #0: accuracy = 0.984089
I0824 20:09:39.810809 43244 solver.cpp:244]     Train net output #1: loss = 0.0404465 (* 1 = 0.0404465 loss)
I0824 20:09:39.810816 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982516
I0824 20:09:39.810820 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988135
I0824 20:09:39.810827 43244 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0824 20:09:56.577450 43244 solver.cpp:228] Iteration 2160, loss = 0.0476067
I0824 20:09:56.577559 43244 solver.cpp:244]     Train net output #0: accuracy = 0.984867
I0824 20:09:56.577576 43244 solver.cpp:244]     Train net output #1: loss = 0.0476066 (* 1 = 0.0476066 loss)
I0824 20:09:56.577584 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994134
I0824 20:09:56.577590 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.961653
I0824 20:09:56.577597 43244 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0824 20:10:13.359140 43244 solver.cpp:228] Iteration 2180, loss = 0.0551876
I0824 20:10:13.359184 43244 solver.cpp:244]     Train net output #0: accuracy = 0.980177
I0824 20:10:13.359195 43244 solver.cpp:244]     Train net output #1: loss = 0.0551876 (* 1 = 0.0551876 loss)
I0824 20:10:13.359201 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984904
I0824 20:10:13.359206 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.96483
I0824 20:10:13.359213 43244 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0824 20:10:30.128327 43244 solver.cpp:228] Iteration 2200, loss = 0.0581484
I0824 20:10:30.128484 43244 solver.cpp:244]     Train net output #0: accuracy = 0.979463
I0824 20:10:30.128500 43244 solver.cpp:244]     Train net output #1: loss = 0.0581484 (* 1 = 0.0581484 loss)
I0824 20:10:30.128509 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980617
I0824 20:10:30.128515 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976659
I0824 20:10:30.128521 43244 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0824 20:10:46.918407 43244 solver.cpp:228] Iteration 2220, loss = 0.0246831
I0824 20:10:46.918449 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991016
I0824 20:10:46.918464 43244 solver.cpp:244]     Train net output #1: loss = 0.0246831 (* 1 = 0.0246831 loss)
I0824 20:10:46.918471 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98853
I0824 20:10:46.918476 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995002
I0824 20:10:46.918484 43244 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0824 20:11:03.682842 43244 solver.cpp:228] Iteration 2240, loss = 0.0369424
I0824 20:11:03.682963 43244 solver.cpp:244]     Train net output #0: accuracy = 0.982037
I0824 20:11:03.682977 43244 solver.cpp:244]     Train net output #1: loss = 0.0369424 (* 1 = 0.0369424 loss)
I0824 20:11:03.682983 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973352
I0824 20:11:03.682988 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995004
I0824 20:11:03.682996 43244 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0824 20:11:20.475891 43244 solver.cpp:228] Iteration 2260, loss = 0.031909
I0824 20:11:20.475934 43244 solver.cpp:244]     Train net output #0: accuracy = 0.986367
I0824 20:11:20.475949 43244 solver.cpp:244]     Train net output #1: loss = 0.031909 (* 1 = 0.031909 loss)
I0824 20:11:20.475955 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981881
I0824 20:11:20.475960 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994956
I0824 20:11:20.475968 43244 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0824 20:11:37.256747 43244 solver.cpp:228] Iteration 2280, loss = 0.0233177
I0824 20:11:37.256868 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99003
I0824 20:11:37.256883 43244 solver.cpp:244]     Train net output #1: loss = 0.0233177 (* 1 = 0.0233177 loss)
I0824 20:11:37.256891 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986543
I0824 20:11:37.256894 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996187
I0824 20:11:37.256902 43244 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0824 20:11:54.033779 43244 solver.cpp:228] Iteration 2300, loss = 0.0176667
I0824 20:11:54.033821 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992782
I0824 20:11:54.033834 43244 solver.cpp:244]     Train net output #1: loss = 0.0176667 (* 1 = 0.0176667 loss)
I0824 20:11:54.033840 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990316
I0824 20:11:54.033845 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997473
I0824 20:11:54.033852 43244 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0824 20:12:10.779332 43244 solver.cpp:228] Iteration 2320, loss = 0.0438517
I0824 20:12:10.779456 43244 solver.cpp:244]     Train net output #0: accuracy = 0.98952
I0824 20:12:10.779474 43244 solver.cpp:244]     Train net output #1: loss = 0.0438517 (* 1 = 0.0438517 loss)
I0824 20:12:10.779484 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992538
I0824 20:12:10.779489 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986889
I0824 20:12:10.779495 43244 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0824 20:12:27.538125 43244 solver.cpp:228] Iteration 2340, loss = 0.0353348
I0824 20:12:27.538166 43244 solver.cpp:244]     Train net output #0: accuracy = 0.985046
I0824 20:12:27.538179 43244 solver.cpp:244]     Train net output #1: loss = 0.0353348 (* 1 = 0.0353348 loss)
I0824 20:12:27.538185 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978169
I0824 20:12:27.538190 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994809
I0824 20:12:27.538197 43244 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0824 20:12:44.318727 43244 solver.cpp:228] Iteration 2360, loss = 0.038073
I0824 20:12:44.318898 43244 solver.cpp:244]     Train net output #0: accuracy = 0.987859
I0824 20:12:44.318922 43244 solver.cpp:244]     Train net output #1: loss = 0.038073 (* 1 = 0.038073 loss)
I0824 20:12:44.318930 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992421
I0824 20:12:44.318943 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.972716
I0824 20:12:44.318950 43244 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0824 20:13:01.093866 43244 solver.cpp:228] Iteration 2380, loss = 0.0356853
I0824 20:13:01.093914 43244 solver.cpp:244]     Train net output #0: accuracy = 0.988804
I0824 20:13:01.093928 43244 solver.cpp:244]     Train net output #1: loss = 0.0356853 (* 1 = 0.0356853 loss)
I0824 20:13:01.093935 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989376
I0824 20:13:01.093941 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987778
I0824 20:13:01.093948 43244 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0824 20:13:17.865272 43244 solver.cpp:228] Iteration 2400, loss = 0.0234272
I0824 20:13:17.865417 43244 solver.cpp:244]     Train net output #0: accuracy = 0.990415
I0824 20:13:17.865432 43244 solver.cpp:244]     Train net output #1: loss = 0.0234272 (* 1 = 0.0234272 loss)
I0824 20:13:17.865438 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987667
I0824 20:13:17.865444 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994651
I0824 20:13:17.865454 43244 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0824 20:13:34.618657 43244 solver.cpp:228] Iteration 2420, loss = 0.0196842
I0824 20:13:34.618703 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993464
I0824 20:13:34.618717 43244 solver.cpp:244]     Train net output #1: loss = 0.0196842 (* 1 = 0.0196842 loss)
I0824 20:13:34.618724 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993959
I0824 20:13:34.618731 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992253
I0824 20:13:34.618738 43244 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0824 20:13:51.377284 43244 solver.cpp:228] Iteration 2440, loss = 0.0318961
I0824 20:13:51.377413 43244 solver.cpp:244]     Train net output #0: accuracy = 0.9897
I0824 20:13:51.377429 43244 solver.cpp:244]     Train net output #1: loss = 0.0318961 (* 1 = 0.0318961 loss)
I0824 20:13:51.377434 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993224
I0824 20:13:51.377440 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978486
I0824 20:13:51.377447 43244 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0824 20:14:08.139904 43244 solver.cpp:228] Iteration 2460, loss = 0.0262772
I0824 20:14:08.139948 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992216
I0824 20:14:08.139962 43244 solver.cpp:244]     Train net output #1: loss = 0.0262772 (* 1 = 0.0262772 loss)
I0824 20:14:08.139969 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992655
I0824 20:14:08.139976 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989209
I0824 20:14:08.139983 43244 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0824 20:14:24.905691 43244 solver.cpp:228] Iteration 2480, loss = 0.0287736
I0824 20:14:24.905860 43244 solver.cpp:244]     Train net output #0: accuracy = 0.988957
I0824 20:14:24.905903 43244 solver.cpp:244]     Train net output #1: loss = 0.0287736 (* 1 = 0.0287736 loss)
I0824 20:14:24.905912 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988235
I0824 20:14:24.905920 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990247
I0824 20:14:24.905930 43244 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0824 20:14:41.775954 43244 solver.cpp:228] Iteration 2500, loss = 0.0188278
I0824 20:14:41.776006 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992446
I0824 20:14:41.776023 43244 solver.cpp:244]     Train net output #1: loss = 0.0188278 (* 1 = 0.0188278 loss)
I0824 20:14:41.776031 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990696
I0824 20:14:41.776037 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996177
I0824 20:14:41.776046 43244 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0824 20:14:58.602001 43244 solver.cpp:228] Iteration 2520, loss = 0.0217791
I0824 20:14:58.602161 43244 solver.cpp:244]     Train net output #0: accuracy = 0.990528
I0824 20:14:58.602182 43244 solver.cpp:244]     Train net output #1: loss = 0.0217791 (* 1 = 0.0217791 loss)
I0824 20:14:58.602192 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99028
I0824 20:14:58.602202 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991377
I0824 20:14:58.602218 43244 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0824 20:15:15.458729 43244 solver.cpp:228] Iteration 2540, loss = 0.0181296
I0824 20:15:15.458781 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992674
I0824 20:15:15.458796 43244 solver.cpp:244]     Train net output #1: loss = 0.0181296 (* 1 = 0.0181296 loss)
I0824 20:15:15.458802 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992311
I0824 20:15:15.458807 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993466
I0824 20:15:15.458815 43244 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0824 20:15:32.302726 43244 solver.cpp:228] Iteration 2560, loss = 0.0254294
I0824 20:15:32.302851 43244 solver.cpp:244]     Train net output #0: accuracy = 0.990301
I0824 20:15:32.302871 43244 solver.cpp:244]     Train net output #1: loss = 0.0254294 (* 1 = 0.0254294 loss)
I0824 20:15:32.302882 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989313
I0824 20:15:32.302887 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992722
I0824 20:15:32.302896 43244 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0824 20:15:49.153436 43244 solver.cpp:228] Iteration 2580, loss = 0.0201723
I0824 20:15:49.153483 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992548
I0824 20:15:49.153498 43244 solver.cpp:244]     Train net output #1: loss = 0.0201723 (* 1 = 0.0201723 loss)
I0824 20:15:49.153506 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993548
I0824 20:15:49.153511 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988103
I0824 20:15:49.153519 43244 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0824 20:16:05.920645 43244 solver.cpp:228] Iteration 2600, loss = 0.0201716
I0824 20:16:05.920755 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991473
I0824 20:16:05.920770 43244 solver.cpp:244]     Train net output #1: loss = 0.0201716 (* 1 = 0.0201716 loss)
I0824 20:16:05.920783 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988713
I0824 20:16:05.920789 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996113
I0824 20:16:05.920795 43244 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0824 20:16:22.682700 43244 solver.cpp:228] Iteration 2620, loss = 0.0246054
I0824 20:16:22.682744 43244 solver.cpp:244]     Train net output #0: accuracy = 0.989951
I0824 20:16:22.682757 43244 solver.cpp:244]     Train net output #1: loss = 0.0246054 (* 1 = 0.0246054 loss)
I0824 20:16:22.682763 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987697
I0824 20:16:22.682770 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993745
I0824 20:16:22.682776 43244 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0824 20:16:39.439456 43244 solver.cpp:228] Iteration 2640, loss = 0.0207859
I0824 20:16:39.439579 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991798
I0824 20:16:39.439594 43244 solver.cpp:244]     Train net output #1: loss = 0.0207859 (* 1 = 0.0207859 loss)
I0824 20:16:39.439610 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992794
I0824 20:16:39.439620 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989137
I0824 20:16:39.439628 43244 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0824 20:16:56.194546 43244 solver.cpp:228] Iteration 2660, loss = 0.0213327
I0824 20:16:56.194588 43244 solver.cpp:244]     Train net output #0: accuracy = 0.990749
I0824 20:16:56.194603 43244 solver.cpp:244]     Train net output #1: loss = 0.0213327 (* 1 = 0.0213327 loss)
I0824 20:16:56.194608 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989869
I0824 20:16:56.194613 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993655
I0824 20:16:56.194620 43244 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0824 20:17:12.976447 43244 solver.cpp:228] Iteration 2680, loss = 0.0193853
I0824 20:17:12.976650 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992242
I0824 20:17:12.976668 43244 solver.cpp:244]     Train net output #1: loss = 0.0193853 (* 1 = 0.0193853 loss)
I0824 20:17:12.976675 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992713
I0824 20:17:12.976680 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990484
I0824 20:17:12.976687 43244 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0824 20:17:29.747190 43244 solver.cpp:228] Iteration 2700, loss = 0.0201948
I0824 20:17:29.747239 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992541
I0824 20:17:29.747254 43244 solver.cpp:244]     Train net output #1: loss = 0.0201948 (* 1 = 0.0201948 loss)
I0824 20:17:29.747262 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993491
I0824 20:17:29.747267 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986073
I0824 20:17:29.747275 43244 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0824 20:17:46.528988 43244 solver.cpp:228] Iteration 2720, loss = 0.0152464
I0824 20:17:46.529125 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993426
I0824 20:17:46.529141 43244 solver.cpp:244]     Train net output #1: loss = 0.0152464 (* 1 = 0.0152464 loss)
I0824 20:17:46.529155 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991787
I0824 20:17:46.529161 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996636
I0824 20:17:46.529170 43244 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0824 20:18:03.289185 43244 solver.cpp:228] Iteration 2740, loss = 0.0151028
I0824 20:18:03.289230 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993793
I0824 20:18:03.289245 43244 solver.cpp:244]     Train net output #1: loss = 0.0151028 (* 1 = 0.0151028 loss)
I0824 20:18:03.289252 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992923
I0824 20:18:03.289258 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996675
I0824 20:18:03.289273 43244 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0824 20:18:20.051820 43244 solver.cpp:228] Iteration 2760, loss = 0.0121264
I0824 20:18:20.051950 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995394
I0824 20:18:20.051966 43244 solver.cpp:244]     Train net output #1: loss = 0.0121265 (* 1 = 0.0121265 loss)
I0824 20:18:20.051975 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995567
I0824 20:18:20.051980 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994942
I0824 20:18:20.051990 43244 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0824 20:18:36.821951 43244 solver.cpp:228] Iteration 2780, loss = 0.0161888
I0824 20:18:36.821997 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992788
I0824 20:18:36.822011 43244 solver.cpp:244]     Train net output #1: loss = 0.0161888 (* 1 = 0.0161888 loss)
I0824 20:18:36.822017 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990883
I0824 20:18:36.822023 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997212
I0824 20:18:36.822039 43244 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0824 20:18:53.596837 43244 solver.cpp:228] Iteration 2800, loss = 0.0357245
I0824 20:18:53.597066 43244 solver.cpp:244]     Train net output #0: accuracy = 0.987335
I0824 20:18:53.597110 43244 solver.cpp:244]     Train net output #1: loss = 0.0357245 (* 1 = 0.0357245 loss)
I0824 20:18:53.597117 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985748
I0824 20:18:53.597126 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989488
I0824 20:18:53.597136 43244 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0824 20:19:10.422909 43244 solver.cpp:228] Iteration 2820, loss = 0.0130811
I0824 20:19:10.422958 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994705
I0824 20:19:10.422973 43244 solver.cpp:244]     Train net output #1: loss = 0.0130811 (* 1 = 0.0130811 loss)
I0824 20:19:10.422981 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993996
I0824 20:19:10.422986 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99618
I0824 20:19:10.423002 43244 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0824 20:19:27.220839 43244 solver.cpp:228] Iteration 2840, loss = 0.0252898
I0824 20:19:27.220988 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991042
I0824 20:19:27.221004 43244 solver.cpp:244]     Train net output #1: loss = 0.0252898 (* 1 = 0.0252898 loss)
I0824 20:19:27.221011 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990905
I0824 20:19:27.221016 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991445
I0824 20:19:27.221024 43244 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0824 20:19:44.019716 43244 solver.cpp:228] Iteration 2860, loss = 0.0168406
I0824 20:19:44.019769 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99303
I0824 20:19:44.019785 43244 solver.cpp:244]     Train net output #1: loss = 0.0168406 (* 1 = 0.0168406 loss)
I0824 20:19:44.019793 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991007
I0824 20:19:44.019798 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996865
I0824 20:19:44.019811 43244 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0824 20:20:00.893282 43244 solver.cpp:228] Iteration 2880, loss = 0.0143302
I0824 20:20:00.893455 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994159
I0824 20:20:00.893477 43244 solver.cpp:244]     Train net output #1: loss = 0.0143302 (* 1 = 0.0143302 loss)
I0824 20:20:00.893487 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992745
I0824 20:20:00.893498 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996948
I0824 20:20:00.893509 43244 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0824 20:20:17.794818 43244 solver.cpp:228] Iteration 2900, loss = 0.0245009
I0824 20:20:17.794878 43244 solver.cpp:244]     Train net output #0: accuracy = 0.989387
I0824 20:20:17.794895 43244 solver.cpp:244]     Train net output #1: loss = 0.0245009 (* 1 = 0.0245009 loss)
I0824 20:20:17.794904 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984906
I0824 20:20:17.794911 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996938
I0824 20:20:17.794920 43244 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0824 20:20:34.700354 43244 solver.cpp:228] Iteration 2920, loss = 0.0152328
I0824 20:20:34.700498 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994162
I0824 20:20:34.700534 43244 solver.cpp:244]     Train net output #1: loss = 0.0152328 (* 1 = 0.0152328 loss)
I0824 20:20:34.700544 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993219
I0824 20:20:34.700556 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996302
I0824 20:20:34.700563 43244 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0824 20:20:51.539322 43244 solver.cpp:228] Iteration 2940, loss = 0.0279987
I0824 20:20:51.539383 43244 solver.cpp:244]     Train net output #0: accuracy = 0.990285
I0824 20:20:51.539399 43244 solver.cpp:244]     Train net output #1: loss = 0.0279987 (* 1 = 0.0279987 loss)
I0824 20:20:51.539407 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98955
I0824 20:20:51.539418 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991106
I0824 20:20:51.539428 43244 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0824 20:21:08.405567 43244 solver.cpp:228] Iteration 2960, loss = 0.0155306
I0824 20:21:08.405766 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993896
I0824 20:21:08.405804 43244 solver.cpp:244]     Train net output #1: loss = 0.0155306 (* 1 = 0.0155306 loss)
I0824 20:21:08.405813 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994599
I0824 20:21:08.405823 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9919
I0824 20:21:08.405830 43244 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0824 20:21:25.218173 43244 solver.cpp:228] Iteration 2980, loss = 0.0165588
I0824 20:21:25.218237 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993247
I0824 20:21:25.218255 43244 solver.cpp:244]     Train net output #1: loss = 0.0165589 (* 1 = 0.0165589 loss)
I0824 20:21:25.218268 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993551
I0824 20:21:25.218278 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992279
I0824 20:21:25.218288 43244 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0824 20:21:42.047150 43244 solver.cpp:228] Iteration 3000, loss = 0.0167698
I0824 20:21:42.047299 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993223
I0824 20:21:42.047319 43244 solver.cpp:244]     Train net output #1: loss = 0.0167698 (* 1 = 0.0167698 loss)
I0824 20:21:42.047328 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990628
I0824 20:21:42.047339 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997507
I0824 20:21:42.047348 43244 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0824 20:21:58.895732 43244 solver.cpp:228] Iteration 3020, loss = 0.0207572
I0824 20:21:58.895787 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99182
I0824 20:21:58.895804 43244 solver.cpp:244]     Train net output #1: loss = 0.0207572 (* 1 = 0.0207572 loss)
I0824 20:21:58.895812 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989531
I0824 20:21:58.895817 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99487
I0824 20:21:58.895824 43244 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0824 20:22:15.758497 43244 solver.cpp:228] Iteration 3040, loss = 0.0188087
I0824 20:22:15.758623 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99326
I0824 20:22:15.758644 43244 solver.cpp:244]     Train net output #1: loss = 0.0188087 (* 1 = 0.0188087 loss)
I0824 20:22:15.758653 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992849
I0824 20:22:15.758666 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994679
I0824 20:22:15.758680 43244 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0824 20:22:32.617338 43244 solver.cpp:228] Iteration 3060, loss = 0.0306008
I0824 20:22:32.617403 43244 solver.cpp:244]     Train net output #0: accuracy = 0.988947
I0824 20:22:32.617420 43244 solver.cpp:244]     Train net output #1: loss = 0.0306008 (* 1 = 0.0306008 loss)
I0824 20:22:32.617434 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983616
I0824 20:22:32.617446 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994943
I0824 20:22:32.617461 43244 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0824 20:22:49.470052 43244 solver.cpp:228] Iteration 3080, loss = 0.0204133
I0824 20:22:49.470180 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992374
I0824 20:22:49.470201 43244 solver.cpp:244]     Train net output #1: loss = 0.0204133 (* 1 = 0.0204133 loss)
I0824 20:22:49.470212 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992155
I0824 20:22:49.470217 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993099
I0824 20:22:49.470226 43244 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0824 20:23:06.313966 43244 solver.cpp:228] Iteration 3100, loss = 0.0128318
I0824 20:23:06.314025 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994174
I0824 20:23:06.314041 43244 solver.cpp:244]     Train net output #1: loss = 0.0128318 (* 1 = 0.0128318 loss)
I0824 20:23:06.314047 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993223
I0824 20:23:06.314052 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996732
I0824 20:23:06.314060 43244 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0824 20:23:23.139125 43244 solver.cpp:228] Iteration 3120, loss = 0.0128496
I0824 20:23:23.139308 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994978
I0824 20:23:23.139336 43244 solver.cpp:244]     Train net output #1: loss = 0.0128496 (* 1 = 0.0128496 loss)
I0824 20:23:23.139353 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995551
I0824 20:23:23.139365 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992677
I0824 20:23:23.139376 43244 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0824 20:23:39.974385 43244 solver.cpp:228] Iteration 3140, loss = 0.0129979
I0824 20:23:39.974452 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995584
I0824 20:23:39.974478 43244 solver.cpp:244]     Train net output #1: loss = 0.0129979 (* 1 = 0.0129979 loss)
I0824 20:23:39.974486 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995723
I0824 20:23:39.974491 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99491
I0824 20:23:39.974499 43244 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0824 20:23:56.803305 43244 solver.cpp:228] Iteration 3160, loss = 0.0190596
I0824 20:23:56.803421 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991852
I0824 20:23:56.803449 43244 solver.cpp:244]     Train net output #1: loss = 0.0190596 (* 1 = 0.0190596 loss)
I0824 20:23:56.803457 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988056
I0824 20:23:56.803462 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997295
I0824 20:23:56.803470 43244 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0824 20:24:13.642285 43244 solver.cpp:228] Iteration 3180, loss = 0.0122232
I0824 20:24:13.642335 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994411
I0824 20:24:13.642360 43244 solver.cpp:244]     Train net output #1: loss = 0.0122233 (* 1 = 0.0122233 loss)
I0824 20:24:13.642374 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992967
I0824 20:24:13.642379 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997292
I0824 20:24:13.642386 43244 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0824 20:24:30.474639 43244 solver.cpp:228] Iteration 3200, loss = 0.0150215
I0824 20:24:30.474771 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99478
I0824 20:24:30.474799 43244 solver.cpp:244]     Train net output #1: loss = 0.0150215 (* 1 = 0.0150215 loss)
I0824 20:24:30.474808 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995361
I0824 20:24:30.474813 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99266
I0824 20:24:30.474822 43244 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0824 20:24:47.292138 43244 solver.cpp:228] Iteration 3220, loss = 0.0204598
I0824 20:24:47.292197 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991521
I0824 20:24:47.292212 43244 solver.cpp:244]     Train net output #1: loss = 0.0204598 (* 1 = 0.0204598 loss)
I0824 20:24:47.292218 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990484
I0824 20:24:47.292223 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993129
I0824 20:24:47.292232 43244 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0824 20:25:04.109405 43244 solver.cpp:228] Iteration 3240, loss = 0.0153752
I0824 20:25:04.109549 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993725
I0824 20:25:04.109566 43244 solver.cpp:244]     Train net output #1: loss = 0.0153752 (* 1 = 0.0153752 loss)
I0824 20:25:04.109573 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992881
I0824 20:25:04.109578 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995148
I0824 20:25:04.109586 43244 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0824 20:25:20.931741 43244 solver.cpp:228] Iteration 3260, loss = 0.0138719
I0824 20:25:20.931794 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995383
I0824 20:25:20.931824 43244 solver.cpp:244]     Train net output #1: loss = 0.0138719 (* 1 = 0.0138719 loss)
I0824 20:25:20.931834 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995009
I0824 20:25:20.931846 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995849
I0824 20:25:20.931859 43244 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0824 20:25:37.794795 43244 solver.cpp:228] Iteration 3280, loss = 0.0174326
I0824 20:25:37.794972 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993362
I0824 20:25:37.795011 43244 solver.cpp:244]     Train net output #1: loss = 0.0174326 (* 1 = 0.0174326 loss)
I0824 20:25:37.795022 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990398
I0824 20:25:37.795033 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996939
I0824 20:25:37.795042 43244 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0824 20:25:54.606820 43244 solver.cpp:228] Iteration 3300, loss = 0.0119139
I0824 20:25:54.606871 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99557
I0824 20:25:54.606900 43244 solver.cpp:244]     Train net output #1: loss = 0.0119139 (* 1 = 0.0119139 loss)
I0824 20:25:54.606915 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995192
I0824 20:25:54.606923 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996267
I0824 20:25:54.606931 43244 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0824 20:26:11.422372 43244 solver.cpp:228] Iteration 3320, loss = 0.0116701
I0824 20:26:11.422498 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995404
I0824 20:26:11.422514 43244 solver.cpp:244]     Train net output #1: loss = 0.0116701 (* 1 = 0.0116701 loss)
I0824 20:26:11.422521 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994215
I0824 20:26:11.422534 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997501
I0824 20:26:11.422544 43244 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0824 20:26:28.230901 43244 solver.cpp:228] Iteration 3340, loss = 0.0205673
I0824 20:26:28.230953 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993439
I0824 20:26:28.230968 43244 solver.cpp:244]     Train net output #1: loss = 0.0205673 (* 1 = 0.0205673 loss)
I0824 20:26:28.230974 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993946
I0824 20:26:28.230980 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991874
I0824 20:26:28.230988 43244 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0824 20:26:45.052049 43244 solver.cpp:228] Iteration 3360, loss = 0.0129193
I0824 20:26:45.052194 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994456
I0824 20:26:45.052229 43244 solver.cpp:244]     Train net output #1: loss = 0.0129193 (* 1 = 0.0129193 loss)
I0824 20:26:45.052238 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993308
I0824 20:26:45.052249 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997081
I0824 20:26:45.052260 43244 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0824 20:27:01.810606 43244 solver.cpp:228] Iteration 3380, loss = 0.0123802
I0824 20:27:01.810648 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99515
I0824 20:27:01.810662 43244 solver.cpp:244]     Train net output #1: loss = 0.0123802 (* 1 = 0.0123802 loss)
I0824 20:27:01.810667 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994283
I0824 20:27:01.810673 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996829
I0824 20:27:01.810681 43244 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0824 20:27:18.582998 43244 solver.cpp:228] Iteration 3400, loss = 0.0105636
I0824 20:27:18.583184 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995885
I0824 20:27:18.583206 43244 solver.cpp:244]     Train net output #1: loss = 0.0105636 (* 1 = 0.0105636 loss)
I0824 20:27:18.583216 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994743
I0824 20:27:18.583221 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997812
I0824 20:27:18.583232 43244 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0824 20:27:35.342918 43244 solver.cpp:228] Iteration 3420, loss = 0.0149794
I0824 20:27:35.342979 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994465
I0824 20:27:35.342993 43244 solver.cpp:244]     Train net output #1: loss = 0.0149794 (* 1 = 0.0149794 loss)
I0824 20:27:35.342998 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994606
I0824 20:27:35.343003 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99414
I0824 20:27:35.343010 43244 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0824 20:27:52.136204 43244 solver.cpp:228] Iteration 3440, loss = 0.0101678
I0824 20:27:52.136327 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995245
I0824 20:27:52.136344 43244 solver.cpp:244]     Train net output #1: loss = 0.0101678 (* 1 = 0.0101678 loss)
I0824 20:27:52.136354 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994078
I0824 20:27:52.136365 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997846
I0824 20:27:52.136373 43244 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0824 20:28:08.899749 43244 solver.cpp:228] Iteration 3460, loss = 0.0156252
I0824 20:28:08.899796 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993822
I0824 20:28:08.899811 43244 solver.cpp:244]     Train net output #1: loss = 0.0156252 (* 1 = 0.0156252 loss)
I0824 20:28:08.899817 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994751
I0824 20:28:08.899823 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991344
I0824 20:28:08.899832 43244 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0824 20:28:25.659188 43244 solver.cpp:228] Iteration 3480, loss = 0.01259
I0824 20:28:25.659314 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994387
I0824 20:28:25.659330 43244 solver.cpp:244]     Train net output #1: loss = 0.01259 (* 1 = 0.01259 loss)
I0824 20:28:25.659343 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991977
I0824 20:28:25.659348 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998019
I0824 20:28:25.659355 43244 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0824 20:28:42.404048 43244 solver.cpp:228] Iteration 3500, loss = 0.00911861
I0824 20:28:42.404094 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996162
I0824 20:28:42.404109 43244 solver.cpp:244]     Train net output #1: loss = 0.00911862 (* 1 = 0.00911862 loss)
I0824 20:28:42.404115 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99571
I0824 20:28:42.404121 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9972
I0824 20:28:42.404129 43244 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0824 20:28:59.150766 43244 solver.cpp:228] Iteration 3520, loss = 0.0100349
I0824 20:28:59.150892 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996639
I0824 20:28:59.150916 43244 solver.cpp:244]     Train net output #1: loss = 0.0100349 (* 1 = 0.0100349 loss)
I0824 20:28:59.150925 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996869
I0824 20:28:59.150936 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995355
I0824 20:28:59.150944 43244 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0824 20:29:15.918463 43244 solver.cpp:228] Iteration 3540, loss = 0.0103474
I0824 20:29:15.918510 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995768
I0824 20:29:15.918524 43244 solver.cpp:244]     Train net output #1: loss = 0.0103474 (* 1 = 0.0103474 loss)
I0824 20:29:15.918530 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995884
I0824 20:29:15.918534 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995415
I0824 20:29:15.918541 43244 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0824 20:29:32.677618 43244 solver.cpp:228] Iteration 3560, loss = 0.0213598
I0824 20:29:32.677783 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992672
I0824 20:29:32.677800 43244 solver.cpp:244]     Train net output #1: loss = 0.0213598 (* 1 = 0.0213598 loss)
I0824 20:29:32.677809 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992102
I0824 20:29:32.677814 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993469
I0824 20:29:32.677825 43244 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0824 20:29:49.452194 43244 solver.cpp:228] Iteration 3580, loss = 0.0101044
I0824 20:29:49.452235 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995729
I0824 20:29:49.452257 43244 solver.cpp:244]     Train net output #1: loss = 0.0101044 (* 1 = 0.0101044 loss)
I0824 20:29:49.452267 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995491
I0824 20:29:49.452272 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996343
I0824 20:29:49.452280 43244 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0824 20:30:06.228790 43244 solver.cpp:228] Iteration 3600, loss = 0.0101467
I0824 20:30:06.228910 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996589
I0824 20:30:06.228926 43244 solver.cpp:244]     Train net output #1: loss = 0.0101467 (* 1 = 0.0101467 loss)
I0824 20:30:06.228935 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997608
I0824 20:30:06.228940 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989902
I0824 20:30:06.228955 43244 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0824 20:30:23.002065 43244 solver.cpp:228] Iteration 3620, loss = 0.00787126
I0824 20:30:23.002105 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996879
I0824 20:30:23.002118 43244 solver.cpp:244]     Train net output #1: loss = 0.00787127 (* 1 = 0.00787127 loss)
I0824 20:30:23.002125 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996943
I0824 20:30:23.002130 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996601
I0824 20:30:23.002136 43244 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0824 20:30:39.788769 43244 solver.cpp:228] Iteration 3640, loss = 0.0223963
I0824 20:30:39.788880 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992863
I0824 20:30:39.788897 43244 solver.cpp:244]     Train net output #1: loss = 0.0223963 (* 1 = 0.0223963 loss)
I0824 20:30:39.788908 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99162
I0824 20:30:39.788913 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994063
I0824 20:30:39.788919 43244 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0824 20:30:56.563334 43244 solver.cpp:228] Iteration 3660, loss = 0.0145543
I0824 20:30:56.563380 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993333
I0824 20:30:56.563392 43244 solver.cpp:244]     Train net output #1: loss = 0.0145543 (* 1 = 0.0145543 loss)
I0824 20:30:56.563400 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992423
I0824 20:30:56.563405 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995438
I0824 20:30:56.563416 43244 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0824 20:31:13.332926 43244 solver.cpp:228] Iteration 3680, loss = 0.00998277
I0824 20:31:13.333024 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99589
I0824 20:31:13.333039 43244 solver.cpp:244]     Train net output #1: loss = 0.00998278 (* 1 = 0.00998278 loss)
I0824 20:31:13.333045 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994804
I0824 20:31:13.333050 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997707
I0824 20:31:13.333058 43244 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0824 20:31:30.095414 43244 solver.cpp:228] Iteration 3700, loss = 0.0177377
I0824 20:31:30.095470 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992467
I0824 20:31:30.095490 43244 solver.cpp:244]     Train net output #1: loss = 0.0177378 (* 1 = 0.0177378 loss)
I0824 20:31:30.095497 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991394
I0824 20:31:30.095502 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994602
I0824 20:31:30.095516 43244 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0824 20:31:46.851996 43244 solver.cpp:228] Iteration 3720, loss = 0.0142423
I0824 20:31:46.852147 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995033
I0824 20:31:46.852174 43244 solver.cpp:244]     Train net output #1: loss = 0.0142423 (* 1 = 0.0142423 loss)
I0824 20:31:46.852181 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993666
I0824 20:31:46.852187 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996674
I0824 20:31:46.852193 43244 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0824 20:32:03.603900 43244 solver.cpp:228] Iteration 3740, loss = 0.00852228
I0824 20:32:03.603943 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996424
I0824 20:32:03.603956 43244 solver.cpp:244]     Train net output #1: loss = 0.00852228 (* 1 = 0.00852228 loss)
I0824 20:32:03.603962 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996621
I0824 20:32:03.603967 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995495
I0824 20:32:03.603976 43244 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0824 20:32:20.365424 43244 solver.cpp:228] Iteration 3760, loss = 0.00815435
I0824 20:32:20.365521 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99697
I0824 20:32:20.365535 43244 solver.cpp:244]     Train net output #1: loss = 0.00815436 (* 1 = 0.00815436 loss)
I0824 20:32:20.365545 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99724
I0824 20:32:20.365550 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996426
I0824 20:32:20.365556 43244 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0824 20:32:37.136227 43244 solver.cpp:228] Iteration 3780, loss = 0.0176324
I0824 20:32:37.136270 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993795
I0824 20:32:37.136283 43244 solver.cpp:244]     Train net output #1: loss = 0.0176324 (* 1 = 0.0176324 loss)
I0824 20:32:37.136289 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991807
I0824 20:32:37.136294 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996253
I0824 20:32:37.136301 43244 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0824 20:32:53.911067 43244 solver.cpp:228] Iteration 3800, loss = 0.00945029
I0824 20:32:53.911203 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995933
I0824 20:32:53.911237 43244 solver.cpp:244]     Train net output #1: loss = 0.00945029 (* 1 = 0.00945029 loss)
I0824 20:32:53.911247 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995179
I0824 20:32:53.911252 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997558
I0824 20:32:53.911259 43244 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0824 20:33:10.719704 43244 solver.cpp:228] Iteration 3820, loss = 0.010979
I0824 20:33:10.719759 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995282
I0824 20:33:10.719775 43244 solver.cpp:244]     Train net output #1: loss = 0.010979 (* 1 = 0.010979 loss)
I0824 20:33:10.719784 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994902
I0824 20:33:10.719808 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99616
I0824 20:33:10.719820 43244 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0824 20:33:27.532486 43244 solver.cpp:228] Iteration 3840, loss = 0.0109539
I0824 20:33:27.532636 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995586
I0824 20:33:27.532652 43244 solver.cpp:244]     Train net output #1: loss = 0.0109539 (* 1 = 0.0109539 loss)
I0824 20:33:27.532660 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995832
I0824 20:33:27.532665 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994297
I0824 20:33:27.532673 43244 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0824 20:33:44.298815 43244 solver.cpp:228] Iteration 3860, loss = 0.00984313
I0824 20:33:44.298861 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995914
I0824 20:33:44.298874 43244 solver.cpp:244]     Train net output #1: loss = 0.00984314 (* 1 = 0.00984314 loss)
I0824 20:33:44.298882 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995654
I0824 20:33:44.298887 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9965
I0824 20:33:44.298894 43244 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0824 20:34:01.076948 43244 solver.cpp:228] Iteration 3880, loss = 0.00852597
I0824 20:34:01.077147 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996351
I0824 20:34:01.077164 43244 solver.cpp:244]     Train net output #1: loss = 0.00852597 (* 1 = 0.00852597 loss)
I0824 20:34:01.077175 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996048
I0824 20:34:01.077181 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997118
I0824 20:34:01.077189 43244 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0824 20:34:17.858600 43244 solver.cpp:228] Iteration 3900, loss = 0.00786285
I0824 20:34:17.858646 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996707
I0824 20:34:17.858661 43244 solver.cpp:244]     Train net output #1: loss = 0.00786286 (* 1 = 0.00786286 loss)
I0824 20:34:17.858669 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996252
I0824 20:34:17.858680 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997749
I0824 20:34:17.858688 43244 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0824 20:34:34.636852 43244 solver.cpp:228] Iteration 3920, loss = 0.0107871
I0824 20:34:34.637009 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995663
I0824 20:34:34.637053 43244 solver.cpp:244]     Train net output #1: loss = 0.0107871 (* 1 = 0.0107871 loss)
I0824 20:34:34.637061 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996031
I0824 20:34:34.637073 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994217
I0824 20:34:34.637084 43244 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0824 20:34:51.414592 43244 solver.cpp:228] Iteration 3940, loss = 0.0107151
I0824 20:34:51.414640 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995651
I0824 20:34:51.414655 43244 solver.cpp:244]     Train net output #1: loss = 0.0107151 (* 1 = 0.0107151 loss)
I0824 20:34:51.414664 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995097
I0824 20:34:51.414669 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996701
I0824 20:34:51.414679 43244 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0824 20:35:08.172658 43244 solver.cpp:228] Iteration 3960, loss = 0.0125032
I0824 20:35:08.172842 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99526
I0824 20:35:08.172879 43244 solver.cpp:244]     Train net output #1: loss = 0.0125032 (* 1 = 0.0125032 loss)
I0824 20:35:08.172888 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996233
I0824 20:35:08.172899 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992318
I0824 20:35:08.172906 43244 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0824 20:35:24.992398 43244 solver.cpp:228] Iteration 3980, loss = 0.0109555
I0824 20:35:24.992445 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995472
I0824 20:35:24.992460 43244 solver.cpp:244]     Train net output #1: loss = 0.0109555 (* 1 = 0.0109555 loss)
I0824 20:35:24.992467 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994984
I0824 20:35:24.992472 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996778
I0824 20:35:24.992482 43244 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0824 20:35:41.766885 43244 solver.cpp:228] Iteration 4000, loss = 0.0146776
I0824 20:35:41.767099 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994242
I0824 20:35:41.767117 43244 solver.cpp:244]     Train net output #1: loss = 0.0146776 (* 1 = 0.0146776 loss)
I0824 20:35:41.767129 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994057
I0824 20:35:41.767140 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994814
I0824 20:35:41.767149 43244 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0824 20:35:58.543337 43244 solver.cpp:228] Iteration 4020, loss = 0.0094883
I0824 20:35:58.543382 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996104
I0824 20:35:58.543396 43244 solver.cpp:244]     Train net output #1: loss = 0.00948831 (* 1 = 0.00948831 loss)
I0824 20:35:58.543402 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995001
I0824 20:35:58.543408 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998081
I0824 20:35:58.543416 43244 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0824 20:36:15.311076 43244 solver.cpp:228] Iteration 4040, loss = 0.0177514
I0824 20:36:15.311223 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993384
I0824 20:36:15.311245 43244 solver.cpp:244]     Train net output #1: loss = 0.0177514 (* 1 = 0.0177514 loss)
I0824 20:36:15.311254 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993271
I0824 20:36:15.311265 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993589
I0824 20:36:15.311273 43244 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0824 20:36:32.237753 43244 solver.cpp:228] Iteration 4060, loss = 0.017871
I0824 20:36:32.237799 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99328
I0824 20:36:32.237813 43244 solver.cpp:244]     Train net output #1: loss = 0.017871 (* 1 = 0.017871 loss)
I0824 20:36:32.237820 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99181
I0824 20:36:32.237826 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996073
I0824 20:36:32.237834 43244 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0824 20:36:49.011585 43244 solver.cpp:228] Iteration 4080, loss = 0.0109504
I0824 20:36:49.011728 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995628
I0824 20:36:49.011751 43244 solver.cpp:244]     Train net output #1: loss = 0.0109504 (* 1 = 0.0109504 loss)
I0824 20:36:49.011759 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996142
I0824 20:36:49.011770 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994412
I0824 20:36:49.011780 43244 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0824 20:37:05.783660 43244 solver.cpp:228] Iteration 4100, loss = 0.0178354
I0824 20:37:05.783712 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994013
I0824 20:37:05.783727 43244 solver.cpp:244]     Train net output #1: loss = 0.0178354 (* 1 = 0.0178354 loss)
I0824 20:37:05.783733 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994347
I0824 20:37:05.783738 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993311
I0824 20:37:05.783747 43244 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0824 20:37:22.574756 43244 solver.cpp:228] Iteration 4120, loss = 0.0124067
I0824 20:37:22.574889 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996121
I0824 20:37:22.574915 43244 solver.cpp:244]     Train net output #1: loss = 0.0124067 (* 1 = 0.0124067 loss)
I0824 20:37:22.574923 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996383
I0824 20:37:22.574929 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993524
I0824 20:37:22.574937 43244 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0824 20:37:39.338874 43244 solver.cpp:228] Iteration 4140, loss = 0.0170334
I0824 20:37:39.338918 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993704
I0824 20:37:39.338932 43244 solver.cpp:244]     Train net output #1: loss = 0.0170334 (* 1 = 0.0170334 loss)
I0824 20:37:39.338938 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993069
I0824 20:37:39.338944 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995161
I0824 20:37:39.338950 43244 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0824 20:37:56.124171 43244 solver.cpp:228] Iteration 4160, loss = 0.0115437
I0824 20:37:56.124337 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995271
I0824 20:37:56.124354 43244 solver.cpp:244]     Train net output #1: loss = 0.0115437 (* 1 = 0.0115437 loss)
I0824 20:37:56.124363 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994389
I0824 20:37:56.124374 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997076
I0824 20:37:56.124382 43244 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0824 20:38:12.908938 43244 solver.cpp:228] Iteration 4180, loss = 0.0196012
I0824 20:38:12.908984 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994151
I0824 20:38:12.909000 43244 solver.cpp:244]     Train net output #1: loss = 0.0196012 (* 1 = 0.0196012 loss)
I0824 20:38:12.909011 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991505
I0824 20:38:12.909021 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996541
I0824 20:38:12.909029 43244 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0824 20:38:29.682020 43244 solver.cpp:228] Iteration 4200, loss = 0.0109221
I0824 20:38:29.682122 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995541
I0824 20:38:29.682138 43244 solver.cpp:244]     Train net output #1: loss = 0.0109221 (* 1 = 0.0109221 loss)
I0824 20:38:29.682145 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996225
I0824 20:38:29.682150 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992628
I0824 20:38:29.682157 43244 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0824 20:38:46.462139 43244 solver.cpp:228] Iteration 4220, loss = 0.00952039
I0824 20:38:46.462185 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996752
I0824 20:38:46.462198 43244 solver.cpp:244]     Train net output #1: loss = 0.00952039 (* 1 = 0.00952039 loss)
I0824 20:38:46.462205 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997329
I0824 20:38:46.462210 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993807
I0824 20:38:46.462218 43244 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0824 20:39:03.426080 43244 solver.cpp:228] Iteration 4240, loss = 0.0145552
I0824 20:39:03.426200 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993299
I0824 20:39:03.426218 43244 solver.cpp:244]     Train net output #1: loss = 0.0145552 (* 1 = 0.0145552 loss)
I0824 20:39:03.426231 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990699
I0824 20:39:03.426241 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997422
I0824 20:39:03.426249 43244 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0824 20:39:20.191838 43244 solver.cpp:228] Iteration 4260, loss = 0.00937671
I0824 20:39:20.191884 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996503
I0824 20:39:20.191896 43244 solver.cpp:244]     Train net output #1: loss = 0.00937671 (* 1 = 0.00937671 loss)
I0824 20:39:20.191902 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996445
I0824 20:39:20.191907 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996591
I0824 20:39:20.191915 43244 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0824 20:39:36.958991 43244 solver.cpp:228] Iteration 4280, loss = 0.0121905
I0824 20:39:36.959153 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995308
I0824 20:39:36.959193 43244 solver.cpp:244]     Train net output #1: loss = 0.0121905 (* 1 = 0.0121905 loss)
I0824 20:39:36.959203 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995196
I0824 20:39:36.959213 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995545
I0824 20:39:36.959221 43244 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0824 20:39:53.784327 43244 solver.cpp:228] Iteration 4300, loss = 0.0107896
I0824 20:39:53.784375 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996282
I0824 20:39:53.784407 43244 solver.cpp:244]     Train net output #1: loss = 0.0107896 (* 1 = 0.0107896 loss)
I0824 20:39:53.784417 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99765
I0824 20:39:53.784423 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987246
I0824 20:39:53.784431 43244 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0824 20:40:10.618592 43244 solver.cpp:228] Iteration 4320, loss = 0.0231617
I0824 20:40:10.618751 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992072
I0824 20:40:10.618782 43244 solver.cpp:244]     Train net output #1: loss = 0.0231617 (* 1 = 0.0231617 loss)
I0824 20:40:10.618789 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991389
I0824 20:40:10.618794 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993083
I0824 20:40:10.618801 43244 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0824 20:40:27.433997 43244 solver.cpp:228] Iteration 4340, loss = 0.014317
I0824 20:40:27.434042 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994343
I0824 20:40:27.434056 43244 solver.cpp:244]     Train net output #1: loss = 0.014317 (* 1 = 0.014317 loss)
I0824 20:40:27.434062 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994101
I0824 20:40:27.434067 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994998
I0824 20:40:27.434074 43244 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0824 20:40:44.210031 43244 solver.cpp:228] Iteration 4360, loss = 0.0105719
I0824 20:40:44.210167 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99546
I0824 20:40:44.210185 43244 solver.cpp:244]     Train net output #1: loss = 0.0105719 (* 1 = 0.0105719 loss)
I0824 20:40:44.210197 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99392
I0824 20:40:44.210202 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998081
I0824 20:40:44.210209 43244 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0824 20:41:01.004158 43244 solver.cpp:228] Iteration 4380, loss = 0.0177759
I0824 20:41:01.004225 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992481
I0824 20:41:01.004248 43244 solver.cpp:244]     Train net output #1: loss = 0.0177759 (* 1 = 0.0177759 loss)
I0824 20:41:01.004259 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991933
I0824 20:41:01.004266 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993852
I0824 20:41:01.004278 43244 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0824 20:41:17.793148 43244 solver.cpp:228] Iteration 4400, loss = 0.0122203
I0824 20:41:17.793306 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994795
I0824 20:41:17.793323 43244 solver.cpp:244]     Train net output #1: loss = 0.0122203 (* 1 = 0.0122203 loss)
I0824 20:41:17.793337 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994997
I0824 20:41:17.793349 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994396
I0824 20:41:17.793359 43244 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0824 20:41:34.579572 43244 solver.cpp:228] Iteration 4420, loss = 0.00871355
I0824 20:41:34.579619 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996531
I0824 20:41:34.579633 43244 solver.cpp:244]     Train net output #1: loss = 0.00871355 (* 1 = 0.00871355 loss)
I0824 20:41:34.579640 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996781
I0824 20:41:34.579645 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995267
I0824 20:41:34.579651 43244 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0824 20:41:51.343278 43244 solver.cpp:228] Iteration 4440, loss = 0.0113981
I0824 20:41:51.343410 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995373
I0824 20:41:51.343425 43244 solver.cpp:244]     Train net output #1: loss = 0.0113981 (* 1 = 0.0113981 loss)
I0824 20:41:51.343433 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995707
I0824 20:41:51.343438 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99291
I0824 20:41:51.343446 43244 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0824 20:42:08.111369 43244 solver.cpp:228] Iteration 4460, loss = 0.0107814
I0824 20:42:08.111416 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995246
I0824 20:42:08.111430 43244 solver.cpp:244]     Train net output #1: loss = 0.0107814 (* 1 = 0.0107814 loss)
I0824 20:42:08.111436 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995235
I0824 20:42:08.111443 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995298
I0824 20:42:08.111449 43244 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0824 20:42:24.895547 43244 solver.cpp:228] Iteration 4480, loss = 0.0303571
I0824 20:42:24.895766 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991413
I0824 20:42:24.895781 43244 solver.cpp:244]     Train net output #1: loss = 0.0303571 (* 1 = 0.0303571 loss)
I0824 20:42:24.895793 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990785
I0824 20:42:24.895798 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99194
I0824 20:42:24.895805 43244 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0824 20:42:41.672015 43244 solver.cpp:228] Iteration 4500, loss = 0.019124
I0824 20:42:41.672060 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992896
I0824 20:42:41.672072 43244 solver.cpp:244]     Train net output #1: loss = 0.019124 (* 1 = 0.019124 loss)
I0824 20:42:41.672078 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989367
I0824 20:42:41.672085 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997658
I0824 20:42:41.672091 43244 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0824 20:42:58.432370 43244 solver.cpp:228] Iteration 4520, loss = 0.016135
I0824 20:42:58.432499 43244 solver.cpp:244]     Train net output #0: accuracy = 0.992653
I0824 20:42:58.432515 43244 solver.cpp:244]     Train net output #1: loss = 0.016135 (* 1 = 0.016135 loss)
I0824 20:42:58.432521 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992284
I0824 20:42:58.432526 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993833
I0824 20:42:58.432533 43244 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0824 20:43:15.212330 43244 solver.cpp:228] Iteration 4540, loss = 0.00640267
I0824 20:43:15.212375 43244 solver.cpp:244]     Train net output #0: accuracy = 0.997483
I0824 20:43:15.212388 43244 solver.cpp:244]     Train net output #1: loss = 0.00640267 (* 1 = 0.00640267 loss)
I0824 20:43:15.212394 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99785
I0824 20:43:15.212400 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99633
I0824 20:43:15.212409 43244 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0824 20:43:32.099432 43244 solver.cpp:228] Iteration 4560, loss = 0.0169013
I0824 20:43:32.099547 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993601
I0824 20:43:32.099562 43244 solver.cpp:244]     Train net output #1: loss = 0.0169013 (* 1 = 0.0169013 loss)
I0824 20:43:32.099568 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991626
I0824 20:43:32.099573 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99763
I0824 20:43:32.099581 43244 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0824 20:43:48.863092 43244 solver.cpp:228] Iteration 4580, loss = 0.0140066
I0824 20:43:48.863135 43244 solver.cpp:244]     Train net output #0: accuracy = 0.993796
I0824 20:43:48.863149 43244 solver.cpp:244]     Train net output #1: loss = 0.0140066 (* 1 = 0.0140066 loss)
I0824 20:43:48.863155 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991469
I0824 20:43:48.863159 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997588
I0824 20:43:48.863167 43244 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0824 20:44:05.631528 43244 solver.cpp:228] Iteration 4600, loss = 0.00881424
I0824 20:44:05.631705 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996817
I0824 20:44:05.631721 43244 solver.cpp:244]     Train net output #1: loss = 0.00881424 (* 1 = 0.00881424 loss)
I0824 20:44:05.631727 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997425
I0824 20:44:05.631732 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99412
I0824 20:44:05.631739 43244 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0824 20:44:22.405392 43244 solver.cpp:228] Iteration 4620, loss = 0.0104692
I0824 20:44:22.405434 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995592
I0824 20:44:22.405448 43244 solver.cpp:244]     Train net output #1: loss = 0.0104692 (* 1 = 0.0104692 loss)
I0824 20:44:22.405454 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994288
I0824 20:44:22.405458 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997694
I0824 20:44:22.405465 43244 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0824 20:44:39.175194 43244 solver.cpp:228] Iteration 4640, loss = 0.00943838
I0824 20:44:39.175305 43244 solver.cpp:244]     Train net output #0: accuracy = 0.9965
I0824 20:44:39.175321 43244 solver.cpp:244]     Train net output #1: loss = 0.00943839 (* 1 = 0.00943839 loss)
I0824 20:44:39.175328 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997195
I0824 20:44:39.175334 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994829
I0824 20:44:39.175341 43244 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0824 20:44:55.947571 43244 solver.cpp:228] Iteration 4660, loss = 0.0145881
I0824 20:44:55.947613 43244 solver.cpp:244]     Train net output #0: accuracy = 0.99532
I0824 20:44:55.947623 43244 solver.cpp:244]     Train net output #1: loss = 0.0145881 (* 1 = 0.0145881 loss)
I0824 20:44:55.947629 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996145
I0824 20:44:55.947635 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990055
I0824 20:44:55.947641 43244 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0824 20:45:12.707487 43244 solver.cpp:228] Iteration 4680, loss = 0.00884475
I0824 20:45:12.707600 43244 solver.cpp:244]     Train net output #0: accuracy = 0.997127
I0824 20:45:12.707615 43244 solver.cpp:244]     Train net output #1: loss = 0.00884475 (* 1 = 0.00884475 loss)
I0824 20:45:12.707621 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997195
I0824 20:45:12.707628 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99701
I0824 20:45:12.707635 43244 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0824 20:45:29.482300 43244 solver.cpp:228] Iteration 4700, loss = 0.0194724
I0824 20:45:29.482344 43244 solver.cpp:244]     Train net output #0: accuracy = 0.991311
I0824 20:45:29.482358 43244 solver.cpp:244]     Train net output #1: loss = 0.0194724 (* 1 = 0.0194724 loss)
I0824 20:45:29.482364 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991282
I0824 20:45:29.482369 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991447
I0824 20:45:29.482376 43244 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0824 20:45:46.258646 43244 solver.cpp:228] Iteration 4720, loss = 0.0105264
I0824 20:45:46.258766 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996428
I0824 20:45:46.258783 43244 solver.cpp:244]     Train net output #1: loss = 0.0105264 (* 1 = 0.0105264 loss)
I0824 20:45:46.258796 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99484
I0824 20:45:46.258801 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998267
I0824 20:45:46.258810 43244 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0824 20:46:03.029307 43244 solver.cpp:228] Iteration 4740, loss = 0.0102596
I0824 20:46:03.029351 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995927
I0824 20:46:03.029379 43244 solver.cpp:244]     Train net output #1: loss = 0.0102596 (* 1 = 0.0102596 loss)
I0824 20:46:03.029391 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996235
I0824 20:46:03.029395 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995063
I0824 20:46:03.029403 43244 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0824 20:46:19.861073 43244 solver.cpp:228] Iteration 4760, loss = 0.0104026
I0824 20:46:19.861259 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995771
I0824 20:46:19.861301 43244 solver.cpp:244]     Train net output #1: loss = 0.0104026 (* 1 = 0.0104026 loss)
I0824 20:46:19.861310 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994493
I0824 20:46:19.861315 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998005
I0824 20:46:19.861320 43244 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0824 20:46:36.723537 43244 solver.cpp:228] Iteration 4780, loss = 0.0121168
I0824 20:46:36.723610 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994178
I0824 20:46:36.723626 43244 solver.cpp:244]     Train net output #1: loss = 0.0121168 (* 1 = 0.0121168 loss)
I0824 20:46:36.723634 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992811
I0824 20:46:36.723640 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997455
I0824 20:46:36.723649 43244 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0824 20:46:53.558611 43244 solver.cpp:228] Iteration 4800, loss = 0.00847581
I0824 20:46:53.558764 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996264
I0824 20:46:53.558787 43244 solver.cpp:244]     Train net output #1: loss = 0.00847582 (* 1 = 0.00847582 loss)
I0824 20:46:53.558799 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996205
I0824 20:46:53.558809 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996501
I0824 20:46:53.558820 43244 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0824 20:47:10.380271 43244 solver.cpp:228] Iteration 4820, loss = 0.00815425
I0824 20:47:10.380326 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996639
I0824 20:47:10.380352 43244 solver.cpp:244]     Train net output #1: loss = 0.00815425 (* 1 = 0.00815425 loss)
I0824 20:47:10.380362 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996861
I0824 20:47:10.380367 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996061
I0824 20:47:10.380374 43244 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0824 20:47:27.208192 43244 solver.cpp:228] Iteration 4840, loss = 0.0134773
I0824 20:47:27.208312 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995059
I0824 20:47:27.208344 43244 solver.cpp:244]     Train net output #1: loss = 0.0134773 (* 1 = 0.0134773 loss)
I0824 20:47:27.208354 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994205
I0824 20:47:27.208365 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997625
I0824 20:47:27.208374 43244 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0824 20:47:44.024447 43244 solver.cpp:228] Iteration 4860, loss = 0.0113173
I0824 20:47:44.024502 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995696
I0824 20:47:44.024518 43244 solver.cpp:244]     Train net output #1: loss = 0.0113173 (* 1 = 0.0113173 loss)
I0824 20:47:44.024524 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995591
I0824 20:47:44.024530 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995933
I0824 20:47:44.024539 43244 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0824 20:48:00.806679 43244 solver.cpp:228] Iteration 4880, loss = 0.0115267
I0824 20:48:00.806831 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995087
I0824 20:48:00.806854 43244 solver.cpp:244]     Train net output #1: loss = 0.0115267 (* 1 = 0.0115267 loss)
I0824 20:48:00.806869 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995706
I0824 20:48:00.806877 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991948
I0824 20:48:00.806890 43244 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0824 20:48:17.614923 43244 solver.cpp:228] Iteration 4900, loss = 0.0124368
I0824 20:48:17.614979 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995324
I0824 20:48:17.614994 43244 solver.cpp:244]     Train net output #1: loss = 0.0124368 (* 1 = 0.0124368 loss)
I0824 20:48:17.615000 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996028
I0824 20:48:17.615005 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992383
I0824 20:48:17.615011 43244 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0824 20:48:34.402971 43244 solver.cpp:228] Iteration 4920, loss = 0.0104914
I0824 20:48:34.403121 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995281
I0824 20:48:34.403139 43244 solver.cpp:244]     Train net output #1: loss = 0.0104914 (* 1 = 0.0104914 loss)
I0824 20:48:34.403147 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994726
I0824 20:48:34.403152 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996876
I0824 20:48:34.403159 43244 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0824 20:48:51.188042 43244 solver.cpp:228] Iteration 4940, loss = 0.00716784
I0824 20:48:51.188088 43244 solver.cpp:244]     Train net output #0: accuracy = 0.996625
I0824 20:48:51.188102 43244 solver.cpp:244]     Train net output #1: loss = 0.00716785 (* 1 = 0.00716785 loss)
I0824 20:48:51.188109 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996168
I0824 20:48:51.188120 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997938
I0824 20:48:51.188128 43244 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0824 20:49:07.981029 43244 solver.cpp:228] Iteration 4960, loss = 0.0143119
I0824 20:49:07.981155 43244 solver.cpp:244]     Train net output #0: accuracy = 0.994416
I0824 20:49:07.981170 43244 solver.cpp:244]     Train net output #1: loss = 0.0143119 (* 1 = 0.0143119 loss)
I0824 20:49:07.981176 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993264
I0824 20:49:07.981181 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997064
I0824 20:49:07.981187 43244 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0824 20:49:24.749678 43244 solver.cpp:228] Iteration 4980, loss = 0.011395
I0824 20:49:24.749722 43244 solver.cpp:244]     Train net output #0: accuracy = 0.995965
I0824 20:49:24.749752 43244 solver.cpp:244]     Train net output #1: loss = 0.011395 (* 1 = 0.011395 loss)
I0824 20:49:24.749761 43244 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996603
I0824 20:49:24.749773 43244 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994117
I0824 20:49:24.749779 43244 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0824 20:49:41.141165 43244 solver.cpp:454] Snapshotting to binary proto file pocwisc4/training_iter_5000.caffemodel
I0824 20:49:42.141528 43244 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc4/training_iter_5000.solverstate
I0824 20:49:42.740541 43244 solver.cpp:317] Iteration 5000, loss = 0.0123498
I0824 20:49:42.740586 43244 solver.cpp:322] Optimization Done.
I0824 20:49:42.740591 43244 caffe.cpp:254] Optimization Done.

2017-08-24 20:49:43,131 log.framework MainThread  INFO       caffe models found
pocwisc4/training_iter_5000.caffemodel
2017-08-24 20:49:43,131 log.framework MainThread  INFO       Caffe model found: pocwisc4/training_iter_5000.caffemodel
2017-08-24 20:49:44,794 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 20:49:45,005 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 20:49:45,156 log.framework MainThread  INFO       train file number: 49
2017-08-24 20:49:45,156 log.framework MainThread  INFO       test file number: 6
2017-08-24 20:49:45,156 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 20:49:45,156 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 20:49:45,157 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-08-24 20:49:45,157 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-08-24 20:49:45,157 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-08-24 20:49:45,159 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc5/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc5/training"
solver_mode: GPU

2017-08-24 20:49:45,159 log.framework MainThread  INFO       caffe training step
2017-08-24 20:49:45,159 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc5/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-08-24 21:59:09,028 log.framework MainThread  INFO       I0824 20:49:45.264539 43675 caffe.cpp:217] Using GPUs 0
I0824 20:49:45.282768 43675 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0824 20:49:45.835155 43675 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc5/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc5/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0824 20:49:45.835325 43675 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc5/caffe/model_segnet_final/train.prototxt
I0824 20:49:45.838110 43675 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc5/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 20:49:45.838608 43675 layer_factory.hpp:77] Creating layer data
I0824 20:49:45.838629 43675 net.cpp:100] Creating Layer data
I0824 20:49:45.838639 43675 net.cpp:408] data -> data
I0824 20:49:45.838670 43675 net.cpp:408] data -> label
I0824 20:49:45.838690 43675 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc5/HDF5Files/train_combined.txt
I0824 20:49:45.838762 43675 hdf5_data_layer.cpp:93] Number of HDF5 files: 49
I0824 20:49:45.839921 43675 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0824 20:49:45.864806 43675 net.cpp:150] Setting up data
I0824 20:49:45.864835 43675 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 20:49:45.864850 43675 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 20:49:45.864859 43675 net.cpp:165] Memory required for data: 24883200
I0824 20:49:45.864867 43675 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 20:49:45.864883 43675 net.cpp:100] Creating Layer label_data_1_split
I0824 20:49:45.864892 43675 net.cpp:434] label_data_1_split <- label
I0824 20:49:45.864909 43675 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 20:49:45.864923 43675 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 20:49:45.864962 43675 net.cpp:150] Setting up label_data_1_split
I0824 20:49:45.864970 43675 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 20:49:45.864977 43675 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 20:49:45.864980 43675 net.cpp:165] Memory required for data: 30412800
I0824 20:49:45.864985 43675 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 20:49:45.865005 43675 net.cpp:100] Creating Layer conv1_1_1
I0824 20:49:45.865010 43675 net.cpp:434] conv1_1_1 <- data
I0824 20:49:45.865017 43675 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 20:49:46.379737 43675 net.cpp:150] Setting up conv1_1_1
I0824 20:49:46.379776 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:46.379791 43675 net.cpp:165] Memory required for data: 207360000
I0824 20:49:46.379820 43675 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 20:49:46.379839 43675 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 20:49:46.379847 43675 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 20:49:46.379861 43675 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 20:49:46.380257 43675 net.cpp:150] Setting up conv1_1_1_bn
I0824 20:49:46.380267 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:46.380277 43675 net.cpp:165] Memory required for data: 384307200
I0824 20:49:46.380290 43675 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 20:49:46.380307 43675 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 20:49:46.380312 43675 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 20:49:46.380318 43675 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 20:49:46.380368 43675 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 20:49:46.382002 43675 net.cpp:150] Setting up conv1_1_1_scale
I0824 20:49:46.382019 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:46.382025 43675 net.cpp:165] Memory required for data: 561254400
I0824 20:49:46.382033 43675 layer_factory.hpp:77] Creating layer relu1_1
I0824 20:49:46.382045 43675 net.cpp:100] Creating Layer relu1_1
I0824 20:49:46.382050 43675 net.cpp:434] relu1_1 <- conv1_1_1
I0824 20:49:46.382056 43675 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 20:49:46.382282 43675 net.cpp:150] Setting up relu1_1
I0824 20:49:46.382292 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:46.382297 43675 net.cpp:165] Memory required for data: 738201600
I0824 20:49:46.382303 43675 layer_factory.hpp:77] Creating layer conv1_2
I0824 20:49:46.382318 43675 net.cpp:100] Creating Layer conv1_2
I0824 20:49:46.382323 43675 net.cpp:434] conv1_2 <- conv1_1_1
I0824 20:49:46.382330 43675 net.cpp:408] conv1_2 -> conv1_2
I0824 20:49:46.386482 43675 net.cpp:150] Setting up conv1_2
I0824 20:49:46.386499 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:46.386508 43675 net.cpp:165] Memory required for data: 915148800
I0824 20:49:46.386520 43675 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 20:49:46.386533 43675 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 20:49:46.386539 43675 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 20:49:46.386548 43675 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 20:49:46.388075 43675 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 20:49:46.388090 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:46.388098 43675 net.cpp:165] Memory required for data: 1092096000
I0824 20:49:46.388108 43675 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 20:49:46.388118 43675 net.cpp:100] Creating Layer conv1_2_scale
I0824 20:49:46.388124 43675 net.cpp:434] conv1_2_scale <- conv1_2
I0824 20:49:46.388130 43675 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 20:49:46.388173 43675 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 20:49:46.388543 43675 net.cpp:150] Setting up conv1_2_scale
I0824 20:49:46.388553 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:46.388558 43675 net.cpp:165] Memory required for data: 1269043200
I0824 20:49:46.388566 43675 layer_factory.hpp:77] Creating layer relu1_2
I0824 20:49:46.388572 43675 net.cpp:100] Creating Layer relu1_2
I0824 20:49:46.388578 43675 net.cpp:434] relu1_2 <- conv1_2
I0824 20:49:46.388583 43675 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 20:49:46.388774 43675 net.cpp:150] Setting up relu1_2
I0824 20:49:46.388783 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:46.388788 43675 net.cpp:165] Memory required for data: 1445990400
I0824 20:49:46.388795 43675 layer_factory.hpp:77] Creating layer pool1
I0824 20:49:46.388803 43675 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 20:49:46.388809 43675 net.cpp:100] Creating Layer pool1
I0824 20:49:46.388814 43675 net.cpp:434] pool1 <- conv1_2
I0824 20:49:46.388820 43675 net.cpp:408] pool1 -> pool1
I0824 20:49:46.388830 43675 net.cpp:408] pool1 -> pool1_mask
I0824 20:49:46.388883 43675 net.cpp:150] Setting up pool1
I0824 20:49:46.388891 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:46.388897 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:46.388901 43675 net.cpp:165] Memory required for data: 1534464000
I0824 20:49:46.388906 43675 layer_factory.hpp:77] Creating layer conv2_1
I0824 20:49:46.388916 43675 net.cpp:100] Creating Layer conv2_1
I0824 20:49:46.388921 43675 net.cpp:434] conv2_1 <- pool1
I0824 20:49:46.388926 43675 net.cpp:408] conv2_1 -> conv2_1
I0824 20:49:46.394999 43675 net.cpp:150] Setting up conv2_1
I0824 20:49:46.395015 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:46.395025 43675 net.cpp:165] Memory required for data: 1622937600
I0824 20:49:46.395032 43675 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 20:49:46.395040 43675 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 20:49:46.395045 43675 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 20:49:46.395051 43675 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 20:49:46.395270 43675 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 20:49:46.395279 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:46.395283 43675 net.cpp:165] Memory required for data: 1711411200
I0824 20:49:46.395301 43675 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 20:49:46.395328 43675 net.cpp:100] Creating Layer conv2_1_scale
I0824 20:49:46.395335 43675 net.cpp:434] conv2_1_scale <- conv2_1
I0824 20:49:46.395340 43675 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 20:49:46.395382 43675 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 20:49:46.395553 43675 net.cpp:150] Setting up conv2_1_scale
I0824 20:49:46.395562 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:46.395567 43675 net.cpp:165] Memory required for data: 1799884800
I0824 20:49:46.395576 43675 layer_factory.hpp:77] Creating layer relu2_1
I0824 20:49:46.395583 43675 net.cpp:100] Creating Layer relu2_1
I0824 20:49:46.395588 43675 net.cpp:434] relu2_1 <- conv2_1
I0824 20:49:46.395594 43675 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 20:49:46.396611 43675 net.cpp:150] Setting up relu2_1
I0824 20:49:46.396626 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:46.396631 43675 net.cpp:165] Memory required for data: 1888358400
I0824 20:49:46.396636 43675 layer_factory.hpp:77] Creating layer conv2_2
I0824 20:49:46.396649 43675 net.cpp:100] Creating Layer conv2_2
I0824 20:49:46.396654 43675 net.cpp:434] conv2_2 <- conv2_1
I0824 20:49:46.396662 43675 net.cpp:408] conv2_2 -> conv2_2
I0824 20:49:46.403957 43675 net.cpp:150] Setting up conv2_2
I0824 20:49:46.403973 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:46.403982 43675 net.cpp:165] Memory required for data: 1976832000
I0824 20:49:46.403990 43675 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 20:49:46.404008 43675 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 20:49:46.404014 43675 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 20:49:46.404021 43675 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 20:49:46.404243 43675 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 20:49:46.404253 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:46.404263 43675 net.cpp:165] Memory required for data: 2065305600
I0824 20:49:46.404271 43675 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 20:49:46.404278 43675 net.cpp:100] Creating Layer conv2_2_scale
I0824 20:49:46.404284 43675 net.cpp:434] conv2_2_scale <- conv2_2
I0824 20:49:46.404289 43675 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 20:49:46.404328 43675 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 20:49:46.404498 43675 net.cpp:150] Setting up conv2_2_scale
I0824 20:49:46.404507 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:46.404512 43675 net.cpp:165] Memory required for data: 2153779200
I0824 20:49:46.404521 43675 layer_factory.hpp:77] Creating layer relu2_2
I0824 20:49:46.404528 43675 net.cpp:100] Creating Layer relu2_2
I0824 20:49:46.404534 43675 net.cpp:434] relu2_2 <- conv2_2
I0824 20:49:46.404539 43675 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 20:49:46.404729 43675 net.cpp:150] Setting up relu2_2
I0824 20:49:46.404739 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:46.404744 43675 net.cpp:165] Memory required for data: 2242252800
I0824 20:49:46.404748 43675 layer_factory.hpp:77] Creating layer pool2
I0824 20:49:46.404752 43675 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 20:49:46.404758 43675 net.cpp:100] Creating Layer pool2
I0824 20:49:46.404763 43675 net.cpp:434] pool2 <- conv2_2
I0824 20:49:46.404769 43675 net.cpp:408] pool2 -> pool2
I0824 20:49:46.404778 43675 net.cpp:408] pool2 -> pool2_mask
I0824 20:49:46.404820 43675 net.cpp:150] Setting up pool2
I0824 20:49:46.404827 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:46.404832 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:46.404837 43675 net.cpp:165] Memory required for data: 2286489600
I0824 20:49:46.404840 43675 layer_factory.hpp:77] Creating layer conv3_1
I0824 20:49:46.404853 43675 net.cpp:100] Creating Layer conv3_1
I0824 20:49:46.404860 43675 net.cpp:434] conv3_1 <- pool2
I0824 20:49:46.404865 43675 net.cpp:408] conv3_1 -> conv3_1
I0824 20:49:46.416992 43675 net.cpp:150] Setting up conv3_1
I0824 20:49:46.417022 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.417032 43675 net.cpp:165] Memory required for data: 2330726400
I0824 20:49:46.417040 43675 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 20:49:46.417048 43675 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 20:49:46.417055 43675 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 20:49:46.417062 43675 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 20:49:46.417269 43675 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 20:49:46.417277 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.417282 43675 net.cpp:165] Memory required for data: 2374963200
I0824 20:49:46.417297 43675 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 20:49:46.417306 43675 net.cpp:100] Creating Layer conv3_1_scale
I0824 20:49:46.417315 43675 net.cpp:434] conv3_1_scale <- conv3_1
I0824 20:49:46.417321 43675 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 20:49:46.417361 43675 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 20:49:46.417497 43675 net.cpp:150] Setting up conv3_1_scale
I0824 20:49:46.417506 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.417511 43675 net.cpp:165] Memory required for data: 2419200000
I0824 20:49:46.417518 43675 layer_factory.hpp:77] Creating layer relu3_1
I0824 20:49:46.417528 43675 net.cpp:100] Creating Layer relu3_1
I0824 20:49:46.417533 43675 net.cpp:434] relu3_1 <- conv3_1
I0824 20:49:46.417539 43675 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 20:49:46.417726 43675 net.cpp:150] Setting up relu3_1
I0824 20:49:46.417734 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.417739 43675 net.cpp:165] Memory required for data: 2463436800
I0824 20:49:46.417743 43675 layer_factory.hpp:77] Creating layer conv3_2
I0824 20:49:46.417755 43675 net.cpp:100] Creating Layer conv3_2
I0824 20:49:46.417760 43675 net.cpp:434] conv3_2 <- conv3_1
I0824 20:49:46.417768 43675 net.cpp:408] conv3_2 -> conv3_2
I0824 20:49:46.440903 43675 net.cpp:150] Setting up conv3_2
I0824 20:49:46.440919 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.440929 43675 net.cpp:165] Memory required for data: 2507673600
I0824 20:49:46.440938 43675 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 20:49:46.440948 43675 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 20:49:46.440955 43675 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 20:49:46.440963 43675 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 20:49:46.441164 43675 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 20:49:46.441174 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.441184 43675 net.cpp:165] Memory required for data: 2551910400
I0824 20:49:46.441195 43675 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 20:49:46.441203 43675 net.cpp:100] Creating Layer conv3_2_scale
I0824 20:49:46.441210 43675 net.cpp:434] conv3_2_scale <- conv3_2
I0824 20:49:46.441215 43675 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 20:49:46.441256 43675 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 20:49:46.441395 43675 net.cpp:150] Setting up conv3_2_scale
I0824 20:49:46.441403 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.441407 43675 net.cpp:165] Memory required for data: 2596147200
I0824 20:49:46.441414 43675 layer_factory.hpp:77] Creating layer relu3_2
I0824 20:49:46.441421 43675 net.cpp:100] Creating Layer relu3_2
I0824 20:49:46.441427 43675 net.cpp:434] relu3_2 <- conv3_2
I0824 20:49:46.441432 43675 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 20:49:46.441620 43675 net.cpp:150] Setting up relu3_2
I0824 20:49:46.441630 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.441635 43675 net.cpp:165] Memory required for data: 2640384000
I0824 20:49:46.441639 43675 layer_factory.hpp:77] Creating layer conv3_3
I0824 20:49:46.441650 43675 net.cpp:100] Creating Layer conv3_3
I0824 20:49:46.441655 43675 net.cpp:434] conv3_3 <- conv3_2
I0824 20:49:46.441663 43675 net.cpp:408] conv3_3 -> conv3_3
I0824 20:49:46.464813 43675 net.cpp:150] Setting up conv3_3
I0824 20:49:46.464843 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.464854 43675 net.cpp:165] Memory required for data: 2684620800
I0824 20:49:46.464861 43675 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 20:49:46.464874 43675 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 20:49:46.464881 43675 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 20:49:46.464889 43675 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 20:49:46.465098 43675 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 20:49:46.465107 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.465117 43675 net.cpp:165] Memory required for data: 2728857600
I0824 20:49:46.465127 43675 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 20:49:46.465137 43675 net.cpp:100] Creating Layer conv3_3_scale
I0824 20:49:46.465142 43675 net.cpp:434] conv3_3_scale <- conv3_3
I0824 20:49:46.465147 43675 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 20:49:46.465188 43675 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 20:49:46.465318 43675 net.cpp:150] Setting up conv3_3_scale
I0824 20:49:46.465327 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.465332 43675 net.cpp:165] Memory required for data: 2773094400
I0824 20:49:46.465338 43675 layer_factory.hpp:77] Creating layer relu3_3
I0824 20:49:46.465346 43675 net.cpp:100] Creating Layer relu3_3
I0824 20:49:46.465353 43675 net.cpp:434] relu3_3 <- conv3_3
I0824 20:49:46.465358 43675 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 20:49:46.465556 43675 net.cpp:150] Setting up relu3_3
I0824 20:49:46.465567 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:46.465571 43675 net.cpp:165] Memory required for data: 2817331200
I0824 20:49:46.465575 43675 layer_factory.hpp:77] Creating layer pool3
I0824 20:49:46.465581 43675 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 20:49:46.465591 43675 net.cpp:100] Creating Layer pool3
I0824 20:49:46.465596 43675 net.cpp:434] pool3 <- conv3_3
I0824 20:49:46.465602 43675 net.cpp:408] pool3 -> pool3
I0824 20:49:46.465610 43675 net.cpp:408] pool3 -> pool3_mask
I0824 20:49:46.465656 43675 net.cpp:150] Setting up pool3
I0824 20:49:46.465663 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:46.465669 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:46.465674 43675 net.cpp:165] Memory required for data: 2839449600
I0824 20:49:46.465677 43675 layer_factory.hpp:77] Creating layer conv4_1
I0824 20:49:46.465690 43675 net.cpp:100] Creating Layer conv4_1
I0824 20:49:46.465697 43675 net.cpp:434] conv4_1 <- pool3
I0824 20:49:46.465703 43675 net.cpp:408] conv4_1 -> conv4_1
I0824 20:49:46.511643 43675 net.cpp:150] Setting up conv4_1
I0824 20:49:46.511660 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.511673 43675 net.cpp:165] Memory required for data: 2861568000
I0824 20:49:46.511682 43675 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 20:49:46.511689 43675 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 20:49:46.511695 43675 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 20:49:46.511701 43675 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 20:49:46.511906 43675 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 20:49:46.511915 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.511924 43675 net.cpp:165] Memory required for data: 2883686400
I0824 20:49:46.511934 43675 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 20:49:46.511945 43675 net.cpp:100] Creating Layer conv4_1_scale
I0824 20:49:46.511951 43675 net.cpp:434] conv4_1_scale <- conv4_1
I0824 20:49:46.511957 43675 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 20:49:46.512002 43675 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 20:49:46.512125 43675 net.cpp:150] Setting up conv4_1_scale
I0824 20:49:46.512133 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.512138 43675 net.cpp:165] Memory required for data: 2905804800
I0824 20:49:46.512145 43675 layer_factory.hpp:77] Creating layer relu4_1
I0824 20:49:46.512168 43675 net.cpp:100] Creating Layer relu4_1
I0824 20:49:46.512174 43675 net.cpp:434] relu4_1 <- conv4_1
I0824 20:49:46.512181 43675 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 20:49:46.512382 43675 net.cpp:150] Setting up relu4_1
I0824 20:49:46.512393 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.512398 43675 net.cpp:165] Memory required for data: 2927923200
I0824 20:49:46.512404 43675 layer_factory.hpp:77] Creating layer conv4_2
I0824 20:49:46.512416 43675 net.cpp:100] Creating Layer conv4_2
I0824 20:49:46.512423 43675 net.cpp:434] conv4_2 <- conv4_1
I0824 20:49:46.512428 43675 net.cpp:408] conv4_2 -> conv4_2
I0824 20:49:46.595794 43675 net.cpp:150] Setting up conv4_2
I0824 20:49:46.595813 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.595823 43675 net.cpp:165] Memory required for data: 2950041600
I0824 20:49:46.595830 43675 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 20:49:46.595846 43675 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 20:49:46.595854 43675 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 20:49:46.595861 43675 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 20:49:46.596065 43675 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 20:49:46.596073 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.596082 43675 net.cpp:165] Memory required for data: 2972160000
I0824 20:49:46.596092 43675 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 20:49:46.596101 43675 net.cpp:100] Creating Layer conv4_2_scale
I0824 20:49:46.596107 43675 net.cpp:434] conv4_2_scale <- conv4_2
I0824 20:49:46.596113 43675 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 20:49:46.596153 43675 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 20:49:46.596276 43675 net.cpp:150] Setting up conv4_2_scale
I0824 20:49:46.596284 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.596290 43675 net.cpp:165] Memory required for data: 2994278400
I0824 20:49:46.596297 43675 layer_factory.hpp:77] Creating layer relu4_2
I0824 20:49:46.596305 43675 net.cpp:100] Creating Layer relu4_2
I0824 20:49:46.596310 43675 net.cpp:434] relu4_2 <- conv4_2
I0824 20:49:46.596316 43675 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 20:49:46.597357 43675 net.cpp:150] Setting up relu4_2
I0824 20:49:46.597378 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.597384 43675 net.cpp:165] Memory required for data: 3016396800
I0824 20:49:46.597390 43675 layer_factory.hpp:77] Creating layer conv4_3
I0824 20:49:46.597404 43675 net.cpp:100] Creating Layer conv4_3
I0824 20:49:46.597409 43675 net.cpp:434] conv4_3 <- conv4_2
I0824 20:49:46.597417 43675 net.cpp:408] conv4_3 -> conv4_3
I0824 20:49:46.680830 43675 net.cpp:150] Setting up conv4_3
I0824 20:49:46.680847 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.680852 43675 net.cpp:165] Memory required for data: 3038515200
I0824 20:49:46.680872 43675 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 20:49:46.680886 43675 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 20:49:46.680893 43675 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 20:49:46.680901 43675 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 20:49:46.681113 43675 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 20:49:46.681123 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.681131 43675 net.cpp:165] Memory required for data: 3060633600
I0824 20:49:46.681140 43675 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 20:49:46.681150 43675 net.cpp:100] Creating Layer conv4_3_scale
I0824 20:49:46.681156 43675 net.cpp:434] conv4_3_scale <- conv4_3
I0824 20:49:46.681161 43675 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 20:49:46.681202 43675 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 20:49:46.681330 43675 net.cpp:150] Setting up conv4_3_scale
I0824 20:49:46.681339 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.681344 43675 net.cpp:165] Memory required for data: 3082752000
I0824 20:49:46.681351 43675 layer_factory.hpp:77] Creating layer relu4_3
I0824 20:49:46.681380 43675 net.cpp:100] Creating Layer relu4_3
I0824 20:49:46.681387 43675 net.cpp:434] relu4_3 <- conv4_3
I0824 20:49:46.681393 43675 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 20:49:46.681587 43675 net.cpp:150] Setting up relu4_3
I0824 20:49:46.681597 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:46.681602 43675 net.cpp:165] Memory required for data: 3104870400
I0824 20:49:46.681607 43675 layer_factory.hpp:77] Creating layer pool4
I0824 20:49:46.681617 43675 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 20:49:46.681622 43675 net.cpp:100] Creating Layer pool4
I0824 20:49:46.681628 43675 net.cpp:434] pool4 <- conv4_3
I0824 20:49:46.681634 43675 net.cpp:408] pool4 -> pool4
I0824 20:49:46.681644 43675 net.cpp:408] pool4 -> pool4_mask
I0824 20:49:46.681692 43675 net.cpp:150] Setting up pool4
I0824 20:49:46.681700 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.681705 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.681710 43675 net.cpp:165] Memory required for data: 3116175360
I0824 20:49:46.681713 43675 layer_factory.hpp:77] Creating layer conv5_1
I0824 20:49:46.681725 43675 net.cpp:100] Creating Layer conv5_1
I0824 20:49:46.681731 43675 net.cpp:434] conv5_1 <- pool4
I0824 20:49:46.681738 43675 net.cpp:408] conv5_1 -> conv5_1
I0824 20:49:46.765226 43675 net.cpp:150] Setting up conv5_1
I0824 20:49:46.765244 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.765257 43675 net.cpp:165] Memory required for data: 3121827840
I0824 20:49:46.765265 43675 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 20:49:46.765275 43675 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 20:49:46.765280 43675 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 20:49:46.765288 43675 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 20:49:46.765506 43675 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 20:49:46.765516 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.765519 43675 net.cpp:165] Memory required for data: 3127480320
I0824 20:49:46.765527 43675 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 20:49:46.765539 43675 net.cpp:100] Creating Layer conv5_1_scale
I0824 20:49:46.765547 43675 net.cpp:434] conv5_1_scale <- conv5_1
I0824 20:49:46.765553 43675 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 20:49:46.765602 43675 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 20:49:46.765720 43675 net.cpp:150] Setting up conv5_1_scale
I0824 20:49:46.765729 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.765734 43675 net.cpp:165] Memory required for data: 3133132800
I0824 20:49:46.765741 43675 layer_factory.hpp:77] Creating layer relu5_1
I0824 20:49:46.765751 43675 net.cpp:100] Creating Layer relu5_1
I0824 20:49:46.765756 43675 net.cpp:434] relu5_1 <- conv5_1
I0824 20:49:46.765763 43675 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 20:49:46.765959 43675 net.cpp:150] Setting up relu5_1
I0824 20:49:46.765969 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.765974 43675 net.cpp:165] Memory required for data: 3138785280
I0824 20:49:46.765977 43675 layer_factory.hpp:77] Creating layer conv5_2
I0824 20:49:46.765988 43675 net.cpp:100] Creating Layer conv5_2
I0824 20:49:46.765995 43675 net.cpp:434] conv5_2 <- conv5_1
I0824 20:49:46.766001 43675 net.cpp:408] conv5_2 -> conv5_2
I0824 20:49:46.850090 43675 net.cpp:150] Setting up conv5_2
I0824 20:49:46.850112 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.850124 43675 net.cpp:165] Memory required for data: 3144437760
I0824 20:49:46.850134 43675 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 20:49:46.850147 43675 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 20:49:46.850154 43675 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 20:49:46.850162 43675 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 20:49:46.850378 43675 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 20:49:46.850388 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.850409 43675 net.cpp:165] Memory required for data: 3150090240
I0824 20:49:46.850423 43675 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 20:49:46.850435 43675 net.cpp:100] Creating Layer conv5_2_scale
I0824 20:49:46.850440 43675 net.cpp:434] conv5_2_scale <- conv5_2
I0824 20:49:46.850446 43675 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 20:49:46.850497 43675 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 20:49:46.850622 43675 net.cpp:150] Setting up conv5_2_scale
I0824 20:49:46.850631 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.850637 43675 net.cpp:165] Memory required for data: 3155742720
I0824 20:49:46.850643 43675 layer_factory.hpp:77] Creating layer relu5_2
I0824 20:49:46.850654 43675 net.cpp:100] Creating Layer relu5_2
I0824 20:49:46.850661 43675 net.cpp:434] relu5_2 <- conv5_2
I0824 20:49:46.850666 43675 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 20:49:46.850868 43675 net.cpp:150] Setting up relu5_2
I0824 20:49:46.850878 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.850883 43675 net.cpp:165] Memory required for data: 3161395200
I0824 20:49:46.850888 43675 layer_factory.hpp:77] Creating layer conv5_3
I0824 20:49:46.850900 43675 net.cpp:100] Creating Layer conv5_3
I0824 20:49:46.850906 43675 net.cpp:434] conv5_3 <- conv5_2
I0824 20:49:46.850914 43675 net.cpp:408] conv5_3 -> conv5_3
I0824 20:49:46.934423 43675 net.cpp:150] Setting up conv5_3
I0824 20:49:46.934442 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.934454 43675 net.cpp:165] Memory required for data: 3167047680
I0824 20:49:46.934463 43675 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 20:49:46.934473 43675 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 20:49:46.934482 43675 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 20:49:46.934490 43675 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 20:49:46.934707 43675 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 20:49:46.934716 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.934726 43675 net.cpp:165] Memory required for data: 3172700160
I0824 20:49:46.934734 43675 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 20:49:46.934744 43675 net.cpp:100] Creating Layer conv5_3_scale
I0824 20:49:46.934753 43675 net.cpp:434] conv5_3_scale <- conv5_3
I0824 20:49:46.934759 43675 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 20:49:46.934808 43675 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 20:49:46.934932 43675 net.cpp:150] Setting up conv5_3_scale
I0824 20:49:46.934940 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.934944 43675 net.cpp:165] Memory required for data: 3178352640
I0824 20:49:46.934953 43675 layer_factory.hpp:77] Creating layer relu5_3
I0824 20:49:46.934963 43675 net.cpp:100] Creating Layer relu5_3
I0824 20:49:46.934969 43675 net.cpp:434] relu5_3 <- conv5_3
I0824 20:49:46.934975 43675 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 20:49:46.935181 43675 net.cpp:150] Setting up relu5_3
I0824 20:49:46.935192 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.935197 43675 net.cpp:165] Memory required for data: 3184005120
I0824 20:49:46.935201 43675 layer_factory.hpp:77] Creating layer pool5
I0824 20:49:46.935209 43675 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 20:49:46.935216 43675 net.cpp:100] Creating Layer pool5
I0824 20:49:46.935221 43675 net.cpp:434] pool5 <- conv5_3
I0824 20:49:46.935230 43675 net.cpp:408] pool5 -> pool5
I0824 20:49:46.935238 43675 net.cpp:408] pool5 -> pool5_mask
I0824 20:49:46.935284 43675 net.cpp:150] Setting up pool5
I0824 20:49:46.935292 43675 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 20:49:46.935297 43675 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 20:49:46.935302 43675 net.cpp:165] Memory required for data: 3186954240
I0824 20:49:46.935304 43675 layer_factory.hpp:77] Creating layer upsample5
I0824 20:49:46.935317 43675 net.cpp:100] Creating Layer upsample5
I0824 20:49:46.935323 43675 net.cpp:434] upsample5 <- pool5
I0824 20:49:46.935344 43675 net.cpp:434] upsample5 <- pool5_mask
I0824 20:49:46.935353 43675 net.cpp:408] upsample5 -> pool5_D
I0824 20:49:46.935394 43675 net.cpp:150] Setting up upsample5
I0824 20:49:46.935400 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:46.935405 43675 net.cpp:165] Memory required for data: 3192606720
I0824 20:49:46.935408 43675 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 20:49:46.935420 43675 net.cpp:100] Creating Layer conv5_3_D
I0824 20:49:46.935425 43675 net.cpp:434] conv5_3_D <- pool5_D
I0824 20:49:46.935432 43675 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 20:49:47.019827 43675 net.cpp:150] Setting up conv5_3_D
I0824 20:49:47.019845 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.019850 43675 net.cpp:165] Memory required for data: 3198259200
I0824 20:49:47.019860 43675 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 20:49:47.019870 43675 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 20:49:47.019875 43675 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 20:49:47.019881 43675 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 20:49:47.020095 43675 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 20:49:47.020103 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.020113 43675 net.cpp:165] Memory required for data: 3203911680
I0824 20:49:47.020123 43675 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 20:49:47.020133 43675 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 20:49:47.020141 43675 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 20:49:47.020148 43675 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 20:49:47.020196 43675 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 20:49:47.020314 43675 net.cpp:150] Setting up conv5_3_D_scale
I0824 20:49:47.020323 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.020325 43675 net.cpp:165] Memory required for data: 3209564160
I0824 20:49:47.020332 43675 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 20:49:47.020340 43675 net.cpp:100] Creating Layer relu5_3_D
I0824 20:49:47.020345 43675 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 20:49:47.020350 43675 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 20:49:47.020555 43675 net.cpp:150] Setting up relu5_3_D
I0824 20:49:47.020565 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.020570 43675 net.cpp:165] Memory required for data: 3215216640
I0824 20:49:47.020573 43675 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 20:49:47.020602 43675 net.cpp:100] Creating Layer conv5_2_D
I0824 20:49:47.020608 43675 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 20:49:47.020617 43675 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 20:49:47.104146 43675 net.cpp:150] Setting up conv5_2_D
I0824 20:49:47.104163 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.104176 43675 net.cpp:165] Memory required for data: 3220869120
I0824 20:49:47.104187 43675 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 20:49:47.104199 43675 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 20:49:47.104207 43675 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 20:49:47.104214 43675 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 20:49:47.104425 43675 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 20:49:47.104434 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.104436 43675 net.cpp:165] Memory required for data: 3226521600
I0824 20:49:47.104445 43675 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 20:49:47.104454 43675 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 20:49:47.104462 43675 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 20:49:47.104468 43675 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 20:49:47.104511 43675 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 20:49:47.104630 43675 net.cpp:150] Setting up conv5_2_D_scale
I0824 20:49:47.104638 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.104642 43675 net.cpp:165] Memory required for data: 3232174080
I0824 20:49:47.104666 43675 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 20:49:47.104677 43675 net.cpp:100] Creating Layer relu5_2_D
I0824 20:49:47.104682 43675 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 20:49:47.104688 43675 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 20:49:47.105760 43675 net.cpp:150] Setting up relu5_2_D
I0824 20:49:47.105775 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.105780 43675 net.cpp:165] Memory required for data: 3237826560
I0824 20:49:47.105784 43675 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 20:49:47.105798 43675 net.cpp:100] Creating Layer conv5_1_D
I0824 20:49:47.105803 43675 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 20:49:47.105813 43675 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 20:49:47.189316 43675 net.cpp:150] Setting up conv5_1_D
I0824 20:49:47.189333 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.189337 43675 net.cpp:165] Memory required for data: 3243479040
I0824 20:49:47.189347 43675 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 20:49:47.189362 43675 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 20:49:47.189375 43675 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 20:49:47.189383 43675 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 20:49:47.189602 43675 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 20:49:47.189611 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.189615 43675 net.cpp:165] Memory required for data: 3249131520
I0824 20:49:47.189625 43675 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 20:49:47.189631 43675 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 20:49:47.189640 43675 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 20:49:47.189646 43675 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 20:49:47.189693 43675 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 20:49:47.189816 43675 net.cpp:150] Setting up conv5_1_D_scale
I0824 20:49:47.189824 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.189827 43675 net.cpp:165] Memory required for data: 3254784000
I0824 20:49:47.189834 43675 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 20:49:47.189843 43675 net.cpp:100] Creating Layer relu5_1_D
I0824 20:49:47.189848 43675 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 20:49:47.189854 43675 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 20:49:47.190049 43675 net.cpp:150] Setting up relu5_1_D
I0824 20:49:47.190059 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.190063 43675 net.cpp:165] Memory required for data: 3260436480
I0824 20:49:47.190068 43675 layer_factory.hpp:77] Creating layer upsample4
I0824 20:49:47.190078 43675 net.cpp:100] Creating Layer upsample4
I0824 20:49:47.190083 43675 net.cpp:434] upsample4 <- conv5_1_D
I0824 20:49:47.190088 43675 net.cpp:434] upsample4 <- pool4_mask
I0824 20:49:47.190096 43675 net.cpp:408] upsample4 -> pool4_D
I0824 20:49:47.190129 43675 net.cpp:150] Setting up upsample4
I0824 20:49:47.190137 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.190140 43675 net.cpp:165] Memory required for data: 3282554880
I0824 20:49:47.190145 43675 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 20:49:47.190158 43675 net.cpp:100] Creating Layer conv4_3_D
I0824 20:49:47.190163 43675 net.cpp:434] conv4_3_D <- pool4_D
I0824 20:49:47.190171 43675 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 20:49:47.273772 43675 net.cpp:150] Setting up conv4_3_D
I0824 20:49:47.273790 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.273802 43675 net.cpp:165] Memory required for data: 3304673280
I0824 20:49:47.273809 43675 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 20:49:47.273821 43675 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 20:49:47.273828 43675 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 20:49:47.273836 43675 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 20:49:47.274065 43675 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 20:49:47.274073 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.274096 43675 net.cpp:165] Memory required for data: 3326791680
I0824 20:49:47.274106 43675 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 20:49:47.274119 43675 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 20:49:47.274124 43675 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 20:49:47.274130 43675 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 20:49:47.274178 43675 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 20:49:47.274317 43675 net.cpp:150] Setting up conv4_3_D_scale
I0824 20:49:47.274325 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.274329 43675 net.cpp:165] Memory required for data: 3348910080
I0824 20:49:47.274336 43675 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 20:49:47.274344 43675 net.cpp:100] Creating Layer relu4_3_D
I0824 20:49:47.274349 43675 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 20:49:47.274355 43675 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 20:49:47.274555 43675 net.cpp:150] Setting up relu4_3_D
I0824 20:49:47.274564 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.274569 43675 net.cpp:165] Memory required for data: 3371028480
I0824 20:49:47.274574 43675 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 20:49:47.274585 43675 net.cpp:100] Creating Layer conv4_2_D
I0824 20:49:47.274591 43675 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 20:49:47.274600 43675 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 20:49:47.359786 43675 net.cpp:150] Setting up conv4_2_D
I0824 20:49:47.359807 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.359810 43675 net.cpp:165] Memory required for data: 3393146880
I0824 20:49:47.359822 43675 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 20:49:47.359836 43675 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 20:49:47.359848 43675 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 20:49:47.359858 43675 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 20:49:47.360092 43675 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 20:49:47.360100 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.360105 43675 net.cpp:165] Memory required for data: 3415265280
I0824 20:49:47.360113 43675 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 20:49:47.360126 43675 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 20:49:47.360131 43675 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 20:49:47.360136 43675 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 20:49:47.360178 43675 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 20:49:47.360321 43675 net.cpp:150] Setting up conv4_2_D_scale
I0824 20:49:47.360330 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.360333 43675 net.cpp:165] Memory required for data: 3437383680
I0824 20:49:47.360340 43675 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 20:49:47.360349 43675 net.cpp:100] Creating Layer relu4_2_D
I0824 20:49:47.360354 43675 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 20:49:47.360360 43675 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 20:49:47.360564 43675 net.cpp:150] Setting up relu4_2_D
I0824 20:49:47.360574 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.360579 43675 net.cpp:165] Memory required for data: 3459502080
I0824 20:49:47.360584 43675 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 20:49:47.360596 43675 net.cpp:100] Creating Layer conv4_1_D
I0824 20:49:47.360601 43675 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 20:49:47.360610 43675 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 20:49:47.404376 43675 net.cpp:150] Setting up conv4_1_D
I0824 20:49:47.404392 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:47.404402 43675 net.cpp:165] Memory required for data: 3470561280
I0824 20:49:47.404412 43675 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 20:49:47.404420 43675 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 20:49:47.404424 43675 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 20:49:47.404431 43675 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 20:49:47.404669 43675 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 20:49:47.404695 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:47.404703 43675 net.cpp:165] Memory required for data: 3481620480
I0824 20:49:47.404742 43675 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 20:49:47.404752 43675 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 20:49:47.404760 43675 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 20:49:47.404767 43675 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 20:49:47.404820 43675 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 20:49:47.404956 43675 net.cpp:150] Setting up conv4_1_D_scale
I0824 20:49:47.404964 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:47.404968 43675 net.cpp:165] Memory required for data: 3492679680
I0824 20:49:47.404975 43675 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 20:49:47.404984 43675 net.cpp:100] Creating Layer relu4_1_D
I0824 20:49:47.404989 43675 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 20:49:47.404995 43675 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 20:49:47.405208 43675 net.cpp:150] Setting up relu4_1_D
I0824 20:49:47.405217 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:47.405222 43675 net.cpp:165] Memory required for data: 3503738880
I0824 20:49:47.405227 43675 layer_factory.hpp:77] Creating layer upsample3
I0824 20:49:47.405237 43675 net.cpp:100] Creating Layer upsample3
I0824 20:49:47.405242 43675 net.cpp:434] upsample3 <- conv4_1_D
I0824 20:49:47.405249 43675 net.cpp:434] upsample3 <- pool3_mask
I0824 20:49:47.405257 43675 net.cpp:408] upsample3 -> pool3_D
I0824 20:49:47.405267 43675 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 20:49:47.405298 43675 net.cpp:150] Setting up upsample3
I0824 20:49:47.405306 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.405311 43675 net.cpp:165] Memory required for data: 3547975680
I0824 20:49:47.405314 43675 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 20:49:47.405326 43675 net.cpp:100] Creating Layer conv3_3_D
I0824 20:49:47.405331 43675 net.cpp:434] conv3_3_D <- pool3_D
I0824 20:49:47.405340 43675 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 20:49:47.428730 43675 net.cpp:150] Setting up conv3_3_D
I0824 20:49:47.428746 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.428756 43675 net.cpp:165] Memory required for data: 3592212480
I0824 20:49:47.428766 43675 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 20:49:47.428777 43675 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 20:49:47.428786 43675 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 20:49:47.428793 43675 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 20:49:47.429042 43675 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 20:49:47.429052 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.429055 43675 net.cpp:165] Memory required for data: 3636449280
I0824 20:49:47.429064 43675 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 20:49:47.429075 43675 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 20:49:47.429083 43675 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 20:49:47.429090 43675 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 20:49:47.429141 43675 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 20:49:47.429301 43675 net.cpp:150] Setting up conv3_3_D_scale
I0824 20:49:47.429309 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.429316 43675 net.cpp:165] Memory required for data: 3680686080
I0824 20:49:47.429322 43675 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 20:49:47.429330 43675 net.cpp:100] Creating Layer relu3_3_D
I0824 20:49:47.429335 43675 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 20:49:47.429343 43675 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 20:49:47.429561 43675 net.cpp:150] Setting up relu3_3_D
I0824 20:49:47.429574 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.429576 43675 net.cpp:165] Memory required for data: 3724922880
I0824 20:49:47.429596 43675 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 20:49:47.429612 43675 net.cpp:100] Creating Layer conv3_2_D
I0824 20:49:47.429618 43675 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 20:49:47.429627 43675 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 20:49:47.453033 43675 net.cpp:150] Setting up conv3_2_D
I0824 20:49:47.453050 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.453058 43675 net.cpp:165] Memory required for data: 3769159680
I0824 20:49:47.453068 43675 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 20:49:47.453078 43675 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 20:49:47.453088 43675 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 20:49:47.453094 43675 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 20:49:47.453349 43675 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 20:49:47.453358 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.453375 43675 net.cpp:165] Memory required for data: 3813396480
I0824 20:49:47.453388 43675 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 20:49:47.453397 43675 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 20:49:47.453402 43675 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 20:49:47.453410 43675 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 20:49:47.453459 43675 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 20:49:47.453619 43675 net.cpp:150] Setting up conv3_2_D_scale
I0824 20:49:47.453631 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.453636 43675 net.cpp:165] Memory required for data: 3857633280
I0824 20:49:47.453644 43675 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 20:49:47.453654 43675 net.cpp:100] Creating Layer relu3_2_D
I0824 20:49:47.453658 43675 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 20:49:47.453663 43675 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 20:49:47.454756 43675 net.cpp:150] Setting up relu3_2_D
I0824 20:49:47.454769 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.454776 43675 net.cpp:165] Memory required for data: 3901870080
I0824 20:49:47.454779 43675 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 20:49:47.454794 43675 net.cpp:100] Creating Layer conv3_1_D
I0824 20:49:47.454802 43675 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 20:49:47.454808 43675 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 20:49:47.468475 43675 net.cpp:150] Setting up conv3_1_D
I0824 20:49:47.468492 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:47.468502 43675 net.cpp:165] Memory required for data: 3923988480
I0824 20:49:47.468513 43675 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 20:49:47.468524 43675 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 20:49:47.468533 43675 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 20:49:47.468539 43675 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 20:49:47.468793 43675 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 20:49:47.468802 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:47.468812 43675 net.cpp:165] Memory required for data: 3946106880
I0824 20:49:47.468822 43675 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 20:49:47.468832 43675 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 20:49:47.468838 43675 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 20:49:47.468844 43675 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 20:49:47.468893 43675 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 20:49:47.469055 43675 net.cpp:150] Setting up conv3_1_D_scale
I0824 20:49:47.469064 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:47.469069 43675 net.cpp:165] Memory required for data: 3968225280
I0824 20:49:47.469077 43675 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 20:49:47.469085 43675 net.cpp:100] Creating Layer relu3_1_D
I0824 20:49:47.469090 43675 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 20:49:47.469099 43675 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 20:49:47.469316 43675 net.cpp:150] Setting up relu3_1_D
I0824 20:49:47.469341 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:47.469347 43675 net.cpp:165] Memory required for data: 3990343680
I0824 20:49:47.469350 43675 layer_factory.hpp:77] Creating layer upsample2
I0824 20:49:47.469358 43675 net.cpp:100] Creating Layer upsample2
I0824 20:49:47.469363 43675 net.cpp:434] upsample2 <- conv3_1_D
I0824 20:49:47.469375 43675 net.cpp:434] upsample2 <- pool2_mask
I0824 20:49:47.469385 43675 net.cpp:408] upsample2 -> pool2_D
I0824 20:49:47.469395 43675 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 20:49:47.469430 43675 net.cpp:150] Setting up upsample2
I0824 20:49:47.469439 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.469444 43675 net.cpp:165] Memory required for data: 4078817280
I0824 20:49:47.469449 43675 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 20:49:47.469460 43675 net.cpp:100] Creating Layer conv2_2_D
I0824 20:49:47.469466 43675 net.cpp:434] conv2_2_D <- pool2_D
I0824 20:49:47.469475 43675 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 20:49:47.477071 43675 net.cpp:150] Setting up conv2_2_D
I0824 20:49:47.477087 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.477097 43675 net.cpp:165] Memory required for data: 4167290880
I0824 20:49:47.477105 43675 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 20:49:47.477123 43675 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 20:49:47.477129 43675 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 20:49:47.477138 43675 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 20:49:47.477438 43675 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 20:49:47.477448 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.477452 43675 net.cpp:165] Memory required for data: 4255764480
I0824 20:49:47.477461 43675 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 20:49:47.477469 43675 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 20:49:47.477479 43675 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 20:49:47.477488 43675 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 20:49:47.477536 43675 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 20:49:47.479007 43675 net.cpp:150] Setting up conv2_2_D_scale
I0824 20:49:47.479022 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.479029 43675 net.cpp:165] Memory required for data: 4344238080
I0824 20:49:47.479038 43675 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 20:49:47.479048 43675 net.cpp:100] Creating Layer relu2_2_D
I0824 20:49:47.479054 43675 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 20:49:47.479063 43675 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 20:49:47.479293 43675 net.cpp:150] Setting up relu2_2_D
I0824 20:49:47.479305 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.479310 43675 net.cpp:165] Memory required for data: 4432711680
I0824 20:49:47.479313 43675 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 20:49:47.479327 43675 net.cpp:100] Creating Layer conv2_1_D
I0824 20:49:47.479333 43675 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 20:49:47.479343 43675 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 20:49:47.484535 43675 net.cpp:150] Setting up conv2_1_D
I0824 20:49:47.484551 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:47.484561 43675 net.cpp:165] Memory required for data: 4476948480
I0824 20:49:47.484570 43675 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 20:49:47.484586 43675 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 20:49:47.484592 43675 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 20:49:47.484599 43675 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 20:49:47.484891 43675 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 20:49:47.484901 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:47.484906 43675 net.cpp:165] Memory required for data: 4521185280
I0824 20:49:47.484915 43675 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 20:49:47.484938 43675 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 20:49:47.484946 43675 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 20:49:47.484951 43675 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 20:49:47.485003 43675 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 20:49:47.485219 43675 net.cpp:150] Setting up conv2_1_D_scale
I0824 20:49:47.485229 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:47.485234 43675 net.cpp:165] Memory required for data: 4565422080
I0824 20:49:47.485240 43675 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 20:49:47.485251 43675 net.cpp:100] Creating Layer relu2_1_D
I0824 20:49:47.485257 43675 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 20:49:47.485265 43675 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 20:49:47.485492 43675 net.cpp:150] Setting up relu2_1_D
I0824 20:49:47.485503 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:47.485507 43675 net.cpp:165] Memory required for data: 4609658880
I0824 20:49:47.485512 43675 layer_factory.hpp:77] Creating layer upsample1
I0824 20:49:47.485518 43675 net.cpp:100] Creating Layer upsample1
I0824 20:49:47.485523 43675 net.cpp:434] upsample1 <- conv2_1_D
I0824 20:49:47.485529 43675 net.cpp:434] upsample1 <- pool1_mask
I0824 20:49:47.485539 43675 net.cpp:408] upsample1 -> pool1_D
I0824 20:49:47.485548 43675 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 20:49:47.485580 43675 net.cpp:150] Setting up upsample1
I0824 20:49:47.485587 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.485591 43675 net.cpp:165] Memory required for data: 4786606080
I0824 20:49:47.485595 43675 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 20:49:47.485611 43675 net.cpp:100] Creating Layer conv1_2_D
I0824 20:49:47.485617 43675 net.cpp:434] conv1_2_D <- pool1_D
I0824 20:49:47.485623 43675 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 20:49:47.490093 43675 net.cpp:150] Setting up conv1_2_D
I0824 20:49:47.490110 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.490120 43675 net.cpp:165] Memory required for data: 4963553280
I0824 20:49:47.490128 43675 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 20:49:47.490137 43675 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 20:49:47.490144 43675 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 20:49:47.490152 43675 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 20:49:47.490545 43675 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 20:49:47.490556 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.490561 43675 net.cpp:165] Memory required for data: 5140500480
I0824 20:49:47.490568 43675 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 20:49:47.490576 43675 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 20:49:47.490581 43675 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 20:49:47.490587 43675 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 20:49:47.490636 43675 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 20:49:47.492311 43675 net.cpp:150] Setting up conv1_2_D_scale
I0824 20:49:47.492326 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.492331 43675 net.cpp:165] Memory required for data: 5317447680
I0824 20:49:47.492339 43675 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 20:49:47.492350 43675 net.cpp:100] Creating Layer relu1_2_D
I0824 20:49:47.492357 43675 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 20:49:47.492362 43675 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 20:49:47.492594 43675 net.cpp:150] Setting up relu1_2_D
I0824 20:49:47.492604 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.492609 43675 net.cpp:165] Memory required for data: 5494394880
I0824 20:49:47.492614 43675 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 20:49:47.492628 43675 net.cpp:100] Creating Layer conv1_1_1_D
I0824 20:49:47.492635 43675 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 20:49:47.492657 43675 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 20:49:47.494700 43675 net.cpp:150] Setting up conv1_1_1_D
I0824 20:49:47.494716 43675 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 20:49:47.494721 43675 net.cpp:165] Memory required for data: 5499924480
I0824 20:49:47.494729 43675 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 20:49:47.494738 43675 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 20:49:47.494743 43675 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 20:49:47.494752 43675 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 20:49:47.494763 43675 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 20:49:47.494814 43675 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 20:49:47.494825 43675 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 20:49:47.494832 43675 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 20:49:47.494835 43675 net.cpp:165] Memory required for data: 5510983680
I0824 20:49:47.494840 43675 layer_factory.hpp:77] Creating layer loss
I0824 20:49:47.494854 43675 net.cpp:100] Creating Layer loss
I0824 20:49:47.494860 43675 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 20:49:47.494865 43675 net.cpp:434] loss <- label_data_1_split_0
I0824 20:49:47.494873 43675 net.cpp:408] loss -> loss
I0824 20:49:47.494889 43675 layer_factory.hpp:77] Creating layer loss
I0824 20:49:47.498963 43675 net.cpp:150] Setting up loss
I0824 20:49:47.498980 43675 net.cpp:157] Top shape: (1)
I0824 20:49:47.498988 43675 net.cpp:160]     with loss weight 1
I0824 20:49:47.499027 43675 net.cpp:165] Memory required for data: 5510983684
I0824 20:49:47.499032 43675 layer_factory.hpp:77] Creating layer accuracy
I0824 20:49:47.499042 43675 net.cpp:100] Creating Layer accuracy
I0824 20:49:47.499047 43675 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 20:49:47.499053 43675 net.cpp:434] accuracy <- label_data_1_split_1
I0824 20:49:47.499060 43675 net.cpp:408] accuracy -> accuracy
I0824 20:49:47.499068 43675 net.cpp:408] accuracy -> per_class_accuracy
I0824 20:49:47.499124 43675 net.cpp:150] Setting up accuracy
I0824 20:49:47.499131 43675 net.cpp:157] Top shape: (1)
I0824 20:49:47.499136 43675 net.cpp:157] Top shape: 2 (2)
I0824 20:49:47.499141 43675 net.cpp:165] Memory required for data: 5510983696
I0824 20:49:47.499145 43675 net.cpp:228] accuracy does not need backward computation.
I0824 20:49:47.499150 43675 net.cpp:226] loss needs backward computation.
I0824 20:49:47.499156 43675 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 20:49:47.499159 43675 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 20:49:47.499163 43675 net.cpp:226] relu1_2_D needs backward computation.
I0824 20:49:47.499167 43675 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 20:49:47.499171 43675 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 20:49:47.499174 43675 net.cpp:226] conv1_2_D needs backward computation.
I0824 20:49:47.499179 43675 net.cpp:226] upsample1 needs backward computation.
I0824 20:49:47.499183 43675 net.cpp:226] relu2_1_D needs backward computation.
I0824 20:49:47.499186 43675 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 20:49:47.499191 43675 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 20:49:47.499193 43675 net.cpp:226] conv2_1_D needs backward computation.
I0824 20:49:47.499198 43675 net.cpp:226] relu2_2_D needs backward computation.
I0824 20:49:47.499202 43675 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 20:49:47.499205 43675 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 20:49:47.499208 43675 net.cpp:226] conv2_2_D needs backward computation.
I0824 20:49:47.499212 43675 net.cpp:226] upsample2 needs backward computation.
I0824 20:49:47.499217 43675 net.cpp:226] relu3_1_D needs backward computation.
I0824 20:49:47.499222 43675 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 20:49:47.499240 43675 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 20:49:47.499244 43675 net.cpp:226] conv3_1_D needs backward computation.
I0824 20:49:47.499248 43675 net.cpp:226] relu3_2_D needs backward computation.
I0824 20:49:47.499251 43675 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 20:49:47.499256 43675 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 20:49:47.499259 43675 net.cpp:226] conv3_2_D needs backward computation.
I0824 20:49:47.499264 43675 net.cpp:226] relu3_3_D needs backward computation.
I0824 20:49:47.499266 43675 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 20:49:47.499269 43675 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 20:49:47.499274 43675 net.cpp:226] conv3_3_D needs backward computation.
I0824 20:49:47.499277 43675 net.cpp:226] upsample3 needs backward computation.
I0824 20:49:47.499281 43675 net.cpp:226] relu4_1_D needs backward computation.
I0824 20:49:47.499284 43675 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 20:49:47.499289 43675 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 20:49:47.499294 43675 net.cpp:226] conv4_1_D needs backward computation.
I0824 20:49:47.499296 43675 net.cpp:226] relu4_2_D needs backward computation.
I0824 20:49:47.499300 43675 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 20:49:47.499303 43675 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 20:49:47.499307 43675 net.cpp:226] conv4_2_D needs backward computation.
I0824 20:49:47.499312 43675 net.cpp:226] relu4_3_D needs backward computation.
I0824 20:49:47.499316 43675 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 20:49:47.499320 43675 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 20:49:47.499323 43675 net.cpp:226] conv4_3_D needs backward computation.
I0824 20:49:47.499327 43675 net.cpp:226] upsample4 needs backward computation.
I0824 20:49:47.499335 43675 net.cpp:226] relu5_1_D needs backward computation.
I0824 20:49:47.499341 43675 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 20:49:47.499344 43675 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 20:49:47.499347 43675 net.cpp:226] conv5_1_D needs backward computation.
I0824 20:49:47.499352 43675 net.cpp:226] relu5_2_D needs backward computation.
I0824 20:49:47.499358 43675 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 20:49:47.499362 43675 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 20:49:47.499366 43675 net.cpp:226] conv5_2_D needs backward computation.
I0824 20:49:47.499372 43675 net.cpp:226] relu5_3_D needs backward computation.
I0824 20:49:47.499377 43675 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 20:49:47.499380 43675 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 20:49:47.499384 43675 net.cpp:226] conv5_3_D needs backward computation.
I0824 20:49:47.499387 43675 net.cpp:226] upsample5 needs backward computation.
I0824 20:49:47.499393 43675 net.cpp:226] pool5 needs backward computation.
I0824 20:49:47.499399 43675 net.cpp:226] relu5_3 needs backward computation.
I0824 20:49:47.499403 43675 net.cpp:226] conv5_3_scale needs backward computation.
I0824 20:49:47.499408 43675 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 20:49:47.499411 43675 net.cpp:226] conv5_3 needs backward computation.
I0824 20:49:47.499416 43675 net.cpp:226] relu5_2 needs backward computation.
I0824 20:49:47.499419 43675 net.cpp:226] conv5_2_scale needs backward computation.
I0824 20:49:47.499423 43675 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 20:49:47.499428 43675 net.cpp:226] conv5_2 needs backward computation.
I0824 20:49:47.499433 43675 net.cpp:226] relu5_1 needs backward computation.
I0824 20:49:47.499436 43675 net.cpp:226] conv5_1_scale needs backward computation.
I0824 20:49:47.499439 43675 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 20:49:47.499444 43675 net.cpp:226] conv5_1 needs backward computation.
I0824 20:49:47.499449 43675 net.cpp:226] pool4 needs backward computation.
I0824 20:49:47.499464 43675 net.cpp:226] relu4_3 needs backward computation.
I0824 20:49:47.499469 43675 net.cpp:226] conv4_3_scale needs backward computation.
I0824 20:49:47.499474 43675 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 20:49:47.499476 43675 net.cpp:226] conv4_3 needs backward computation.
I0824 20:49:47.499480 43675 net.cpp:226] relu4_2 needs backward computation.
I0824 20:49:47.499485 43675 net.cpp:226] conv4_2_scale needs backward computation.
I0824 20:49:47.499488 43675 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 20:49:47.499492 43675 net.cpp:226] conv4_2 needs backward computation.
I0824 20:49:47.499495 43675 net.cpp:226] relu4_1 needs backward computation.
I0824 20:49:47.499500 43675 net.cpp:226] conv4_1_scale needs backward computation.
I0824 20:49:47.499505 43675 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 20:49:47.499508 43675 net.cpp:226] conv4_1 needs backward computation.
I0824 20:49:47.499512 43675 net.cpp:226] pool3 needs backward computation.
I0824 20:49:47.499518 43675 net.cpp:226] relu3_3 needs backward computation.
I0824 20:49:47.499522 43675 net.cpp:226] conv3_3_scale needs backward computation.
I0824 20:49:47.499526 43675 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 20:49:47.499529 43675 net.cpp:226] conv3_3 needs backward computation.
I0824 20:49:47.499533 43675 net.cpp:226] relu3_2 needs backward computation.
I0824 20:49:47.499537 43675 net.cpp:226] conv3_2_scale needs backward computation.
I0824 20:49:47.499541 43675 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 20:49:47.499544 43675 net.cpp:226] conv3_2 needs backward computation.
I0824 20:49:47.499548 43675 net.cpp:226] relu3_1 needs backward computation.
I0824 20:49:47.499552 43675 net.cpp:226] conv3_1_scale needs backward computation.
I0824 20:49:47.499558 43675 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 20:49:47.499562 43675 net.cpp:226] conv3_1 needs backward computation.
I0824 20:49:47.499565 43675 net.cpp:226] pool2 needs backward computation.
I0824 20:49:47.499569 43675 net.cpp:226] relu2_2 needs backward computation.
I0824 20:49:47.499573 43675 net.cpp:226] conv2_2_scale needs backward computation.
I0824 20:49:47.499577 43675 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 20:49:47.499580 43675 net.cpp:226] conv2_2 needs backward computation.
I0824 20:49:47.499586 43675 net.cpp:226] relu2_1 needs backward computation.
I0824 20:49:47.499590 43675 net.cpp:226] conv2_1_scale needs backward computation.
I0824 20:49:47.499593 43675 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 20:49:47.499598 43675 net.cpp:226] conv2_1 needs backward computation.
I0824 20:49:47.499601 43675 net.cpp:226] pool1 needs backward computation.
I0824 20:49:47.499605 43675 net.cpp:226] relu1_2 needs backward computation.
I0824 20:49:47.499608 43675 net.cpp:226] conv1_2_scale needs backward computation.
I0824 20:49:47.499613 43675 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 20:49:47.499616 43675 net.cpp:226] conv1_2 needs backward computation.
I0824 20:49:47.499620 43675 net.cpp:226] relu1_1 needs backward computation.
I0824 20:49:47.499624 43675 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 20:49:47.499627 43675 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 20:49:47.499632 43675 net.cpp:226] conv1_1_1 needs backward computation.
I0824 20:49:47.499637 43675 net.cpp:228] label_data_1_split does not need backward computation.
I0824 20:49:47.499644 43675 net.cpp:228] data does not need backward computation.
I0824 20:49:47.499650 43675 net.cpp:270] This network produces output accuracy
I0824 20:49:47.499655 43675 net.cpp:270] This network produces output loss
I0824 20:49:47.499658 43675 net.cpp:270] This network produces output per_class_accuracy
I0824 20:49:47.499727 43675 net.cpp:283] Network initialization done.
I0824 20:49:47.502071 43675 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc5/caffe/model_segnet_final/train.prototxt
I0824 20:49:47.502758 43675 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc5/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 20:49:47.503170 43675 layer_factory.hpp:77] Creating layer data
I0824 20:49:47.503183 43675 net.cpp:100] Creating Layer data
I0824 20:49:47.503190 43675 net.cpp:408] data -> data
I0824 20:49:47.503198 43675 net.cpp:408] data -> label
I0824 20:49:47.503207 43675 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc5/HDF5Files/train_combined.txt
I0824 20:49:47.503259 43675 hdf5_data_layer.cpp:93] Number of HDF5 files: 49
I0824 20:49:47.531713 43675 net.cpp:150] Setting up data
I0824 20:49:47.531731 43675 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 20:49:47.531738 43675 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 20:49:47.531741 43675 net.cpp:165] Memory required for data: 24883200
I0824 20:49:47.531745 43675 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 20:49:47.531755 43675 net.cpp:100] Creating Layer label_data_1_split
I0824 20:49:47.531764 43675 net.cpp:434] label_data_1_split <- label
I0824 20:49:47.531770 43675 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 20:49:47.531780 43675 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 20:49:47.531823 43675 net.cpp:150] Setting up label_data_1_split
I0824 20:49:47.531831 43675 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 20:49:47.531836 43675 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 20:49:47.531846 43675 net.cpp:165] Memory required for data: 30412800
I0824 20:49:47.531849 43675 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 20:49:47.531859 43675 net.cpp:100] Creating Layer conv1_1_1
I0824 20:49:47.531864 43675 net.cpp:434] conv1_1_1 <- data
I0824 20:49:47.531870 43675 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 20:49:47.535321 43675 net.cpp:150] Setting up conv1_1_1
I0824 20:49:47.535339 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.535347 43675 net.cpp:165] Memory required for data: 207360000
I0824 20:49:47.535359 43675 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 20:49:47.535372 43675 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 20:49:47.535379 43675 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 20:49:47.535385 43675 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 20:49:47.535763 43675 net.cpp:150] Setting up conv1_1_1_bn
I0824 20:49:47.535773 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.535782 43675 net.cpp:165] Memory required for data: 384307200
I0824 20:49:47.535794 43675 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 20:49:47.535804 43675 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 20:49:47.535809 43675 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 20:49:47.535814 43675 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 20:49:47.535861 43675 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 20:49:47.537549 43675 net.cpp:150] Setting up conv1_1_1_scale
I0824 20:49:47.537565 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.537570 43675 net.cpp:165] Memory required for data: 561254400
I0824 20:49:47.537580 43675 layer_factory.hpp:77] Creating layer relu1_1
I0824 20:49:47.537587 43675 net.cpp:100] Creating Layer relu1_1
I0824 20:49:47.537592 43675 net.cpp:434] relu1_1 <- conv1_1_1
I0824 20:49:47.537598 43675 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 20:49:47.537812 43675 net.cpp:150] Setting up relu1_1
I0824 20:49:47.537822 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.537827 43675 net.cpp:165] Memory required for data: 738201600
I0824 20:49:47.537832 43675 layer_factory.hpp:77] Creating layer conv1_2
I0824 20:49:47.537840 43675 net.cpp:100] Creating Layer conv1_2
I0824 20:49:47.537845 43675 net.cpp:434] conv1_2 <- conv1_1_1
I0824 20:49:47.537852 43675 net.cpp:408] conv1_2 -> conv1_2
I0824 20:49:47.541918 43675 net.cpp:150] Setting up conv1_2
I0824 20:49:47.541934 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.541942 43675 net.cpp:165] Memory required for data: 915148800
I0824 20:49:47.541971 43675 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 20:49:47.541981 43675 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 20:49:47.541987 43675 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 20:49:47.541993 43675 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 20:49:47.542366 43675 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 20:49:47.542376 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.542381 43675 net.cpp:165] Memory required for data: 1092096000
I0824 20:49:47.542389 43675 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 20:49:47.542398 43675 net.cpp:100] Creating Layer conv1_2_scale
I0824 20:49:47.542403 43675 net.cpp:434] conv1_2_scale <- conv1_2
I0824 20:49:47.542408 43675 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 20:49:47.542457 43675 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 20:49:47.544144 43675 net.cpp:150] Setting up conv1_2_scale
I0824 20:49:47.544159 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.544164 43675 net.cpp:165] Memory required for data: 1269043200
I0824 20:49:47.544172 43675 layer_factory.hpp:77] Creating layer relu1_2
I0824 20:49:47.544179 43675 net.cpp:100] Creating Layer relu1_2
I0824 20:49:47.544184 43675 net.cpp:434] relu1_2 <- conv1_2
I0824 20:49:47.544190 43675 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 20:49:47.545298 43675 net.cpp:150] Setting up relu1_2
I0824 20:49:47.545313 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:47.545318 43675 net.cpp:165] Memory required for data: 1445990400
I0824 20:49:47.545322 43675 layer_factory.hpp:77] Creating layer pool1
I0824 20:49:47.545327 43675 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 20:49:47.545334 43675 net.cpp:100] Creating Layer pool1
I0824 20:49:47.545339 43675 net.cpp:434] pool1 <- conv1_2
I0824 20:49:47.545348 43675 net.cpp:408] pool1 -> pool1
I0824 20:49:47.545358 43675 net.cpp:408] pool1 -> pool1_mask
I0824 20:49:47.545420 43675 net.cpp:150] Setting up pool1
I0824 20:49:47.545429 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:47.545434 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:47.545440 43675 net.cpp:165] Memory required for data: 1534464000
I0824 20:49:47.545444 43675 layer_factory.hpp:77] Creating layer conv2_1
I0824 20:49:47.545456 43675 net.cpp:100] Creating Layer conv2_1
I0824 20:49:47.545462 43675 net.cpp:434] conv2_1 <- pool1
I0824 20:49:47.545469 43675 net.cpp:408] conv2_1 -> conv2_1
I0824 20:49:47.549774 43675 net.cpp:150] Setting up conv2_1
I0824 20:49:47.549790 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.549803 43675 net.cpp:165] Memory required for data: 1622937600
I0824 20:49:47.549809 43675 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 20:49:47.549819 43675 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 20:49:47.549826 43675 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 20:49:47.549835 43675 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 20:49:47.550144 43675 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 20:49:47.550153 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.550158 43675 net.cpp:165] Memory required for data: 1711411200
I0824 20:49:47.550170 43675 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 20:49:47.550181 43675 net.cpp:100] Creating Layer conv2_1_scale
I0824 20:49:47.550187 43675 net.cpp:434] conv2_1_scale <- conv2_1
I0824 20:49:47.550194 43675 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 20:49:47.550246 43675 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 20:49:47.550485 43675 net.cpp:150] Setting up conv2_1_scale
I0824 20:49:47.550495 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.550500 43675 net.cpp:165] Memory required for data: 1799884800
I0824 20:49:47.550508 43675 layer_factory.hpp:77] Creating layer relu2_1
I0824 20:49:47.550514 43675 net.cpp:100] Creating Layer relu2_1
I0824 20:49:47.550519 43675 net.cpp:434] relu2_1 <- conv2_1
I0824 20:49:47.550526 43675 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 20:49:47.551654 43675 net.cpp:150] Setting up relu2_1
I0824 20:49:47.551668 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.551674 43675 net.cpp:165] Memory required for data: 1888358400
I0824 20:49:47.551678 43675 layer_factory.hpp:77] Creating layer conv2_2
I0824 20:49:47.551692 43675 net.cpp:100] Creating Layer conv2_2
I0824 20:49:47.551698 43675 net.cpp:434] conv2_2 <- conv2_1
I0824 20:49:47.551707 43675 net.cpp:408] conv2_2 -> conv2_2
I0824 20:49:47.560705 43675 net.cpp:150] Setting up conv2_2
I0824 20:49:47.560724 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.560734 43675 net.cpp:165] Memory required for data: 1976832000
I0824 20:49:47.560741 43675 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 20:49:47.560753 43675 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 20:49:47.560760 43675 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 20:49:47.560766 43675 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 20:49:47.562350 43675 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 20:49:47.562363 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.562373 43675 net.cpp:165] Memory required for data: 2065305600
I0824 20:49:47.562383 43675 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 20:49:47.562393 43675 net.cpp:100] Creating Layer conv2_2_scale
I0824 20:49:47.562402 43675 net.cpp:434] conv2_2_scale <- conv2_2
I0824 20:49:47.562407 43675 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 20:49:47.562467 43675 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 20:49:47.562680 43675 net.cpp:150] Setting up conv2_2_scale
I0824 20:49:47.562688 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.562693 43675 net.cpp:165] Memory required for data: 2153779200
I0824 20:49:47.562700 43675 layer_factory.hpp:77] Creating layer relu2_2
I0824 20:49:47.562707 43675 net.cpp:100] Creating Layer relu2_2
I0824 20:49:47.562712 43675 net.cpp:434] relu2_2 <- conv2_2
I0824 20:49:47.562721 43675 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 20:49:47.562940 43675 net.cpp:150] Setting up relu2_2
I0824 20:49:47.562950 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:47.562955 43675 net.cpp:165] Memory required for data: 2242252800
I0824 20:49:47.562959 43675 layer_factory.hpp:77] Creating layer pool2
I0824 20:49:47.562963 43675 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 20:49:47.562974 43675 net.cpp:100] Creating Layer pool2
I0824 20:49:47.562979 43675 net.cpp:434] pool2 <- conv2_2
I0824 20:49:47.562985 43675 net.cpp:408] pool2 -> pool2
I0824 20:49:47.562994 43675 net.cpp:408] pool2 -> pool2_mask
I0824 20:49:47.563052 43675 net.cpp:150] Setting up pool2
I0824 20:49:47.563060 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:47.563066 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:47.563069 43675 net.cpp:165] Memory required for data: 2286489600
I0824 20:49:47.563073 43675 layer_factory.hpp:77] Creating layer conv3_1
I0824 20:49:47.563086 43675 net.cpp:100] Creating Layer conv3_1
I0824 20:49:47.563091 43675 net.cpp:434] conv3_1 <- pool2
I0824 20:49:47.563099 43675 net.cpp:408] conv3_1 -> conv3_1
I0824 20:49:47.575575 43675 net.cpp:150] Setting up conv3_1
I0824 20:49:47.575597 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.575603 43675 net.cpp:165] Memory required for data: 2330726400
I0824 20:49:47.575613 43675 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 20:49:47.575619 43675 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 20:49:47.575625 43675 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 20:49:47.575633 43675 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 20:49:47.575911 43675 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 20:49:47.575920 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.575932 43675 net.cpp:165] Memory required for data: 2374963200
I0824 20:49:47.575944 43675 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 20:49:47.575969 43675 net.cpp:100] Creating Layer conv3_1_scale
I0824 20:49:47.575975 43675 net.cpp:434] conv3_1_scale <- conv3_1
I0824 20:49:47.575981 43675 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 20:49:47.576037 43675 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 20:49:47.576215 43675 net.cpp:150] Setting up conv3_1_scale
I0824 20:49:47.576223 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.576228 43675 net.cpp:165] Memory required for data: 2419200000
I0824 20:49:47.576236 43675 layer_factory.hpp:77] Creating layer relu3_1
I0824 20:49:47.576242 43675 net.cpp:100] Creating Layer relu3_1
I0824 20:49:47.576247 43675 net.cpp:434] relu3_1 <- conv3_1
I0824 20:49:47.576252 43675 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 20:49:47.576475 43675 net.cpp:150] Setting up relu3_1
I0824 20:49:47.576485 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.576490 43675 net.cpp:165] Memory required for data: 2463436800
I0824 20:49:47.576494 43675 layer_factory.hpp:77] Creating layer conv3_2
I0824 20:49:47.576506 43675 net.cpp:100] Creating Layer conv3_2
I0824 20:49:47.576512 43675 net.cpp:434] conv3_2 <- conv3_1
I0824 20:49:47.576521 43675 net.cpp:408] conv3_2 -> conv3_2
I0824 20:49:47.600095 43675 net.cpp:150] Setting up conv3_2
I0824 20:49:47.600111 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.600121 43675 net.cpp:165] Memory required for data: 2507673600
I0824 20:49:47.600129 43675 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 20:49:47.600139 43675 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 20:49:47.600147 43675 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 20:49:47.600152 43675 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 20:49:47.600435 43675 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 20:49:47.600443 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.600452 43675 net.cpp:165] Memory required for data: 2551910400
I0824 20:49:47.600461 43675 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 20:49:47.600469 43675 net.cpp:100] Creating Layer conv3_2_scale
I0824 20:49:47.600477 43675 net.cpp:434] conv3_2_scale <- conv3_2
I0824 20:49:47.600482 43675 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 20:49:47.600534 43675 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 20:49:47.600711 43675 net.cpp:150] Setting up conv3_2_scale
I0824 20:49:47.600720 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.600726 43675 net.cpp:165] Memory required for data: 2596147200
I0824 20:49:47.600733 43675 layer_factory.hpp:77] Creating layer relu3_2
I0824 20:49:47.600742 43675 net.cpp:100] Creating Layer relu3_2
I0824 20:49:47.600749 43675 net.cpp:434] relu3_2 <- conv3_2
I0824 20:49:47.600754 43675 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 20:49:47.600980 43675 net.cpp:150] Setting up relu3_2
I0824 20:49:47.600991 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.600998 43675 net.cpp:165] Memory required for data: 2640384000
I0824 20:49:47.601003 43675 layer_factory.hpp:77] Creating layer conv3_3
I0824 20:49:47.601014 43675 net.cpp:100] Creating Layer conv3_3
I0824 20:49:47.601019 43675 net.cpp:434] conv3_3 <- conv3_2
I0824 20:49:47.601028 43675 net.cpp:408] conv3_3 -> conv3_3
I0824 20:49:47.624579 43675 net.cpp:150] Setting up conv3_3
I0824 20:49:47.624596 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.624606 43675 net.cpp:165] Memory required for data: 2684620800
I0824 20:49:47.624614 43675 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 20:49:47.624624 43675 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 20:49:47.624634 43675 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 20:49:47.624640 43675 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 20:49:47.624924 43675 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 20:49:47.624933 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.624943 43675 net.cpp:165] Memory required for data: 2728857600
I0824 20:49:47.624953 43675 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 20:49:47.624976 43675 net.cpp:100] Creating Layer conv3_3_scale
I0824 20:49:47.624982 43675 net.cpp:434] conv3_3_scale <- conv3_3
I0824 20:49:47.624987 43675 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 20:49:47.625042 43675 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 20:49:47.625221 43675 net.cpp:150] Setting up conv3_3_scale
I0824 20:49:47.625231 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.625236 43675 net.cpp:165] Memory required for data: 2773094400
I0824 20:49:47.625242 43675 layer_factory.hpp:77] Creating layer relu3_3
I0824 20:49:47.625252 43675 net.cpp:100] Creating Layer relu3_3
I0824 20:49:47.625258 43675 net.cpp:434] relu3_3 <- conv3_3
I0824 20:49:47.625263 43675 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 20:49:47.625491 43675 net.cpp:150] Setting up relu3_3
I0824 20:49:47.625502 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:47.625506 43675 net.cpp:165] Memory required for data: 2817331200
I0824 20:49:47.625510 43675 layer_factory.hpp:77] Creating layer pool3
I0824 20:49:47.625515 43675 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 20:49:47.625530 43675 net.cpp:100] Creating Layer pool3
I0824 20:49:47.625535 43675 net.cpp:434] pool3 <- conv3_3
I0824 20:49:47.625541 43675 net.cpp:408] pool3 -> pool3
I0824 20:49:47.625550 43675 net.cpp:408] pool3 -> pool3_mask
I0824 20:49:47.625610 43675 net.cpp:150] Setting up pool3
I0824 20:49:47.625618 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:47.625625 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:47.625628 43675 net.cpp:165] Memory required for data: 2839449600
I0824 20:49:47.625633 43675 layer_factory.hpp:77] Creating layer conv4_1
I0824 20:49:47.625643 43675 net.cpp:100] Creating Layer conv4_1
I0824 20:49:47.625649 43675 net.cpp:434] conv4_1 <- pool3
I0824 20:49:47.625659 43675 net.cpp:408] conv4_1 -> conv4_1
I0824 20:49:47.669548 43675 net.cpp:150] Setting up conv4_1
I0824 20:49:47.669565 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.669574 43675 net.cpp:165] Memory required for data: 2861568000
I0824 20:49:47.669582 43675 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 20:49:47.669590 43675 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 20:49:47.669596 43675 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 20:49:47.669605 43675 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 20:49:47.669888 43675 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 20:49:47.669896 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.669905 43675 net.cpp:165] Memory required for data: 2883686400
I0824 20:49:47.669914 43675 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 20:49:47.669924 43675 net.cpp:100] Creating Layer conv4_1_scale
I0824 20:49:47.669929 43675 net.cpp:434] conv4_1_scale <- conv4_1
I0824 20:49:47.669934 43675 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 20:49:47.669986 43675 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 20:49:47.670150 43675 net.cpp:150] Setting up conv4_1_scale
I0824 20:49:47.670158 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.670163 43675 net.cpp:165] Memory required for data: 2905804800
I0824 20:49:47.670171 43675 layer_factory.hpp:77] Creating layer relu4_1
I0824 20:49:47.670177 43675 net.cpp:100] Creating Layer relu4_1
I0824 20:49:47.670182 43675 net.cpp:434] relu4_1 <- conv4_1
I0824 20:49:47.670189 43675 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 20:49:47.671321 43675 net.cpp:150] Setting up relu4_1
I0824 20:49:47.671336 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.671341 43675 net.cpp:165] Memory required for data: 2927923200
I0824 20:49:47.671345 43675 layer_factory.hpp:77] Creating layer conv4_2
I0824 20:49:47.671358 43675 net.cpp:100] Creating Layer conv4_2
I0824 20:49:47.671365 43675 net.cpp:434] conv4_2 <- conv4_1
I0824 20:49:47.671375 43675 net.cpp:408] conv4_2 -> conv4_2
I0824 20:49:47.754060 43675 net.cpp:150] Setting up conv4_2
I0824 20:49:47.754092 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.754097 43675 net.cpp:165] Memory required for data: 2950041600
I0824 20:49:47.754106 43675 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 20:49:47.754120 43675 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 20:49:47.754127 43675 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 20:49:47.754133 43675 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 20:49:47.754405 43675 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 20:49:47.754415 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.754423 43675 net.cpp:165] Memory required for data: 2972160000
I0824 20:49:47.754431 43675 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 20:49:47.754441 43675 net.cpp:100] Creating Layer conv4_2_scale
I0824 20:49:47.754451 43675 net.cpp:434] conv4_2_scale <- conv4_2
I0824 20:49:47.754457 43675 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 20:49:47.754505 43675 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 20:49:47.754668 43675 net.cpp:150] Setting up conv4_2_scale
I0824 20:49:47.754679 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.754684 43675 net.cpp:165] Memory required for data: 2994278400
I0824 20:49:47.754691 43675 layer_factory.hpp:77] Creating layer relu4_2
I0824 20:49:47.754699 43675 net.cpp:100] Creating Layer relu4_2
I0824 20:49:47.754703 43675 net.cpp:434] relu4_2 <- conv4_2
I0824 20:49:47.754709 43675 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 20:49:47.755859 43675 net.cpp:150] Setting up relu4_2
I0824 20:49:47.755874 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.755879 43675 net.cpp:165] Memory required for data: 3016396800
I0824 20:49:47.755884 43675 layer_factory.hpp:77] Creating layer conv4_3
I0824 20:49:47.755899 43675 net.cpp:100] Creating Layer conv4_3
I0824 20:49:47.755905 43675 net.cpp:434] conv4_3 <- conv4_2
I0824 20:49:47.755913 43675 net.cpp:408] conv4_3 -> conv4_3
I0824 20:49:47.839640 43675 net.cpp:150] Setting up conv4_3
I0824 20:49:47.839660 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.839668 43675 net.cpp:165] Memory required for data: 3038515200
I0824 20:49:47.839691 43675 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 20:49:47.839701 43675 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 20:49:47.839709 43675 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 20:49:47.839715 43675 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 20:49:47.839993 43675 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 20:49:47.840003 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.840010 43675 net.cpp:165] Memory required for data: 3060633600
I0824 20:49:47.840019 43675 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 20:49:47.840028 43675 net.cpp:100] Creating Layer conv4_3_scale
I0824 20:49:47.840032 43675 net.cpp:434] conv4_3_scale <- conv4_3
I0824 20:49:47.840037 43675 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 20:49:47.840090 43675 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 20:49:47.840257 43675 net.cpp:150] Setting up conv4_3_scale
I0824 20:49:47.840266 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.840270 43675 net.cpp:165] Memory required for data: 3082752000
I0824 20:49:47.840276 43675 layer_factory.hpp:77] Creating layer relu4_3
I0824 20:49:47.840286 43675 net.cpp:100] Creating Layer relu4_3
I0824 20:49:47.840291 43675 net.cpp:434] relu4_3 <- conv4_3
I0824 20:49:47.840297 43675 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 20:49:47.840510 43675 net.cpp:150] Setting up relu4_3
I0824 20:49:47.840520 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:47.840525 43675 net.cpp:165] Memory required for data: 3104870400
I0824 20:49:47.840529 43675 layer_factory.hpp:77] Creating layer pool4
I0824 20:49:47.840533 43675 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 20:49:47.840541 43675 net.cpp:100] Creating Layer pool4
I0824 20:49:47.840548 43675 net.cpp:434] pool4 <- conv4_3
I0824 20:49:47.840571 43675 net.cpp:408] pool4 -> pool4
I0824 20:49:47.840581 43675 net.cpp:408] pool4 -> pool4_mask
I0824 20:49:47.840639 43675 net.cpp:150] Setting up pool4
I0824 20:49:47.840651 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.840656 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.840661 43675 net.cpp:165] Memory required for data: 3116175360
I0824 20:49:47.840663 43675 layer_factory.hpp:77] Creating layer conv5_1
I0824 20:49:47.840677 43675 net.cpp:100] Creating Layer conv5_1
I0824 20:49:47.840683 43675 net.cpp:434] conv5_1 <- pool4
I0824 20:49:47.840689 43675 net.cpp:408] conv5_1 -> conv5_1
I0824 20:49:47.924327 43675 net.cpp:150] Setting up conv5_1
I0824 20:49:47.924345 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.924350 43675 net.cpp:165] Memory required for data: 3121827840
I0824 20:49:47.924357 43675 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 20:49:47.924376 43675 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 20:49:47.924382 43675 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 20:49:47.924396 43675 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 20:49:47.924671 43675 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 20:49:47.924680 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.924690 43675 net.cpp:165] Memory required for data: 3127480320
I0824 20:49:47.924698 43675 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 20:49:47.924708 43675 net.cpp:100] Creating Layer conv5_1_scale
I0824 20:49:47.924713 43675 net.cpp:434] conv5_1_scale <- conv5_1
I0824 20:49:47.924721 43675 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 20:49:47.924777 43675 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 20:49:47.924928 43675 net.cpp:150] Setting up conv5_1_scale
I0824 20:49:47.924937 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.924942 43675 net.cpp:165] Memory required for data: 3133132800
I0824 20:49:47.924948 43675 layer_factory.hpp:77] Creating layer relu5_1
I0824 20:49:47.924957 43675 net.cpp:100] Creating Layer relu5_1
I0824 20:49:47.924960 43675 net.cpp:434] relu5_1 <- conv5_1
I0824 20:49:47.924967 43675 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 20:49:47.925184 43675 net.cpp:150] Setting up relu5_1
I0824 20:49:47.925194 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:47.925199 43675 net.cpp:165] Memory required for data: 3138785280
I0824 20:49:47.925204 43675 layer_factory.hpp:77] Creating layer conv5_2
I0824 20:49:47.925215 43675 net.cpp:100] Creating Layer conv5_2
I0824 20:49:47.925221 43675 net.cpp:434] conv5_2 <- conv5_1
I0824 20:49:47.925230 43675 net.cpp:408] conv5_2 -> conv5_2
I0824 20:49:48.008779 43675 net.cpp:150] Setting up conv5_2
I0824 20:49:48.008795 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.008800 43675 net.cpp:165] Memory required for data: 3144437760
I0824 20:49:48.008808 43675 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 20:49:48.008822 43675 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 20:49:48.008829 43675 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 20:49:48.008836 43675 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 20:49:48.009104 43675 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 20:49:48.009114 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.009117 43675 net.cpp:165] Memory required for data: 3150090240
I0824 20:49:48.009125 43675 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 20:49:48.009140 43675 net.cpp:100] Creating Layer conv5_2_scale
I0824 20:49:48.009146 43675 net.cpp:434] conv5_2_scale <- conv5_2
I0824 20:49:48.009152 43675 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 20:49:48.009208 43675 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 20:49:48.009361 43675 net.cpp:150] Setting up conv5_2_scale
I0824 20:49:48.009377 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.009382 43675 net.cpp:165] Memory required for data: 3155742720
I0824 20:49:48.009388 43675 layer_factory.hpp:77] Creating layer relu5_2
I0824 20:49:48.009414 43675 net.cpp:100] Creating Layer relu5_2
I0824 20:49:48.009421 43675 net.cpp:434] relu5_2 <- conv5_2
I0824 20:49:48.009426 43675 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 20:49:48.009642 43675 net.cpp:150] Setting up relu5_2
I0824 20:49:48.009652 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.009657 43675 net.cpp:165] Memory required for data: 3161395200
I0824 20:49:48.009661 43675 layer_factory.hpp:77] Creating layer conv5_3
I0824 20:49:48.009676 43675 net.cpp:100] Creating Layer conv5_3
I0824 20:49:48.009682 43675 net.cpp:434] conv5_3 <- conv5_2
I0824 20:49:48.009690 43675 net.cpp:408] conv5_3 -> conv5_3
I0824 20:49:48.093194 43675 net.cpp:150] Setting up conv5_3
I0824 20:49:48.093211 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.093221 43675 net.cpp:165] Memory required for data: 3167047680
I0824 20:49:48.093230 43675 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 20:49:48.093240 43675 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 20:49:48.093246 43675 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 20:49:48.093253 43675 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 20:49:48.093534 43675 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 20:49:48.093544 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.093549 43675 net.cpp:165] Memory required for data: 3172700160
I0824 20:49:48.093557 43675 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 20:49:48.093564 43675 net.cpp:100] Creating Layer conv5_3_scale
I0824 20:49:48.093571 43675 net.cpp:434] conv5_3_scale <- conv5_3
I0824 20:49:48.093576 43675 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 20:49:48.093641 43675 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 20:49:48.093796 43675 net.cpp:150] Setting up conv5_3_scale
I0824 20:49:48.093804 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.093808 43675 net.cpp:165] Memory required for data: 3178352640
I0824 20:49:48.093814 43675 layer_factory.hpp:77] Creating layer relu5_3
I0824 20:49:48.093824 43675 net.cpp:100] Creating Layer relu5_3
I0824 20:49:48.093830 43675 net.cpp:434] relu5_3 <- conv5_3
I0824 20:49:48.093835 43675 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 20:49:48.094053 43675 net.cpp:150] Setting up relu5_3
I0824 20:49:48.094065 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.094070 43675 net.cpp:165] Memory required for data: 3184005120
I0824 20:49:48.094074 43675 layer_factory.hpp:77] Creating layer pool5
I0824 20:49:48.094079 43675 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 20:49:48.094086 43675 net.cpp:100] Creating Layer pool5
I0824 20:49:48.094091 43675 net.cpp:434] pool5 <- conv5_3
I0824 20:49:48.094099 43675 net.cpp:408] pool5 -> pool5
I0824 20:49:48.094108 43675 net.cpp:408] pool5 -> pool5_mask
I0824 20:49:48.094168 43675 net.cpp:150] Setting up pool5
I0824 20:49:48.094178 43675 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 20:49:48.094185 43675 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 20:49:48.094188 43675 net.cpp:165] Memory required for data: 3186954240
I0824 20:49:48.094192 43675 layer_factory.hpp:77] Creating layer upsample5
I0824 20:49:48.094199 43675 net.cpp:100] Creating Layer upsample5
I0824 20:49:48.094204 43675 net.cpp:434] upsample5 <- pool5
I0824 20:49:48.094209 43675 net.cpp:434] upsample5 <- pool5_mask
I0824 20:49:48.094215 43675 net.cpp:408] upsample5 -> pool5_D
I0824 20:49:48.094250 43675 net.cpp:150] Setting up upsample5
I0824 20:49:48.094259 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.094262 43675 net.cpp:165] Memory required for data: 3192606720
I0824 20:49:48.094265 43675 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 20:49:48.094279 43675 net.cpp:100] Creating Layer conv5_3_D
I0824 20:49:48.094285 43675 net.cpp:434] conv5_3_D <- pool5_D
I0824 20:49:48.094293 43675 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 20:49:48.178459 43675 net.cpp:150] Setting up conv5_3_D
I0824 20:49:48.178481 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.178503 43675 net.cpp:165] Memory required for data: 3198259200
I0824 20:49:48.178524 43675 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 20:49:48.178536 43675 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 20:49:48.178547 43675 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 20:49:48.178556 43675 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 20:49:48.178836 43675 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 20:49:48.178845 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.178850 43675 net.cpp:165] Memory required for data: 3203911680
I0824 20:49:48.178859 43675 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 20:49:48.178867 43675 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 20:49:48.178872 43675 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 20:49:48.178882 43675 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 20:49:48.178939 43675 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 20:49:48.179096 43675 net.cpp:150] Setting up conv5_3_D_scale
I0824 20:49:48.179105 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.179108 43675 net.cpp:165] Memory required for data: 3209564160
I0824 20:49:48.179116 43675 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 20:49:48.179122 43675 net.cpp:100] Creating Layer relu5_3_D
I0824 20:49:48.179127 43675 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 20:49:48.179132 43675 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 20:49:48.180279 43675 net.cpp:150] Setting up relu5_3_D
I0824 20:49:48.180296 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.180302 43675 net.cpp:165] Memory required for data: 3215216640
I0824 20:49:48.180307 43675 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 20:49:48.180354 43675 net.cpp:100] Creating Layer conv5_2_D
I0824 20:49:48.180362 43675 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 20:49:48.180369 43675 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 20:49:48.263886 43675 net.cpp:150] Setting up conv5_2_D
I0824 20:49:48.263902 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.263907 43675 net.cpp:165] Memory required for data: 3220869120
I0824 20:49:48.263916 43675 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 20:49:48.263932 43675 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 20:49:48.263939 43675 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 20:49:48.263948 43675 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 20:49:48.264230 43675 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 20:49:48.264240 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.264250 43675 net.cpp:165] Memory required for data: 3226521600
I0824 20:49:48.264258 43675 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 20:49:48.264271 43675 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 20:49:48.264276 43675 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 20:49:48.264281 43675 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 20:49:48.264341 43675 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 20:49:48.264500 43675 net.cpp:150] Setting up conv5_2_D_scale
I0824 20:49:48.264509 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.264514 43675 net.cpp:165] Memory required for data: 3232174080
I0824 20:49:48.264521 43675 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 20:49:48.264528 43675 net.cpp:100] Creating Layer relu5_2_D
I0824 20:49:48.264533 43675 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 20:49:48.264542 43675 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 20:49:48.265697 43675 net.cpp:150] Setting up relu5_2_D
I0824 20:49:48.265712 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.265717 43675 net.cpp:165] Memory required for data: 3237826560
I0824 20:49:48.265720 43675 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 20:49:48.265736 43675 net.cpp:100] Creating Layer conv5_1_D
I0824 20:49:48.265743 43675 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 20:49:48.265753 43675 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 20:49:48.349300 43675 net.cpp:150] Setting up conv5_1_D
I0824 20:49:48.349318 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.349329 43675 net.cpp:165] Memory required for data: 3243479040
I0824 20:49:48.349337 43675 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 20:49:48.349347 43675 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 20:49:48.349354 43675 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 20:49:48.349360 43675 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 20:49:48.349642 43675 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 20:49:48.349653 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.349656 43675 net.cpp:165] Memory required for data: 3249131520
I0824 20:49:48.349665 43675 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 20:49:48.349673 43675 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 20:49:48.349681 43675 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 20:49:48.349689 43675 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 20:49:48.349750 43675 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 20:49:48.349906 43675 net.cpp:150] Setting up conv5_1_D_scale
I0824 20:49:48.349917 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.349923 43675 net.cpp:165] Memory required for data: 3254784000
I0824 20:49:48.349930 43675 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 20:49:48.349937 43675 net.cpp:100] Creating Layer relu5_1_D
I0824 20:49:48.349942 43675 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 20:49:48.349948 43675 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 20:49:48.350172 43675 net.cpp:150] Setting up relu5_1_D
I0824 20:49:48.350183 43675 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 20:49:48.350188 43675 net.cpp:165] Memory required for data: 3260436480
I0824 20:49:48.350190 43675 layer_factory.hpp:77] Creating layer upsample4
I0824 20:49:48.350198 43675 net.cpp:100] Creating Layer upsample4
I0824 20:49:48.350203 43675 net.cpp:434] upsample4 <- conv5_1_D
I0824 20:49:48.350211 43675 net.cpp:434] upsample4 <- pool4_mask
I0824 20:49:48.350219 43675 net.cpp:408] upsample4 -> pool4_D
I0824 20:49:48.350260 43675 net.cpp:150] Setting up upsample4
I0824 20:49:48.350267 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:48.350271 43675 net.cpp:165] Memory required for data: 3282554880
I0824 20:49:48.350275 43675 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 20:49:48.350287 43675 net.cpp:100] Creating Layer conv4_3_D
I0824 20:49:48.350293 43675 net.cpp:434] conv4_3_D <- pool4_D
I0824 20:49:48.350304 43675 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 20:49:48.433845 43675 net.cpp:150] Setting up conv4_3_D
I0824 20:49:48.433863 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:48.433873 43675 net.cpp:165] Memory required for data: 3304673280
I0824 20:49:48.433881 43675 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 20:49:48.433892 43675 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 20:49:48.433898 43675 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 20:49:48.433904 43675 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 20:49:48.434190 43675 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 20:49:48.434200 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:48.434209 43675 net.cpp:165] Memory required for data: 3326791680
I0824 20:49:48.434219 43675 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 20:49:48.434228 43675 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 20:49:48.434237 43675 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 20:49:48.434242 43675 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 20:49:48.434295 43675 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 20:49:48.434468 43675 net.cpp:150] Setting up conv4_3_D_scale
I0824 20:49:48.434476 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:48.434481 43675 net.cpp:165] Memory required for data: 3348910080
I0824 20:49:48.434489 43675 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 20:49:48.434516 43675 net.cpp:100] Creating Layer relu4_3_D
I0824 20:49:48.434522 43675 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 20:49:48.434528 43675 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 20:49:48.434746 43675 net.cpp:150] Setting up relu4_3_D
I0824 20:49:48.434756 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:48.434762 43675 net.cpp:165] Memory required for data: 3371028480
I0824 20:49:48.434765 43675 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 20:49:48.434779 43675 net.cpp:100] Creating Layer conv4_2_D
I0824 20:49:48.434785 43675 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 20:49:48.434792 43675 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 20:49:48.518337 43675 net.cpp:150] Setting up conv4_2_D
I0824 20:49:48.518357 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:48.518365 43675 net.cpp:165] Memory required for data: 3393146880
I0824 20:49:48.518373 43675 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 20:49:48.518381 43675 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 20:49:48.518386 43675 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 20:49:48.518393 43675 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 20:49:48.518683 43675 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 20:49:48.518692 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:48.518702 43675 net.cpp:165] Memory required for data: 3415265280
I0824 20:49:48.518710 43675 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 20:49:48.518721 43675 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 20:49:48.518730 43675 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 20:49:48.518736 43675 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 20:49:48.518798 43675 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 20:49:48.518975 43675 net.cpp:150] Setting up conv4_2_D_scale
I0824 20:49:48.518985 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:48.518990 43675 net.cpp:165] Memory required for data: 3437383680
I0824 20:49:48.518996 43675 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 20:49:48.519003 43675 net.cpp:100] Creating Layer relu4_2_D
I0824 20:49:48.519008 43675 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 20:49:48.519016 43675 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 20:49:48.519234 43675 net.cpp:150] Setting up relu4_2_D
I0824 20:49:48.519244 43675 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 20:49:48.519249 43675 net.cpp:165] Memory required for data: 3459502080
I0824 20:49:48.519253 43675 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 20:49:48.519266 43675 net.cpp:100] Creating Layer conv4_1_D
I0824 20:49:48.519273 43675 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 20:49:48.519281 43675 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 20:49:48.563172 43675 net.cpp:150] Setting up conv4_1_D
I0824 20:49:48.563189 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:48.563199 43675 net.cpp:165] Memory required for data: 3470561280
I0824 20:49:48.563210 43675 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 20:49:48.563223 43675 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 20:49:48.563232 43675 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 20:49:48.563238 43675 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 20:49:48.563534 43675 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 20:49:48.563544 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:48.563554 43675 net.cpp:165] Memory required for data: 3481620480
I0824 20:49:48.563609 43675 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 20:49:48.563618 43675 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 20:49:48.563624 43675 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 20:49:48.563630 43675 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 20:49:48.563693 43675 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 20:49:48.563863 43675 net.cpp:150] Setting up conv4_1_D_scale
I0824 20:49:48.563872 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:48.563894 43675 net.cpp:165] Memory required for data: 3492679680
I0824 20:49:48.563901 43675 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 20:49:48.563907 43675 net.cpp:100] Creating Layer relu4_1_D
I0824 20:49:48.563912 43675 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 20:49:48.563922 43675 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 20:49:48.564154 43675 net.cpp:150] Setting up relu4_1_D
I0824 20:49:48.564165 43675 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 20:49:48.564169 43675 net.cpp:165] Memory required for data: 3503738880
I0824 20:49:48.564173 43675 layer_factory.hpp:77] Creating layer upsample3
I0824 20:49:48.564182 43675 net.cpp:100] Creating Layer upsample3
I0824 20:49:48.564187 43675 net.cpp:434] upsample3 <- conv4_1_D
I0824 20:49:48.564194 43675 net.cpp:434] upsample3 <- pool3_mask
I0824 20:49:48.564203 43675 net.cpp:408] upsample3 -> pool3_D
I0824 20:49:48.564211 43675 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 20:49:48.564251 43675 net.cpp:150] Setting up upsample3
I0824 20:49:48.564260 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:48.564263 43675 net.cpp:165] Memory required for data: 3547975680
I0824 20:49:48.564268 43675 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 20:49:48.564280 43675 net.cpp:100] Creating Layer conv3_3_D
I0824 20:49:48.564286 43675 net.cpp:434] conv3_3_D <- pool3_D
I0824 20:49:48.564296 43675 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 20:49:48.587947 43675 net.cpp:150] Setting up conv3_3_D
I0824 20:49:48.587965 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:48.587975 43675 net.cpp:165] Memory required for data: 3592212480
I0824 20:49:48.587982 43675 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 20:49:48.587992 43675 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 20:49:48.587998 43675 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 20:49:48.588006 43675 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 20:49:48.588315 43675 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 20:49:48.588323 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:48.588333 43675 net.cpp:165] Memory required for data: 3636449280
I0824 20:49:48.588342 43675 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 20:49:48.588352 43675 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 20:49:48.588357 43675 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 20:49:48.588363 43675 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 20:49:48.588420 43675 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 20:49:48.588611 43675 net.cpp:150] Setting up conv3_3_D_scale
I0824 20:49:48.588620 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:48.588625 43675 net.cpp:165] Memory required for data: 3680686080
I0824 20:49:48.588631 43675 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 20:49:48.588641 43675 net.cpp:100] Creating Layer relu3_3_D
I0824 20:49:48.588646 43675 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 20:49:48.588651 43675 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 20:49:48.589823 43675 net.cpp:150] Setting up relu3_3_D
I0824 20:49:48.589839 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:48.589844 43675 net.cpp:165] Memory required for data: 3724922880
I0824 20:49:48.589849 43675 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 20:49:48.589862 43675 net.cpp:100] Creating Layer conv3_2_D
I0824 20:49:48.589869 43675 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 20:49:48.589879 43675 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 20:49:48.612596 43675 net.cpp:150] Setting up conv3_2_D
I0824 20:49:48.612612 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:48.612622 43675 net.cpp:165] Memory required for data: 3769159680
I0824 20:49:48.612630 43675 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 20:49:48.612648 43675 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 20:49:48.612653 43675 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 20:49:48.612675 43675 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 20:49:48.612985 43675 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 20:49:48.612995 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:48.613000 43675 net.cpp:165] Memory required for data: 3813396480
I0824 20:49:48.613011 43675 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 20:49:48.613021 43675 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 20:49:48.613026 43675 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 20:49:48.613031 43675 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 20:49:48.613090 43675 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 20:49:48.613281 43675 net.cpp:150] Setting up conv3_2_D_scale
I0824 20:49:48.613291 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:48.613296 43675 net.cpp:165] Memory required for data: 3857633280
I0824 20:49:48.613301 43675 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 20:49:48.613312 43675 net.cpp:100] Creating Layer relu3_2_D
I0824 20:49:48.613317 43675 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 20:49:48.613322 43675 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 20:49:48.614485 43675 net.cpp:150] Setting up relu3_2_D
I0824 20:49:48.614500 43675 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 20:49:48.614504 43675 net.cpp:165] Memory required for data: 3901870080
I0824 20:49:48.614509 43675 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 20:49:48.614523 43675 net.cpp:100] Creating Layer conv3_1_D
I0824 20:49:48.614531 43675 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 20:49:48.614539 43675 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 20:49:48.628412 43675 net.cpp:150] Setting up conv3_1_D
I0824 20:49:48.628428 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:48.628437 43675 net.cpp:165] Memory required for data: 3923988480
I0824 20:49:48.628445 43675 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 20:49:48.628459 43675 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 20:49:48.628468 43675 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 20:49:48.628476 43675 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 20:49:48.628784 43675 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 20:49:48.628794 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:48.628803 43675 net.cpp:165] Memory required for data: 3946106880
I0824 20:49:48.628813 43675 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 20:49:48.628821 43675 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 20:49:48.628826 43675 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 20:49:48.628832 43675 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 20:49:48.628890 43675 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 20:49:48.630342 43675 net.cpp:150] Setting up conv3_1_D_scale
I0824 20:49:48.630357 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:48.630367 43675 net.cpp:165] Memory required for data: 3968225280
I0824 20:49:48.630374 43675 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 20:49:48.630384 43675 net.cpp:100] Creating Layer relu3_1_D
I0824 20:49:48.630390 43675 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 20:49:48.630396 43675 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 20:49:48.630637 43675 net.cpp:150] Setting up relu3_1_D
I0824 20:49:48.630647 43675 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 20:49:48.630652 43675 net.cpp:165] Memory required for data: 3990343680
I0824 20:49:48.630656 43675 layer_factory.hpp:77] Creating layer upsample2
I0824 20:49:48.630663 43675 net.cpp:100] Creating Layer upsample2
I0824 20:49:48.630668 43675 net.cpp:434] upsample2 <- conv3_1_D
I0824 20:49:48.630674 43675 net.cpp:434] upsample2 <- pool2_mask
I0824 20:49:48.630683 43675 net.cpp:408] upsample2 -> pool2_D
I0824 20:49:48.630693 43675 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 20:49:48.630731 43675 net.cpp:150] Setting up upsample2
I0824 20:49:48.630756 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:48.630761 43675 net.cpp:165] Memory required for data: 4078817280
I0824 20:49:48.630765 43675 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 20:49:48.630777 43675 net.cpp:100] Creating Layer conv2_2_D
I0824 20:49:48.630784 43675 net.cpp:434] conv2_2_D <- pool2_D
I0824 20:49:48.630790 43675 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 20:49:48.638660 43675 net.cpp:150] Setting up conv2_2_D
I0824 20:49:48.638677 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:48.638685 43675 net.cpp:165] Memory required for data: 4167290880
I0824 20:49:48.638694 43675 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 20:49:48.638705 43675 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 20:49:48.638712 43675 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 20:49:48.638721 43675 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 20:49:48.639060 43675 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 20:49:48.639070 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:48.639075 43675 net.cpp:165] Memory required for data: 4255764480
I0824 20:49:48.639083 43675 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 20:49:48.639092 43675 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 20:49:48.639101 43675 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 20:49:48.639109 43675 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 20:49:48.639168 43675 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 20:49:48.639425 43675 net.cpp:150] Setting up conv2_2_D_scale
I0824 20:49:48.639436 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:48.639441 43675 net.cpp:165] Memory required for data: 4344238080
I0824 20:49:48.639447 43675 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 20:49:48.639454 43675 net.cpp:100] Creating Layer relu2_2_D
I0824 20:49:48.639459 43675 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 20:49:48.639464 43675 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 20:49:48.639700 43675 net.cpp:150] Setting up relu2_2_D
I0824 20:49:48.639710 43675 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 20:49:48.639715 43675 net.cpp:165] Memory required for data: 4432711680
I0824 20:49:48.639719 43675 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 20:49:48.639731 43675 net.cpp:100] Creating Layer conv2_1_D
I0824 20:49:48.639739 43675 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 20:49:48.639747 43675 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 20:49:48.645192 43675 net.cpp:150] Setting up conv2_1_D
I0824 20:49:48.645208 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:48.645216 43675 net.cpp:165] Memory required for data: 4476948480
I0824 20:49:48.645227 43675 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 20:49:48.645239 43675 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 20:49:48.645247 43675 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 20:49:48.645253 43675 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 20:49:48.645618 43675 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 20:49:48.645628 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:48.645632 43675 net.cpp:165] Memory required for data: 4521185280
I0824 20:49:48.645643 43675 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 20:49:48.645653 43675 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 20:49:48.645658 43675 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 20:49:48.645664 43675 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 20:49:48.645726 43675 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 20:49:48.645994 43675 net.cpp:150] Setting up conv2_1_D_scale
I0824 20:49:48.646004 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:48.646009 43675 net.cpp:165] Memory required for data: 4565422080
I0824 20:49:48.646016 43675 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 20:49:48.646023 43675 net.cpp:100] Creating Layer relu2_1_D
I0824 20:49:48.646028 43675 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 20:49:48.646049 43675 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 20:49:48.646287 43675 net.cpp:150] Setting up relu2_1_D
I0824 20:49:48.646297 43675 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 20:49:48.646303 43675 net.cpp:165] Memory required for data: 4609658880
I0824 20:49:48.646307 43675 layer_factory.hpp:77] Creating layer upsample1
I0824 20:49:48.646313 43675 net.cpp:100] Creating Layer upsample1
I0824 20:49:48.646318 43675 net.cpp:434] upsample1 <- conv2_1_D
I0824 20:49:48.646323 43675 net.cpp:434] upsample1 <- pool1_mask
I0824 20:49:48.646332 43675 net.cpp:408] upsample1 -> pool1_D
I0824 20:49:48.646340 43675 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 20:49:48.646378 43675 net.cpp:150] Setting up upsample1
I0824 20:49:48.646389 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:48.646394 43675 net.cpp:165] Memory required for data: 4786606080
I0824 20:49:48.646396 43675 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 20:49:48.646409 43675 net.cpp:100] Creating Layer conv1_2_D
I0824 20:49:48.646414 43675 net.cpp:434] conv1_2_D <- pool1_D
I0824 20:49:48.646421 43675 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 20:49:48.651074 43675 net.cpp:150] Setting up conv1_2_D
I0824 20:49:48.651091 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:48.651099 43675 net.cpp:165] Memory required for data: 4963553280
I0824 20:49:48.651108 43675 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 20:49:48.651120 43675 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 20:49:48.651127 43675 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 20:49:48.651134 43675 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 20:49:48.651571 43675 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 20:49:48.651579 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:48.651584 43675 net.cpp:165] Memory required for data: 5140500480
I0824 20:49:48.651595 43675 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 20:49:48.651604 43675 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 20:49:48.651609 43675 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 20:49:48.651614 43675 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 20:49:48.651676 43675 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 20:49:48.653391 43675 net.cpp:150] Setting up conv1_2_D_scale
I0824 20:49:48.653406 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:48.653412 43675 net.cpp:165] Memory required for data: 5317447680
I0824 20:49:48.653420 43675 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 20:49:48.653429 43675 net.cpp:100] Creating Layer relu1_2_D
I0824 20:49:48.653434 43675 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 20:49:48.653439 43675 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 20:49:48.653682 43675 net.cpp:150] Setting up relu1_2_D
I0824 20:49:48.653693 43675 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 20:49:48.653698 43675 net.cpp:165] Memory required for data: 5494394880
I0824 20:49:48.653702 43675 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 20:49:48.653714 43675 net.cpp:100] Creating Layer conv1_1_1_D
I0824 20:49:48.653722 43675 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 20:49:48.653729 43675 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 20:49:48.655913 43675 net.cpp:150] Setting up conv1_1_1_D
I0824 20:49:48.655930 43675 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 20:49:48.655935 43675 net.cpp:165] Memory required for data: 5499924480
I0824 20:49:48.655942 43675 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 20:49:48.655951 43675 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 20:49:48.655956 43675 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 20:49:48.655966 43675 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 20:49:48.655975 43675 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 20:49:48.656051 43675 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 20:49:48.656061 43675 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 20:49:48.656067 43675 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 20:49:48.656070 43675 net.cpp:165] Memory required for data: 5510983680
I0824 20:49:48.656075 43675 layer_factory.hpp:77] Creating layer loss
I0824 20:49:48.656088 43675 net.cpp:100] Creating Layer loss
I0824 20:49:48.656095 43675 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 20:49:48.656100 43675 net.cpp:434] loss <- label_data_1_split_0
I0824 20:49:48.656110 43675 net.cpp:408] loss -> loss
I0824 20:49:48.656121 43675 layer_factory.hpp:77] Creating layer loss
I0824 20:49:48.660146 43675 net.cpp:150] Setting up loss
I0824 20:49:48.660161 43675 net.cpp:157] Top shape: (1)
I0824 20:49:48.660171 43675 net.cpp:160]     with loss weight 1
I0824 20:49:48.660187 43675 net.cpp:165] Memory required for data: 5510983684
I0824 20:49:48.660192 43675 layer_factory.hpp:77] Creating layer accuracy
I0824 20:49:48.660199 43675 net.cpp:100] Creating Layer accuracy
I0824 20:49:48.660205 43675 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 20:49:48.660212 43675 net.cpp:434] accuracy <- label_data_1_split_1
I0824 20:49:48.660220 43675 net.cpp:408] accuracy -> accuracy
I0824 20:49:48.660229 43675 net.cpp:408] accuracy -> per_class_accuracy
I0824 20:49:48.660284 43675 net.cpp:150] Setting up accuracy
I0824 20:49:48.660291 43675 net.cpp:157] Top shape: (1)
I0824 20:49:48.660296 43675 net.cpp:157] Top shape: 2 (2)
I0824 20:49:48.660300 43675 net.cpp:165] Memory required for data: 5510983696
I0824 20:49:48.660305 43675 net.cpp:228] accuracy does not need backward computation.
I0824 20:49:48.660308 43675 net.cpp:226] loss needs backward computation.
I0824 20:49:48.660313 43675 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 20:49:48.660320 43675 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 20:49:48.660326 43675 net.cpp:226] relu1_2_D needs backward computation.
I0824 20:49:48.660329 43675 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 20:49:48.660332 43675 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 20:49:48.660336 43675 net.cpp:226] conv1_2_D needs backward computation.
I0824 20:49:48.660341 43675 net.cpp:226] upsample1 needs backward computation.
I0824 20:49:48.660346 43675 net.cpp:226] relu2_1_D needs backward computation.
I0824 20:49:48.660349 43675 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 20:49:48.660353 43675 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 20:49:48.660356 43675 net.cpp:226] conv2_1_D needs backward computation.
I0824 20:49:48.660360 43675 net.cpp:226] relu2_2_D needs backward computation.
I0824 20:49:48.660363 43675 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 20:49:48.660367 43675 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 20:49:48.660370 43675 net.cpp:226] conv2_2_D needs backward computation.
I0824 20:49:48.660374 43675 net.cpp:226] upsample2 needs backward computation.
I0824 20:49:48.660379 43675 net.cpp:226] relu3_1_D needs backward computation.
I0824 20:49:48.660383 43675 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 20:49:48.660387 43675 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 20:49:48.660390 43675 net.cpp:226] conv3_1_D needs backward computation.
I0824 20:49:48.660393 43675 net.cpp:226] relu3_2_D needs backward computation.
I0824 20:49:48.660398 43675 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 20:49:48.660400 43675 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 20:49:48.660403 43675 net.cpp:226] conv3_2_D needs backward computation.
I0824 20:49:48.660408 43675 net.cpp:226] relu3_3_D needs backward computation.
I0824 20:49:48.660411 43675 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 20:49:48.660416 43675 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 20:49:48.660434 43675 net.cpp:226] conv3_3_D needs backward computation.
I0824 20:49:48.660439 43675 net.cpp:226] upsample3 needs backward computation.
I0824 20:49:48.660444 43675 net.cpp:226] relu4_1_D needs backward computation.
I0824 20:49:48.660446 43675 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 20:49:48.660450 43675 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 20:49:48.660454 43675 net.cpp:226] conv4_1_D needs backward computation.
I0824 20:49:48.660457 43675 net.cpp:226] relu4_2_D needs backward computation.
I0824 20:49:48.660460 43675 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 20:49:48.660465 43675 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 20:49:48.660467 43675 net.cpp:226] conv4_2_D needs backward computation.
I0824 20:49:48.660471 43675 net.cpp:226] relu4_3_D needs backward computation.
I0824 20:49:48.660475 43675 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 20:49:48.660478 43675 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 20:49:48.660482 43675 net.cpp:226] conv4_3_D needs backward computation.
I0824 20:49:48.660486 43675 net.cpp:226] upsample4 needs backward computation.
I0824 20:49:48.660490 43675 net.cpp:226] relu5_1_D needs backward computation.
I0824 20:49:48.660495 43675 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 20:49:48.660500 43675 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 20:49:48.660503 43675 net.cpp:226] conv5_1_D needs backward computation.
I0824 20:49:48.660507 43675 net.cpp:226] relu5_2_D needs backward computation.
I0824 20:49:48.660511 43675 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 20:49:48.660514 43675 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 20:49:48.660519 43675 net.cpp:226] conv5_2_D needs backward computation.
I0824 20:49:48.660523 43675 net.cpp:226] relu5_3_D needs backward computation.
I0824 20:49:48.660527 43675 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 20:49:48.660531 43675 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 20:49:48.660534 43675 net.cpp:226] conv5_3_D needs backward computation.
I0824 20:49:48.660538 43675 net.cpp:226] upsample5 needs backward computation.
I0824 20:49:48.660542 43675 net.cpp:226] pool5 needs backward computation.
I0824 20:49:48.660549 43675 net.cpp:226] relu5_3 needs backward computation.
I0824 20:49:48.660553 43675 net.cpp:226] conv5_3_scale needs backward computation.
I0824 20:49:48.660557 43675 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 20:49:48.660563 43675 net.cpp:226] conv5_3 needs backward computation.
I0824 20:49:48.660568 43675 net.cpp:226] relu5_2 needs backward computation.
I0824 20:49:48.660573 43675 net.cpp:226] conv5_2_scale needs backward computation.
I0824 20:49:48.660576 43675 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 20:49:48.660579 43675 net.cpp:226] conv5_2 needs backward computation.
I0824 20:49:48.660583 43675 net.cpp:226] relu5_1 needs backward computation.
I0824 20:49:48.660588 43675 net.cpp:226] conv5_1_scale needs backward computation.
I0824 20:49:48.660591 43675 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 20:49:48.660596 43675 net.cpp:226] conv5_1 needs backward computation.
I0824 20:49:48.660601 43675 net.cpp:226] pool4 needs backward computation.
I0824 20:49:48.660605 43675 net.cpp:226] relu4_3 needs backward computation.
I0824 20:49:48.660609 43675 net.cpp:226] conv4_3_scale needs backward computation.
I0824 20:49:48.660612 43675 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 20:49:48.660619 43675 net.cpp:226] conv4_3 needs backward computation.
I0824 20:49:48.660622 43675 net.cpp:226] relu4_2 needs backward computation.
I0824 20:49:48.660627 43675 net.cpp:226] conv4_2_scale needs backward computation.
I0824 20:49:48.660630 43675 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 20:49:48.660634 43675 net.cpp:226] conv4_2 needs backward computation.
I0824 20:49:48.660639 43675 net.cpp:226] relu4_1 needs backward computation.
I0824 20:49:48.660651 43675 net.cpp:226] conv4_1_scale needs backward computation.
I0824 20:49:48.660656 43675 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 20:49:48.660660 43675 net.cpp:226] conv4_1 needs backward computation.
I0824 20:49:48.660663 43675 net.cpp:226] pool3 needs backward computation.
I0824 20:49:48.660670 43675 net.cpp:226] relu3_3 needs backward computation.
I0824 20:49:48.660672 43675 net.cpp:226] conv3_3_scale needs backward computation.
I0824 20:49:48.660676 43675 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 20:49:48.660679 43675 net.cpp:226] conv3_3 needs backward computation.
I0824 20:49:48.660683 43675 net.cpp:226] relu3_2 needs backward computation.
I0824 20:49:48.660689 43675 net.cpp:226] conv3_2_scale needs backward computation.
I0824 20:49:48.660693 43675 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 20:49:48.660696 43675 net.cpp:226] conv3_2 needs backward computation.
I0824 20:49:48.660701 43675 net.cpp:226] relu3_1 needs backward computation.
I0824 20:49:48.660704 43675 net.cpp:226] conv3_1_scale needs backward computation.
I0824 20:49:48.660707 43675 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 20:49:48.660712 43675 net.cpp:226] conv3_1 needs backward computation.
I0824 20:49:48.660718 43675 net.cpp:226] pool2 needs backward computation.
I0824 20:49:48.660722 43675 net.cpp:226] relu2_2 needs backward computation.
I0824 20:49:48.660725 43675 net.cpp:226] conv2_2_scale needs backward computation.
I0824 20:49:48.660730 43675 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 20:49:48.660734 43675 net.cpp:226] conv2_2 needs backward computation.
I0824 20:49:48.660739 43675 net.cpp:226] relu2_1 needs backward computation.
I0824 20:49:48.660742 43675 net.cpp:226] conv2_1_scale needs backward computation.
I0824 20:49:48.660748 43675 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 20:49:48.660751 43675 net.cpp:226] conv2_1 needs backward computation.
I0824 20:49:48.660755 43675 net.cpp:226] pool1 needs backward computation.
I0824 20:49:48.660759 43675 net.cpp:226] relu1_2 needs backward computation.
I0824 20:49:48.660763 43675 net.cpp:226] conv1_2_scale needs backward computation.
I0824 20:49:48.660768 43675 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 20:49:48.660773 43675 net.cpp:226] conv1_2 needs backward computation.
I0824 20:49:48.660776 43675 net.cpp:226] relu1_1 needs backward computation.
I0824 20:49:48.660781 43675 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 20:49:48.660785 43675 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 20:49:48.660789 43675 net.cpp:226] conv1_1_1 needs backward computation.
I0824 20:49:48.660794 43675 net.cpp:228] label_data_1_split does not need backward computation.
I0824 20:49:48.660799 43675 net.cpp:228] data does not need backward computation.
I0824 20:49:48.660804 43675 net.cpp:270] This network produces output accuracy
I0824 20:49:48.660807 43675 net.cpp:270] This network produces output loss
I0824 20:49:48.660811 43675 net.cpp:270] This network produces output per_class_accuracy
I0824 20:49:48.660876 43675 net.cpp:283] Network initialization done.
I0824 20:49:48.661237 43675 solver.cpp:60] Solver scaffolding done.
I0824 20:49:48.670444 43675 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0824 20:49:48.933580 43675 net.cpp:761] Ignoring source layer conv1_1
I0824 20:49:48.933607 43675 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 20:49:48.933658 43675 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 20:49:48.933665 43675 net.cpp:761] Ignoring source layer pool1_drop
I0824 20:49:48.933743 43675 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 20:49:48.933889 43675 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 20:49:48.933897 43675 net.cpp:761] Ignoring source layer pool2_drop
I0824 20:49:48.934170 43675 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 20:49:48.934732 43675 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 20:49:48.935276 43675 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 20:49:48.935313 43675 net.cpp:761] Ignoring source layer pool3_drop
I0824 20:49:48.936393 43675 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 20:49:48.938563 43675 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 20:49:48.940724 43675 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 20:49:48.940732 43675 net.cpp:761] Ignoring source layer pool4_drop
I0824 20:49:48.942914 43675 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 20:49:48.945077 43675 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 20:49:48.947259 43675 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 20:49:48.947268 43675 net.cpp:761] Ignoring source layer pool5_drop
I0824 20:49:48.947273 43675 net.cpp:761] Ignoring source layer upsample5_drop
I0824 20:49:48.949447 43675 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 20:49:48.951618 43675 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 20:49:48.953804 43675 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 20:49:48.953814 43675 net.cpp:761] Ignoring source layer upsample4_drop
I0824 20:49:48.955843 43675 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 20:49:48.957852 43675 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 20:49:48.958956 43675 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 20:49:48.958964 43675 net.cpp:761] Ignoring source layer upsample3_drop
I0824 20:49:48.959496 43675 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 20:49:48.960005 43675 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 20:49:48.960271 43675 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 20:49:48.960279 43675 net.cpp:761] Ignoring source layer upsample2_drop
I0824 20:49:48.960414 43675 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 20:49:48.960490 43675 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 20:49:48.960497 43675 net.cpp:761] Ignoring source layer upsample1_drop
I0824 20:49:48.960542 43675 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 20:49:48.960549 43675 net.cpp:761] Ignoring source layer conv1_1_D
I0824 20:49:48.960553 43675 net.cpp:761] Ignoring source layer prob
I0824 20:49:49.194615 43675 net.cpp:761] Ignoring source layer conv1_1
I0824 20:49:49.194644 43675 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 20:49:49.194691 43675 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 20:49:49.194697 43675 net.cpp:761] Ignoring source layer pool1_drop
I0824 20:49:49.194775 43675 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 20:49:49.194923 43675 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 20:49:49.194931 43675 net.cpp:761] Ignoring source layer pool2_drop
I0824 20:49:49.195204 43675 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 20:49:49.195763 43675 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 20:49:49.196297 43675 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 20:49:49.196305 43675 net.cpp:761] Ignoring source layer pool3_drop
I0824 20:49:49.197376 43675 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 20:49:49.199537 43675 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 20:49:49.201719 43675 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 20:49:49.201727 43675 net.cpp:761] Ignoring source layer pool4_drop
I0824 20:49:49.203896 43675 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 20:49:49.206081 43675 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 20:49:49.208256 43675 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 20:49:49.208264 43675 net.cpp:761] Ignoring source layer pool5_drop
I0824 20:49:49.208269 43675 net.cpp:761] Ignoring source layer upsample5_drop
I0824 20:49:49.210453 43675 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 20:49:49.212635 43675 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 20:49:49.214830 43675 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 20:49:49.214838 43675 net.cpp:761] Ignoring source layer upsample4_drop
I0824 20:49:49.217015 43675 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 20:49:49.219115 43675 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 20:49:49.220214 43675 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 20:49:49.220223 43675 net.cpp:761] Ignoring source layer upsample3_drop
I0824 20:49:49.220753 43675 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 20:49:49.221285 43675 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 20:49:49.221590 43675 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 20:49:49.221597 43675 net.cpp:761] Ignoring source layer upsample2_drop
I0824 20:49:49.221750 43675 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 20:49:49.221828 43675 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 20:49:49.221835 43675 net.cpp:761] Ignoring source layer upsample1_drop
I0824 20:49:49.221876 43675 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 20:49:49.221884 43675 net.cpp:761] Ignoring source layer conv1_1_D
I0824 20:49:49.221887 43675 net.cpp:761] Ignoring source layer prob
I0824 20:49:49.225028 43675 caffe.cpp:251] Starting Optimization
I0824 20:49:49.225049 43675 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0824 20:49:49.225055 43675 solver.cpp:280] Learning Rate Policy: step
I0824 20:49:50.342345 43675 solver.cpp:228] Iteration 0, loss = 1.15682
I0824 20:49:50.342386 43675 solver.cpp:244]     Train net output #0: accuracy = 0.4299
I0824 20:49:50.342399 43675 solver.cpp:244]     Train net output #1: loss = 1.15682 (* 1 = 1.15682 loss)
I0824 20:49:50.342411 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.472994
I0824 20:49:50.342422 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.296384
I0824 20:49:50.342444 43675 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0824 20:50:07.993340 43675 solver.cpp:228] Iteration 20, loss = 0.635023
I0824 20:50:07.993393 43675 solver.cpp:244]     Train net output #0: accuracy = 0.673216
I0824 20:50:07.993405 43675 solver.cpp:244]     Train net output #1: loss = 0.635023 (* 1 = 0.635023 loss)
I0824 20:50:07.993412 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.564758
I0824 20:50:07.993417 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.804789
I0824 20:50:07.993424 43675 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0824 20:50:24.584712 43675 solver.cpp:228] Iteration 40, loss = 0.524292
I0824 20:50:24.584854 43675 solver.cpp:244]     Train net output #0: accuracy = 0.763171
I0824 20:50:24.584868 43675 solver.cpp:244]     Train net output #1: loss = 0.524292 (* 1 = 0.524292 loss)
I0824 20:50:24.584879 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.740634
I0824 20:50:24.584885 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.795295
I0824 20:50:24.584892 43675 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0824 20:50:41.191596 43675 solver.cpp:228] Iteration 60, loss = 0.423678
I0824 20:50:41.191643 43675 solver.cpp:244]     Train net output #0: accuracy = 0.779614
I0824 20:50:41.191656 43675 solver.cpp:244]     Train net output #1: loss = 0.423678 (* 1 = 0.423678 loss)
I0824 20:50:41.191663 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.725918
I0824 20:50:41.191668 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.919249
I0824 20:50:41.191674 43675 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0824 20:50:57.796082 43675 solver.cpp:228] Iteration 80, loss = 0.448744
I0824 20:50:57.796237 43675 solver.cpp:244]     Train net output #0: accuracy = 0.759099
I0824 20:50:57.796257 43675 solver.cpp:244]     Train net output #1: loss = 0.448744 (* 1 = 0.448744 loss)
I0824 20:50:57.796267 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.718791
I0824 20:50:57.796277 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.868171
I0824 20:50:57.796284 43675 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0824 20:51:14.400240 43675 solver.cpp:228] Iteration 100, loss = 0.333234
I0824 20:51:14.400290 43675 solver.cpp:244]     Train net output #0: accuracy = 0.842607
I0824 20:51:14.400301 43675 solver.cpp:244]     Train net output #1: loss = 0.333234 (* 1 = 0.333234 loss)
I0824 20:51:14.400307 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.811912
I0824 20:51:14.400312 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.913071
I0824 20:51:14.400319 43675 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0824 20:51:31.010190 43675 solver.cpp:228] Iteration 120, loss = 0.304402
I0824 20:51:31.010337 43675 solver.cpp:244]     Train net output #0: accuracy = 0.890208
I0824 20:51:31.010359 43675 solver.cpp:244]     Train net output #1: loss = 0.304402 (* 1 = 0.304402 loss)
I0824 20:51:31.010365 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.894521
I0824 20:51:31.010371 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.884028
I0824 20:51:31.010378 43675 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0824 20:51:47.630359 43675 solver.cpp:228] Iteration 140, loss = 0.273813
I0824 20:51:47.630404 43675 solver.cpp:244]     Train net output #0: accuracy = 0.875255
I0824 20:51:47.630417 43675 solver.cpp:244]     Train net output #1: loss = 0.273813 (* 1 = 0.273813 loss)
I0824 20:51:47.630424 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.846686
I0824 20:51:47.630429 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.94294
I0824 20:51:47.630436 43675 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0824 20:52:04.223742 43675 solver.cpp:228] Iteration 160, loss = 0.34999
I0824 20:52:04.223855 43675 solver.cpp:244]     Train net output #0: accuracy = 0.780028
I0824 20:52:04.223870 43675 solver.cpp:244]     Train net output #1: loss = 0.34999 (* 1 = 0.34999 loss)
I0824 20:52:04.223875 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.751339
I0824 20:52:04.223879 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.915785
I0824 20:52:04.223887 43675 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0824 20:52:20.845974 43675 solver.cpp:228] Iteration 180, loss = 0.324079
I0824 20:52:20.846020 43675 solver.cpp:244]     Train net output #0: accuracy = 0.900185
I0824 20:52:20.846034 43675 solver.cpp:244]     Train net output #1: loss = 0.324079 (* 1 = 0.324079 loss)
I0824 20:52:20.846040 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.937862
I0824 20:52:20.846045 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.865211
I0824 20:52:20.846051 43675 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0824 20:52:37.452179 43675 solver.cpp:228] Iteration 200, loss = 0.271623
I0824 20:52:37.452291 43675 solver.cpp:244]     Train net output #0: accuracy = 0.832992
I0824 20:52:37.452303 43675 solver.cpp:244]     Train net output #1: loss = 0.271623 (* 1 = 0.271623 loss)
I0824 20:52:37.452309 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.790025
I0824 20:52:37.452314 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985029
I0824 20:52:37.452322 43675 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0824 20:52:54.062371 43675 solver.cpp:228] Iteration 220, loss = 0.193981
I0824 20:52:54.062415 43675 solver.cpp:244]     Train net output #0: accuracy = 0.893614
I0824 20:52:54.062428 43675 solver.cpp:244]     Train net output #1: loss = 0.193981 (* 1 = 0.193981 loss)
I0824 20:52:54.062434 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.840125
I0824 20:52:54.062439 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989549
I0824 20:52:54.062446 43675 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0824 20:53:10.659157 43675 solver.cpp:228] Iteration 240, loss = 0.185097
I0824 20:53:10.659260 43675 solver.cpp:244]     Train net output #0: accuracy = 0.897964
I0824 20:53:10.659273 43675 solver.cpp:244]     Train net output #1: loss = 0.185097 (* 1 = 0.185097 loss)
I0824 20:53:10.659279 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.864003
I0824 20:53:10.659284 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988657
I0824 20:53:10.659291 43675 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0824 20:53:27.274651 43675 solver.cpp:228] Iteration 260, loss = 0.127719
I0824 20:53:27.274693 43675 solver.cpp:244]     Train net output #0: accuracy = 0.94985
I0824 20:53:27.274705 43675 solver.cpp:244]     Train net output #1: loss = 0.127719 (* 1 = 0.127719 loss)
I0824 20:53:27.274711 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.94671
I0824 20:53:27.274716 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.954905
I0824 20:53:27.274724 43675 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0824 20:53:43.892887 43675 solver.cpp:228] Iteration 280, loss = 0.126861
I0824 20:53:43.893051 43675 solver.cpp:244]     Train net output #0: accuracy = 0.960142
I0824 20:53:43.893069 43675 solver.cpp:244]     Train net output #1: loss = 0.126861 (* 1 = 0.126861 loss)
I0824 20:53:43.893084 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.968691
I0824 20:53:43.893088 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.947301
I0824 20:53:43.893095 43675 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0824 20:54:00.502537 43675 solver.cpp:228] Iteration 300, loss = 0.434129
I0824 20:54:00.502578 43675 solver.cpp:244]     Train net output #0: accuracy = 0.869889
I0824 20:54:00.502589 43675 solver.cpp:244]     Train net output #1: loss = 0.434129 (* 1 = 0.434129 loss)
I0824 20:54:00.502596 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.960181
I0824 20:54:00.502602 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.741517
I0824 20:54:00.502609 43675 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0824 20:54:17.121099 43675 solver.cpp:228] Iteration 320, loss = 0.273034
I0824 20:54:17.121217 43675 solver.cpp:244]     Train net output #0: accuracy = 0.854417
I0824 20:54:17.121232 43675 solver.cpp:244]     Train net output #1: loss = 0.273034 (* 1 = 0.273034 loss)
I0824 20:54:17.121238 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.815045
I0824 20:54:17.121243 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987509
I0824 20:54:17.121249 43675 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0824 20:54:33.734985 43675 solver.cpp:228] Iteration 340, loss = 0.160795
I0824 20:54:33.735033 43675 solver.cpp:244]     Train net output #0: accuracy = 0.933179
I0824 20:54:33.735046 43675 solver.cpp:244]     Train net output #1: loss = 0.160795 (* 1 = 0.160795 loss)
I0824 20:54:33.735052 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.912074
I0824 20:54:33.735057 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.971505
I0824 20:54:33.735064 43675 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0824 20:54:50.328938 43675 solver.cpp:228] Iteration 360, loss = 0.07736
I0824 20:54:50.329057 43675 solver.cpp:244]     Train net output #0: accuracy = 0.978574
I0824 20:54:50.329073 43675 solver.cpp:244]     Train net output #1: loss = 0.07736 (* 1 = 0.07736 loss)
I0824 20:54:50.329084 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.976628
I0824 20:54:50.329090 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981896
I0824 20:54:50.329097 43675 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0824 20:55:06.942831 43675 solver.cpp:228] Iteration 380, loss = 0.102361
I0824 20:55:06.942873 43675 solver.cpp:244]     Train net output #0: accuracy = 0.96667
I0824 20:55:06.942886 43675 solver.cpp:244]     Train net output #1: loss = 0.102361 (* 1 = 0.102361 loss)
I0824 20:55:06.942893 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.960978
I0824 20:55:06.942898 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.975814
I0824 20:55:06.942904 43675 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0824 20:55:23.528586 43675 solver.cpp:228] Iteration 400, loss = 0.124258
I0824 20:55:23.528698 43675 solver.cpp:244]     Train net output #0: accuracy = 0.94931
I0824 20:55:23.528714 43675 solver.cpp:244]     Train net output #1: loss = 0.124258 (* 1 = 0.124258 loss)
I0824 20:55:23.528720 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.939427
I0824 20:55:23.528725 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.975628
I0824 20:55:23.528733 43675 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0824 20:55:40.128530 43675 solver.cpp:228] Iteration 420, loss = 0.0833638
I0824 20:55:40.128569 43675 solver.cpp:244]     Train net output #0: accuracy = 0.959138
I0824 20:55:40.128582 43675 solver.cpp:244]     Train net output #1: loss = 0.0833638 (* 1 = 0.0833638 loss)
I0824 20:55:40.128589 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.945858
I0824 20:55:40.128594 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999078
I0824 20:55:40.128602 43675 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0824 20:55:56.733932 43675 solver.cpp:228] Iteration 440, loss = 0.083349
I0824 20:55:56.734102 43675 solver.cpp:244]     Train net output #0: accuracy = 0.963514
I0824 20:55:56.734117 43675 solver.cpp:244]     Train net output #1: loss = 0.083349 (* 1 = 0.083349 loss)
I0824 20:55:56.734127 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.95314
I0824 20:55:56.734131 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985051
I0824 20:55:56.734138 43675 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0824 20:56:13.341976 43675 solver.cpp:228] Iteration 460, loss = 0.169852
I0824 20:56:13.342015 43675 solver.cpp:244]     Train net output #0: accuracy = 0.922378
I0824 20:56:13.342027 43675 solver.cpp:244]     Train net output #1: loss = 0.169852 (* 1 = 0.169852 loss)
I0824 20:56:13.342032 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.893416
I0824 20:56:13.342038 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.971368
I0824 20:56:13.342046 43675 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0824 20:56:29.947592 43675 solver.cpp:228] Iteration 480, loss = 0.15871
I0824 20:56:29.947692 43675 solver.cpp:244]     Train net output #0: accuracy = 0.919145
I0824 20:56:29.947708 43675 solver.cpp:244]     Train net output #1: loss = 0.15871 (* 1 = 0.15871 loss)
I0824 20:56:29.947718 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.895868
I0824 20:56:29.947723 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992677
I0824 20:56:29.947732 43675 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0824 20:56:46.549170 43675 solver.cpp:228] Iteration 500, loss = 0.0703191
I0824 20:56:46.549206 43675 solver.cpp:244]     Train net output #0: accuracy = 0.970952
I0824 20:56:46.549218 43675 solver.cpp:244]     Train net output #1: loss = 0.0703191 (* 1 = 0.0703191 loss)
I0824 20:56:46.549224 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.961754
I0824 20:56:46.549229 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989833
I0824 20:56:46.549237 43675 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0824 20:57:03.155345 43675 solver.cpp:228] Iteration 520, loss = 0.149439
I0824 20:57:03.155447 43675 solver.cpp:244]     Train net output #0: accuracy = 0.927811
I0824 20:57:03.155462 43675 solver.cpp:244]     Train net output #1: loss = 0.149439 (* 1 = 0.149439 loss)
I0824 20:57:03.155468 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.907762
I0824 20:57:03.155472 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980583
I0824 20:57:03.155480 43675 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0824 20:57:19.759675 43675 solver.cpp:228] Iteration 540, loss = 0.166059
I0824 20:57:19.759719 43675 solver.cpp:244]     Train net output #0: accuracy = 0.963317
I0824 20:57:19.759732 43675 solver.cpp:244]     Train net output #1: loss = 0.166059 (* 1 = 0.166059 loss)
I0824 20:57:19.759738 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.976561
I0824 20:57:19.759743 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.95244
I0824 20:57:19.759750 43675 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0824 20:57:36.371706 43675 solver.cpp:228] Iteration 560, loss = 0.069225
I0824 20:57:36.371870 43675 solver.cpp:244]     Train net output #0: accuracy = 0.973628
I0824 20:57:36.371886 43675 solver.cpp:244]     Train net output #1: loss = 0.069225 (* 1 = 0.069225 loss)
I0824 20:57:36.371892 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.960443
I0824 20:57:36.371897 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992401
I0824 20:57:36.371904 43675 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0824 20:57:52.968348 43675 solver.cpp:228] Iteration 580, loss = 0.0703895
I0824 20:57:52.968394 43675 solver.cpp:244]     Train net output #0: accuracy = 0.967428
I0824 20:57:52.968407 43675 solver.cpp:244]     Train net output #1: loss = 0.0703894 (* 1 = 0.0703894 loss)
I0824 20:57:52.968413 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.953928
I0824 20:57:52.968420 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991582
I0824 20:57:52.968426 43675 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0824 20:58:09.571498 43675 solver.cpp:228] Iteration 600, loss = 0.100088
I0824 20:58:09.571609 43675 solver.cpp:244]     Train net output #0: accuracy = 0.965654
I0824 20:58:09.571627 43675 solver.cpp:244]     Train net output #1: loss = 0.100088 (* 1 = 0.100088 loss)
I0824 20:58:09.571633 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.970695
I0824 20:58:09.571638 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.955415
I0824 20:58:09.571647 43675 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0824 20:58:26.185271 43675 solver.cpp:228] Iteration 620, loss = 0.0507784
I0824 20:58:26.185318 43675 solver.cpp:244]     Train net output #0: accuracy = 0.979796
I0824 20:58:26.185336 43675 solver.cpp:244]     Train net output #1: loss = 0.0507784 (* 1 = 0.0507784 loss)
I0824 20:58:26.185344 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978373
I0824 20:58:26.185350 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98363
I0824 20:58:26.185359 43675 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0824 20:58:42.824012 43675 solver.cpp:228] Iteration 640, loss = 0.0768066
I0824 20:58:42.824146 43675 solver.cpp:244]     Train net output #0: accuracy = 0.97742
I0824 20:58:42.824164 43675 solver.cpp:244]     Train net output #1: loss = 0.0768065 (* 1 = 0.0768065 loss)
I0824 20:58:42.824175 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97765
I0824 20:58:42.824187 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.977101
I0824 20:58:42.824196 43675 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0824 20:58:59.463243 43675 solver.cpp:228] Iteration 660, loss = 0.061067
I0824 20:58:59.463294 43675 solver.cpp:244]     Train net output #0: accuracy = 0.971351
I0824 20:58:59.463325 43675 solver.cpp:244]     Train net output #1: loss = 0.061067 (* 1 = 0.061067 loss)
I0824 20:58:59.463335 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.959953
I0824 20:58:59.463340 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993826
I0824 20:58:59.463348 43675 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0824 20:59:16.068343 43675 solver.cpp:228] Iteration 680, loss = 0.0883338
I0824 20:59:16.068500 43675 solver.cpp:244]     Train net output #0: accuracy = 0.960394
I0824 20:59:16.068541 43675 solver.cpp:244]     Train net output #1: loss = 0.0883338 (* 1 = 0.0883338 loss)
I0824 20:59:16.068549 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.952439
I0824 20:59:16.068559 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987838
I0824 20:59:16.068568 43675 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0824 20:59:32.759104 43675 solver.cpp:228] Iteration 700, loss = 0.0375845
I0824 20:59:32.759171 43675 solver.cpp:244]     Train net output #0: accuracy = 0.986534
I0824 20:59:32.759192 43675 solver.cpp:244]     Train net output #1: loss = 0.0375845 (* 1 = 0.0375845 loss)
I0824 20:59:32.759201 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98528
I0824 20:59:32.759207 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988814
I0824 20:59:32.759214 43675 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0824 20:59:49.445747 43675 solver.cpp:228] Iteration 720, loss = 0.0439113
I0824 20:59:49.445899 43675 solver.cpp:244]     Train net output #0: accuracy = 0.984939
I0824 20:59:49.445916 43675 solver.cpp:244]     Train net output #1: loss = 0.0439112 (* 1 = 0.0439112 loss)
I0824 20:59:49.445927 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986062
I0824 20:59:49.445932 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982721
I0824 20:59:49.445941 43675 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0824 21:00:06.139891 43675 solver.cpp:228] Iteration 740, loss = 0.0476378
I0824 21:00:06.139963 43675 solver.cpp:244]     Train net output #0: accuracy = 0.981302
I0824 21:00:06.139982 43675 solver.cpp:244]     Train net output #1: loss = 0.0476378 (* 1 = 0.0476378 loss)
I0824 21:00:06.139988 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9707
I0824 21:00:06.139994 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995334
I0824 21:00:06.140002 43675 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0824 21:00:22.803812 43675 solver.cpp:228] Iteration 760, loss = 0.0513036
I0824 21:00:22.803925 43675 solver.cpp:244]     Train net output #0: accuracy = 0.982309
I0824 21:00:22.803951 43675 solver.cpp:244]     Train net output #1: loss = 0.0513036 (* 1 = 0.0513036 loss)
I0824 21:00:22.803958 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975317
I0824 21:00:22.803964 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990898
I0824 21:00:22.803972 43675 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0824 21:00:39.478701 43675 solver.cpp:228] Iteration 780, loss = 0.106618
I0824 21:00:39.478770 43675 solver.cpp:244]     Train net output #0: accuracy = 0.966531
I0824 21:00:39.478790 43675 solver.cpp:244]     Train net output #1: loss = 0.106618 (* 1 = 0.106618 loss)
I0824 21:00:39.478798 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973757
I0824 21:00:39.478804 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.95861
I0824 21:00:39.478818 43675 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0824 21:00:56.125615 43675 solver.cpp:228] Iteration 800, loss = 0.0700511
I0824 21:00:56.125733 43675 solver.cpp:244]     Train net output #0: accuracy = 0.966377
I0824 21:00:56.125749 43675 solver.cpp:244]     Train net output #1: loss = 0.0700511 (* 1 = 0.0700511 loss)
I0824 21:00:56.125773 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.956378
I0824 21:00:56.125782 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986086
I0824 21:00:56.125789 43675 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0824 21:01:12.749768 43675 solver.cpp:228] Iteration 820, loss = 0.0522317
I0824 21:01:12.749835 43675 solver.cpp:244]     Train net output #0: accuracy = 0.981798
I0824 21:01:12.749862 43675 solver.cpp:244]     Train net output #1: loss = 0.0522317 (* 1 = 0.0522317 loss)
I0824 21:01:12.749871 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978435
I0824 21:01:12.749876 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987356
I0824 21:01:12.749883 43675 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0824 21:01:29.376729 43675 solver.cpp:228] Iteration 840, loss = 0.0758343
I0824 21:01:29.376853 43675 solver.cpp:244]     Train net output #0: accuracy = 0.969251
I0824 21:01:29.376879 43675 solver.cpp:244]     Train net output #1: loss = 0.0758343 (* 1 = 0.0758343 loss)
I0824 21:01:29.376888 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.966045
I0824 21:01:29.376893 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976144
I0824 21:01:29.376900 43675 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0824 21:01:46.009488 43675 solver.cpp:228] Iteration 860, loss = 0.0985813
I0824 21:01:46.009536 43675 solver.cpp:244]     Train net output #0: accuracy = 0.958802
I0824 21:01:46.009551 43675 solver.cpp:244]     Train net output #1: loss = 0.0985813 (* 1 = 0.0985813 loss)
I0824 21:01:46.009557 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.955112
I0824 21:01:46.009562 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.965122
I0824 21:01:46.009568 43675 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0824 21:02:02.618196 43675 solver.cpp:228] Iteration 880, loss = 0.0647574
I0824 21:02:02.618369 43675 solver.cpp:244]     Train net output #0: accuracy = 0.975661
I0824 21:02:02.618401 43675 solver.cpp:244]     Train net output #1: loss = 0.0647574 (* 1 = 0.0647574 loss)
I0824 21:02:02.618409 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97215
I0824 21:02:02.618415 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98153
I0824 21:02:02.618422 43675 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0824 21:02:19.235450 43675 solver.cpp:228] Iteration 900, loss = 0.0987883
I0824 21:02:19.235497 43675 solver.cpp:244]     Train net output #0: accuracy = 0.970654
I0824 21:02:19.235524 43675 solver.cpp:244]     Train net output #1: loss = 0.0987883 (* 1 = 0.0987883 loss)
I0824 21:02:19.235535 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983445
I0824 21:02:19.235548 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.950516
I0824 21:02:19.235558 43675 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0824 21:02:35.846190 43675 solver.cpp:228] Iteration 920, loss = 0.0441071
I0824 21:02:35.846309 43675 solver.cpp:244]     Train net output #0: accuracy = 0.984515
I0824 21:02:35.846339 43675 solver.cpp:244]     Train net output #1: loss = 0.0441071 (* 1 = 0.0441071 loss)
I0824 21:02:35.846349 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986225
I0824 21:02:35.846354 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981493
I0824 21:02:35.846361 43675 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0824 21:02:52.452039 43675 solver.cpp:228] Iteration 940, loss = 0.0363357
I0824 21:02:52.452086 43675 solver.cpp:244]     Train net output #0: accuracy = 0.985072
I0824 21:02:52.452101 43675 solver.cpp:244]     Train net output #1: loss = 0.0363357 (* 1 = 0.0363357 loss)
I0824 21:02:52.452108 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978315
I0824 21:02:52.452113 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994131
I0824 21:02:52.452123 43675 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0824 21:03:09.067157 43675 solver.cpp:228] Iteration 960, loss = 0.0438633
I0824 21:03:09.067261 43675 solver.cpp:244]     Train net output #0: accuracy = 0.986521
I0824 21:03:09.067276 43675 solver.cpp:244]     Train net output #1: loss = 0.0438633 (* 1 = 0.0438633 loss)
I0824 21:03:09.067286 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987611
I0824 21:03:09.067291 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981161
I0824 21:03:09.067298 43675 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0824 21:03:25.700933 43675 solver.cpp:228] Iteration 980, loss = 0.0445454
I0824 21:03:25.700978 43675 solver.cpp:244]     Train net output #0: accuracy = 0.981395
I0824 21:03:25.701005 43675 solver.cpp:244]     Train net output #1: loss = 0.0445454 (* 1 = 0.0445454 loss)
I0824 21:03:25.701015 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974045
I0824 21:03:25.701021 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993887
I0824 21:03:25.701028 43675 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0824 21:03:42.308311 43675 solver.cpp:228] Iteration 1000, loss = 0.0545666
I0824 21:03:42.308425 43675 solver.cpp:244]     Train net output #0: accuracy = 0.977681
I0824 21:03:42.308439 43675 solver.cpp:244]     Train net output #1: loss = 0.0545666 (* 1 = 0.0545666 loss)
I0824 21:03:42.308449 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974784
I0824 21:03:42.308454 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984028
I0824 21:03:42.308461 43675 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0824 21:03:58.937597 43675 solver.cpp:228] Iteration 1020, loss = 0.0230997
I0824 21:03:58.937644 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992341
I0824 21:03:58.937657 43675 solver.cpp:244]     Train net output #1: loss = 0.0230997 (* 1 = 0.0230997 loss)
I0824 21:03:58.937664 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993097
I0824 21:03:58.937669 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990041
I0824 21:03:58.937677 43675 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0824 21:04:15.561154 43675 solver.cpp:228] Iteration 1040, loss = 0.0374542
I0824 21:04:15.561329 43675 solver.cpp:244]     Train net output #0: accuracy = 0.985078
I0824 21:04:15.561372 43675 solver.cpp:244]     Train net output #1: loss = 0.0374542 (* 1 = 0.0374542 loss)
I0824 21:04:15.561383 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979626
I0824 21:04:15.561395 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993419
I0824 21:04:15.561406 43675 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0824 21:04:32.196403 43675 solver.cpp:228] Iteration 1060, loss = 0.0753907
I0824 21:04:32.196450 43675 solver.cpp:244]     Train net output #0: accuracy = 0.983737
I0824 21:04:32.196462 43675 solver.cpp:244]     Train net output #1: loss = 0.0753907 (* 1 = 0.0753907 loss)
I0824 21:04:32.196486 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988037
I0824 21:04:32.196496 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980309
I0824 21:04:32.196509 43675 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0824 21:04:48.826911 43675 solver.cpp:228] Iteration 1080, loss = 0.0353419
I0824 21:04:48.827033 43675 solver.cpp:244]     Train net output #0: accuracy = 0.987263
I0824 21:04:48.827049 43675 solver.cpp:244]     Train net output #1: loss = 0.0353419 (* 1 = 0.0353419 loss)
I0824 21:04:48.827055 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988898
I0824 21:04:48.827060 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98346
I0824 21:04:48.827069 43675 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0824 21:05:05.433228 43675 solver.cpp:228] Iteration 1100, loss = 0.0211244
I0824 21:05:05.433270 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992595
I0824 21:05:05.433284 43675 solver.cpp:244]     Train net output #1: loss = 0.0211244 (* 1 = 0.0211244 loss)
I0824 21:05:05.433290 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993656
I0824 21:05:05.433295 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98879
I0824 21:05:05.433302 43675 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0824 21:05:22.059156 43675 solver.cpp:228] Iteration 1120, loss = 0.0499905
I0824 21:05:22.059275 43675 solver.cpp:244]     Train net output #0: accuracy = 0.979805
I0824 21:05:22.059293 43675 solver.cpp:244]     Train net output #1: loss = 0.0499905 (* 1 = 0.0499905 loss)
I0824 21:05:22.059300 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969186
I0824 21:05:22.059305 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993464
I0824 21:05:22.059312 43675 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0824 21:05:38.684072 43675 solver.cpp:228] Iteration 1140, loss = 0.0220422
I0824 21:05:38.684110 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99205
I0824 21:05:38.684123 43675 solver.cpp:244]     Train net output #1: loss = 0.0220422 (* 1 = 0.0220422 loss)
I0824 21:05:38.684128 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992185
I0824 21:05:38.684134 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991682
I0824 21:05:38.684140 43675 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0824 21:05:55.305987 43675 solver.cpp:228] Iteration 1160, loss = 0.0337015
I0824 21:05:55.306145 43675 solver.cpp:244]     Train net output #0: accuracy = 0.987235
I0824 21:05:55.306175 43675 solver.cpp:244]     Train net output #1: loss = 0.0337015 (* 1 = 0.0337015 loss)
I0824 21:05:55.306185 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988892
I0824 21:05:55.306195 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982752
I0824 21:05:55.306202 43675 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0824 21:06:11.941303 43675 solver.cpp:228] Iteration 1180, loss = 0.0309088
I0824 21:06:11.941350 43675 solver.cpp:244]     Train net output #0: accuracy = 0.987203
I0824 21:06:11.941364 43675 solver.cpp:244]     Train net output #1: loss = 0.0309088 (* 1 = 0.0309088 loss)
I0824 21:06:11.941376 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984581
I0824 21:06:11.941381 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99222
I0824 21:06:11.941395 43675 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0824 21:06:28.555641 43675 solver.cpp:228] Iteration 1200, loss = 0.0317103
I0824 21:06:28.555761 43675 solver.cpp:244]     Train net output #0: accuracy = 0.988799
I0824 21:06:28.555778 43675 solver.cpp:244]     Train net output #1: loss = 0.0317103 (* 1 = 0.0317103 loss)
I0824 21:06:28.555789 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990029
I0824 21:06:28.555794 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984509
I0824 21:06:28.555802 43675 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0824 21:06:45.168503 43675 solver.cpp:228] Iteration 1220, loss = 0.0292941
I0824 21:06:45.168548 43675 solver.cpp:244]     Train net output #0: accuracy = 0.989566
I0824 21:06:45.168578 43675 solver.cpp:244]     Train net output #1: loss = 0.0292941 (* 1 = 0.0292941 loss)
I0824 21:06:45.168589 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985866
I0824 21:06:45.168599 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994001
I0824 21:06:45.168606 43675 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0824 21:07:01.791223 43675 solver.cpp:228] Iteration 1240, loss = 0.0211992
I0824 21:07:01.791340 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992678
I0824 21:07:01.791355 43675 solver.cpp:244]     Train net output #1: loss = 0.0211992 (* 1 = 0.0211992 loss)
I0824 21:07:01.791368 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993605
I0824 21:07:01.791373 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989896
I0824 21:07:01.791380 43675 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0824 21:07:18.409342 43675 solver.cpp:228] Iteration 1260, loss = 0.0350937
I0824 21:07:18.409395 43675 solver.cpp:244]     Train net output #0: accuracy = 0.984664
I0824 21:07:18.409425 43675 solver.cpp:244]     Train net output #1: loss = 0.0350937 (* 1 = 0.0350937 loss)
I0824 21:07:18.409436 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981229
I0824 21:07:18.409448 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990449
I0824 21:07:18.409456 43675 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0824 21:07:35.035733 43675 solver.cpp:228] Iteration 1280, loss = 0.0341085
I0824 21:07:35.035836 43675 solver.cpp:244]     Train net output #0: accuracy = 0.987714
I0824 21:07:35.035851 43675 solver.cpp:244]     Train net output #1: loss = 0.0341085 (* 1 = 0.0341085 loss)
I0824 21:07:35.035861 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986277
I0824 21:07:35.035867 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991717
I0824 21:07:35.035873 43675 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0824 21:07:51.660617 43675 solver.cpp:228] Iteration 1300, loss = 0.0322912
I0824 21:07:51.660663 43675 solver.cpp:244]     Train net output #0: accuracy = 0.988864
I0824 21:07:51.660677 43675 solver.cpp:244]     Train net output #1: loss = 0.0322912 (* 1 = 0.0322912 loss)
I0824 21:07:51.660683 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991946
I0824 21:07:51.660688 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980619
I0824 21:07:51.660696 43675 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0824 21:08:08.282099 43675 solver.cpp:228] Iteration 1320, loss = 0.0344452
I0824 21:08:08.282274 43675 solver.cpp:244]     Train net output #0: accuracy = 0.988432
I0824 21:08:08.282294 43675 solver.cpp:244]     Train net output #1: loss = 0.0344452 (* 1 = 0.0344452 loss)
I0824 21:08:08.282302 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992346
I0824 21:08:08.282308 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.977365
I0824 21:08:08.282332 43675 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0824 21:08:24.897256 43675 solver.cpp:228] Iteration 1340, loss = 0.0186569
I0824 21:08:24.897302 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992752
I0824 21:08:24.897316 43675 solver.cpp:244]     Train net output #1: loss = 0.0186569 (* 1 = 0.0186569 loss)
I0824 21:08:24.897322 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991158
I0824 21:08:24.897327 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995871
I0824 21:08:24.897334 43675 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0824 21:08:41.512105 43675 solver.cpp:228] Iteration 1360, loss = 0.025404
I0824 21:08:41.512229 43675 solver.cpp:244]     Train net output #0: accuracy = 0.989376
I0824 21:08:41.512270 43675 solver.cpp:244]     Train net output #1: loss = 0.025404 (* 1 = 0.025404 loss)
I0824 21:08:41.512281 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988257
I0824 21:08:41.512293 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99195
I0824 21:08:41.512310 43675 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0824 21:08:58.134477 43675 solver.cpp:228] Iteration 1380, loss = 0.0460328
I0824 21:08:58.134524 43675 solver.cpp:244]     Train net output #0: accuracy = 0.980179
I0824 21:08:58.134538 43675 solver.cpp:244]     Train net output #1: loss = 0.0460328 (* 1 = 0.0460328 loss)
I0824 21:08:58.134546 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973705
I0824 21:08:58.134552 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991355
I0824 21:08:58.134558 43675 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0824 21:09:14.741094 43675 solver.cpp:228] Iteration 1400, loss = 0.033928
I0824 21:09:14.741192 43675 solver.cpp:244]     Train net output #0: accuracy = 0.985343
I0824 21:09:14.741209 43675 solver.cpp:244]     Train net output #1: loss = 0.033928 (* 1 = 0.033928 loss)
I0824 21:09:14.741219 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981339
I0824 21:09:14.741225 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991352
I0824 21:09:14.741233 43675 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0824 21:09:31.368163 43675 solver.cpp:228] Iteration 1420, loss = 0.0445955
I0824 21:09:31.368207 43675 solver.cpp:244]     Train net output #0: accuracy = 0.98329
I0824 21:09:31.368221 43675 solver.cpp:244]     Train net output #1: loss = 0.0445955 (* 1 = 0.0445955 loss)
I0824 21:09:31.368227 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977771
I0824 21:09:31.368232 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989361
I0824 21:09:31.368239 43675 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0824 21:09:47.992048 43675 solver.cpp:228] Iteration 1440, loss = 0.0252406
I0824 21:09:47.992161 43675 solver.cpp:244]     Train net output #0: accuracy = 0.990757
I0824 21:09:47.992177 43675 solver.cpp:244]     Train net output #1: loss = 0.0252406 (* 1 = 0.0252406 loss)
I0824 21:09:47.992183 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990688
I0824 21:09:47.992188 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990912
I0824 21:09:47.992195 43675 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0824 21:10:04.591348 43675 solver.cpp:228] Iteration 1460, loss = 0.033047
I0824 21:10:04.591392 43675 solver.cpp:244]     Train net output #0: accuracy = 0.986468
I0824 21:10:04.591406 43675 solver.cpp:244]     Train net output #1: loss = 0.033047 (* 1 = 0.033047 loss)
I0824 21:10:04.591413 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983681
I0824 21:10:04.591419 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994611
I0824 21:10:04.591428 43675 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0824 21:10:21.210081 43675 solver.cpp:228] Iteration 1480, loss = 0.0223904
I0824 21:10:21.210240 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992083
I0824 21:10:21.210256 43675 solver.cpp:244]     Train net output #1: loss = 0.0223904 (* 1 = 0.0223904 loss)
I0824 21:10:21.210263 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99154
I0824 21:10:21.210268 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994447
I0824 21:10:21.210274 43675 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0824 21:10:37.837833 43675 solver.cpp:228] Iteration 1500, loss = 0.0218878
I0824 21:10:37.837882 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991787
I0824 21:10:37.837896 43675 solver.cpp:244]     Train net output #1: loss = 0.0218878 (* 1 = 0.0218878 loss)
I0824 21:10:37.837903 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992166
I0824 21:10:37.837908 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990114
I0824 21:10:37.837916 43675 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0824 21:10:54.468127 43675 solver.cpp:228] Iteration 1520, loss = 0.0331986
I0824 21:10:54.468240 43675 solver.cpp:244]     Train net output #0: accuracy = 0.986062
I0824 21:10:54.468257 43675 solver.cpp:244]     Train net output #1: loss = 0.0331986 (* 1 = 0.0331986 loss)
I0824 21:10:54.468268 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981713
I0824 21:10:54.468273 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994066
I0824 21:10:54.468281 43675 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0824 21:11:11.106413 43675 solver.cpp:228] Iteration 1540, loss = 0.0238581
I0824 21:11:11.106461 43675 solver.cpp:244]     Train net output #0: accuracy = 0.988521
I0824 21:11:11.106474 43675 solver.cpp:244]     Train net output #1: loss = 0.0238581 (* 1 = 0.0238581 loss)
I0824 21:11:11.106482 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986201
I0824 21:11:11.106487 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993542
I0824 21:11:11.106493 43675 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0824 21:11:27.719324 43675 solver.cpp:228] Iteration 1560, loss = 0.0399435
I0824 21:11:27.719434 43675 solver.cpp:244]     Train net output #0: accuracy = 0.983915
I0824 21:11:27.719458 43675 solver.cpp:244]     Train net output #1: loss = 0.0399435 (* 1 = 0.0399435 loss)
I0824 21:11:27.719466 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979652
I0824 21:11:27.719480 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991272
I0824 21:11:27.719487 43675 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0824 21:11:44.345938 43675 solver.cpp:228] Iteration 1580, loss = 0.0410571
I0824 21:11:44.345979 43675 solver.cpp:244]     Train net output #0: accuracy = 0.987872
I0824 21:11:44.345993 43675 solver.cpp:244]     Train net output #1: loss = 0.0410571 (* 1 = 0.0410571 loss)
I0824 21:11:44.345999 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98612
I0824 21:11:44.346004 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989409
I0824 21:11:44.346011 43675 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0824 21:12:00.954241 43675 solver.cpp:228] Iteration 1600, loss = 0.0315091
I0824 21:12:00.954355 43675 solver.cpp:244]     Train net output #0: accuracy = 0.988317
I0824 21:12:00.954372 43675 solver.cpp:244]     Train net output #1: loss = 0.0315091 (* 1 = 0.0315091 loss)
I0824 21:12:00.954380 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989396
I0824 21:12:00.954386 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986546
I0824 21:12:00.954396 43675 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0824 21:12:17.575419 43675 solver.cpp:228] Iteration 1620, loss = 0.0303681
I0824 21:12:17.575458 43675 solver.cpp:244]     Train net output #0: accuracy = 0.988419
I0824 21:12:17.575472 43675 solver.cpp:244]     Train net output #1: loss = 0.0303681 (* 1 = 0.0303681 loss)
I0824 21:12:17.575479 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985051
I0824 21:12:17.575484 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993622
I0824 21:12:17.575492 43675 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0824 21:12:34.200964 43675 solver.cpp:228] Iteration 1640, loss = 0.0203592
I0824 21:12:34.201124 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993566
I0824 21:12:34.201146 43675 solver.cpp:244]     Train net output #1: loss = 0.0203592 (* 1 = 0.0203592 loss)
I0824 21:12:34.201154 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995072
I0824 21:12:34.201159 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989684
I0824 21:12:34.201166 43675 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0824 21:12:50.825127 43675 solver.cpp:228] Iteration 1660, loss = 0.0348501
I0824 21:12:50.825171 43675 solver.cpp:244]     Train net output #0: accuracy = 0.98672
I0824 21:12:50.825186 43675 solver.cpp:244]     Train net output #1: loss = 0.0348501 (* 1 = 0.0348501 loss)
I0824 21:12:50.825197 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986759
I0824 21:12:50.825202 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986659
I0824 21:12:50.825211 43675 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0824 21:13:07.437774 43675 solver.cpp:228] Iteration 1680, loss = 0.0239364
I0824 21:13:07.437881 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991531
I0824 21:13:07.437896 43675 solver.cpp:244]     Train net output #1: loss = 0.0239364 (* 1 = 0.0239364 loss)
I0824 21:13:07.437904 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990557
I0824 21:13:07.437909 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993113
I0824 21:13:07.437916 43675 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0824 21:13:24.061342 43675 solver.cpp:228] Iteration 1700, loss = 0.0263786
I0824 21:13:24.061391 43675 solver.cpp:244]     Train net output #0: accuracy = 0.990071
I0824 21:13:24.061405 43675 solver.cpp:244]     Train net output #1: loss = 0.0263786 (* 1 = 0.0263786 loss)
I0824 21:13:24.061413 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990122
I0824 21:13:24.061419 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989973
I0824 21:13:24.061425 43675 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0824 21:13:40.688221 43675 solver.cpp:228] Iteration 1720, loss = 0.0301696
I0824 21:13:40.688320 43675 solver.cpp:244]     Train net output #0: accuracy = 0.989363
I0824 21:13:40.688335 43675 solver.cpp:244]     Train net output #1: loss = 0.0301695 (* 1 = 0.0301695 loss)
I0824 21:13:40.688341 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987926
I0824 21:13:40.688346 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991245
I0824 21:13:40.688354 43675 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0824 21:13:57.317401 43675 solver.cpp:228] Iteration 1740, loss = 0.0287112
I0824 21:13:57.317438 43675 solver.cpp:244]     Train net output #0: accuracy = 0.987247
I0824 21:13:57.317451 43675 solver.cpp:244]     Train net output #1: loss = 0.0287112 (* 1 = 0.0287112 loss)
I0824 21:13:57.317456 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982931
I0824 21:13:57.317461 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994371
I0824 21:13:57.317469 43675 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0824 21:14:13.948052 43675 solver.cpp:228] Iteration 1760, loss = 0.0281393
I0824 21:14:13.948213 43675 solver.cpp:244]     Train net output #0: accuracy = 0.989774
I0824 21:14:13.948233 43675 solver.cpp:244]     Train net output #1: loss = 0.0281393 (* 1 = 0.0281393 loss)
I0824 21:14:13.948241 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988086
I0824 21:14:13.948246 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992083
I0824 21:14:13.948253 43675 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0824 21:14:30.564857 43675 solver.cpp:228] Iteration 1780, loss = 0.0189935
I0824 21:14:30.564898 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992313
I0824 21:14:30.564911 43675 solver.cpp:244]     Train net output #1: loss = 0.0189935 (* 1 = 0.0189935 loss)
I0824 21:14:30.564918 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989976
I0824 21:14:30.564923 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995944
I0824 21:14:30.564929 43675 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0824 21:14:47.180117 43675 solver.cpp:228] Iteration 1800, loss = 0.023856
I0824 21:14:47.180227 43675 solver.cpp:244]     Train net output #0: accuracy = 0.988954
I0824 21:14:47.180244 43675 solver.cpp:244]     Train net output #1: loss = 0.023856 (* 1 = 0.023856 loss)
I0824 21:14:47.180253 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983285
I0824 21:14:47.180258 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997975
I0824 21:14:47.180265 43675 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0824 21:15:03.792193 43675 solver.cpp:228] Iteration 1820, loss = 0.0234472
I0824 21:15:03.792234 43675 solver.cpp:244]     Train net output #0: accuracy = 0.989452
I0824 21:15:03.792248 43675 solver.cpp:244]     Train net output #1: loss = 0.0234472 (* 1 = 0.0234472 loss)
I0824 21:15:03.792253 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987801
I0824 21:15:03.792258 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994045
I0824 21:15:03.792266 43675 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0824 21:15:20.420634 43675 solver.cpp:228] Iteration 1840, loss = 0.0244206
I0824 21:15:20.420737 43675 solver.cpp:244]     Train net output #0: accuracy = 0.990214
I0824 21:15:20.420753 43675 solver.cpp:244]     Train net output #1: loss = 0.0244206 (* 1 = 0.0244206 loss)
I0824 21:15:20.420759 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98714
I0824 21:15:20.420765 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994292
I0824 21:15:20.420774 43675 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0824 21:15:37.041980 43675 solver.cpp:228] Iteration 1860, loss = 0.0186145
I0824 21:15:37.042018 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994096
I0824 21:15:37.042032 43675 solver.cpp:244]     Train net output #1: loss = 0.0186145 (* 1 = 0.0186145 loss)
I0824 21:15:37.042038 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993115
I0824 21:15:37.042043 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995351
I0824 21:15:37.042050 43675 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0824 21:15:53.677830 43675 solver.cpp:228] Iteration 1880, loss = 0.0267973
I0824 21:15:53.677929 43675 solver.cpp:244]     Train net output #0: accuracy = 0.988656
I0824 21:15:53.677944 43675 solver.cpp:244]     Train net output #1: loss = 0.0267973 (* 1 = 0.0267973 loss)
I0824 21:15:53.677950 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985334
I0824 21:15:53.677955 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993054
I0824 21:15:53.677963 43675 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0824 21:16:10.294041 43675 solver.cpp:228] Iteration 1900, loss = 0.0438382
I0824 21:16:10.294087 43675 solver.cpp:244]     Train net output #0: accuracy = 0.986198
I0824 21:16:10.294100 43675 solver.cpp:244]     Train net output #1: loss = 0.0438382 (* 1 = 0.0438382 loss)
I0824 21:16:10.294106 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982649
I0824 21:16:10.294111 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990198
I0824 21:16:10.294119 43675 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0824 21:16:26.913220 43675 solver.cpp:228] Iteration 1920, loss = 0.0320567
I0824 21:16:26.913381 43675 solver.cpp:244]     Train net output #0: accuracy = 0.982963
I0824 21:16:26.913403 43675 solver.cpp:244]     Train net output #1: loss = 0.0320567 (* 1 = 0.0320567 loss)
I0824 21:16:26.913409 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975989
I0824 21:16:26.913415 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997078
I0824 21:16:26.913422 43675 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0824 21:16:43.534370 43675 solver.cpp:228] Iteration 1940, loss = 0.0316754
I0824 21:16:43.534415 43675 solver.cpp:244]     Train net output #0: accuracy = 0.989174
I0824 21:16:43.534430 43675 solver.cpp:244]     Train net output #1: loss = 0.0316753 (* 1 = 0.0316753 loss)
I0824 21:16:43.534435 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987611
I0824 21:16:43.534440 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991538
I0824 21:16:43.534447 43675 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0824 21:17:00.156462 43675 solver.cpp:228] Iteration 1960, loss = 0.0229035
I0824 21:17:00.156563 43675 solver.cpp:244]     Train net output #0: accuracy = 0.990295
I0824 21:17:00.156579 43675 solver.cpp:244]     Train net output #1: loss = 0.0229034 (* 1 = 0.0229034 loss)
I0824 21:17:00.156585 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985952
I0824 21:17:00.156590 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996691
I0824 21:17:00.156599 43675 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0824 21:17:16.778867 43675 solver.cpp:228] Iteration 1980, loss = 0.0207941
I0824 21:17:16.778904 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991334
I0824 21:17:16.778918 43675 solver.cpp:244]     Train net output #1: loss = 0.0207941 (* 1 = 0.0207941 loss)
I0824 21:17:16.778924 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989407
I0824 21:17:16.778937 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996223
I0824 21:17:16.778945 43675 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0824 21:17:33.407357 43675 solver.cpp:228] Iteration 2000, loss = 0.0624372
I0824 21:17:33.407472 43675 solver.cpp:244]     Train net output #0: accuracy = 0.981564
I0824 21:17:33.407487 43675 solver.cpp:244]     Train net output #1: loss = 0.0624372 (* 1 = 0.0624372 loss)
I0824 21:17:33.407495 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983826
I0824 21:17:33.407500 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978529
I0824 21:17:33.407506 43675 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0824 21:17:50.017725 43675 solver.cpp:228] Iteration 2020, loss = 0.0565943
I0824 21:17:50.017766 43675 solver.cpp:244]     Train net output #0: accuracy = 0.97758
I0824 21:17:50.017779 43675 solver.cpp:244]     Train net output #1: loss = 0.0565943 (* 1 = 0.0565943 loss)
I0824 21:17:50.017786 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980231
I0824 21:17:50.017791 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.971485
I0824 21:17:50.017798 43675 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0824 21:18:06.631379 43675 solver.cpp:228] Iteration 2040, loss = 0.0303635
I0824 21:18:06.631481 43675 solver.cpp:244]     Train net output #0: accuracy = 0.987585
I0824 21:18:06.631497 43675 solver.cpp:244]     Train net output #1: loss = 0.0303635 (* 1 = 0.0303635 loss)
I0824 21:18:06.631511 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984326
I0824 21:18:06.631521 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993821
I0824 21:18:06.631528 43675 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0824 21:18:23.254214 43675 solver.cpp:228] Iteration 2060, loss = 0.0370206
I0824 21:18:23.254254 43675 solver.cpp:244]     Train net output #0: accuracy = 0.98627
I0824 21:18:23.254267 43675 solver.cpp:244]     Train net output #1: loss = 0.0370206 (* 1 = 0.0370206 loss)
I0824 21:18:23.254274 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978551
I0824 21:18:23.254279 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994436
I0824 21:18:23.254287 43675 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0824 21:18:39.883396 43675 solver.cpp:228] Iteration 2080, loss = 0.0316781
I0824 21:18:39.883560 43675 solver.cpp:244]     Train net output #0: accuracy = 0.986372
I0824 21:18:39.883584 43675 solver.cpp:244]     Train net output #1: loss = 0.0316781 (* 1 = 0.0316781 loss)
I0824 21:18:39.883591 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978937
I0824 21:18:39.883602 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995068
I0824 21:18:39.883610 43675 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0824 21:18:56.497730 43675 solver.cpp:228] Iteration 2100, loss = 0.0275848
I0824 21:18:56.497767 43675 solver.cpp:244]     Train net output #0: accuracy = 0.988872
I0824 21:18:56.497781 43675 solver.cpp:244]     Train net output #1: loss = 0.0275848 (* 1 = 0.0275848 loss)
I0824 21:18:56.497788 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98631
I0824 21:18:56.497793 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993516
I0824 21:18:56.497800 43675 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0824 21:19:13.132242 43675 solver.cpp:228] Iteration 2120, loss = 0.0330456
I0824 21:19:13.132375 43675 solver.cpp:244]     Train net output #0: accuracy = 0.983325
I0824 21:19:13.132391 43675 solver.cpp:244]     Train net output #1: loss = 0.0330456 (* 1 = 0.0330456 loss)
I0824 21:19:13.132405 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972937
I0824 21:19:13.132410 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999079
I0824 21:19:13.132417 43675 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0824 21:19:29.771620 43675 solver.cpp:228] Iteration 2140, loss = 0.0203097
I0824 21:19:29.771666 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992144
I0824 21:19:29.771680 43675 solver.cpp:244]     Train net output #1: loss = 0.0203098 (* 1 = 0.0203098 loss)
I0824 21:19:29.771687 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991886
I0824 21:19:29.771692 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99319
I0824 21:19:29.771699 43675 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0824 21:19:46.411437 43675 solver.cpp:228] Iteration 2160, loss = 0.0255019
I0824 21:19:46.411576 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99081
I0824 21:19:46.411594 43675 solver.cpp:244]     Train net output #1: loss = 0.0255019 (* 1 = 0.0255019 loss)
I0824 21:19:46.411603 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990092
I0824 21:19:46.411617 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99206
I0824 21:19:46.411631 43675 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0824 21:20:03.052373 43675 solver.cpp:228] Iteration 2180, loss = 0.0387803
I0824 21:20:03.052420 43675 solver.cpp:244]     Train net output #0: accuracy = 0.986764
I0824 21:20:03.052435 43675 solver.cpp:244]     Train net output #1: loss = 0.0387803 (* 1 = 0.0387803 loss)
I0824 21:20:03.052443 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990411
I0824 21:20:03.052453 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981256
I0824 21:20:03.052460 43675 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0824 21:20:19.648840 43675 solver.cpp:228] Iteration 2200, loss = 0.0189677
I0824 21:20:19.648942 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99287
I0824 21:20:19.648958 43675 solver.cpp:244]     Train net output #1: loss = 0.0189677 (* 1 = 0.0189677 loss)
I0824 21:20:19.648964 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994098
I0824 21:20:19.648970 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989743
I0824 21:20:19.648977 43675 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0824 21:20:36.271627 43675 solver.cpp:228] Iteration 2220, loss = 0.021592
I0824 21:20:36.271673 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99135
I0824 21:20:36.271687 43675 solver.cpp:244]     Train net output #1: loss = 0.021592 (* 1 = 0.021592 loss)
I0824 21:20:36.271693 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988737
I0824 21:20:36.271698 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995698
I0824 21:20:36.271706 43675 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0824 21:20:52.891991 43675 solver.cpp:228] Iteration 2240, loss = 0.0143133
I0824 21:20:52.892160 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99492
I0824 21:20:52.892184 43675 solver.cpp:244]     Train net output #1: loss = 0.0143133 (* 1 = 0.0143133 loss)
I0824 21:20:52.892194 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994939
I0824 21:20:52.892204 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994872
I0824 21:20:52.892212 43675 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0824 21:21:09.521961 43675 solver.cpp:228] Iteration 2260, loss = 0.0219735
I0824 21:21:09.522001 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991549
I0824 21:21:09.522013 43675 solver.cpp:244]     Train net output #1: loss = 0.0219735 (* 1 = 0.0219735 loss)
I0824 21:21:09.522019 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991224
I0824 21:21:09.522024 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992698
I0824 21:21:09.522032 43675 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0824 21:21:26.142594 43675 solver.cpp:228] Iteration 2280, loss = 0.0171638
I0824 21:21:26.142714 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993652
I0824 21:21:26.142730 43675 solver.cpp:244]     Train net output #1: loss = 0.0171638 (* 1 = 0.0171638 loss)
I0824 21:21:26.142737 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993735
I0824 21:21:26.142742 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993469
I0824 21:21:26.142750 43675 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0824 21:21:42.771050 43675 solver.cpp:228] Iteration 2300, loss = 0.0204483
I0824 21:21:42.771091 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99202
I0824 21:21:42.771105 43675 solver.cpp:244]     Train net output #1: loss = 0.0204483 (* 1 = 0.0204483 loss)
I0824 21:21:42.771111 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992408
I0824 21:21:42.771116 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991144
I0824 21:21:42.771124 43675 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0824 21:21:59.391366 43675 solver.cpp:228] Iteration 2320, loss = 0.0223171
I0824 21:21:59.391479 43675 solver.cpp:244]     Train net output #0: accuracy = 0.990745
I0824 21:21:59.391494 43675 solver.cpp:244]     Train net output #1: loss = 0.0223171 (* 1 = 0.0223171 loss)
I0824 21:21:59.391500 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991619
I0824 21:21:59.391505 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986716
I0824 21:21:59.391512 43675 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0824 21:22:16.022106 43675 solver.cpp:228] Iteration 2340, loss = 0.0155249
I0824 21:22:16.022151 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993623
I0824 21:22:16.022166 43675 solver.cpp:244]     Train net output #1: loss = 0.0155249 (* 1 = 0.0155249 loss)
I0824 21:22:16.022172 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992756
I0824 21:22:16.022177 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995712
I0824 21:22:16.022184 43675 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0824 21:22:32.690255 43675 solver.cpp:228] Iteration 2360, loss = 0.0160643
I0824 21:22:32.690445 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994771
I0824 21:22:32.690464 43675 solver.cpp:244]     Train net output #1: loss = 0.0160643 (* 1 = 0.0160643 loss)
I0824 21:22:32.690470 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995645
I0824 21:22:32.690481 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992741
I0824 21:22:32.690490 43675 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0824 21:22:49.302422 43675 solver.cpp:228] Iteration 2380, loss = 0.0171288
I0824 21:22:49.302466 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993247
I0824 21:22:49.302480 43675 solver.cpp:244]     Train net output #1: loss = 0.0171288 (* 1 = 0.0171288 loss)
I0824 21:22:49.302486 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991996
I0824 21:22:49.302491 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995681
I0824 21:22:49.302500 43675 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0824 21:23:05.921339 43675 solver.cpp:228] Iteration 2400, loss = 0.0154601
I0824 21:23:05.921454 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99444
I0824 21:23:05.921473 43675 solver.cpp:244]     Train net output #1: loss = 0.0154601 (* 1 = 0.0154601 loss)
I0824 21:23:05.921485 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99404
I0824 21:23:05.921490 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995153
I0824 21:23:05.921497 43675 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0824 21:23:22.532397 43675 solver.cpp:228] Iteration 2420, loss = 0.0245753
I0824 21:23:22.532441 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991267
I0824 21:23:22.532454 43675 solver.cpp:244]     Train net output #1: loss = 0.0245753 (* 1 = 0.0245753 loss)
I0824 21:23:22.532462 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992414
I0824 21:23:22.532467 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988742
I0824 21:23:22.532474 43675 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0824 21:23:39.140137 43675 solver.cpp:228] Iteration 2440, loss = 0.0190748
I0824 21:23:39.140249 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991419
I0824 21:23:39.140266 43675 solver.cpp:244]     Train net output #1: loss = 0.0190748 (* 1 = 0.0190748 loss)
I0824 21:23:39.140281 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988944
I0824 21:23:39.140293 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996404
I0824 21:23:39.140301 43675 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0824 21:23:55.765588 43675 solver.cpp:228] Iteration 2460, loss = 0.0270352
I0824 21:23:55.765627 43675 solver.cpp:244]     Train net output #0: accuracy = 0.990292
I0824 21:23:55.765641 43675 solver.cpp:244]     Train net output #1: loss = 0.0270352 (* 1 = 0.0270352 loss)
I0824 21:23:55.765647 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991305
I0824 21:23:55.765652 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98865
I0824 21:23:55.765660 43675 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0824 21:24:12.386790 43675 solver.cpp:228] Iteration 2480, loss = 0.0206172
I0824 21:24:12.386895 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991505
I0824 21:24:12.386911 43675 solver.cpp:244]     Train net output #1: loss = 0.0206172 (* 1 = 0.0206172 loss)
I0824 21:24:12.386919 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991756
I0824 21:24:12.386934 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99085
I0824 21:24:12.386948 43675 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0824 21:24:29.004117 43675 solver.cpp:228] Iteration 2500, loss = 0.0257529
I0824 21:24:29.004158 43675 solver.cpp:244]     Train net output #0: accuracy = 0.989675
I0824 21:24:29.004171 43675 solver.cpp:244]     Train net output #1: loss = 0.0257529 (* 1 = 0.0257529 loss)
I0824 21:24:29.004178 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988966
I0824 21:24:29.004182 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99121
I0824 21:24:29.004189 43675 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0824 21:24:45.610589 43675 solver.cpp:228] Iteration 2520, loss = 0.0229318
I0824 21:24:45.610752 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991291
I0824 21:24:45.610770 43675 solver.cpp:244]     Train net output #1: loss = 0.0229318 (* 1 = 0.0229318 loss)
I0824 21:24:45.610782 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991377
I0824 21:24:45.610788 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991101
I0824 21:24:45.610796 43675 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0824 21:25:02.227254 43675 solver.cpp:228] Iteration 2540, loss = 0.0255022
I0824 21:25:02.227299 43675 solver.cpp:244]     Train net output #0: accuracy = 0.990231
I0824 21:25:02.227313 43675 solver.cpp:244]     Train net output #1: loss = 0.0255022 (* 1 = 0.0255022 loss)
I0824 21:25:02.227319 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98968
I0824 21:25:02.227324 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991465
I0824 21:25:02.227334 43675 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0824 21:25:18.833129 43675 solver.cpp:228] Iteration 2560, loss = 0.0716419
I0824 21:25:18.833235 43675 solver.cpp:244]     Train net output #0: accuracy = 0.969282
I0824 21:25:18.833250 43675 solver.cpp:244]     Train net output #1: loss = 0.0716419 (* 1 = 0.0716419 loss)
I0824 21:25:18.833256 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.966291
I0824 21:25:18.833261 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992419
I0824 21:25:18.833269 43675 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0824 21:25:35.448865 43675 solver.cpp:228] Iteration 2580, loss = 0.0200946
I0824 21:25:35.448911 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992231
I0824 21:25:35.448925 43675 solver.cpp:244]     Train net output #1: loss = 0.0200946 (* 1 = 0.0200946 loss)
I0824 21:25:35.448930 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991601
I0824 21:25:35.448935 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993216
I0824 21:25:35.448943 43675 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0824 21:25:52.061532 43675 solver.cpp:228] Iteration 2600, loss = 0.0282202
I0824 21:25:52.061640 43675 solver.cpp:244]     Train net output #0: accuracy = 0.989447
I0824 21:25:52.061655 43675 solver.cpp:244]     Train net output #1: loss = 0.0282203 (* 1 = 0.0282203 loss)
I0824 21:25:52.061661 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988198
I0824 21:25:52.061666 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991701
I0824 21:25:52.061674 43675 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0824 21:26:08.668344 43675 solver.cpp:228] Iteration 2620, loss = 0.0279153
I0824 21:26:08.668390 43675 solver.cpp:244]     Train net output #0: accuracy = 0.988462
I0824 21:26:08.668403 43675 solver.cpp:244]     Train net output #1: loss = 0.0279153 (* 1 = 0.0279153 loss)
I0824 21:26:08.668411 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987702
I0824 21:26:08.668416 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990028
I0824 21:26:08.668427 43675 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0824 21:26:25.288952 43675 solver.cpp:228] Iteration 2640, loss = 0.0215114
I0824 21:26:25.289052 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992742
I0824 21:26:25.289068 43675 solver.cpp:244]     Train net output #1: loss = 0.0215114 (* 1 = 0.0215114 loss)
I0824 21:26:25.289074 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994353
I0824 21:26:25.289079 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98999
I0824 21:26:25.289088 43675 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0824 21:26:41.899225 43675 solver.cpp:228] Iteration 2660, loss = 0.0236359
I0824 21:26:41.899266 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991192
I0824 21:26:41.899278 43675 solver.cpp:244]     Train net output #1: loss = 0.0236359 (* 1 = 0.0236359 loss)
I0824 21:26:41.899284 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98736
I0824 21:26:41.899291 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995407
I0824 21:26:41.899297 43675 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0824 21:26:58.516968 43675 solver.cpp:228] Iteration 2680, loss = 0.0230814
I0824 21:26:58.517123 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991183
I0824 21:26:58.517141 43675 solver.cpp:244]     Train net output #1: loss = 0.0230814 (* 1 = 0.0230814 loss)
I0824 21:26:58.517151 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989777
I0824 21:26:58.517156 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994634
I0824 21:26:58.517163 43675 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0824 21:27:15.138536 43675 solver.cpp:228] Iteration 2700, loss = 0.0164576
I0824 21:27:15.138578 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992474
I0824 21:27:15.138592 43675 solver.cpp:244]     Train net output #1: loss = 0.0164576 (* 1 = 0.0164576 loss)
I0824 21:27:15.138598 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99003
I0824 21:27:15.138603 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997575
I0824 21:27:15.138612 43675 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0824 21:27:31.767668 43675 solver.cpp:228] Iteration 2720, loss = 0.0195116
I0824 21:27:31.767796 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992972
I0824 21:27:31.767812 43675 solver.cpp:244]     Train net output #1: loss = 0.0195117 (* 1 = 0.0195117 loss)
I0824 21:27:31.767818 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991601
I0824 21:27:31.767824 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994822
I0824 21:27:31.767833 43675 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0824 21:27:48.382068 43675 solver.cpp:228] Iteration 2740, loss = 0.0261806
I0824 21:27:48.382117 43675 solver.cpp:244]     Train net output #0: accuracy = 0.98862
I0824 21:27:48.382131 43675 solver.cpp:244]     Train net output #1: loss = 0.0261806 (* 1 = 0.0261806 loss)
I0824 21:27:48.382138 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983536
I0824 21:27:48.382145 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996338
I0824 21:27:48.382153 43675 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0824 21:28:05.036612 43675 solver.cpp:228] Iteration 2760, loss = 0.0194388
I0824 21:28:05.036777 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991234
I0824 21:28:05.036816 43675 solver.cpp:244]     Train net output #1: loss = 0.0194388 (* 1 = 0.0194388 loss)
I0824 21:28:05.036826 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987157
I0824 21:28:05.036837 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996831
I0824 21:28:05.036844 43675 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0824 21:28:21.700521 43675 solver.cpp:228] Iteration 2780, loss = 0.0219631
I0824 21:28:21.700572 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991536
I0824 21:28:21.700588 43675 solver.cpp:244]     Train net output #1: loss = 0.0219631 (* 1 = 0.0219631 loss)
I0824 21:28:21.700595 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98856
I0824 21:28:21.700601 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995099
I0824 21:28:21.700611 43675 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0824 21:28:38.314954 43675 solver.cpp:228] Iteration 2800, loss = 0.0165154
I0824 21:28:38.315141 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994682
I0824 21:28:38.315162 43675 solver.cpp:244]     Train net output #1: loss = 0.0165154 (* 1 = 0.0165154 loss)
I0824 21:28:38.315171 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99464
I0824 21:28:38.315177 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994826
I0824 21:28:38.315186 43675 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0824 21:28:54.931567 43675 solver.cpp:228] Iteration 2820, loss = 0.0178594
I0824 21:28:54.931613 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993497
I0824 21:28:54.931627 43675 solver.cpp:244]     Train net output #1: loss = 0.0178594 (* 1 = 0.0178594 loss)
I0824 21:28:54.931633 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993239
I0824 21:28:54.931638 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993928
I0824 21:28:54.931645 43675 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0824 21:29:11.563238 43675 solver.cpp:228] Iteration 2840, loss = 0.0185948
I0824 21:29:11.563360 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993624
I0824 21:29:11.563377 43675 solver.cpp:244]     Train net output #1: loss = 0.0185948 (* 1 = 0.0185948 loss)
I0824 21:29:11.563387 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996499
I0824 21:29:11.563392 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985504
I0824 21:29:11.563401 43675 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0824 21:29:28.190134 43675 solver.cpp:228] Iteration 2860, loss = 0.0173815
I0824 21:29:28.190178 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993668
I0824 21:29:28.190192 43675 solver.cpp:244]     Train net output #1: loss = 0.0173815 (* 1 = 0.0173815 loss)
I0824 21:29:28.190198 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991758
I0824 21:29:28.190203 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996089
I0824 21:29:28.190210 43675 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0824 21:29:44.814312 43675 solver.cpp:228] Iteration 2880, loss = 0.0124975
I0824 21:29:44.814421 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995519
I0824 21:29:44.814437 43675 solver.cpp:244]     Train net output #1: loss = 0.0124975 (* 1 = 0.0124975 loss)
I0824 21:29:44.814450 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996004
I0824 21:29:44.814455 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993854
I0824 21:29:44.814462 43675 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0824 21:30:01.415869 43675 solver.cpp:228] Iteration 2900, loss = 0.0127598
I0824 21:30:01.415915 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995143
I0824 21:30:01.415930 43675 solver.cpp:244]     Train net output #1: loss = 0.0127598 (* 1 = 0.0127598 loss)
I0824 21:30:01.415935 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995468
I0824 21:30:01.415940 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994273
I0824 21:30:01.415947 43675 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0824 21:30:18.031339 43675 solver.cpp:228] Iteration 2920, loss = 0.0130044
I0824 21:30:18.031451 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994165
I0824 21:30:18.031466 43675 solver.cpp:244]     Train net output #1: loss = 0.0130044 (* 1 = 0.0130044 loss)
I0824 21:30:18.031473 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992151
I0824 21:30:18.031478 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997978
I0824 21:30:18.031486 43675 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0824 21:30:34.661666 43675 solver.cpp:228] Iteration 2940, loss = 0.0117924
I0824 21:30:34.661712 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995156
I0824 21:30:34.661727 43675 solver.cpp:244]     Train net output #1: loss = 0.0117924 (* 1 = 0.0117924 loss)
I0824 21:30:34.661733 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993922
I0824 21:30:34.661738 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997437
I0824 21:30:34.661746 43675 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0824 21:30:51.299553 43675 solver.cpp:228] Iteration 2960, loss = 0.0317079
I0824 21:30:51.299706 43675 solver.cpp:244]     Train net output #0: accuracy = 0.988479
I0824 21:30:51.299724 43675 solver.cpp:244]     Train net output #1: loss = 0.0317079 (* 1 = 0.0317079 loss)
I0824 21:30:51.299731 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986754
I0824 21:30:51.299737 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991854
I0824 21:30:51.299746 43675 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0824 21:31:07.938926 43675 solver.cpp:228] Iteration 2980, loss = 0.00970005
I0824 21:31:07.938976 43675 solver.cpp:244]     Train net output #0: accuracy = 0.9964
I0824 21:31:07.938990 43675 solver.cpp:244]     Train net output #1: loss = 0.00970006 (* 1 = 0.00970006 loss)
I0824 21:31:07.938998 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996759
I0824 21:31:07.939004 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995132
I0824 21:31:07.939015 43675 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0824 21:31:24.588699 43675 solver.cpp:228] Iteration 3000, loss = 0.0208943
I0824 21:31:24.588829 43675 solver.cpp:244]     Train net output #0: accuracy = 0.9942
I0824 21:31:24.588846 43675 solver.cpp:244]     Train net output #1: loss = 0.0208943 (* 1 = 0.0208943 loss)
I0824 21:31:24.588853 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993687
I0824 21:31:24.588860 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994662
I0824 21:31:24.588868 43675 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0824 21:31:41.217921 43675 solver.cpp:228] Iteration 3020, loss = 0.0179708
I0824 21:31:41.217968 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99303
I0824 21:31:41.217983 43675 solver.cpp:244]     Train net output #1: loss = 0.0179708 (* 1 = 0.0179708 loss)
I0824 21:31:41.217989 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992201
I0824 21:31:41.217996 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994913
I0824 21:31:41.218003 43675 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0824 21:31:57.853935 43675 solver.cpp:228] Iteration 3040, loss = 0.0156937
I0824 21:31:57.854054 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992797
I0824 21:31:57.854071 43675 solver.cpp:244]     Train net output #1: loss = 0.0156937 (* 1 = 0.0156937 loss)
I0824 21:31:57.854080 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991276
I0824 21:31:57.854091 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996582
I0824 21:31:57.854099 43675 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0824 21:32:14.478857 43675 solver.cpp:228] Iteration 3060, loss = 0.0167688
I0824 21:32:14.478905 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992247
I0824 21:32:14.478920 43675 solver.cpp:244]     Train net output #1: loss = 0.0167688 (* 1 = 0.0167688 loss)
I0824 21:32:14.478927 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989452
I0824 21:32:14.478935 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998202
I0824 21:32:14.478942 43675 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0824 21:32:31.098917 43675 solver.cpp:228] Iteration 3080, loss = 0.0195551
I0824 21:32:31.099023 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992004
I0824 21:32:31.099040 43675 solver.cpp:244]     Train net output #1: loss = 0.0195551 (* 1 = 0.0195551 loss)
I0824 21:32:31.099045 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989669
I0824 21:32:31.099050 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996312
I0824 21:32:31.099059 43675 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0824 21:32:47.742724 43675 solver.cpp:228] Iteration 3100, loss = 0.0188721
I0824 21:32:47.742769 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992163
I0824 21:32:47.742784 43675 solver.cpp:244]     Train net output #1: loss = 0.0188721 (* 1 = 0.0188721 loss)
I0824 21:32:47.742790 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991055
I0824 21:32:47.742795 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994275
I0824 21:32:47.742804 43675 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0824 21:33:04.368054 43675 solver.cpp:228] Iteration 3120, loss = 0.0163788
I0824 21:33:04.368194 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99276
I0824 21:33:04.368211 43675 solver.cpp:244]     Train net output #1: loss = 0.0163788 (* 1 = 0.0163788 loss)
I0824 21:33:04.368219 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991527
I0824 21:33:04.368224 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995591
I0824 21:33:04.368232 43675 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0824 21:33:20.989073 43675 solver.cpp:228] Iteration 3140, loss = 0.016462
I0824 21:33:20.989120 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993165
I0824 21:33:20.989133 43675 solver.cpp:244]     Train net output #1: loss = 0.016462 (* 1 = 0.016462 loss)
I0824 21:33:20.989147 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991597
I0824 21:33:20.989152 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995991
I0824 21:33:20.989161 43675 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0824 21:33:37.610203 43675 solver.cpp:228] Iteration 3160, loss = 0.0237586
I0824 21:33:37.610302 43675 solver.cpp:244]     Train net output #0: accuracy = 0.990864
I0824 21:33:37.610317 43675 solver.cpp:244]     Train net output #1: loss = 0.0237586 (* 1 = 0.0237586 loss)
I0824 21:33:37.610323 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989046
I0824 21:33:37.610328 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994096
I0824 21:33:37.610335 43675 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0824 21:33:54.235167 43675 solver.cpp:228] Iteration 3180, loss = 0.0140401
I0824 21:33:54.235213 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994586
I0824 21:33:54.235227 43675 solver.cpp:244]     Train net output #1: loss = 0.0140401 (* 1 = 0.0140401 loss)
I0824 21:33:54.235241 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995242
I0824 21:33:54.235254 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99287
I0824 21:33:54.235262 43675 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0824 21:34:10.848001 43675 solver.cpp:228] Iteration 3200, loss = 0.0171003
I0824 21:34:10.848088 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995067
I0824 21:34:10.848104 43675 solver.cpp:244]     Train net output #1: loss = 0.0171003 (* 1 = 0.0171003 loss)
I0824 21:34:10.848115 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993544
I0824 21:34:10.848120 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99639
I0824 21:34:10.848127 43675 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0824 21:34:27.470908 43675 solver.cpp:228] Iteration 3220, loss = 0.0212172
I0824 21:34:27.470950 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992556
I0824 21:34:27.470963 43675 solver.cpp:244]     Train net output #1: loss = 0.0212172 (* 1 = 0.0212172 loss)
I0824 21:34:27.470970 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991623
I0824 21:34:27.470975 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994393
I0824 21:34:27.470983 43675 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0824 21:34:44.086936 43675 solver.cpp:228] Iteration 3240, loss = 0.0128153
I0824 21:34:44.087040 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994216
I0824 21:34:44.087057 43675 solver.cpp:244]     Train net output #1: loss = 0.0128153 (* 1 = 0.0128153 loss)
I0824 21:34:44.087067 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992831
I0824 21:34:44.087072 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996779
I0824 21:34:44.087080 43675 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0824 21:35:00.711084 43675 solver.cpp:228] Iteration 3260, loss = 0.0128153
I0824 21:35:00.711124 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99526
I0824 21:35:00.711138 43675 solver.cpp:244]     Train net output #1: loss = 0.0128153 (* 1 = 0.0128153 loss)
I0824 21:35:00.711144 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996197
I0824 21:35:00.711149 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99195
I0824 21:35:00.711156 43675 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0824 21:35:17.321499 43675 solver.cpp:228] Iteration 3280, loss = 0.0149628
I0824 21:35:17.321653 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994612
I0824 21:35:17.321674 43675 solver.cpp:244]     Train net output #1: loss = 0.0149628 (* 1 = 0.0149628 loss)
I0824 21:35:17.321683 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994207
I0824 21:35:17.321693 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995415
I0824 21:35:17.321702 43675 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0824 21:35:33.949360 43675 solver.cpp:228] Iteration 3300, loss = 0.0118571
I0824 21:35:33.949407 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995245
I0824 21:35:33.949421 43675 solver.cpp:244]     Train net output #1: loss = 0.0118571 (* 1 = 0.0118571 loss)
I0824 21:35:33.949427 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995392
I0824 21:35:33.949432 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99491
I0824 21:35:33.949440 43675 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0824 21:35:50.572001 43675 solver.cpp:228] Iteration 3320, loss = 0.0202338
I0824 21:35:50.572098 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993864
I0824 21:35:50.572114 43675 solver.cpp:244]     Train net output #1: loss = 0.0202339 (* 1 = 0.0202339 loss)
I0824 21:35:50.572120 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995833
I0824 21:35:50.572126 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986652
I0824 21:35:50.572134 43675 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0824 21:36:07.208585 43675 solver.cpp:228] Iteration 3340, loss = 0.0115489
I0824 21:36:07.208629 43675 solver.cpp:244]     Train net output #0: accuracy = 0.996369
I0824 21:36:07.208643 43675 solver.cpp:244]     Train net output #1: loss = 0.0115489 (* 1 = 0.0115489 loss)
I0824 21:36:07.208649 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997577
I0824 21:36:07.208655 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994482
I0824 21:36:07.208662 43675 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0824 21:36:23.838610 43675 solver.cpp:228] Iteration 3360, loss = 0.00973491
I0824 21:36:23.838706 43675 solver.cpp:244]     Train net output #0: accuracy = 0.996481
I0824 21:36:23.838721 43675 solver.cpp:244]     Train net output #1: loss = 0.00973492 (* 1 = 0.00973492 loss)
I0824 21:36:23.838727 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997036
I0824 21:36:23.838732 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994571
I0824 21:36:23.838739 43675 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0824 21:36:40.462327 43675 solver.cpp:228] Iteration 3380, loss = 0.00746472
I0824 21:36:40.462373 43675 solver.cpp:244]     Train net output #0: accuracy = 0.996513
I0824 21:36:40.462386 43675 solver.cpp:244]     Train net output #1: loss = 0.00746472 (* 1 = 0.00746472 loss)
I0824 21:36:40.462393 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995447
I0824 21:36:40.462399 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998885
I0824 21:36:40.462406 43675 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0824 21:36:57.098120 43675 solver.cpp:228] Iteration 3400, loss = 0.0127565
I0824 21:36:57.098282 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994771
I0824 21:36:57.098299 43675 solver.cpp:244]     Train net output #1: loss = 0.0127565 (* 1 = 0.0127565 loss)
I0824 21:36:57.098305 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993546
I0824 21:36:57.098310 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996779
I0824 21:36:57.098318 43675 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0824 21:37:13.712515 43675 solver.cpp:228] Iteration 3420, loss = 0.0140158
I0824 21:37:13.712563 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994129
I0824 21:37:13.712579 43675 solver.cpp:244]     Train net output #1: loss = 0.0140158 (* 1 = 0.0140158 loss)
I0824 21:37:13.712585 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994599
I0824 21:37:13.712591 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993027
I0824 21:37:13.712599 43675 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0824 21:37:30.331054 43675 solver.cpp:228] Iteration 3440, loss = 0.014946
I0824 21:37:30.331146 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992841
I0824 21:37:30.331163 43675 solver.cpp:244]     Train net output #1: loss = 0.0149461 (* 1 = 0.0149461 loss)
I0824 21:37:30.331169 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989473
I0824 21:37:30.331174 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998672
I0824 21:37:30.331182 43675 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0824 21:37:46.954314 43675 solver.cpp:228] Iteration 3460, loss = 0.0169136
I0824 21:37:46.954355 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993896
I0824 21:37:46.954367 43675 solver.cpp:244]     Train net output #1: loss = 0.0169136 (* 1 = 0.0169136 loss)
I0824 21:37:46.954373 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994948
I0824 21:37:46.954378 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991264
I0824 21:37:46.954386 43675 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0824 21:38:03.579964 43675 solver.cpp:228] Iteration 3480, loss = 0.01318
I0824 21:38:03.580070 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995448
I0824 21:38:03.580087 43675 solver.cpp:244]     Train net output #1: loss = 0.01318 (* 1 = 0.01318 loss)
I0824 21:38:03.580098 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994932
I0824 21:38:03.580103 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99636
I0824 21:38:03.580111 43675 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0824 21:38:20.191416 43675 solver.cpp:228] Iteration 3500, loss = 0.0207129
I0824 21:38:20.191458 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992755
I0824 21:38:20.191471 43675 solver.cpp:244]     Train net output #1: loss = 0.0207129 (* 1 = 0.0207129 loss)
I0824 21:38:20.191478 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991406
I0824 21:38:20.191483 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994537
I0824 21:38:20.191490 43675 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0824 21:38:36.823544 43675 solver.cpp:228] Iteration 3520, loss = 0.025347
I0824 21:38:36.823645 43675 solver.cpp:244]     Train net output #0: accuracy = 0.98951
I0824 21:38:36.823663 43675 solver.cpp:244]     Train net output #1: loss = 0.025347 (* 1 = 0.025347 loss)
I0824 21:38:36.823673 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98676
I0824 21:38:36.823684 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994215
I0824 21:38:36.823693 43675 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0824 21:38:53.447254 43675 solver.cpp:228] Iteration 3540, loss = 0.0146109
I0824 21:38:53.447294 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993715
I0824 21:38:53.447307 43675 solver.cpp:244]     Train net output #1: loss = 0.0146109 (* 1 = 0.0146109 loss)
I0824 21:38:53.447314 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992787
I0824 21:38:53.447319 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996066
I0824 21:38:53.447326 43675 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0824 21:39:10.065556 43675 solver.cpp:228] Iteration 3560, loss = 0.0204686
I0824 21:39:10.065714 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991306
I0824 21:39:10.065737 43675 solver.cpp:244]     Train net output #1: loss = 0.0204686 (* 1 = 0.0204686 loss)
I0824 21:39:10.065745 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989082
I0824 21:39:10.065752 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994298
I0824 21:39:10.065758 43675 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0824 21:39:26.696084 43675 solver.cpp:228] Iteration 3580, loss = 0.0106175
I0824 21:39:26.696130 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995596
I0824 21:39:26.696143 43675 solver.cpp:244]     Train net output #1: loss = 0.0106175 (* 1 = 0.0106175 loss)
I0824 21:39:26.696149 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995437
I0824 21:39:26.696154 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996154
I0824 21:39:26.696162 43675 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0824 21:39:43.317270 43675 solver.cpp:228] Iteration 3600, loss = 0.00926549
I0824 21:39:43.317375 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995864
I0824 21:39:43.317391 43675 solver.cpp:244]     Train net output #1: loss = 0.00926549 (* 1 = 0.00926549 loss)
I0824 21:39:43.317399 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995245
I0824 21:39:43.317404 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997201
I0824 21:39:43.317411 43675 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0824 21:39:59.939357 43675 solver.cpp:228] Iteration 3620, loss = 0.0121967
I0824 21:39:59.939402 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995331
I0824 21:39:59.939417 43675 solver.cpp:244]     Train net output #1: loss = 0.0121967 (* 1 = 0.0121967 loss)
I0824 21:39:59.939424 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995081
I0824 21:39:59.939430 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995897
I0824 21:39:59.939440 43675 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0824 21:40:16.559221 43675 solver.cpp:228] Iteration 3640, loss = 0.0135186
I0824 21:40:16.559316 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994201
I0824 21:40:16.559330 43675 solver.cpp:244]     Train net output #1: loss = 0.0135186 (* 1 = 0.0135186 loss)
I0824 21:40:16.559336 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992773
I0824 21:40:16.559342 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996556
I0824 21:40:16.559350 43675 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0824 21:40:33.181977 43675 solver.cpp:228] Iteration 3660, loss = 0.015666
I0824 21:40:33.182023 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993885
I0824 21:40:33.182037 43675 solver.cpp:244]     Train net output #1: loss = 0.015666 (* 1 = 0.015666 loss)
I0824 21:40:33.182044 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99408
I0824 21:40:33.182051 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993534
I0824 21:40:33.182060 43675 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0824 21:40:49.805171 43675 solver.cpp:228] Iteration 3680, loss = 0.0179209
I0824 21:40:49.805264 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993063
I0824 21:40:49.805280 43675 solver.cpp:244]     Train net output #1: loss = 0.0179209 (* 1 = 0.0179209 loss)
I0824 21:40:49.805287 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991009
I0824 21:40:49.805292 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995646
I0824 21:40:49.805299 43675 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0824 21:41:06.406908 43675 solver.cpp:228] Iteration 3700, loss = 0.0224046
I0824 21:41:06.406951 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992015
I0824 21:41:06.406965 43675 solver.cpp:244]     Train net output #1: loss = 0.0224046 (* 1 = 0.0224046 loss)
I0824 21:41:06.406970 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992166
I0824 21:41:06.406976 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991294
I0824 21:41:06.406983 43675 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0824 21:41:23.019997 43675 solver.cpp:228] Iteration 3720, loss = 0.00820185
I0824 21:41:23.020167 43675 solver.cpp:244]     Train net output #0: accuracy = 0.996973
I0824 21:41:23.020190 43675 solver.cpp:244]     Train net output #1: loss = 0.00820185 (* 1 = 0.00820185 loss)
I0824 21:41:23.020200 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997371
I0824 21:41:23.020210 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995612
I0824 21:41:23.020216 43675 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0824 21:41:39.641295 43675 solver.cpp:228] Iteration 3740, loss = 0.0145258
I0824 21:41:39.641340 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994268
I0824 21:41:39.641355 43675 solver.cpp:244]     Train net output #1: loss = 0.0145258 (* 1 = 0.0145258 loss)
I0824 21:41:39.641362 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991988
I0824 21:41:39.641376 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997478
I0824 21:41:39.641383 43675 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0824 21:41:56.259457 43675 solver.cpp:228] Iteration 3760, loss = 0.0165345
I0824 21:41:56.259560 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993034
I0824 21:41:56.259577 43675 solver.cpp:244]     Train net output #1: loss = 0.0165345 (* 1 = 0.0165345 loss)
I0824 21:41:56.259582 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991903
I0824 21:41:56.259588 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99481
I0824 21:41:56.259594 43675 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0824 21:42:12.881815 43675 solver.cpp:228] Iteration 3780, loss = 0.0168206
I0824 21:42:12.881861 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993112
I0824 21:42:12.881876 43675 solver.cpp:244]     Train net output #1: loss = 0.0168206 (* 1 = 0.0168206 loss)
I0824 21:42:12.881884 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993847
I0824 21:42:12.881891 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991032
I0824 21:42:12.881898 43675 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0824 21:42:29.495826 43675 solver.cpp:228] Iteration 3800, loss = 0.00970034
I0824 21:42:29.495924 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995679
I0824 21:42:29.495939 43675 solver.cpp:244]     Train net output #1: loss = 0.00970034 (* 1 = 0.00970034 loss)
I0824 21:42:29.495946 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994911
I0824 21:42:29.495951 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997653
I0824 21:42:29.495959 43675 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0824 21:42:46.137419 43675 solver.cpp:228] Iteration 3820, loss = 0.0139043
I0824 21:42:46.137465 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995626
I0824 21:42:46.137477 43675 solver.cpp:244]     Train net output #1: loss = 0.0139043 (* 1 = 0.0139043 loss)
I0824 21:42:46.137483 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995108
I0824 21:42:46.137490 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996234
I0824 21:42:46.137496 43675 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0824 21:43:02.761309 43675 solver.cpp:228] Iteration 3840, loss = 0.0246714
I0824 21:43:02.761405 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991635
I0824 21:43:02.761422 43675 solver.cpp:244]     Train net output #1: loss = 0.0246714 (* 1 = 0.0246714 loss)
I0824 21:43:02.761435 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988229
I0824 21:43:02.761440 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994816
I0824 21:43:02.761447 43675 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0824 21:43:19.377791 43675 solver.cpp:228] Iteration 3860, loss = 0.0102047
I0824 21:43:19.377837 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995532
I0824 21:43:19.377851 43675 solver.cpp:244]     Train net output #1: loss = 0.0102047 (* 1 = 0.0102047 loss)
I0824 21:43:19.377858 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994913
I0824 21:43:19.377863 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996871
I0824 21:43:19.377871 43675 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0824 21:43:36.005506 43675 solver.cpp:228] Iteration 3880, loss = 0.0152554
I0824 21:43:36.005671 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994771
I0824 21:43:36.005688 43675 solver.cpp:244]     Train net output #1: loss = 0.0152554 (* 1 = 0.0152554 loss)
I0824 21:43:36.005699 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994778
I0824 21:43:36.005704 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994757
I0824 21:43:36.005712 43675 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0824 21:43:52.626394 43675 solver.cpp:228] Iteration 3900, loss = 0.0105952
I0824 21:43:52.626442 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99627
I0824 21:43:52.626457 43675 solver.cpp:244]     Train net output #1: loss = 0.0105952 (* 1 = 0.0105952 loss)
I0824 21:43:52.626463 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994771
I0824 21:43:52.626468 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997897
I0824 21:43:52.626477 43675 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0824 21:44:09.251901 43675 solver.cpp:228] Iteration 3920, loss = 0.010507
I0824 21:44:09.252012 43675 solver.cpp:244]     Train net output #0: accuracy = 0.996005
I0824 21:44:09.252027 43675 solver.cpp:244]     Train net output #1: loss = 0.010507 (* 1 = 0.010507 loss)
I0824 21:44:09.252038 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996484
I0824 21:44:09.252049 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994489
I0824 21:44:09.252058 43675 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0824 21:44:25.878556 43675 solver.cpp:228] Iteration 3940, loss = 0.0151512
I0824 21:44:25.878597 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994796
I0824 21:44:25.878610 43675 solver.cpp:244]     Train net output #1: loss = 0.0151512 (* 1 = 0.0151512 loss)
I0824 21:44:25.878617 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991129
I0824 21:44:25.878621 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998218
I0824 21:44:25.878628 43675 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0824 21:44:42.489293 43675 solver.cpp:228] Iteration 3960, loss = 0.014691
I0824 21:44:42.489441 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994397
I0824 21:44:42.489485 43675 solver.cpp:244]     Train net output #1: loss = 0.014691 (* 1 = 0.014691 loss)
I0824 21:44:42.489493 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991876
I0824 21:44:42.489504 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997169
I0824 21:44:42.489514 43675 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0824 21:44:59.182471 43675 solver.cpp:228] Iteration 3980, loss = 0.0189292
I0824 21:44:59.182518 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991619
I0824 21:44:59.182531 43675 solver.cpp:244]     Train net output #1: loss = 0.0189292 (* 1 = 0.0189292 loss)
I0824 21:44:59.182538 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988213
I0824 21:44:59.182543 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998609
I0824 21:44:59.182552 43675 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0824 21:45:15.870620 43675 solver.cpp:228] Iteration 4000, loss = 0.008758
I0824 21:45:15.870790 43675 solver.cpp:244]     Train net output #0: accuracy = 0.996985
I0824 21:45:15.870820 43675 solver.cpp:244]     Train net output #1: loss = 0.008758 (* 1 = 0.008758 loss)
I0824 21:45:15.870831 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997436
I0824 21:45:15.870842 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995985
I0824 21:45:15.870853 43675 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0824 21:45:32.549664 43675 solver.cpp:228] Iteration 4020, loss = 0.013214
I0824 21:45:32.549726 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994936
I0824 21:45:32.549741 43675 solver.cpp:244]     Train net output #1: loss = 0.013214 (* 1 = 0.013214 loss)
I0824 21:45:32.549747 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993558
I0824 21:45:32.549752 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997177
I0824 21:45:32.549760 43675 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0824 21:45:49.259973 43675 solver.cpp:228] Iteration 4040, loss = 0.00923381
I0824 21:45:49.260110 43675 solver.cpp:244]     Train net output #0: accuracy = 0.996259
I0824 21:45:49.260138 43675 solver.cpp:244]     Train net output #1: loss = 0.00923382 (* 1 = 0.00923382 loss)
I0824 21:45:49.260149 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996485
I0824 21:45:49.260159 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995503
I0824 21:45:49.260166 43675 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0824 21:46:05.943056 43675 solver.cpp:228] Iteration 4060, loss = 0.0128343
I0824 21:46:05.943100 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994916
I0824 21:46:05.943115 43675 solver.cpp:244]     Train net output #1: loss = 0.0128343 (* 1 = 0.0128343 loss)
I0824 21:46:05.943121 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994097
I0824 21:46:05.943126 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996448
I0824 21:46:05.943135 43675 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0824 21:46:22.605259 43675 solver.cpp:228] Iteration 4080, loss = 0.0239427
I0824 21:46:22.605386 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991152
I0824 21:46:22.605409 43675 solver.cpp:244]     Train net output #1: loss = 0.0239427 (* 1 = 0.0239427 loss)
I0824 21:46:22.605424 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99028
I0824 21:46:22.605438 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992885
I0824 21:46:22.605455 43675 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0824 21:46:39.239189 43675 solver.cpp:228] Iteration 4100, loss = 0.0183107
I0824 21:46:39.239279 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992441
I0824 21:46:39.239295 43675 solver.cpp:244]     Train net output #1: loss = 0.0183107 (* 1 = 0.0183107 loss)
I0824 21:46:39.239305 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989317
I0824 21:46:39.239316 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997729
I0824 21:46:39.239326 43675 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0824 21:46:55.860980 43675 solver.cpp:228] Iteration 4120, loss = 0.0115555
I0824 21:46:55.861089 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995023
I0824 21:46:55.861106 43675 solver.cpp:244]     Train net output #1: loss = 0.0115555 (* 1 = 0.0115555 loss)
I0824 21:46:55.861119 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994934
I0824 21:46:55.861131 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995288
I0824 21:46:55.861140 43675 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0824 21:47:12.488451 43675 solver.cpp:228] Iteration 4140, loss = 0.0156782
I0824 21:47:12.488502 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994508
I0824 21:47:12.488519 43675 solver.cpp:244]     Train net output #1: loss = 0.0156782 (* 1 = 0.0156782 loss)
I0824 21:47:12.488526 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99471
I0824 21:47:12.488533 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994023
I0824 21:47:12.488540 43675 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0824 21:47:29.105213 43675 solver.cpp:228] Iteration 4160, loss = 0.0160234
I0824 21:47:29.105370 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994738
I0824 21:47:29.105406 43675 solver.cpp:244]     Train net output #1: loss = 0.0160234 (* 1 = 0.0160234 loss)
I0824 21:47:29.105417 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995788
I0824 21:47:29.105424 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987336
I0824 21:47:29.105432 43675 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0824 21:47:45.729195 43675 solver.cpp:228] Iteration 4180, loss = 0.0143192
I0824 21:47:45.729240 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994255
I0824 21:47:45.729255 43675 solver.cpp:244]     Train net output #1: loss = 0.0143192 (* 1 = 0.0143192 loss)
I0824 21:47:45.729262 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992823
I0824 21:47:45.729269 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996166
I0824 21:47:45.729277 43675 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0824 21:48:02.360322 43675 solver.cpp:228] Iteration 4200, loss = 0.0174737
I0824 21:48:02.360445 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993902
I0824 21:48:02.360461 43675 solver.cpp:244]     Train net output #1: loss = 0.0174737 (* 1 = 0.0174737 loss)
I0824 21:48:02.360471 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991381
I0824 21:48:02.360476 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996606
I0824 21:48:02.360486 43675 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0824 21:48:18.998416 43675 solver.cpp:228] Iteration 4220, loss = 0.012342
I0824 21:48:18.998464 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994767
I0824 21:48:18.998478 43675 solver.cpp:244]     Train net output #1: loss = 0.012342 (* 1 = 0.012342 loss)
I0824 21:48:18.998494 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993381
I0824 21:48:18.998507 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99811
I0824 21:48:18.998515 43675 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0824 21:48:35.596796 43675 solver.cpp:228] Iteration 4240, loss = 0.0170989
I0824 21:48:35.596915 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99242
I0824 21:48:35.596932 43675 solver.cpp:244]     Train net output #1: loss = 0.0170989 (* 1 = 0.0170989 loss)
I0824 21:48:35.596946 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989917
I0824 21:48:35.596958 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99635
I0824 21:48:35.596972 43675 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0824 21:48:52.192451 43675 solver.cpp:228] Iteration 4260, loss = 0.0153025
I0824 21:48:52.192497 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994022
I0824 21:48:52.192513 43675 solver.cpp:244]     Train net output #1: loss = 0.0153025 (* 1 = 0.0153025 loss)
I0824 21:48:52.192520 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992377
I0824 21:48:52.192526 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996584
I0824 21:48:52.192536 43675 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0824 21:49:08.799401 43675 solver.cpp:228] Iteration 4280, loss = 0.00996777
I0824 21:49:08.799505 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995835
I0824 21:49:08.799520 43675 solver.cpp:244]     Train net output #1: loss = 0.00996777 (* 1 = 0.00996777 loss)
I0824 21:49:08.799527 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994967
I0824 21:49:08.799535 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998035
I0824 21:49:08.799541 43675 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0824 21:49:25.417898 43675 solver.cpp:228] Iteration 4300, loss = 0.0164864
I0824 21:49:25.417944 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992587
I0824 21:49:25.417960 43675 solver.cpp:244]     Train net output #1: loss = 0.0164864 (* 1 = 0.0164864 loss)
I0824 21:49:25.417968 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989478
I0824 21:49:25.417973 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997159
I0824 21:49:25.417981 43675 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0824 21:49:42.056452 43675 solver.cpp:228] Iteration 4320, loss = 0.0105302
I0824 21:49:42.056622 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995936
I0824 21:49:42.056643 43675 solver.cpp:244]     Train net output #1: loss = 0.0105302 (* 1 = 0.0105302 loss)
I0824 21:49:42.056651 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996448
I0824 21:49:42.056663 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993932
I0824 21:49:42.056670 43675 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0824 21:49:58.682998 43675 solver.cpp:228] Iteration 4340, loss = 0.0107024
I0824 21:49:58.683039 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995556
I0824 21:49:58.683053 43675 solver.cpp:244]     Train net output #1: loss = 0.0107024 (* 1 = 0.0107024 loss)
I0824 21:49:58.683061 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99542
I0824 21:49:58.683066 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995872
I0824 21:49:58.683084 43675 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0824 21:50:15.295089 43675 solver.cpp:228] Iteration 4360, loss = 0.0122876
I0824 21:50:15.295202 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995218
I0824 21:50:15.295219 43675 solver.cpp:244]     Train net output #1: loss = 0.0122876 (* 1 = 0.0122876 loss)
I0824 21:50:15.295229 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993019
I0824 21:50:15.295240 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997975
I0824 21:50:15.295248 43675 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0824 21:50:31.926477 43675 solver.cpp:228] Iteration 4380, loss = 0.0159554
I0824 21:50:31.926520 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994223
I0824 21:50:31.926533 43675 solver.cpp:244]     Train net output #1: loss = 0.0159554 (* 1 = 0.0159554 loss)
I0824 21:50:31.926539 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994634
I0824 21:50:31.926544 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992927
I0824 21:50:31.926553 43675 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0824 21:50:48.566825 43675 solver.cpp:228] Iteration 4400, loss = 0.0134503
I0824 21:50:48.566939 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994774
I0824 21:50:48.566967 43675 solver.cpp:244]     Train net output #1: loss = 0.0134503 (* 1 = 0.0134503 loss)
I0824 21:50:48.566975 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992857
I0824 21:50:48.566987 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99729
I0824 21:50:48.566996 43675 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0824 21:51:05.226734 43675 solver.cpp:228] Iteration 4420, loss = 0.0134591
I0824 21:51:05.226778 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995375
I0824 21:51:05.226794 43675 solver.cpp:244]     Train net output #1: loss = 0.0134591 (* 1 = 0.0134591 loss)
I0824 21:51:05.226800 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994702
I0824 21:51:05.226806 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996568
I0824 21:51:05.226812 43675 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0824 21:51:21.849678 43675 solver.cpp:228] Iteration 4440, loss = 0.00929568
I0824 21:51:21.849803 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995829
I0824 21:51:21.849822 43675 solver.cpp:244]     Train net output #1: loss = 0.00929568 (* 1 = 0.00929568 loss)
I0824 21:51:21.849834 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99388
I0824 21:51:21.849841 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998593
I0824 21:51:21.849851 43675 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0824 21:51:38.478082 43675 solver.cpp:228] Iteration 4460, loss = 0.013126
I0824 21:51:38.478130 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99502
I0824 21:51:38.478145 43675 solver.cpp:244]     Train net output #1: loss = 0.013126 (* 1 = 0.013126 loss)
I0824 21:51:38.478152 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994679
I0824 21:51:38.478158 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995559
I0824 21:51:38.478180 43675 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0824 21:51:55.088977 43675 solver.cpp:228] Iteration 4480, loss = 0.0125508
I0824 21:51:55.089135 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995832
I0824 21:51:55.089154 43675 solver.cpp:244]     Train net output #1: loss = 0.0125508 (* 1 = 0.0125508 loss)
I0824 21:51:55.089164 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996293
I0824 21:51:55.089171 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995037
I0824 21:51:55.089179 43675 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0824 21:52:11.694056 43675 solver.cpp:228] Iteration 4500, loss = 0.00915437
I0824 21:52:11.694105 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99662
I0824 21:52:11.694121 43675 solver.cpp:244]     Train net output #1: loss = 0.00915437 (* 1 = 0.00915437 loss)
I0824 21:52:11.694128 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995785
I0824 21:52:11.694134 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998296
I0824 21:52:11.694152 43675 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0824 21:52:28.318681 43675 solver.cpp:228] Iteration 4520, loss = 0.0198288
I0824 21:52:28.318795 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99157
I0824 21:52:28.318812 43675 solver.cpp:244]     Train net output #1: loss = 0.0198288 (* 1 = 0.0198288 loss)
I0824 21:52:28.318825 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98954
I0824 21:52:28.318837 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995753
I0824 21:52:28.318846 43675 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0824 21:52:44.945061 43675 solver.cpp:228] Iteration 4540, loss = 0.0115165
I0824 21:52:44.945102 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99463
I0824 21:52:44.945116 43675 solver.cpp:244]     Train net output #1: loss = 0.0115165 (* 1 = 0.0115165 loss)
I0824 21:52:44.945122 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993352
I0824 21:52:44.945129 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997717
I0824 21:52:44.945137 43675 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0824 21:53:01.575036 43675 solver.cpp:228] Iteration 4560, loss = 0.00887064
I0824 21:53:01.575145 43675 solver.cpp:244]     Train net output #0: accuracy = 0.996628
I0824 21:53:01.575163 43675 solver.cpp:244]     Train net output #1: loss = 0.00887064 (* 1 = 0.00887064 loss)
I0824 21:53:01.575172 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99603
I0824 21:53:01.575184 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997811
I0824 21:53:01.575193 43675 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0824 21:53:18.189666 43675 solver.cpp:228] Iteration 4580, loss = 0.0173673
I0824 21:53:18.189705 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993909
I0824 21:53:18.189719 43675 solver.cpp:244]     Train net output #1: loss = 0.0173673 (* 1 = 0.0173673 loss)
I0824 21:53:18.189726 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994128
I0824 21:53:18.189731 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993339
I0824 21:53:18.189740 43675 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0824 21:53:34.803272 43675 solver.cpp:228] Iteration 4600, loss = 0.0123394
I0824 21:53:34.803436 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995862
I0824 21:53:34.803454 43675 solver.cpp:244]     Train net output #1: loss = 0.0123395 (* 1 = 0.0123395 loss)
I0824 21:53:34.803467 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995886
I0824 21:53:34.803478 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995815
I0824 21:53:34.803486 43675 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0824 21:53:51.403671 43675 solver.cpp:228] Iteration 4620, loss = 0.0212336
I0824 21:53:51.403712 43675 solver.cpp:244]     Train net output #0: accuracy = 0.991583
I0824 21:53:51.403725 43675 solver.cpp:244]     Train net output #1: loss = 0.0212337 (* 1 = 0.0212337 loss)
I0824 21:53:51.403733 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991505
I0824 21:53:51.403738 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991731
I0824 21:53:51.403744 43675 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0824 21:54:08.014190 43675 solver.cpp:228] Iteration 4640, loss = 0.011252
I0824 21:54:08.014320 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995496
I0824 21:54:08.014338 43675 solver.cpp:244]     Train net output #1: loss = 0.0112521 (* 1 = 0.0112521 loss)
I0824 21:54:08.014348 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994445
I0824 21:54:08.014360 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997233
I0824 21:54:08.014369 43675 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0824 21:54:24.632273 43675 solver.cpp:228] Iteration 4660, loss = 0.0160721
I0824 21:54:24.632318 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994433
I0824 21:54:24.632333 43675 solver.cpp:244]     Train net output #1: loss = 0.0160721 (* 1 = 0.0160721 loss)
I0824 21:54:24.632340 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995098
I0824 21:54:24.632346 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993143
I0824 21:54:24.632354 43675 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0824 21:54:41.281164 43675 solver.cpp:228] Iteration 4680, loss = 0.0161427
I0824 21:54:41.281303 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995042
I0824 21:54:41.281325 43675 solver.cpp:244]     Train net output #1: loss = 0.0161427 (* 1 = 0.0161427 loss)
I0824 21:54:41.281334 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996902
I0824 21:54:41.281345 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991586
I0824 21:54:41.281354 43675 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0824 21:54:57.929024 43675 solver.cpp:228] Iteration 4700, loss = 0.0176108
I0824 21:54:57.929075 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992598
I0824 21:54:57.929091 43675 solver.cpp:244]     Train net output #1: loss = 0.0176108 (* 1 = 0.0176108 loss)
I0824 21:54:57.929100 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990353
I0824 21:54:57.929105 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996385
I0824 21:54:57.929114 43675 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0824 21:55:14.579351 43675 solver.cpp:228] Iteration 4720, loss = 0.0182378
I0824 21:55:14.579488 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993536
I0824 21:55:14.579506 43675 solver.cpp:244]     Train net output #1: loss = 0.0182378 (* 1 = 0.0182378 loss)
I0824 21:55:14.579515 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993468
I0824 21:55:14.579526 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99371
I0824 21:55:14.579535 43675 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0824 21:55:31.223788 43675 solver.cpp:228] Iteration 4740, loss = 0.0090906
I0824 21:55:31.223837 43675 solver.cpp:244]     Train net output #0: accuracy = 0.996738
I0824 21:55:31.223855 43675 solver.cpp:244]     Train net output #1: loss = 0.00909062 (* 1 = 0.00909062 loss)
I0824 21:55:31.223861 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997147
I0824 21:55:31.223867 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995528
I0824 21:55:31.223876 43675 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0824 21:55:47.856554 43675 solver.cpp:228] Iteration 4760, loss = 0.00978914
I0824 21:55:47.856739 43675 solver.cpp:244]     Train net output #0: accuracy = 0.996166
I0824 21:55:47.856761 43675 solver.cpp:244]     Train net output #1: loss = 0.00978915 (* 1 = 0.00978915 loss)
I0824 21:55:47.856771 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996357
I0824 21:55:47.856781 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995536
I0824 21:55:47.856791 43675 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0824 21:56:04.498697 43675 solver.cpp:228] Iteration 4780, loss = 0.0132446
I0824 21:56:04.498739 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994314
I0824 21:56:04.498754 43675 solver.cpp:244]     Train net output #1: loss = 0.0132446 (* 1 = 0.0132446 loss)
I0824 21:56:04.498761 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993525
I0824 21:56:04.498769 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995988
I0824 21:56:04.498776 43675 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0824 21:56:21.148054 43675 solver.cpp:228] Iteration 4800, loss = 0.014174
I0824 21:56:21.148192 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994352
I0824 21:56:21.148216 43675 solver.cpp:244]     Train net output #1: loss = 0.014174 (* 1 = 0.014174 loss)
I0824 21:56:21.148224 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99361
I0824 21:56:21.148236 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996226
I0824 21:56:21.148243 43675 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0824 21:56:37.769160 43675 solver.cpp:228] Iteration 4820, loss = 0.0215383
I0824 21:56:37.769208 43675 solver.cpp:244]     Train net output #0: accuracy = 0.992173
I0824 21:56:37.769223 43675 solver.cpp:244]     Train net output #1: loss = 0.0215383 (* 1 = 0.0215383 loss)
I0824 21:56:37.769230 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9922
I0824 21:56:37.769237 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992107
I0824 21:56:37.769245 43675 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0824 21:56:54.402323 43675 solver.cpp:228] Iteration 4840, loss = 0.012576
I0824 21:56:54.402460 43675 solver.cpp:244]     Train net output #0: accuracy = 0.994799
I0824 21:56:54.402477 43675 solver.cpp:244]     Train net output #1: loss = 0.012576 (* 1 = 0.012576 loss)
I0824 21:56:54.402490 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994327
I0824 21:56:54.402496 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995857
I0824 21:56:54.402504 43675 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0824 21:57:11.036754 43675 solver.cpp:228] Iteration 4860, loss = 0.0209017
I0824 21:57:11.036803 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993024
I0824 21:57:11.036818 43675 solver.cpp:244]     Train net output #1: loss = 0.0209017 (* 1 = 0.0209017 loss)
I0824 21:57:11.036825 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994319
I0824 21:57:11.036839 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990773
I0824 21:57:11.036846 43675 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0824 21:57:27.672195 43675 solver.cpp:228] Iteration 4880, loss = 0.0118334
I0824 21:57:27.672344 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995514
I0824 21:57:27.672361 43675 solver.cpp:244]     Train net output #1: loss = 0.0118334 (* 1 = 0.0118334 loss)
I0824 21:57:27.672371 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994946
I0824 21:57:27.672384 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996774
I0824 21:57:27.672391 43675 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0824 21:57:44.306522 43675 solver.cpp:228] Iteration 4900, loss = 0.0159949
I0824 21:57:44.306572 43675 solver.cpp:244]     Train net output #0: accuracy = 0.993905
I0824 21:57:44.306588 43675 solver.cpp:244]     Train net output #1: loss = 0.0159949 (* 1 = 0.0159949 loss)
I0824 21:57:44.306596 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993006
I0824 21:57:44.306602 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996111
I0824 21:57:44.306618 43675 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0824 21:58:00.934159 43675 solver.cpp:228] Iteration 4920, loss = 0.00982187
I0824 21:58:00.934327 43675 solver.cpp:244]     Train net output #0: accuracy = 0.996272
I0824 21:58:00.934350 43675 solver.cpp:244]     Train net output #1: loss = 0.00982189 (* 1 = 0.00982189 loss)
I0824 21:58:00.934358 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995089
I0824 21:58:00.934370 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997849
I0824 21:58:00.934378 43675 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0824 21:58:17.562134 43675 solver.cpp:228] Iteration 4940, loss = 0.0127925
I0824 21:58:17.562181 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99498
I0824 21:58:17.562196 43675 solver.cpp:244]     Train net output #1: loss = 0.0127926 (* 1 = 0.0127926 loss)
I0824 21:58:17.562203 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994681
I0824 21:58:17.562209 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995544
I0824 21:58:17.562217 43675 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0824 21:58:34.178266 43675 solver.cpp:228] Iteration 4960, loss = 0.0109145
I0824 21:58:34.178375 43675 solver.cpp:244]     Train net output #0: accuracy = 0.995654
I0824 21:58:34.178392 43675 solver.cpp:244]     Train net output #1: loss = 0.0109145 (* 1 = 0.0109145 loss)
I0824 21:58:34.178400 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994911
I0824 21:58:34.178411 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996884
I0824 21:58:34.178419 43675 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0824 21:58:50.803874 43675 solver.cpp:228] Iteration 4980, loss = 0.0127709
I0824 21:58:50.803915 43675 solver.cpp:244]     Train net output #0: accuracy = 0.99468
I0824 21:58:50.803928 43675 solver.cpp:244]     Train net output #1: loss = 0.0127709 (* 1 = 0.0127709 loss)
I0824 21:58:50.803936 43675 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993578
I0824 21:58:50.803941 43675 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996446
I0824 21:58:50.803949 43675 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0824 21:59:07.066377 43675 solver.cpp:454] Snapshotting to binary proto file pocwisc5/training_iter_5000.caffemodel
I0824 21:59:08.027714 43675 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc5/training_iter_5000.solverstate
I0824 21:59:08.624408 43675 solver.cpp:317] Iteration 5000, loss = 0.0100794
I0824 21:59:08.624452 43675 solver.cpp:322] Optimization Done.
I0824 21:59:08.624457 43675 caffe.cpp:254] Optimization Done.

2017-08-24 21:59:09,030 log.framework MainThread  INFO       caffe models found
pocwisc5/training_iter_5000.caffemodel
2017-08-24 21:59:09,030 log.framework MainThread  INFO       Caffe model found: pocwisc5/training_iter_5000.caffemodel
2017-08-24 21:59:11,211 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 21:59:11,441 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 21:59:11,652 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 21:59:11,856 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 21:59:12,064 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 21:59:12,269 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 21:59:12,419 log.framework MainThread  INFO       train file number: 50
2017-08-24 21:59:12,419 log.framework MainThread  INFO       test file number: 5
2017-08-24 21:59:12,419 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 21:59:12,420 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 21:59:12,420 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-08-24 21:59:12,420 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-08-24 21:59:12,421 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-08-24 21:59:12,422 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc6/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc6/training"
solver_mode: GPU

2017-08-24 21:59:12,422 log.framework MainThread  INFO       caffe training step
2017-08-24 21:59:12,422 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc6/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-08-24 23:08:33,656 log.framework MainThread  INFO       I0824 21:59:12.495617 43755 caffe.cpp:217] Using GPUs 0
I0824 21:59:12.508124 43755 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0824 21:59:13.047313 43755 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc6/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc6/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0824 21:59:13.047487 43755 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc6/caffe/model_segnet_final/train.prototxt
I0824 21:59:13.050308 43755 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc6/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 21:59:13.050820 43755 layer_factory.hpp:77] Creating layer data
I0824 21:59:13.050866 43755 net.cpp:100] Creating Layer data
I0824 21:59:13.050879 43755 net.cpp:408] data -> data
I0824 21:59:13.050911 43755 net.cpp:408] data -> label
I0824 21:59:13.050932 43755 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc6/HDF5Files/train_combined.txt
I0824 21:59:13.051007 43755 hdf5_data_layer.cpp:93] Number of HDF5 files: 50
I0824 21:59:13.052225 43755 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0824 21:59:13.110010 43755 net.cpp:150] Setting up data
I0824 21:59:13.110041 43755 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 21:59:13.110049 43755 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 21:59:13.110054 43755 net.cpp:165] Memory required for data: 24883200
I0824 21:59:13.110062 43755 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 21:59:13.110082 43755 net.cpp:100] Creating Layer label_data_1_split
I0824 21:59:13.110090 43755 net.cpp:434] label_data_1_split <- label
I0824 21:59:13.110108 43755 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 21:59:13.110121 43755 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 21:59:13.110164 43755 net.cpp:150] Setting up label_data_1_split
I0824 21:59:13.110172 43755 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 21:59:13.110177 43755 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 21:59:13.110183 43755 net.cpp:165] Memory required for data: 30412800
I0824 21:59:13.110186 43755 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 21:59:13.110208 43755 net.cpp:100] Creating Layer conv1_1_1
I0824 21:59:13.110213 43755 net.cpp:434] conv1_1_1 <- data
I0824 21:59:13.110219 43755 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 21:59:13.634124 43755 net.cpp:150] Setting up conv1_1_1
I0824 21:59:13.634165 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:13.634169 43755 net.cpp:165] Memory required for data: 207360000
I0824 21:59:13.634202 43755 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 21:59:13.634220 43755 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 21:59:13.634228 43755 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 21:59:13.634243 43755 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 21:59:13.634645 43755 net.cpp:150] Setting up conv1_1_1_bn
I0824 21:59:13.634656 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:13.634665 43755 net.cpp:165] Memory required for data: 384307200
I0824 21:59:13.634680 43755 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 21:59:13.634697 43755 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 21:59:13.634702 43755 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 21:59:13.634708 43755 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 21:59:13.634760 43755 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 21:59:13.636405 43755 net.cpp:150] Setting up conv1_1_1_scale
I0824 21:59:13.636421 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:13.636427 43755 net.cpp:165] Memory required for data: 561254400
I0824 21:59:13.636436 43755 layer_factory.hpp:77] Creating layer relu1_1
I0824 21:59:13.636448 43755 net.cpp:100] Creating Layer relu1_1
I0824 21:59:13.636453 43755 net.cpp:434] relu1_1 <- conv1_1_1
I0824 21:59:13.636461 43755 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 21:59:13.636692 43755 net.cpp:150] Setting up relu1_1
I0824 21:59:13.636703 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:13.636708 43755 net.cpp:165] Memory required for data: 738201600
I0824 21:59:13.636713 43755 layer_factory.hpp:77] Creating layer conv1_2
I0824 21:59:13.636729 43755 net.cpp:100] Creating Layer conv1_2
I0824 21:59:13.636735 43755 net.cpp:434] conv1_2 <- conv1_1_1
I0824 21:59:13.636744 43755 net.cpp:408] conv1_2 -> conv1_2
I0824 21:59:13.640949 43755 net.cpp:150] Setting up conv1_2
I0824 21:59:13.640966 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:13.640976 43755 net.cpp:165] Memory required for data: 915148800
I0824 21:59:13.640988 43755 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 21:59:13.641000 43755 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 21:59:13.641007 43755 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 21:59:13.641013 43755 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 21:59:13.642575 43755 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 21:59:13.642590 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:13.642599 43755 net.cpp:165] Memory required for data: 1092096000
I0824 21:59:13.642609 43755 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 21:59:13.642621 43755 net.cpp:100] Creating Layer conv1_2_scale
I0824 21:59:13.642627 43755 net.cpp:434] conv1_2_scale <- conv1_2
I0824 21:59:13.642633 43755 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 21:59:13.642678 43755 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 21:59:13.643054 43755 net.cpp:150] Setting up conv1_2_scale
I0824 21:59:13.643064 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:13.643069 43755 net.cpp:165] Memory required for data: 1269043200
I0824 21:59:13.643076 43755 layer_factory.hpp:77] Creating layer relu1_2
I0824 21:59:13.643085 43755 net.cpp:100] Creating Layer relu1_2
I0824 21:59:13.643090 43755 net.cpp:434] relu1_2 <- conv1_2
I0824 21:59:13.643095 43755 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 21:59:13.643295 43755 net.cpp:150] Setting up relu1_2
I0824 21:59:13.643304 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:13.643309 43755 net.cpp:165] Memory required for data: 1445990400
I0824 21:59:13.643313 43755 layer_factory.hpp:77] Creating layer pool1
I0824 21:59:13.643321 43755 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 21:59:13.643329 43755 net.cpp:100] Creating Layer pool1
I0824 21:59:13.643334 43755 net.cpp:434] pool1 <- conv1_2
I0824 21:59:13.643339 43755 net.cpp:408] pool1 -> pool1
I0824 21:59:13.643350 43755 net.cpp:408] pool1 -> pool1_mask
I0824 21:59:13.643406 43755 net.cpp:150] Setting up pool1
I0824 21:59:13.643415 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:13.643420 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:13.643424 43755 net.cpp:165] Memory required for data: 1534464000
I0824 21:59:13.643429 43755 layer_factory.hpp:77] Creating layer conv2_1
I0824 21:59:13.643440 43755 net.cpp:100] Creating Layer conv2_1
I0824 21:59:13.643445 43755 net.cpp:434] conv2_1 <- pool1
I0824 21:59:13.643451 43755 net.cpp:408] conv2_1 -> conv2_1
I0824 21:59:13.649602 43755 net.cpp:150] Setting up conv2_1
I0824 21:59:13.649621 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:13.649628 43755 net.cpp:165] Memory required for data: 1622937600
I0824 21:59:13.649637 43755 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 21:59:13.649646 43755 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 21:59:13.649654 43755 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 21:59:13.649660 43755 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 21:59:13.649889 43755 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 21:59:13.649899 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:13.649904 43755 net.cpp:165] Memory required for data: 1711411200
I0824 21:59:13.649917 43755 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 21:59:13.649940 43755 net.cpp:100] Creating Layer conv2_1_scale
I0824 21:59:13.649945 43755 net.cpp:434] conv2_1_scale <- conv2_1
I0824 21:59:13.649950 43755 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 21:59:13.649994 43755 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 21:59:13.650171 43755 net.cpp:150] Setting up conv2_1_scale
I0824 21:59:13.650180 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:13.650185 43755 net.cpp:165] Memory required for data: 1799884800
I0824 21:59:13.650192 43755 layer_factory.hpp:77] Creating layer relu2_1
I0824 21:59:13.650203 43755 net.cpp:100] Creating Layer relu2_1
I0824 21:59:13.650208 43755 net.cpp:434] relu2_1 <- conv2_1
I0824 21:59:13.650213 43755 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 21:59:13.651244 43755 net.cpp:150] Setting up relu2_1
I0824 21:59:13.651259 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:13.651264 43755 net.cpp:165] Memory required for data: 1888358400
I0824 21:59:13.651271 43755 layer_factory.hpp:77] Creating layer conv2_2
I0824 21:59:13.651284 43755 net.cpp:100] Creating Layer conv2_2
I0824 21:59:13.651290 43755 net.cpp:434] conv2_2 <- conv2_1
I0824 21:59:13.651298 43755 net.cpp:408] conv2_2 -> conv2_2
I0824 21:59:13.658682 43755 net.cpp:150] Setting up conv2_2
I0824 21:59:13.658699 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:13.658707 43755 net.cpp:165] Memory required for data: 1976832000
I0824 21:59:13.658716 43755 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 21:59:13.658727 43755 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 21:59:13.658733 43755 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 21:59:13.658740 43755 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 21:59:13.658970 43755 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 21:59:13.658980 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:13.658984 43755 net.cpp:165] Memory required for data: 2065305600
I0824 21:59:13.658993 43755 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 21:59:13.659004 43755 net.cpp:100] Creating Layer conv2_2_scale
I0824 21:59:13.659010 43755 net.cpp:434] conv2_2_scale <- conv2_2
I0824 21:59:13.659015 43755 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 21:59:13.659059 43755 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 21:59:13.659236 43755 net.cpp:150] Setting up conv2_2_scale
I0824 21:59:13.659246 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:13.659251 43755 net.cpp:165] Memory required for data: 2153779200
I0824 21:59:13.659258 43755 layer_factory.hpp:77] Creating layer relu2_2
I0824 21:59:13.659266 43755 net.cpp:100] Creating Layer relu2_2
I0824 21:59:13.659271 43755 net.cpp:434] relu2_2 <- conv2_2
I0824 21:59:13.659277 43755 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 21:59:13.659473 43755 net.cpp:150] Setting up relu2_2
I0824 21:59:13.659483 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:13.659488 43755 net.cpp:165] Memory required for data: 2242252800
I0824 21:59:13.659494 43755 layer_factory.hpp:77] Creating layer pool2
I0824 21:59:13.659499 43755 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 21:59:13.659505 43755 net.cpp:100] Creating Layer pool2
I0824 21:59:13.659510 43755 net.cpp:434] pool2 <- conv2_2
I0824 21:59:13.659518 43755 net.cpp:408] pool2 -> pool2
I0824 21:59:13.659525 43755 net.cpp:408] pool2 -> pool2_mask
I0824 21:59:13.659570 43755 net.cpp:150] Setting up pool2
I0824 21:59:13.659579 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:13.659582 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:13.659587 43755 net.cpp:165] Memory required for data: 2286489600
I0824 21:59:13.659591 43755 layer_factory.hpp:77] Creating layer conv3_1
I0824 21:59:13.659602 43755 net.cpp:100] Creating Layer conv3_1
I0824 21:59:13.659607 43755 net.cpp:434] conv3_1 <- pool2
I0824 21:59:13.659613 43755 net.cpp:408] conv3_1 -> conv3_1
I0824 21:59:13.671824 43755 net.cpp:150] Setting up conv3_1
I0824 21:59:13.671855 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.671866 43755 net.cpp:165] Memory required for data: 2330726400
I0824 21:59:13.671875 43755 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 21:59:13.671882 43755 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 21:59:13.671890 43755 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 21:59:13.671896 43755 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 21:59:13.672113 43755 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 21:59:13.672122 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.672127 43755 net.cpp:165] Memory required for data: 2374963200
I0824 21:59:13.672139 43755 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 21:59:13.672150 43755 net.cpp:100] Creating Layer conv3_1_scale
I0824 21:59:13.672158 43755 net.cpp:434] conv3_1_scale <- conv3_1
I0824 21:59:13.672163 43755 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 21:59:13.672207 43755 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 21:59:13.672343 43755 net.cpp:150] Setting up conv3_1_scale
I0824 21:59:13.672351 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.672355 43755 net.cpp:165] Memory required for data: 2419200000
I0824 21:59:13.672363 43755 layer_factory.hpp:77] Creating layer relu3_1
I0824 21:59:13.672371 43755 net.cpp:100] Creating Layer relu3_1
I0824 21:59:13.672377 43755 net.cpp:434] relu3_1 <- conv3_1
I0824 21:59:13.672382 43755 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 21:59:13.672580 43755 net.cpp:150] Setting up relu3_1
I0824 21:59:13.672591 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.672596 43755 net.cpp:165] Memory required for data: 2463436800
I0824 21:59:13.672600 43755 layer_factory.hpp:77] Creating layer conv3_2
I0824 21:59:13.672613 43755 net.cpp:100] Creating Layer conv3_2
I0824 21:59:13.672619 43755 net.cpp:434] conv3_2 <- conv3_1
I0824 21:59:13.672626 43755 net.cpp:408] conv3_2 -> conv3_2
I0824 21:59:13.695943 43755 net.cpp:150] Setting up conv3_2
I0824 21:59:13.695961 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.695971 43755 net.cpp:165] Memory required for data: 2507673600
I0824 21:59:13.695979 43755 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 21:59:13.695989 43755 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 21:59:13.695998 43755 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 21:59:13.696004 43755 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 21:59:13.696218 43755 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 21:59:13.696228 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.696238 43755 net.cpp:165] Memory required for data: 2551910400
I0824 21:59:13.696246 43755 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 21:59:13.696259 43755 net.cpp:100] Creating Layer conv3_2_scale
I0824 21:59:13.696264 43755 net.cpp:434] conv3_2_scale <- conv3_2
I0824 21:59:13.696269 43755 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 21:59:13.696313 43755 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 21:59:13.696451 43755 net.cpp:150] Setting up conv3_2_scale
I0824 21:59:13.696460 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.696466 43755 net.cpp:165] Memory required for data: 2596147200
I0824 21:59:13.696473 43755 layer_factory.hpp:77] Creating layer relu3_2
I0824 21:59:13.696481 43755 net.cpp:100] Creating Layer relu3_2
I0824 21:59:13.696486 43755 net.cpp:434] relu3_2 <- conv3_2
I0824 21:59:13.696492 43755 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 21:59:13.696696 43755 net.cpp:150] Setting up relu3_2
I0824 21:59:13.696707 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.696712 43755 net.cpp:165] Memory required for data: 2640384000
I0824 21:59:13.696715 43755 layer_factory.hpp:77] Creating layer conv3_3
I0824 21:59:13.696725 43755 net.cpp:100] Creating Layer conv3_3
I0824 21:59:13.696732 43755 net.cpp:434] conv3_3 <- conv3_2
I0824 21:59:13.696738 43755 net.cpp:408] conv3_3 -> conv3_3
I0824 21:59:13.720046 43755 net.cpp:150] Setting up conv3_3
I0824 21:59:13.720078 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.720088 43755 net.cpp:165] Memory required for data: 2684620800
I0824 21:59:13.720096 43755 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 21:59:13.720104 43755 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 21:59:13.720109 43755 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 21:59:13.720115 43755 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 21:59:13.720327 43755 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 21:59:13.720337 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.720340 43755 net.cpp:165] Memory required for data: 2728857600
I0824 21:59:13.720350 43755 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 21:59:13.720361 43755 net.cpp:100] Creating Layer conv3_3_scale
I0824 21:59:13.720371 43755 net.cpp:434] conv3_3_scale <- conv3_3
I0824 21:59:13.720376 43755 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 21:59:13.720424 43755 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 21:59:13.720561 43755 net.cpp:150] Setting up conv3_3_scale
I0824 21:59:13.720571 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.720576 43755 net.cpp:165] Memory required for data: 2773094400
I0824 21:59:13.720582 43755 layer_factory.hpp:77] Creating layer relu3_3
I0824 21:59:13.720590 43755 net.cpp:100] Creating Layer relu3_3
I0824 21:59:13.720597 43755 net.cpp:434] relu3_3 <- conv3_3
I0824 21:59:13.720602 43755 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 21:59:13.720801 43755 net.cpp:150] Setting up relu3_3
I0824 21:59:13.720813 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:13.720818 43755 net.cpp:165] Memory required for data: 2817331200
I0824 21:59:13.720821 43755 layer_factory.hpp:77] Creating layer pool3
I0824 21:59:13.720825 43755 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 21:59:13.720834 43755 net.cpp:100] Creating Layer pool3
I0824 21:59:13.720840 43755 net.cpp:434] pool3 <- conv3_3
I0824 21:59:13.720846 43755 net.cpp:408] pool3 -> pool3
I0824 21:59:13.720855 43755 net.cpp:408] pool3 -> pool3_mask
I0824 21:59:13.720903 43755 net.cpp:150] Setting up pool3
I0824 21:59:13.720911 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:13.720916 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:13.720921 43755 net.cpp:165] Memory required for data: 2839449600
I0824 21:59:13.720924 43755 layer_factory.hpp:77] Creating layer conv4_1
I0824 21:59:13.720937 43755 net.cpp:100] Creating Layer conv4_1
I0824 21:59:13.720942 43755 net.cpp:434] conv4_1 <- pool3
I0824 21:59:13.720949 43755 net.cpp:408] conv4_1 -> conv4_1
I0824 21:59:13.767216 43755 net.cpp:150] Setting up conv4_1
I0824 21:59:13.767235 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.767247 43755 net.cpp:165] Memory required for data: 2861568000
I0824 21:59:13.767258 43755 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 21:59:13.767268 43755 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 21:59:13.767277 43755 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 21:59:13.767284 43755 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 21:59:13.767493 43755 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 21:59:13.767503 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.767506 43755 net.cpp:165] Memory required for data: 2883686400
I0824 21:59:13.767514 43755 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 21:59:13.767524 43755 net.cpp:100] Creating Layer conv4_1_scale
I0824 21:59:13.767531 43755 net.cpp:434] conv4_1_scale <- conv4_1
I0824 21:59:13.767537 43755 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 21:59:13.767580 43755 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 21:59:13.767709 43755 net.cpp:150] Setting up conv4_1_scale
I0824 21:59:13.767717 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.767720 43755 net.cpp:165] Memory required for data: 2905804800
I0824 21:59:13.767727 43755 layer_factory.hpp:77] Creating layer relu4_1
I0824 21:59:13.767752 43755 net.cpp:100] Creating Layer relu4_1
I0824 21:59:13.767757 43755 net.cpp:434] relu4_1 <- conv4_1
I0824 21:59:13.767763 43755 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 21:59:13.767973 43755 net.cpp:150] Setting up relu4_1
I0824 21:59:13.767983 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.767988 43755 net.cpp:165] Memory required for data: 2927923200
I0824 21:59:13.767993 43755 layer_factory.hpp:77] Creating layer conv4_2
I0824 21:59:13.768005 43755 net.cpp:100] Creating Layer conv4_2
I0824 21:59:13.768012 43755 net.cpp:434] conv4_2 <- conv4_1
I0824 21:59:13.768018 43755 net.cpp:408] conv4_2 -> conv4_2
I0824 21:59:13.851924 43755 net.cpp:150] Setting up conv4_2
I0824 21:59:13.851943 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.851948 43755 net.cpp:165] Memory required for data: 2950041600
I0824 21:59:13.851958 43755 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 21:59:13.851968 43755 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 21:59:13.851972 43755 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 21:59:13.851979 43755 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 21:59:13.852185 43755 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 21:59:13.852193 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.852196 43755 net.cpp:165] Memory required for data: 2972160000
I0824 21:59:13.852205 43755 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 21:59:13.852216 43755 net.cpp:100] Creating Layer conv4_2_scale
I0824 21:59:13.852224 43755 net.cpp:434] conv4_2_scale <- conv4_2
I0824 21:59:13.852229 43755 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 21:59:13.852270 43755 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 21:59:13.852397 43755 net.cpp:150] Setting up conv4_2_scale
I0824 21:59:13.852406 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.852416 43755 net.cpp:165] Memory required for data: 2994278400
I0824 21:59:13.852422 43755 layer_factory.hpp:77] Creating layer relu4_2
I0824 21:59:13.852429 43755 net.cpp:100] Creating Layer relu4_2
I0824 21:59:13.852434 43755 net.cpp:434] relu4_2 <- conv4_2
I0824 21:59:13.852440 43755 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 21:59:13.853500 43755 net.cpp:150] Setting up relu4_2
I0824 21:59:13.853516 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.853521 43755 net.cpp:165] Memory required for data: 3016396800
I0824 21:59:13.853526 43755 layer_factory.hpp:77] Creating layer conv4_3
I0824 21:59:13.853540 43755 net.cpp:100] Creating Layer conv4_3
I0824 21:59:13.853546 43755 net.cpp:434] conv4_3 <- conv4_2
I0824 21:59:13.853554 43755 net.cpp:408] conv4_3 -> conv4_3
I0824 21:59:13.937556 43755 net.cpp:150] Setting up conv4_3
I0824 21:59:13.937575 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.937580 43755 net.cpp:165] Memory required for data: 3038515200
I0824 21:59:13.937603 43755 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 21:59:13.937615 43755 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 21:59:13.937623 43755 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 21:59:13.937630 43755 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 21:59:13.937844 43755 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 21:59:13.937852 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.937856 43755 net.cpp:165] Memory required for data: 3060633600
I0824 21:59:13.937865 43755 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 21:59:13.937878 43755 net.cpp:100] Creating Layer conv4_3_scale
I0824 21:59:13.937887 43755 net.cpp:434] conv4_3_scale <- conv4_3
I0824 21:59:13.937893 43755 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 21:59:13.937937 43755 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 21:59:13.938067 43755 net.cpp:150] Setting up conv4_3_scale
I0824 21:59:13.938076 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.938079 43755 net.cpp:165] Memory required for data: 3082752000
I0824 21:59:13.938086 43755 layer_factory.hpp:77] Creating layer relu4_3
I0824 21:59:13.938109 43755 net.cpp:100] Creating Layer relu4_3
I0824 21:59:13.938114 43755 net.cpp:434] relu4_3 <- conv4_3
I0824 21:59:13.938120 43755 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 21:59:13.938323 43755 net.cpp:150] Setting up relu4_3
I0824 21:59:13.938333 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:13.938338 43755 net.cpp:165] Memory required for data: 3104870400
I0824 21:59:13.938341 43755 layer_factory.hpp:77] Creating layer pool4
I0824 21:59:13.938345 43755 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 21:59:13.938354 43755 net.cpp:100] Creating Layer pool4
I0824 21:59:13.938357 43755 net.cpp:434] pool4 <- conv4_3
I0824 21:59:13.938364 43755 net.cpp:408] pool4 -> pool4
I0824 21:59:13.938372 43755 net.cpp:408] pool4 -> pool4_mask
I0824 21:59:13.938421 43755 net.cpp:150] Setting up pool4
I0824 21:59:13.938429 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:13.938434 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:13.938439 43755 net.cpp:165] Memory required for data: 3116175360
I0824 21:59:13.938444 43755 layer_factory.hpp:77] Creating layer conv5_1
I0824 21:59:13.938457 43755 net.cpp:100] Creating Layer conv5_1
I0824 21:59:13.938462 43755 net.cpp:434] conv5_1 <- pool4
I0824 21:59:13.938469 43755 net.cpp:408] conv5_1 -> conv5_1
I0824 21:59:14.023059 43755 net.cpp:150] Setting up conv5_1
I0824 21:59:14.023087 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.023099 43755 net.cpp:165] Memory required for data: 3121827840
I0824 21:59:14.023111 43755 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 21:59:14.023123 43755 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 21:59:14.023130 43755 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 21:59:14.023138 43755 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 21:59:14.023362 43755 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 21:59:14.023371 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.023375 43755 net.cpp:165] Memory required for data: 3127480320
I0824 21:59:14.023385 43755 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 21:59:14.023396 43755 net.cpp:100] Creating Layer conv5_1_scale
I0824 21:59:14.023401 43755 net.cpp:434] conv5_1_scale <- conv5_1
I0824 21:59:14.023406 43755 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 21:59:14.023455 43755 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 21:59:14.023586 43755 net.cpp:150] Setting up conv5_1_scale
I0824 21:59:14.023593 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.023597 43755 net.cpp:165] Memory required for data: 3133132800
I0824 21:59:14.023603 43755 layer_factory.hpp:77] Creating layer relu5_1
I0824 21:59:14.023613 43755 net.cpp:100] Creating Layer relu5_1
I0824 21:59:14.023618 43755 net.cpp:434] relu5_1 <- conv5_1
I0824 21:59:14.023625 43755 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 21:59:14.023834 43755 net.cpp:150] Setting up relu5_1
I0824 21:59:14.023845 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.023850 43755 net.cpp:165] Memory required for data: 3138785280
I0824 21:59:14.023855 43755 layer_factory.hpp:77] Creating layer conv5_2
I0824 21:59:14.023869 43755 net.cpp:100] Creating Layer conv5_2
I0824 21:59:14.023875 43755 net.cpp:434] conv5_2 <- conv5_1
I0824 21:59:14.023883 43755 net.cpp:408] conv5_2 -> conv5_2
I0824 21:59:14.108006 43755 net.cpp:150] Setting up conv5_2
I0824 21:59:14.108024 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.108028 43755 net.cpp:165] Memory required for data: 3144437760
I0824 21:59:14.108036 43755 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 21:59:14.108045 43755 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 21:59:14.108050 43755 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 21:59:14.108058 43755 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 21:59:14.108278 43755 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 21:59:14.108288 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.108309 43755 net.cpp:165] Memory required for data: 3150090240
I0824 21:59:14.108319 43755 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 21:59:14.108330 43755 net.cpp:100] Creating Layer conv5_2_scale
I0824 21:59:14.108337 43755 net.cpp:434] conv5_2_scale <- conv5_2
I0824 21:59:14.108343 43755 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 21:59:14.108399 43755 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 21:59:14.108528 43755 net.cpp:150] Setting up conv5_2_scale
I0824 21:59:14.108536 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.108541 43755 net.cpp:165] Memory required for data: 3155742720
I0824 21:59:14.108547 43755 layer_factory.hpp:77] Creating layer relu5_2
I0824 21:59:14.108556 43755 net.cpp:100] Creating Layer relu5_2
I0824 21:59:14.108561 43755 net.cpp:434] relu5_2 <- conv5_2
I0824 21:59:14.108567 43755 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 21:59:14.108775 43755 net.cpp:150] Setting up relu5_2
I0824 21:59:14.108785 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.108790 43755 net.cpp:165] Memory required for data: 3161395200
I0824 21:59:14.108795 43755 layer_factory.hpp:77] Creating layer conv5_3
I0824 21:59:14.108808 43755 net.cpp:100] Creating Layer conv5_3
I0824 21:59:14.108814 43755 net.cpp:434] conv5_3 <- conv5_2
I0824 21:59:14.108821 43755 net.cpp:408] conv5_3 -> conv5_3
I0824 21:59:14.192803 43755 net.cpp:150] Setting up conv5_3
I0824 21:59:14.192821 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.192826 43755 net.cpp:165] Memory required for data: 3167047680
I0824 21:59:14.192833 43755 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 21:59:14.192844 43755 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 21:59:14.192849 43755 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 21:59:14.192857 43755 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 21:59:14.193084 43755 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 21:59:14.193092 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.193096 43755 net.cpp:165] Memory required for data: 3172700160
I0824 21:59:14.193106 43755 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 21:59:14.193115 43755 net.cpp:100] Creating Layer conv5_3_scale
I0824 21:59:14.193123 43755 net.cpp:434] conv5_3_scale <- conv5_3
I0824 21:59:14.193130 43755 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 21:59:14.193182 43755 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 21:59:14.193310 43755 net.cpp:150] Setting up conv5_3_scale
I0824 21:59:14.193320 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.193322 43755 net.cpp:165] Memory required for data: 3178352640
I0824 21:59:14.193331 43755 layer_factory.hpp:77] Creating layer relu5_3
I0824 21:59:14.193339 43755 net.cpp:100] Creating Layer relu5_3
I0824 21:59:14.193344 43755 net.cpp:434] relu5_3 <- conv5_3
I0824 21:59:14.193351 43755 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 21:59:14.193567 43755 net.cpp:150] Setting up relu5_3
I0824 21:59:14.193578 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.193581 43755 net.cpp:165] Memory required for data: 3184005120
I0824 21:59:14.193588 43755 layer_factory.hpp:77] Creating layer pool5
I0824 21:59:14.193593 43755 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 21:59:14.193601 43755 net.cpp:100] Creating Layer pool5
I0824 21:59:14.193606 43755 net.cpp:434] pool5 <- conv5_3
I0824 21:59:14.193615 43755 net.cpp:408] pool5 -> pool5
I0824 21:59:14.193624 43755 net.cpp:408] pool5 -> pool5_mask
I0824 21:59:14.193677 43755 net.cpp:150] Setting up pool5
I0824 21:59:14.193686 43755 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 21:59:14.193691 43755 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 21:59:14.193696 43755 net.cpp:165] Memory required for data: 3186954240
I0824 21:59:14.193698 43755 layer_factory.hpp:77] Creating layer upsample5
I0824 21:59:14.193712 43755 net.cpp:100] Creating Layer upsample5
I0824 21:59:14.193717 43755 net.cpp:434] upsample5 <- pool5
I0824 21:59:14.193737 43755 net.cpp:434] upsample5 <- pool5_mask
I0824 21:59:14.193745 43755 net.cpp:408] upsample5 -> pool5_D
I0824 21:59:14.193789 43755 net.cpp:150] Setting up upsample5
I0824 21:59:14.193797 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.193800 43755 net.cpp:165] Memory required for data: 3192606720
I0824 21:59:14.193804 43755 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 21:59:14.193816 43755 net.cpp:100] Creating Layer conv5_3_D
I0824 21:59:14.193822 43755 net.cpp:434] conv5_3_D <- pool5_D
I0824 21:59:14.193830 43755 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 21:59:14.278681 43755 net.cpp:150] Setting up conv5_3_D
I0824 21:59:14.278700 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.278704 43755 net.cpp:165] Memory required for data: 3198259200
I0824 21:59:14.278713 43755 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 21:59:14.278729 43755 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 21:59:14.278736 43755 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 21:59:14.278744 43755 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 21:59:14.278972 43755 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 21:59:14.278981 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.278985 43755 net.cpp:165] Memory required for data: 3203911680
I0824 21:59:14.278995 43755 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 21:59:14.279011 43755 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 21:59:14.279018 43755 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 21:59:14.279024 43755 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 21:59:14.279075 43755 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 21:59:14.279206 43755 net.cpp:150] Setting up conv5_3_D_scale
I0824 21:59:14.279214 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.279217 43755 net.cpp:165] Memory required for data: 3209564160
I0824 21:59:14.279224 43755 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 21:59:14.279232 43755 net.cpp:100] Creating Layer relu5_3_D
I0824 21:59:14.279237 43755 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 21:59:14.279244 43755 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 21:59:14.279464 43755 net.cpp:150] Setting up relu5_3_D
I0824 21:59:14.279474 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.279479 43755 net.cpp:165] Memory required for data: 3215216640
I0824 21:59:14.279484 43755 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 21:59:14.279520 43755 net.cpp:100] Creating Layer conv5_2_D
I0824 21:59:14.279526 43755 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 21:59:14.279534 43755 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 21:59:14.363747 43755 net.cpp:150] Setting up conv5_2_D
I0824 21:59:14.363766 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.363770 43755 net.cpp:165] Memory required for data: 3220869120
I0824 21:59:14.363786 43755 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 21:59:14.363797 43755 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 21:59:14.363804 43755 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 21:59:14.363812 43755 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 21:59:14.364042 43755 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 21:59:14.364050 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.364054 43755 net.cpp:165] Memory required for data: 3226521600
I0824 21:59:14.364063 43755 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 21:59:14.364073 43755 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 21:59:14.364078 43755 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 21:59:14.364084 43755 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 21:59:14.364135 43755 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 21:59:14.364266 43755 net.cpp:150] Setting up conv5_2_D_scale
I0824 21:59:14.364274 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.364279 43755 net.cpp:165] Memory required for data: 3232174080
I0824 21:59:14.364302 43755 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 21:59:14.364312 43755 net.cpp:100] Creating Layer relu5_2_D
I0824 21:59:14.364317 43755 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 21:59:14.364325 43755 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 21:59:14.365442 43755 net.cpp:150] Setting up relu5_2_D
I0824 21:59:14.365458 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.365463 43755 net.cpp:165] Memory required for data: 3237826560
I0824 21:59:14.365468 43755 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 21:59:14.365481 43755 net.cpp:100] Creating Layer conv5_1_D
I0824 21:59:14.365487 43755 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 21:59:14.365496 43755 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 21:59:14.449589 43755 net.cpp:150] Setting up conv5_1_D
I0824 21:59:14.449607 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.449611 43755 net.cpp:165] Memory required for data: 3243479040
I0824 21:59:14.449620 43755 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 21:59:14.449630 43755 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 21:59:14.449638 43755 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 21:59:14.449646 43755 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 21:59:14.449879 43755 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 21:59:14.449889 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.449898 43755 net.cpp:165] Memory required for data: 3249131520
I0824 21:59:14.449908 43755 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 21:59:14.449916 43755 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 21:59:14.449923 43755 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 21:59:14.449929 43755 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 21:59:14.449982 43755 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 21:59:14.450119 43755 net.cpp:150] Setting up conv5_1_D_scale
I0824 21:59:14.450127 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.450131 43755 net.cpp:165] Memory required for data: 3254784000
I0824 21:59:14.450137 43755 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 21:59:14.450147 43755 net.cpp:100] Creating Layer relu5_1_D
I0824 21:59:14.450153 43755 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 21:59:14.450160 43755 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 21:59:14.450367 43755 net.cpp:150] Setting up relu5_1_D
I0824 21:59:14.450377 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:14.450382 43755 net.cpp:165] Memory required for data: 3260436480
I0824 21:59:14.450387 43755 layer_factory.hpp:77] Creating layer upsample4
I0824 21:59:14.450395 43755 net.cpp:100] Creating Layer upsample4
I0824 21:59:14.450400 43755 net.cpp:434] upsample4 <- conv5_1_D
I0824 21:59:14.450407 43755 net.cpp:434] upsample4 <- pool4_mask
I0824 21:59:14.450415 43755 net.cpp:408] upsample4 -> pool4_D
I0824 21:59:14.450450 43755 net.cpp:150] Setting up upsample4
I0824 21:59:14.450458 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.450461 43755 net.cpp:165] Memory required for data: 3282554880
I0824 21:59:14.450464 43755 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 21:59:14.450479 43755 net.cpp:100] Creating Layer conv4_3_D
I0824 21:59:14.450485 43755 net.cpp:434] conv4_3_D <- pool4_D
I0824 21:59:14.450492 43755 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 21:59:14.536439 43755 net.cpp:150] Setting up conv4_3_D
I0824 21:59:14.536463 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.536473 43755 net.cpp:165] Memory required for data: 3304673280
I0824 21:59:14.536484 43755 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 21:59:14.536499 43755 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 21:59:14.536510 43755 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 21:59:14.536520 43755 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 21:59:14.536757 43755 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 21:59:14.536767 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.536788 43755 net.cpp:165] Memory required for data: 3326791680
I0824 21:59:14.536799 43755 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 21:59:14.536810 43755 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 21:59:14.536815 43755 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 21:59:14.536821 43755 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 21:59:14.536870 43755 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 21:59:14.537017 43755 net.cpp:150] Setting up conv4_3_D_scale
I0824 21:59:14.537026 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.537031 43755 net.cpp:165] Memory required for data: 3348910080
I0824 21:59:14.537039 43755 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 21:59:14.537047 43755 net.cpp:100] Creating Layer relu4_3_D
I0824 21:59:14.537052 43755 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 21:59:14.537058 43755 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 21:59:14.537264 43755 net.cpp:150] Setting up relu4_3_D
I0824 21:59:14.537274 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.537279 43755 net.cpp:165] Memory required for data: 3371028480
I0824 21:59:14.537283 43755 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 21:59:14.537297 43755 net.cpp:100] Creating Layer conv4_2_D
I0824 21:59:14.537303 43755 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 21:59:14.537313 43755 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 21:59:14.621474 43755 net.cpp:150] Setting up conv4_2_D
I0824 21:59:14.621492 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.621496 43755 net.cpp:165] Memory required for data: 3393146880
I0824 21:59:14.621505 43755 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 21:59:14.621522 43755 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 21:59:14.621529 43755 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 21:59:14.621537 43755 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 21:59:14.621773 43755 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 21:59:14.621781 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.621791 43755 net.cpp:165] Memory required for data: 3415265280
I0824 21:59:14.621799 43755 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 21:59:14.621810 43755 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 21:59:14.621815 43755 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 21:59:14.621821 43755 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 21:59:14.621866 43755 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 21:59:14.622015 43755 net.cpp:150] Setting up conv4_2_D_scale
I0824 21:59:14.622023 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.622027 43755 net.cpp:165] Memory required for data: 3437383680
I0824 21:59:14.622035 43755 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 21:59:14.622042 43755 net.cpp:100] Creating Layer relu4_2_D
I0824 21:59:14.622047 43755 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 21:59:14.622054 43755 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 21:59:14.622262 43755 net.cpp:150] Setting up relu4_2_D
I0824 21:59:14.622272 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.622277 43755 net.cpp:165] Memory required for data: 3459502080
I0824 21:59:14.622282 43755 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 21:59:14.622297 43755 net.cpp:100] Creating Layer conv4_1_D
I0824 21:59:14.622303 43755 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 21:59:14.622310 43755 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 21:59:14.666383 43755 net.cpp:150] Setting up conv4_1_D
I0824 21:59:14.666401 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:14.666414 43755 net.cpp:165] Memory required for data: 3470561280
I0824 21:59:14.666422 43755 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 21:59:14.666437 43755 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 21:59:14.666445 43755 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 21:59:14.666450 43755 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 21:59:14.666690 43755 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 21:59:14.666714 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:14.666721 43755 net.cpp:165] Memory required for data: 3481620480
I0824 21:59:14.666776 43755 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 21:59:14.666786 43755 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 21:59:14.666792 43755 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 21:59:14.666798 43755 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 21:59:14.666854 43755 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 21:59:14.666996 43755 net.cpp:150] Setting up conv4_1_D_scale
I0824 21:59:14.667004 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:14.667009 43755 net.cpp:165] Memory required for data: 3492679680
I0824 21:59:14.667016 43755 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 21:59:14.667026 43755 net.cpp:100] Creating Layer relu4_1_D
I0824 21:59:14.667031 43755 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 21:59:14.667037 43755 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 21:59:14.667258 43755 net.cpp:150] Setting up relu4_1_D
I0824 21:59:14.667268 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:14.667273 43755 net.cpp:165] Memory required for data: 3503738880
I0824 21:59:14.667276 43755 layer_factory.hpp:77] Creating layer upsample3
I0824 21:59:14.667286 43755 net.cpp:100] Creating Layer upsample3
I0824 21:59:14.667292 43755 net.cpp:434] upsample3 <- conv4_1_D
I0824 21:59:14.667299 43755 net.cpp:434] upsample3 <- pool3_mask
I0824 21:59:14.667307 43755 net.cpp:408] upsample3 -> pool3_D
I0824 21:59:14.667316 43755 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 21:59:14.667349 43755 net.cpp:150] Setting up upsample3
I0824 21:59:14.667357 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.667362 43755 net.cpp:165] Memory required for data: 3547975680
I0824 21:59:14.667366 43755 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 21:59:14.667378 43755 net.cpp:100] Creating Layer conv3_3_D
I0824 21:59:14.667383 43755 net.cpp:434] conv3_3_D <- pool3_D
I0824 21:59:14.667392 43755 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 21:59:14.691541 43755 net.cpp:150] Setting up conv3_3_D
I0824 21:59:14.691572 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.691581 43755 net.cpp:165] Memory required for data: 3592212480
I0824 21:59:14.691597 43755 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 21:59:14.691617 43755 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 21:59:14.691628 43755 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 21:59:14.691637 43755 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 21:59:14.691917 43755 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 21:59:14.691926 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.691931 43755 net.cpp:165] Memory required for data: 3636449280
I0824 21:59:14.691939 43755 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 21:59:14.691954 43755 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 21:59:14.691959 43755 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 21:59:14.691965 43755 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 21:59:14.692018 43755 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 21:59:14.692203 43755 net.cpp:150] Setting up conv3_3_D_scale
I0824 21:59:14.692212 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.692215 43755 net.cpp:165] Memory required for data: 3680686080
I0824 21:59:14.692222 43755 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 21:59:14.692236 43755 net.cpp:100] Creating Layer relu3_3_D
I0824 21:59:14.692242 43755 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 21:59:14.692251 43755 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 21:59:14.692487 43755 net.cpp:150] Setting up relu3_3_D
I0824 21:59:14.692497 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.692500 43755 net.cpp:165] Memory required for data: 3724922880
I0824 21:59:14.692524 43755 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 21:59:14.692543 43755 net.cpp:100] Creating Layer conv3_2_D
I0824 21:59:14.692548 43755 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 21:59:14.692560 43755 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 21:59:14.716359 43755 net.cpp:150] Setting up conv3_2_D
I0824 21:59:14.716375 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.716387 43755 net.cpp:165] Memory required for data: 3769159680
I0824 21:59:14.716395 43755 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 21:59:14.716418 43755 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 21:59:14.716425 43755 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 21:59:14.716434 43755 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 21:59:14.716688 43755 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 21:59:14.716696 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.716701 43755 net.cpp:165] Memory required for data: 3813396480
I0824 21:59:14.716709 43755 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 21:59:14.716717 43755 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 21:59:14.716722 43755 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 21:59:14.716728 43755 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 21:59:14.716776 43755 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 21:59:14.716941 43755 net.cpp:150] Setting up conv3_2_D_scale
I0824 21:59:14.716951 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.716954 43755 net.cpp:165] Memory required for data: 3857633280
I0824 21:59:14.716961 43755 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 21:59:14.716974 43755 net.cpp:100] Creating Layer relu3_2_D
I0824 21:59:14.716979 43755 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 21:59:14.716984 43755 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 21:59:14.718122 43755 net.cpp:150] Setting up relu3_2_D
I0824 21:59:14.718135 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.718139 43755 net.cpp:165] Memory required for data: 3901870080
I0824 21:59:14.718144 43755 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 21:59:14.718166 43755 net.cpp:100] Creating Layer conv3_1_D
I0824 21:59:14.718173 43755 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 21:59:14.718180 43755 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 21:59:14.732116 43755 net.cpp:150] Setting up conv3_1_D
I0824 21:59:14.732133 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:14.732137 43755 net.cpp:165] Memory required for data: 3923988480
I0824 21:59:14.732148 43755 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 21:59:14.732164 43755 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 21:59:14.732173 43755 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 21:59:14.732180 43755 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 21:59:14.732439 43755 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 21:59:14.732447 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:14.732451 43755 net.cpp:165] Memory required for data: 3946106880
I0824 21:59:14.732460 43755 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 21:59:14.732467 43755 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 21:59:14.732473 43755 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 21:59:14.732480 43755 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 21:59:14.732532 43755 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 21:59:14.732702 43755 net.cpp:150] Setting up conv3_1_D_scale
I0824 21:59:14.732709 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:14.732713 43755 net.cpp:165] Memory required for data: 3968225280
I0824 21:59:14.732720 43755 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 21:59:14.732739 43755 net.cpp:100] Creating Layer relu3_1_D
I0824 21:59:14.732744 43755 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 21:59:14.732756 43755 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 21:59:14.732977 43755 net.cpp:150] Setting up relu3_1_D
I0824 21:59:14.733001 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:14.733006 43755 net.cpp:165] Memory required for data: 3990343680
I0824 21:59:14.733009 43755 layer_factory.hpp:77] Creating layer upsample2
I0824 21:59:14.733021 43755 net.cpp:100] Creating Layer upsample2
I0824 21:59:14.733026 43755 net.cpp:434] upsample2 <- conv3_1_D
I0824 21:59:14.733031 43755 net.cpp:434] upsample2 <- pool2_mask
I0824 21:59:14.733037 43755 net.cpp:408] upsample2 -> pool2_D
I0824 21:59:14.733047 43755 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 21:59:14.733083 43755 net.cpp:150] Setting up upsample2
I0824 21:59:14.733091 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.733094 43755 net.cpp:165] Memory required for data: 4078817280
I0824 21:59:14.733098 43755 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 21:59:14.733109 43755 net.cpp:100] Creating Layer conv2_2_D
I0824 21:59:14.733114 43755 net.cpp:434] conv2_2_D <- pool2_D
I0824 21:59:14.733122 43755 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 21:59:14.740885 43755 net.cpp:150] Setting up conv2_2_D
I0824 21:59:14.740900 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.740905 43755 net.cpp:165] Memory required for data: 4167290880
I0824 21:59:14.740912 43755 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 21:59:14.740931 43755 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 21:59:14.740938 43755 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 21:59:14.740947 43755 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 21:59:14.741259 43755 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 21:59:14.741268 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.741272 43755 net.cpp:165] Memory required for data: 4255764480
I0824 21:59:14.741286 43755 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 21:59:14.741298 43755 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 21:59:14.741305 43755 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 21:59:14.741310 43755 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 21:59:14.741363 43755 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 21:59:14.742951 43755 net.cpp:150] Setting up conv2_2_D_scale
I0824 21:59:14.742966 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.742975 43755 net.cpp:165] Memory required for data: 4344238080
I0824 21:59:14.742986 43755 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 21:59:14.742995 43755 net.cpp:100] Creating Layer relu2_2_D
I0824 21:59:14.742998 43755 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 21:59:14.743008 43755 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 21:59:14.743238 43755 net.cpp:150] Setting up relu2_2_D
I0824 21:59:14.743247 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.743252 43755 net.cpp:165] Memory required for data: 4432711680
I0824 21:59:14.743254 43755 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 21:59:14.743271 43755 net.cpp:100] Creating Layer conv2_1_D
I0824 21:59:14.743276 43755 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 21:59:14.743288 43755 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 21:59:14.748569 43755 net.cpp:150] Setting up conv2_1_D
I0824 21:59:14.748585 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:14.748594 43755 net.cpp:165] Memory required for data: 4476948480
I0824 21:59:14.748602 43755 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 21:59:14.748621 43755 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 21:59:14.748628 43755 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 21:59:14.748636 43755 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 21:59:14.748930 43755 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 21:59:14.748939 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:14.748942 43755 net.cpp:165] Memory required for data: 4521185280
I0824 21:59:14.748957 43755 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 21:59:14.748983 43755 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 21:59:14.748988 43755 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 21:59:14.748993 43755 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 21:59:14.749047 43755 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 21:59:14.749266 43755 net.cpp:150] Setting up conv2_1_D_scale
I0824 21:59:14.749275 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:14.749279 43755 net.cpp:165] Memory required for data: 4565422080
I0824 21:59:14.749285 43755 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 21:59:14.749292 43755 net.cpp:100] Creating Layer relu2_1_D
I0824 21:59:14.749296 43755 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 21:59:14.749302 43755 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 21:59:14.749553 43755 net.cpp:150] Setting up relu2_1_D
I0824 21:59:14.749563 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:14.749567 43755 net.cpp:165] Memory required for data: 4609658880
I0824 21:59:14.749572 43755 layer_factory.hpp:77] Creating layer upsample1
I0824 21:59:14.749585 43755 net.cpp:100] Creating Layer upsample1
I0824 21:59:14.749591 43755 net.cpp:434] upsample1 <- conv2_1_D
I0824 21:59:14.749598 43755 net.cpp:434] upsample1 <- pool1_mask
I0824 21:59:14.749604 43755 net.cpp:408] upsample1 -> pool1_D
I0824 21:59:14.749614 43755 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 21:59:14.749646 43755 net.cpp:150] Setting up upsample1
I0824 21:59:14.749653 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.749656 43755 net.cpp:165] Memory required for data: 4786606080
I0824 21:59:14.749660 43755 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 21:59:14.749673 43755 net.cpp:100] Creating Layer conv1_2_D
I0824 21:59:14.749678 43755 net.cpp:434] conv1_2_D <- pool1_D
I0824 21:59:14.749686 43755 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 21:59:14.754267 43755 net.cpp:150] Setting up conv1_2_D
I0824 21:59:14.754283 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.754293 43755 net.cpp:165] Memory required for data: 4963553280
I0824 21:59:14.754308 43755 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 21:59:14.754317 43755 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 21:59:14.754323 43755 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 21:59:14.754330 43755 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 21:59:14.754727 43755 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 21:59:14.754735 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.754739 43755 net.cpp:165] Memory required for data: 5140500480
I0824 21:59:14.754748 43755 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 21:59:14.754761 43755 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 21:59:14.754767 43755 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 21:59:14.754775 43755 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 21:59:14.754824 43755 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 21:59:14.756527 43755 net.cpp:150] Setting up conv1_2_D_scale
I0824 21:59:14.756541 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.756546 43755 net.cpp:165] Memory required for data: 5317447680
I0824 21:59:14.756554 43755 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 21:59:14.756563 43755 net.cpp:100] Creating Layer relu1_2_D
I0824 21:59:14.756569 43755 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 21:59:14.756574 43755 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 21:59:14.756814 43755 net.cpp:150] Setting up relu1_2_D
I0824 21:59:14.756824 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.756827 43755 net.cpp:165] Memory required for data: 5494394880
I0824 21:59:14.756830 43755 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 21:59:14.756844 43755 net.cpp:100] Creating Layer conv1_1_1_D
I0824 21:59:14.756850 43755 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 21:59:14.756873 43755 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 21:59:14.758961 43755 net.cpp:150] Setting up conv1_1_1_D
I0824 21:59:14.758977 43755 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 21:59:14.758981 43755 net.cpp:165] Memory required for data: 5499924480
I0824 21:59:14.758991 43755 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 21:59:14.759001 43755 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 21:59:14.759007 43755 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 21:59:14.759016 43755 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 21:59:14.759026 43755 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 21:59:14.759078 43755 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 21:59:14.759088 43755 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 21:59:14.759093 43755 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 21:59:14.759095 43755 net.cpp:165] Memory required for data: 5510983680
I0824 21:59:14.759106 43755 layer_factory.hpp:77] Creating layer loss
I0824 21:59:14.759126 43755 net.cpp:100] Creating Layer loss
I0824 21:59:14.759132 43755 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 21:59:14.759137 43755 net.cpp:434] loss <- label_data_1_split_0
I0824 21:59:14.759145 43755 net.cpp:408] loss -> loss
I0824 21:59:14.759163 43755 layer_factory.hpp:77] Creating layer loss
I0824 21:59:14.763335 43755 net.cpp:150] Setting up loss
I0824 21:59:14.763350 43755 net.cpp:157] Top shape: (1)
I0824 21:59:14.763355 43755 net.cpp:160]     with loss weight 1
I0824 21:59:14.763408 43755 net.cpp:165] Memory required for data: 5510983684
I0824 21:59:14.763415 43755 layer_factory.hpp:77] Creating layer accuracy
I0824 21:59:14.763425 43755 net.cpp:100] Creating Layer accuracy
I0824 21:59:14.763432 43755 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 21:59:14.763438 43755 net.cpp:434] accuracy <- label_data_1_split_1
I0824 21:59:14.763444 43755 net.cpp:408] accuracy -> accuracy
I0824 21:59:14.763453 43755 net.cpp:408] accuracy -> per_class_accuracy
I0824 21:59:14.763507 43755 net.cpp:150] Setting up accuracy
I0824 21:59:14.763515 43755 net.cpp:157] Top shape: (1)
I0824 21:59:14.763520 43755 net.cpp:157] Top shape: 2 (2)
I0824 21:59:14.763522 43755 net.cpp:165] Memory required for data: 5510983696
I0824 21:59:14.763526 43755 net.cpp:228] accuracy does not need backward computation.
I0824 21:59:14.763530 43755 net.cpp:226] loss needs backward computation.
I0824 21:59:14.763535 43755 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 21:59:14.763540 43755 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 21:59:14.763545 43755 net.cpp:226] relu1_2_D needs backward computation.
I0824 21:59:14.763547 43755 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 21:59:14.763551 43755 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 21:59:14.763555 43755 net.cpp:226] conv1_2_D needs backward computation.
I0824 21:59:14.763558 43755 net.cpp:226] upsample1 needs backward computation.
I0824 21:59:14.763562 43755 net.cpp:226] relu2_1_D needs backward computation.
I0824 21:59:14.763566 43755 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 21:59:14.763569 43755 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 21:59:14.763573 43755 net.cpp:226] conv2_1_D needs backward computation.
I0824 21:59:14.763576 43755 net.cpp:226] relu2_2_D needs backward computation.
I0824 21:59:14.763579 43755 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 21:59:14.763583 43755 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 21:59:14.763587 43755 net.cpp:226] conv2_2_D needs backward computation.
I0824 21:59:14.763591 43755 net.cpp:226] upsample2 needs backward computation.
I0824 21:59:14.763595 43755 net.cpp:226] relu3_1_D needs backward computation.
I0824 21:59:14.763599 43755 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 21:59:14.763618 43755 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 21:59:14.763622 43755 net.cpp:226] conv3_1_D needs backward computation.
I0824 21:59:14.763626 43755 net.cpp:226] relu3_2_D needs backward computation.
I0824 21:59:14.763629 43755 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 21:59:14.763633 43755 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 21:59:14.763636 43755 net.cpp:226] conv3_2_D needs backward computation.
I0824 21:59:14.763641 43755 net.cpp:226] relu3_3_D needs backward computation.
I0824 21:59:14.763645 43755 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 21:59:14.763650 43755 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 21:59:14.763653 43755 net.cpp:226] conv3_3_D needs backward computation.
I0824 21:59:14.763659 43755 net.cpp:226] upsample3 needs backward computation.
I0824 21:59:14.763664 43755 net.cpp:226] relu4_1_D needs backward computation.
I0824 21:59:14.763666 43755 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 21:59:14.763670 43755 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 21:59:14.763674 43755 net.cpp:226] conv4_1_D needs backward computation.
I0824 21:59:14.763679 43755 net.cpp:226] relu4_2_D needs backward computation.
I0824 21:59:14.763684 43755 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 21:59:14.763689 43755 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 21:59:14.763692 43755 net.cpp:226] conv4_2_D needs backward computation.
I0824 21:59:14.763695 43755 net.cpp:226] relu4_3_D needs backward computation.
I0824 21:59:14.763700 43755 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 21:59:14.763703 43755 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 21:59:14.763707 43755 net.cpp:226] conv4_3_D needs backward computation.
I0824 21:59:14.763712 43755 net.cpp:226] upsample4 needs backward computation.
I0824 21:59:14.763720 43755 net.cpp:226] relu5_1_D needs backward computation.
I0824 21:59:14.763725 43755 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 21:59:14.763728 43755 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 21:59:14.763732 43755 net.cpp:226] conv5_1_D needs backward computation.
I0824 21:59:14.763737 43755 net.cpp:226] relu5_2_D needs backward computation.
I0824 21:59:14.763742 43755 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 21:59:14.763746 43755 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 21:59:14.763751 43755 net.cpp:226] conv5_2_D needs backward computation.
I0824 21:59:14.763756 43755 net.cpp:226] relu5_3_D needs backward computation.
I0824 21:59:14.763761 43755 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 21:59:14.763766 43755 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 21:59:14.763769 43755 net.cpp:226] conv5_3_D needs backward computation.
I0824 21:59:14.763773 43755 net.cpp:226] upsample5 needs backward computation.
I0824 21:59:14.763778 43755 net.cpp:226] pool5 needs backward computation.
I0824 21:59:14.763783 43755 net.cpp:226] relu5_3 needs backward computation.
I0824 21:59:14.763789 43755 net.cpp:226] conv5_3_scale needs backward computation.
I0824 21:59:14.763793 43755 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 21:59:14.763797 43755 net.cpp:226] conv5_3 needs backward computation.
I0824 21:59:14.763803 43755 net.cpp:226] relu5_2 needs backward computation.
I0824 21:59:14.763806 43755 net.cpp:226] conv5_2_scale needs backward computation.
I0824 21:59:14.763810 43755 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 21:59:14.763814 43755 net.cpp:226] conv5_2 needs backward computation.
I0824 21:59:14.763818 43755 net.cpp:226] relu5_1 needs backward computation.
I0824 21:59:14.763824 43755 net.cpp:226] conv5_1_scale needs backward computation.
I0824 21:59:14.763830 43755 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 21:59:14.763834 43755 net.cpp:226] conv5_1 needs backward computation.
I0824 21:59:14.763839 43755 net.cpp:226] pool4 needs backward computation.
I0824 21:59:14.763852 43755 net.cpp:226] relu4_3 needs backward computation.
I0824 21:59:14.763856 43755 net.cpp:226] conv4_3_scale needs backward computation.
I0824 21:59:14.763860 43755 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 21:59:14.763864 43755 net.cpp:226] conv4_3 needs backward computation.
I0824 21:59:14.763871 43755 net.cpp:226] relu4_2 needs backward computation.
I0824 21:59:14.763876 43755 net.cpp:226] conv4_2_scale needs backward computation.
I0824 21:59:14.763880 43755 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 21:59:14.763885 43755 net.cpp:226] conv4_2 needs backward computation.
I0824 21:59:14.763890 43755 net.cpp:226] relu4_1 needs backward computation.
I0824 21:59:14.763893 43755 net.cpp:226] conv4_1_scale needs backward computation.
I0824 21:59:14.763896 43755 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 21:59:14.763900 43755 net.cpp:226] conv4_1 needs backward computation.
I0824 21:59:14.763906 43755 net.cpp:226] pool3 needs backward computation.
I0824 21:59:14.763911 43755 net.cpp:226] relu3_3 needs backward computation.
I0824 21:59:14.763916 43755 net.cpp:226] conv3_3_scale needs backward computation.
I0824 21:59:14.763919 43755 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 21:59:14.763926 43755 net.cpp:226] conv3_3 needs backward computation.
I0824 21:59:14.763931 43755 net.cpp:226] relu3_2 needs backward computation.
I0824 21:59:14.763934 43755 net.cpp:226] conv3_2_scale needs backward computation.
I0824 21:59:14.763938 43755 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 21:59:14.763942 43755 net.cpp:226] conv3_2 needs backward computation.
I0824 21:59:14.763947 43755 net.cpp:226] relu3_1 needs backward computation.
I0824 21:59:14.763952 43755 net.cpp:226] conv3_1_scale needs backward computation.
I0824 21:59:14.763955 43755 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 21:59:14.763959 43755 net.cpp:226] conv3_1 needs backward computation.
I0824 21:59:14.763963 43755 net.cpp:226] pool2 needs backward computation.
I0824 21:59:14.763968 43755 net.cpp:226] relu2_2 needs backward computation.
I0824 21:59:14.763973 43755 net.cpp:226] conv2_2_scale needs backward computation.
I0824 21:59:14.763978 43755 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 21:59:14.763983 43755 net.cpp:226] conv2_2 needs backward computation.
I0824 21:59:14.763988 43755 net.cpp:226] relu2_1 needs backward computation.
I0824 21:59:14.763993 43755 net.cpp:226] conv2_1_scale needs backward computation.
I0824 21:59:14.763999 43755 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 21:59:14.764003 43755 net.cpp:226] conv2_1 needs backward computation.
I0824 21:59:14.764011 43755 net.cpp:226] pool1 needs backward computation.
I0824 21:59:14.764015 43755 net.cpp:226] relu1_2 needs backward computation.
I0824 21:59:14.764021 43755 net.cpp:226] conv1_2_scale needs backward computation.
I0824 21:59:14.764026 43755 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 21:59:14.764030 43755 net.cpp:226] conv1_2 needs backward computation.
I0824 21:59:14.764034 43755 net.cpp:226] relu1_1 needs backward computation.
I0824 21:59:14.764039 43755 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 21:59:14.764042 43755 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 21:59:14.764045 43755 net.cpp:226] conv1_1_1 needs backward computation.
I0824 21:59:14.764052 43755 net.cpp:228] label_data_1_split does not need backward computation.
I0824 21:59:14.764057 43755 net.cpp:228] data does not need backward computation.
I0824 21:59:14.764062 43755 net.cpp:270] This network produces output accuracy
I0824 21:59:14.764066 43755 net.cpp:270] This network produces output loss
I0824 21:59:14.764070 43755 net.cpp:270] This network produces output per_class_accuracy
I0824 21:59:14.764137 43755 net.cpp:283] Network initialization done.
I0824 21:59:14.766657 43755 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc6/caffe/model_segnet_final/train.prototxt
I0824 21:59:14.767355 43755 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc6/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 21:59:14.767788 43755 layer_factory.hpp:77] Creating layer data
I0824 21:59:14.767802 43755 net.cpp:100] Creating Layer data
I0824 21:59:14.767807 43755 net.cpp:408] data -> data
I0824 21:59:14.767815 43755 net.cpp:408] data -> label
I0824 21:59:14.767824 43755 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc6/HDF5Files/train_combined.txt
I0824 21:59:14.767879 43755 hdf5_data_layer.cpp:93] Number of HDF5 files: 50
I0824 21:59:14.801591 43755 net.cpp:150] Setting up data
I0824 21:59:14.801614 43755 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 21:59:14.801620 43755 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 21:59:14.801623 43755 net.cpp:165] Memory required for data: 24883200
I0824 21:59:14.801628 43755 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 21:59:14.801638 43755 net.cpp:100] Creating Layer label_data_1_split
I0824 21:59:14.801642 43755 net.cpp:434] label_data_1_split <- label
I0824 21:59:14.801650 43755 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 21:59:14.801667 43755 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 21:59:14.801715 43755 net.cpp:150] Setting up label_data_1_split
I0824 21:59:14.801723 43755 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 21:59:14.801728 43755 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 21:59:14.801735 43755 net.cpp:165] Memory required for data: 30412800
I0824 21:59:14.801739 43755 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 21:59:14.801750 43755 net.cpp:100] Creating Layer conv1_1_1
I0824 21:59:14.801756 43755 net.cpp:434] conv1_1_1 <- data
I0824 21:59:14.801762 43755 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 21:59:14.805645 43755 net.cpp:150] Setting up conv1_1_1
I0824 21:59:14.805663 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.805672 43755 net.cpp:165] Memory required for data: 207360000
I0824 21:59:14.805685 43755 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 21:59:14.805693 43755 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 21:59:14.805701 43755 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 21:59:14.805706 43755 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 21:59:14.806094 43755 net.cpp:150] Setting up conv1_1_1_bn
I0824 21:59:14.806103 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.806107 43755 net.cpp:165] Memory required for data: 384307200
I0824 21:59:14.806118 43755 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 21:59:14.806128 43755 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 21:59:14.806133 43755 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 21:59:14.806138 43755 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 21:59:14.806187 43755 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 21:59:14.808212 43755 net.cpp:150] Setting up conv1_1_1_scale
I0824 21:59:14.808226 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.808234 43755 net.cpp:165] Memory required for data: 561254400
I0824 21:59:14.808243 43755 layer_factory.hpp:77] Creating layer relu1_1
I0824 21:59:14.808251 43755 net.cpp:100] Creating Layer relu1_1
I0824 21:59:14.808256 43755 net.cpp:434] relu1_1 <- conv1_1_1
I0824 21:59:14.808262 43755 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 21:59:14.808480 43755 net.cpp:150] Setting up relu1_1
I0824 21:59:14.808490 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.808495 43755 net.cpp:165] Memory required for data: 738201600
I0824 21:59:14.808499 43755 layer_factory.hpp:77] Creating layer conv1_2
I0824 21:59:14.808509 43755 net.cpp:100] Creating Layer conv1_2
I0824 21:59:14.808514 43755 net.cpp:434] conv1_2 <- conv1_1_1
I0824 21:59:14.808521 43755 net.cpp:408] conv1_2 -> conv1_2
I0824 21:59:14.812633 43755 net.cpp:150] Setting up conv1_2
I0824 21:59:14.812650 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.812660 43755 net.cpp:165] Memory required for data: 915148800
I0824 21:59:14.812690 43755 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 21:59:14.812696 43755 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 21:59:14.812705 43755 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 21:59:14.812711 43755 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 21:59:14.813087 43755 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 21:59:14.813097 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.813099 43755 net.cpp:165] Memory required for data: 1092096000
I0824 21:59:14.813108 43755 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 21:59:14.813117 43755 net.cpp:100] Creating Layer conv1_2_scale
I0824 21:59:14.813122 43755 net.cpp:434] conv1_2_scale <- conv1_2
I0824 21:59:14.813127 43755 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 21:59:14.813174 43755 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 21:59:14.815167 43755 net.cpp:150] Setting up conv1_2_scale
I0824 21:59:14.815182 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.815191 43755 net.cpp:165] Memory required for data: 1269043200
I0824 21:59:14.815199 43755 layer_factory.hpp:77] Creating layer relu1_2
I0824 21:59:14.815207 43755 net.cpp:100] Creating Layer relu1_2
I0824 21:59:14.815212 43755 net.cpp:434] relu1_2 <- conv1_2
I0824 21:59:14.815217 43755 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 21:59:14.816344 43755 net.cpp:150] Setting up relu1_2
I0824 21:59:14.816359 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:14.816365 43755 net.cpp:165] Memory required for data: 1445990400
I0824 21:59:14.816368 43755 layer_factory.hpp:77] Creating layer pool1
I0824 21:59:14.816373 43755 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 21:59:14.816381 43755 net.cpp:100] Creating Layer pool1
I0824 21:59:14.816386 43755 net.cpp:434] pool1 <- conv1_2
I0824 21:59:14.816396 43755 net.cpp:408] pool1 -> pool1
I0824 21:59:14.816406 43755 net.cpp:408] pool1 -> pool1_mask
I0824 21:59:14.816462 43755 net.cpp:150] Setting up pool1
I0824 21:59:14.816469 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:14.816473 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:14.816478 43755 net.cpp:165] Memory required for data: 1534464000
I0824 21:59:14.816480 43755 layer_factory.hpp:77] Creating layer conv2_1
I0824 21:59:14.816495 43755 net.cpp:100] Creating Layer conv2_1
I0824 21:59:14.816500 43755 net.cpp:434] conv2_1 <- pool1
I0824 21:59:14.816506 43755 net.cpp:408] conv2_1 -> conv2_1
I0824 21:59:14.820879 43755 net.cpp:150] Setting up conv2_1
I0824 21:59:14.820895 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.820905 43755 net.cpp:165] Memory required for data: 1622937600
I0824 21:59:14.820914 43755 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 21:59:14.820926 43755 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 21:59:14.820932 43755 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 21:59:14.820941 43755 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 21:59:14.821256 43755 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 21:59:14.821265 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.821269 43755 net.cpp:165] Memory required for data: 1711411200
I0824 21:59:14.821283 43755 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 21:59:14.821291 43755 net.cpp:100] Creating Layer conv2_1_scale
I0824 21:59:14.821296 43755 net.cpp:434] conv2_1_scale <- conv2_1
I0824 21:59:14.821301 43755 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 21:59:14.821354 43755 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 21:59:14.821604 43755 net.cpp:150] Setting up conv2_1_scale
I0824 21:59:14.821614 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.821617 43755 net.cpp:165] Memory required for data: 1799884800
I0824 21:59:14.821624 43755 layer_factory.hpp:77] Creating layer relu2_1
I0824 21:59:14.821631 43755 net.cpp:100] Creating Layer relu2_1
I0824 21:59:14.821636 43755 net.cpp:434] relu2_1 <- conv2_1
I0824 21:59:14.821643 43755 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 21:59:14.822796 43755 net.cpp:150] Setting up relu2_1
I0824 21:59:14.822811 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.822819 43755 net.cpp:165] Memory required for data: 1888358400
I0824 21:59:14.822824 43755 layer_factory.hpp:77] Creating layer conv2_2
I0824 21:59:14.822834 43755 net.cpp:100] Creating Layer conv2_2
I0824 21:59:14.822839 43755 net.cpp:434] conv2_2 <- conv2_1
I0824 21:59:14.822849 43755 net.cpp:408] conv2_2 -> conv2_2
I0824 21:59:14.832293 43755 net.cpp:150] Setting up conv2_2
I0824 21:59:14.832310 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.832321 43755 net.cpp:165] Memory required for data: 1976832000
I0824 21:59:14.832329 43755 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 21:59:14.832342 43755 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 21:59:14.832350 43755 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 21:59:14.832355 43755 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 21:59:14.834280 43755 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 21:59:14.834296 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.834307 43755 net.cpp:165] Memory required for data: 2065305600
I0824 21:59:14.834316 43755 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 21:59:14.834326 43755 net.cpp:100] Creating Layer conv2_2_scale
I0824 21:59:14.834332 43755 net.cpp:434] conv2_2_scale <- conv2_2
I0824 21:59:14.834338 43755 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 21:59:14.834399 43755 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 21:59:14.834616 43755 net.cpp:150] Setting up conv2_2_scale
I0824 21:59:14.834625 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.834628 43755 net.cpp:165] Memory required for data: 2153779200
I0824 21:59:14.834635 43755 layer_factory.hpp:77] Creating layer relu2_2
I0824 21:59:14.834645 43755 net.cpp:100] Creating Layer relu2_2
I0824 21:59:14.834650 43755 net.cpp:434] relu2_2 <- conv2_2
I0824 21:59:14.834656 43755 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 21:59:14.834884 43755 net.cpp:150] Setting up relu2_2
I0824 21:59:14.834893 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:14.834897 43755 net.cpp:165] Memory required for data: 2242252800
I0824 21:59:14.834902 43755 layer_factory.hpp:77] Creating layer pool2
I0824 21:59:14.834908 43755 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 21:59:14.834915 43755 net.cpp:100] Creating Layer pool2
I0824 21:59:14.834920 43755 net.cpp:434] pool2 <- conv2_2
I0824 21:59:14.834926 43755 net.cpp:408] pool2 -> pool2
I0824 21:59:14.834935 43755 net.cpp:408] pool2 -> pool2_mask
I0824 21:59:14.834991 43755 net.cpp:150] Setting up pool2
I0824 21:59:14.835000 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:14.835003 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:14.835007 43755 net.cpp:165] Memory required for data: 2286489600
I0824 21:59:14.835011 43755 layer_factory.hpp:77] Creating layer conv3_1
I0824 21:59:14.835023 43755 net.cpp:100] Creating Layer conv3_1
I0824 21:59:14.835028 43755 net.cpp:434] conv3_1 <- pool2
I0824 21:59:14.835036 43755 net.cpp:408] conv3_1 -> conv3_1
I0824 21:59:14.847620 43755 net.cpp:150] Setting up conv3_1
I0824 21:59:14.847640 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.847647 43755 net.cpp:165] Memory required for data: 2330726400
I0824 21:59:14.847656 43755 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 21:59:14.847666 43755 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 21:59:14.847674 43755 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 21:59:14.847685 43755 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 21:59:14.847977 43755 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 21:59:14.847986 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.847990 43755 net.cpp:165] Memory required for data: 2374963200
I0824 21:59:14.848003 43755 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 21:59:14.848029 43755 net.cpp:100] Creating Layer conv3_1_scale
I0824 21:59:14.848036 43755 net.cpp:434] conv3_1_scale <- conv3_1
I0824 21:59:14.848040 43755 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 21:59:14.848096 43755 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 21:59:14.848281 43755 net.cpp:150] Setting up conv3_1_scale
I0824 21:59:14.848290 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.848294 43755 net.cpp:165] Memory required for data: 2419200000
I0824 21:59:14.848300 43755 layer_factory.hpp:77] Creating layer relu3_1
I0824 21:59:14.848307 43755 net.cpp:100] Creating Layer relu3_1
I0824 21:59:14.848312 43755 net.cpp:434] relu3_1 <- conv3_1
I0824 21:59:14.848317 43755 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 21:59:14.848544 43755 net.cpp:150] Setting up relu3_1
I0824 21:59:14.848553 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.848557 43755 net.cpp:165] Memory required for data: 2463436800
I0824 21:59:14.848562 43755 layer_factory.hpp:77] Creating layer conv3_2
I0824 21:59:14.848575 43755 net.cpp:100] Creating Layer conv3_2
I0824 21:59:14.848580 43755 net.cpp:434] conv3_2 <- conv3_1
I0824 21:59:14.848590 43755 net.cpp:408] conv3_2 -> conv3_2
I0824 21:59:14.872874 43755 net.cpp:150] Setting up conv3_2
I0824 21:59:14.872890 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.872900 43755 net.cpp:165] Memory required for data: 2507673600
I0824 21:59:14.872908 43755 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 21:59:14.872920 43755 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 21:59:14.872923 43755 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 21:59:14.872930 43755 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 21:59:14.873219 43755 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 21:59:14.873227 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.873230 43755 net.cpp:165] Memory required for data: 2551910400
I0824 21:59:14.873239 43755 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 21:59:14.873247 43755 net.cpp:100] Creating Layer conv3_2_scale
I0824 21:59:14.873257 43755 net.cpp:434] conv3_2_scale <- conv3_2
I0824 21:59:14.873265 43755 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 21:59:14.873317 43755 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 21:59:14.873507 43755 net.cpp:150] Setting up conv3_2_scale
I0824 21:59:14.873517 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.873519 43755 net.cpp:165] Memory required for data: 2596147200
I0824 21:59:14.873527 43755 layer_factory.hpp:77] Creating layer relu3_2
I0824 21:59:14.873536 43755 net.cpp:100] Creating Layer relu3_2
I0824 21:59:14.873541 43755 net.cpp:434] relu3_2 <- conv3_2
I0824 21:59:14.873546 43755 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 21:59:14.873780 43755 net.cpp:150] Setting up relu3_2
I0824 21:59:14.873792 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.873797 43755 net.cpp:165] Memory required for data: 2640384000
I0824 21:59:14.873801 43755 layer_factory.hpp:77] Creating layer conv3_3
I0824 21:59:14.873813 43755 net.cpp:100] Creating Layer conv3_3
I0824 21:59:14.873819 43755 net.cpp:434] conv3_3 <- conv3_2
I0824 21:59:14.873826 43755 net.cpp:408] conv3_3 -> conv3_3
I0824 21:59:14.897935 43755 net.cpp:150] Setting up conv3_3
I0824 21:59:14.897953 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.897964 43755 net.cpp:165] Memory required for data: 2684620800
I0824 21:59:14.897979 43755 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 21:59:14.897987 43755 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 21:59:14.897996 43755 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 21:59:14.898002 43755 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 21:59:14.898290 43755 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 21:59:14.898298 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.898301 43755 net.cpp:165] Memory required for data: 2728857600
I0824 21:59:14.898310 43755 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 21:59:14.898334 43755 net.cpp:100] Creating Layer conv3_3_scale
I0824 21:59:14.898342 43755 net.cpp:434] conv3_3_scale <- conv3_3
I0824 21:59:14.898347 43755 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 21:59:14.898406 43755 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 21:59:14.898587 43755 net.cpp:150] Setting up conv3_3_scale
I0824 21:59:14.898596 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.898599 43755 net.cpp:165] Memory required for data: 2773094400
I0824 21:59:14.898605 43755 layer_factory.hpp:77] Creating layer relu3_3
I0824 21:59:14.898615 43755 net.cpp:100] Creating Layer relu3_3
I0824 21:59:14.898620 43755 net.cpp:434] relu3_3 <- conv3_3
I0824 21:59:14.898625 43755 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 21:59:14.898852 43755 net.cpp:150] Setting up relu3_3
I0824 21:59:14.898861 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:14.898866 43755 net.cpp:165] Memory required for data: 2817331200
I0824 21:59:14.898870 43755 layer_factory.hpp:77] Creating layer pool3
I0824 21:59:14.898875 43755 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 21:59:14.898888 43755 net.cpp:100] Creating Layer pool3
I0824 21:59:14.898893 43755 net.cpp:434] pool3 <- conv3_3
I0824 21:59:14.898900 43755 net.cpp:408] pool3 -> pool3
I0824 21:59:14.898907 43755 net.cpp:408] pool3 -> pool3_mask
I0824 21:59:14.898967 43755 net.cpp:150] Setting up pool3
I0824 21:59:14.898975 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:14.898980 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:14.898984 43755 net.cpp:165] Memory required for data: 2839449600
I0824 21:59:14.898988 43755 layer_factory.hpp:77] Creating layer conv4_1
I0824 21:59:14.899000 43755 net.cpp:100] Creating Layer conv4_1
I0824 21:59:14.899005 43755 net.cpp:434] conv4_1 <- pool3
I0824 21:59:14.899015 43755 net.cpp:408] conv4_1 -> conv4_1
I0824 21:59:14.944041 43755 net.cpp:150] Setting up conv4_1
I0824 21:59:14.944058 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.944062 43755 net.cpp:165] Memory required for data: 2861568000
I0824 21:59:14.944070 43755 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 21:59:14.944087 43755 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 21:59:14.944093 43755 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 21:59:14.944099 43755 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 21:59:14.944383 43755 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 21:59:14.944391 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.944396 43755 net.cpp:165] Memory required for data: 2883686400
I0824 21:59:14.944403 43755 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 21:59:14.944412 43755 net.cpp:100] Creating Layer conv4_1_scale
I0824 21:59:14.944422 43755 net.cpp:434] conv4_1_scale <- conv4_1
I0824 21:59:14.944427 43755 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 21:59:14.944481 43755 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 21:59:14.944648 43755 net.cpp:150] Setting up conv4_1_scale
I0824 21:59:14.944658 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.944660 43755 net.cpp:165] Memory required for data: 2905804800
I0824 21:59:14.944666 43755 layer_factory.hpp:77] Creating layer relu4_1
I0824 21:59:14.944675 43755 net.cpp:100] Creating Layer relu4_1
I0824 21:59:14.944680 43755 net.cpp:434] relu4_1 <- conv4_1
I0824 21:59:14.944685 43755 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 21:59:14.945847 43755 net.cpp:150] Setting up relu4_1
I0824 21:59:14.945863 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:14.945868 43755 net.cpp:165] Memory required for data: 2927923200
I0824 21:59:14.945873 43755 layer_factory.hpp:77] Creating layer conv4_2
I0824 21:59:14.945886 43755 net.cpp:100] Creating Layer conv4_2
I0824 21:59:14.945893 43755 net.cpp:434] conv4_2 <- conv4_1
I0824 21:59:14.945902 43755 net.cpp:408] conv4_2 -> conv4_2
I0824 21:59:15.030755 43755 net.cpp:150] Setting up conv4_2
I0824 21:59:15.030787 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.030792 43755 net.cpp:165] Memory required for data: 2950041600
I0824 21:59:15.030799 43755 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 21:59:15.030815 43755 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 21:59:15.030822 43755 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 21:59:15.030827 43755 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 21:59:15.031111 43755 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 21:59:15.031118 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.031121 43755 net.cpp:165] Memory required for data: 2972160000
I0824 21:59:15.031129 43755 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 21:59:15.031136 43755 net.cpp:100] Creating Layer conv4_2_scale
I0824 21:59:15.031144 43755 net.cpp:434] conv4_2_scale <- conv4_2
I0824 21:59:15.031152 43755 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 21:59:15.031201 43755 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 21:59:15.031366 43755 net.cpp:150] Setting up conv4_2_scale
I0824 21:59:15.031376 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.031380 43755 net.cpp:165] Memory required for data: 2994278400
I0824 21:59:15.031388 43755 layer_factory.hpp:77] Creating layer relu4_2
I0824 21:59:15.031394 43755 net.cpp:100] Creating Layer relu4_2
I0824 21:59:15.031399 43755 net.cpp:434] relu4_2 <- conv4_2
I0824 21:59:15.031405 43755 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 21:59:15.032577 43755 net.cpp:150] Setting up relu4_2
I0824 21:59:15.032593 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.032598 43755 net.cpp:165] Memory required for data: 3016396800
I0824 21:59:15.032603 43755 layer_factory.hpp:77] Creating layer conv4_3
I0824 21:59:15.032618 43755 net.cpp:100] Creating Layer conv4_3
I0824 21:59:15.032624 43755 net.cpp:434] conv4_3 <- conv4_2
I0824 21:59:15.032631 43755 net.cpp:408] conv4_3 -> conv4_3
I0824 21:59:15.118397 43755 net.cpp:150] Setting up conv4_3
I0824 21:59:15.118418 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.118422 43755 net.cpp:165] Memory required for data: 3038515200
I0824 21:59:15.118448 43755 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 21:59:15.118458 43755 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 21:59:15.118466 43755 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 21:59:15.118475 43755 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 21:59:15.118754 43755 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 21:59:15.118762 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.118767 43755 net.cpp:165] Memory required for data: 3060633600
I0824 21:59:15.118774 43755 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 21:59:15.118787 43755 net.cpp:100] Creating Layer conv4_3_scale
I0824 21:59:15.118795 43755 net.cpp:434] conv4_3_scale <- conv4_3
I0824 21:59:15.118801 43755 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 21:59:15.118854 43755 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 21:59:15.119021 43755 net.cpp:150] Setting up conv4_3_scale
I0824 21:59:15.119030 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.119033 43755 net.cpp:165] Memory required for data: 3082752000
I0824 21:59:15.119040 43755 layer_factory.hpp:77] Creating layer relu4_3
I0824 21:59:15.119050 43755 net.cpp:100] Creating Layer relu4_3
I0824 21:59:15.119055 43755 net.cpp:434] relu4_3 <- conv4_3
I0824 21:59:15.119062 43755 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 21:59:15.119283 43755 net.cpp:150] Setting up relu4_3
I0824 21:59:15.119292 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.119297 43755 net.cpp:165] Memory required for data: 3104870400
I0824 21:59:15.119302 43755 layer_factory.hpp:77] Creating layer pool4
I0824 21:59:15.119305 43755 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 21:59:15.119312 43755 net.cpp:100] Creating Layer pool4
I0824 21:59:15.119316 43755 net.cpp:434] pool4 <- conv4_3
I0824 21:59:15.119340 43755 net.cpp:408] pool4 -> pool4
I0824 21:59:15.119350 43755 net.cpp:408] pool4 -> pool4_mask
I0824 21:59:15.119410 43755 net.cpp:150] Setting up pool4
I0824 21:59:15.119418 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.119422 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.119427 43755 net.cpp:165] Memory required for data: 3116175360
I0824 21:59:15.119431 43755 layer_factory.hpp:77] Creating layer conv5_1
I0824 21:59:15.119443 43755 net.cpp:100] Creating Layer conv5_1
I0824 21:59:15.119448 43755 net.cpp:434] conv5_1 <- pool4
I0824 21:59:15.119455 43755 net.cpp:408] conv5_1 -> conv5_1
I0824 21:59:15.205209 43755 net.cpp:150] Setting up conv5_1
I0824 21:59:15.205226 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.205230 43755 net.cpp:165] Memory required for data: 3121827840
I0824 21:59:15.205238 43755 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 21:59:15.205248 43755 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 21:59:15.205253 43755 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 21:59:15.205265 43755 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 21:59:15.205555 43755 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 21:59:15.205564 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.205569 43755 net.cpp:165] Memory required for data: 3127480320
I0824 21:59:15.205576 43755 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 21:59:15.205590 43755 net.cpp:100] Creating Layer conv5_1_scale
I0824 21:59:15.205596 43755 net.cpp:434] conv5_1_scale <- conv5_1
I0824 21:59:15.205601 43755 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 21:59:15.205663 43755 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 21:59:15.205819 43755 net.cpp:150] Setting up conv5_1_scale
I0824 21:59:15.205828 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.205832 43755 net.cpp:165] Memory required for data: 3133132800
I0824 21:59:15.205837 43755 layer_factory.hpp:77] Creating layer relu5_1
I0824 21:59:15.205845 43755 net.cpp:100] Creating Layer relu5_1
I0824 21:59:15.205850 43755 net.cpp:434] relu5_1 <- conv5_1
I0824 21:59:15.205855 43755 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 21:59:15.206079 43755 net.cpp:150] Setting up relu5_1
I0824 21:59:15.206089 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.206092 43755 net.cpp:165] Memory required for data: 3138785280
I0824 21:59:15.206095 43755 layer_factory.hpp:77] Creating layer conv5_2
I0824 21:59:15.206110 43755 net.cpp:100] Creating Layer conv5_2
I0824 21:59:15.206115 43755 net.cpp:434] conv5_2 <- conv5_1
I0824 21:59:15.206125 43755 net.cpp:408] conv5_2 -> conv5_2
I0824 21:59:15.291893 43755 net.cpp:150] Setting up conv5_2
I0824 21:59:15.291911 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.291915 43755 net.cpp:165] Memory required for data: 3144437760
I0824 21:59:15.291923 43755 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 21:59:15.291934 43755 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 21:59:15.291939 43755 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 21:59:15.291944 43755 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 21:59:15.292220 43755 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 21:59:15.292228 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.292232 43755 net.cpp:165] Memory required for data: 3150090240
I0824 21:59:15.292243 43755 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 21:59:15.292251 43755 net.cpp:100] Creating Layer conv5_2_scale
I0824 21:59:15.292259 43755 net.cpp:434] conv5_2_scale <- conv5_2
I0824 21:59:15.292265 43755 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 21:59:15.292328 43755 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 21:59:15.292485 43755 net.cpp:150] Setting up conv5_2_scale
I0824 21:59:15.292493 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.292497 43755 net.cpp:165] Memory required for data: 3155742720
I0824 21:59:15.292505 43755 layer_factory.hpp:77] Creating layer relu5_2
I0824 21:59:15.292531 43755 net.cpp:100] Creating Layer relu5_2
I0824 21:59:15.292536 43755 net.cpp:434] relu5_2 <- conv5_2
I0824 21:59:15.292541 43755 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 21:59:15.292762 43755 net.cpp:150] Setting up relu5_2
I0824 21:59:15.292773 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.292778 43755 net.cpp:165] Memory required for data: 3161395200
I0824 21:59:15.292781 43755 layer_factory.hpp:77] Creating layer conv5_3
I0824 21:59:15.292798 43755 net.cpp:100] Creating Layer conv5_3
I0824 21:59:15.292804 43755 net.cpp:434] conv5_3 <- conv5_2
I0824 21:59:15.292809 43755 net.cpp:408] conv5_3 -> conv5_3
I0824 21:59:15.380138 43755 net.cpp:150] Setting up conv5_3
I0824 21:59:15.380167 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.380182 43755 net.cpp:165] Memory required for data: 3167047680
I0824 21:59:15.380199 43755 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 21:59:15.380209 43755 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 21:59:15.380220 43755 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 21:59:15.380234 43755 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 21:59:15.380515 43755 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 21:59:15.380524 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.380528 43755 net.cpp:165] Memory required for data: 3172700160
I0824 21:59:15.380537 43755 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 21:59:15.380548 43755 net.cpp:100] Creating Layer conv5_3_scale
I0824 21:59:15.380558 43755 net.cpp:434] conv5_3_scale <- conv5_3
I0824 21:59:15.380563 43755 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 21:59:15.380623 43755 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 21:59:15.380780 43755 net.cpp:150] Setting up conv5_3_scale
I0824 21:59:15.380789 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.380792 43755 net.cpp:165] Memory required for data: 3178352640
I0824 21:59:15.380798 43755 layer_factory.hpp:77] Creating layer relu5_3
I0824 21:59:15.380806 43755 net.cpp:100] Creating Layer relu5_3
I0824 21:59:15.380811 43755 net.cpp:434] relu5_3 <- conv5_3
I0824 21:59:15.380817 43755 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 21:59:15.381036 43755 net.cpp:150] Setting up relu5_3
I0824 21:59:15.381045 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.381050 43755 net.cpp:165] Memory required for data: 3184005120
I0824 21:59:15.381054 43755 layer_factory.hpp:77] Creating layer pool5
I0824 21:59:15.381058 43755 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 21:59:15.381065 43755 net.cpp:100] Creating Layer pool5
I0824 21:59:15.381070 43755 net.cpp:434] pool5 <- conv5_3
I0824 21:59:15.381088 43755 net.cpp:408] pool5 -> pool5
I0824 21:59:15.381099 43755 net.cpp:408] pool5 -> pool5_mask
I0824 21:59:15.381161 43755 net.cpp:150] Setting up pool5
I0824 21:59:15.381170 43755 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 21:59:15.381173 43755 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 21:59:15.381177 43755 net.cpp:165] Memory required for data: 3186954240
I0824 21:59:15.381181 43755 layer_factory.hpp:77] Creating layer upsample5
I0824 21:59:15.381188 43755 net.cpp:100] Creating Layer upsample5
I0824 21:59:15.381193 43755 net.cpp:434] upsample5 <- pool5
I0824 21:59:15.381198 43755 net.cpp:434] upsample5 <- pool5_mask
I0824 21:59:15.381203 43755 net.cpp:408] upsample5 -> pool5_D
I0824 21:59:15.381237 43755 net.cpp:150] Setting up upsample5
I0824 21:59:15.381243 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.381247 43755 net.cpp:165] Memory required for data: 3192606720
I0824 21:59:15.381250 43755 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 21:59:15.381263 43755 net.cpp:100] Creating Layer conv5_3_D
I0824 21:59:15.381268 43755 net.cpp:434] conv5_3_D <- pool5_D
I0824 21:59:15.381275 43755 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 21:59:15.467121 43755 net.cpp:150] Setting up conv5_3_D
I0824 21:59:15.467139 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.467162 43755 net.cpp:165] Memory required for data: 3198259200
I0824 21:59:15.467171 43755 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 21:59:15.467181 43755 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 21:59:15.467190 43755 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 21:59:15.467198 43755 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 21:59:15.467471 43755 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 21:59:15.467480 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.467483 43755 net.cpp:165] Memory required for data: 3203911680
I0824 21:59:15.467492 43755 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 21:59:15.467502 43755 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 21:59:15.467509 43755 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 21:59:15.467514 43755 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 21:59:15.467571 43755 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 21:59:15.467730 43755 net.cpp:150] Setting up conv5_3_D_scale
I0824 21:59:15.467737 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.467741 43755 net.cpp:165] Memory required for data: 3209564160
I0824 21:59:15.467747 43755 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 21:59:15.467754 43755 net.cpp:100] Creating Layer relu5_3_D
I0824 21:59:15.467759 43755 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 21:59:15.467764 43755 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 21:59:15.468909 43755 net.cpp:150] Setting up relu5_3_D
I0824 21:59:15.468924 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.468930 43755 net.cpp:165] Memory required for data: 3215216640
I0824 21:59:15.468933 43755 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 21:59:15.468993 43755 net.cpp:100] Creating Layer conv5_2_D
I0824 21:59:15.469000 43755 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 21:59:15.469009 43755 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 21:59:15.553514 43755 net.cpp:150] Setting up conv5_2_D
I0824 21:59:15.553531 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.553535 43755 net.cpp:165] Memory required for data: 3220869120
I0824 21:59:15.553545 43755 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 21:59:15.553561 43755 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 21:59:15.553570 43755 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 21:59:15.553575 43755 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 21:59:15.553859 43755 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 21:59:15.553867 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.553870 43755 net.cpp:165] Memory required for data: 3226521600
I0824 21:59:15.553879 43755 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 21:59:15.553894 43755 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 21:59:15.553900 43755 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 21:59:15.553906 43755 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 21:59:15.553963 43755 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 21:59:15.554123 43755 net.cpp:150] Setting up conv5_2_D_scale
I0824 21:59:15.554131 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.554134 43755 net.cpp:165] Memory required for data: 3232174080
I0824 21:59:15.554141 43755 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 21:59:15.554148 43755 net.cpp:100] Creating Layer relu5_2_D
I0824 21:59:15.554154 43755 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 21:59:15.554163 43755 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 21:59:15.555325 43755 net.cpp:150] Setting up relu5_2_D
I0824 21:59:15.555339 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.555344 43755 net.cpp:165] Memory required for data: 3237826560
I0824 21:59:15.555348 43755 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 21:59:15.555363 43755 net.cpp:100] Creating Layer conv5_1_D
I0824 21:59:15.555369 43755 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 21:59:15.555378 43755 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 21:59:15.639796 43755 net.cpp:150] Setting up conv5_1_D
I0824 21:59:15.639813 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.639817 43755 net.cpp:165] Memory required for data: 3243479040
I0824 21:59:15.639825 43755 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 21:59:15.639835 43755 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 21:59:15.639840 43755 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 21:59:15.639845 43755 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 21:59:15.640123 43755 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 21:59:15.640132 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.640136 43755 net.cpp:165] Memory required for data: 3249131520
I0824 21:59:15.640143 43755 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 21:59:15.640154 43755 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 21:59:15.640163 43755 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 21:59:15.640173 43755 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 21:59:15.640229 43755 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 21:59:15.640390 43755 net.cpp:150] Setting up conv5_1_D_scale
I0824 21:59:15.640398 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.640401 43755 net.cpp:165] Memory required for data: 3254784000
I0824 21:59:15.640408 43755 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 21:59:15.640415 43755 net.cpp:100] Creating Layer relu5_1_D
I0824 21:59:15.640420 43755 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 21:59:15.640425 43755 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 21:59:15.640647 43755 net.cpp:150] Setting up relu5_1_D
I0824 21:59:15.640657 43755 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 21:59:15.640662 43755 net.cpp:165] Memory required for data: 3260436480
I0824 21:59:15.640666 43755 layer_factory.hpp:77] Creating layer upsample4
I0824 21:59:15.640673 43755 net.cpp:100] Creating Layer upsample4
I0824 21:59:15.640678 43755 net.cpp:434] upsample4 <- conv5_1_D
I0824 21:59:15.640683 43755 net.cpp:434] upsample4 <- pool4_mask
I0824 21:59:15.640691 43755 net.cpp:408] upsample4 -> pool4_D
I0824 21:59:15.640730 43755 net.cpp:150] Setting up upsample4
I0824 21:59:15.640739 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.640744 43755 net.cpp:165] Memory required for data: 3282554880
I0824 21:59:15.640748 43755 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 21:59:15.640758 43755 net.cpp:100] Creating Layer conv4_3_D
I0824 21:59:15.640763 43755 net.cpp:434] conv4_3_D <- pool4_D
I0824 21:59:15.640770 43755 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 21:59:15.725174 43755 net.cpp:150] Setting up conv4_3_D
I0824 21:59:15.725191 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.725195 43755 net.cpp:165] Memory required for data: 3304673280
I0824 21:59:15.725203 43755 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 21:59:15.725214 43755 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 21:59:15.725217 43755 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 21:59:15.725224 43755 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 21:59:15.725536 43755 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 21:59:15.725546 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.725549 43755 net.cpp:165] Memory required for data: 3326791680
I0824 21:59:15.725558 43755 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 21:59:15.725569 43755 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 21:59:15.725577 43755 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 21:59:15.725582 43755 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 21:59:15.725636 43755 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 21:59:15.725805 43755 net.cpp:150] Setting up conv4_3_D_scale
I0824 21:59:15.725813 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.725816 43755 net.cpp:165] Memory required for data: 3348910080
I0824 21:59:15.725823 43755 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 21:59:15.725849 43755 net.cpp:100] Creating Layer relu4_3_D
I0824 21:59:15.725854 43755 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 21:59:15.725859 43755 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 21:59:15.726078 43755 net.cpp:150] Setting up relu4_3_D
I0824 21:59:15.726089 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.726094 43755 net.cpp:165] Memory required for data: 3371028480
I0824 21:59:15.726097 43755 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 21:59:15.726109 43755 net.cpp:100] Creating Layer conv4_2_D
I0824 21:59:15.726114 43755 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 21:59:15.726121 43755 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 21:59:15.810523 43755 net.cpp:150] Setting up conv4_2_D
I0824 21:59:15.810542 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.810546 43755 net.cpp:165] Memory required for data: 3393146880
I0824 21:59:15.810554 43755 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 21:59:15.810562 43755 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 21:59:15.810575 43755 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 21:59:15.810582 43755 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 21:59:15.810871 43755 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 21:59:15.810879 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.810883 43755 net.cpp:165] Memory required for data: 3415265280
I0824 21:59:15.810891 43755 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 21:59:15.810900 43755 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 21:59:15.810909 43755 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 21:59:15.810914 43755 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 21:59:15.810967 43755 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 21:59:15.811139 43755 net.cpp:150] Setting up conv4_2_D_scale
I0824 21:59:15.811147 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.811151 43755 net.cpp:165] Memory required for data: 3437383680
I0824 21:59:15.811156 43755 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 21:59:15.811164 43755 net.cpp:100] Creating Layer relu4_2_D
I0824 21:59:15.811169 43755 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 21:59:15.811177 43755 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 21:59:15.811396 43755 net.cpp:150] Setting up relu4_2_D
I0824 21:59:15.811405 43755 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 21:59:15.811411 43755 net.cpp:165] Memory required for data: 3459502080
I0824 21:59:15.811414 43755 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 21:59:15.811426 43755 net.cpp:100] Creating Layer conv4_1_D
I0824 21:59:15.811432 43755 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 21:59:15.811441 43755 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 21:59:15.855800 43755 net.cpp:150] Setting up conv4_1_D
I0824 21:59:15.855818 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:15.855829 43755 net.cpp:165] Memory required for data: 3470561280
I0824 21:59:15.855840 43755 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 21:59:15.855854 43755 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 21:59:15.855862 43755 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 21:59:15.855868 43755 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 21:59:15.856164 43755 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 21:59:15.856173 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:15.856176 43755 net.cpp:165] Memory required for data: 3481620480
I0824 21:59:15.856236 43755 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 21:59:15.856245 43755 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 21:59:15.856256 43755 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 21:59:15.856261 43755 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 21:59:15.856320 43755 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 21:59:15.856490 43755 net.cpp:150] Setting up conv4_1_D_scale
I0824 21:59:15.856498 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:15.856518 43755 net.cpp:165] Memory required for data: 3492679680
I0824 21:59:15.856524 43755 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 21:59:15.856530 43755 net.cpp:100] Creating Layer relu4_1_D
I0824 21:59:15.856536 43755 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 21:59:15.856545 43755 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 21:59:15.856781 43755 net.cpp:150] Setting up relu4_1_D
I0824 21:59:15.856791 43755 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 21:59:15.856796 43755 net.cpp:165] Memory required for data: 3503738880
I0824 21:59:15.856799 43755 layer_factory.hpp:77] Creating layer upsample3
I0824 21:59:15.856808 43755 net.cpp:100] Creating Layer upsample3
I0824 21:59:15.856814 43755 net.cpp:434] upsample3 <- conv4_1_D
I0824 21:59:15.856819 43755 net.cpp:434] upsample3 <- pool3_mask
I0824 21:59:15.856827 43755 net.cpp:408] upsample3 -> pool3_D
I0824 21:59:15.856835 43755 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 21:59:15.856874 43755 net.cpp:150] Setting up upsample3
I0824 21:59:15.856881 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:15.856884 43755 net.cpp:165] Memory required for data: 3547975680
I0824 21:59:15.856887 43755 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 21:59:15.856899 43755 net.cpp:100] Creating Layer conv3_3_D
I0824 21:59:15.856904 43755 net.cpp:434] conv3_3_D <- pool3_D
I0824 21:59:15.856914 43755 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 21:59:15.880841 43755 net.cpp:150] Setting up conv3_3_D
I0824 21:59:15.880857 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:15.880867 43755 net.cpp:165] Memory required for data: 3592212480
I0824 21:59:15.880874 43755 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 21:59:15.880885 43755 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 21:59:15.880892 43755 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 21:59:15.880897 43755 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 21:59:15.881209 43755 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 21:59:15.881217 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:15.881220 43755 net.cpp:165] Memory required for data: 3636449280
I0824 21:59:15.881229 43755 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 21:59:15.881240 43755 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 21:59:15.881249 43755 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 21:59:15.881256 43755 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 21:59:15.881312 43755 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 21:59:15.881525 43755 net.cpp:150] Setting up conv3_3_D_scale
I0824 21:59:15.881534 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:15.881537 43755 net.cpp:165] Memory required for data: 3680686080
I0824 21:59:15.881544 43755 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 21:59:15.881554 43755 net.cpp:100] Creating Layer relu3_3_D
I0824 21:59:15.881558 43755 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 21:59:15.881563 43755 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 21:59:15.882732 43755 net.cpp:150] Setting up relu3_3_D
I0824 21:59:15.882747 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:15.882752 43755 net.cpp:165] Memory required for data: 3724922880
I0824 21:59:15.882756 43755 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 21:59:15.882771 43755 net.cpp:100] Creating Layer conv3_2_D
I0824 21:59:15.882777 43755 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 21:59:15.882784 43755 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 21:59:15.905776 43755 net.cpp:150] Setting up conv3_2_D
I0824 21:59:15.905792 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:15.905797 43755 net.cpp:165] Memory required for data: 3769159680
I0824 21:59:15.905807 43755 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 21:59:15.905814 43755 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 21:59:15.905827 43755 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 21:59:15.905848 43755 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 21:59:15.906157 43755 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 21:59:15.906167 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:15.906169 43755 net.cpp:165] Memory required for data: 3813396480
I0824 21:59:15.906178 43755 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 21:59:15.906194 43755 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 21:59:15.906203 43755 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 21:59:15.906208 43755 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 21:59:15.906268 43755 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 21:59:15.906461 43755 net.cpp:150] Setting up conv3_2_D_scale
I0824 21:59:15.906468 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:15.906471 43755 net.cpp:165] Memory required for data: 3857633280
I0824 21:59:15.906478 43755 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 21:59:15.906488 43755 net.cpp:100] Creating Layer relu3_2_D
I0824 21:59:15.906493 43755 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 21:59:15.906497 43755 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 21:59:15.907655 43755 net.cpp:150] Setting up relu3_2_D
I0824 21:59:15.907673 43755 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 21:59:15.907678 43755 net.cpp:165] Memory required for data: 3901870080
I0824 21:59:15.907682 43755 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 21:59:15.907696 43755 net.cpp:100] Creating Layer conv3_1_D
I0824 21:59:15.907701 43755 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 21:59:15.907708 43755 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 21:59:15.921780 43755 net.cpp:150] Setting up conv3_1_D
I0824 21:59:15.921797 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:15.921809 43755 net.cpp:165] Memory required for data: 3923988480
I0824 21:59:15.921818 43755 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 21:59:15.921828 43755 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 21:59:15.921838 43755 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 21:59:15.921846 43755 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 21:59:15.922157 43755 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 21:59:15.922164 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:15.922168 43755 net.cpp:165] Memory required for data: 3946106880
I0824 21:59:15.922176 43755 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 21:59:15.922195 43755 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 21:59:15.922200 43755 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 21:59:15.922206 43755 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 21:59:15.922264 43755 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 21:59:15.923784 43755 net.cpp:150] Setting up conv3_1_D_scale
I0824 21:59:15.923799 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:15.923810 43755 net.cpp:165] Memory required for data: 3968225280
I0824 21:59:15.923817 43755 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 21:59:15.923827 43755 net.cpp:100] Creating Layer relu3_1_D
I0824 21:59:15.923833 43755 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 21:59:15.923841 43755 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 21:59:15.924084 43755 net.cpp:150] Setting up relu3_1_D
I0824 21:59:15.924094 43755 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 21:59:15.924099 43755 net.cpp:165] Memory required for data: 3990343680
I0824 21:59:15.924103 43755 layer_factory.hpp:77] Creating layer upsample2
I0824 21:59:15.924110 43755 net.cpp:100] Creating Layer upsample2
I0824 21:59:15.924115 43755 net.cpp:434] upsample2 <- conv3_1_D
I0824 21:59:15.924120 43755 net.cpp:434] upsample2 <- pool2_mask
I0824 21:59:15.924129 43755 net.cpp:408] upsample2 -> pool2_D
I0824 21:59:15.924136 43755 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 21:59:15.924178 43755 net.cpp:150] Setting up upsample2
I0824 21:59:15.924199 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:15.924204 43755 net.cpp:165] Memory required for data: 4078817280
I0824 21:59:15.924207 43755 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 21:59:15.924219 43755 net.cpp:100] Creating Layer conv2_2_D
I0824 21:59:15.924226 43755 net.cpp:434] conv2_2_D <- pool2_D
I0824 21:59:15.924233 43755 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 21:59:15.932193 43755 net.cpp:150] Setting up conv2_2_D
I0824 21:59:15.932210 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:15.932220 43755 net.cpp:165] Memory required for data: 4167290880
I0824 21:59:15.932229 43755 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 21:59:15.932246 43755 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 21:59:15.932252 43755 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 21:59:15.932260 43755 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 21:59:15.932605 43755 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 21:59:15.932613 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:15.932617 43755 net.cpp:165] Memory required for data: 4255764480
I0824 21:59:15.932626 43755 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 21:59:15.932636 43755 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 21:59:15.932641 43755 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 21:59:15.932647 43755 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 21:59:15.932703 43755 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 21:59:15.932967 43755 net.cpp:150] Setting up conv2_2_D_scale
I0824 21:59:15.932976 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:15.932978 43755 net.cpp:165] Memory required for data: 4344238080
I0824 21:59:15.932986 43755 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 21:59:15.932993 43755 net.cpp:100] Creating Layer relu2_2_D
I0824 21:59:15.932998 43755 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 21:59:15.933003 43755 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 21:59:15.933241 43755 net.cpp:150] Setting up relu2_2_D
I0824 21:59:15.933251 43755 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 21:59:15.933256 43755 net.cpp:165] Memory required for data: 4432711680
I0824 21:59:15.933259 43755 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 21:59:15.933272 43755 net.cpp:100] Creating Layer conv2_1_D
I0824 21:59:15.933277 43755 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 21:59:15.933286 43755 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 21:59:15.938827 43755 net.cpp:150] Setting up conv2_1_D
I0824 21:59:15.938843 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:15.938853 43755 net.cpp:165] Memory required for data: 4476948480
I0824 21:59:15.938863 43755 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 21:59:15.938876 43755 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 21:59:15.938884 43755 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 21:59:15.938890 43755 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 21:59:15.939245 43755 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 21:59:15.939254 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:15.939257 43755 net.cpp:165] Memory required for data: 4521185280
I0824 21:59:15.939266 43755 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 21:59:15.939275 43755 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 21:59:15.939280 43755 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 21:59:15.939286 43755 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 21:59:15.939347 43755 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 21:59:15.939621 43755 net.cpp:150] Setting up conv2_1_D_scale
I0824 21:59:15.939630 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:15.939633 43755 net.cpp:165] Memory required for data: 4565422080
I0824 21:59:15.939640 43755 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 21:59:15.939648 43755 net.cpp:100] Creating Layer relu2_1_D
I0824 21:59:15.939652 43755 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 21:59:15.939672 43755 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 21:59:15.939913 43755 net.cpp:150] Setting up relu2_1_D
I0824 21:59:15.939923 43755 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 21:59:15.939927 43755 net.cpp:165] Memory required for data: 4609658880
I0824 21:59:15.939931 43755 layer_factory.hpp:77] Creating layer upsample1
I0824 21:59:15.939937 43755 net.cpp:100] Creating Layer upsample1
I0824 21:59:15.939942 43755 net.cpp:434] upsample1 <- conv2_1_D
I0824 21:59:15.939947 43755 net.cpp:434] upsample1 <- pool1_mask
I0824 21:59:15.939955 43755 net.cpp:408] upsample1 -> pool1_D
I0824 21:59:15.939965 43755 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 21:59:15.940004 43755 net.cpp:150] Setting up upsample1
I0824 21:59:15.940011 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:15.940014 43755 net.cpp:165] Memory required for data: 4786606080
I0824 21:59:15.940018 43755 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 21:59:15.940029 43755 net.cpp:100] Creating Layer conv1_2_D
I0824 21:59:15.940035 43755 net.cpp:434] conv1_2_D <- pool1_D
I0824 21:59:15.940042 43755 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 21:59:15.944797 43755 net.cpp:150] Setting up conv1_2_D
I0824 21:59:15.944814 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:15.944824 43755 net.cpp:165] Memory required for data: 4963553280
I0824 21:59:15.944833 43755 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 21:59:15.944841 43755 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 21:59:15.944849 43755 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 21:59:15.944854 43755 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 21:59:15.945302 43755 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 21:59:15.945312 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:15.945314 43755 net.cpp:165] Memory required for data: 5140500480
I0824 21:59:15.945323 43755 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 21:59:15.945339 43755 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 21:59:15.945344 43755 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 21:59:15.945349 43755 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 21:59:15.945432 43755 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 21:59:15.947211 43755 net.cpp:150] Setting up conv1_2_D_scale
I0824 21:59:15.947227 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:15.947232 43755 net.cpp:165] Memory required for data: 5317447680
I0824 21:59:15.947239 43755 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 21:59:15.947247 43755 net.cpp:100] Creating Layer relu1_2_D
I0824 21:59:15.947252 43755 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 21:59:15.947260 43755 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 21:59:15.947504 43755 net.cpp:150] Setting up relu1_2_D
I0824 21:59:15.947515 43755 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 21:59:15.947518 43755 net.cpp:165] Memory required for data: 5494394880
I0824 21:59:15.947522 43755 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 21:59:15.947535 43755 net.cpp:100] Creating Layer conv1_1_1_D
I0824 21:59:15.947541 43755 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 21:59:15.947549 43755 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 21:59:15.949789 43755 net.cpp:150] Setting up conv1_1_1_D
I0824 21:59:15.949803 43755 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 21:59:15.949810 43755 net.cpp:165] Memory required for data: 5499924480
I0824 21:59:15.949817 43755 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 21:59:15.949826 43755 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 21:59:15.949832 43755 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 21:59:15.949841 43755 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 21:59:15.949849 43755 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 21:59:15.949926 43755 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 21:59:15.949934 43755 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 21:59:15.949939 43755 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 21:59:15.949944 43755 net.cpp:165] Memory required for data: 5510983680
I0824 21:59:15.949947 43755 layer_factory.hpp:77] Creating layer loss
I0824 21:59:15.949959 43755 net.cpp:100] Creating Layer loss
I0824 21:59:15.949965 43755 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 21:59:15.949970 43755 net.cpp:434] loss <- label_data_1_split_0
I0824 21:59:15.949976 43755 net.cpp:408] loss -> loss
I0824 21:59:15.949987 43755 layer_factory.hpp:77] Creating layer loss
I0824 21:59:15.954133 43755 net.cpp:150] Setting up loss
I0824 21:59:15.954147 43755 net.cpp:157] Top shape: (1)
I0824 21:59:15.954157 43755 net.cpp:160]     with loss weight 1
I0824 21:59:15.954174 43755 net.cpp:165] Memory required for data: 5510983684
I0824 21:59:15.954179 43755 layer_factory.hpp:77] Creating layer accuracy
I0824 21:59:15.954187 43755 net.cpp:100] Creating Layer accuracy
I0824 21:59:15.954192 43755 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 21:59:15.954198 43755 net.cpp:434] accuracy <- label_data_1_split_1
I0824 21:59:15.954210 43755 net.cpp:408] accuracy -> accuracy
I0824 21:59:15.954218 43755 net.cpp:408] accuracy -> per_class_accuracy
I0824 21:59:15.954275 43755 net.cpp:150] Setting up accuracy
I0824 21:59:15.954282 43755 net.cpp:157] Top shape: (1)
I0824 21:59:15.954288 43755 net.cpp:157] Top shape: 2 (2)
I0824 21:59:15.954291 43755 net.cpp:165] Memory required for data: 5510983696
I0824 21:59:15.954295 43755 net.cpp:228] accuracy does not need backward computation.
I0824 21:59:15.954300 43755 net.cpp:226] loss needs backward computation.
I0824 21:59:15.954304 43755 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 21:59:15.954309 43755 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 21:59:15.954313 43755 net.cpp:226] relu1_2_D needs backward computation.
I0824 21:59:15.954316 43755 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 21:59:15.954319 43755 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 21:59:15.954324 43755 net.cpp:226] conv1_2_D needs backward computation.
I0824 21:59:15.954326 43755 net.cpp:226] upsample1 needs backward computation.
I0824 21:59:15.954330 43755 net.cpp:226] relu2_1_D needs backward computation.
I0824 21:59:15.954334 43755 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 21:59:15.954337 43755 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 21:59:15.954340 43755 net.cpp:226] conv2_1_D needs backward computation.
I0824 21:59:15.954344 43755 net.cpp:226] relu2_2_D needs backward computation.
I0824 21:59:15.954346 43755 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 21:59:15.954350 43755 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 21:59:15.954354 43755 net.cpp:226] conv2_2_D needs backward computation.
I0824 21:59:15.954356 43755 net.cpp:226] upsample2 needs backward computation.
I0824 21:59:15.954360 43755 net.cpp:226] relu3_1_D needs backward computation.
I0824 21:59:15.954365 43755 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 21:59:15.954368 43755 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 21:59:15.954371 43755 net.cpp:226] conv3_1_D needs backward computation.
I0824 21:59:15.954375 43755 net.cpp:226] relu3_2_D needs backward computation.
I0824 21:59:15.954378 43755 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 21:59:15.954381 43755 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 21:59:15.954385 43755 net.cpp:226] conv3_2_D needs backward computation.
I0824 21:59:15.954387 43755 net.cpp:226] relu3_3_D needs backward computation.
I0824 21:59:15.954391 43755 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 21:59:15.954394 43755 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 21:59:15.954411 43755 net.cpp:226] conv3_3_D needs backward computation.
I0824 21:59:15.954416 43755 net.cpp:226] upsample3 needs backward computation.
I0824 21:59:15.954419 43755 net.cpp:226] relu4_1_D needs backward computation.
I0824 21:59:15.954423 43755 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 21:59:15.954427 43755 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 21:59:15.954429 43755 net.cpp:226] conv4_1_D needs backward computation.
I0824 21:59:15.954433 43755 net.cpp:226] relu4_2_D needs backward computation.
I0824 21:59:15.954437 43755 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 21:59:15.954439 43755 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 21:59:15.954443 43755 net.cpp:226] conv4_2_D needs backward computation.
I0824 21:59:15.954447 43755 net.cpp:226] relu4_3_D needs backward computation.
I0824 21:59:15.954450 43755 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 21:59:15.954453 43755 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 21:59:15.954457 43755 net.cpp:226] conv4_3_D needs backward computation.
I0824 21:59:15.954460 43755 net.cpp:226] upsample4 needs backward computation.
I0824 21:59:15.954464 43755 net.cpp:226] relu5_1_D needs backward computation.
I0824 21:59:15.954468 43755 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 21:59:15.954473 43755 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 21:59:15.954476 43755 net.cpp:226] conv5_1_D needs backward computation.
I0824 21:59:15.954480 43755 net.cpp:226] relu5_2_D needs backward computation.
I0824 21:59:15.954484 43755 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 21:59:15.954488 43755 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 21:59:15.954491 43755 net.cpp:226] conv5_2_D needs backward computation.
I0824 21:59:15.954495 43755 net.cpp:226] relu5_3_D needs backward computation.
I0824 21:59:15.954499 43755 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 21:59:15.954502 43755 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 21:59:15.954505 43755 net.cpp:226] conv5_3_D needs backward computation.
I0824 21:59:15.954509 43755 net.cpp:226] upsample5 needs backward computation.
I0824 21:59:15.954514 43755 net.cpp:226] pool5 needs backward computation.
I0824 21:59:15.954517 43755 net.cpp:226] relu5_3 needs backward computation.
I0824 21:59:15.954521 43755 net.cpp:226] conv5_3_scale needs backward computation.
I0824 21:59:15.954526 43755 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 21:59:15.954530 43755 net.cpp:226] conv5_3 needs backward computation.
I0824 21:59:15.954533 43755 net.cpp:226] relu5_2 needs backward computation.
I0824 21:59:15.954537 43755 net.cpp:226] conv5_2_scale needs backward computation.
I0824 21:59:15.954541 43755 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 21:59:15.954545 43755 net.cpp:226] conv5_2 needs backward computation.
I0824 21:59:15.954548 43755 net.cpp:226] relu5_1 needs backward computation.
I0824 21:59:15.954555 43755 net.cpp:226] conv5_1_scale needs backward computation.
I0824 21:59:15.954557 43755 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 21:59:15.954560 43755 net.cpp:226] conv5_1 needs backward computation.
I0824 21:59:15.954566 43755 net.cpp:226] pool4 needs backward computation.
I0824 21:59:15.954568 43755 net.cpp:226] relu4_3 needs backward computation.
I0824 21:59:15.954572 43755 net.cpp:226] conv4_3_scale needs backward computation.
I0824 21:59:15.954576 43755 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 21:59:15.954583 43755 net.cpp:226] conv4_3 needs backward computation.
I0824 21:59:15.954588 43755 net.cpp:226] relu4_2 needs backward computation.
I0824 21:59:15.954591 43755 net.cpp:226] conv4_2_scale needs backward computation.
I0824 21:59:15.954596 43755 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 21:59:15.954598 43755 net.cpp:226] conv4_2 needs backward computation.
I0824 21:59:15.954603 43755 net.cpp:226] relu4_1 needs backward computation.
I0824 21:59:15.954615 43755 net.cpp:226] conv4_1_scale needs backward computation.
I0824 21:59:15.954619 43755 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 21:59:15.954622 43755 net.cpp:226] conv4_1 needs backward computation.
I0824 21:59:15.954627 43755 net.cpp:226] pool3 needs backward computation.
I0824 21:59:15.954630 43755 net.cpp:226] relu3_3 needs backward computation.
I0824 21:59:15.954634 43755 net.cpp:226] conv3_3_scale needs backward computation.
I0824 21:59:15.954638 43755 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 21:59:15.954641 43755 net.cpp:226] conv3_3 needs backward computation.
I0824 21:59:15.954645 43755 net.cpp:226] relu3_2 needs backward computation.
I0824 21:59:15.954648 43755 net.cpp:226] conv3_2_scale needs backward computation.
I0824 21:59:15.954653 43755 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 21:59:15.954656 43755 net.cpp:226] conv3_2 needs backward computation.
I0824 21:59:15.954659 43755 net.cpp:226] relu3_1 needs backward computation.
I0824 21:59:15.954663 43755 net.cpp:226] conv3_1_scale needs backward computation.
I0824 21:59:15.954666 43755 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 21:59:15.954669 43755 net.cpp:226] conv3_1 needs backward computation.
I0824 21:59:15.954674 43755 net.cpp:226] pool2 needs backward computation.
I0824 21:59:15.954677 43755 net.cpp:226] relu2_2 needs backward computation.
I0824 21:59:15.954680 43755 net.cpp:226] conv2_2_scale needs backward computation.
I0824 21:59:15.954684 43755 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 21:59:15.954687 43755 net.cpp:226] conv2_2 needs backward computation.
I0824 21:59:15.954692 43755 net.cpp:226] relu2_1 needs backward computation.
I0824 21:59:15.954697 43755 net.cpp:226] conv2_1_scale needs backward computation.
I0824 21:59:15.954700 43755 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 21:59:15.954704 43755 net.cpp:226] conv2_1 needs backward computation.
I0824 21:59:15.954708 43755 net.cpp:226] pool1 needs backward computation.
I0824 21:59:15.954711 43755 net.cpp:226] relu1_2 needs backward computation.
I0824 21:59:15.954715 43755 net.cpp:226] conv1_2_scale needs backward computation.
I0824 21:59:15.954718 43755 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 21:59:15.954723 43755 net.cpp:226] conv1_2 needs backward computation.
I0824 21:59:15.954727 43755 net.cpp:226] relu1_1 needs backward computation.
I0824 21:59:15.954732 43755 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 21:59:15.954736 43755 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 21:59:15.954740 43755 net.cpp:226] conv1_1_1 needs backward computation.
I0824 21:59:15.954744 43755 net.cpp:228] label_data_1_split does not need backward computation.
I0824 21:59:15.954748 43755 net.cpp:228] data does not need backward computation.
I0824 21:59:15.954753 43755 net.cpp:270] This network produces output accuracy
I0824 21:59:15.954757 43755 net.cpp:270] This network produces output loss
I0824 21:59:15.954761 43755 net.cpp:270] This network produces output per_class_accuracy
I0824 21:59:15.954824 43755 net.cpp:283] Network initialization done.
I0824 21:59:15.955236 43755 solver.cpp:60] Solver scaffolding done.
I0824 21:59:15.964738 43755 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0824 21:59:16.384261 43755 net.cpp:761] Ignoring source layer conv1_1
I0824 21:59:16.384290 43755 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 21:59:16.384346 43755 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 21:59:16.384354 43755 net.cpp:761] Ignoring source layer pool1_drop
I0824 21:59:16.384433 43755 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 21:59:16.384582 43755 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 21:59:16.384588 43755 net.cpp:761] Ignoring source layer pool2_drop
I0824 21:59:16.384867 43755 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 21:59:16.385447 43755 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 21:59:16.385969 43755 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 21:59:16.385999 43755 net.cpp:761] Ignoring source layer pool3_drop
I0824 21:59:16.387012 43755 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 21:59:16.389029 43755 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 21:59:16.391062 43755 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 21:59:16.391073 43755 net.cpp:761] Ignoring source layer pool4_drop
I0824 21:59:16.393076 43755 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 21:59:16.395094 43755 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 21:59:16.397112 43755 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 21:59:16.397122 43755 net.cpp:761] Ignoring source layer pool5_drop
I0824 21:59:16.397126 43755 net.cpp:761] Ignoring source layer upsample5_drop
I0824 21:59:16.399163 43755 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 21:59:16.401190 43755 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 21:59:16.403218 43755 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 21:59:16.403225 43755 net.cpp:761] Ignoring source layer upsample4_drop
I0824 21:59:16.405232 43755 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 21:59:16.407251 43755 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 21:59:16.408253 43755 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 21:59:16.408260 43755 net.cpp:761] Ignoring source layer upsample3_drop
I0824 21:59:16.408767 43755 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 21:59:16.409332 43755 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 21:59:16.409657 43755 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 21:59:16.409665 43755 net.cpp:761] Ignoring source layer upsample2_drop
I0824 21:59:16.409821 43755 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 21:59:16.409915 43755 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 21:59:16.409927 43755 net.cpp:761] Ignoring source layer upsample1_drop
I0824 21:59:16.409983 43755 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 21:59:16.409991 43755 net.cpp:761] Ignoring source layer conv1_1_D
I0824 21:59:16.409993 43755 net.cpp:761] Ignoring source layer prob
I0824 21:59:16.649262 43755 net.cpp:761] Ignoring source layer conv1_1
I0824 21:59:16.649288 43755 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 21:59:16.649390 43755 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 21:59:16.649399 43755 net.cpp:761] Ignoring source layer pool1_drop
I0824 21:59:16.649524 43755 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 21:59:16.649772 43755 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 21:59:16.649780 43755 net.cpp:761] Ignoring source layer pool2_drop
I0824 21:59:16.650243 43755 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 21:59:16.650949 43755 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 21:59:16.651661 43755 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 21:59:16.651669 43755 net.cpp:761] Ignoring source layer pool3_drop
I0824 21:59:16.652873 43755 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 21:59:16.655098 43755 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 21:59:16.657423 43755 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 21:59:16.657433 43755 net.cpp:761] Ignoring source layer pool4_drop
I0824 21:59:16.659752 43755 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 21:59:16.662077 43755 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 21:59:16.664686 43755 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 21:59:16.664695 43755 net.cpp:761] Ignoring source layer pool5_drop
I0824 21:59:16.664700 43755 net.cpp:761] Ignoring source layer upsample5_drop
I0824 21:59:16.668164 43755 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 21:59:16.671591 43755 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 21:59:16.675015 43755 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 21:59:16.675025 43755 net.cpp:761] Ignoring source layer upsample4_drop
I0824 21:59:16.677021 43755 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 21:59:16.679026 43755 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 21:59:16.680061 43755 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 21:59:16.680070 43755 net.cpp:761] Ignoring source layer upsample3_drop
I0824 21:59:16.680582 43755 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 21:59:16.681089 43755 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 21:59:16.681355 43755 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 21:59:16.681362 43755 net.cpp:761] Ignoring source layer upsample2_drop
I0824 21:59:16.681504 43755 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 21:59:16.681584 43755 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 21:59:16.681592 43755 net.cpp:761] Ignoring source layer upsample1_drop
I0824 21:59:16.681638 43755 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 21:59:16.681646 43755 net.cpp:761] Ignoring source layer conv1_1_D
I0824 21:59:16.681650 43755 net.cpp:761] Ignoring source layer prob
I0824 21:59:16.686939 43755 caffe.cpp:251] Starting Optimization
I0824 21:59:16.686961 43755 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0824 21:59:16.686966 43755 solver.cpp:280] Learning Rate Policy: step
I0824 21:59:17.767812 43755 solver.cpp:228] Iteration 0, loss = 0.730228
I0824 21:59:17.767856 43755 solver.cpp:244]     Train net output #0: accuracy = 0.500577
I0824 21:59:17.767869 43755 solver.cpp:244]     Train net output #1: loss = 0.730228 (* 1 = 0.730228 loss)
I0824 21:59:17.767885 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.411287
I0824 21:59:17.767896 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.806794
I0824 21:59:17.767920 43755 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0824 21:59:34.803642 43755 solver.cpp:228] Iteration 20, loss = 0.566612
I0824 21:59:34.803689 43755 solver.cpp:244]     Train net output #0: accuracy = 0.580936
I0824 21:59:34.803699 43755 solver.cpp:244]     Train net output #1: loss = 0.566612 (* 1 = 0.566612 loss)
I0824 21:59:34.803705 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.551235
I0824 21:59:34.803710 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.740401
I0824 21:59:34.803717 43755 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0824 21:59:51.417330 43755 solver.cpp:228] Iteration 40, loss = 0.399689
I0824 21:59:51.417481 43755 solver.cpp:244]     Train net output #0: accuracy = 0.81649
I0824 21:59:51.417496 43755 solver.cpp:244]     Train net output #1: loss = 0.399689 (* 1 = 0.399689 loss)
I0824 21:59:51.417503 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.780338
I0824 21:59:51.417507 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.894005
I0824 21:59:51.417515 43755 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0824 22:00:07.988441 43755 solver.cpp:228] Iteration 60, loss = 0.472333
I0824 22:00:07.988488 43755 solver.cpp:244]     Train net output #0: accuracy = 0.765023
I0824 22:00:07.988502 43755 solver.cpp:244]     Train net output #1: loss = 0.472333 (* 1 = 0.472333 loss)
I0824 22:00:07.988507 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.795936
I0824 22:00:07.988512 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.638918
I0824 22:00:07.988519 43755 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0824 22:00:24.570989 43755 solver.cpp:228] Iteration 80, loss = 0.369927
I0824 22:00:24.571133 43755 solver.cpp:244]     Train net output #0: accuracy = 0.833517
I0824 22:00:24.571149 43755 solver.cpp:244]     Train net output #1: loss = 0.369927 (* 1 = 0.369927 loss)
I0824 22:00:24.571159 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.826425
I0824 22:00:24.571164 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.849611
I0824 22:00:24.571172 43755 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0824 22:00:41.163869 43755 solver.cpp:228] Iteration 100, loss = 0.372209
I0824 22:00:41.163913 43755 solver.cpp:244]     Train net output #0: accuracy = 0.869761
I0824 22:00:41.163925 43755 solver.cpp:244]     Train net output #1: loss = 0.372209 (* 1 = 0.372209 loss)
I0824 22:00:41.163931 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.937278
I0824 22:00:41.163936 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.787068
I0824 22:00:41.163944 43755 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0824 22:00:57.755089 43755 solver.cpp:228] Iteration 120, loss = 0.419203
I0824 22:00:57.755264 43755 solver.cpp:244]     Train net output #0: accuracy = 0.75383
I0824 22:00:57.755281 43755 solver.cpp:244]     Train net output #1: loss = 0.419203 (* 1 = 0.419203 loss)
I0824 22:00:57.755290 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.709391
I0824 22:00:57.755295 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9708
I0824 22:00:57.755302 43755 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0824 22:01:14.358219 43755 solver.cpp:228] Iteration 140, loss = 0.15818
I0824 22:01:14.358263 43755 solver.cpp:244]     Train net output #0: accuracy = 0.953887
I0824 22:01:14.358275 43755 solver.cpp:244]     Train net output #1: loss = 0.158181 (* 1 = 0.158181 loss)
I0824 22:01:14.358281 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.952778
I0824 22:01:14.358286 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.955554
I0824 22:01:14.358294 43755 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0824 22:01:30.952147 43755 solver.cpp:228] Iteration 160, loss = 0.170022
I0824 22:01:30.952270 43755 solver.cpp:244]     Train net output #0: accuracy = 0.936473
I0824 22:01:30.952283 43755 solver.cpp:244]     Train net output #1: loss = 0.170022 (* 1 = 0.170022 loss)
I0824 22:01:30.952288 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.928291
I0824 22:01:30.952293 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.955357
I0824 22:01:30.952301 43755 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0824 22:01:47.548719 43755 solver.cpp:228] Iteration 180, loss = 0.174049
I0824 22:01:47.548763 43755 solver.cpp:244]     Train net output #0: accuracy = 0.957332
I0824 22:01:47.548775 43755 solver.cpp:244]     Train net output #1: loss = 0.174049 (* 1 = 0.174049 loss)
I0824 22:01:47.548782 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975727
I0824 22:01:47.548787 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.934609
I0824 22:01:47.548795 43755 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0824 22:02:04.138394 43755 solver.cpp:228] Iteration 200, loss = 0.28937
I0824 22:02:04.138494 43755 solver.cpp:244]     Train net output #0: accuracy = 0.893218
I0824 22:02:04.138509 43755 solver.cpp:244]     Train net output #1: loss = 0.28937 (* 1 = 0.28937 loss)
I0824 22:02:04.138514 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.889285
I0824 22:02:04.138519 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.899332
I0824 22:02:04.138525 43755 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0824 22:02:20.744233 43755 solver.cpp:228] Iteration 220, loss = 0.1704
I0824 22:02:20.744287 43755 solver.cpp:244]     Train net output #0: accuracy = 0.92489
I0824 22:02:20.744302 43755 solver.cpp:244]     Train net output #1: loss = 0.1704 (* 1 = 0.1704 loss)
I0824 22:02:20.744307 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.900512
I0824 22:02:20.744313 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989214
I0824 22:02:20.744321 43755 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0824 22:02:37.386798 43755 solver.cpp:228] Iteration 240, loss = 0.115591
I0824 22:02:37.386907 43755 solver.cpp:244]     Train net output #0: accuracy = 0.954834
I0824 22:02:37.386922 43755 solver.cpp:244]     Train net output #1: loss = 0.115591 (* 1 = 0.115591 loss)
I0824 22:02:37.386929 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.940903
I0824 22:02:37.386934 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984649
I0824 22:02:37.386941 43755 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0824 22:02:53.978453 43755 solver.cpp:228] Iteration 260, loss = 0.1054
I0824 22:02:53.978495 43755 solver.cpp:244]     Train net output #0: accuracy = 0.953378
I0824 22:02:53.978507 43755 solver.cpp:244]     Train net output #1: loss = 0.1054 (* 1 = 0.1054 loss)
I0824 22:02:53.978513 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.946579
I0824 22:02:53.978526 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.971191
I0824 22:02:53.978533 43755 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0824 22:03:10.564476 43755 solver.cpp:228] Iteration 280, loss = 0.0995086
I0824 22:03:10.564647 43755 solver.cpp:244]     Train net output #0: accuracy = 0.967597
I0824 22:03:10.564663 43755 solver.cpp:244]     Train net output #1: loss = 0.0995087 (* 1 = 0.0995087 loss)
I0824 22:03:10.564676 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.956935
I0824 22:03:10.564680 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990796
I0824 22:03:10.564687 43755 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0824 22:03:27.160307 43755 solver.cpp:228] Iteration 300, loss = 0.213427
I0824 22:03:27.160349 43755 solver.cpp:244]     Train net output #0: accuracy = 0.905835
I0824 22:03:27.160362 43755 solver.cpp:244]     Train net output #1: loss = 0.213427 (* 1 = 0.213427 loss)
I0824 22:03:27.160369 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.864446
I0824 22:03:27.160374 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986
I0824 22:03:27.160382 43755 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0824 22:03:43.763553 43755 solver.cpp:228] Iteration 320, loss = 0.087862
I0824 22:03:43.763667 43755 solver.cpp:244]     Train net output #0: accuracy = 0.966047
I0824 22:03:43.763682 43755 solver.cpp:244]     Train net output #1: loss = 0.0878621 (* 1 = 0.0878621 loss)
I0824 22:03:43.763691 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.957282
I0824 22:03:43.763696 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988518
I0824 22:03:43.763703 43755 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0824 22:04:00.345993 43755 solver.cpp:228] Iteration 340, loss = 0.212455
I0824 22:04:00.346036 43755 solver.cpp:244]     Train net output #0: accuracy = 0.931411
I0824 22:04:00.346051 43755 solver.cpp:244]     Train net output #1: loss = 0.212455 (* 1 = 0.212455 loss)
I0824 22:04:00.346057 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.93072
I0824 22:04:00.346062 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.932284
I0824 22:04:00.346071 43755 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0824 22:04:16.948897 43755 solver.cpp:228] Iteration 360, loss = 0.122711
I0824 22:04:16.949009 43755 solver.cpp:244]     Train net output #0: accuracy = 0.960645
I0824 22:04:16.949023 43755 solver.cpp:244]     Train net output #1: loss = 0.122711 (* 1 = 0.122711 loss)
I0824 22:04:16.949035 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975125
I0824 22:04:16.949040 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.93613
I0824 22:04:16.949048 43755 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0824 22:04:33.544401 43755 solver.cpp:228] Iteration 380, loss = 0.0623916
I0824 22:04:33.544445 43755 solver.cpp:244]     Train net output #0: accuracy = 0.971766
I0824 22:04:33.544458 43755 solver.cpp:244]     Train net output #1: loss = 0.0623916 (* 1 = 0.0623916 loss)
I0824 22:04:33.544464 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.964673
I0824 22:04:33.544471 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98704
I0824 22:04:33.544477 43755 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0824 22:04:50.131501 43755 solver.cpp:228] Iteration 400, loss = 0.0503058
I0824 22:04:50.131613 43755 solver.cpp:244]     Train net output #0: accuracy = 0.98387
I0824 22:04:50.131628 43755 solver.cpp:244]     Train net output #1: loss = 0.0503059 (* 1 = 0.0503059 loss)
I0824 22:04:50.131641 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983818
I0824 22:04:50.131646 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983951
I0824 22:04:50.131654 43755 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0824 22:05:06.725903 43755 solver.cpp:228] Iteration 420, loss = 0.119053
I0824 22:05:06.725939 43755 solver.cpp:244]     Train net output #0: accuracy = 0.954715
I0824 22:05:06.725955 43755 solver.cpp:244]     Train net output #1: loss = 0.119053 (* 1 = 0.119053 loss)
I0824 22:05:06.725961 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.949362
I0824 22:05:06.725966 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.975145
I0824 22:05:06.725973 43755 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0824 22:05:23.313298 43755 solver.cpp:228] Iteration 440, loss = 0.121964
I0824 22:05:23.313473 43755 solver.cpp:244]     Train net output #0: accuracy = 0.948391
I0824 22:05:23.313491 43755 solver.cpp:244]     Train net output #1: loss = 0.121964 (* 1 = 0.121964 loss)
I0824 22:05:23.313500 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.928267
I0824 22:05:23.313505 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988318
I0824 22:05:23.313513 43755 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0824 22:05:39.913002 43755 solver.cpp:228] Iteration 460, loss = 0.0723825
I0824 22:05:39.913044 43755 solver.cpp:244]     Train net output #0: accuracy = 0.972144
I0824 22:05:39.913058 43755 solver.cpp:244]     Train net output #1: loss = 0.0723825 (* 1 = 0.0723825 loss)
I0824 22:05:39.913064 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969726
I0824 22:05:39.913069 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982208
I0824 22:05:39.913075 43755 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0824 22:05:56.529278 43755 solver.cpp:228] Iteration 480, loss = 0.0502746
I0824 22:05:56.529392 43755 solver.cpp:244]     Train net output #0: accuracy = 0.982501
I0824 22:05:56.529408 43755 solver.cpp:244]     Train net output #1: loss = 0.0502746 (* 1 = 0.0502746 loss)
I0824 22:05:56.529424 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984864
I0824 22:05:56.529429 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.975795
I0824 22:05:56.529438 43755 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0824 22:06:13.131923 43755 solver.cpp:228] Iteration 500, loss = 0.0534243
I0824 22:06:13.131965 43755 solver.cpp:244]     Train net output #0: accuracy = 0.978004
I0824 22:06:13.131978 43755 solver.cpp:244]     Train net output #1: loss = 0.0534244 (* 1 = 0.0534244 loss)
I0824 22:06:13.131984 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975704
I0824 22:06:13.131989 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9841
I0824 22:06:13.131997 43755 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0824 22:06:29.728920 43755 solver.cpp:228] Iteration 520, loss = 0.0503521
I0824 22:06:29.729022 43755 solver.cpp:244]     Train net output #0: accuracy = 0.982985
I0824 22:06:29.729037 43755 solver.cpp:244]     Train net output #1: loss = 0.0503522 (* 1 = 0.0503522 loss)
I0824 22:06:29.729043 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987125
I0824 22:06:29.729048 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.966969
I0824 22:06:29.729055 43755 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0824 22:06:46.306670 43755 solver.cpp:228] Iteration 540, loss = 0.0593158
I0824 22:06:46.306707 43755 solver.cpp:244]     Train net output #0: accuracy = 0.971574
I0824 22:06:46.306720 43755 solver.cpp:244]     Train net output #1: loss = 0.0593159 (* 1 = 0.0593159 loss)
I0824 22:06:46.306725 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.966344
I0824 22:06:46.306730 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986447
I0824 22:06:46.306737 43755 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0824 22:07:02.910641 43755 solver.cpp:228] Iteration 560, loss = 0.0618197
I0824 22:07:02.910806 43755 solver.cpp:244]     Train net output #0: accuracy = 0.979657
I0824 22:07:02.910822 43755 solver.cpp:244]     Train net output #1: loss = 0.0618198 (* 1 = 0.0618198 loss)
I0824 22:07:02.910830 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985032
I0824 22:07:02.910835 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.966493
I0824 22:07:02.910848 43755 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0824 22:07:19.536960 43755 solver.cpp:228] Iteration 580, loss = 0.0378207
I0824 22:07:19.537005 43755 solver.cpp:244]     Train net output #0: accuracy = 0.985372
I0824 22:07:19.537020 43755 solver.cpp:244]     Train net output #1: loss = 0.0378208 (* 1 = 0.0378208 loss)
I0824 22:07:19.537026 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984686
I0824 22:07:19.537031 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986821
I0824 22:07:19.537039 43755 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0824 22:07:36.131147 43755 solver.cpp:228] Iteration 600, loss = 0.046831
I0824 22:07:36.131256 43755 solver.cpp:244]     Train net output #0: accuracy = 0.984267
I0824 22:07:36.131271 43755 solver.cpp:244]     Train net output #1: loss = 0.046831 (* 1 = 0.046831 loss)
I0824 22:07:36.131283 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987419
I0824 22:07:36.131287 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.972369
I0824 22:07:36.131294 43755 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0824 22:07:52.722836 43755 solver.cpp:228] Iteration 620, loss = 0.0460092
I0824 22:07:52.722882 43755 solver.cpp:244]     Train net output #0: accuracy = 0.981438
I0824 22:07:52.722895 43755 solver.cpp:244]     Train net output #1: loss = 0.0460093 (* 1 = 0.0460093 loss)
I0824 22:07:52.722901 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.978055
I0824 22:07:52.722906 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992529
I0824 22:07:52.722913 43755 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0824 22:08:09.318771 43755 solver.cpp:228] Iteration 640, loss = 0.0313963
I0824 22:08:09.318904 43755 solver.cpp:244]     Train net output #0: accuracy = 0.987526
I0824 22:08:09.318919 43755 solver.cpp:244]     Train net output #1: loss = 0.0313964 (* 1 = 0.0313964 loss)
I0824 22:08:09.318924 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983681
I0824 22:08:09.318930 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994206
I0824 22:08:09.318938 43755 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0824 22:08:25.924386 43755 solver.cpp:228] Iteration 660, loss = 0.034784
I0824 22:08:25.924424 43755 solver.cpp:244]     Train net output #0: accuracy = 0.990101
I0824 22:08:25.924437 43755 solver.cpp:244]     Train net output #1: loss = 0.0347841 (* 1 = 0.0347841 loss)
I0824 22:08:25.924443 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995955
I0824 22:08:25.924448 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.966821
I0824 22:08:25.924455 43755 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0824 22:08:42.522034 43755 solver.cpp:228] Iteration 680, loss = 0.0451854
I0824 22:08:42.522153 43755 solver.cpp:244]     Train net output #0: accuracy = 0.983356
I0824 22:08:42.522169 43755 solver.cpp:244]     Train net output #1: loss = 0.0451855 (* 1 = 0.0451855 loss)
I0824 22:08:42.522176 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975329
I0824 22:08:42.522181 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992957
I0824 22:08:42.522188 43755 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0824 22:08:59.132946 43755 solver.cpp:228] Iteration 700, loss = 0.0443061
I0824 22:08:59.132987 43755 solver.cpp:244]     Train net output #0: accuracy = 0.984249
I0824 22:08:59.132999 43755 solver.cpp:244]     Train net output #1: loss = 0.0443061 (* 1 = 0.0443061 loss)
I0824 22:08:59.133005 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982562
I0824 22:08:59.133016 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986865
I0824 22:08:59.133024 43755 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0824 22:09:15.738634 43755 solver.cpp:228] Iteration 720, loss = 0.029534
I0824 22:09:15.738814 43755 solver.cpp:244]     Train net output #0: accuracy = 0.988744
I0824 22:09:15.738831 43755 solver.cpp:244]     Train net output #1: loss = 0.0295341 (* 1 = 0.0295341 loss)
I0824 22:09:15.738838 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987718
I0824 22:09:15.738843 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991135
I0824 22:09:15.738852 43755 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0824 22:09:32.366094 43755 solver.cpp:228] Iteration 740, loss = 0.0421577
I0824 22:09:32.366143 43755 solver.cpp:244]     Train net output #0: accuracy = 0.983377
I0824 22:09:32.366158 43755 solver.cpp:244]     Train net output #1: loss = 0.0421578 (* 1 = 0.0421578 loss)
I0824 22:09:32.366171 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983163
I0824 22:09:32.366181 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984202
I0824 22:09:32.366191 43755 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0824 22:09:48.978341 43755 solver.cpp:228] Iteration 760, loss = 0.0518915
I0824 22:09:48.978502 43755 solver.cpp:244]     Train net output #0: accuracy = 0.984959
I0824 22:09:48.978543 43755 solver.cpp:244]     Train net output #1: loss = 0.0518915 (* 1 = 0.0518915 loss)
I0824 22:09:48.978551 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983933
I0824 22:09:48.978562 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986054
I0824 22:09:48.978570 43755 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0824 22:10:05.601924 43755 solver.cpp:228] Iteration 780, loss = 0.041455
I0824 22:10:05.601976 43755 solver.cpp:244]     Train net output #0: accuracy = 0.982036
I0824 22:10:05.601992 43755 solver.cpp:244]     Train net output #1: loss = 0.0414551 (* 1 = 0.0414551 loss)
I0824 22:10:05.602000 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975732
I0824 22:10:05.602006 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995101
I0824 22:10:05.602016 43755 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0824 22:10:22.215709 43755 solver.cpp:228] Iteration 800, loss = 0.0467347
I0824 22:10:22.215836 43755 solver.cpp:244]     Train net output #0: accuracy = 0.982915
I0824 22:10:22.215852 43755 solver.cpp:244]     Train net output #1: loss = 0.0467347 (* 1 = 0.0467347 loss)
I0824 22:10:22.215859 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980614
I0824 22:10:22.215864 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986163
I0824 22:10:22.215873 43755 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0824 22:10:38.822825 43755 solver.cpp:228] Iteration 820, loss = 0.0223061
I0824 22:10:38.822872 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99178
I0824 22:10:38.822886 43755 solver.cpp:244]     Train net output #1: loss = 0.0223061 (* 1 = 0.0223061 loss)
I0824 22:10:38.822892 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991612
I0824 22:10:38.822898 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992183
I0824 22:10:38.822907 43755 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0824 22:10:55.442113 43755 solver.cpp:228] Iteration 840, loss = 0.033138
I0824 22:10:55.442230 43755 solver.cpp:244]     Train net output #0: accuracy = 0.987982
I0824 22:10:55.442247 43755 solver.cpp:244]     Train net output #1: loss = 0.033138 (* 1 = 0.033138 loss)
I0824 22:10:55.442255 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989829
I0824 22:10:55.442260 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984314
I0824 22:10:55.442270 43755 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0824 22:11:12.041883 43755 solver.cpp:228] Iteration 860, loss = 0.0403198
I0824 22:11:12.041926 43755 solver.cpp:244]     Train net output #0: accuracy = 0.986477
I0824 22:11:12.041939 43755 solver.cpp:244]     Train net output #1: loss = 0.0403199 (* 1 = 0.0403199 loss)
I0824 22:11:12.041945 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99036
I0824 22:11:12.041951 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.97242
I0824 22:11:12.041959 43755 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0824 22:11:28.660578 43755 solver.cpp:228] Iteration 880, loss = 0.0429112
I0824 22:11:28.660753 43755 solver.cpp:244]     Train net output #0: accuracy = 0.982321
I0824 22:11:28.660769 43755 solver.cpp:244]     Train net output #1: loss = 0.0429113 (* 1 = 0.0429113 loss)
I0824 22:11:28.660776 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977034
I0824 22:11:28.660781 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990834
I0824 22:11:28.660789 43755 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0824 22:11:45.256352 43755 solver.cpp:228] Iteration 900, loss = 0.040336
I0824 22:11:45.256400 43755 solver.cpp:244]     Train net output #0: accuracy = 0.986668
I0824 22:11:45.256415 43755 solver.cpp:244]     Train net output #1: loss = 0.0403361 (* 1 = 0.0403361 loss)
I0824 22:11:45.256423 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990231
I0824 22:11:45.256429 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.967235
I0824 22:11:45.256438 43755 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0824 22:12:01.867880 43755 solver.cpp:228] Iteration 920, loss = 0.0342726
I0824 22:12:01.868001 43755 solver.cpp:244]     Train net output #0: accuracy = 0.988578
I0824 22:12:01.868017 43755 solver.cpp:244]     Train net output #1: loss = 0.0342726 (* 1 = 0.0342726 loss)
I0824 22:12:01.868024 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981948
I0824 22:12:01.868031 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995859
I0824 22:12:01.868039 43755 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0824 22:12:18.467870 43755 solver.cpp:228] Iteration 940, loss = 0.0588311
I0824 22:12:18.467918 43755 solver.cpp:244]     Train net output #0: accuracy = 0.978343
I0824 22:12:18.467932 43755 solver.cpp:244]     Train net output #1: loss = 0.0588311 (* 1 = 0.0588311 loss)
I0824 22:12:18.467939 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982389
I0824 22:12:18.467947 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.967599
I0824 22:12:18.467954 43755 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0824 22:12:35.081655 43755 solver.cpp:228] Iteration 960, loss = 0.0541434
I0824 22:12:35.081769 43755 solver.cpp:244]     Train net output #0: accuracy = 0.978503
I0824 22:12:35.081786 43755 solver.cpp:244]     Train net output #1: loss = 0.0541435 (* 1 = 0.0541435 loss)
I0824 22:12:35.081794 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975185
I0824 22:12:35.081800 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986769
I0824 22:12:35.081809 43755 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0824 22:12:51.718988 43755 solver.cpp:228] Iteration 980, loss = 0.0493949
I0824 22:12:51.719032 43755 solver.cpp:244]     Train net output #0: accuracy = 0.984605
I0824 22:12:51.719044 43755 solver.cpp:244]     Train net output #1: loss = 0.049395 (* 1 = 0.049395 loss)
I0824 22:12:51.719050 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98529
I0824 22:12:51.719055 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983632
I0824 22:12:51.719063 43755 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0824 22:13:08.315093 43755 solver.cpp:228] Iteration 1000, loss = 0.0266228
I0824 22:13:08.315218 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989974
I0824 22:13:08.315235 43755 solver.cpp:244]     Train net output #1: loss = 0.0266229 (* 1 = 0.0266229 loss)
I0824 22:13:08.315241 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989896
I0824 22:13:08.315248 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990159
I0824 22:13:08.315254 43755 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0824 22:13:24.936162 43755 solver.cpp:228] Iteration 1020, loss = 0.0436823
I0824 22:13:24.936205 43755 solver.cpp:244]     Train net output #0: accuracy = 0.985282
I0824 22:13:24.936218 43755 solver.cpp:244]     Train net output #1: loss = 0.0436824 (* 1 = 0.0436824 loss)
I0824 22:13:24.936225 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983752
I0824 22:13:24.936231 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98748
I0824 22:13:24.936239 43755 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0824 22:13:41.542604 43755 solver.cpp:228] Iteration 1040, loss = 0.0362155
I0824 22:13:41.542776 43755 solver.cpp:244]     Train net output #0: accuracy = 0.988275
I0824 22:13:41.542793 43755 solver.cpp:244]     Train net output #1: loss = 0.0362156 (* 1 = 0.0362156 loss)
I0824 22:13:41.542805 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989241
I0824 22:13:41.542810 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986724
I0824 22:13:41.542817 43755 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0824 22:13:58.141064 43755 solver.cpp:228] Iteration 1060, loss = 0.0365389
I0824 22:13:58.141105 43755 solver.cpp:244]     Train net output #0: accuracy = 0.987117
I0824 22:13:58.141118 43755 solver.cpp:244]     Train net output #1: loss = 0.036539 (* 1 = 0.036539 loss)
I0824 22:13:58.141124 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989142
I0824 22:13:58.141129 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980182
I0824 22:13:58.141136 43755 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0824 22:14:14.780467 43755 solver.cpp:228] Iteration 1080, loss = 0.0320843
I0824 22:14:14.780627 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989311
I0824 22:14:14.780647 43755 solver.cpp:244]     Train net output #1: loss = 0.0320844 (* 1 = 0.0320844 loss)
I0824 22:14:14.780658 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990762
I0824 22:14:14.780670 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986183
I0824 22:14:14.780680 43755 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0824 22:14:31.384618 43755 solver.cpp:228] Iteration 1100, loss = 0.053408
I0824 22:14:31.384668 43755 solver.cpp:244]     Train net output #0: accuracy = 0.980943
I0824 22:14:31.384683 43755 solver.cpp:244]     Train net output #1: loss = 0.0534082 (* 1 = 0.0534082 loss)
I0824 22:14:31.384691 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984199
I0824 22:14:31.384696 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.96912
I0824 22:14:31.384704 43755 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0824 22:14:48.020483 43755 solver.cpp:228] Iteration 1120, loss = 0.0516823
I0824 22:14:48.020603 43755 solver.cpp:244]     Train net output #0: accuracy = 0.986191
I0824 22:14:48.020622 43755 solver.cpp:244]     Train net output #1: loss = 0.0516824 (* 1 = 0.0516824 loss)
I0824 22:14:48.020628 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996724
I0824 22:14:48.020635 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.944444
I0824 22:14:48.020644 43755 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0824 22:15:04.647179 43755 solver.cpp:228] Iteration 1140, loss = 0.0708547
I0824 22:15:04.647224 43755 solver.cpp:244]     Train net output #0: accuracy = 0.980065
I0824 22:15:04.647238 43755 solver.cpp:244]     Train net output #1: loss = 0.0708548 (* 1 = 0.0708548 loss)
I0824 22:15:04.647245 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973628
I0824 22:15:04.647250 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986649
I0824 22:15:04.647259 43755 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0824 22:15:21.266839 43755 solver.cpp:228] Iteration 1160, loss = 0.0679423
I0824 22:15:21.267010 43755 solver.cpp:244]     Train net output #0: accuracy = 0.984601
I0824 22:15:21.267030 43755 solver.cpp:244]     Train net output #1: loss = 0.0679424 (* 1 = 0.0679424 loss)
I0824 22:15:21.267037 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987724
I0824 22:15:21.267042 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982167
I0824 22:15:21.267050 43755 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0824 22:15:37.903187 43755 solver.cpp:228] Iteration 1180, loss = 0.0309482
I0824 22:15:37.903231 43755 solver.cpp:244]     Train net output #0: accuracy = 0.988843
I0824 22:15:37.903245 43755 solver.cpp:244]     Train net output #1: loss = 0.0309483 (* 1 = 0.0309483 loss)
I0824 22:15:37.903252 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990415
I0824 22:15:37.903257 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984642
I0824 22:15:37.903266 43755 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0824 22:15:54.518815 43755 solver.cpp:228] Iteration 1200, loss = 0.0342553
I0824 22:15:54.518928 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989485
I0824 22:15:54.518944 43755 solver.cpp:244]     Train net output #1: loss = 0.0342554 (* 1 = 0.0342554 loss)
I0824 22:15:54.518957 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992525
I0824 22:15:54.518963 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983379
I0824 22:15:54.518970 43755 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0824 22:16:11.131428 43755 solver.cpp:228] Iteration 1220, loss = 0.0316689
I0824 22:16:11.131474 43755 solver.cpp:244]     Train net output #0: accuracy = 0.985651
I0824 22:16:11.131486 43755 solver.cpp:244]     Train net output #1: loss = 0.031669 (* 1 = 0.031669 loss)
I0824 22:16:11.131494 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98449
I0824 22:16:11.131498 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988709
I0824 22:16:11.131506 43755 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0824 22:16:27.775089 43755 solver.cpp:228] Iteration 1240, loss = 0.0283895
I0824 22:16:27.775204 43755 solver.cpp:244]     Train net output #0: accuracy = 0.988977
I0824 22:16:27.775223 43755 solver.cpp:244]     Train net output #1: loss = 0.0283896 (* 1 = 0.0283896 loss)
I0824 22:16:27.775234 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989382
I0824 22:16:27.775245 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988061
I0824 22:16:27.775254 43755 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0824 22:16:44.376874 43755 solver.cpp:228] Iteration 1260, loss = 0.0331072
I0824 22:16:44.376917 43755 solver.cpp:244]     Train net output #0: accuracy = 0.987637
I0824 22:16:44.376933 43755 solver.cpp:244]     Train net output #1: loss = 0.0331073 (* 1 = 0.0331073 loss)
I0824 22:16:44.376940 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98734
I0824 22:16:44.376946 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988174
I0824 22:16:44.376955 43755 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0824 22:17:01.020615 43755 solver.cpp:228] Iteration 1280, loss = 0.0211245
I0824 22:17:01.020722 43755 solver.cpp:244]     Train net output #0: accuracy = 0.991875
I0824 22:17:01.020736 43755 solver.cpp:244]     Train net output #1: loss = 0.0211246 (* 1 = 0.0211246 loss)
I0824 22:17:01.020743 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990517
I0824 22:17:01.020758 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994391
I0824 22:17:01.020766 43755 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0824 22:17:17.636198 43755 solver.cpp:228] Iteration 1300, loss = 0.0288343
I0824 22:17:17.636245 43755 solver.cpp:244]     Train net output #0: accuracy = 0.990506
I0824 22:17:17.636260 43755 solver.cpp:244]     Train net output #1: loss = 0.0288344 (* 1 = 0.0288344 loss)
I0824 22:17:17.636267 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995325
I0824 22:17:17.636273 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.977637
I0824 22:17:17.636281 43755 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0824 22:17:34.260009 43755 solver.cpp:228] Iteration 1320, loss = 0.0189571
I0824 22:17:34.260174 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992742
I0824 22:17:34.260192 43755 solver.cpp:244]     Train net output #1: loss = 0.0189572 (* 1 = 0.0189572 loss)
I0824 22:17:34.260200 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992269
I0824 22:17:34.260205 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993785
I0824 22:17:34.260212 43755 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0824 22:17:50.865643 43755 solver.cpp:228] Iteration 1340, loss = 0.0245234
I0824 22:17:50.865689 43755 solver.cpp:244]     Train net output #0: accuracy = 0.990842
I0824 22:17:50.865705 43755 solver.cpp:244]     Train net output #1: loss = 0.0245235 (* 1 = 0.0245235 loss)
I0824 22:17:50.865712 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992585
I0824 22:17:50.865720 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98505
I0824 22:17:50.865730 43755 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0824 22:18:07.489403 43755 solver.cpp:228] Iteration 1360, loss = 0.0291663
I0824 22:18:07.489507 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989327
I0824 22:18:07.489524 43755 solver.cpp:244]     Train net output #1: loss = 0.0291664 (* 1 = 0.0291664 loss)
I0824 22:18:07.489532 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98872
I0824 22:18:07.489538 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992417
I0824 22:18:07.489548 43755 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0824 22:18:24.103960 43755 solver.cpp:228] Iteration 1380, loss = 0.029475
I0824 22:18:24.104008 43755 solver.cpp:244]     Train net output #0: accuracy = 0.988125
I0824 22:18:24.104023 43755 solver.cpp:244]     Train net output #1: loss = 0.0294751 (* 1 = 0.0294751 loss)
I0824 22:18:24.104032 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98615
I0824 22:18:24.104038 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991374
I0824 22:18:24.104046 43755 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0824 22:18:40.744686 43755 solver.cpp:228] Iteration 1400, loss = 0.0205666
I0824 22:18:40.744796 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99339
I0824 22:18:40.744812 43755 solver.cpp:244]     Train net output #1: loss = 0.0205667 (* 1 = 0.0205667 loss)
I0824 22:18:40.744818 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994155
I0824 22:18:40.744832 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991678
I0824 22:18:40.744838 43755 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0824 22:18:57.346048 43755 solver.cpp:228] Iteration 1420, loss = 0.02708
I0824 22:18:57.346096 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989679
I0824 22:18:57.346112 43755 solver.cpp:244]     Train net output #1: loss = 0.0270801 (* 1 = 0.0270801 loss)
I0824 22:18:57.346118 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989936
I0824 22:18:57.346123 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988527
I0824 22:18:57.346132 43755 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0824 22:19:13.950117 43755 solver.cpp:228] Iteration 1440, loss = 0.0271327
I0824 22:19:13.950225 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989334
I0824 22:19:13.950242 43755 solver.cpp:244]     Train net output #1: loss = 0.0271329 (* 1 = 0.0271329 loss)
I0824 22:19:13.950248 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985591
I0824 22:19:13.950253 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994181
I0824 22:19:13.950260 43755 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0824 22:19:30.554811 43755 solver.cpp:228] Iteration 1460, loss = 0.0329735
I0824 22:19:30.554854 43755 solver.cpp:244]     Train net output #0: accuracy = 0.988008
I0824 22:19:30.554869 43755 solver.cpp:244]     Train net output #1: loss = 0.0329737 (* 1 = 0.0329737 loss)
I0824 22:19:30.554883 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988855
I0824 22:19:30.554888 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985242
I0824 22:19:30.554895 43755 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0824 22:19:47.143251 43755 solver.cpp:228] Iteration 1480, loss = 0.0196831
I0824 22:19:47.143415 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993445
I0824 22:19:47.143438 43755 solver.cpp:244]     Train net output #1: loss = 0.0196832 (* 1 = 0.0196832 loss)
I0824 22:19:47.143446 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995637
I0824 22:19:47.143452 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983021
I0824 22:19:47.143460 43755 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0824 22:20:03.764659 43755 solver.cpp:228] Iteration 1500, loss = 0.033494
I0824 22:20:03.764701 43755 solver.cpp:244]     Train net output #0: accuracy = 0.986811
I0824 22:20:03.764714 43755 solver.cpp:244]     Train net output #1: loss = 0.0334941 (* 1 = 0.0334941 loss)
I0824 22:20:03.764720 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985951
I0824 22:20:03.764725 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988263
I0824 22:20:03.764734 43755 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0824 22:20:20.353896 43755 solver.cpp:228] Iteration 1520, loss = 0.0282054
I0824 22:20:20.353993 43755 solver.cpp:244]     Train net output #0: accuracy = 0.990525
I0824 22:20:20.354010 43755 solver.cpp:244]     Train net output #1: loss = 0.0282055 (* 1 = 0.0282055 loss)
I0824 22:20:20.354022 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99207
I0824 22:20:20.354032 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988119
I0824 22:20:20.354040 43755 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0824 22:20:36.953758 43755 solver.cpp:228] Iteration 1540, loss = 0.0392136
I0824 22:20:36.953804 43755 solver.cpp:244]     Train net output #0: accuracy = 0.983845
I0824 22:20:36.953817 43755 solver.cpp:244]     Train net output #1: loss = 0.0392137 (* 1 = 0.0392137 loss)
I0824 22:20:36.953824 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.97903
I0824 22:20:36.953829 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990784
I0824 22:20:36.953835 43755 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0824 22:20:53.536785 43755 solver.cpp:228] Iteration 1560, loss = 0.0289494
I0824 22:20:53.536880 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989054
I0824 22:20:53.536896 43755 solver.cpp:244]     Train net output #1: loss = 0.0289495 (* 1 = 0.0289495 loss)
I0824 22:20:53.536907 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990059
I0824 22:20:53.536912 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985361
I0824 22:20:53.536921 43755 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0824 22:21:10.133828 43755 solver.cpp:228] Iteration 1580, loss = 0.022462
I0824 22:21:10.133872 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99124
I0824 22:21:10.133886 43755 solver.cpp:244]     Train net output #1: loss = 0.0224621 (* 1 = 0.0224621 loss)
I0824 22:21:10.133893 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991312
I0824 22:21:10.133898 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991042
I0824 22:21:10.133904 43755 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0824 22:21:26.722156 43755 solver.cpp:228] Iteration 1600, loss = 0.0258754
I0824 22:21:26.722257 43755 solver.cpp:244]     Train net output #0: accuracy = 0.990162
I0824 22:21:26.722272 43755 solver.cpp:244]     Train net output #1: loss = 0.0258755 (* 1 = 0.0258755 loss)
I0824 22:21:26.722278 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987517
I0824 22:21:26.722283 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994092
I0824 22:21:26.722291 43755 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0824 22:21:43.310142 43755 solver.cpp:228] Iteration 1620, loss = 0.0296254
I0824 22:21:43.310186 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989175
I0824 22:21:43.310202 43755 solver.cpp:244]     Train net output #1: loss = 0.0296255 (* 1 = 0.0296255 loss)
I0824 22:21:43.310209 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985518
I0824 22:21:43.310214 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99341
I0824 22:21:43.310223 43755 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0824 22:21:59.912209 43755 solver.cpp:228] Iteration 1640, loss = 0.0220804
I0824 22:21:59.912367 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992448
I0824 22:21:59.912385 43755 solver.cpp:244]     Train net output #1: loss = 0.0220806 (* 1 = 0.0220806 loss)
I0824 22:21:59.912395 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993853
I0824 22:21:59.912400 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989229
I0824 22:21:59.912407 43755 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0824 22:22:16.512092 43755 solver.cpp:228] Iteration 1660, loss = 0.0240252
I0824 22:22:16.512135 43755 solver.cpp:244]     Train net output #0: accuracy = 0.9915
I0824 22:22:16.512148 43755 solver.cpp:244]     Train net output #1: loss = 0.0240253 (* 1 = 0.0240253 loss)
I0824 22:22:16.512153 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987994
I0824 22:22:16.512158 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995452
I0824 22:22:16.512166 43755 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0824 22:22:33.127982 43755 solver.cpp:228] Iteration 1680, loss = 0.0213485
I0824 22:22:33.128074 43755 solver.cpp:244]     Train net output #0: accuracy = 0.991509
I0824 22:22:33.128092 43755 solver.cpp:244]     Train net output #1: loss = 0.0213486 (* 1 = 0.0213486 loss)
I0824 22:22:33.128098 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992477
I0824 22:22:33.128103 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986535
I0824 22:22:33.128109 43755 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0824 22:22:49.736979 43755 solver.cpp:228] Iteration 1700, loss = 0.0443501
I0824 22:22:49.737021 43755 solver.cpp:244]     Train net output #0: accuracy = 0.987334
I0824 22:22:49.737035 43755 solver.cpp:244]     Train net output #1: loss = 0.0443502 (* 1 = 0.0443502 loss)
I0824 22:22:49.737040 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982345
I0824 22:22:49.737046 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991526
I0824 22:22:49.737053 43755 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0824 22:23:06.347154 43755 solver.cpp:228] Iteration 1720, loss = 0.0270066
I0824 22:23:06.347259 43755 solver.cpp:244]     Train net output #0: accuracy = 0.990615
I0824 22:23:06.347273 43755 solver.cpp:244]     Train net output #1: loss = 0.0270067 (* 1 = 0.0270067 loss)
I0824 22:23:06.347288 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991365
I0824 22:23:06.347301 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987771
I0824 22:23:06.347308 43755 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0824 22:23:22.946225 43755 solver.cpp:228] Iteration 1740, loss = 0.0195276
I0824 22:23:22.946267 43755 solver.cpp:244]     Train net output #0: accuracy = 0.991988
I0824 22:23:22.946281 43755 solver.cpp:244]     Train net output #1: loss = 0.0195277 (* 1 = 0.0195277 loss)
I0824 22:23:22.946288 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989613
I0824 22:23:22.946293 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995569
I0824 22:23:22.946301 43755 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0824 22:23:39.569063 43755 solver.cpp:228] Iteration 1760, loss = 0.0147889
I0824 22:23:39.569200 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993822
I0824 22:23:39.569223 43755 solver.cpp:244]     Train net output #1: loss = 0.014789 (* 1 = 0.014789 loss)
I0824 22:23:39.569231 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992887
I0824 22:23:39.569241 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996004
I0824 22:23:39.569248 43755 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0824 22:23:56.190748 43755 solver.cpp:228] Iteration 1780, loss = 0.0333054
I0824 22:23:56.190793 43755 solver.cpp:244]     Train net output #0: accuracy = 0.986887
I0824 22:23:56.190807 43755 solver.cpp:244]     Train net output #1: loss = 0.0333055 (* 1 = 0.0333055 loss)
I0824 22:23:56.190814 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981588
I0824 22:23:56.190819 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994929
I0824 22:23:56.190826 43755 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0824 22:24:12.784567 43755 solver.cpp:228] Iteration 1800, loss = 0.0136427
I0824 22:24:12.784677 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994048
I0824 22:24:12.784692 43755 solver.cpp:244]     Train net output #1: loss = 0.0136428 (* 1 = 0.0136428 loss)
I0824 22:24:12.784698 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993321
I0824 22:24:12.784703 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996349
I0824 22:24:12.784709 43755 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0824 22:24:29.387610 43755 solver.cpp:228] Iteration 1820, loss = 0.02864
I0824 22:24:29.387655 43755 solver.cpp:244]     Train net output #0: accuracy = 0.988844
I0824 22:24:29.387670 43755 solver.cpp:244]     Train net output #1: loss = 0.0286401 (* 1 = 0.0286401 loss)
I0824 22:24:29.387676 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989016
I0824 22:24:29.387681 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988056
I0824 22:24:29.387689 43755 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0824 22:24:46.003489 43755 solver.cpp:228] Iteration 1840, loss = 0.0400552
I0824 22:24:46.003583 43755 solver.cpp:244]     Train net output #0: accuracy = 0.983174
I0824 22:24:46.003598 43755 solver.cpp:244]     Train net output #1: loss = 0.0400553 (* 1 = 0.0400553 loss)
I0824 22:24:46.003604 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.981544
I0824 22:24:46.003609 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986891
I0824 22:24:46.003618 43755 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0824 22:25:02.598924 43755 solver.cpp:228] Iteration 1860, loss = 0.0143508
I0824 22:25:02.598969 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993821
I0824 22:25:02.598986 43755 solver.cpp:244]     Train net output #1: loss = 0.0143509 (* 1 = 0.0143509 loss)
I0824 22:25:02.598992 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992937
I0824 22:25:02.598999 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995963
I0824 22:25:02.599006 43755 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0824 22:25:19.181728 43755 solver.cpp:228] Iteration 1880, loss = 0.0162084
I0824 22:25:19.181826 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99401
I0824 22:25:19.181840 43755 solver.cpp:244]     Train net output #1: loss = 0.0162085 (* 1 = 0.0162085 loss)
I0824 22:25:19.181846 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993564
I0824 22:25:19.181851 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994838
I0824 22:25:19.181859 43755 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0824 22:25:35.784936 43755 solver.cpp:228] Iteration 1900, loss = 0.0271976
I0824 22:25:35.784978 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989401
I0824 22:25:35.784991 43755 solver.cpp:244]     Train net output #1: loss = 0.0271977 (* 1 = 0.0271977 loss)
I0824 22:25:35.784997 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985457
I0824 22:25:35.785003 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994224
I0824 22:25:35.785010 43755 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0824 22:25:52.411509 43755 solver.cpp:228] Iteration 1920, loss = 0.019304
I0824 22:25:52.411664 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992541
I0824 22:25:52.411682 43755 solver.cpp:244]     Train net output #1: loss = 0.0193041 (* 1 = 0.0193041 loss)
I0824 22:25:52.411689 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993122
I0824 22:25:52.411695 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991426
I0824 22:25:52.411702 43755 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0824 22:26:09.011660 43755 solver.cpp:228] Iteration 1940, loss = 0.0178745
I0824 22:26:09.011703 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993294
I0824 22:26:09.011715 43755 solver.cpp:244]     Train net output #1: loss = 0.0178746 (* 1 = 0.0178746 loss)
I0824 22:26:09.011721 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993606
I0824 22:26:09.011726 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992372
I0824 22:26:09.011734 43755 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0824 22:26:25.620007 43755 solver.cpp:228] Iteration 1960, loss = 0.0135861
I0824 22:26:25.620111 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995777
I0824 22:26:25.620128 43755 solver.cpp:244]     Train net output #1: loss = 0.0135862 (* 1 = 0.0135862 loss)
I0824 22:26:25.620141 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997229
I0824 22:26:25.620153 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987374
I0824 22:26:25.620162 43755 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0824 22:26:42.224985 43755 solver.cpp:228] Iteration 1980, loss = 0.0306386
I0824 22:26:42.225036 43755 solver.cpp:244]     Train net output #0: accuracy = 0.988041
I0824 22:26:42.225052 43755 solver.cpp:244]     Train net output #1: loss = 0.0306388 (* 1 = 0.0306388 loss)
I0824 22:26:42.225059 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987346
I0824 22:26:42.225066 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989605
I0824 22:26:42.225077 43755 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0824 22:26:58.841338 43755 solver.cpp:228] Iteration 2000, loss = 0.0356008
I0824 22:26:58.841464 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993152
I0824 22:26:58.841482 43755 solver.cpp:244]     Train net output #1: loss = 0.0356009 (* 1 = 0.0356009 loss)
I0824 22:26:58.841491 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993408
I0824 22:26:58.841503 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988531
I0824 22:26:58.841517 43755 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0824 22:27:15.455534 43755 solver.cpp:228] Iteration 2020, loss = 0.0231189
I0824 22:27:15.455585 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989557
I0824 22:27:15.455600 43755 solver.cpp:244]     Train net output #1: loss = 0.023119 (* 1 = 0.023119 loss)
I0824 22:27:15.455608 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982967
I0824 22:27:15.455615 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99873
I0824 22:27:15.455622 43755 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0824 22:27:32.072486 43755 solver.cpp:228] Iteration 2040, loss = 0.0208666
I0824 22:27:32.072597 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992049
I0824 22:27:32.072612 43755 solver.cpp:244]     Train net output #1: loss = 0.0208667 (* 1 = 0.0208667 loss)
I0824 22:27:32.072618 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990777
I0824 22:27:32.072628 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994741
I0824 22:27:32.072636 43755 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0824 22:27:48.712985 43755 solver.cpp:228] Iteration 2060, loss = 0.0201263
I0824 22:27:48.713032 43755 solver.cpp:244]     Train net output #0: accuracy = 0.991868
I0824 22:27:48.713047 43755 solver.cpp:244]     Train net output #1: loss = 0.0201264 (* 1 = 0.0201264 loss)
I0824 22:27:48.713053 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987412
I0824 22:27:48.713059 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99698
I0824 22:27:48.713068 43755 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0824 22:28:05.324404 43755 solver.cpp:228] Iteration 2080, loss = 0.01939
I0824 22:28:05.324575 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992096
I0824 22:28:05.324594 43755 solver.cpp:244]     Train net output #1: loss = 0.0193901 (* 1 = 0.0193901 loss)
I0824 22:28:05.324605 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988415
I0824 22:28:05.324610 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997349
I0824 22:28:05.324618 43755 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0824 22:28:21.933017 43755 solver.cpp:228] Iteration 2100, loss = 0.0114714
I0824 22:28:21.933063 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995593
I0824 22:28:21.933079 43755 solver.cpp:244]     Train net output #1: loss = 0.0114715 (* 1 = 0.0114715 loss)
I0824 22:28:21.933086 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995893
I0824 22:28:21.933094 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994891
I0824 22:28:21.933101 43755 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0824 22:28:38.586786 43755 solver.cpp:228] Iteration 2120, loss = 0.0201633
I0824 22:28:38.586910 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992915
I0824 22:28:38.586925 43755 solver.cpp:244]     Train net output #1: loss = 0.0201634 (* 1 = 0.0201634 loss)
I0824 22:28:38.586937 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992719
I0824 22:28:38.586943 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994138
I0824 22:28:38.586951 43755 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0824 22:28:55.217569 43755 solver.cpp:228] Iteration 2140, loss = 0.0150664
I0824 22:28:55.217612 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993662
I0824 22:28:55.217624 43755 solver.cpp:244]     Train net output #1: loss = 0.0150665 (* 1 = 0.0150665 loss)
I0824 22:28:55.217631 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993218
I0824 22:28:55.217636 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994997
I0824 22:28:55.217644 43755 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0824 22:29:11.832885 43755 solver.cpp:228] Iteration 2160, loss = 0.0280455
I0824 22:29:11.833006 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989084
I0824 22:29:11.833024 43755 solver.cpp:244]     Train net output #1: loss = 0.0280457 (* 1 = 0.0280457 loss)
I0824 22:29:11.833036 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989389
I0824 22:29:11.833047 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987936
I0824 22:29:11.833055 43755 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0824 22:29:28.445791 43755 solver.cpp:228] Iteration 2180, loss = 0.0137857
I0824 22:29:28.445835 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994857
I0824 22:29:28.445850 43755 solver.cpp:244]     Train net output #1: loss = 0.0137858 (* 1 = 0.0137858 loss)
I0824 22:29:28.445857 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995769
I0824 22:29:28.445863 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992623
I0824 22:29:28.445870 43755 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0824 22:29:45.065742 43755 solver.cpp:228] Iteration 2200, loss = 0.0195437
I0824 22:29:45.065906 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994784
I0824 22:29:45.065924 43755 solver.cpp:244]     Train net output #1: loss = 0.0195438 (* 1 = 0.0195438 loss)
I0824 22:29:45.065933 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993839
I0824 22:29:45.065939 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995674
I0824 22:29:45.065948 43755 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0824 22:30:01.709048 43755 solver.cpp:228] Iteration 2220, loss = 0.0228748
I0824 22:30:01.709095 43755 solver.cpp:244]     Train net output #0: accuracy = 0.991748
I0824 22:30:01.709108 43755 solver.cpp:244]     Train net output #1: loss = 0.0228749 (* 1 = 0.0228749 loss)
I0824 22:30:01.709115 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992935
I0824 22:30:01.709120 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984785
I0824 22:30:01.709127 43755 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0824 22:30:18.320441 43755 solver.cpp:228] Iteration 2240, loss = 0.021728
I0824 22:30:18.320555 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989863
I0824 22:30:18.320574 43755 solver.cpp:244]     Train net output #1: loss = 0.0217281 (* 1 = 0.0217281 loss)
I0824 22:30:18.320585 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987606
I0824 22:30:18.320595 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995462
I0824 22:30:18.320603 43755 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0824 22:30:34.949324 43755 solver.cpp:228] Iteration 2260, loss = 0.0253659
I0824 22:30:34.949373 43755 solver.cpp:244]     Train net output #0: accuracy = 0.990386
I0824 22:30:34.949388 43755 solver.cpp:244]     Train net output #1: loss = 0.025366 (* 1 = 0.025366 loss)
I0824 22:30:34.949395 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989556
I0824 22:30:34.949400 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992052
I0824 22:30:34.949409 43755 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0824 22:30:51.590382 43755 solver.cpp:228] Iteration 2280, loss = 0.0116156
I0824 22:30:51.590481 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995611
I0824 22:30:51.590498 43755 solver.cpp:244]     Train net output #1: loss = 0.0116157 (* 1 = 0.0116157 loss)
I0824 22:30:51.590512 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995135
I0824 22:30:51.590523 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997007
I0824 22:30:51.590530 43755 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0824 22:31:08.213107 43755 solver.cpp:228] Iteration 2300, loss = 0.0165764
I0824 22:31:08.213157 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993469
I0824 22:31:08.213171 43755 solver.cpp:244]     Train net output #1: loss = 0.0165766 (* 1 = 0.0165766 loss)
I0824 22:31:08.213178 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992584
I0824 22:31:08.213184 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995537
I0824 22:31:08.213192 43755 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0824 22:31:24.799674 43755 solver.cpp:228] Iteration 2320, loss = 0.0174383
I0824 22:31:24.799777 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993641
I0824 22:31:24.799793 43755 solver.cpp:244]     Train net output #1: loss = 0.0174385 (* 1 = 0.0174385 loss)
I0824 22:31:24.799806 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994888
I0824 22:31:24.799813 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985885
I0824 22:31:24.799820 43755 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0824 22:31:41.409889 43755 solver.cpp:228] Iteration 2340, loss = 0.0185663
I0824 22:31:41.409936 43755 solver.cpp:244]     Train net output #0: accuracy = 0.991934
I0824 22:31:41.409952 43755 solver.cpp:244]     Train net output #1: loss = 0.0185664 (* 1 = 0.0185664 loss)
I0824 22:31:41.409960 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99005
I0824 22:31:41.409967 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9952
I0824 22:31:41.409976 43755 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0824 22:31:58.010754 43755 solver.cpp:228] Iteration 2360, loss = 0.0185194
I0824 22:31:58.010915 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992491
I0824 22:31:58.010931 43755 solver.cpp:244]     Train net output #1: loss = 0.0185195 (* 1 = 0.0185195 loss)
I0824 22:31:58.010942 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990935
I0824 22:31:58.010949 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995088
I0824 22:31:58.010957 43755 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0824 22:32:14.637951 43755 solver.cpp:228] Iteration 2380, loss = 0.0208442
I0824 22:32:14.637994 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994295
I0824 22:32:14.638010 43755 solver.cpp:244]     Train net output #1: loss = 0.0208443 (* 1 = 0.0208443 loss)
I0824 22:32:14.638022 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99437
I0824 22:32:14.638028 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993391
I0824 22:32:14.638037 43755 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0824 22:32:31.279320 43755 solver.cpp:228] Iteration 2400, loss = 0.0130528
I0824 22:32:31.279428 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994378
I0824 22:32:31.279445 43755 solver.cpp:244]     Train net output #1: loss = 0.0130529 (* 1 = 0.0130529 loss)
I0824 22:32:31.279456 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994186
I0824 22:32:31.279461 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995133
I0824 22:32:31.279469 43755 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0824 22:32:47.912340 43755 solver.cpp:228] Iteration 2420, loss = 0.016007
I0824 22:32:47.912389 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993024
I0824 22:32:47.912402 43755 solver.cpp:244]     Train net output #1: loss = 0.0160072 (* 1 = 0.0160072 loss)
I0824 22:32:47.912408 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99195
I0824 22:32:47.912415 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995279
I0824 22:32:47.912422 43755 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0824 22:33:04.536062 43755 solver.cpp:228] Iteration 2440, loss = 0.0211835
I0824 22:33:04.536161 43755 solver.cpp:244]     Train net output #0: accuracy = 0.990476
I0824 22:33:04.536180 43755 solver.cpp:244]     Train net output #1: loss = 0.0211837 (* 1 = 0.0211837 loss)
I0824 22:33:04.536190 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989646
I0824 22:33:04.536201 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992654
I0824 22:33:04.536209 43755 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0824 22:33:21.147065 43755 solver.cpp:228] Iteration 2460, loss = 0.0150609
I0824 22:33:21.147110 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993993
I0824 22:33:21.147125 43755 solver.cpp:244]     Train net output #1: loss = 0.015061 (* 1 = 0.015061 loss)
I0824 22:33:21.147131 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991629
I0824 22:33:21.147136 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996935
I0824 22:33:21.147145 43755 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0824 22:33:37.771877 43755 solver.cpp:228] Iteration 2480, loss = 0.0171996
I0824 22:33:37.771978 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995985
I0824 22:33:37.771996 43755 solver.cpp:244]     Train net output #1: loss = 0.0171997 (* 1 = 0.0171997 loss)
I0824 22:33:37.772008 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998524
I0824 22:33:37.772019 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.972619
I0824 22:33:37.772029 43755 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0824 22:33:54.404933 43755 solver.cpp:228] Iteration 2500, loss = 0.0153754
I0824 22:33:54.404975 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995077
I0824 22:33:54.404991 43755 solver.cpp:244]     Train net output #1: loss = 0.0153756 (* 1 = 0.0153756 loss)
I0824 22:33:54.404997 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996353
I0824 22:33:54.405004 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985475
I0824 22:33:54.405011 43755 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0824 22:34:11.019474 43755 solver.cpp:228] Iteration 2520, loss = 0.0127852
I0824 22:34:11.019640 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995276
I0824 22:34:11.019657 43755 solver.cpp:244]     Train net output #1: loss = 0.0127853 (* 1 = 0.0127853 loss)
I0824 22:34:11.019665 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992768
I0824 22:34:11.019671 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998237
I0824 22:34:11.019680 43755 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0824 22:34:27.640980 43755 solver.cpp:228] Iteration 2540, loss = 0.0148807
I0824 22:34:27.641027 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994028
I0824 22:34:27.641043 43755 solver.cpp:244]     Train net output #1: loss = 0.0148808 (* 1 = 0.0148808 loss)
I0824 22:34:27.641050 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993798
I0824 22:34:27.641057 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99455
I0824 22:34:27.641065 43755 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0824 22:34:44.271056 43755 solver.cpp:228] Iteration 2560, loss = 0.0151934
I0824 22:34:44.271157 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995305
I0824 22:34:44.271173 43755 solver.cpp:244]     Train net output #1: loss = 0.0151935 (* 1 = 0.0151935 loss)
I0824 22:34:44.271178 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996023
I0824 22:34:44.271184 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991847
I0824 22:34:44.271191 43755 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0824 22:35:00.918615 43755 solver.cpp:228] Iteration 2580, loss = 0.00954384
I0824 22:35:00.918663 43755 solver.cpp:244]     Train net output #0: accuracy = 0.9961
I0824 22:35:00.918679 43755 solver.cpp:244]     Train net output #1: loss = 0.00954395 (* 1 = 0.00954395 loss)
I0824 22:35:00.918694 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996235
I0824 22:35:00.918705 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995613
I0824 22:35:00.918716 43755 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0824 22:35:17.553877 43755 solver.cpp:228] Iteration 2600, loss = 0.0173667
I0824 22:35:17.553983 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992086
I0824 22:35:17.553999 43755 solver.cpp:244]     Train net output #1: loss = 0.0173668 (* 1 = 0.0173668 loss)
I0824 22:35:17.554005 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989491
I0824 22:35:17.554011 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996414
I0824 22:35:17.554019 43755 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0824 22:35:34.181931 43755 solver.cpp:228] Iteration 2620, loss = 0.0284663
I0824 22:35:34.181972 43755 solver.cpp:244]     Train net output #0: accuracy = 0.991234
I0824 22:35:34.181988 43755 solver.cpp:244]     Train net output #1: loss = 0.0284664 (* 1 = 0.0284664 loss)
I0824 22:35:34.181993 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988886
I0824 22:35:34.181999 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993567
I0824 22:35:34.182008 43755 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0824 22:35:50.799399 43755 solver.cpp:228] Iteration 2640, loss = 0.0178808
I0824 22:35:50.799504 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993679
I0824 22:35:50.799522 43755 solver.cpp:244]     Train net output #1: loss = 0.0178809 (* 1 = 0.0178809 loss)
I0824 22:35:50.799531 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994965
I0824 22:35:50.799541 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989534
I0824 22:35:50.799549 43755 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0824 22:36:07.429122 43755 solver.cpp:228] Iteration 2660, loss = 0.0178125
I0824 22:36:07.429167 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993523
I0824 22:36:07.429181 43755 solver.cpp:244]     Train net output #1: loss = 0.0178126 (* 1 = 0.0178126 loss)
I0824 22:36:07.429188 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990693
I0824 22:36:07.429193 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996671
I0824 22:36:07.429201 43755 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0824 22:36:24.032722 43755 solver.cpp:228] Iteration 2680, loss = 0.0117479
I0824 22:36:24.032868 43755 solver.cpp:244]     Train net output #0: accuracy = 0.9949
I0824 22:36:24.032907 43755 solver.cpp:244]     Train net output #1: loss = 0.011748 (* 1 = 0.011748 loss)
I0824 22:36:24.032917 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994879
I0824 22:36:24.032927 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994987
I0824 22:36:24.032937 43755 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0824 22:36:40.659144 43755 solver.cpp:228] Iteration 2700, loss = 0.0125761
I0824 22:36:40.659189 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994453
I0824 22:36:40.659204 43755 solver.cpp:244]     Train net output #1: loss = 0.0125762 (* 1 = 0.0125762 loss)
I0824 22:36:40.659209 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991955
I0824 22:36:40.659215 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997977
I0824 22:36:40.659224 43755 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0824 22:36:57.292819 43755 solver.cpp:228] Iteration 2720, loss = 0.0138349
I0824 22:36:57.292927 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994865
I0824 22:36:57.292943 43755 solver.cpp:244]     Train net output #1: loss = 0.013835 (* 1 = 0.013835 loss)
I0824 22:36:57.292953 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99376
I0824 22:36:57.292965 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996583
I0824 22:36:57.292975 43755 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0824 22:37:13.929420 43755 solver.cpp:228] Iteration 2740, loss = 0.0170134
I0824 22:37:13.929461 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993958
I0824 22:37:13.929476 43755 solver.cpp:244]     Train net output #1: loss = 0.0170135 (* 1 = 0.0170135 loss)
I0824 22:37:13.929483 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995574
I0824 22:37:13.929489 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.983868
I0824 22:37:13.929497 43755 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0824 22:37:30.572464 43755 solver.cpp:228] Iteration 2760, loss = 0.0122596
I0824 22:37:30.572564 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995502
I0824 22:37:30.572580 43755 solver.cpp:244]     Train net output #1: loss = 0.0122598 (* 1 = 0.0122598 loss)
I0824 22:37:30.572593 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993672
I0824 22:37:30.572598 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998046
I0824 22:37:30.572605 43755 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0824 22:37:47.206543 43755 solver.cpp:228] Iteration 2780, loss = 0.0107524
I0824 22:37:47.206591 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995509
I0824 22:37:47.206607 43755 solver.cpp:244]     Train net output #1: loss = 0.0107525 (* 1 = 0.0107525 loss)
I0824 22:37:47.206615 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995231
I0824 22:37:47.206621 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996171
I0824 22:37:47.206630 43755 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0824 22:38:03.829854 43755 solver.cpp:228] Iteration 2800, loss = 0.0165438
I0824 22:38:03.830029 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993261
I0824 22:38:03.830045 43755 solver.cpp:244]     Train net output #1: loss = 0.0165439 (* 1 = 0.0165439 loss)
I0824 22:38:03.830058 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992128
I0824 22:38:03.830063 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996128
I0824 22:38:03.830071 43755 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0824 22:38:20.452296 43755 solver.cpp:228] Iteration 2820, loss = 0.0167766
I0824 22:38:20.452344 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993161
I0824 22:38:20.452359 43755 solver.cpp:244]     Train net output #1: loss = 0.0167767 (* 1 = 0.0167767 loss)
I0824 22:38:20.452366 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993196
I0824 22:38:20.452373 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993088
I0824 22:38:20.452381 43755 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0824 22:38:37.083106 43755 solver.cpp:228] Iteration 2840, loss = 0.0155341
I0824 22:38:37.083214 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993345
I0824 22:38:37.083230 43755 solver.cpp:244]     Train net output #1: loss = 0.0155342 (* 1 = 0.0155342 loss)
I0824 22:38:37.083241 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991527
I0824 22:38:37.083246 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996078
I0824 22:38:37.083256 43755 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0824 22:38:53.725848 43755 solver.cpp:228] Iteration 2860, loss = 0.0146713
I0824 22:38:53.725893 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99424
I0824 22:38:53.725905 43755 solver.cpp:244]     Train net output #1: loss = 0.0146714 (* 1 = 0.0146714 loss)
I0824 22:38:53.725911 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994287
I0824 22:38:53.725917 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994151
I0824 22:38:53.725926 43755 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0824 22:39:10.357791 43755 solver.cpp:228] Iteration 2880, loss = 0.0150101
I0824 22:39:10.357915 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993908
I0824 22:39:10.357933 43755 solver.cpp:244]     Train net output #1: loss = 0.0150102 (* 1 = 0.0150102 loss)
I0824 22:39:10.357941 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994296
I0824 22:39:10.357952 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992927
I0824 22:39:10.357961 43755 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0824 22:39:26.973814 43755 solver.cpp:228] Iteration 2900, loss = 0.0172173
I0824 22:39:26.973857 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993057
I0824 22:39:26.973871 43755 solver.cpp:244]     Train net output #1: loss = 0.0172174 (* 1 = 0.0172174 loss)
I0824 22:39:26.973877 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99026
I0824 22:39:26.973883 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997603
I0824 22:39:26.973892 43755 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0824 22:39:43.591265 43755 solver.cpp:228] Iteration 2920, loss = 0.0118282
I0824 22:39:43.591377 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995749
I0824 22:39:43.591394 43755 solver.cpp:244]     Train net output #1: loss = 0.0118283 (* 1 = 0.0118283 loss)
I0824 22:39:43.591401 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996838
I0824 22:39:43.591408 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989795
I0824 22:39:43.591418 43755 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0824 22:40:00.233670 43755 solver.cpp:228] Iteration 2940, loss = 0.0173847
I0824 22:40:00.233716 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993828
I0824 22:40:00.233731 43755 solver.cpp:244]     Train net output #1: loss = 0.0173848 (* 1 = 0.0173848 loss)
I0824 22:40:00.233737 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994911
I0824 22:40:00.233743 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989887
I0824 22:40:00.233752 43755 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0824 22:40:16.852704 43755 solver.cpp:228] Iteration 2960, loss = 0.0103595
I0824 22:40:16.852869 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996131
I0824 22:40:16.852895 43755 solver.cpp:244]     Train net output #1: loss = 0.0103596 (* 1 = 0.0103596 loss)
I0824 22:40:16.852903 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996145
I0824 22:40:16.852908 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996101
I0824 22:40:16.852921 43755 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0824 22:40:33.481617 43755 solver.cpp:228] Iteration 2980, loss = 0.0222691
I0824 22:40:33.481667 43755 solver.cpp:244]     Train net output #0: accuracy = 0.991175
I0824 22:40:33.481680 43755 solver.cpp:244]     Train net output #1: loss = 0.0222692 (* 1 = 0.0222692 loss)
I0824 22:40:33.481686 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98895
I0824 22:40:33.481693 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995819
I0824 22:40:33.481700 43755 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0824 22:40:50.092893 43755 solver.cpp:228] Iteration 3000, loss = 0.0141675
I0824 22:40:50.093019 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995113
I0824 22:40:50.093036 43755 solver.cpp:244]     Train net output #1: loss = 0.0141676 (* 1 = 0.0141676 loss)
I0824 22:40:50.093050 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996133
I0824 22:40:50.093061 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987385
I0824 22:40:50.093070 43755 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0824 22:41:06.679239 43755 solver.cpp:228] Iteration 3020, loss = 0.0199814
I0824 22:41:06.679287 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993455
I0824 22:41:06.679303 43755 solver.cpp:244]     Train net output #1: loss = 0.0199816 (* 1 = 0.0199816 loss)
I0824 22:41:06.679309 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995537
I0824 22:41:06.679316 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988319
I0824 22:41:06.679324 43755 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0824 22:41:23.300935 43755 solver.cpp:228] Iteration 3040, loss = 0.0143974
I0824 22:41:23.301050 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993779
I0824 22:41:23.301065 43755 solver.cpp:244]     Train net output #1: loss = 0.0143975 (* 1 = 0.0143975 loss)
I0824 22:41:23.301071 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991326
I0824 22:41:23.301076 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997402
I0824 22:41:23.301084 43755 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0824 22:41:39.919134 43755 solver.cpp:228] Iteration 3060, loss = 0.024058
I0824 22:41:39.919183 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989902
I0824 22:41:39.919198 43755 solver.cpp:244]     Train net output #1: loss = 0.0240581 (* 1 = 0.0240581 loss)
I0824 22:41:39.919204 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982878
I0824 22:41:39.919210 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998524
I0824 22:41:39.919220 43755 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0824 22:41:56.533502 43755 solver.cpp:228] Iteration 3080, loss = 0.017343
I0824 22:41:56.533614 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993273
I0824 22:41:56.533632 43755 solver.cpp:244]     Train net output #1: loss = 0.0173431 (* 1 = 0.0173431 loss)
I0824 22:41:56.533645 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991119
I0824 22:41:56.533650 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99587
I0824 22:41:56.533658 43755 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0824 22:42:13.163403 43755 solver.cpp:228] Iteration 3100, loss = 0.0132393
I0824 22:42:13.163447 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99522
I0824 22:42:13.163461 43755 solver.cpp:244]     Train net output #1: loss = 0.0132394 (* 1 = 0.0132394 loss)
I0824 22:42:13.163467 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99597
I0824 22:42:13.163473 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991395
I0824 22:42:13.163481 43755 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0824 22:42:29.769093 43755 solver.cpp:228] Iteration 3120, loss = 0.0210051
I0824 22:42:29.769268 43755 solver.cpp:244]     Train net output #0: accuracy = 0.9914
I0824 22:42:29.769287 43755 solver.cpp:244]     Train net output #1: loss = 0.0210052 (* 1 = 0.0210052 loss)
I0824 22:42:29.769295 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989048
I0824 22:42:29.769307 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995804
I0824 22:42:29.769316 43755 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0824 22:42:46.360733 43755 solver.cpp:228] Iteration 3140, loss = 0.01319
I0824 22:42:46.360775 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994185
I0824 22:42:46.360790 43755 solver.cpp:244]     Train net output #1: loss = 0.0131901 (* 1 = 0.0131901 loss)
I0824 22:42:46.360795 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991492
I0824 22:42:46.360800 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998975
I0824 22:42:46.360808 43755 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0824 22:43:02.991552 43755 solver.cpp:228] Iteration 3160, loss = 0.0157349
I0824 22:43:02.991705 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99354
I0824 22:43:02.991722 43755 solver.cpp:244]     Train net output #1: loss = 0.015735 (* 1 = 0.015735 loss)
I0824 22:43:02.991736 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992686
I0824 22:43:02.991747 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995095
I0824 22:43:02.991756 43755 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0824 22:43:19.608134 43755 solver.cpp:228] Iteration 3180, loss = 0.0121953
I0824 22:43:19.608181 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995149
I0824 22:43:19.608197 43755 solver.cpp:244]     Train net output #1: loss = 0.0121954 (* 1 = 0.0121954 loss)
I0824 22:43:19.608204 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994288
I0824 22:43:19.608211 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996714
I0824 22:43:19.608219 43755 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0824 22:43:36.201504 43755 solver.cpp:228] Iteration 3200, loss = 0.0159054
I0824 22:43:36.201618 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994301
I0824 22:43:36.201635 43755 solver.cpp:244]     Train net output #1: loss = 0.0159055 (* 1 = 0.0159055 loss)
I0824 22:43:36.201647 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994998
I0824 22:43:36.201659 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991582
I0824 22:43:36.201668 43755 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0824 22:43:52.812254 43755 solver.cpp:228] Iteration 3220, loss = 0.0209181
I0824 22:43:52.812297 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992313
I0824 22:43:52.812310 43755 solver.cpp:244]     Train net output #1: loss = 0.0209182 (* 1 = 0.0209182 loss)
I0824 22:43:52.812317 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992125
I0824 22:43:52.812328 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992905
I0824 22:43:52.812336 43755 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0824 22:44:09.425545 43755 solver.cpp:228] Iteration 3240, loss = 0.00839309
I0824 22:44:09.425658 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996975
I0824 22:44:09.425676 43755 solver.cpp:244]     Train net output #1: loss = 0.00839321 (* 1 = 0.00839321 loss)
I0824 22:44:09.425689 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997746
I0824 22:44:09.425700 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993591
I0824 22:44:09.425710 43755 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0824 22:44:26.049656 43755 solver.cpp:228] Iteration 3260, loss = 0.0109651
I0824 22:44:26.049700 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995428
I0824 22:44:26.049712 43755 solver.cpp:244]     Train net output #1: loss = 0.0109652 (* 1 = 0.0109652 loss)
I0824 22:44:26.049718 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994141
I0824 22:44:26.049723 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998663
I0824 22:44:26.049731 43755 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0824 22:44:42.673007 43755 solver.cpp:228] Iteration 3280, loss = 0.016078
I0824 22:44:42.673166 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993102
I0824 22:44:42.673184 43755 solver.cpp:244]     Train net output #1: loss = 0.0160782 (* 1 = 0.0160782 loss)
I0824 22:44:42.673192 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98922
I0824 22:44:42.673204 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998694
I0824 22:44:42.673213 43755 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0824 22:44:59.272011 43755 solver.cpp:228] Iteration 3300, loss = 0.0146049
I0824 22:44:59.272053 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994523
I0824 22:44:59.272066 43755 solver.cpp:244]     Train net output #1: loss = 0.014605 (* 1 = 0.014605 loss)
I0824 22:44:59.272073 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994564
I0824 22:44:59.272086 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994417
I0824 22:44:59.272094 43755 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0824 22:45:15.883514 43755 solver.cpp:228] Iteration 3320, loss = 0.0125672
I0824 22:45:15.883637 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994439
I0824 22:45:15.883654 43755 solver.cpp:244]     Train net output #1: loss = 0.0125673 (* 1 = 0.0125673 loss)
I0824 22:45:15.883667 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991831
I0824 22:45:15.883679 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99804
I0824 22:45:15.883688 43755 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0824 22:45:32.500319 43755 solver.cpp:228] Iteration 3340, loss = 0.010316
I0824 22:45:32.500356 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995773
I0824 22:45:32.500368 43755 solver.cpp:244]     Train net output #1: loss = 0.0103162 (* 1 = 0.0103162 loss)
I0824 22:45:32.500375 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99488
I0824 22:45:32.500380 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997224
I0824 22:45:32.500388 43755 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0824 22:45:49.102808 43755 solver.cpp:228] Iteration 3360, loss = 0.00897865
I0824 22:45:49.102907 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996839
I0824 22:45:49.102922 43755 solver.cpp:244]     Train net output #1: loss = 0.00897877 (* 1 = 0.00897877 loss)
I0824 22:45:49.102928 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996259
I0824 22:45:49.102933 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997686
I0824 22:45:49.102941 43755 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0824 22:46:05.712869 43755 solver.cpp:228] Iteration 3380, loss = 0.0104297
I0824 22:46:05.712913 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995133
I0824 22:46:05.712929 43755 solver.cpp:244]     Train net output #1: loss = 0.0104299 (* 1 = 0.0104299 loss)
I0824 22:46:05.712935 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99297
I0824 22:46:05.712941 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99854
I0824 22:46:05.712949 43755 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0824 22:46:22.297678 43755 solver.cpp:228] Iteration 3400, loss = 0.00801157
I0824 22:46:22.297844 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996769
I0824 22:46:22.297861 43755 solver.cpp:244]     Train net output #1: loss = 0.00801169 (* 1 = 0.00801169 loss)
I0824 22:46:22.297868 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996889
I0824 22:46:22.297873 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996209
I0824 22:46:22.297879 43755 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0824 22:46:38.922507 43755 solver.cpp:228] Iteration 3420, loss = 0.0101378
I0824 22:46:38.922554 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995826
I0824 22:46:38.922569 43755 solver.cpp:244]     Train net output #1: loss = 0.0101379 (* 1 = 0.0101379 loss)
I0824 22:46:38.922576 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996149
I0824 22:46:38.922587 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994709
I0824 22:46:38.922595 43755 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0824 22:46:55.535565 43755 solver.cpp:228] Iteration 3440, loss = 0.0223012
I0824 22:46:55.535689 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99228
I0824 22:46:55.535706 43755 solver.cpp:244]     Train net output #1: loss = 0.0223013 (* 1 = 0.0223013 loss)
I0824 22:46:55.535720 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989982
I0824 22:46:55.535732 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99475
I0824 22:46:55.535742 43755 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0824 22:47:12.136519 43755 solver.cpp:228] Iteration 3460, loss = 0.0148704
I0824 22:47:12.136569 43755 solver.cpp:244]     Train net output #0: accuracy = 0.9935
I0824 22:47:12.136584 43755 solver.cpp:244]     Train net output #1: loss = 0.0148705 (* 1 = 0.0148705 loss)
I0824 22:47:12.136591 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992908
I0824 22:47:12.136597 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994898
I0824 22:47:12.136605 43755 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0824 22:47:28.751499 43755 solver.cpp:228] Iteration 3480, loss = 0.0183944
I0824 22:47:28.751618 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992517
I0824 22:47:28.751636 43755 solver.cpp:244]     Train net output #1: loss = 0.0183945 (* 1 = 0.0183945 loss)
I0824 22:47:28.751651 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990687
I0824 22:47:28.751657 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995062
I0824 22:47:28.751665 43755 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0824 22:47:45.359370 43755 solver.cpp:228] Iteration 3500, loss = 0.00886932
I0824 22:47:45.359416 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995757
I0824 22:47:45.359432 43755 solver.cpp:244]     Train net output #1: loss = 0.00886945 (* 1 = 0.00886945 loss)
I0824 22:47:45.359439 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994609
I0824 22:47:45.359446 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998474
I0824 22:47:45.359453 43755 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0824 22:48:01.967185 43755 solver.cpp:228] Iteration 3520, loss = 0.0127643
I0824 22:48:01.967299 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994317
I0824 22:48:01.967315 43755 solver.cpp:244]     Train net output #1: loss = 0.0127645 (* 1 = 0.0127645 loss)
I0824 22:48:01.967326 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993565
I0824 22:48:01.967334 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996101
I0824 22:48:01.967340 43755 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0824 22:48:18.574307 43755 solver.cpp:228] Iteration 3540, loss = 0.0125301
I0824 22:48:18.574352 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994321
I0824 22:48:18.574368 43755 solver.cpp:244]     Train net output #1: loss = 0.0125302 (* 1 = 0.0125302 loss)
I0824 22:48:18.574374 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994712
I0824 22:48:18.574380 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992686
I0824 22:48:18.574389 43755 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0824 22:48:35.168283 43755 solver.cpp:228] Iteration 3560, loss = 0.0129409
I0824 22:48:35.168445 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99487
I0824 22:48:35.168464 43755 solver.cpp:244]     Train net output #1: loss = 0.012941 (* 1 = 0.012941 loss)
I0824 22:48:35.168471 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995104
I0824 22:48:35.168478 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994159
I0824 22:48:35.168484 43755 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0824 22:48:51.771600 43755 solver.cpp:228] Iteration 3580, loss = 0.011834
I0824 22:48:51.771642 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995693
I0824 22:48:51.771656 43755 solver.cpp:244]     Train net output #1: loss = 0.0118342 (* 1 = 0.0118342 loss)
I0824 22:48:51.771662 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995042
I0824 22:48:51.771668 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996625
I0824 22:48:51.771675 43755 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0824 22:49:08.402249 43755 solver.cpp:228] Iteration 3600, loss = 0.013454
I0824 22:49:08.402350 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99554
I0824 22:49:08.402367 43755 solver.cpp:244]     Train net output #1: loss = 0.0134541 (* 1 = 0.0134541 loss)
I0824 22:49:08.402380 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993664
I0824 22:49:08.402386 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997766
I0824 22:49:08.402395 43755 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0824 22:49:25.007709 43755 solver.cpp:228] Iteration 3620, loss = 0.0119429
I0824 22:49:25.007751 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994672
I0824 22:49:25.007764 43755 solver.cpp:244]     Train net output #1: loss = 0.011943 (* 1 = 0.011943 loss)
I0824 22:49:25.007771 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993495
I0824 22:49:25.007776 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997068
I0824 22:49:25.007783 43755 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0824 22:49:41.636878 43755 solver.cpp:228] Iteration 3640, loss = 0.00848864
I0824 22:49:41.636992 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996202
I0824 22:49:41.637009 43755 solver.cpp:244]     Train net output #1: loss = 0.00848877 (* 1 = 0.00848877 loss)
I0824 22:49:41.637017 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995043
I0824 22:49:41.637022 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99829
I0824 22:49:41.637030 43755 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0824 22:49:58.237473 43755 solver.cpp:228] Iteration 3660, loss = 0.0135988
I0824 22:49:58.237514 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995081
I0824 22:49:58.237527 43755 solver.cpp:244]     Train net output #1: loss = 0.013599 (* 1 = 0.013599 loss)
I0824 22:49:58.237534 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992598
I0824 22:49:58.237537 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998186
I0824 22:49:58.237545 43755 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0824 22:50:14.860920 43755 solver.cpp:228] Iteration 3680, loss = 0.010541
I0824 22:50:14.861059 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996589
I0824 22:50:14.861075 43755 solver.cpp:244]     Train net output #1: loss = 0.0105411 (* 1 = 0.0105411 loss)
I0824 22:50:14.861088 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997152
I0824 22:50:14.861099 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994509
I0824 22:50:14.861109 43755 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0824 22:50:31.464334 43755 solver.cpp:228] Iteration 3700, loss = 0.0111554
I0824 22:50:31.464375 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995493
I0824 22:50:31.464388 43755 solver.cpp:244]     Train net output #1: loss = 0.0111555 (* 1 = 0.0111555 loss)
I0824 22:50:31.464395 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995086
I0824 22:50:31.464401 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996258
I0824 22:50:31.464407 43755 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0824 22:50:48.081262 43755 solver.cpp:228] Iteration 3720, loss = 0.00915502
I0824 22:50:48.081455 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996458
I0824 22:50:48.081497 43755 solver.cpp:244]     Train net output #1: loss = 0.00915514 (* 1 = 0.00915514 loss)
I0824 22:50:48.081507 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99677
I0824 22:50:48.081518 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994687
I0824 22:50:48.081533 43755 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0824 22:51:04.764438 43755 solver.cpp:228] Iteration 3740, loss = 0.0116804
I0824 22:51:04.764484 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995221
I0824 22:51:04.764498 43755 solver.cpp:244]     Train net output #1: loss = 0.0116805 (* 1 = 0.0116805 loss)
I0824 22:51:04.764505 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994762
I0824 22:51:04.764510 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997077
I0824 22:51:04.764519 43755 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0824 22:51:21.437006 43755 solver.cpp:228] Iteration 3760, loss = 0.0154528
I0824 22:51:21.437131 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993497
I0824 22:51:21.437160 43755 solver.cpp:244]     Train net output #1: loss = 0.0154529 (* 1 = 0.0154529 loss)
I0824 22:51:21.437170 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99242
I0824 22:51:21.437180 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996244
I0824 22:51:21.437189 43755 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0824 22:51:38.082921 43755 solver.cpp:228] Iteration 3780, loss = 0.0117789
I0824 22:51:38.082973 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995328
I0824 22:51:38.082986 43755 solver.cpp:244]     Train net output #1: loss = 0.011779 (* 1 = 0.011779 loss)
I0824 22:51:38.082994 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994726
I0824 22:51:38.083000 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996215
I0824 22:51:38.083010 43755 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0824 22:51:54.673897 43755 solver.cpp:228] Iteration 3800, loss = 0.0157973
I0824 22:51:54.674039 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993165
I0824 22:51:54.674055 43755 solver.cpp:244]     Train net output #1: loss = 0.0157975 (* 1 = 0.0157975 loss)
I0824 22:51:54.674067 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992325
I0824 22:51:54.674078 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994912
I0824 22:51:54.674088 43755 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0824 22:52:11.289443 43755 solver.cpp:228] Iteration 3820, loss = 0.0264512
I0824 22:52:11.289490 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989699
I0824 22:52:11.289505 43755 solver.cpp:244]     Train net output #1: loss = 0.0264513 (* 1 = 0.0264513 loss)
I0824 22:52:11.289511 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986957
I0824 22:52:11.289523 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994961
I0824 22:52:11.289531 43755 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0824 22:52:27.890290 43755 solver.cpp:228] Iteration 3840, loss = 0.0103748
I0824 22:52:27.890457 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996328
I0824 22:52:27.890499 43755 solver.cpp:244]     Train net output #1: loss = 0.0103749 (* 1 = 0.0103749 loss)
I0824 22:52:27.890511 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994899
I0824 22:52:27.890521 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998855
I0824 22:52:27.890532 43755 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0824 22:52:44.525815 43755 solver.cpp:228] Iteration 3860, loss = 0.0188469
I0824 22:52:44.525862 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993356
I0824 22:52:44.525877 43755 solver.cpp:244]     Train net output #1: loss = 0.0188471 (* 1 = 0.0188471 loss)
I0824 22:52:44.525884 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992591
I0824 22:52:44.525890 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994555
I0824 22:52:44.525899 43755 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0824 22:53:01.142266 43755 solver.cpp:228] Iteration 3880, loss = 0.0106676
I0824 22:53:01.142490 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996778
I0824 22:53:01.142532 43755 solver.cpp:244]     Train net output #1: loss = 0.0106677 (* 1 = 0.0106677 loss)
I0824 22:53:01.142542 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997747
I0824 22:53:01.142552 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988272
I0824 22:53:01.142563 43755 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0824 22:53:17.846163 43755 solver.cpp:228] Iteration 3900, loss = 0.00789147
I0824 22:53:17.846215 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996263
I0824 22:53:17.846236 43755 solver.cpp:244]     Train net output #1: loss = 0.00789159 (* 1 = 0.00789159 loss)
I0824 22:53:17.846245 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995777
I0824 22:53:17.846251 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998092
I0824 22:53:17.846261 43755 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0824 22:53:34.509649 43755 solver.cpp:228] Iteration 3920, loss = 0.0102114
I0824 22:53:34.509768 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995924
I0824 22:53:34.509785 43755 solver.cpp:244]     Train net output #1: loss = 0.0102115 (* 1 = 0.0102115 loss)
I0824 22:53:34.509793 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994544
I0824 22:53:34.509799 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99808
I0824 22:53:34.509807 43755 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0824 22:53:51.130093 43755 solver.cpp:228] Iteration 3940, loss = 0.00901913
I0824 22:53:51.130141 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995992
I0824 22:53:51.130156 43755 solver.cpp:244]     Train net output #1: loss = 0.00901925 (* 1 = 0.00901925 loss)
I0824 22:53:51.130163 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99572
I0824 22:53:51.130170 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996642
I0824 22:53:51.130178 43755 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0824 22:54:07.741240 43755 solver.cpp:228] Iteration 3960, loss = 0.0101647
I0824 22:54:07.741355 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996117
I0824 22:54:07.741377 43755 solver.cpp:244]     Train net output #1: loss = 0.0101648 (* 1 = 0.0101648 loss)
I0824 22:54:07.741384 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99664
I0824 22:54:07.741391 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994735
I0824 22:54:07.741400 43755 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0824 22:54:24.344039 43755 solver.cpp:228] Iteration 3980, loss = 0.0204468
I0824 22:54:24.344084 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992195
I0824 22:54:24.344115 43755 solver.cpp:244]     Train net output #1: loss = 0.0204469 (* 1 = 0.0204469 loss)
I0824 22:54:24.344125 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991182
I0824 22:54:24.344135 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994414
I0824 22:54:24.344144 43755 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0824 22:54:40.966080 43755 solver.cpp:228] Iteration 4000, loss = 0.0121543
I0824 22:54:40.966248 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995485
I0824 22:54:40.966265 43755 solver.cpp:244]     Train net output #1: loss = 0.0121545 (* 1 = 0.0121545 loss)
I0824 22:54:40.966271 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994277
I0824 22:54:40.966277 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997324
I0824 22:54:40.966289 43755 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0824 22:54:57.588646 43755 solver.cpp:228] Iteration 4020, loss = 0.0101252
I0824 22:54:57.588692 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995958
I0824 22:54:57.588706 43755 solver.cpp:244]     Train net output #1: loss = 0.0101253 (* 1 = 0.0101253 loss)
I0824 22:54:57.588713 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996438
I0824 22:54:57.588719 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994112
I0824 22:54:57.588728 43755 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0824 22:55:14.203883 43755 solver.cpp:228] Iteration 4040, loss = 0.00803331
I0824 22:55:14.203989 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99706
I0824 22:55:14.204005 43755 solver.cpp:244]     Train net output #1: loss = 0.00803343 (* 1 = 0.00803343 loss)
I0824 22:55:14.204018 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997021
I0824 22:55:14.204030 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99716
I0824 22:55:14.204037 43755 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0824 22:55:30.813350 43755 solver.cpp:228] Iteration 4060, loss = 0.00860132
I0824 22:55:30.813401 43755 solver.cpp:244]     Train net output #0: accuracy = 0.997257
I0824 22:55:30.813416 43755 solver.cpp:244]     Train net output #1: loss = 0.00860144 (* 1 = 0.00860144 loss)
I0824 22:55:30.813431 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99773
I0824 22:55:30.813441 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995919
I0824 22:55:30.813448 43755 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0824 22:55:47.451498 43755 solver.cpp:228] Iteration 4080, loss = 0.00948222
I0824 22:55:47.451643 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995985
I0824 22:55:47.451681 43755 solver.cpp:244]     Train net output #1: loss = 0.00948234 (* 1 = 0.00948234 loss)
I0824 22:55:47.451691 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995699
I0824 22:55:47.451704 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996592
I0824 22:55:47.451715 43755 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0824 22:56:04.101773 43755 solver.cpp:228] Iteration 4100, loss = 0.0212069
I0824 22:56:04.101820 43755 solver.cpp:244]     Train net output #0: accuracy = 0.991431
I0824 22:56:04.101835 43755 solver.cpp:244]     Train net output #1: loss = 0.021207 (* 1 = 0.021207 loss)
I0824 22:56:04.101842 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989274
I0824 22:56:04.101848 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996907
I0824 22:56:04.101857 43755 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0824 22:56:20.737797 43755 solver.cpp:228] Iteration 4120, loss = 0.0152848
I0824 22:56:20.737905 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993135
I0824 22:56:20.737921 43755 solver.cpp:244]     Train net output #1: loss = 0.015285 (* 1 = 0.015285 loss)
I0824 22:56:20.737927 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992103
I0824 22:56:20.737939 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995431
I0824 22:56:20.737953 43755 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0824 22:56:37.347424 43755 solver.cpp:228] Iteration 4140, loss = 0.00956459
I0824 22:56:37.347471 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995984
I0824 22:56:37.347486 43755 solver.cpp:244]     Train net output #1: loss = 0.0095647 (* 1 = 0.0095647 loss)
I0824 22:56:37.347493 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994635
I0824 22:56:37.347499 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998032
I0824 22:56:37.347508 43755 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0824 22:56:53.944492 43755 solver.cpp:228] Iteration 4160, loss = 0.0210755
I0824 22:56:53.944665 43755 solver.cpp:244]     Train net output #0: accuracy = 0.992737
I0824 22:56:53.944684 43755 solver.cpp:244]     Train net output #1: loss = 0.0210756 (* 1 = 0.0210756 loss)
I0824 22:56:53.944692 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992317
I0824 22:56:53.944705 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993743
I0824 22:56:53.944712 43755 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0824 22:57:10.573299 43755 solver.cpp:228] Iteration 4180, loss = 0.00959375
I0824 22:57:10.573343 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996794
I0824 22:57:10.573355 43755 solver.cpp:244]     Train net output #1: loss = 0.00959386 (* 1 = 0.00959386 loss)
I0824 22:57:10.573361 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997111
I0824 22:57:10.573379 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995447
I0824 22:57:10.573386 43755 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0824 22:57:27.188282 43755 solver.cpp:228] Iteration 4200, loss = 0.00863117
I0824 22:57:27.188396 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996382
I0824 22:57:27.188413 43755 solver.cpp:244]     Train net output #1: loss = 0.00863129 (* 1 = 0.00863129 loss)
I0824 22:57:27.188424 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996303
I0824 22:57:27.188431 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996735
I0824 22:57:27.188438 43755 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0824 22:57:43.818141 43755 solver.cpp:228] Iteration 4220, loss = 0.0118434
I0824 22:57:43.818182 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995476
I0824 22:57:43.818197 43755 solver.cpp:244]     Train net output #1: loss = 0.0118435 (* 1 = 0.0118435 loss)
I0824 22:57:43.818202 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992362
I0824 22:57:43.818207 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998844
I0824 22:57:43.818215 43755 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0824 22:58:00.443404 43755 solver.cpp:228] Iteration 4240, loss = 0.0109063
I0824 22:58:00.443507 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99558
I0824 22:58:00.443524 43755 solver.cpp:244]     Train net output #1: loss = 0.0109064 (* 1 = 0.0109064 loss)
I0824 22:58:00.443532 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995487
I0824 22:58:00.443539 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995785
I0824 22:58:00.443547 43755 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0824 22:58:17.086498 43755 solver.cpp:228] Iteration 4260, loss = 0.0151402
I0824 22:58:17.086546 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994236
I0824 22:58:17.086561 43755 solver.cpp:244]     Train net output #1: loss = 0.0151403 (* 1 = 0.0151403 loss)
I0824 22:58:17.086568 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992795
I0824 22:58:17.086575 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997205
I0824 22:58:17.086582 43755 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0824 22:58:33.716049 43755 solver.cpp:228] Iteration 4280, loss = 0.0108182
I0824 22:58:33.716176 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996315
I0824 22:58:33.716192 43755 solver.cpp:244]     Train net output #1: loss = 0.0108183 (* 1 = 0.0108183 loss)
I0824 22:58:33.716203 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995318
I0824 22:58:33.716215 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997414
I0824 22:58:33.716223 43755 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0824 22:58:50.328207 43755 solver.cpp:228] Iteration 4300, loss = 0.00736671
I0824 22:58:50.328256 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996976
I0824 22:58:50.328270 43755 solver.cpp:244]     Train net output #1: loss = 0.00736683 (* 1 = 0.00736683 loss)
I0824 22:58:50.328277 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996786
I0824 22:58:50.328284 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997425
I0824 22:58:50.328299 43755 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0824 22:59:06.951616 43755 solver.cpp:228] Iteration 4320, loss = 0.0115816
I0824 22:59:06.951772 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995126
I0824 22:59:06.951795 43755 solver.cpp:244]     Train net output #1: loss = 0.0115817 (* 1 = 0.0115817 loss)
I0824 22:59:06.951803 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993634
I0824 22:59:06.951817 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998202
I0824 22:59:06.951824 43755 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0824 22:59:23.541978 43755 solver.cpp:228] Iteration 4340, loss = 0.00879649
I0824 22:59:23.542027 43755 solver.cpp:244]     Train net output #0: accuracy = 0.9964
I0824 22:59:23.542042 43755 solver.cpp:244]     Train net output #1: loss = 0.00879661 (* 1 = 0.00879661 loss)
I0824 22:59:23.542057 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996493
I0824 22:59:23.542068 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996113
I0824 22:59:23.542078 43755 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0824 22:59:40.136379 43755 solver.cpp:228] Iteration 4360, loss = 0.0070961
I0824 22:59:40.136528 43755 solver.cpp:244]     Train net output #0: accuracy = 0.997222
I0824 22:59:40.136569 43755 solver.cpp:244]     Train net output #1: loss = 0.00709622 (* 1 = 0.00709622 loss)
I0824 22:59:40.136579 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997472
I0824 22:59:40.136590 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995844
I0824 22:59:40.136605 43755 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0824 22:59:56.809322 43755 solver.cpp:228] Iteration 4380, loss = 0.00810946
I0824 22:59:56.809371 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996512
I0824 22:59:56.809386 43755 solver.cpp:244]     Train net output #1: loss = 0.00810958 (* 1 = 0.00810958 loss)
I0824 22:59:56.809393 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996461
I0824 22:59:56.809398 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996702
I0824 22:59:56.809407 43755 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0824 23:00:13.483840 43755 solver.cpp:228] Iteration 4400, loss = 0.00943672
I0824 23:00:13.483953 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996568
I0824 23:00:13.483970 43755 solver.cpp:244]     Train net output #1: loss = 0.00943684 (* 1 = 0.00943684 loss)
I0824 23:00:13.483978 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996583
I0824 23:00:13.483983 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996506
I0824 23:00:13.483991 43755 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0824 23:00:30.109735 43755 solver.cpp:228] Iteration 4420, loss = 0.0180178
I0824 23:00:30.109783 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993333
I0824 23:00:30.109798 43755 solver.cpp:244]     Train net output #1: loss = 0.0180179 (* 1 = 0.0180179 loss)
I0824 23:00:30.109810 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994688
I0824 23:00:30.109822 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987628
I0824 23:00:30.109832 43755 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0824 23:00:46.734958 43755 solver.cpp:228] Iteration 4440, loss = 0.0246216
I0824 23:00:46.735066 43755 solver.cpp:244]     Train net output #0: accuracy = 0.989492
I0824 23:00:46.735083 43755 solver.cpp:244]     Train net output #1: loss = 0.0246217 (* 1 = 0.0246217 loss)
I0824 23:00:46.735092 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980352
I0824 23:00:46.735105 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998466
I0824 23:00:46.735113 43755 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0824 23:01:03.346891 43755 solver.cpp:228] Iteration 4460, loss = 0.0130321
I0824 23:01:03.346937 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995428
I0824 23:01:03.346953 43755 solver.cpp:244]     Train net output #1: loss = 0.0130322 (* 1 = 0.0130322 loss)
I0824 23:01:03.346961 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994857
I0824 23:01:03.346967 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996798
I0824 23:01:03.346983 43755 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0824 23:01:19.969544 43755 solver.cpp:228] Iteration 4480, loss = 0.00768108
I0824 23:01:19.969712 43755 solver.cpp:244]     Train net output #0: accuracy = 0.997364
I0824 23:01:19.969729 43755 solver.cpp:244]     Train net output #1: loss = 0.0076812 (* 1 = 0.0076812 loss)
I0824 23:01:19.969738 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99694
I0824 23:01:19.969744 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998183
I0824 23:01:19.969751 43755 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0824 23:01:36.609786 43755 solver.cpp:228] Iteration 4500, loss = 0.0109668
I0824 23:01:36.609834 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995149
I0824 23:01:36.609849 43755 solver.cpp:244]     Train net output #1: loss = 0.0109669 (* 1 = 0.0109669 loss)
I0824 23:01:36.609858 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993723
I0824 23:01:36.609863 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997816
I0824 23:01:36.609872 43755 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0824 23:01:53.223325 43755 solver.cpp:228] Iteration 4520, loss = 0.012285
I0824 23:01:53.223453 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995742
I0824 23:01:53.223469 43755 solver.cpp:244]     Train net output #1: loss = 0.0122851 (* 1 = 0.0122851 loss)
I0824 23:01:53.223480 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995607
I0824 23:01:53.223487 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99602
I0824 23:01:53.223496 43755 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0824 23:02:09.845165 43755 solver.cpp:228] Iteration 4540, loss = 0.0145434
I0824 23:02:09.845214 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994511
I0824 23:02:09.845229 43755 solver.cpp:244]     Train net output #1: loss = 0.0145435 (* 1 = 0.0145435 loss)
I0824 23:02:09.845242 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994989
I0824 23:02:09.845253 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993649
I0824 23:02:09.845262 43755 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0824 23:02:26.462755 43755 solver.cpp:228] Iteration 4560, loss = 0.0100711
I0824 23:02:26.462873 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996379
I0824 23:02:26.462890 43755 solver.cpp:244]     Train net output #1: loss = 0.0100712 (* 1 = 0.0100712 loss)
I0824 23:02:26.462903 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994316
I0824 23:02:26.462913 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998738
I0824 23:02:26.462926 43755 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0824 23:02:43.086071 43755 solver.cpp:228] Iteration 4580, loss = 0.011083
I0824 23:02:43.086117 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994968
I0824 23:02:43.086133 43755 solver.cpp:244]     Train net output #1: loss = 0.0110831 (* 1 = 0.0110831 loss)
I0824 23:02:43.086146 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994597
I0824 23:02:43.086158 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995891
I0824 23:02:43.086166 43755 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0824 23:02:59.711258 43755 solver.cpp:228] Iteration 4600, loss = 0.0112166
I0824 23:02:59.711426 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995718
I0824 23:02:59.711444 43755 solver.cpp:244]     Train net output #1: loss = 0.0112167 (* 1 = 0.0112167 loss)
I0824 23:02:59.711452 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995337
I0824 23:02:59.711460 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996587
I0824 23:02:59.711468 43755 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0824 23:03:16.297278 43755 solver.cpp:228] Iteration 4620, loss = 0.0103161
I0824 23:03:16.297323 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996222
I0824 23:03:16.297338 43755 solver.cpp:244]     Train net output #1: loss = 0.0103163 (* 1 = 0.0103163 loss)
I0824 23:03:16.297345 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996431
I0824 23:03:16.297351 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995683
I0824 23:03:16.297359 43755 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0824 23:03:32.922451 43755 solver.cpp:228] Iteration 4640, loss = 0.00747645
I0824 23:03:32.922554 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996999
I0824 23:03:32.922569 43755 solver.cpp:244]     Train net output #1: loss = 0.00747657 (* 1 = 0.00747657 loss)
I0824 23:03:32.922574 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997139
I0824 23:03:32.922580 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996316
I0824 23:03:32.922587 43755 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0824 23:03:49.532289 43755 solver.cpp:228] Iteration 4660, loss = 0.012063
I0824 23:03:49.532332 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995266
I0824 23:03:49.532346 43755 solver.cpp:244]     Train net output #1: loss = 0.0120631 (* 1 = 0.0120631 loss)
I0824 23:03:49.532353 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995626
I0824 23:03:49.532359 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992498
I0824 23:03:49.532368 43755 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0824 23:04:06.146224 43755 solver.cpp:228] Iteration 4680, loss = 0.00951229
I0824 23:04:06.146353 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996794
I0824 23:04:06.146407 43755 solver.cpp:244]     Train net output #1: loss = 0.00951241 (* 1 = 0.00951241 loss)
I0824 23:04:06.146417 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995836
I0824 23:04:06.146427 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998012
I0824 23:04:06.146436 43755 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0824 23:04:22.766762 43755 solver.cpp:228] Iteration 4700, loss = 0.0135145
I0824 23:04:22.766809 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994769
I0824 23:04:22.766825 43755 solver.cpp:244]     Train net output #1: loss = 0.0135146 (* 1 = 0.0135146 loss)
I0824 23:04:22.766832 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993953
I0824 23:04:22.766837 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995893
I0824 23:04:22.766846 43755 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0824 23:04:39.375756 43755 solver.cpp:228] Iteration 4720, loss = 0.0114839
I0824 23:04:39.375874 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99542
I0824 23:04:39.375891 43755 solver.cpp:244]     Train net output #1: loss = 0.011484 (* 1 = 0.011484 loss)
I0824 23:04:39.375897 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993065
I0824 23:04:39.375903 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99801
I0824 23:04:39.375913 43755 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0824 23:04:55.993388 43755 solver.cpp:228] Iteration 4740, loss = 0.00732001
I0824 23:04:55.993432 43755 solver.cpp:244]     Train net output #0: accuracy = 0.997237
I0824 23:04:55.993446 43755 solver.cpp:244]     Train net output #1: loss = 0.00732013 (* 1 = 0.00732013 loss)
I0824 23:04:55.993453 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997865
I0824 23:04:55.993459 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995347
I0824 23:04:55.993468 43755 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0824 23:05:12.613643 43755 solver.cpp:228] Iteration 4760, loss = 0.00840983
I0824 23:05:12.613812 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996306
I0824 23:05:12.613836 43755 solver.cpp:244]     Train net output #1: loss = 0.00840995 (* 1 = 0.00840995 loss)
I0824 23:05:12.613843 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995649
I0824 23:05:12.613850 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997684
I0824 23:05:12.613857 43755 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0824 23:05:29.207115 43755 solver.cpp:228] Iteration 4780, loss = 0.0110985
I0824 23:05:29.207157 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995381
I0824 23:05:29.207172 43755 solver.cpp:244]     Train net output #1: loss = 0.0110986 (* 1 = 0.0110986 loss)
I0824 23:05:29.207178 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994711
I0824 23:05:29.207185 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997337
I0824 23:05:29.207192 43755 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0824 23:05:45.808585 43755 solver.cpp:228] Iteration 4800, loss = 0.0116856
I0824 23:05:45.808699 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995269
I0824 23:05:45.808717 43755 solver.cpp:244]     Train net output #1: loss = 0.0116857 (* 1 = 0.0116857 loss)
I0824 23:05:45.808729 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995634
I0824 23:05:45.808739 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993127
I0824 23:05:45.808748 43755 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0824 23:06:02.420388 43755 solver.cpp:228] Iteration 4820, loss = 0.00736028
I0824 23:06:02.420430 43755 solver.cpp:244]     Train net output #0: accuracy = 0.997218
I0824 23:06:02.420444 43755 solver.cpp:244]     Train net output #1: loss = 0.0073604 (* 1 = 0.0073604 loss)
I0824 23:06:02.420451 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997801
I0824 23:06:02.420459 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994819
I0824 23:06:02.420466 43755 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0824 23:06:19.034396 43755 solver.cpp:228] Iteration 4840, loss = 0.00661007
I0824 23:06:19.034509 43755 solver.cpp:244]     Train net output #0: accuracy = 0.997228
I0824 23:06:19.034525 43755 solver.cpp:244]     Train net output #1: loss = 0.00661019 (* 1 = 0.00661019 loss)
I0824 23:06:19.034534 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99685
I0824 23:06:19.034545 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99801
I0824 23:06:19.034554 43755 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0824 23:06:35.647517 43755 solver.cpp:228] Iteration 4860, loss = 0.010763
I0824 23:06:35.647562 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99589
I0824 23:06:35.647575 43755 solver.cpp:244]     Train net output #1: loss = 0.0107631 (* 1 = 0.0107631 loss)
I0824 23:06:35.647581 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994049
I0824 23:06:35.647586 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997927
I0824 23:06:35.647594 43755 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0824 23:06:52.275799 43755 solver.cpp:228] Iteration 4880, loss = 0.013776
I0824 23:06:52.275923 43755 solver.cpp:244]     Train net output #0: accuracy = 0.99508
I0824 23:06:52.275940 43755 solver.cpp:244]     Train net output #1: loss = 0.0137761 (* 1 = 0.0137761 loss)
I0824 23:06:52.275952 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994634
I0824 23:06:52.275965 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996056
I0824 23:06:52.275974 43755 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0824 23:07:08.867229 43755 solver.cpp:228] Iteration 4900, loss = 0.00871215
I0824 23:07:08.867280 43755 solver.cpp:244]     Train net output #0: accuracy = 0.996536
I0824 23:07:08.867295 43755 solver.cpp:244]     Train net output #1: loss = 0.00871227 (* 1 = 0.00871227 loss)
I0824 23:07:08.867301 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996779
I0824 23:07:08.867307 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995588
I0824 23:07:08.867317 43755 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0824 23:07:25.490434 43755 solver.cpp:228] Iteration 4920, loss = 0.0126431
I0824 23:07:25.490618 43755 solver.cpp:244]     Train net output #0: accuracy = 0.994984
I0824 23:07:25.490639 43755 solver.cpp:244]     Train net output #1: loss = 0.0126432 (* 1 = 0.0126432 loss)
I0824 23:07:25.490648 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99391
I0824 23:07:25.490659 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996935
I0824 23:07:25.490667 43755 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0824 23:07:42.104079 43755 solver.cpp:228] Iteration 4940, loss = 0.0194734
I0824 23:07:42.104120 43755 solver.cpp:244]     Train net output #0: accuracy = 0.993349
I0824 23:07:42.104133 43755 solver.cpp:244]     Train net output #1: loss = 0.0194736 (* 1 = 0.0194736 loss)
I0824 23:07:42.104140 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993177
I0824 23:07:42.104146 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993587
I0824 23:07:42.104154 43755 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0824 23:07:58.734033 43755 solver.cpp:228] Iteration 4960, loss = 0.011903
I0824 23:07:58.734153 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995352
I0824 23:07:58.734175 43755 solver.cpp:244]     Train net output #1: loss = 0.0119031 (* 1 = 0.0119031 loss)
I0824 23:07:58.734184 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995836
I0824 23:07:58.734194 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994041
I0824 23:07:58.734210 43755 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0824 23:08:15.339237 43755 solver.cpp:228] Iteration 4980, loss = 0.0107864
I0824 23:08:15.339287 43755 solver.cpp:244]     Train net output #0: accuracy = 0.995417
I0824 23:08:15.339303 43755 solver.cpp:244]     Train net output #1: loss = 0.0107865 (* 1 = 0.0107865 loss)
I0824 23:08:15.339310 43755 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994239
I0824 23:08:15.339316 43755 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99738
I0824 23:08:15.339326 43755 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0824 23:08:31.589469 43755 solver.cpp:454] Snapshotting to binary proto file pocwisc6/training_iter_5000.caffemodel
I0824 23:08:32.642707 43755 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc6/training_iter_5000.solverstate
I0824 23:08:33.241730 43755 solver.cpp:317] Iteration 5000, loss = 0.00575807
I0824 23:08:33.241777 43755 solver.cpp:322] Optimization Done.
I0824 23:08:33.241781 43755 caffe.cpp:254] Optimization Done.

2017-08-24 23:08:33,659 log.framework MainThread  INFO       caffe models found
pocwisc6/training_iter_5000.caffemodel
2017-08-24 23:08:33,659 log.framework MainThread  INFO       Caffe model found: pocwisc6/training_iter_5000.caffemodel
2017-08-24 23:08:35,332 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 23:08:35,543 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 23:08:35,738 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 23:08:35,951 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 23:08:36,146 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-24 23:08:36,296 log.framework MainThread  INFO       train file number: 48
2017-08-24 23:08:36,296 log.framework MainThread  INFO       test file number: 7
2017-08-24 23:08:36,296 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 23:08:36,296 log.framework MainThread  INFO       subdirectory tree 
2017-08-24 23:08:36,297 log.framework MainThread  INFO       Opening inference file: inference.prototxt
2017-08-24 23:08:36,376 log.framework MainThread  INFO       Opening training file: train.prototxt
2017-08-24 23:08:36,376 log.framework MainThread  INFO       Opening solver file: segnet_solver.prototxt
2017-08-24 23:08:36,377 log.framework MainThread  INFO       Caffe runs with this configuration
net: "/disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/train.prototxt"
test_initialization: false
test_iter: 1
test_interval: 10000000
base_lr: 0.001
lr_policy: "step"
gamma: 1.0
stepsize: 10000000
display: 20
momentum: 0.9
max_iter: 5000
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "pocwisc7/training"
solver_mode: GPU

2017-08-24 23:08:36,377 log.framework MainThread  INFO       caffe training step
2017-08-24 23:08:36,378 log.framework MainThread  INFO       Calling the following command for training:
/root/caffe-segnet-cudnn5/build/tools/caffe train -gpu 0 -solver /disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/segnet_solver.prototxt -weights /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel 2>&1 | tee caffe_log.txt
2017-08-25 00:18:06,216 log.framework MainThread  INFO       I0824 23:08:36.429520 44210 caffe.cpp:217] Using GPUs 0
I0824 23:08:36.441011 44210 caffe.cpp:222] GPU 0: Tesla P100-PCIE-16GB
I0824 23:08:36.967221 44210 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 5000
snapshot_prefix: "pocwisc7/training"
solver_mode: GPU
device_id: 0
net: "/disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0824 23:08:36.967394 44210 solver.cpp:91] Creating training net from net file: /disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/train.prototxt
I0824 23:08:36.970214 44210 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 23:08:36.970727 44210 layer_factory.hpp:77] Creating layer data
I0824 23:08:36.970749 44210 net.cpp:100] Creating Layer data
I0824 23:08:36.970759 44210 net.cpp:408] data -> data
I0824 23:08:36.970789 44210 net.cpp:408] data -> label
I0824 23:08:36.970811 44210 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt
I0824 23:08:36.973834 44210 hdf5_data_layer.cpp:93] Number of HDF5 files: 48
I0824 23:08:36.975046 44210 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0824 23:08:37.078507 44210 net.cpp:150] Setting up data
I0824 23:08:37.078536 44210 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 23:08:37.078548 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:37.078557 44210 net.cpp:165] Memory required for data: 24883200
I0824 23:08:37.078565 44210 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 23:08:37.078580 44210 net.cpp:100] Creating Layer label_data_1_split
I0824 23:08:37.078589 44210 net.cpp:434] label_data_1_split <- label
I0824 23:08:37.078606 44210 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 23:08:37.078619 44210 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 23:08:37.078662 44210 net.cpp:150] Setting up label_data_1_split
I0824 23:08:37.078670 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:37.078676 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:37.078680 44210 net.cpp:165] Memory required for data: 30412800
I0824 23:08:37.078685 44210 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 23:08:37.078706 44210 net.cpp:100] Creating Layer conv1_1_1
I0824 23:08:37.078712 44210 net.cpp:434] conv1_1_1 <- data
I0824 23:08:37.078718 44210 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 23:08:37.600358 44210 net.cpp:150] Setting up conv1_1_1
I0824 23:08:37.600399 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.600404 44210 net.cpp:165] Memory required for data: 207360000
I0824 23:08:37.600436 44210 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 23:08:37.600455 44210 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 23:08:37.600462 44210 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 23:08:37.600471 44210 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 23:08:37.600872 44210 net.cpp:150] Setting up conv1_1_1_bn
I0824 23:08:37.600883 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.600893 44210 net.cpp:165] Memory required for data: 384307200
I0824 23:08:37.600906 44210 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 23:08:37.600924 44210 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 23:08:37.600930 44210 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 23:08:37.600936 44210 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 23:08:37.600988 44210 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 23:08:37.602650 44210 net.cpp:150] Setting up conv1_1_1_scale
I0824 23:08:37.602668 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.602676 44210 net.cpp:165] Memory required for data: 561254400
I0824 23:08:37.602685 44210 layer_factory.hpp:77] Creating layer relu1_1
I0824 23:08:37.602696 44210 net.cpp:100] Creating Layer relu1_1
I0824 23:08:37.602702 44210 net.cpp:434] relu1_1 <- conv1_1_1
I0824 23:08:37.602708 44210 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 23:08:37.602941 44210 net.cpp:150] Setting up relu1_1
I0824 23:08:37.602953 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.602958 44210 net.cpp:165] Memory required for data: 738201600
I0824 23:08:37.602962 44210 layer_factory.hpp:77] Creating layer conv1_2
I0824 23:08:37.602977 44210 net.cpp:100] Creating Layer conv1_2
I0824 23:08:37.602982 44210 net.cpp:434] conv1_2 <- conv1_1_1
I0824 23:08:37.602989 44210 net.cpp:408] conv1_2 -> conv1_2
I0824 23:08:37.607216 44210 net.cpp:150] Setting up conv1_2
I0824 23:08:37.607234 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.607244 44210 net.cpp:165] Memory required for data: 915148800
I0824 23:08:37.607257 44210 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 23:08:37.607267 44210 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 23:08:37.607276 44210 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 23:08:37.607282 44210 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 23:08:37.608834 44210 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 23:08:37.608850 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.608857 44210 net.cpp:165] Memory required for data: 1092096000
I0824 23:08:37.608868 44210 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 23:08:37.608878 44210 net.cpp:100] Creating Layer conv1_2_scale
I0824 23:08:37.608885 44210 net.cpp:434] conv1_2_scale <- conv1_2
I0824 23:08:37.608891 44210 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 23:08:37.608937 44210 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 23:08:37.609313 44210 net.cpp:150] Setting up conv1_2_scale
I0824 23:08:37.609323 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.609328 44210 net.cpp:165] Memory required for data: 1269043200
I0824 23:08:37.609334 44210 layer_factory.hpp:77] Creating layer relu1_2
I0824 23:08:37.609342 44210 net.cpp:100] Creating Layer relu1_2
I0824 23:08:37.609347 44210 net.cpp:434] relu1_2 <- conv1_2
I0824 23:08:37.609352 44210 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 23:08:37.609560 44210 net.cpp:150] Setting up relu1_2
I0824 23:08:37.609570 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:37.609575 44210 net.cpp:165] Memory required for data: 1445990400
I0824 23:08:37.609578 44210 layer_factory.hpp:77] Creating layer pool1
I0824 23:08:37.609586 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:37.609592 44210 net.cpp:100] Creating Layer pool1
I0824 23:08:37.609597 44210 net.cpp:434] pool1 <- conv1_2
I0824 23:08:37.609603 44210 net.cpp:408] pool1 -> pool1
I0824 23:08:37.609614 44210 net.cpp:408] pool1 -> pool1_mask
I0824 23:08:37.609673 44210 net.cpp:150] Setting up pool1
I0824 23:08:37.609680 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:37.609685 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:37.609690 44210 net.cpp:165] Memory required for data: 1534464000
I0824 23:08:37.609695 44210 layer_factory.hpp:77] Creating layer conv2_1
I0824 23:08:37.609709 44210 net.cpp:100] Creating Layer conv2_1
I0824 23:08:37.609714 44210 net.cpp:434] conv2_1 <- pool1
I0824 23:08:37.609719 44210 net.cpp:408] conv2_1 -> conv2_1
I0824 23:08:37.615838 44210 net.cpp:150] Setting up conv2_1
I0824 23:08:37.615855 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.615867 44210 net.cpp:165] Memory required for data: 1622937600
I0824 23:08:37.615876 44210 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 23:08:37.615885 44210 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 23:08:37.615890 44210 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 23:08:37.615895 44210 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 23:08:37.616127 44210 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 23:08:37.616137 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.616140 44210 net.cpp:165] Memory required for data: 1711411200
I0824 23:08:37.616160 44210 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 23:08:37.616183 44210 net.cpp:100] Creating Layer conv2_1_scale
I0824 23:08:37.616188 44210 net.cpp:434] conv2_1_scale <- conv2_1
I0824 23:08:37.616194 44210 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 23:08:37.616240 44210 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 23:08:37.616417 44210 net.cpp:150] Setting up conv2_1_scale
I0824 23:08:37.616427 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.616431 44210 net.cpp:165] Memory required for data: 1799884800
I0824 23:08:37.616439 44210 layer_factory.hpp:77] Creating layer relu2_1
I0824 23:08:37.616449 44210 net.cpp:100] Creating Layer relu2_1
I0824 23:08:37.616454 44210 net.cpp:434] relu2_1 <- conv2_1
I0824 23:08:37.616461 44210 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 23:08:37.617497 44210 net.cpp:150] Setting up relu2_1
I0824 23:08:37.617513 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.617518 44210 net.cpp:165] Memory required for data: 1888358400
I0824 23:08:37.617525 44210 layer_factory.hpp:77] Creating layer conv2_2
I0824 23:08:37.617538 44210 net.cpp:100] Creating Layer conv2_2
I0824 23:08:37.617544 44210 net.cpp:434] conv2_2 <- conv2_1
I0824 23:08:37.617552 44210 net.cpp:408] conv2_2 -> conv2_2
I0824 23:08:37.624904 44210 net.cpp:150] Setting up conv2_2
I0824 23:08:37.624922 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.624930 44210 net.cpp:165] Memory required for data: 1976832000
I0824 23:08:37.624939 44210 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 23:08:37.624951 44210 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 23:08:37.624958 44210 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 23:08:37.624963 44210 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 23:08:37.625197 44210 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 23:08:37.625207 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.625211 44210 net.cpp:165] Memory required for data: 2065305600
I0824 23:08:37.625221 44210 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 23:08:37.625231 44210 net.cpp:100] Creating Layer conv2_2_scale
I0824 23:08:37.625239 44210 net.cpp:434] conv2_2_scale <- conv2_2
I0824 23:08:37.625246 44210 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 23:08:37.625288 44210 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 23:08:37.625474 44210 net.cpp:150] Setting up conv2_2_scale
I0824 23:08:37.625484 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.625488 44210 net.cpp:165] Memory required for data: 2153779200
I0824 23:08:37.625495 44210 layer_factory.hpp:77] Creating layer relu2_2
I0824 23:08:37.625502 44210 net.cpp:100] Creating Layer relu2_2
I0824 23:08:37.625507 44210 net.cpp:434] relu2_2 <- conv2_2
I0824 23:08:37.625514 44210 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 23:08:37.625711 44210 net.cpp:150] Setting up relu2_2
I0824 23:08:37.625721 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:37.625726 44210 net.cpp:165] Memory required for data: 2242252800
I0824 23:08:37.625732 44210 layer_factory.hpp:77] Creating layer pool2
I0824 23:08:37.625738 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:37.625744 44210 net.cpp:100] Creating Layer pool2
I0824 23:08:37.625749 44210 net.cpp:434] pool2 <- conv2_2
I0824 23:08:37.625756 44210 net.cpp:408] pool2 -> pool2
I0824 23:08:37.625764 44210 net.cpp:408] pool2 -> pool2_mask
I0824 23:08:37.625811 44210 net.cpp:150] Setting up pool2
I0824 23:08:37.625818 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:37.625823 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:37.625828 44210 net.cpp:165] Memory required for data: 2286489600
I0824 23:08:37.625831 44210 layer_factory.hpp:77] Creating layer conv3_1
I0824 23:08:37.625844 44210 net.cpp:100] Creating Layer conv3_1
I0824 23:08:37.625849 44210 net.cpp:434] conv3_1 <- pool2
I0824 23:08:37.625855 44210 net.cpp:408] conv3_1 -> conv3_1
I0824 23:08:37.637965 44210 net.cpp:150] Setting up conv3_1
I0824 23:08:37.637996 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.638007 44210 net.cpp:165] Memory required for data: 2330726400
I0824 23:08:37.638016 44210 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 23:08:37.638026 44210 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 23:08:37.638033 44210 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 23:08:37.638041 44210 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 23:08:37.638262 44210 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 23:08:37.638270 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.638279 44210 net.cpp:165] Memory required for data: 2374963200
I0824 23:08:37.638293 44210 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 23:08:37.638303 44210 net.cpp:100] Creating Layer conv3_1_scale
I0824 23:08:37.638309 44210 net.cpp:434] conv3_1_scale <- conv3_1
I0824 23:08:37.638314 44210 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 23:08:37.638357 44210 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 23:08:37.638494 44210 net.cpp:150] Setting up conv3_1_scale
I0824 23:08:37.638502 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.638509 44210 net.cpp:165] Memory required for data: 2419200000
I0824 23:08:37.638517 44210 layer_factory.hpp:77] Creating layer relu3_1
I0824 23:08:37.638526 44210 net.cpp:100] Creating Layer relu3_1
I0824 23:08:37.638531 44210 net.cpp:434] relu3_1 <- conv3_1
I0824 23:08:37.638537 44210 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 23:08:37.638736 44210 net.cpp:150] Setting up relu3_1
I0824 23:08:37.638746 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.638751 44210 net.cpp:165] Memory required for data: 2463436800
I0824 23:08:37.638756 44210 layer_factory.hpp:77] Creating layer conv3_2
I0824 23:08:37.638768 44210 net.cpp:100] Creating Layer conv3_2
I0824 23:08:37.638773 44210 net.cpp:434] conv3_2 <- conv3_1
I0824 23:08:37.638782 44210 net.cpp:408] conv3_2 -> conv3_2
I0824 23:08:37.662006 44210 net.cpp:150] Setting up conv3_2
I0824 23:08:37.662024 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.662034 44210 net.cpp:165] Memory required for data: 2507673600
I0824 23:08:37.662042 44210 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 23:08:37.662056 44210 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 23:08:37.662065 44210 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 23:08:37.662070 44210 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 23:08:37.662286 44210 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 23:08:37.662294 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.662298 44210 net.cpp:165] Memory required for data: 2551910400
I0824 23:08:37.662307 44210 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 23:08:37.662319 44210 net.cpp:100] Creating Layer conv3_2_scale
I0824 23:08:37.662324 44210 net.cpp:434] conv3_2_scale <- conv3_2
I0824 23:08:37.662330 44210 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 23:08:37.662374 44210 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 23:08:37.662513 44210 net.cpp:150] Setting up conv3_2_scale
I0824 23:08:37.662523 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.662528 44210 net.cpp:165] Memory required for data: 2596147200
I0824 23:08:37.662534 44210 layer_factory.hpp:77] Creating layer relu3_2
I0824 23:08:37.662541 44210 net.cpp:100] Creating Layer relu3_2
I0824 23:08:37.662547 44210 net.cpp:434] relu3_2 <- conv3_2
I0824 23:08:37.662552 44210 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 23:08:37.662755 44210 net.cpp:150] Setting up relu3_2
I0824 23:08:37.662765 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.662770 44210 net.cpp:165] Memory required for data: 2640384000
I0824 23:08:37.662775 44210 layer_factory.hpp:77] Creating layer conv3_3
I0824 23:08:37.662786 44210 net.cpp:100] Creating Layer conv3_3
I0824 23:08:37.662791 44210 net.cpp:434] conv3_3 <- conv3_2
I0824 23:08:37.662797 44210 net.cpp:408] conv3_3 -> conv3_3
I0824 23:08:37.686049 44210 net.cpp:150] Setting up conv3_3
I0824 23:08:37.686081 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.686090 44210 net.cpp:165] Memory required for data: 2684620800
I0824 23:08:37.686100 44210 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 23:08:37.686113 44210 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 23:08:37.686121 44210 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 23:08:37.686127 44210 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 23:08:37.686347 44210 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 23:08:37.686357 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.686360 44210 net.cpp:165] Memory required for data: 2728857600
I0824 23:08:37.686375 44210 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 23:08:37.686388 44210 net.cpp:100] Creating Layer conv3_3_scale
I0824 23:08:37.686393 44210 net.cpp:434] conv3_3_scale <- conv3_3
I0824 23:08:37.686398 44210 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 23:08:37.686444 44210 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 23:08:37.686583 44210 net.cpp:150] Setting up conv3_3_scale
I0824 23:08:37.686591 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.686596 44210 net.cpp:165] Memory required for data: 2773094400
I0824 23:08:37.686604 44210 layer_factory.hpp:77] Creating layer relu3_3
I0824 23:08:37.686611 44210 net.cpp:100] Creating Layer relu3_3
I0824 23:08:37.686616 44210 net.cpp:434] relu3_3 <- conv3_3
I0824 23:08:37.686621 44210 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 23:08:37.686827 44210 net.cpp:150] Setting up relu3_3
I0824 23:08:37.686837 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:37.686842 44210 net.cpp:165] Memory required for data: 2817331200
I0824 23:08:37.686846 44210 layer_factory.hpp:77] Creating layer pool3
I0824 23:08:37.686851 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:37.686861 44210 net.cpp:100] Creating Layer pool3
I0824 23:08:37.686867 44210 net.cpp:434] pool3 <- conv3_3
I0824 23:08:37.686873 44210 net.cpp:408] pool3 -> pool3
I0824 23:08:37.686882 44210 net.cpp:408] pool3 -> pool3_mask
I0824 23:08:37.686930 44210 net.cpp:150] Setting up pool3
I0824 23:08:37.686939 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:37.686944 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:37.686949 44210 net.cpp:165] Memory required for data: 2839449600
I0824 23:08:37.686951 44210 layer_factory.hpp:77] Creating layer conv4_1
I0824 23:08:37.686964 44210 net.cpp:100] Creating Layer conv4_1
I0824 23:08:37.686969 44210 net.cpp:434] conv4_1 <- pool3
I0824 23:08:37.686975 44210 net.cpp:408] conv4_1 -> conv4_1
I0824 23:08:37.733089 44210 net.cpp:150] Setting up conv4_1
I0824 23:08:37.733108 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.733119 44210 net.cpp:165] Memory required for data: 2861568000
I0824 23:08:37.733130 44210 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 23:08:37.733140 44210 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 23:08:37.733147 44210 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 23:08:37.733155 44210 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 23:08:37.733388 44210 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 23:08:37.733399 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.733403 44210 net.cpp:165] Memory required for data: 2883686400
I0824 23:08:37.733412 44210 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 23:08:37.733423 44210 net.cpp:100] Creating Layer conv4_1_scale
I0824 23:08:37.733428 44210 net.cpp:434] conv4_1_scale <- conv4_1
I0824 23:08:37.733434 44210 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 23:08:37.733479 44210 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 23:08:37.733606 44210 net.cpp:150] Setting up conv4_1_scale
I0824 23:08:37.733614 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.733618 44210 net.cpp:165] Memory required for data: 2905804800
I0824 23:08:37.733625 44210 layer_factory.hpp:77] Creating layer relu4_1
I0824 23:08:37.733649 44210 net.cpp:100] Creating Layer relu4_1
I0824 23:08:37.733654 44210 net.cpp:434] relu4_1 <- conv4_1
I0824 23:08:37.733660 44210 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 23:08:37.733873 44210 net.cpp:150] Setting up relu4_1
I0824 23:08:37.733883 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.733888 44210 net.cpp:165] Memory required for data: 2927923200
I0824 23:08:37.733892 44210 layer_factory.hpp:77] Creating layer conv4_2
I0824 23:08:37.733904 44210 net.cpp:100] Creating Layer conv4_2
I0824 23:08:37.733911 44210 net.cpp:434] conv4_2 <- conv4_1
I0824 23:08:37.733917 44210 net.cpp:408] conv4_2 -> conv4_2
I0824 23:08:37.817332 44210 net.cpp:150] Setting up conv4_2
I0824 23:08:37.817350 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.817356 44210 net.cpp:165] Memory required for data: 2950041600
I0824 23:08:37.817384 44210 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 23:08:37.817394 44210 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 23:08:37.817399 44210 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 23:08:37.817406 44210 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 23:08:37.817617 44210 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 23:08:37.817627 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.817631 44210 net.cpp:165] Memory required for data: 2972160000
I0824 23:08:37.817641 44210 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 23:08:37.817656 44210 net.cpp:100] Creating Layer conv4_2_scale
I0824 23:08:37.817663 44210 net.cpp:434] conv4_2_scale <- conv4_2
I0824 23:08:37.817668 44210 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 23:08:37.817715 44210 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 23:08:37.817842 44210 net.cpp:150] Setting up conv4_2_scale
I0824 23:08:37.817852 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.817854 44210 net.cpp:165] Memory required for data: 2994278400
I0824 23:08:37.817862 44210 layer_factory.hpp:77] Creating layer relu4_2
I0824 23:08:37.817870 44210 net.cpp:100] Creating Layer relu4_2
I0824 23:08:37.817875 44210 net.cpp:434] relu4_2 <- conv4_2
I0824 23:08:37.817881 44210 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 23:08:37.818939 44210 net.cpp:150] Setting up relu4_2
I0824 23:08:37.818955 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.818960 44210 net.cpp:165] Memory required for data: 3016396800
I0824 23:08:37.818965 44210 layer_factory.hpp:77] Creating layer conv4_3
I0824 23:08:37.818979 44210 net.cpp:100] Creating Layer conv4_3
I0824 23:08:37.818985 44210 net.cpp:434] conv4_3 <- conv4_2
I0824 23:08:37.818994 44210 net.cpp:408] conv4_3 -> conv4_3
I0824 23:08:37.902564 44210 net.cpp:150] Setting up conv4_3
I0824 23:08:37.902582 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.902587 44210 net.cpp:165] Memory required for data: 3038515200
I0824 23:08:37.902611 44210 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 23:08:37.902623 44210 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 23:08:37.902631 44210 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 23:08:37.902637 44210 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 23:08:37.902853 44210 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 23:08:37.902863 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.902871 44210 net.cpp:165] Memory required for data: 3060633600
I0824 23:08:37.902881 44210 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 23:08:37.902890 44210 net.cpp:100] Creating Layer conv4_3_scale
I0824 23:08:37.902895 44210 net.cpp:434] conv4_3_scale <- conv4_3
I0824 23:08:37.902901 44210 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 23:08:37.902945 44210 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 23:08:37.903076 44210 net.cpp:150] Setting up conv4_3_scale
I0824 23:08:37.903085 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.903090 44210 net.cpp:165] Memory required for data: 3082752000
I0824 23:08:37.903097 44210 layer_factory.hpp:77] Creating layer relu4_3
I0824 23:08:37.903120 44210 net.cpp:100] Creating Layer relu4_3
I0824 23:08:37.903126 44210 net.cpp:434] relu4_3 <- conv4_3
I0824 23:08:37.903132 44210 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 23:08:37.903338 44210 net.cpp:150] Setting up relu4_3
I0824 23:08:37.903348 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:37.903353 44210 net.cpp:165] Memory required for data: 3104870400
I0824 23:08:37.903357 44210 layer_factory.hpp:77] Creating layer pool4
I0824 23:08:37.903362 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:37.903370 44210 net.cpp:100] Creating Layer pool4
I0824 23:08:37.903375 44210 net.cpp:434] pool4 <- conv4_3
I0824 23:08:37.903383 44210 net.cpp:408] pool4 -> pool4
I0824 23:08:37.903393 44210 net.cpp:408] pool4 -> pool4_mask
I0824 23:08:37.903441 44210 net.cpp:150] Setting up pool4
I0824 23:08:37.903450 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.903453 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.903458 44210 net.cpp:165] Memory required for data: 3116175360
I0824 23:08:37.903463 44210 layer_factory.hpp:77] Creating layer conv5_1
I0824 23:08:37.903477 44210 net.cpp:100] Creating Layer conv5_1
I0824 23:08:37.903482 44210 net.cpp:434] conv5_1 <- pool4
I0824 23:08:37.903489 44210 net.cpp:408] conv5_1 -> conv5_1
I0824 23:08:37.987026 44210 net.cpp:150] Setting up conv5_1
I0824 23:08:37.987046 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.987057 44210 net.cpp:165] Memory required for data: 3121827840
I0824 23:08:37.987066 44210 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 23:08:37.987074 44210 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 23:08:37.987083 44210 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 23:08:37.987090 44210 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 23:08:37.987308 44210 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 23:08:37.987316 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.987320 44210 net.cpp:165] Memory required for data: 3127480320
I0824 23:08:37.987335 44210 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 23:08:37.987345 44210 net.cpp:100] Creating Layer conv5_1_scale
I0824 23:08:37.987350 44210 net.cpp:434] conv5_1_scale <- conv5_1
I0824 23:08:37.987356 44210 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 23:08:37.987404 44210 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 23:08:37.987527 44210 net.cpp:150] Setting up conv5_1_scale
I0824 23:08:37.987536 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.987540 44210 net.cpp:165] Memory required for data: 3133132800
I0824 23:08:37.987547 44210 layer_factory.hpp:77] Creating layer relu5_1
I0824 23:08:37.987557 44210 net.cpp:100] Creating Layer relu5_1
I0824 23:08:37.987563 44210 net.cpp:434] relu5_1 <- conv5_1
I0824 23:08:37.987568 44210 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 23:08:37.987772 44210 net.cpp:150] Setting up relu5_1
I0824 23:08:37.987782 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:37.987787 44210 net.cpp:165] Memory required for data: 3138785280
I0824 23:08:37.987793 44210 layer_factory.hpp:77] Creating layer conv5_2
I0824 23:08:37.987807 44210 net.cpp:100] Creating Layer conv5_2
I0824 23:08:37.987812 44210 net.cpp:434] conv5_2 <- conv5_1
I0824 23:08:37.987821 44210 net.cpp:408] conv5_2 -> conv5_2
I0824 23:08:38.072044 44210 net.cpp:150] Setting up conv5_2
I0824 23:08:38.072067 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.072079 44210 net.cpp:165] Memory required for data: 3144437760
I0824 23:08:38.072091 44210 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 23:08:38.072104 44210 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 23:08:38.072113 44210 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 23:08:38.072125 44210 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 23:08:38.072350 44210 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 23:08:38.072360 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.072381 44210 net.cpp:165] Memory required for data: 3150090240
I0824 23:08:38.072391 44210 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 23:08:38.072403 44210 net.cpp:100] Creating Layer conv5_2_scale
I0824 23:08:38.072408 44210 net.cpp:434] conv5_2_scale <- conv5_2
I0824 23:08:38.072414 44210 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 23:08:38.072468 44210 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 23:08:38.072599 44210 net.cpp:150] Setting up conv5_2_scale
I0824 23:08:38.072608 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.072613 44210 net.cpp:165] Memory required for data: 3155742720
I0824 23:08:38.072620 44210 layer_factory.hpp:77] Creating layer relu5_2
I0824 23:08:38.072629 44210 net.cpp:100] Creating Layer relu5_2
I0824 23:08:38.072634 44210 net.cpp:434] relu5_2 <- conv5_2
I0824 23:08:38.072640 44210 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 23:08:38.072849 44210 net.cpp:150] Setting up relu5_2
I0824 23:08:38.072860 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.072865 44210 net.cpp:165] Memory required for data: 3161395200
I0824 23:08:38.072870 44210 layer_factory.hpp:77] Creating layer conv5_3
I0824 23:08:38.072885 44210 net.cpp:100] Creating Layer conv5_3
I0824 23:08:38.072890 44210 net.cpp:434] conv5_3 <- conv5_2
I0824 23:08:38.072898 44210 net.cpp:408] conv5_3 -> conv5_3
I0824 23:08:38.156597 44210 net.cpp:150] Setting up conv5_3
I0824 23:08:38.156617 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.156626 44210 net.cpp:165] Memory required for data: 3167047680
I0824 23:08:38.156635 44210 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 23:08:38.156646 44210 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 23:08:38.156652 44210 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 23:08:38.156661 44210 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 23:08:38.156886 44210 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 23:08:38.156895 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.156898 44210 net.cpp:165] Memory required for data: 3172700160
I0824 23:08:38.156908 44210 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 23:08:38.156919 44210 net.cpp:100] Creating Layer conv5_3_scale
I0824 23:08:38.156925 44210 net.cpp:434] conv5_3_scale <- conv5_3
I0824 23:08:38.156931 44210 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 23:08:38.156981 44210 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 23:08:38.157112 44210 net.cpp:150] Setting up conv5_3_scale
I0824 23:08:38.157121 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.157124 44210 net.cpp:165] Memory required for data: 3178352640
I0824 23:08:38.157131 44210 layer_factory.hpp:77] Creating layer relu5_3
I0824 23:08:38.157140 44210 net.cpp:100] Creating Layer relu5_3
I0824 23:08:38.157145 44210 net.cpp:434] relu5_3 <- conv5_3
I0824 23:08:38.157150 44210 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 23:08:38.157358 44210 net.cpp:150] Setting up relu5_3
I0824 23:08:38.157387 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.157392 44210 net.cpp:165] Memory required for data: 3184005120
I0824 23:08:38.157397 44210 layer_factory.hpp:77] Creating layer pool5
I0824 23:08:38.157402 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:38.157410 44210 net.cpp:100] Creating Layer pool5
I0824 23:08:38.157415 44210 net.cpp:434] pool5 <- conv5_3
I0824 23:08:38.157423 44210 net.cpp:408] pool5 -> pool5
I0824 23:08:38.157433 44210 net.cpp:408] pool5 -> pool5_mask
I0824 23:08:38.157485 44210 net.cpp:150] Setting up pool5
I0824 23:08:38.157493 44210 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 23:08:38.157498 44210 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 23:08:38.157502 44210 net.cpp:165] Memory required for data: 3186954240
I0824 23:08:38.157506 44210 layer_factory.hpp:77] Creating layer upsample5
I0824 23:08:38.157521 44210 net.cpp:100] Creating Layer upsample5
I0824 23:08:38.157526 44210 net.cpp:434] upsample5 <- pool5
I0824 23:08:38.157546 44210 net.cpp:434] upsample5 <- pool5_mask
I0824 23:08:38.157554 44210 net.cpp:408] upsample5 -> pool5_D
I0824 23:08:38.157598 44210 net.cpp:150] Setting up upsample5
I0824 23:08:38.157606 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.157610 44210 net.cpp:165] Memory required for data: 3192606720
I0824 23:08:38.157613 44210 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 23:08:38.157627 44210 net.cpp:100] Creating Layer conv5_3_D
I0824 23:08:38.157634 44210 net.cpp:434] conv5_3_D <- pool5_D
I0824 23:08:38.157641 44210 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 23:08:38.242136 44210 net.cpp:150] Setting up conv5_3_D
I0824 23:08:38.242154 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.242166 44210 net.cpp:165] Memory required for data: 3198259200
I0824 23:08:38.242174 44210 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 23:08:38.242184 44210 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 23:08:38.242192 44210 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 23:08:38.242199 44210 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 23:08:38.242429 44210 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 23:08:38.242439 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.242441 44210 net.cpp:165] Memory required for data: 3203911680
I0824 23:08:38.242456 44210 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 23:08:38.242466 44210 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 23:08:38.242471 44210 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 23:08:38.242478 44210 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 23:08:38.242528 44210 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 23:08:38.242660 44210 net.cpp:150] Setting up conv5_3_D_scale
I0824 23:08:38.242668 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.242672 44210 net.cpp:165] Memory required for data: 3209564160
I0824 23:08:38.242679 44210 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 23:08:38.242686 44210 net.cpp:100] Creating Layer relu5_3_D
I0824 23:08:38.242691 44210 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 23:08:38.242698 44210 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 23:08:38.242918 44210 net.cpp:150] Setting up relu5_3_D
I0824 23:08:38.242928 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.242933 44210 net.cpp:165] Memory required for data: 3215216640
I0824 23:08:38.242936 44210 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 23:08:38.242974 44210 net.cpp:100] Creating Layer conv5_2_D
I0824 23:08:38.242980 44210 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 23:08:38.242990 44210 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 23:08:38.326680 44210 net.cpp:150] Setting up conv5_2_D
I0824 23:08:38.326699 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.326702 44210 net.cpp:165] Memory required for data: 3220869120
I0824 23:08:38.326711 44210 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 23:08:38.326720 44210 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 23:08:38.326726 44210 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 23:08:38.326733 44210 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 23:08:38.326962 44210 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 23:08:38.326972 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.326974 44210 net.cpp:165] Memory required for data: 3226521600
I0824 23:08:38.326985 44210 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 23:08:38.326995 44210 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 23:08:38.327002 44210 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 23:08:38.327008 44210 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 23:08:38.327060 44210 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 23:08:38.327193 44210 net.cpp:150] Setting up conv5_2_D_scale
I0824 23:08:38.327201 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.327205 44210 net.cpp:165] Memory required for data: 3232174080
I0824 23:08:38.327229 44210 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 23:08:38.327237 44210 net.cpp:100] Creating Layer relu5_2_D
I0824 23:08:38.327244 44210 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 23:08:38.327250 44210 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 23:08:38.328336 44210 net.cpp:150] Setting up relu5_2_D
I0824 23:08:38.328351 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.328356 44210 net.cpp:165] Memory required for data: 3237826560
I0824 23:08:38.328361 44210 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 23:08:38.328375 44210 net.cpp:100] Creating Layer conv5_1_D
I0824 23:08:38.328382 44210 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 23:08:38.328390 44210 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 23:08:38.412014 44210 net.cpp:150] Setting up conv5_1_D
I0824 23:08:38.412034 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.412045 44210 net.cpp:165] Memory required for data: 3243479040
I0824 23:08:38.412053 44210 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 23:08:38.412065 44210 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 23:08:38.412070 44210 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 23:08:38.412078 44210 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 23:08:38.412315 44210 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 23:08:38.412324 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.412333 44210 net.cpp:165] Memory required for data: 3249131520
I0824 23:08:38.412343 44210 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 23:08:38.412353 44210 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 23:08:38.412358 44210 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 23:08:38.412365 44210 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 23:08:38.412416 44210 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 23:08:38.412552 44210 net.cpp:150] Setting up conv5_1_D_scale
I0824 23:08:38.412560 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.412564 44210 net.cpp:165] Memory required for data: 3254784000
I0824 23:08:38.412571 44210 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 23:08:38.412580 44210 net.cpp:100] Creating Layer relu5_1_D
I0824 23:08:38.412585 44210 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 23:08:38.412591 44210 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 23:08:38.412801 44210 net.cpp:150] Setting up relu5_1_D
I0824 23:08:38.412811 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:38.412816 44210 net.cpp:165] Memory required for data: 3260436480
I0824 23:08:38.412819 44210 layer_factory.hpp:77] Creating layer upsample4
I0824 23:08:38.412828 44210 net.cpp:100] Creating Layer upsample4
I0824 23:08:38.412833 44210 net.cpp:434] upsample4 <- conv5_1_D
I0824 23:08:38.412838 44210 net.cpp:434] upsample4 <- pool4_mask
I0824 23:08:38.412847 44210 net.cpp:408] upsample4 -> pool4_D
I0824 23:08:38.412883 44210 net.cpp:150] Setting up upsample4
I0824 23:08:38.412892 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.412896 44210 net.cpp:165] Memory required for data: 3282554880
I0824 23:08:38.412900 44210 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 23:08:38.412914 44210 net.cpp:100] Creating Layer conv4_3_D
I0824 23:08:38.412919 44210 net.cpp:434] conv4_3_D <- pool4_D
I0824 23:08:38.412926 44210 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 23:08:38.496631 44210 net.cpp:150] Setting up conv4_3_D
I0824 23:08:38.496651 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.496661 44210 net.cpp:165] Memory required for data: 3304673280
I0824 23:08:38.496670 44210 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 23:08:38.496680 44210 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 23:08:38.496686 44210 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 23:08:38.496693 44210 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 23:08:38.496933 44210 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 23:08:38.496942 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.496964 44210 net.cpp:165] Memory required for data: 3326791680
I0824 23:08:38.496975 44210 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 23:08:38.496987 44210 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 23:08:38.496992 44210 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 23:08:38.496999 44210 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 23:08:38.497048 44210 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 23:08:38.497200 44210 net.cpp:150] Setting up conv4_3_D_scale
I0824 23:08:38.497210 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.497213 44210 net.cpp:165] Memory required for data: 3348910080
I0824 23:08:38.497220 44210 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 23:08:38.497229 44210 net.cpp:100] Creating Layer relu4_3_D
I0824 23:08:38.497234 44210 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 23:08:38.497241 44210 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 23:08:38.497470 44210 net.cpp:150] Setting up relu4_3_D
I0824 23:08:38.497481 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.497488 44210 net.cpp:165] Memory required for data: 3371028480
I0824 23:08:38.497491 44210 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 23:08:38.497509 44210 net.cpp:100] Creating Layer conv4_2_D
I0824 23:08:38.497514 44210 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 23:08:38.497522 44210 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 23:08:38.582813 44210 net.cpp:150] Setting up conv4_2_D
I0824 23:08:38.582834 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.582845 44210 net.cpp:165] Memory required for data: 3393146880
I0824 23:08:38.582857 44210 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 23:08:38.582871 44210 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 23:08:38.582883 44210 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 23:08:38.582895 44210 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 23:08:38.583137 44210 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 23:08:38.583145 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.583149 44210 net.cpp:165] Memory required for data: 3415265280
I0824 23:08:38.583158 44210 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 23:08:38.583171 44210 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 23:08:38.583176 44210 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 23:08:38.583183 44210 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 23:08:38.583228 44210 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 23:08:38.583379 44210 net.cpp:150] Setting up conv4_2_D_scale
I0824 23:08:38.583386 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.583390 44210 net.cpp:165] Memory required for data: 3437383680
I0824 23:08:38.583397 44210 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 23:08:38.583405 44210 net.cpp:100] Creating Layer relu4_2_D
I0824 23:08:38.583410 44210 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 23:08:38.583417 44210 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 23:08:38.583626 44210 net.cpp:150] Setting up relu4_2_D
I0824 23:08:38.583636 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.583640 44210 net.cpp:165] Memory required for data: 3459502080
I0824 23:08:38.583644 44210 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 23:08:38.583660 44210 net.cpp:100] Creating Layer conv4_1_D
I0824 23:08:38.583665 44210 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 23:08:38.583674 44210 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 23:08:38.627575 44210 net.cpp:150] Setting up conv4_1_D
I0824 23:08:38.627593 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.627604 44210 net.cpp:165] Memory required for data: 3470561280
I0824 23:08:38.627612 44210 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 23:08:38.627622 44210 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 23:08:38.627629 44210 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 23:08:38.627637 44210 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 23:08:38.627881 44210 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 23:08:38.627907 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.627915 44210 net.cpp:165] Memory required for data: 3481620480
I0824 23:08:38.627969 44210 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 23:08:38.627979 44210 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 23:08:38.627985 44210 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 23:08:38.627991 44210 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 23:08:38.628046 44210 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 23:08:38.628191 44210 net.cpp:150] Setting up conv4_1_D_scale
I0824 23:08:38.628201 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.628203 44210 net.cpp:165] Memory required for data: 3492679680
I0824 23:08:38.628211 44210 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 23:08:38.628221 44210 net.cpp:100] Creating Layer relu4_1_D
I0824 23:08:38.628226 44210 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 23:08:38.628232 44210 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 23:08:38.628454 44210 net.cpp:150] Setting up relu4_1_D
I0824 23:08:38.628464 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.628469 44210 net.cpp:165] Memory required for data: 3503738880
I0824 23:08:38.628473 44210 layer_factory.hpp:77] Creating layer upsample3
I0824 23:08:38.628484 44210 net.cpp:100] Creating Layer upsample3
I0824 23:08:38.628489 44210 net.cpp:434] upsample3 <- conv4_1_D
I0824 23:08:38.628495 44210 net.cpp:434] upsample3 <- pool3_mask
I0824 23:08:38.628504 44210 net.cpp:408] upsample3 -> pool3_D
I0824 23:08:38.628513 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:38.628547 44210 net.cpp:150] Setting up upsample3
I0824 23:08:38.628556 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.628561 44210 net.cpp:165] Memory required for data: 3547975680
I0824 23:08:38.628564 44210 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 23:08:38.628578 44210 net.cpp:100] Creating Layer conv3_3_D
I0824 23:08:38.628583 44210 net.cpp:434] conv3_3_D <- pool3_D
I0824 23:08:38.628594 44210 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 23:08:38.652086 44210 net.cpp:150] Setting up conv3_3_D
I0824 23:08:38.652103 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.652113 44210 net.cpp:165] Memory required for data: 3592212480
I0824 23:08:38.652122 44210 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 23:08:38.652133 44210 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 23:08:38.652140 44210 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 23:08:38.652148 44210 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 23:08:38.652405 44210 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 23:08:38.652413 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.652417 44210 net.cpp:165] Memory required for data: 3636449280
I0824 23:08:38.652426 44210 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 23:08:38.652438 44210 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 23:08:38.652444 44210 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 23:08:38.652451 44210 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 23:08:38.652500 44210 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 23:08:38.652664 44210 net.cpp:150] Setting up conv3_3_D_scale
I0824 23:08:38.652673 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.652678 44210 net.cpp:165] Memory required for data: 3680686080
I0824 23:08:38.652685 44210 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 23:08:38.652694 44210 net.cpp:100] Creating Layer relu3_3_D
I0824 23:08:38.652699 44210 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 23:08:38.652705 44210 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 23:08:38.652925 44210 net.cpp:150] Setting up relu3_3_D
I0824 23:08:38.652935 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.652940 44210 net.cpp:165] Memory required for data: 3724922880
I0824 23:08:38.652958 44210 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 23:08:38.652972 44210 net.cpp:100] Creating Layer conv3_2_D
I0824 23:08:38.652977 44210 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 23:08:38.652987 44210 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 23:08:38.676457 44210 net.cpp:150] Setting up conv3_2_D
I0824 23:08:38.676476 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.676489 44210 net.cpp:165] Memory required for data: 3769159680
I0824 23:08:38.676499 44210 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 23:08:38.676512 44210 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 23:08:38.676519 44210 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 23:08:38.676527 44210 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 23:08:38.676791 44210 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 23:08:38.676801 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.676810 44210 net.cpp:165] Memory required for data: 3813396480
I0824 23:08:38.676820 44210 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 23:08:38.676828 44210 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 23:08:38.676834 44210 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 23:08:38.676841 44210 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 23:08:38.676892 44210 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 23:08:38.677054 44210 net.cpp:150] Setting up conv3_2_D_scale
I0824 23:08:38.677063 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.677067 44210 net.cpp:165] Memory required for data: 3857633280
I0824 23:08:38.677074 44210 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 23:08:38.677084 44210 net.cpp:100] Creating Layer relu3_2_D
I0824 23:08:38.677089 44210 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 23:08:38.677096 44210 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 23:08:38.678210 44210 net.cpp:150] Setting up relu3_2_D
I0824 23:08:38.678226 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.678231 44210 net.cpp:165] Memory required for data: 3901870080
I0824 23:08:38.678236 44210 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 23:08:38.678251 44210 net.cpp:100] Creating Layer conv3_1_D
I0824 23:08:38.678257 44210 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 23:08:38.678267 44210 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 23:08:38.692014 44210 net.cpp:150] Setting up conv3_1_D
I0824 23:08:38.692032 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.692041 44210 net.cpp:165] Memory required for data: 3923988480
I0824 23:08:38.692050 44210 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 23:08:38.692061 44210 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 23:08:38.692068 44210 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 23:08:38.692075 44210 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 23:08:38.692338 44210 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 23:08:38.692348 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.692356 44210 net.cpp:165] Memory required for data: 3946106880
I0824 23:08:38.692366 44210 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 23:08:38.692375 44210 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 23:08:38.692380 44210 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 23:08:38.692386 44210 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 23:08:38.692437 44210 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 23:08:38.692607 44210 net.cpp:150] Setting up conv3_1_D_scale
I0824 23:08:38.692616 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.692620 44210 net.cpp:165] Memory required for data: 3968225280
I0824 23:08:38.692626 44210 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 23:08:38.692636 44210 net.cpp:100] Creating Layer relu3_1_D
I0824 23:08:38.692641 44210 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 23:08:38.692647 44210 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 23:08:38.692867 44210 net.cpp:150] Setting up relu3_1_D
I0824 23:08:38.692890 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.692896 44210 net.cpp:165] Memory required for data: 3990343680
I0824 23:08:38.692900 44210 layer_factory.hpp:77] Creating layer upsample2
I0824 23:08:38.692909 44210 net.cpp:100] Creating Layer upsample2
I0824 23:08:38.692914 44210 net.cpp:434] upsample2 <- conv3_1_D
I0824 23:08:38.692919 44210 net.cpp:434] upsample2 <- pool2_mask
I0824 23:08:38.692927 44210 net.cpp:408] upsample2 -> pool2_D
I0824 23:08:38.692936 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:38.692972 44210 net.cpp:150] Setting up upsample2
I0824 23:08:38.692981 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.692986 44210 net.cpp:165] Memory required for data: 4078817280
I0824 23:08:38.692988 44210 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 23:08:38.693001 44210 net.cpp:100] Creating Layer conv2_2_D
I0824 23:08:38.693006 44210 net.cpp:434] conv2_2_D <- pool2_D
I0824 23:08:38.693014 44210 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 23:08:38.700687 44210 net.cpp:150] Setting up conv2_2_D
I0824 23:08:38.700706 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.700713 44210 net.cpp:165] Memory required for data: 4167290880
I0824 23:08:38.700722 44210 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 23:08:38.700736 44210 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 23:08:38.700742 44210 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 23:08:38.700752 44210 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 23:08:38.701058 44210 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 23:08:38.701068 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.701078 44210 net.cpp:165] Memory required for data: 4255764480
I0824 23:08:38.701087 44210 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 23:08:38.701097 44210 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 23:08:38.701102 44210 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 23:08:38.701108 44210 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 23:08:38.701161 44210 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 23:08:38.702672 44210 net.cpp:150] Setting up conv2_2_D_scale
I0824 23:08:38.702688 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.702693 44210 net.cpp:165] Memory required for data: 4344238080
I0824 23:08:38.702702 44210 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 23:08:38.702711 44210 net.cpp:100] Creating Layer relu2_2_D
I0824 23:08:38.702718 44210 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 23:08:38.702725 44210 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 23:08:38.702961 44210 net.cpp:150] Setting up relu2_2_D
I0824 23:08:38.702971 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.702976 44210 net.cpp:165] Memory required for data: 4432711680
I0824 23:08:38.702980 44210 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 23:08:38.702993 44210 net.cpp:100] Creating Layer conv2_1_D
I0824 23:08:38.702999 44210 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 23:08:38.703008 44210 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 23:08:38.708256 44210 net.cpp:150] Setting up conv2_1_D
I0824 23:08:38.708274 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.708281 44210 net.cpp:165] Memory required for data: 4476948480
I0824 23:08:38.708290 44210 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 23:08:38.708304 44210 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 23:08:38.708312 44210 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 23:08:38.708318 44210 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 23:08:38.708621 44210 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 23:08:38.708631 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.708636 44210 net.cpp:165] Memory required for data: 4521185280
I0824 23:08:38.708645 44210 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 23:08:38.708668 44210 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 23:08:38.708673 44210 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 23:08:38.708680 44210 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 23:08:38.708739 44210 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 23:08:38.708961 44210 net.cpp:150] Setting up conv2_1_D_scale
I0824 23:08:38.708971 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.708976 44210 net.cpp:165] Memory required for data: 4565422080
I0824 23:08:38.708983 44210 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 23:08:38.708992 44210 net.cpp:100] Creating Layer relu2_1_D
I0824 23:08:38.708997 44210 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 23:08:38.709002 44210 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 23:08:38.709231 44210 net.cpp:150] Setting up relu2_1_D
I0824 23:08:38.709241 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.709246 44210 net.cpp:165] Memory required for data: 4609658880
I0824 23:08:38.709250 44210 layer_factory.hpp:77] Creating layer upsample1
I0824 23:08:38.709259 44210 net.cpp:100] Creating Layer upsample1
I0824 23:08:38.709264 44210 net.cpp:434] upsample1 <- conv2_1_D
I0824 23:08:38.709270 44210 net.cpp:434] upsample1 <- pool1_mask
I0824 23:08:38.709280 44210 net.cpp:408] upsample1 -> pool1_D
I0824 23:08:38.709288 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:38.709323 44210 net.cpp:150] Setting up upsample1
I0824 23:08:38.709331 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.709336 44210 net.cpp:165] Memory required for data: 4786606080
I0824 23:08:38.709339 44210 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 23:08:38.709352 44210 net.cpp:100] Creating Layer conv1_2_D
I0824 23:08:38.709357 44210 net.cpp:434] conv1_2_D <- pool1_D
I0824 23:08:38.709379 44210 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 23:08:38.713910 44210 net.cpp:150] Setting up conv1_2_D
I0824 23:08:38.713928 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.713938 44210 net.cpp:165] Memory required for data: 4963553280
I0824 23:08:38.713948 44210 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 23:08:38.713963 44210 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 23:08:38.713968 44210 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 23:08:38.713975 44210 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 23:08:38.714371 44210 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 23:08:38.714380 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.714385 44210 net.cpp:165] Memory required for data: 5140500480
I0824 23:08:38.714396 44210 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 23:08:38.714406 44210 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 23:08:38.714411 44210 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 23:08:38.714417 44210 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 23:08:38.714470 44210 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 23:08:38.716159 44210 net.cpp:150] Setting up conv1_2_D_scale
I0824 23:08:38.716176 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.716181 44210 net.cpp:165] Memory required for data: 5317447680
I0824 23:08:38.716189 44210 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 23:08:38.716198 44210 net.cpp:100] Creating Layer relu1_2_D
I0824 23:08:38.716204 44210 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 23:08:38.716212 44210 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 23:08:38.716446 44210 net.cpp:150] Setting up relu1_2_D
I0824 23:08:38.716457 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.716461 44210 net.cpp:165] Memory required for data: 5494394880
I0824 23:08:38.716466 44210 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 23:08:38.716478 44210 net.cpp:100] Creating Layer conv1_1_1_D
I0824 23:08:38.716485 44210 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 23:08:38.716508 44210 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 23:08:38.718585 44210 net.cpp:150] Setting up conv1_1_1_D
I0824 23:08:38.718602 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:38.718608 44210 net.cpp:165] Memory required for data: 5499924480
I0824 23:08:38.718617 44210 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:38.718626 44210 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:38.718632 44210 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 23:08:38.718641 44210 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 23:08:38.718650 44210 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 23:08:38.718708 44210 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:38.718715 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:38.718722 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:38.718725 44210 net.cpp:165] Memory required for data: 5510983680
I0824 23:08:38.718730 44210 layer_factory.hpp:77] Creating layer loss
I0824 23:08:38.718746 44210 net.cpp:100] Creating Layer loss
I0824 23:08:38.718752 44210 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 23:08:38.718757 44210 net.cpp:434] loss <- label_data_1_split_0
I0824 23:08:38.718766 44210 net.cpp:408] loss -> loss
I0824 23:08:38.718786 44210 layer_factory.hpp:77] Creating layer loss
I0824 23:08:38.722909 44210 net.cpp:150] Setting up loss
I0824 23:08:38.722925 44210 net.cpp:157] Top shape: (1)
I0824 23:08:38.722934 44210 net.cpp:160]     with loss weight 1
I0824 23:08:38.722973 44210 net.cpp:165] Memory required for data: 5510983684
I0824 23:08:38.722978 44210 layer_factory.hpp:77] Creating layer accuracy
I0824 23:08:38.722991 44210 net.cpp:100] Creating Layer accuracy
I0824 23:08:38.722996 44210 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 23:08:38.723003 44210 net.cpp:434] accuracy <- label_data_1_split_1
I0824 23:08:38.723012 44210 net.cpp:408] accuracy -> accuracy
I0824 23:08:38.723021 44210 net.cpp:408] accuracy -> per_class_accuracy
I0824 23:08:38.723080 44210 net.cpp:150] Setting up accuracy
I0824 23:08:38.723088 44210 net.cpp:157] Top shape: (1)
I0824 23:08:38.723093 44210 net.cpp:157] Top shape: 2 (2)
I0824 23:08:38.723098 44210 net.cpp:165] Memory required for data: 5510983696
I0824 23:08:38.723101 44210 net.cpp:228] accuracy does not need backward computation.
I0824 23:08:38.723105 44210 net.cpp:226] loss needs backward computation.
I0824 23:08:38.723110 44210 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 23:08:38.723114 44210 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 23:08:38.723117 44210 net.cpp:226] relu1_2_D needs backward computation.
I0824 23:08:38.723122 44210 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 23:08:38.723125 44210 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 23:08:38.723129 44210 net.cpp:226] conv1_2_D needs backward computation.
I0824 23:08:38.723131 44210 net.cpp:226] upsample1 needs backward computation.
I0824 23:08:38.723135 44210 net.cpp:226] relu2_1_D needs backward computation.
I0824 23:08:38.723140 44210 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 23:08:38.723142 44210 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 23:08:38.723145 44210 net.cpp:226] conv2_1_D needs backward computation.
I0824 23:08:38.723148 44210 net.cpp:226] relu2_2_D needs backward computation.
I0824 23:08:38.723151 44210 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 23:08:38.723155 44210 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 23:08:38.723157 44210 net.cpp:226] conv2_2_D needs backward computation.
I0824 23:08:38.723161 44210 net.cpp:226] upsample2 needs backward computation.
I0824 23:08:38.723165 44210 net.cpp:226] relu3_1_D needs backward computation.
I0824 23:08:38.723168 44210 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 23:08:38.723186 44210 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 23:08:38.723189 44210 net.cpp:226] conv3_1_D needs backward computation.
I0824 23:08:38.723193 44210 net.cpp:226] relu3_2_D needs backward computation.
I0824 23:08:38.723196 44210 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 23:08:38.723199 44210 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 23:08:38.723203 44210 net.cpp:226] conv3_2_D needs backward computation.
I0824 23:08:38.723206 44210 net.cpp:226] relu3_3_D needs backward computation.
I0824 23:08:38.723212 44210 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 23:08:38.723214 44210 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 23:08:38.723217 44210 net.cpp:226] conv3_3_D needs backward computation.
I0824 23:08:38.723220 44210 net.cpp:226] upsample3 needs backward computation.
I0824 23:08:38.723225 44210 net.cpp:226] relu4_1_D needs backward computation.
I0824 23:08:38.723228 44210 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 23:08:38.723232 44210 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 23:08:38.723234 44210 net.cpp:226] conv4_1_D needs backward computation.
I0824 23:08:38.723238 44210 net.cpp:226] relu4_2_D needs backward computation.
I0824 23:08:38.723242 44210 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 23:08:38.723244 44210 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 23:08:38.723248 44210 net.cpp:226] conv4_2_D needs backward computation.
I0824 23:08:38.723253 44210 net.cpp:226] relu4_3_D needs backward computation.
I0824 23:08:38.723258 44210 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 23:08:38.723260 44210 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 23:08:38.723264 44210 net.cpp:226] conv4_3_D needs backward computation.
I0824 23:08:38.723268 44210 net.cpp:226] upsample4 needs backward computation.
I0824 23:08:38.723274 44210 net.cpp:226] relu5_1_D needs backward computation.
I0824 23:08:38.723279 44210 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 23:08:38.723284 44210 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 23:08:38.723286 44210 net.cpp:226] conv5_1_D needs backward computation.
I0824 23:08:38.723291 44210 net.cpp:226] relu5_2_D needs backward computation.
I0824 23:08:38.723294 44210 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 23:08:38.723300 44210 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 23:08:38.723304 44210 net.cpp:226] conv5_2_D needs backward computation.
I0824 23:08:38.723309 44210 net.cpp:226] relu5_3_D needs backward computation.
I0824 23:08:38.723312 44210 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 23:08:38.723316 44210 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 23:08:38.723320 44210 net.cpp:226] conv5_3_D needs backward computation.
I0824 23:08:38.723323 44210 net.cpp:226] upsample5 needs backward computation.
I0824 23:08:38.723327 44210 net.cpp:226] pool5 needs backward computation.
I0824 23:08:38.723333 44210 net.cpp:226] relu5_3 needs backward computation.
I0824 23:08:38.723338 44210 net.cpp:226] conv5_3_scale needs backward computation.
I0824 23:08:38.723342 44210 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 23:08:38.723345 44210 net.cpp:226] conv5_3 needs backward computation.
I0824 23:08:38.723350 44210 net.cpp:226] relu5_2 needs backward computation.
I0824 23:08:38.723354 44210 net.cpp:226] conv5_2_scale needs backward computation.
I0824 23:08:38.723357 44210 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 23:08:38.723361 44210 net.cpp:226] conv5_2 needs backward computation.
I0824 23:08:38.723366 44210 net.cpp:226] relu5_1 needs backward computation.
I0824 23:08:38.723369 44210 net.cpp:226] conv5_1_scale needs backward computation.
I0824 23:08:38.723373 44210 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 23:08:38.723376 44210 net.cpp:226] conv5_1 needs backward computation.
I0824 23:08:38.723381 44210 net.cpp:226] pool4 needs backward computation.
I0824 23:08:38.723392 44210 net.cpp:226] relu4_3 needs backward computation.
I0824 23:08:38.723395 44210 net.cpp:226] conv4_3_scale needs backward computation.
I0824 23:08:38.723399 44210 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 23:08:38.723402 44210 net.cpp:226] conv4_3 needs backward computation.
I0824 23:08:38.723407 44210 net.cpp:226] relu4_2 needs backward computation.
I0824 23:08:38.723409 44210 net.cpp:226] conv4_2_scale needs backward computation.
I0824 23:08:38.723413 44210 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 23:08:38.723417 44210 net.cpp:226] conv4_2 needs backward computation.
I0824 23:08:38.723420 44210 net.cpp:226] relu4_1 needs backward computation.
I0824 23:08:38.723423 44210 net.cpp:226] conv4_1_scale needs backward computation.
I0824 23:08:38.723426 44210 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 23:08:38.723430 44210 net.cpp:226] conv4_1 needs backward computation.
I0824 23:08:38.723433 44210 net.cpp:226] pool3 needs backward computation.
I0824 23:08:38.723438 44210 net.cpp:226] relu3_3 needs backward computation.
I0824 23:08:38.723443 44210 net.cpp:226] conv3_3_scale needs backward computation.
I0824 23:08:38.723445 44210 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 23:08:38.723449 44210 net.cpp:226] conv3_3 needs backward computation.
I0824 23:08:38.723453 44210 net.cpp:226] relu3_2 needs backward computation.
I0824 23:08:38.723456 44210 net.cpp:226] conv3_2_scale needs backward computation.
I0824 23:08:38.723459 44210 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 23:08:38.723464 44210 net.cpp:226] conv3_2 needs backward computation.
I0824 23:08:38.723466 44210 net.cpp:226] relu3_1 needs backward computation.
I0824 23:08:38.723471 44210 net.cpp:226] conv3_1_scale needs backward computation.
I0824 23:08:38.723474 44210 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 23:08:38.723477 44210 net.cpp:226] conv3_1 needs backward computation.
I0824 23:08:38.723484 44210 net.cpp:226] pool2 needs backward computation.
I0824 23:08:38.723486 44210 net.cpp:226] relu2_2 needs backward computation.
I0824 23:08:38.723490 44210 net.cpp:226] conv2_2_scale needs backward computation.
I0824 23:08:38.723495 44210 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 23:08:38.723498 44210 net.cpp:226] conv2_2 needs backward computation.
I0824 23:08:38.723503 44210 net.cpp:226] relu2_1 needs backward computation.
I0824 23:08:38.723506 44210 net.cpp:226] conv2_1_scale needs backward computation.
I0824 23:08:38.723511 44210 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 23:08:38.723515 44210 net.cpp:226] conv2_1 needs backward computation.
I0824 23:08:38.723518 44210 net.cpp:226] pool1 needs backward computation.
I0824 23:08:38.723523 44210 net.cpp:226] relu1_2 needs backward computation.
I0824 23:08:38.723527 44210 net.cpp:226] conv1_2_scale needs backward computation.
I0824 23:08:38.723531 44210 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 23:08:38.723534 44210 net.cpp:226] conv1_2 needs backward computation.
I0824 23:08:38.723537 44210 net.cpp:226] relu1_1 needs backward computation.
I0824 23:08:38.723541 44210 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 23:08:38.723546 44210 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 23:08:38.723548 44210 net.cpp:226] conv1_1_1 needs backward computation.
I0824 23:08:38.723553 44210 net.cpp:228] label_data_1_split does not need backward computation.
I0824 23:08:38.723557 44210 net.cpp:228] data does not need backward computation.
I0824 23:08:38.723563 44210 net.cpp:270] This network produces output accuracy
I0824 23:08:38.723567 44210 net.cpp:270] This network produces output loss
I0824 23:08:38.723572 44210 net.cpp:270] This network produces output per_class_accuracy
I0824 23:08:38.723634 44210 net.cpp:283] Network initialization done.
I0824 23:08:38.726013 44210 solver.cpp:181] Creating test net (#0) specified by net file: /disk2/nik/Analyzer/test/pocwisc7/caffe/model_segnet_final/train.prototxt
I0824 23:08:38.726707 44210 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt"
    batch_size: 4
    shuffle: true
  }
}
layer {
  name: "conv1_1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_1_1_scale"
  type: "Scale"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1_1"
  top: "conv1_1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_scale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 23
    upsample_w: 30
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3_D_scale"
  type: "Scale"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2_D_scale"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1_D_scale"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 45
    upsample_w: 60
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_D_scale"
  type: "Scale"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_D_scale"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_D_scale"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_D_scale"
  type: "Scale"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_D_scale"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_D_scale"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_D_scale"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_D_scale"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_D_bn_tmp"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1_2_D_scale"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    weight_by_label_freqs: true
    class_weighting: 0.7564
    class_weighting: 1.5572
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0824 23:08:38.727114 44210 layer_factory.hpp:77] Creating layer data
I0824 23:08:38.727128 44210 net.cpp:100] Creating Layer data
I0824 23:08:38.727133 44210 net.cpp:408] data -> data
I0824 23:08:38.727143 44210 net.cpp:408] data -> label
I0824 23:08:38.727151 44210 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /disk2/nik/Analyzer/test/pocwisc7/HDF5Files/train_combined.txt
I0824 23:08:38.727200 44210 hdf5_data_layer.cpp:93] Number of HDF5 files: 48
I0824 23:08:38.785923 44210 net.cpp:150] Setting up data
I0824 23:08:38.785943 44210 net.cpp:157] Top shape: 4 8 360 480 (5529600)
I0824 23:08:38.785948 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:38.785953 44210 net.cpp:165] Memory required for data: 24883200
I0824 23:08:38.785957 44210 layer_factory.hpp:77] Creating layer label_data_1_split
I0824 23:08:38.785967 44210 net.cpp:100] Creating Layer label_data_1_split
I0824 23:08:38.785974 44210 net.cpp:434] label_data_1_split <- label
I0824 23:08:38.785979 44210 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0824 23:08:38.785993 44210 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0824 23:08:38.786041 44210 net.cpp:150] Setting up label_data_1_split
I0824 23:08:38.786048 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:38.786054 44210 net.cpp:157] Top shape: 4 1 360 480 (691200)
I0824 23:08:38.786062 44210 net.cpp:165] Memory required for data: 30412800
I0824 23:08:38.786065 44210 layer_factory.hpp:77] Creating layer conv1_1_1
I0824 23:08:38.786077 44210 net.cpp:100] Creating Layer conv1_1_1
I0824 23:08:38.786082 44210 net.cpp:434] conv1_1_1 <- data
I0824 23:08:38.786087 44210 net.cpp:408] conv1_1_1 -> conv1_1_1
I0824 23:08:38.789608 44210 net.cpp:150] Setting up conv1_1_1
I0824 23:08:38.789626 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.789633 44210 net.cpp:165] Memory required for data: 207360000
I0824 23:08:38.789646 44210 layer_factory.hpp:77] Creating layer conv1_1_1_bn
I0824 23:08:38.789655 44210 net.cpp:100] Creating Layer conv1_1_1_bn
I0824 23:08:38.789664 44210 net.cpp:434] conv1_1_1_bn <- conv1_1_1
I0824 23:08:38.789670 44210 net.cpp:395] conv1_1_1_bn -> conv1_1_1 (in-place)
I0824 23:08:38.790052 44210 net.cpp:150] Setting up conv1_1_1_bn
I0824 23:08:38.790062 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.790066 44210 net.cpp:165] Memory required for data: 384307200
I0824 23:08:38.790084 44210 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 23:08:38.790093 44210 net.cpp:100] Creating Layer conv1_1_1_scale
I0824 23:08:38.790098 44210 net.cpp:434] conv1_1_1_scale <- conv1_1_1
I0824 23:08:38.790104 44210 net.cpp:395] conv1_1_1_scale -> conv1_1_1 (in-place)
I0824 23:08:38.790156 44210 layer_factory.hpp:77] Creating layer conv1_1_1_scale
I0824 23:08:38.791860 44210 net.cpp:150] Setting up conv1_1_1_scale
I0824 23:08:38.791877 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.791882 44210 net.cpp:165] Memory required for data: 561254400
I0824 23:08:38.791891 44210 layer_factory.hpp:77] Creating layer relu1_1
I0824 23:08:38.791899 44210 net.cpp:100] Creating Layer relu1_1
I0824 23:08:38.791904 44210 net.cpp:434] relu1_1 <- conv1_1_1
I0824 23:08:38.791910 44210 net.cpp:395] relu1_1 -> conv1_1_1 (in-place)
I0824 23:08:38.792134 44210 net.cpp:150] Setting up relu1_1
I0824 23:08:38.792143 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.792148 44210 net.cpp:165] Memory required for data: 738201600
I0824 23:08:38.792152 44210 layer_factory.hpp:77] Creating layer conv1_2
I0824 23:08:38.792162 44210 net.cpp:100] Creating Layer conv1_2
I0824 23:08:38.792167 44210 net.cpp:434] conv1_2 <- conv1_1_1
I0824 23:08:38.792174 44210 net.cpp:408] conv1_2 -> conv1_2
I0824 23:08:38.796279 44210 net.cpp:150] Setting up conv1_2
I0824 23:08:38.796298 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.796309 44210 net.cpp:165] Memory required for data: 915148800
I0824 23:08:38.796339 44210 layer_factory.hpp:77] Creating layer conv1_2_bn_tmp
I0824 23:08:38.796349 44210 net.cpp:100] Creating Layer conv1_2_bn_tmp
I0824 23:08:38.796353 44210 net.cpp:434] conv1_2_bn_tmp <- conv1_2
I0824 23:08:38.796360 44210 net.cpp:395] conv1_2_bn_tmp -> conv1_2 (in-place)
I0824 23:08:38.796741 44210 net.cpp:150] Setting up conv1_2_bn_tmp
I0824 23:08:38.796751 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.796756 44210 net.cpp:165] Memory required for data: 1092096000
I0824 23:08:38.796766 44210 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 23:08:38.796774 44210 net.cpp:100] Creating Layer conv1_2_scale
I0824 23:08:38.796779 44210 net.cpp:434] conv1_2_scale <- conv1_2
I0824 23:08:38.796784 44210 net.cpp:395] conv1_2_scale -> conv1_2 (in-place)
I0824 23:08:38.796836 44210 layer_factory.hpp:77] Creating layer conv1_2_scale
I0824 23:08:38.798555 44210 net.cpp:150] Setting up conv1_2_scale
I0824 23:08:38.798571 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.798578 44210 net.cpp:165] Memory required for data: 1269043200
I0824 23:08:38.798585 44210 layer_factory.hpp:77] Creating layer relu1_2
I0824 23:08:38.798593 44210 net.cpp:100] Creating Layer relu1_2
I0824 23:08:38.798599 44210 net.cpp:434] relu1_2 <- conv1_2
I0824 23:08:38.798604 44210 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0824 23:08:38.799724 44210 net.cpp:150] Setting up relu1_2
I0824 23:08:38.799742 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:38.799748 44210 net.cpp:165] Memory required for data: 1445990400
I0824 23:08:38.799752 44210 layer_factory.hpp:77] Creating layer pool1
I0824 23:08:38.799759 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:38.799765 44210 net.cpp:100] Creating Layer pool1
I0824 23:08:38.799770 44210 net.cpp:434] pool1 <- conv1_2
I0824 23:08:38.799777 44210 net.cpp:408] pool1 -> pool1
I0824 23:08:38.799787 44210 net.cpp:408] pool1 -> pool1_mask
I0824 23:08:38.799847 44210 net.cpp:150] Setting up pool1
I0824 23:08:38.799856 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.799862 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:38.799866 44210 net.cpp:165] Memory required for data: 1534464000
I0824 23:08:38.799870 44210 layer_factory.hpp:77] Creating layer conv2_1
I0824 23:08:38.799882 44210 net.cpp:100] Creating Layer conv2_1
I0824 23:08:38.799887 44210 net.cpp:434] conv2_1 <- pool1
I0824 23:08:38.799895 44210 net.cpp:408] conv2_1 -> conv2_1
I0824 23:08:38.804253 44210 net.cpp:150] Setting up conv2_1
I0824 23:08:38.804273 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.804282 44210 net.cpp:165] Memory required for data: 1622937600
I0824 23:08:38.804291 44210 layer_factory.hpp:77] Creating layer conv2_1_bn_tmp
I0824 23:08:38.804298 44210 net.cpp:100] Creating Layer conv2_1_bn_tmp
I0824 23:08:38.804307 44210 net.cpp:434] conv2_1_bn_tmp <- conv2_1
I0824 23:08:38.804316 44210 net.cpp:395] conv2_1_bn_tmp -> conv2_1 (in-place)
I0824 23:08:38.804633 44210 net.cpp:150] Setting up conv2_1_bn_tmp
I0824 23:08:38.804642 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.804647 44210 net.cpp:165] Memory required for data: 1711411200
I0824 23:08:38.804661 44210 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 23:08:38.804668 44210 net.cpp:100] Creating Layer conv2_1_scale
I0824 23:08:38.804674 44210 net.cpp:434] conv2_1_scale <- conv2_1
I0824 23:08:38.804682 44210 net.cpp:395] conv2_1_scale -> conv2_1 (in-place)
I0824 23:08:38.804734 44210 layer_factory.hpp:77] Creating layer conv2_1_scale
I0824 23:08:38.804976 44210 net.cpp:150] Setting up conv2_1_scale
I0824 23:08:38.804986 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.804991 44210 net.cpp:165] Memory required for data: 1799884800
I0824 23:08:38.804997 44210 layer_factory.hpp:77] Creating layer relu2_1
I0824 23:08:38.805007 44210 net.cpp:100] Creating Layer relu2_1
I0824 23:08:38.805012 44210 net.cpp:434] relu2_1 <- conv2_1
I0824 23:08:38.805017 44210 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0824 23:08:38.806169 44210 net.cpp:150] Setting up relu2_1
I0824 23:08:38.806185 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.806190 44210 net.cpp:165] Memory required for data: 1888358400
I0824 23:08:38.806195 44210 layer_factory.hpp:77] Creating layer conv2_2
I0824 23:08:38.806208 44210 net.cpp:100] Creating Layer conv2_2
I0824 23:08:38.806215 44210 net.cpp:434] conv2_2 <- conv2_1
I0824 23:08:38.806222 44210 net.cpp:408] conv2_2 -> conv2_2
I0824 23:08:38.815299 44210 net.cpp:150] Setting up conv2_2
I0824 23:08:38.815316 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.815325 44210 net.cpp:165] Memory required for data: 1976832000
I0824 23:08:38.815336 44210 layer_factory.hpp:77] Creating layer conv2_2_bn_tmp
I0824 23:08:38.815354 44210 net.cpp:100] Creating Layer conv2_2_bn_tmp
I0824 23:08:38.815361 44210 net.cpp:434] conv2_2_bn_tmp <- conv2_2
I0824 23:08:38.815366 44210 net.cpp:395] conv2_2_bn_tmp -> conv2_2 (in-place)
I0824 23:08:38.816962 44210 net.cpp:150] Setting up conv2_2_bn_tmp
I0824 23:08:38.816977 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.816985 44210 net.cpp:165] Memory required for data: 2065305600
I0824 23:08:38.816995 44210 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 23:08:38.817004 44210 net.cpp:100] Creating Layer conv2_2_scale
I0824 23:08:38.817013 44210 net.cpp:434] conv2_2_scale <- conv2_2
I0824 23:08:38.817018 44210 net.cpp:395] conv2_2_scale -> conv2_2 (in-place)
I0824 23:08:38.817080 44210 layer_factory.hpp:77] Creating layer conv2_2_scale
I0824 23:08:38.817296 44210 net.cpp:150] Setting up conv2_2_scale
I0824 23:08:38.817304 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.817309 44210 net.cpp:165] Memory required for data: 2153779200
I0824 23:08:38.817317 44210 layer_factory.hpp:77] Creating layer relu2_2
I0824 23:08:38.817327 44210 net.cpp:100] Creating Layer relu2_2
I0824 23:08:38.817332 44210 net.cpp:434] relu2_2 <- conv2_2
I0824 23:08:38.817337 44210 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0824 23:08:38.817577 44210 net.cpp:150] Setting up relu2_2
I0824 23:08:38.817589 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:38.817596 44210 net.cpp:165] Memory required for data: 2242252800
I0824 23:08:38.817600 44210 layer_factory.hpp:77] Creating layer pool2
I0824 23:08:38.817605 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:38.817611 44210 net.cpp:100] Creating Layer pool2
I0824 23:08:38.817616 44210 net.cpp:434] pool2 <- conv2_2
I0824 23:08:38.817622 44210 net.cpp:408] pool2 -> pool2
I0824 23:08:38.817631 44210 net.cpp:408] pool2 -> pool2_mask
I0824 23:08:38.817692 44210 net.cpp:150] Setting up pool2
I0824 23:08:38.817700 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.817706 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:38.817709 44210 net.cpp:165] Memory required for data: 2286489600
I0824 23:08:38.817713 44210 layer_factory.hpp:77] Creating layer conv3_1
I0824 23:08:38.817724 44210 net.cpp:100] Creating Layer conv3_1
I0824 23:08:38.817729 44210 net.cpp:434] conv3_1 <- pool2
I0824 23:08:38.817739 44210 net.cpp:408] conv3_1 -> conv3_1
I0824 23:08:38.830238 44210 net.cpp:150] Setting up conv3_1
I0824 23:08:38.830255 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.830265 44210 net.cpp:165] Memory required for data: 2330726400
I0824 23:08:38.830273 44210 layer_factory.hpp:77] Creating layer conv3_1_bn_tmp
I0824 23:08:38.830284 44210 net.cpp:100] Creating Layer conv3_1_bn_tmp
I0824 23:08:38.830291 44210 net.cpp:434] conv3_1_bn_tmp <- conv3_1
I0824 23:08:38.830299 44210 net.cpp:395] conv3_1_bn_tmp -> conv3_1 (in-place)
I0824 23:08:38.830582 44210 net.cpp:150] Setting up conv3_1_bn_tmp
I0824 23:08:38.830591 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.830595 44210 net.cpp:165] Memory required for data: 2374963200
I0824 23:08:38.830611 44210 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 23:08:38.830634 44210 net.cpp:100] Creating Layer conv3_1_scale
I0824 23:08:38.830642 44210 net.cpp:434] conv3_1_scale <- conv3_1
I0824 23:08:38.830647 44210 net.cpp:395] conv3_1_scale -> conv3_1 (in-place)
I0824 23:08:38.830709 44210 layer_factory.hpp:77] Creating layer conv3_1_scale
I0824 23:08:38.830891 44210 net.cpp:150] Setting up conv3_1_scale
I0824 23:08:38.830900 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.830905 44210 net.cpp:165] Memory required for data: 2419200000
I0824 23:08:38.830912 44210 layer_factory.hpp:77] Creating layer relu3_1
I0824 23:08:38.830919 44210 net.cpp:100] Creating Layer relu3_1
I0824 23:08:38.830924 44210 net.cpp:434] relu3_1 <- conv3_1
I0824 23:08:38.830931 44210 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0824 23:08:38.831163 44210 net.cpp:150] Setting up relu3_1
I0824 23:08:38.831173 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.831178 44210 net.cpp:165] Memory required for data: 2463436800
I0824 23:08:38.831182 44210 layer_factory.hpp:77] Creating layer conv3_2
I0824 23:08:38.831194 44210 net.cpp:100] Creating Layer conv3_2
I0824 23:08:38.831200 44210 net.cpp:434] conv3_2 <- conv3_1
I0824 23:08:38.831209 44210 net.cpp:408] conv3_2 -> conv3_2
I0824 23:08:38.854835 44210 net.cpp:150] Setting up conv3_2
I0824 23:08:38.854853 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.854863 44210 net.cpp:165] Memory required for data: 2507673600
I0824 23:08:38.854872 44210 layer_factory.hpp:77] Creating layer conv3_2_bn_tmp
I0824 23:08:38.854883 44210 net.cpp:100] Creating Layer conv3_2_bn_tmp
I0824 23:08:38.854889 44210 net.cpp:434] conv3_2_bn_tmp <- conv3_2
I0824 23:08:38.854897 44210 net.cpp:395] conv3_2_bn_tmp -> conv3_2 (in-place)
I0824 23:08:38.855186 44210 net.cpp:150] Setting up conv3_2_bn_tmp
I0824 23:08:38.855195 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.855199 44210 net.cpp:165] Memory required for data: 2551910400
I0824 23:08:38.855211 44210 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 23:08:38.855219 44210 net.cpp:100] Creating Layer conv3_2_scale
I0824 23:08:38.855224 44210 net.cpp:434] conv3_2_scale <- conv3_2
I0824 23:08:38.855229 44210 net.cpp:395] conv3_2_scale -> conv3_2 (in-place)
I0824 23:08:38.855284 44210 layer_factory.hpp:77] Creating layer conv3_2_scale
I0824 23:08:38.855468 44210 net.cpp:150] Setting up conv3_2_scale
I0824 23:08:38.855476 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.855480 44210 net.cpp:165] Memory required for data: 2596147200
I0824 23:08:38.855487 44210 layer_factory.hpp:77] Creating layer relu3_2
I0824 23:08:38.855496 44210 net.cpp:100] Creating Layer relu3_2
I0824 23:08:38.855501 44210 net.cpp:434] relu3_2 <- conv3_2
I0824 23:08:38.855506 44210 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0824 23:08:38.855733 44210 net.cpp:150] Setting up relu3_2
I0824 23:08:38.855744 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.855748 44210 net.cpp:165] Memory required for data: 2640384000
I0824 23:08:38.855753 44210 layer_factory.hpp:77] Creating layer conv3_3
I0824 23:08:38.855767 44210 net.cpp:100] Creating Layer conv3_3
I0824 23:08:38.855772 44210 net.cpp:434] conv3_3 <- conv3_2
I0824 23:08:38.855779 44210 net.cpp:408] conv3_3 -> conv3_3
I0824 23:08:38.879400 44210 net.cpp:150] Setting up conv3_3
I0824 23:08:38.879417 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.879426 44210 net.cpp:165] Memory required for data: 2684620800
I0824 23:08:38.879436 44210 layer_factory.hpp:77] Creating layer conv3_3_bn_tmp
I0824 23:08:38.879446 44210 net.cpp:100] Creating Layer conv3_3_bn_tmp
I0824 23:08:38.879454 44210 net.cpp:434] conv3_3_bn_tmp <- conv3_3
I0824 23:08:38.879461 44210 net.cpp:395] conv3_3_bn_tmp -> conv3_3 (in-place)
I0824 23:08:38.879747 44210 net.cpp:150] Setting up conv3_3_bn_tmp
I0824 23:08:38.879757 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.879761 44210 net.cpp:165] Memory required for data: 2728857600
I0824 23:08:38.879776 44210 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 23:08:38.879797 44210 net.cpp:100] Creating Layer conv3_3_scale
I0824 23:08:38.879803 44210 net.cpp:434] conv3_3_scale <- conv3_3
I0824 23:08:38.879811 44210 net.cpp:395] conv3_3_scale -> conv3_3 (in-place)
I0824 23:08:38.879866 44210 layer_factory.hpp:77] Creating layer conv3_3_scale
I0824 23:08:38.880048 44210 net.cpp:150] Setting up conv3_3_scale
I0824 23:08:38.880058 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.880061 44210 net.cpp:165] Memory required for data: 2773094400
I0824 23:08:38.880069 44210 layer_factory.hpp:77] Creating layer relu3_3
I0824 23:08:38.880076 44210 net.cpp:100] Creating Layer relu3_3
I0824 23:08:38.880081 44210 net.cpp:434] relu3_3 <- conv3_3
I0824 23:08:38.880086 44210 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0824 23:08:38.880317 44210 net.cpp:150] Setting up relu3_3
I0824 23:08:38.880328 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:38.880332 44210 net.cpp:165] Memory required for data: 2817331200
I0824 23:08:38.880336 44210 layer_factory.hpp:77] Creating layer pool3
I0824 23:08:38.880340 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:38.880352 44210 net.cpp:100] Creating Layer pool3
I0824 23:08:38.880357 44210 net.cpp:434] pool3 <- conv3_3
I0824 23:08:38.880364 44210 net.cpp:408] pool3 -> pool3
I0824 23:08:38.880373 44210 net.cpp:408] pool3 -> pool3_mask
I0824 23:08:38.880434 44210 net.cpp:150] Setting up pool3
I0824 23:08:38.880442 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.880448 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:38.880452 44210 net.cpp:165] Memory required for data: 2839449600
I0824 23:08:38.880456 44210 layer_factory.hpp:77] Creating layer conv4_1
I0824 23:08:38.880467 44210 net.cpp:100] Creating Layer conv4_1
I0824 23:08:38.880472 44210 net.cpp:434] conv4_1 <- pool3
I0824 23:08:38.880482 44210 net.cpp:408] conv4_1 -> conv4_1
I0824 23:08:38.924474 44210 net.cpp:150] Setting up conv4_1
I0824 23:08:38.924492 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.924502 44210 net.cpp:165] Memory required for data: 2861568000
I0824 23:08:38.924511 44210 layer_factory.hpp:77] Creating layer conv4_1_bn_tmp
I0824 23:08:38.924523 44210 net.cpp:100] Creating Layer conv4_1_bn_tmp
I0824 23:08:38.924530 44210 net.cpp:434] conv4_1_bn_tmp <- conv4_1
I0824 23:08:38.924535 44210 net.cpp:395] conv4_1_bn_tmp -> conv4_1 (in-place)
I0824 23:08:38.924814 44210 net.cpp:150] Setting up conv4_1_bn_tmp
I0824 23:08:38.924823 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.924827 44210 net.cpp:165] Memory required for data: 2883686400
I0824 23:08:38.924836 44210 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 23:08:38.924849 44210 net.cpp:100] Creating Layer conv4_1_scale
I0824 23:08:38.924855 44210 net.cpp:434] conv4_1_scale <- conv4_1
I0824 23:08:38.924860 44210 net.cpp:395] conv4_1_scale -> conv4_1 (in-place)
I0824 23:08:38.924912 44210 layer_factory.hpp:77] Creating layer conv4_1_scale
I0824 23:08:38.925079 44210 net.cpp:150] Setting up conv4_1_scale
I0824 23:08:38.925088 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.925091 44210 net.cpp:165] Memory required for data: 2905804800
I0824 23:08:38.925098 44210 layer_factory.hpp:77] Creating layer relu4_1
I0824 23:08:38.925107 44210 net.cpp:100] Creating Layer relu4_1
I0824 23:08:38.925112 44210 net.cpp:434] relu4_1 <- conv4_1
I0824 23:08:38.925122 44210 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0824 23:08:38.926270 44210 net.cpp:150] Setting up relu4_1
I0824 23:08:38.926286 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:38.926291 44210 net.cpp:165] Memory required for data: 2927923200
I0824 23:08:38.926295 44210 layer_factory.hpp:77] Creating layer conv4_2
I0824 23:08:38.926311 44210 net.cpp:100] Creating Layer conv4_2
I0824 23:08:38.926317 44210 net.cpp:434] conv4_2 <- conv4_1
I0824 23:08:38.926326 44210 net.cpp:408] conv4_2 -> conv4_2
I0824 23:08:39.009132 44210 net.cpp:150] Setting up conv4_2
I0824 23:08:39.009165 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.009169 44210 net.cpp:165] Memory required for data: 2950041600
I0824 23:08:39.009178 44210 layer_factory.hpp:77] Creating layer conv4_2_bn_tmp
I0824 23:08:39.009188 44210 net.cpp:100] Creating Layer conv4_2_bn_tmp
I0824 23:08:39.009196 44210 net.cpp:434] conv4_2_bn_tmp <- conv4_2
I0824 23:08:39.009202 44210 net.cpp:395] conv4_2_bn_tmp -> conv4_2 (in-place)
I0824 23:08:39.009488 44210 net.cpp:150] Setting up conv4_2_bn_tmp
I0824 23:08:39.009500 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.009510 44210 net.cpp:165] Memory required for data: 2972160000
I0824 23:08:39.009519 44210 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 23:08:39.009526 44210 net.cpp:100] Creating Layer conv4_2_scale
I0824 23:08:39.009536 44210 net.cpp:434] conv4_2_scale <- conv4_2
I0824 23:08:39.009541 44210 net.cpp:395] conv4_2_scale -> conv4_2 (in-place)
I0824 23:08:39.009596 44210 layer_factory.hpp:77] Creating layer conv4_2_scale
I0824 23:08:39.009763 44210 net.cpp:150] Setting up conv4_2_scale
I0824 23:08:39.009773 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.009776 44210 net.cpp:165] Memory required for data: 2994278400
I0824 23:08:39.009783 44210 layer_factory.hpp:77] Creating layer relu4_2
I0824 23:08:39.009793 44210 net.cpp:100] Creating Layer relu4_2
I0824 23:08:39.009798 44210 net.cpp:434] relu4_2 <- conv4_2
I0824 23:08:39.009802 44210 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0824 23:08:39.010972 44210 net.cpp:150] Setting up relu4_2
I0824 23:08:39.010987 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.010993 44210 net.cpp:165] Memory required for data: 3016396800
I0824 23:08:39.010996 44210 layer_factory.hpp:77] Creating layer conv4_3
I0824 23:08:39.011011 44210 net.cpp:100] Creating Layer conv4_3
I0824 23:08:39.011018 44210 net.cpp:434] conv4_3 <- conv4_2
I0824 23:08:39.011027 44210 net.cpp:408] conv4_3 -> conv4_3
I0824 23:08:39.094899 44210 net.cpp:150] Setting up conv4_3
I0824 23:08:39.094918 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.094929 44210 net.cpp:165] Memory required for data: 3038515200
I0824 23:08:39.094954 44210 layer_factory.hpp:77] Creating layer conv4_3_bn_tmp
I0824 23:08:39.094965 44210 net.cpp:100] Creating Layer conv4_3_bn_tmp
I0824 23:08:39.094972 44210 net.cpp:434] conv4_3_bn_tmp <- conv4_3
I0824 23:08:39.094980 44210 net.cpp:395] conv4_3_bn_tmp -> conv4_3 (in-place)
I0824 23:08:39.095254 44210 net.cpp:150] Setting up conv4_3_bn_tmp
I0824 23:08:39.095263 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.095268 44210 net.cpp:165] Memory required for data: 3060633600
I0824 23:08:39.095275 44210 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 23:08:39.095284 44210 net.cpp:100] Creating Layer conv4_3_scale
I0824 23:08:39.095289 44210 net.cpp:434] conv4_3_scale <- conv4_3
I0824 23:08:39.095299 44210 net.cpp:395] conv4_3_scale -> conv4_3 (in-place)
I0824 23:08:39.095351 44210 layer_factory.hpp:77] Creating layer conv4_3_scale
I0824 23:08:39.095516 44210 net.cpp:150] Setting up conv4_3_scale
I0824 23:08:39.095525 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.095530 44210 net.cpp:165] Memory required for data: 3082752000
I0824 23:08:39.095538 44210 layer_factory.hpp:77] Creating layer relu4_3
I0824 23:08:39.095546 44210 net.cpp:100] Creating Layer relu4_3
I0824 23:08:39.095551 44210 net.cpp:434] relu4_3 <- conv4_3
I0824 23:08:39.095556 44210 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0824 23:08:39.095782 44210 net.cpp:150] Setting up relu4_3
I0824 23:08:39.095793 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.095798 44210 net.cpp:165] Memory required for data: 3104870400
I0824 23:08:39.095801 44210 layer_factory.hpp:77] Creating layer pool4
I0824 23:08:39.095806 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:39.095813 44210 net.cpp:100] Creating Layer pool4
I0824 23:08:39.095818 44210 net.cpp:434] pool4 <- conv4_3
I0824 23:08:39.095841 44210 net.cpp:408] pool4 -> pool4
I0824 23:08:39.095850 44210 net.cpp:408] pool4 -> pool4_mask
I0824 23:08:39.095911 44210 net.cpp:150] Setting up pool4
I0824 23:08:39.095918 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.095926 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.095928 44210 net.cpp:165] Memory required for data: 3116175360
I0824 23:08:39.095932 44210 layer_factory.hpp:77] Creating layer conv5_1
I0824 23:08:39.095945 44210 net.cpp:100] Creating Layer conv5_1
I0824 23:08:39.095950 44210 net.cpp:434] conv5_1 <- pool4
I0824 23:08:39.095957 44210 net.cpp:408] conv5_1 -> conv5_1
I0824 23:08:39.180421 44210 net.cpp:150] Setting up conv5_1
I0824 23:08:39.180449 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.180455 44210 net.cpp:165] Memory required for data: 3121827840
I0824 23:08:39.180469 44210 layer_factory.hpp:77] Creating layer conv5_1_bn_tmp
I0824 23:08:39.180480 44210 net.cpp:100] Creating Layer conv5_1_bn_tmp
I0824 23:08:39.180490 44210 net.cpp:434] conv5_1_bn_tmp <- conv5_1
I0824 23:08:39.180505 44210 net.cpp:395] conv5_1_bn_tmp -> conv5_1 (in-place)
I0824 23:08:39.180794 44210 net.cpp:150] Setting up conv5_1_bn_tmp
I0824 23:08:39.180804 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.180807 44210 net.cpp:165] Memory required for data: 3127480320
I0824 23:08:39.180816 44210 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 23:08:39.180824 44210 net.cpp:100] Creating Layer conv5_1_scale
I0824 23:08:39.180830 44210 net.cpp:434] conv5_1_scale <- conv5_1
I0824 23:08:39.180835 44210 net.cpp:395] conv5_1_scale -> conv5_1 (in-place)
I0824 23:08:39.180896 44210 layer_factory.hpp:77] Creating layer conv5_1_scale
I0824 23:08:39.181052 44210 net.cpp:150] Setting up conv5_1_scale
I0824 23:08:39.181061 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.181066 44210 net.cpp:165] Memory required for data: 3133132800
I0824 23:08:39.181072 44210 layer_factory.hpp:77] Creating layer relu5_1
I0824 23:08:39.181080 44210 net.cpp:100] Creating Layer relu5_1
I0824 23:08:39.181085 44210 net.cpp:434] relu5_1 <- conv5_1
I0824 23:08:39.181093 44210 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0824 23:08:39.181318 44210 net.cpp:150] Setting up relu5_1
I0824 23:08:39.181329 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.181332 44210 net.cpp:165] Memory required for data: 3138785280
I0824 23:08:39.181336 44210 layer_factory.hpp:77] Creating layer conv5_2
I0824 23:08:39.181349 44210 net.cpp:100] Creating Layer conv5_2
I0824 23:08:39.181354 44210 net.cpp:434] conv5_2 <- conv5_1
I0824 23:08:39.181362 44210 net.cpp:408] conv5_2 -> conv5_2
I0824 23:08:39.265224 44210 net.cpp:150] Setting up conv5_2
I0824 23:08:39.265244 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.265247 44210 net.cpp:165] Memory required for data: 3144437760
I0824 23:08:39.265255 44210 layer_factory.hpp:77] Creating layer conv5_2_bn_tmp
I0824 23:08:39.265265 44210 net.cpp:100] Creating Layer conv5_2_bn_tmp
I0824 23:08:39.265277 44210 net.cpp:434] conv5_2_bn_tmp <- conv5_2
I0824 23:08:39.265285 44210 net.cpp:395] conv5_2_bn_tmp -> conv5_2 (in-place)
I0824 23:08:39.265568 44210 net.cpp:150] Setting up conv5_2_bn_tmp
I0824 23:08:39.265578 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.265583 44210 net.cpp:165] Memory required for data: 3150090240
I0824 23:08:39.265591 44210 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 23:08:39.265604 44210 net.cpp:100] Creating Layer conv5_2_scale
I0824 23:08:39.265614 44210 net.cpp:434] conv5_2_scale <- conv5_2
I0824 23:08:39.265622 44210 net.cpp:395] conv5_2_scale -> conv5_2 (in-place)
I0824 23:08:39.265679 44210 layer_factory.hpp:77] Creating layer conv5_2_scale
I0824 23:08:39.265835 44210 net.cpp:150] Setting up conv5_2_scale
I0824 23:08:39.265846 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.265851 44210 net.cpp:165] Memory required for data: 3155742720
I0824 23:08:39.265857 44210 layer_factory.hpp:77] Creating layer relu5_2
I0824 23:08:39.265880 44210 net.cpp:100] Creating Layer relu5_2
I0824 23:08:39.265885 44210 net.cpp:434] relu5_2 <- conv5_2
I0824 23:08:39.265890 44210 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0824 23:08:39.266116 44210 net.cpp:150] Setting up relu5_2
I0824 23:08:39.266129 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.266134 44210 net.cpp:165] Memory required for data: 3161395200
I0824 23:08:39.266137 44210 layer_factory.hpp:77] Creating layer conv5_3
I0824 23:08:39.266152 44210 net.cpp:100] Creating Layer conv5_3
I0824 23:08:39.266158 44210 net.cpp:434] conv5_3 <- conv5_2
I0824 23:08:39.266165 44210 net.cpp:408] conv5_3 -> conv5_3
I0824 23:08:39.349966 44210 net.cpp:150] Setting up conv5_3
I0824 23:08:39.349983 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.349988 44210 net.cpp:165] Memory required for data: 3167047680
I0824 23:08:39.349997 44210 layer_factory.hpp:77] Creating layer conv5_3_bn_tmp
I0824 23:08:39.350006 44210 net.cpp:100] Creating Layer conv5_3_bn_tmp
I0824 23:08:39.350016 44210 net.cpp:434] conv5_3_bn_tmp <- conv5_3
I0824 23:08:39.350024 44210 net.cpp:395] conv5_3_bn_tmp -> conv5_3 (in-place)
I0824 23:08:39.350296 44210 net.cpp:150] Setting up conv5_3_bn_tmp
I0824 23:08:39.350306 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.350309 44210 net.cpp:165] Memory required for data: 3172700160
I0824 23:08:39.350319 44210 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 23:08:39.350329 44210 net.cpp:100] Creating Layer conv5_3_scale
I0824 23:08:39.350335 44210 net.cpp:434] conv5_3_scale <- conv5_3
I0824 23:08:39.350342 44210 net.cpp:395] conv5_3_scale -> conv5_3 (in-place)
I0824 23:08:39.350404 44210 layer_factory.hpp:77] Creating layer conv5_3_scale
I0824 23:08:39.350563 44210 net.cpp:150] Setting up conv5_3_scale
I0824 23:08:39.350570 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.350574 44210 net.cpp:165] Memory required for data: 3178352640
I0824 23:08:39.350581 44210 layer_factory.hpp:77] Creating layer relu5_3
I0824 23:08:39.350589 44210 net.cpp:100] Creating Layer relu5_3
I0824 23:08:39.350594 44210 net.cpp:434] relu5_3 <- conv5_3
I0824 23:08:39.350599 44210 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0824 23:08:39.350826 44210 net.cpp:150] Setting up relu5_3
I0824 23:08:39.350836 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.350841 44210 net.cpp:165] Memory required for data: 3184005120
I0824 23:08:39.350845 44210 layer_factory.hpp:77] Creating layer pool5
I0824 23:08:39.350850 44210 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0824 23:08:39.350858 44210 net.cpp:100] Creating Layer pool5
I0824 23:08:39.350863 44210 net.cpp:434] pool5 <- conv5_3
I0824 23:08:39.350874 44210 net.cpp:408] pool5 -> pool5
I0824 23:08:39.350883 44210 net.cpp:408] pool5 -> pool5_mask
I0824 23:08:39.350945 44210 net.cpp:150] Setting up pool5
I0824 23:08:39.350953 44210 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 23:08:39.350958 44210 net.cpp:157] Top shape: 4 512 12 15 (368640)
I0824 23:08:39.350962 44210 net.cpp:165] Memory required for data: 3186954240
I0824 23:08:39.350966 44210 layer_factory.hpp:77] Creating layer upsample5
I0824 23:08:39.350975 44210 net.cpp:100] Creating Layer upsample5
I0824 23:08:39.350980 44210 net.cpp:434] upsample5 <- pool5
I0824 23:08:39.350986 44210 net.cpp:434] upsample5 <- pool5_mask
I0824 23:08:39.350994 44210 net.cpp:408] upsample5 -> pool5_D
I0824 23:08:39.351028 44210 net.cpp:150] Setting up upsample5
I0824 23:08:39.351035 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.351038 44210 net.cpp:165] Memory required for data: 3192606720
I0824 23:08:39.351042 44210 layer_factory.hpp:77] Creating layer conv5_3_D
I0824 23:08:39.351056 44210 net.cpp:100] Creating Layer conv5_3_D
I0824 23:08:39.351061 44210 net.cpp:434] conv5_3_D <- pool5_D
I0824 23:08:39.351068 44210 net.cpp:408] conv5_3_D -> conv5_3_D
I0824 23:08:39.434933 44210 net.cpp:150] Setting up conv5_3_D
I0824 23:08:39.434953 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.434976 44210 net.cpp:165] Memory required for data: 3198259200
I0824 23:08:39.434985 44210 layer_factory.hpp:77] Creating layer conv5_3_D_bn_tmp
I0824 23:08:39.434994 44210 net.cpp:100] Creating Layer conv5_3_D_bn_tmp
I0824 23:08:39.435003 44210 net.cpp:434] conv5_3_D_bn_tmp <- conv5_3_D
I0824 23:08:39.435009 44210 net.cpp:395] conv5_3_D_bn_tmp -> conv5_3_D (in-place)
I0824 23:08:39.435297 44210 net.cpp:150] Setting up conv5_3_D_bn_tmp
I0824 23:08:39.435305 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.435314 44210 net.cpp:165] Memory required for data: 3203911680
I0824 23:08:39.435323 44210 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 23:08:39.435331 44210 net.cpp:100] Creating Layer conv5_3_D_scale
I0824 23:08:39.435336 44210 net.cpp:434] conv5_3_D_scale <- conv5_3_D
I0824 23:08:39.435341 44210 net.cpp:395] conv5_3_D_scale -> conv5_3_D (in-place)
I0824 23:08:39.435405 44210 layer_factory.hpp:77] Creating layer conv5_3_D_scale
I0824 23:08:39.435566 44210 net.cpp:150] Setting up conv5_3_D_scale
I0824 23:08:39.435575 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.435578 44210 net.cpp:165] Memory required for data: 3209564160
I0824 23:08:39.435585 44210 layer_factory.hpp:77] Creating layer relu5_3_D
I0824 23:08:39.435593 44210 net.cpp:100] Creating Layer relu5_3_D
I0824 23:08:39.435598 44210 net.cpp:434] relu5_3_D <- conv5_3_D
I0824 23:08:39.435606 44210 net.cpp:395] relu5_3_D -> conv5_3_D (in-place)
I0824 23:08:39.436759 44210 net.cpp:150] Setting up relu5_3_D
I0824 23:08:39.436775 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.436780 44210 net.cpp:165] Memory required for data: 3215216640
I0824 23:08:39.436784 44210 layer_factory.hpp:77] Creating layer conv5_2_D
I0824 23:08:39.436823 44210 net.cpp:100] Creating Layer conv5_2_D
I0824 23:08:39.436830 44210 net.cpp:434] conv5_2_D <- conv5_3_D
I0824 23:08:39.436838 44210 net.cpp:408] conv5_2_D -> conv5_2_D
I0824 23:08:39.520823 44210 net.cpp:150] Setting up conv5_2_D
I0824 23:08:39.520841 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.520845 44210 net.cpp:165] Memory required for data: 3220869120
I0824 23:08:39.520854 44210 layer_factory.hpp:77] Creating layer conv5_2_D_bn_tmp
I0824 23:08:39.520869 44210 net.cpp:100] Creating Layer conv5_2_D_bn_tmp
I0824 23:08:39.520876 44210 net.cpp:434] conv5_2_D_bn_tmp <- conv5_2_D
I0824 23:08:39.520884 44210 net.cpp:395] conv5_2_D_bn_tmp -> conv5_2_D (in-place)
I0824 23:08:39.521173 44210 net.cpp:150] Setting up conv5_2_D_bn_tmp
I0824 23:08:39.521183 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.521186 44210 net.cpp:165] Memory required for data: 3226521600
I0824 23:08:39.521199 44210 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 23:08:39.521210 44210 net.cpp:100] Creating Layer conv5_2_D_scale
I0824 23:08:39.521215 44210 net.cpp:434] conv5_2_D_scale <- conv5_2_D
I0824 23:08:39.521220 44210 net.cpp:395] conv5_2_D_scale -> conv5_2_D (in-place)
I0824 23:08:39.521282 44210 layer_factory.hpp:77] Creating layer conv5_2_D_scale
I0824 23:08:39.521468 44210 net.cpp:150] Setting up conv5_2_D_scale
I0824 23:08:39.521479 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.521482 44210 net.cpp:165] Memory required for data: 3232174080
I0824 23:08:39.521491 44210 layer_factory.hpp:77] Creating layer relu5_2_D
I0824 23:08:39.521498 44210 net.cpp:100] Creating Layer relu5_2_D
I0824 23:08:39.521503 44210 net.cpp:434] relu5_2_D <- conv5_2_D
I0824 23:08:39.521510 44210 net.cpp:395] relu5_2_D -> conv5_2_D (in-place)
I0824 23:08:39.522708 44210 net.cpp:150] Setting up relu5_2_D
I0824 23:08:39.522723 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.522729 44210 net.cpp:165] Memory required for data: 3237826560
I0824 23:08:39.522733 44210 layer_factory.hpp:77] Creating layer conv5_1_D
I0824 23:08:39.522748 44210 net.cpp:100] Creating Layer conv5_1_D
I0824 23:08:39.522754 44210 net.cpp:434] conv5_1_D <- conv5_2_D
I0824 23:08:39.522764 44210 net.cpp:408] conv5_1_D -> conv5_1_D
I0824 23:08:39.607126 44210 net.cpp:150] Setting up conv5_1_D
I0824 23:08:39.607162 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.607167 44210 net.cpp:165] Memory required for data: 3243479040
I0824 23:08:39.607177 44210 layer_factory.hpp:77] Creating layer conv5_1_D_bn_tmp
I0824 23:08:39.607193 44210 net.cpp:100] Creating Layer conv5_1_D_bn_tmp
I0824 23:08:39.607208 44210 net.cpp:434] conv5_1_D_bn_tmp <- conv5_1_D
I0824 23:08:39.607221 44210 net.cpp:395] conv5_1_D_bn_tmp -> conv5_1_D (in-place)
I0824 23:08:39.607512 44210 net.cpp:150] Setting up conv5_1_D_bn_tmp
I0824 23:08:39.607522 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.607524 44210 net.cpp:165] Memory required for data: 3249131520
I0824 23:08:39.607533 44210 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 23:08:39.607543 44210 net.cpp:100] Creating Layer conv5_1_D_scale
I0824 23:08:39.607550 44210 net.cpp:434] conv5_1_D_scale <- conv5_1_D
I0824 23:08:39.607556 44210 net.cpp:395] conv5_1_D_scale -> conv5_1_D (in-place)
I0824 23:08:39.607620 44210 layer_factory.hpp:77] Creating layer conv5_1_D_scale
I0824 23:08:39.607780 44210 net.cpp:150] Setting up conv5_1_D_scale
I0824 23:08:39.607789 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.607791 44210 net.cpp:165] Memory required for data: 3254784000
I0824 23:08:39.607798 44210 layer_factory.hpp:77] Creating layer relu5_1_D
I0824 23:08:39.607810 44210 net.cpp:100] Creating Layer relu5_1_D
I0824 23:08:39.607815 44210 net.cpp:434] relu5_1_D <- conv5_1_D
I0824 23:08:39.607820 44210 net.cpp:395] relu5_1_D -> conv5_1_D (in-place)
I0824 23:08:39.608047 44210 net.cpp:150] Setting up relu5_1_D
I0824 23:08:39.608057 44210 net.cpp:157] Top shape: 4 512 23 30 (1413120)
I0824 23:08:39.608060 44210 net.cpp:165] Memory required for data: 3260436480
I0824 23:08:39.608064 44210 layer_factory.hpp:77] Creating layer upsample4
I0824 23:08:39.608073 44210 net.cpp:100] Creating Layer upsample4
I0824 23:08:39.608078 44210 net.cpp:434] upsample4 <- conv5_1_D
I0824 23:08:39.608084 44210 net.cpp:434] upsample4 <- pool4_mask
I0824 23:08:39.608093 44210 net.cpp:408] upsample4 -> pool4_D
I0824 23:08:39.608134 44210 net.cpp:150] Setting up upsample4
I0824 23:08:39.608140 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.608144 44210 net.cpp:165] Memory required for data: 3282554880
I0824 23:08:39.608147 44210 layer_factory.hpp:77] Creating layer conv4_3_D
I0824 23:08:39.608163 44210 net.cpp:100] Creating Layer conv4_3_D
I0824 23:08:39.608170 44210 net.cpp:434] conv4_3_D <- pool4_D
I0824 23:08:39.608176 44210 net.cpp:408] conv4_3_D -> conv4_3_D
I0824 23:08:39.692481 44210 net.cpp:150] Setting up conv4_3_D
I0824 23:08:39.692500 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.692504 44210 net.cpp:165] Memory required for data: 3304673280
I0824 23:08:39.692512 44210 layer_factory.hpp:77] Creating layer conv4_3_D_bn_tmp
I0824 23:08:39.692523 44210 net.cpp:100] Creating Layer conv4_3_D_bn_tmp
I0824 23:08:39.692530 44210 net.cpp:434] conv4_3_D_bn_tmp <- conv4_3_D
I0824 23:08:39.692538 44210 net.cpp:395] conv4_3_D_bn_tmp -> conv4_3_D (in-place)
I0824 23:08:39.692824 44210 net.cpp:150] Setting up conv4_3_D_bn_tmp
I0824 23:08:39.692833 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.692836 44210 net.cpp:165] Memory required for data: 3326791680
I0824 23:08:39.692845 44210 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 23:08:39.692857 44210 net.cpp:100] Creating Layer conv4_3_D_scale
I0824 23:08:39.692867 44210 net.cpp:434] conv4_3_D_scale <- conv4_3_D
I0824 23:08:39.692874 44210 net.cpp:395] conv4_3_D_scale -> conv4_3_D (in-place)
I0824 23:08:39.692929 44210 layer_factory.hpp:77] Creating layer conv4_3_D_scale
I0824 23:08:39.693104 44210 net.cpp:150] Setting up conv4_3_D_scale
I0824 23:08:39.693111 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.693114 44210 net.cpp:165] Memory required for data: 3348910080
I0824 23:08:39.693121 44210 layer_factory.hpp:77] Creating layer relu4_3_D
I0824 23:08:39.693147 44210 net.cpp:100] Creating Layer relu4_3_D
I0824 23:08:39.693153 44210 net.cpp:434] relu4_3_D <- conv4_3_D
I0824 23:08:39.693158 44210 net.cpp:395] relu4_3_D -> conv4_3_D (in-place)
I0824 23:08:39.693408 44210 net.cpp:150] Setting up relu4_3_D
I0824 23:08:39.693418 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.693423 44210 net.cpp:165] Memory required for data: 3371028480
I0824 23:08:39.693426 44210 layer_factory.hpp:77] Creating layer conv4_2_D
I0824 23:08:39.693439 44210 net.cpp:100] Creating Layer conv4_2_D
I0824 23:08:39.693444 44210 net.cpp:434] conv4_2_D <- conv4_3_D
I0824 23:08:39.693454 44210 net.cpp:408] conv4_2_D -> conv4_2_D
I0824 23:08:39.777825 44210 net.cpp:150] Setting up conv4_2_D
I0824 23:08:39.777842 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.777848 44210 net.cpp:165] Memory required for data: 3393146880
I0824 23:08:39.777854 44210 layer_factory.hpp:77] Creating layer conv4_2_D_bn_tmp
I0824 23:08:39.777871 44210 net.cpp:100] Creating Layer conv4_2_D_bn_tmp
I0824 23:08:39.777878 44210 net.cpp:434] conv4_2_D_bn_tmp <- conv4_2_D
I0824 23:08:39.777886 44210 net.cpp:395] conv4_2_D_bn_tmp -> conv4_2_D (in-place)
I0824 23:08:39.778175 44210 net.cpp:150] Setting up conv4_2_D_bn_tmp
I0824 23:08:39.778184 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.778187 44210 net.cpp:165] Memory required for data: 3415265280
I0824 23:08:39.778197 44210 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 23:08:39.778211 44210 net.cpp:100] Creating Layer conv4_2_D_scale
I0824 23:08:39.778218 44210 net.cpp:434] conv4_2_D_scale <- conv4_2_D
I0824 23:08:39.778223 44210 net.cpp:395] conv4_2_D_scale -> conv4_2_D (in-place)
I0824 23:08:39.778275 44210 layer_factory.hpp:77] Creating layer conv4_2_D_scale
I0824 23:08:39.778448 44210 net.cpp:150] Setting up conv4_2_D_scale
I0824 23:08:39.778456 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.778460 44210 net.cpp:165] Memory required for data: 3437383680
I0824 23:08:39.778466 44210 layer_factory.hpp:77] Creating layer relu4_2_D
I0824 23:08:39.778475 44210 net.cpp:100] Creating Layer relu4_2_D
I0824 23:08:39.778481 44210 net.cpp:434] relu4_2_D <- conv4_2_D
I0824 23:08:39.778487 44210 net.cpp:395] relu4_2_D -> conv4_2_D (in-place)
I0824 23:08:39.778709 44210 net.cpp:150] Setting up relu4_2_D
I0824 23:08:39.778718 44210 net.cpp:157] Top shape: 4 512 45 60 (5529600)
I0824 23:08:39.778723 44210 net.cpp:165] Memory required for data: 3459502080
I0824 23:08:39.778725 44210 layer_factory.hpp:77] Creating layer conv4_1_D
I0824 23:08:39.778743 44210 net.cpp:100] Creating Layer conv4_1_D
I0824 23:08:39.778748 44210 net.cpp:434] conv4_1_D <- conv4_2_D
I0824 23:08:39.778758 44210 net.cpp:408] conv4_1_D -> conv4_1_D
I0824 23:08:39.823861 44210 net.cpp:150] Setting up conv4_1_D
I0824 23:08:39.823879 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:39.823884 44210 net.cpp:165] Memory required for data: 3470561280
I0824 23:08:39.823891 44210 layer_factory.hpp:77] Creating layer conv4_1_D_bn_tmp
I0824 23:08:39.823901 44210 net.cpp:100] Creating Layer conv4_1_D_bn_tmp
I0824 23:08:39.823909 44210 net.cpp:434] conv4_1_D_bn_tmp <- conv4_1_D
I0824 23:08:39.823918 44210 net.cpp:395] conv4_1_D_bn_tmp -> conv4_1_D (in-place)
I0824 23:08:39.824213 44210 net.cpp:150] Setting up conv4_1_D_bn_tmp
I0824 23:08:39.824221 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:39.824224 44210 net.cpp:165] Memory required for data: 3481620480
I0824 23:08:39.824385 44210 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 23:08:39.824398 44210 net.cpp:100] Creating Layer conv4_1_D_scale
I0824 23:08:39.824405 44210 net.cpp:434] conv4_1_D_scale <- conv4_1_D
I0824 23:08:39.824411 44210 net.cpp:395] conv4_1_D_scale -> conv4_1_D (in-place)
I0824 23:08:39.824475 44210 layer_factory.hpp:77] Creating layer conv4_1_D_scale
I0824 23:08:39.824648 44210 net.cpp:150] Setting up conv4_1_D_scale
I0824 23:08:39.824656 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:39.824676 44210 net.cpp:165] Memory required for data: 3492679680
I0824 23:08:39.824684 44210 layer_factory.hpp:77] Creating layer relu4_1_D
I0824 23:08:39.824690 44210 net.cpp:100] Creating Layer relu4_1_D
I0824 23:08:39.824697 44210 net.cpp:434] relu4_1_D <- conv4_1_D
I0824 23:08:39.824702 44210 net.cpp:395] relu4_1_D -> conv4_1_D (in-place)
I0824 23:08:39.824939 44210 net.cpp:150] Setting up relu4_1_D
I0824 23:08:39.824949 44210 net.cpp:157] Top shape: 4 256 45 60 (2764800)
I0824 23:08:39.824954 44210 net.cpp:165] Memory required for data: 3503738880
I0824 23:08:39.824957 44210 layer_factory.hpp:77] Creating layer upsample3
I0824 23:08:39.824968 44210 net.cpp:100] Creating Layer upsample3
I0824 23:08:39.824973 44210 net.cpp:434] upsample3 <- conv4_1_D
I0824 23:08:39.824978 44210 net.cpp:434] upsample3 <- pool3_mask
I0824 23:08:39.824985 44210 net.cpp:408] upsample3 -> pool3_D
I0824 23:08:39.824993 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:39.825033 44210 net.cpp:150] Setting up upsample3
I0824 23:08:39.825039 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.825043 44210 net.cpp:165] Memory required for data: 3547975680
I0824 23:08:39.825047 44210 layer_factory.hpp:77] Creating layer conv3_3_D
I0824 23:08:39.825058 44210 net.cpp:100] Creating Layer conv3_3_D
I0824 23:08:39.825064 44210 net.cpp:434] conv3_3_D <- pool3_D
I0824 23:08:39.825073 44210 net.cpp:408] conv3_3_D -> conv3_3_D
I0824 23:08:39.851440 44210 net.cpp:150] Setting up conv3_3_D
I0824 23:08:39.851459 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.851464 44210 net.cpp:165] Memory required for data: 3592212480
I0824 23:08:39.851474 44210 layer_factory.hpp:77] Creating layer conv3_3_D_bn_tmp
I0824 23:08:39.851490 44210 net.cpp:100] Creating Layer conv3_3_D_bn_tmp
I0824 23:08:39.851500 44210 net.cpp:434] conv3_3_D_bn_tmp <- conv3_3_D
I0824 23:08:39.851511 44210 net.cpp:395] conv3_3_D_bn_tmp -> conv3_3_D (in-place)
I0824 23:08:39.851824 44210 net.cpp:150] Setting up conv3_3_D_bn_tmp
I0824 23:08:39.851833 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.851837 44210 net.cpp:165] Memory required for data: 3636449280
I0824 23:08:39.851847 44210 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 23:08:39.851861 44210 net.cpp:100] Creating Layer conv3_3_D_scale
I0824 23:08:39.851866 44210 net.cpp:434] conv3_3_D_scale <- conv3_3_D
I0824 23:08:39.851871 44210 net.cpp:395] conv3_3_D_scale -> conv3_3_D (in-place)
I0824 23:08:39.851930 44210 layer_factory.hpp:77] Creating layer conv3_3_D_scale
I0824 23:08:39.852130 44210 net.cpp:150] Setting up conv3_3_D_scale
I0824 23:08:39.852138 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.852143 44210 net.cpp:165] Memory required for data: 3680686080
I0824 23:08:39.852149 44210 layer_factory.hpp:77] Creating layer relu3_3_D
I0824 23:08:39.852159 44210 net.cpp:100] Creating Layer relu3_3_D
I0824 23:08:39.852164 44210 net.cpp:434] relu3_3_D <- conv3_3_D
I0824 23:08:39.852169 44210 net.cpp:395] relu3_3_D -> conv3_3_D (in-place)
I0824 23:08:39.853348 44210 net.cpp:150] Setting up relu3_3_D
I0824 23:08:39.853363 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.853384 44210 net.cpp:165] Memory required for data: 3724922880
I0824 23:08:39.853389 44210 layer_factory.hpp:77] Creating layer conv3_2_D
I0824 23:08:39.853406 44210 net.cpp:100] Creating Layer conv3_2_D
I0824 23:08:39.853411 44210 net.cpp:434] conv3_2_D <- conv3_3_D
I0824 23:08:39.853421 44210 net.cpp:408] conv3_2_D -> conv3_2_D
I0824 23:08:39.876401 44210 net.cpp:150] Setting up conv3_2_D
I0824 23:08:39.876417 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.876427 44210 net.cpp:165] Memory required for data: 3769159680
I0824 23:08:39.876435 44210 layer_factory.hpp:77] Creating layer conv3_2_D_bn_tmp
I0824 23:08:39.876453 44210 net.cpp:100] Creating Layer conv3_2_D_bn_tmp
I0824 23:08:39.876461 44210 net.cpp:434] conv3_2_D_bn_tmp <- conv3_2_D
I0824 23:08:39.876482 44210 net.cpp:395] conv3_2_D_bn_tmp -> conv3_2_D (in-place)
I0824 23:08:39.876790 44210 net.cpp:150] Setting up conv3_2_D_bn_tmp
I0824 23:08:39.876797 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.876801 44210 net.cpp:165] Memory required for data: 3813396480
I0824 23:08:39.876809 44210 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 23:08:39.876821 44210 net.cpp:100] Creating Layer conv3_2_D_scale
I0824 23:08:39.876826 44210 net.cpp:434] conv3_2_D_scale <- conv3_2_D
I0824 23:08:39.876833 44210 net.cpp:395] conv3_2_D_scale -> conv3_2_D (in-place)
I0824 23:08:39.876888 44210 layer_factory.hpp:77] Creating layer conv3_2_D_scale
I0824 23:08:39.877082 44210 net.cpp:150] Setting up conv3_2_D_scale
I0824 23:08:39.877090 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.877094 44210 net.cpp:165] Memory required for data: 3857633280
I0824 23:08:39.877100 44210 layer_factory.hpp:77] Creating layer relu3_2_D
I0824 23:08:39.877110 44210 net.cpp:100] Creating Layer relu3_2_D
I0824 23:08:39.877115 44210 net.cpp:434] relu3_2_D <- conv3_2_D
I0824 23:08:39.877120 44210 net.cpp:395] relu3_2_D -> conv3_2_D (in-place)
I0824 23:08:39.878324 44210 net.cpp:150] Setting up relu3_2_D
I0824 23:08:39.878340 44210 net.cpp:157] Top shape: 4 256 90 120 (11059200)
I0824 23:08:39.878345 44210 net.cpp:165] Memory required for data: 3901870080
I0824 23:08:39.878350 44210 layer_factory.hpp:77] Creating layer conv3_1_D
I0824 23:08:39.878366 44210 net.cpp:100] Creating Layer conv3_1_D
I0824 23:08:39.878372 44210 net.cpp:434] conv3_1_D <- conv3_2_D
I0824 23:08:39.878381 44210 net.cpp:408] conv3_1_D -> conv3_1_D
I0824 23:08:39.892482 44210 net.cpp:150] Setting up conv3_1_D
I0824 23:08:39.892501 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:39.892509 44210 net.cpp:165] Memory required for data: 3923988480
I0824 23:08:39.892518 44210 layer_factory.hpp:77] Creating layer conv3_1_D_bn_tmp
I0824 23:08:39.892535 44210 net.cpp:100] Creating Layer conv3_1_D_bn_tmp
I0824 23:08:39.892540 44210 net.cpp:434] conv3_1_D_bn_tmp <- conv3_1_D
I0824 23:08:39.892547 44210 net.cpp:395] conv3_1_D_bn_tmp -> conv3_1_D (in-place)
I0824 23:08:39.892858 44210 net.cpp:150] Setting up conv3_1_D_bn_tmp
I0824 23:08:39.892866 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:39.892869 44210 net.cpp:165] Memory required for data: 3946106880
I0824 23:08:39.892879 44210 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 23:08:39.892891 44210 net.cpp:100] Creating Layer conv3_1_D_scale
I0824 23:08:39.892896 44210 net.cpp:434] conv3_1_D_scale <- conv3_1_D
I0824 23:08:39.892902 44210 net.cpp:395] conv3_1_D_scale -> conv3_1_D (in-place)
I0824 23:08:39.892961 44210 layer_factory.hpp:77] Creating layer conv3_1_D_scale
I0824 23:08:39.894583 44210 net.cpp:150] Setting up conv3_1_D_scale
I0824 23:08:39.894599 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:39.894604 44210 net.cpp:165] Memory required for data: 3968225280
I0824 23:08:39.894613 44210 layer_factory.hpp:77] Creating layer relu3_1_D
I0824 23:08:39.894623 44210 net.cpp:100] Creating Layer relu3_1_D
I0824 23:08:39.894628 44210 net.cpp:434] relu3_1_D <- conv3_1_D
I0824 23:08:39.894635 44210 net.cpp:395] relu3_1_D -> conv3_1_D (in-place)
I0824 23:08:39.894876 44210 net.cpp:150] Setting up relu3_1_D
I0824 23:08:39.894886 44210 net.cpp:157] Top shape: 4 128 90 120 (5529600)
I0824 23:08:39.894891 44210 net.cpp:165] Memory required for data: 3990343680
I0824 23:08:39.894894 44210 layer_factory.hpp:77] Creating layer upsample2
I0824 23:08:39.894903 44210 net.cpp:100] Creating Layer upsample2
I0824 23:08:39.894911 44210 net.cpp:434] upsample2 <- conv3_1_D
I0824 23:08:39.894917 44210 net.cpp:434] upsample2 <- pool2_mask
I0824 23:08:39.894924 44210 net.cpp:408] upsample2 -> pool2_D
I0824 23:08:39.894933 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:39.894973 44210 net.cpp:150] Setting up upsample2
I0824 23:08:39.894994 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:39.894999 44210 net.cpp:165] Memory required for data: 4078817280
I0824 23:08:39.895004 44210 layer_factory.hpp:77] Creating layer conv2_2_D
I0824 23:08:39.895020 44210 net.cpp:100] Creating Layer conv2_2_D
I0824 23:08:39.895025 44210 net.cpp:434] conv2_2_D <- pool2_D
I0824 23:08:39.895031 44210 net.cpp:408] conv2_2_D -> conv2_2_D
I0824 23:08:39.903007 44210 net.cpp:150] Setting up conv2_2_D
I0824 23:08:39.903026 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:39.903033 44210 net.cpp:165] Memory required for data: 4167290880
I0824 23:08:39.903041 44210 layer_factory.hpp:77] Creating layer conv2_2_D_bn_tmp
I0824 23:08:39.903051 44210 net.cpp:100] Creating Layer conv2_2_D_bn_tmp
I0824 23:08:39.903061 44210 net.cpp:434] conv2_2_D_bn_tmp <- conv2_2_D
I0824 23:08:39.903069 44210 net.cpp:395] conv2_2_D_bn_tmp -> conv2_2_D (in-place)
I0824 23:08:39.903419 44210 net.cpp:150] Setting up conv2_2_D_bn_tmp
I0824 23:08:39.903427 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:39.903430 44210 net.cpp:165] Memory required for data: 4255764480
I0824 23:08:39.903439 44210 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 23:08:39.903448 44210 net.cpp:100] Creating Layer conv2_2_D_scale
I0824 23:08:39.903456 44210 net.cpp:434] conv2_2_D_scale <- conv2_2_D
I0824 23:08:39.903462 44210 net.cpp:395] conv2_2_D_scale -> conv2_2_D (in-place)
I0824 23:08:39.903524 44210 layer_factory.hpp:77] Creating layer conv2_2_D_scale
I0824 23:08:39.903800 44210 net.cpp:150] Setting up conv2_2_D_scale
I0824 23:08:39.903810 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:39.903812 44210 net.cpp:165] Memory required for data: 4344238080
I0824 23:08:39.903820 44210 layer_factory.hpp:77] Creating layer relu2_2_D
I0824 23:08:39.903826 44210 net.cpp:100] Creating Layer relu2_2_D
I0824 23:08:39.903831 44210 net.cpp:434] relu2_2_D <- conv2_2_D
I0824 23:08:39.903838 44210 net.cpp:395] relu2_2_D -> conv2_2_D (in-place)
I0824 23:08:39.904078 44210 net.cpp:150] Setting up relu2_2_D
I0824 23:08:39.904088 44210 net.cpp:157] Top shape: 4 128 180 240 (22118400)
I0824 23:08:39.904093 44210 net.cpp:165] Memory required for data: 4432711680
I0824 23:08:39.904098 44210 layer_factory.hpp:77] Creating layer conv2_1_D
I0824 23:08:39.904111 44210 net.cpp:100] Creating Layer conv2_1_D
I0824 23:08:39.904116 44210 net.cpp:434] conv2_1_D <- conv2_2_D
I0824 23:08:39.904127 44210 net.cpp:408] conv2_1_D -> conv2_1_D
I0824 23:08:39.909689 44210 net.cpp:150] Setting up conv2_1_D
I0824 23:08:39.909705 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:39.909714 44210 net.cpp:165] Memory required for data: 4476948480
I0824 23:08:39.909723 44210 layer_factory.hpp:77] Creating layer conv2_1_D_bn_tmp
I0824 23:08:39.909734 44210 net.cpp:100] Creating Layer conv2_1_D_bn_tmp
I0824 23:08:39.909740 44210 net.cpp:434] conv2_1_D_bn_tmp <- conv2_1_D
I0824 23:08:39.909749 44210 net.cpp:395] conv2_1_D_bn_tmp -> conv2_1_D (in-place)
I0824 23:08:39.910109 44210 net.cpp:150] Setting up conv2_1_D_bn_tmp
I0824 23:08:39.910118 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:39.910122 44210 net.cpp:165] Memory required for data: 4521185280
I0824 23:08:39.910130 44210 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 23:08:39.910142 44210 net.cpp:100] Creating Layer conv2_1_D_scale
I0824 23:08:39.910147 44210 net.cpp:434] conv2_1_D_scale <- conv2_1_D
I0824 23:08:39.910153 44210 net.cpp:395] conv2_1_D_scale -> conv2_1_D (in-place)
I0824 23:08:39.910213 44210 layer_factory.hpp:77] Creating layer conv2_1_D_scale
I0824 23:08:39.910498 44210 net.cpp:150] Setting up conv2_1_D_scale
I0824 23:08:39.910507 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:39.910511 44210 net.cpp:165] Memory required for data: 4565422080
I0824 23:08:39.910517 44210 layer_factory.hpp:77] Creating layer relu2_1_D
I0824 23:08:39.910524 44210 net.cpp:100] Creating Layer relu2_1_D
I0824 23:08:39.910529 44210 net.cpp:434] relu2_1_D <- conv2_1_D
I0824 23:08:39.910552 44210 net.cpp:395] relu2_1_D -> conv2_1_D (in-place)
I0824 23:08:39.910786 44210 net.cpp:150] Setting up relu2_1_D
I0824 23:08:39.910796 44210 net.cpp:157] Top shape: 4 64 180 240 (11059200)
I0824 23:08:39.910801 44210 net.cpp:165] Memory required for data: 4609658880
I0824 23:08:39.910805 44210 layer_factory.hpp:77] Creating layer upsample1
I0824 23:08:39.910815 44210 net.cpp:100] Creating Layer upsample1
I0824 23:08:39.910820 44210 net.cpp:434] upsample1 <- conv2_1_D
I0824 23:08:39.910825 44210 net.cpp:434] upsample1 <- pool1_mask
I0824 23:08:39.910832 44210 net.cpp:408] upsample1 -> pool1_D
I0824 23:08:39.910841 44210 upsample_layer.cpp:27] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0824 23:08:39.910879 44210 net.cpp:150] Setting up upsample1
I0824 23:08:39.910887 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:39.910889 44210 net.cpp:165] Memory required for data: 4786606080
I0824 23:08:39.910893 44210 layer_factory.hpp:77] Creating layer conv1_2_D
I0824 23:08:39.910907 44210 net.cpp:100] Creating Layer conv1_2_D
I0824 23:08:39.910912 44210 net.cpp:434] conv1_2_D <- pool1_D
I0824 23:08:39.910918 44210 net.cpp:408] conv1_2_D -> conv1_2_D
I0824 23:08:39.915745 44210 net.cpp:150] Setting up conv1_2_D
I0824 23:08:39.915761 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:39.915771 44210 net.cpp:165] Memory required for data: 4963553280
I0824 23:08:39.915778 44210 layer_factory.hpp:77] Creating layer conv1_2_D_bn_tmp
I0824 23:08:39.915788 44210 net.cpp:100] Creating Layer conv1_2_D_bn_tmp
I0824 23:08:39.915794 44210 net.cpp:434] conv1_2_D_bn_tmp <- conv1_2_D
I0824 23:08:39.915801 44210 net.cpp:395] conv1_2_D_bn_tmp -> conv1_2_D (in-place)
I0824 23:08:39.916241 44210 net.cpp:150] Setting up conv1_2_D_bn_tmp
I0824 23:08:39.916250 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:39.916254 44210 net.cpp:165] Memory required for data: 5140500480
I0824 23:08:39.916262 44210 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 23:08:39.916272 44210 net.cpp:100] Creating Layer conv1_2_D_scale
I0824 23:08:39.916278 44210 net.cpp:434] conv1_2_D_scale <- conv1_2_D
I0824 23:08:39.916285 44210 net.cpp:395] conv1_2_D_scale -> conv1_2_D (in-place)
I0824 23:08:39.916344 44210 layer_factory.hpp:77] Creating layer conv1_2_D_scale
I0824 23:08:39.918238 44210 net.cpp:150] Setting up conv1_2_D_scale
I0824 23:08:39.918254 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:39.918259 44210 net.cpp:165] Memory required for data: 5317447680
I0824 23:08:39.918267 44210 layer_factory.hpp:77] Creating layer relu1_2_D
I0824 23:08:39.918278 44210 net.cpp:100] Creating Layer relu1_2_D
I0824 23:08:39.918283 44210 net.cpp:434] relu1_2_D <- conv1_2_D
I0824 23:08:39.918292 44210 net.cpp:395] relu1_2_D -> conv1_2_D (in-place)
I0824 23:08:39.918537 44210 net.cpp:150] Setting up relu1_2_D
I0824 23:08:39.918546 44210 net.cpp:157] Top shape: 4 64 360 480 (44236800)
I0824 23:08:39.918552 44210 net.cpp:165] Memory required for data: 5494394880
I0824 23:08:39.918556 44210 layer_factory.hpp:77] Creating layer conv1_1_1_D
I0824 23:08:39.918570 44210 net.cpp:100] Creating Layer conv1_1_1_D
I0824 23:08:39.918575 44210 net.cpp:434] conv1_1_1_D <- conv1_2_D
I0824 23:08:39.918583 44210 net.cpp:408] conv1_1_1_D -> conv1_1_1_D
I0824 23:08:39.920814 44210 net.cpp:150] Setting up conv1_1_1_D
I0824 23:08:39.920830 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:39.920835 44210 net.cpp:165] Memory required for data: 5499924480
I0824 23:08:39.920842 44210 layer_factory.hpp:77] Creating layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:39.920852 44210 net.cpp:100] Creating Layer conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:39.920861 44210 net.cpp:434] conv1_1_1_D_conv1_1_1_D_0_split <- conv1_1_1_D
I0824 23:08:39.920866 44210 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 23:08:39.920876 44210 net.cpp:408] conv1_1_1_D_conv1_1_1_D_0_split -> conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 23:08:39.920953 44210 net.cpp:150] Setting up conv1_1_1_D_conv1_1_1_D_0_split
I0824 23:08:39.920961 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:39.920965 44210 net.cpp:157] Top shape: 4 2 360 480 (1382400)
I0824 23:08:39.920970 44210 net.cpp:165] Memory required for data: 5510983680
I0824 23:08:39.920974 44210 layer_factory.hpp:77] Creating layer loss
I0824 23:08:39.920984 44210 net.cpp:100] Creating Layer loss
I0824 23:08:39.920989 44210 net.cpp:434] loss <- conv1_1_1_D_conv1_1_1_D_0_split_0
I0824 23:08:39.920994 44210 net.cpp:434] loss <- label_data_1_split_0
I0824 23:08:39.921002 44210 net.cpp:408] loss -> loss
I0824 23:08:39.921013 44210 layer_factory.hpp:77] Creating layer loss
I0824 23:08:39.925277 44210 net.cpp:150] Setting up loss
I0824 23:08:39.925293 44210 net.cpp:157] Top shape: (1)
I0824 23:08:39.925297 44210 net.cpp:160]     with loss weight 1
I0824 23:08:39.925317 44210 net.cpp:165] Memory required for data: 5510983684
I0824 23:08:39.925320 44210 layer_factory.hpp:77] Creating layer accuracy
I0824 23:08:39.925329 44210 net.cpp:100] Creating Layer accuracy
I0824 23:08:39.925338 44210 net.cpp:434] accuracy <- conv1_1_1_D_conv1_1_1_D_0_split_1
I0824 23:08:39.925348 44210 net.cpp:434] accuracy <- label_data_1_split_1
I0824 23:08:39.925356 44210 net.cpp:408] accuracy -> accuracy
I0824 23:08:39.925381 44210 net.cpp:408] accuracy -> per_class_accuracy
I0824 23:08:39.925442 44210 net.cpp:150] Setting up accuracy
I0824 23:08:39.925449 44210 net.cpp:157] Top shape: (1)
I0824 23:08:39.925454 44210 net.cpp:157] Top shape: 2 (2)
I0824 23:08:39.925458 44210 net.cpp:165] Memory required for data: 5510983696
I0824 23:08:39.925462 44210 net.cpp:228] accuracy does not need backward computation.
I0824 23:08:39.925467 44210 net.cpp:226] loss needs backward computation.
I0824 23:08:39.925472 44210 net.cpp:226] conv1_1_1_D_conv1_1_1_D_0_split needs backward computation.
I0824 23:08:39.925475 44210 net.cpp:226] conv1_1_1_D needs backward computation.
I0824 23:08:39.925479 44210 net.cpp:226] relu1_2_D needs backward computation.
I0824 23:08:39.925482 44210 net.cpp:226] conv1_2_D_scale needs backward computation.
I0824 23:08:39.925485 44210 net.cpp:226] conv1_2_D_bn_tmp needs backward computation.
I0824 23:08:39.925488 44210 net.cpp:226] conv1_2_D needs backward computation.
I0824 23:08:39.925493 44210 net.cpp:226] upsample1 needs backward computation.
I0824 23:08:39.925496 44210 net.cpp:226] relu2_1_D needs backward computation.
I0824 23:08:39.925499 44210 net.cpp:226] conv2_1_D_scale needs backward computation.
I0824 23:08:39.925503 44210 net.cpp:226] conv2_1_D_bn_tmp needs backward computation.
I0824 23:08:39.925505 44210 net.cpp:226] conv2_1_D needs backward computation.
I0824 23:08:39.925509 44210 net.cpp:226] relu2_2_D needs backward computation.
I0824 23:08:39.925513 44210 net.cpp:226] conv2_2_D_scale needs backward computation.
I0824 23:08:39.925515 44210 net.cpp:226] conv2_2_D_bn_tmp needs backward computation.
I0824 23:08:39.925518 44210 net.cpp:226] conv2_2_D needs backward computation.
I0824 23:08:39.925521 44210 net.cpp:226] upsample2 needs backward computation.
I0824 23:08:39.925525 44210 net.cpp:226] relu3_1_D needs backward computation.
I0824 23:08:39.925529 44210 net.cpp:226] conv3_1_D_scale needs backward computation.
I0824 23:08:39.925531 44210 net.cpp:226] conv3_1_D_bn_tmp needs backward computation.
I0824 23:08:39.925534 44210 net.cpp:226] conv3_1_D needs backward computation.
I0824 23:08:39.925539 44210 net.cpp:226] relu3_2_D needs backward computation.
I0824 23:08:39.925541 44210 net.cpp:226] conv3_2_D_scale needs backward computation.
I0824 23:08:39.925545 44210 net.cpp:226] conv3_2_D_bn_tmp needs backward computation.
I0824 23:08:39.925550 44210 net.cpp:226] conv3_2_D needs backward computation.
I0824 23:08:39.925554 44210 net.cpp:226] relu3_3_D needs backward computation.
I0824 23:08:39.925556 44210 net.cpp:226] conv3_3_D_scale needs backward computation.
I0824 23:08:39.925559 44210 net.cpp:226] conv3_3_D_bn_tmp needs backward computation.
I0824 23:08:39.925576 44210 net.cpp:226] conv3_3_D needs backward computation.
I0824 23:08:39.925581 44210 net.cpp:226] upsample3 needs backward computation.
I0824 23:08:39.925586 44210 net.cpp:226] relu4_1_D needs backward computation.
I0824 23:08:39.925592 44210 net.cpp:226] conv4_1_D_scale needs backward computation.
I0824 23:08:39.925595 44210 net.cpp:226] conv4_1_D_bn_tmp needs backward computation.
I0824 23:08:39.925599 44210 net.cpp:226] conv4_1_D needs backward computation.
I0824 23:08:39.925604 44210 net.cpp:226] relu4_2_D needs backward computation.
I0824 23:08:39.925607 44210 net.cpp:226] conv4_2_D_scale needs backward computation.
I0824 23:08:39.925612 44210 net.cpp:226] conv4_2_D_bn_tmp needs backward computation.
I0824 23:08:39.925617 44210 net.cpp:226] conv4_2_D needs backward computation.
I0824 23:08:39.925621 44210 net.cpp:226] relu4_3_D needs backward computation.
I0824 23:08:39.925626 44210 net.cpp:226] conv4_3_D_scale needs backward computation.
I0824 23:08:39.925629 44210 net.cpp:226] conv4_3_D_bn_tmp needs backward computation.
I0824 23:08:39.925633 44210 net.cpp:226] conv4_3_D needs backward computation.
I0824 23:08:39.925637 44210 net.cpp:226] upsample4 needs backward computation.
I0824 23:08:39.925642 44210 net.cpp:226] relu5_1_D needs backward computation.
I0824 23:08:39.925647 44210 net.cpp:226] conv5_1_D_scale needs backward computation.
I0824 23:08:39.925650 44210 net.cpp:226] conv5_1_D_bn_tmp needs backward computation.
I0824 23:08:39.925655 44210 net.cpp:226] conv5_1_D needs backward computation.
I0824 23:08:39.925658 44210 net.cpp:226] relu5_2_D needs backward computation.
I0824 23:08:39.925664 44210 net.cpp:226] conv5_2_D_scale needs backward computation.
I0824 23:08:39.925668 44210 net.cpp:226] conv5_2_D_bn_tmp needs backward computation.
I0824 23:08:39.925671 44210 net.cpp:226] conv5_2_D needs backward computation.
I0824 23:08:39.925675 44210 net.cpp:226] relu5_3_D needs backward computation.
I0824 23:08:39.925679 44210 net.cpp:226] conv5_3_D_scale needs backward computation.
I0824 23:08:39.925683 44210 net.cpp:226] conv5_3_D_bn_tmp needs backward computation.
I0824 23:08:39.925685 44210 net.cpp:226] conv5_3_D needs backward computation.
I0824 23:08:39.925689 44210 net.cpp:226] upsample5 needs backward computation.
I0824 23:08:39.925694 44210 net.cpp:226] pool5 needs backward computation.
I0824 23:08:39.925699 44210 net.cpp:226] relu5_3 needs backward computation.
I0824 23:08:39.925704 44210 net.cpp:226] conv5_3_scale needs backward computation.
I0824 23:08:39.925709 44210 net.cpp:226] conv5_3_bn_tmp needs backward computation.
I0824 23:08:39.925712 44210 net.cpp:226] conv5_3 needs backward computation.
I0824 23:08:39.925716 44210 net.cpp:226] relu5_2 needs backward computation.
I0824 23:08:39.925719 44210 net.cpp:226] conv5_2_scale needs backward computation.
I0824 23:08:39.925724 44210 net.cpp:226] conv5_2_bn_tmp needs backward computation.
I0824 23:08:39.925727 44210 net.cpp:226] conv5_2 needs backward computation.
I0824 23:08:39.925731 44210 net.cpp:226] relu5_1 needs backward computation.
I0824 23:08:39.925736 44210 net.cpp:226] conv5_1_scale needs backward computation.
I0824 23:08:39.925740 44210 net.cpp:226] conv5_1_bn_tmp needs backward computation.
I0824 23:08:39.925743 44210 net.cpp:226] conv5_1 needs backward computation.
I0824 23:08:39.925747 44210 net.cpp:226] pool4 needs backward computation.
I0824 23:08:39.925751 44210 net.cpp:226] relu4_3 needs backward computation.
I0824 23:08:39.925755 44210 net.cpp:226] conv4_3_scale needs backward computation.
I0824 23:08:39.925758 44210 net.cpp:226] conv4_3_bn_tmp needs backward computation.
I0824 23:08:39.925762 44210 net.cpp:226] conv4_3 needs backward computation.
I0824 23:08:39.925767 44210 net.cpp:226] relu4_2 needs backward computation.
I0824 23:08:39.925772 44210 net.cpp:226] conv4_2_scale needs backward computation.
I0824 23:08:39.925776 44210 net.cpp:226] conv4_2_bn_tmp needs backward computation.
I0824 23:08:39.925786 44210 net.cpp:226] conv4_2 needs backward computation.
I0824 23:08:39.925792 44210 net.cpp:226] relu4_1 needs backward computation.
I0824 23:08:39.925806 44210 net.cpp:226] conv4_1_scale needs backward computation.
I0824 23:08:39.925809 44210 net.cpp:226] conv4_1_bn_tmp needs backward computation.
I0824 23:08:39.925813 44210 net.cpp:226] conv4_1 needs backward computation.
I0824 23:08:39.925817 44210 net.cpp:226] pool3 needs backward computation.
I0824 23:08:39.925820 44210 net.cpp:226] relu3_3 needs backward computation.
I0824 23:08:39.925824 44210 net.cpp:226] conv3_3_scale needs backward computation.
I0824 23:08:39.925827 44210 net.cpp:226] conv3_3_bn_tmp needs backward computation.
I0824 23:08:39.925837 44210 net.cpp:226] conv3_3 needs backward computation.
I0824 23:08:39.925843 44210 net.cpp:226] relu3_2 needs backward computation.
I0824 23:08:39.925845 44210 net.cpp:226] conv3_2_scale needs backward computation.
I0824 23:08:39.925849 44210 net.cpp:226] conv3_2_bn_tmp needs backward computation.
I0824 23:08:39.925858 44210 net.cpp:226] conv3_2 needs backward computation.
I0824 23:08:39.925863 44210 net.cpp:226] relu3_1 needs backward computation.
I0824 23:08:39.925866 44210 net.cpp:226] conv3_1_scale needs backward computation.
I0824 23:08:39.925869 44210 net.cpp:226] conv3_1_bn_tmp needs backward computation.
I0824 23:08:39.925873 44210 net.cpp:226] conv3_1 needs backward computation.
I0824 23:08:39.925879 44210 net.cpp:226] pool2 needs backward computation.
I0824 23:08:39.925884 44210 net.cpp:226] relu2_2 needs backward computation.
I0824 23:08:39.925887 44210 net.cpp:226] conv2_2_scale needs backward computation.
I0824 23:08:39.925894 44210 net.cpp:226] conv2_2_bn_tmp needs backward computation.
I0824 23:08:39.925901 44210 net.cpp:226] conv2_2 needs backward computation.
I0824 23:08:39.925906 44210 net.cpp:226] relu2_1 needs backward computation.
I0824 23:08:39.925910 44210 net.cpp:226] conv2_1_scale needs backward computation.
I0824 23:08:39.925914 44210 net.cpp:226] conv2_1_bn_tmp needs backward computation.
I0824 23:08:39.925917 44210 net.cpp:226] conv2_1 needs backward computation.
I0824 23:08:39.925922 44210 net.cpp:226] pool1 needs backward computation.
I0824 23:08:39.925926 44210 net.cpp:226] relu1_2 needs backward computation.
I0824 23:08:39.925931 44210 net.cpp:226] conv1_2_scale needs backward computation.
I0824 23:08:39.925937 44210 net.cpp:226] conv1_2_bn_tmp needs backward computation.
I0824 23:08:39.925941 44210 net.cpp:226] conv1_2 needs backward computation.
I0824 23:08:39.925951 44210 net.cpp:226] relu1_1 needs backward computation.
I0824 23:08:39.925956 44210 net.cpp:226] conv1_1_1_scale needs backward computation.
I0824 23:08:39.925958 44210 net.cpp:226] conv1_1_1_bn needs backward computation.
I0824 23:08:39.925962 44210 net.cpp:226] conv1_1_1 needs backward computation.
I0824 23:08:39.925967 44210 net.cpp:228] label_data_1_split does not need backward computation.
I0824 23:08:39.925973 44210 net.cpp:228] data does not need backward computation.
I0824 23:08:39.925976 44210 net.cpp:270] This network produces output accuracy
I0824 23:08:39.925981 44210 net.cpp:270] This network produces output loss
I0824 23:08:39.925984 44210 net.cpp:270] This network produces output per_class_accuracy
I0824 23:08:39.926048 44210 net.cpp:283] Network initialization done.
I0824 23:08:39.926533 44210 solver.cpp:60] Solver scaffolding done.
I0824 23:08:39.935967 44210 caffe.cpp:155] Finetuning from /disk1/model_zoo/segNet/v2/segnet_pascal.caffemodel
I0824 23:08:40.364194 44210 net.cpp:761] Ignoring source layer conv1_1
I0824 23:08:40.364213 44210 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 23:08:40.364276 44210 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 23:08:40.364285 44210 net.cpp:761] Ignoring source layer pool1_drop
I0824 23:08:40.364372 44210 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 23:08:40.364533 44210 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 23:08:40.364540 44210 net.cpp:761] Ignoring source layer pool2_drop
I0824 23:08:40.364830 44210 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 23:08:40.365408 44210 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 23:08:40.365983 44210 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 23:08:40.366008 44210 net.cpp:761] Ignoring source layer pool3_drop
I0824 23:08:40.367115 44210 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 23:08:40.369323 44210 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 23:08:40.371541 44210 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 23:08:40.371551 44210 net.cpp:761] Ignoring source layer pool4_drop
I0824 23:08:40.373762 44210 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 23:08:40.375985 44210 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 23:08:40.378227 44210 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 23:08:40.378235 44210 net.cpp:761] Ignoring source layer pool5_drop
I0824 23:08:40.378240 44210 net.cpp:761] Ignoring source layer upsample5_drop
I0824 23:08:40.380452 44210 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 23:08:40.382688 44210 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 23:08:40.384856 44210 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 23:08:40.384867 44210 net.cpp:761] Ignoring source layer upsample4_drop
I0824 23:08:40.386893 44210 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 23:08:40.389029 44210 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 23:08:40.390197 44210 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 23:08:40.390206 44210 net.cpp:761] Ignoring source layer upsample3_drop
I0824 23:08:40.390781 44210 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 23:08:40.391355 44210 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 23:08:40.391660 44210 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 23:08:40.391667 44210 net.cpp:761] Ignoring source layer upsample2_drop
I0824 23:08:40.391825 44210 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 23:08:40.391912 44210 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 23:08:40.391921 44210 net.cpp:761] Ignoring source layer upsample1_drop
I0824 23:08:40.391968 44210 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 23:08:40.391973 44210 net.cpp:761] Ignoring source layer conv1_1_D
I0824 23:08:40.391978 44210 net.cpp:761] Ignoring source layer prob
I0824 23:08:40.695796 44210 net.cpp:761] Ignoring source layer conv1_1
I0824 23:08:40.695823 44210 net.cpp:761] Ignoring source layer conv1_1_bn
I0824 23:08:40.695875 44210 net.cpp:761] Ignoring source layer conv1_2_bn
I0824 23:08:40.695881 44210 net.cpp:761] Ignoring source layer pool1_drop
I0824 23:08:40.695960 44210 net.cpp:761] Ignoring source layer conv2_1_bn
I0824 23:08:40.696111 44210 net.cpp:761] Ignoring source layer conv2_2_bn
I0824 23:08:40.696118 44210 net.cpp:761] Ignoring source layer pool2_drop
I0824 23:08:40.696419 44210 net.cpp:761] Ignoring source layer conv3_1_bn
I0824 23:08:40.697006 44210 net.cpp:761] Ignoring source layer conv3_2_bn
I0824 23:08:40.697609 44210 net.cpp:761] Ignoring source layer conv3_3_bn
I0824 23:08:40.697616 44210 net.cpp:761] Ignoring source layer pool3_drop
I0824 23:08:40.698688 44210 net.cpp:761] Ignoring source layer conv4_1_bn
I0824 23:08:40.700747 44210 net.cpp:761] Ignoring source layer conv4_2_bn
I0824 23:08:40.702816 44210 net.cpp:761] Ignoring source layer conv4_3_bn
I0824 23:08:40.702826 44210 net.cpp:761] Ignoring source layer pool4_drop
I0824 23:08:40.704890 44210 net.cpp:761] Ignoring source layer conv5_1_bn
I0824 23:08:40.706970 44210 net.cpp:761] Ignoring source layer conv5_2_bn
I0824 23:08:40.709046 44210 net.cpp:761] Ignoring source layer conv5_3_bn
I0824 23:08:40.709055 44210 net.cpp:761] Ignoring source layer pool5_drop
I0824 23:08:40.709059 44210 net.cpp:761] Ignoring source layer upsample5_drop
I0824 23:08:40.711143 44210 net.cpp:761] Ignoring source layer conv5_3_D_bn
I0824 23:08:40.713224 44210 net.cpp:761] Ignoring source layer conv5_2_D_bn
I0824 23:08:40.715319 44210 net.cpp:761] Ignoring source layer conv5_1_D_bn
I0824 23:08:40.715328 44210 net.cpp:761] Ignoring source layer upsample4_drop
I0824 23:08:40.717614 44210 net.cpp:761] Ignoring source layer conv4_3_D_bn
I0824 23:08:40.719894 44210 net.cpp:761] Ignoring source layer conv4_2_D_bn
I0824 23:08:40.721065 44210 net.cpp:761] Ignoring source layer conv4_1_D_bn
I0824 23:08:40.721074 44210 net.cpp:761] Ignoring source layer upsample3_drop
I0824 23:08:40.721658 44210 net.cpp:761] Ignoring source layer conv3_3_D_bn
I0824 23:08:40.722306 44210 net.cpp:761] Ignoring source layer conv3_2_D_bn
I0824 23:08:40.722604 44210 net.cpp:761] Ignoring source layer conv3_1_D_bn
I0824 23:08:40.722611 44210 net.cpp:761] Ignoring source layer upsample2_drop
I0824 23:08:40.722764 44210 net.cpp:761] Ignoring source layer conv2_2_D_bn
I0824 23:08:40.722847 44210 net.cpp:761] Ignoring source layer conv2_1_D_bn
I0824 23:08:40.722853 44210 net.cpp:761] Ignoring source layer upsample1_drop
I0824 23:08:40.722896 44210 net.cpp:761] Ignoring source layer conv1_2_D_bn
I0824 23:08:40.722903 44210 net.cpp:761] Ignoring source layer conv1_1_D
I0824 23:08:40.722908 44210 net.cpp:761] Ignoring source layer prob
I0824 23:08:40.731330 44210 caffe.cpp:251] Starting Optimization
I0824 23:08:40.731350 44210 solver.cpp:279] Solving VGG_ILSVRC_16_layer
I0824 23:08:40.731355 44210 solver.cpp:280] Learning Rate Policy: step
I0824 23:08:41.820837 44210 solver.cpp:228] Iteration 0, loss = 0.733806
I0824 23:08:41.820881 44210 solver.cpp:244]     Train net output #0: accuracy = 0.583604
I0824 23:08:41.820894 44210 solver.cpp:244]     Train net output #1: loss = 0.733806 (* 1 = 0.733806 loss)
I0824 23:08:41.820901 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.614179
I0824 23:08:41.820905 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.430134
I0824 23:08:41.820929 44210 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0824 23:09:00.755303 44210 solver.cpp:228] Iteration 20, loss = 0.483828
I0824 23:09:00.755353 44210 solver.cpp:244]     Train net output #0: accuracy = 0.682053
I0824 23:09:00.755367 44210 solver.cpp:244]     Train net output #1: loss = 0.483828 (* 1 = 0.483828 loss)
I0824 23:09:00.755374 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.646236
I0824 23:09:00.755378 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.878325
I0824 23:09:00.755386 44210 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0824 23:09:17.379230 44210 solver.cpp:228] Iteration 40, loss = 0.485339
I0824 23:09:17.379389 44210 solver.cpp:244]     Train net output #0: accuracy = 0.636534
I0824 23:09:17.379405 44210 solver.cpp:244]     Train net output #1: loss = 0.485339 (* 1 = 0.485339 loss)
I0824 23:09:17.379410 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.632187
I0824 23:09:17.379415 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.710945
I0824 23:09:17.379423 44210 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0824 23:09:34.012181 44210 solver.cpp:228] Iteration 60, loss = 0.325711
I0824 23:09:34.012230 44210 solver.cpp:244]     Train net output #0: accuracy = 0.889521
I0824 23:09:34.012243 44210 solver.cpp:244]     Train net output #1: loss = 0.325711 (* 1 = 0.325711 loss)
I0824 23:09:34.012249 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.898684
I0824 23:09:34.012254 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.874768
I0824 23:09:34.012262 44210 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0824 23:09:50.619493 44210 solver.cpp:228] Iteration 80, loss = 0.37178
I0824 23:09:50.619645 44210 solver.cpp:244]     Train net output #0: accuracy = 0.82167
I0824 23:09:50.619666 44210 solver.cpp:244]     Train net output #1: loss = 0.37178 (* 1 = 0.37178 loss)
I0824 23:09:50.619674 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.80969
I0824 23:09:50.619679 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.858202
I0824 23:09:50.619688 44210 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0824 23:10:07.247624 44210 solver.cpp:228] Iteration 100, loss = 0.207385
I0824 23:10:07.247674 44210 solver.cpp:244]     Train net output #0: accuracy = 0.939125
I0824 23:10:07.247687 44210 solver.cpp:244]     Train net output #1: loss = 0.207385 (* 1 = 0.207385 loss)
I0824 23:10:07.247694 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.935902
I0824 23:10:07.247699 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.945559
I0824 23:10:07.247706 44210 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0824 23:10:23.878125 44210 solver.cpp:228] Iteration 120, loss = 0.186188
I0824 23:10:23.878286 44210 solver.cpp:244]     Train net output #0: accuracy = 0.923131
I0824 23:10:23.878304 44210 solver.cpp:244]     Train net output #1: loss = 0.186188 (* 1 = 0.186188 loss)
I0824 23:10:23.878311 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.911759
I0824 23:10:23.878316 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.960648
I0824 23:10:23.878329 44210 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0824 23:10:40.495554 44210 solver.cpp:228] Iteration 140, loss = 0.282919
I0824 23:10:40.495601 44210 solver.cpp:244]     Train net output #0: accuracy = 0.911353
I0824 23:10:40.495615 44210 solver.cpp:244]     Train net output #1: loss = 0.282919 (* 1 = 0.282919 loss)
I0824 23:10:40.495621 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977657
I0824 23:10:40.495626 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.817041
I0824 23:10:40.495635 44210 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0824 23:10:57.133512 44210 solver.cpp:228] Iteration 160, loss = 0.247097
I0824 23:10:57.133631 44210 solver.cpp:244]     Train net output #0: accuracy = 0.924787
I0824 23:10:57.133652 44210 solver.cpp:244]     Train net output #1: loss = 0.247097 (* 1 = 0.247097 loss)
I0824 23:10:57.133661 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990806
I0824 23:10:57.133666 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.790549
I0824 23:10:57.133672 44210 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0824 23:11:13.762153 44210 solver.cpp:228] Iteration 180, loss = 0.254152
I0824 23:11:13.762199 44210 solver.cpp:244]     Train net output #0: accuracy = 0.929916
I0824 23:11:13.762214 44210 solver.cpp:244]     Train net output #1: loss = 0.254152 (* 1 = 0.254152 loss)
I0824 23:11:13.762228 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.96941
I0824 23:11:13.762234 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.863261
I0824 23:11:13.762243 44210 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0824 23:11:30.385151 44210 solver.cpp:228] Iteration 200, loss = 0.191782
I0824 23:11:30.385267 44210 solver.cpp:244]     Train net output #0: accuracy = 0.907995
I0824 23:11:30.385282 44210 solver.cpp:244]     Train net output #1: loss = 0.191782 (* 1 = 0.191782 loss)
I0824 23:11:30.385288 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.898643
I0824 23:11:30.385293 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.952275
I0824 23:11:30.385300 44210 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0824 23:11:47.031513 44210 solver.cpp:228] Iteration 220, loss = 0.141058
I0824 23:11:47.031556 44210 solver.cpp:244]     Train net output #0: accuracy = 0.951613
I0824 23:11:47.031568 44210 solver.cpp:244]     Train net output #1: loss = 0.141058 (* 1 = 0.141058 loss)
I0824 23:11:47.031574 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.953609
I0824 23:11:47.031579 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.946737
I0824 23:11:47.031586 44210 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0824 23:12:03.663853 44210 solver.cpp:228] Iteration 240, loss = 0.0676143
I0824 23:12:03.663995 44210 solver.cpp:244]     Train net output #0: accuracy = 0.978882
I0824 23:12:03.664021 44210 solver.cpp:244]     Train net output #1: loss = 0.0676142 (* 1 = 0.0676142 loss)
I0824 23:12:03.664029 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980512
I0824 23:12:03.664033 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.974417
I0824 23:12:03.664041 44210 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0824 23:12:20.288956 44210 solver.cpp:228] Iteration 260, loss = 0.141707
I0824 23:12:20.289002 44210 solver.cpp:244]     Train net output #0: accuracy = 0.92929
I0824 23:12:20.289016 44210 solver.cpp:244]     Train net output #1: loss = 0.141707 (* 1 = 0.141707 loss)
I0824 23:12:20.289022 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.925492
I0824 23:12:20.289036 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.949118
I0824 23:12:20.289043 44210 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0824 23:12:36.914073 44210 solver.cpp:228] Iteration 280, loss = 0.0908463
I0824 23:12:36.914271 44210 solver.cpp:244]     Train net output #0: accuracy = 0.968138
I0824 23:12:36.914289 44210 solver.cpp:244]     Train net output #1: loss = 0.0908463 (* 1 = 0.0908463 loss)
I0824 23:12:36.914299 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972439
I0824 23:12:36.914304 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.957388
I0824 23:12:36.914310 44210 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0824 23:12:53.721305 44210 solver.cpp:228] Iteration 300, loss = 0.115633
I0824 23:12:53.721354 44210 solver.cpp:244]     Train net output #0: accuracy = 0.961957
I0824 23:12:53.721372 44210 solver.cpp:244]     Train net output #1: loss = 0.115633 (* 1 = 0.115633 loss)
I0824 23:12:53.721379 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.964981
I0824 23:12:53.721384 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.954348
I0824 23:12:53.721390 44210 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0824 23:13:10.342118 44210 solver.cpp:228] Iteration 320, loss = 0.0689311
I0824 23:13:10.342258 44210 solver.cpp:244]     Train net output #0: accuracy = 0.971221
I0824 23:13:10.342274 44210 solver.cpp:244]     Train net output #1: loss = 0.0689311 (* 1 = 0.0689311 loss)
I0824 23:13:10.342280 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.96663
I0824 23:13:10.342286 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982374
I0824 23:13:10.342294 44210 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0824 23:13:26.963672 44210 solver.cpp:228] Iteration 340, loss = 0.0709022
I0824 23:13:26.963719 44210 solver.cpp:244]     Train net output #0: accuracy = 0.974446
I0824 23:13:26.963734 44210 solver.cpp:244]     Train net output #1: loss = 0.0709022 (* 1 = 0.0709022 loss)
I0824 23:13:26.963740 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.972717
I0824 23:13:26.963745 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.977523
I0824 23:13:26.963752 44210 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0824 23:13:43.587692 44210 solver.cpp:228] Iteration 360, loss = 0.0644762
I0824 23:13:43.587824 44210 solver.cpp:244]     Train net output #0: accuracy = 0.974207
I0824 23:13:43.587841 44210 solver.cpp:244]     Train net output #1: loss = 0.0644762 (* 1 = 0.0644762 loss)
I0824 23:13:43.587851 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.968572
I0824 23:13:43.587854 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98663
I0824 23:13:43.587862 44210 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0824 23:14:00.220765 44210 solver.cpp:228] Iteration 380, loss = 0.0845994
I0824 23:14:00.220809 44210 solver.cpp:244]     Train net output #0: accuracy = 0.971564
I0824 23:14:00.220824 44210 solver.cpp:244]     Train net output #1: loss = 0.0845993 (* 1 = 0.0845993 loss)
I0824 23:14:00.220829 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985419
I0824 23:14:00.220834 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.944256
I0824 23:14:00.220840 44210 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0824 23:14:16.837371 44210 solver.cpp:228] Iteration 400, loss = 0.106256
I0824 23:14:16.837496 44210 solver.cpp:244]     Train net output #0: accuracy = 0.955085
I0824 23:14:16.837512 44210 solver.cpp:244]     Train net output #1: loss = 0.106256 (* 1 = 0.106256 loss)
I0824 23:14:16.837517 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.948631
I0824 23:14:16.837522 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987985
I0824 23:14:16.837529 44210 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0824 23:14:33.491046 44210 solver.cpp:228] Iteration 420, loss = 0.047781
I0824 23:14:33.491091 44210 solver.cpp:244]     Train net output #0: accuracy = 0.982273
I0824 23:14:33.491103 44210 solver.cpp:244]     Train net output #1: loss = 0.047781 (* 1 = 0.047781 loss)
I0824 23:14:33.491109 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980435
I0824 23:14:33.491116 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986446
I0824 23:14:33.491122 44210 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0824 23:14:50.110047 44210 solver.cpp:228] Iteration 440, loss = 0.053097
I0824 23:14:50.110266 44210 solver.cpp:244]     Train net output #0: accuracy = 0.979554
I0824 23:14:50.110282 44210 solver.cpp:244]     Train net output #1: loss = 0.053097 (* 1 = 0.053097 loss)
I0824 23:14:50.110291 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.977736
I0824 23:14:50.110296 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985131
I0824 23:14:50.110303 44210 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0824 23:15:06.729490 44210 solver.cpp:228] Iteration 460, loss = 0.0436465
I0824 23:15:06.729537 44210 solver.cpp:244]     Train net output #0: accuracy = 0.9872
I0824 23:15:06.729549 44210 solver.cpp:244]     Train net output #1: loss = 0.0436464 (* 1 = 0.0436464 loss)
I0824 23:15:06.729557 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990285
I0824 23:15:06.729562 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98079
I0824 23:15:06.729568 44210 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0824 23:15:23.331383 44210 solver.cpp:228] Iteration 480, loss = 0.0595345
I0824 23:15:23.331511 44210 solver.cpp:244]     Train net output #0: accuracy = 0.972993
I0824 23:15:23.331527 44210 solver.cpp:244]     Train net output #1: loss = 0.0595344 (* 1 = 0.0595344 loss)
I0824 23:15:23.331533 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969368
I0824 23:15:23.331538 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98517
I0824 23:15:23.331545 44210 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0824 23:15:39.955260 44210 solver.cpp:228] Iteration 500, loss = 0.0469334
I0824 23:15:39.955307 44210 solver.cpp:244]     Train net output #0: accuracy = 0.983419
I0824 23:15:39.955322 44210 solver.cpp:244]     Train net output #1: loss = 0.0469333 (* 1 = 0.0469333 loss)
I0824 23:15:39.955327 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985096
I0824 23:15:39.955332 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978556
I0824 23:15:39.955338 44210 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0824 23:15:56.567229 44210 solver.cpp:228] Iteration 520, loss = 0.0527975
I0824 23:15:56.567364 44210 solver.cpp:244]     Train net output #0: accuracy = 0.977159
I0824 23:15:56.567379 44210 solver.cpp:244]     Train net output #1: loss = 0.0527974 (* 1 = 0.0527974 loss)
I0824 23:15:56.567385 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.973389
I0824 23:15:56.567390 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98746
I0824 23:15:56.567397 44210 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0824 23:16:13.187294 44210 solver.cpp:228] Iteration 540, loss = 0.0728903
I0824 23:16:13.187342 44210 solver.cpp:244]     Train net output #0: accuracy = 0.971798
I0824 23:16:13.187355 44210 solver.cpp:244]     Train net output #1: loss = 0.0728902 (* 1 = 0.0728902 loss)
I0824 23:16:13.187360 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.968405
I0824 23:16:13.187364 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.979355
I0824 23:16:13.187372 44210 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0824 23:16:29.798708 44210 solver.cpp:228] Iteration 560, loss = 0.0538692
I0824 23:16:29.798895 44210 solver.cpp:244]     Train net output #0: accuracy = 0.977985
I0824 23:16:29.798918 44210 solver.cpp:244]     Train net output #1: loss = 0.0538691 (* 1 = 0.0538691 loss)
I0824 23:16:29.798924 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.969747
I0824 23:16:29.798929 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992156
I0824 23:16:29.798941 44210 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0824 23:16:46.411001 44210 solver.cpp:228] Iteration 580, loss = 0.0384053
I0824 23:16:46.411044 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986318
I0824 23:16:46.411057 44210 solver.cpp:244]     Train net output #1: loss = 0.0384053 (* 1 = 0.0384053 loss)
I0824 23:16:46.411063 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987253
I0824 23:16:46.411067 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982718
I0824 23:16:46.411074 44210 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0824 23:17:03.017498 44210 solver.cpp:228] Iteration 600, loss = 0.0727702
I0824 23:17:03.017624 44210 solver.cpp:244]     Train net output #0: accuracy = 0.97526
I0824 23:17:03.017640 44210 solver.cpp:244]     Train net output #1: loss = 0.0727701 (* 1 = 0.0727701 loss)
I0824 23:17:03.017647 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980947
I0824 23:17:03.017652 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.946691
I0824 23:17:03.017662 44210 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0824 23:17:19.620561 44210 solver.cpp:228] Iteration 620, loss = 0.0343988
I0824 23:17:19.620604 44210 solver.cpp:244]     Train net output #0: accuracy = 0.987183
I0824 23:17:19.620615 44210 solver.cpp:244]     Train net output #1: loss = 0.0343987 (* 1 = 0.0343987 loss)
I0824 23:17:19.620621 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98846
I0824 23:17:19.620626 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981089
I0824 23:17:19.620635 44210 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0824 23:17:36.233618 44210 solver.cpp:228] Iteration 640, loss = 0.0420002
I0824 23:17:36.233749 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986836
I0824 23:17:36.233763 44210 solver.cpp:244]     Train net output #1: loss = 0.0420001 (* 1 = 0.0420001 loss)
I0824 23:17:36.233769 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989605
I0824 23:17:36.233774 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.976527
I0824 23:17:36.233780 44210 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0824 23:17:52.846823 44210 solver.cpp:228] Iteration 660, loss = 0.040764
I0824 23:17:52.846865 44210 solver.cpp:244]     Train net output #0: accuracy = 0.982109
I0824 23:17:52.846879 44210 solver.cpp:244]     Train net output #1: loss = 0.0407639 (* 1 = 0.0407639 loss)
I0824 23:17:52.846884 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980427
I0824 23:17:52.846889 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9873
I0824 23:17:52.846896 44210 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0824 23:18:09.469231 44210 solver.cpp:228] Iteration 680, loss = 0.0369429
I0824 23:18:09.469352 44210 solver.cpp:244]     Train net output #0: accuracy = 0.985376
I0824 23:18:09.469373 44210 solver.cpp:244]     Train net output #1: loss = 0.0369429 (* 1 = 0.0369429 loss)
I0824 23:18:09.469380 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982798
I0824 23:18:09.469385 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991001
I0824 23:18:09.469393 44210 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0824 23:18:26.081450 44210 solver.cpp:228] Iteration 700, loss = 0.163663
I0824 23:18:26.081491 44210 solver.cpp:244]     Train net output #0: accuracy = 0.952934
I0824 23:18:26.081502 44210 solver.cpp:244]     Train net output #1: loss = 0.163663 (* 1 = 0.163663 loss)
I0824 23:18:26.081511 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98572
I0824 23:18:26.081516 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.857177
I0824 23:18:26.081522 44210 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0824 23:18:42.694874 44210 solver.cpp:228] Iteration 720, loss = 0.0663919
I0824 23:18:42.695031 44210 solver.cpp:244]     Train net output #0: accuracy = 0.982209
I0824 23:18:42.695049 44210 solver.cpp:244]     Train net output #1: loss = 0.0663918 (* 1 = 0.0663918 loss)
I0824 23:18:42.695055 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993472
I0824 23:18:42.695058 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.963239
I0824 23:18:42.695066 44210 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0824 23:18:59.310497 44210 solver.cpp:228] Iteration 740, loss = 0.0352414
I0824 23:18:59.310539 44210 solver.cpp:244]     Train net output #0: accuracy = 0.984783
I0824 23:18:59.310550 44210 solver.cpp:244]     Train net output #1: loss = 0.0352413 (* 1 = 0.0352413 loss)
I0824 23:18:59.310556 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98365
I0824 23:18:59.310562 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988703
I0824 23:18:59.310570 44210 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0824 23:19:15.943104 44210 solver.cpp:228] Iteration 760, loss = 0.0349238
I0824 23:19:15.943224 44210 solver.cpp:244]     Train net output #0: accuracy = 0.985651
I0824 23:19:15.943240 44210 solver.cpp:244]     Train net output #1: loss = 0.0349237 (* 1 = 0.0349237 loss)
I0824 23:19:15.943251 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982538
I0824 23:19:15.943258 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99475
I0824 23:19:15.943265 44210 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0824 23:19:32.558012 44210 solver.cpp:228] Iteration 780, loss = 0.0304722
I0824 23:19:32.558056 44210 solver.cpp:244]     Train net output #0: accuracy = 0.988695
I0824 23:19:32.558069 44210 solver.cpp:244]     Train net output #1: loss = 0.0304721 (* 1 = 0.0304721 loss)
I0824 23:19:32.558076 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988885
I0824 23:19:32.558089 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987688
I0824 23:19:32.558096 44210 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0824 23:19:49.187002 44210 solver.cpp:228] Iteration 800, loss = 0.0526581
I0824 23:19:49.187116 44210 solver.cpp:244]     Train net output #0: accuracy = 0.980606
I0824 23:19:49.187131 44210 solver.cpp:244]     Train net output #1: loss = 0.0526581 (* 1 = 0.0526581 loss)
I0824 23:19:49.187144 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.980721
I0824 23:19:49.187147 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980376
I0824 23:19:49.187155 44210 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0824 23:20:05.814538 44210 solver.cpp:228] Iteration 820, loss = 0.0376138
I0824 23:20:05.814582 44210 solver.cpp:244]     Train net output #0: accuracy = 0.985372
I0824 23:20:05.814596 44210 solver.cpp:244]     Train net output #1: loss = 0.0376137 (* 1 = 0.0376137 loss)
I0824 23:20:05.814602 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9803
I0824 23:20:05.814606 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993193
I0824 23:20:05.814613 44210 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0824 23:20:22.432809 44210 solver.cpp:228] Iteration 840, loss = 0.0851661
I0824 23:20:22.432924 44210 solver.cpp:244]     Train net output #0: accuracy = 0.976231
I0824 23:20:22.432940 44210 solver.cpp:244]     Train net output #1: loss = 0.0851661 (* 1 = 0.0851661 loss)
I0824 23:20:22.432951 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.975465
I0824 23:20:22.432955 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989504
I0824 23:20:22.432962 44210 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0824 23:20:39.058461 44210 solver.cpp:228] Iteration 860, loss = 0.0274111
I0824 23:20:39.058502 44210 solver.cpp:244]     Train net output #0: accuracy = 0.988536
I0824 23:20:39.058514 44210 solver.cpp:244]     Train net output #1: loss = 0.0274111 (* 1 = 0.0274111 loss)
I0824 23:20:39.058521 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987211
I0824 23:20:39.058533 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992762
I0824 23:20:39.058540 44210 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0824 23:20:55.685783 44210 solver.cpp:228] Iteration 880, loss = 0.0403005
I0824 23:20:55.685945 44210 solver.cpp:244]     Train net output #0: accuracy = 0.987124
I0824 23:20:55.685962 44210 solver.cpp:244]     Train net output #1: loss = 0.0403004 (* 1 = 0.0403004 loss)
I0824 23:20:55.685974 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986769
I0824 23:20:55.685979 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987673
I0824 23:20:55.685986 44210 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0824 23:21:12.298741 44210 solver.cpp:228] Iteration 900, loss = 0.0307094
I0824 23:21:12.298785 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989855
I0824 23:21:12.298799 44210 solver.cpp:244]     Train net output #1: loss = 0.0307093 (* 1 = 0.0307093 loss)
I0824 23:21:12.298804 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991098
I0824 23:21:12.298808 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984984
I0824 23:21:12.298815 44210 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0824 23:21:28.901779 44210 solver.cpp:228] Iteration 920, loss = 0.0236842
I0824 23:21:28.901886 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991026
I0824 23:21:28.901902 44210 solver.cpp:244]     Train net output #1: loss = 0.0236841 (* 1 = 0.0236841 loss)
I0824 23:21:28.901908 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991245
I0824 23:21:28.901913 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989928
I0824 23:21:28.901919 44210 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0824 23:21:45.507853 44210 solver.cpp:228] Iteration 940, loss = 0.0271621
I0824 23:21:45.507894 44210 solver.cpp:244]     Train net output #0: accuracy = 0.988105
I0824 23:21:45.507905 44210 solver.cpp:244]     Train net output #1: loss = 0.027162 (* 1 = 0.027162 loss)
I0824 23:21:45.507911 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98524
I0824 23:21:45.507916 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994427
I0824 23:21:45.507923 44210 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0824 23:22:02.274657 44210 solver.cpp:228] Iteration 960, loss = 0.0213186
I0824 23:22:02.274778 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992636
I0824 23:22:02.274794 44210 solver.cpp:244]     Train net output #1: loss = 0.0213185 (* 1 = 0.0213185 loss)
I0824 23:22:02.274801 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995131
I0824 23:22:02.274806 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981209
I0824 23:22:02.274812 44210 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0824 23:22:18.905177 44210 solver.cpp:228] Iteration 980, loss = 0.0252555
I0824 23:22:18.905221 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990088
I0824 23:22:18.905236 44210 solver.cpp:244]     Train net output #1: loss = 0.0252554 (* 1 = 0.0252554 loss)
I0824 23:22:18.905241 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991137
I0824 23:22:18.905246 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986621
I0824 23:22:18.905253 44210 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0824 23:22:35.514134 44210 solver.cpp:228] Iteration 1000, loss = 0.0353197
I0824 23:22:35.514261 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986723
I0824 23:22:35.514276 44210 solver.cpp:244]     Train net output #1: loss = 0.0353197 (* 1 = 0.0353197 loss)
I0824 23:22:35.514288 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985151
I0824 23:22:35.514293 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989286
I0824 23:22:35.514300 44210 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0824 23:22:52.166627 44210 solver.cpp:228] Iteration 1020, loss = 0.0337199
I0824 23:22:52.166682 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986659
I0824 23:22:52.166698 44210 solver.cpp:244]     Train net output #1: loss = 0.0337198 (* 1 = 0.0337198 loss)
I0824 23:22:52.166705 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988966
I0824 23:22:52.166712 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.97827
I0824 23:22:52.166723 44210 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0824 23:23:08.857573 44210 solver.cpp:228] Iteration 1040, loss = 0.0232015
I0824 23:23:08.857861 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990878
I0824 23:23:08.857894 44210 solver.cpp:244]     Train net output #1: loss = 0.0232015 (* 1 = 0.0232015 loss)
I0824 23:23:08.857903 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990896
I0824 23:23:08.857913 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990822
I0824 23:23:08.857919 44210 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0824 23:23:25.483193 44210 solver.cpp:228] Iteration 1060, loss = 0.0237464
I0824 23:23:25.483248 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99111
I0824 23:23:25.483269 44210 solver.cpp:244]     Train net output #1: loss = 0.0237464 (* 1 = 0.0237464 loss)
I0824 23:23:25.483288 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991712
I0824 23:23:25.483299 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989443
I0824 23:23:25.483314 44210 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0824 23:23:42.100529 44210 solver.cpp:228] Iteration 1080, loss = 0.0321298
I0824 23:23:42.100664 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986111
I0824 23:23:42.100680 44210 solver.cpp:244]     Train net output #1: loss = 0.0321297 (* 1 = 0.0321297 loss)
I0824 23:23:42.100687 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.98463
I0824 23:23:42.100692 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989239
I0824 23:23:42.100698 44210 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0824 23:23:58.709820 44210 solver.cpp:228] Iteration 1100, loss = 0.0258923
I0824 23:23:58.709870 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990951
I0824 23:23:58.709884 44210 solver.cpp:244]     Train net output #1: loss = 0.0258923 (* 1 = 0.0258923 loss)
I0824 23:23:58.709892 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989723
I0824 23:23:58.709904 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993053
I0824 23:23:58.709911 44210 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0824 23:24:15.316035 44210 solver.cpp:228] Iteration 1120, loss = 0.0257613
I0824 23:24:15.316169 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990185
I0824 23:24:15.316207 44210 solver.cpp:244]     Train net output #1: loss = 0.0257612 (* 1 = 0.0257612 loss)
I0824 23:24:15.316215 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991499
I0824 23:24:15.316226 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.978805
I0824 23:24:15.316236 44210 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0824 23:24:32.010740 44210 solver.cpp:228] Iteration 1140, loss = 0.027707
I0824 23:24:32.010808 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990365
I0824 23:24:32.010828 44210 solver.cpp:244]     Train net output #1: loss = 0.0277069 (* 1 = 0.0277069 loss)
I0824 23:24:32.010841 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991847
I0824 23:24:32.010852 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984402
I0824 23:24:32.010869 44210 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0824 23:24:48.705471 44210 solver.cpp:228] Iteration 1160, loss = 0.0384505
I0824 23:24:48.705672 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986927
I0824 23:24:48.705696 44210 solver.cpp:244]     Train net output #1: loss = 0.0384504 (* 1 = 0.0384504 loss)
I0824 23:24:48.705705 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988481
I0824 23:24:48.705718 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984197
I0824 23:24:48.705727 44210 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0824 23:25:05.332430 44210 solver.cpp:228] Iteration 1180, loss = 0.028131
I0824 23:25:05.332474 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989504
I0824 23:25:05.332487 44210 solver.cpp:244]     Train net output #1: loss = 0.0281309 (* 1 = 0.0281309 loss)
I0824 23:25:05.332494 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991364
I0824 23:25:05.332499 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98197
I0824 23:25:05.332509 44210 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0824 23:25:21.960239 44210 solver.cpp:228] Iteration 1200, loss = 0.0135996
I0824 23:25:21.960398 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994149
I0824 23:25:21.960422 44210 solver.cpp:244]     Train net output #1: loss = 0.0135995 (* 1 = 0.0135995 loss)
I0824 23:25:21.960434 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993713
I0824 23:25:21.960446 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995805
I0824 23:25:21.960461 44210 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0824 23:25:38.567454 44210 solver.cpp:228] Iteration 1220, loss = 0.0350264
I0824 23:25:38.567528 44210 solver.cpp:244]     Train net output #0: accuracy = 0.984537
I0824 23:25:38.567544 44210 solver.cpp:244]     Train net output #1: loss = 0.0350264 (* 1 = 0.0350264 loss)
I0824 23:25:38.567559 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.982188
I0824 23:25:38.567564 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989744
I0824 23:25:38.567574 44210 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0824 23:25:55.215899 44210 solver.cpp:228] Iteration 1240, loss = 0.0319381
I0824 23:25:55.216032 44210 solver.cpp:244]     Train net output #0: accuracy = 0.988764
I0824 23:25:55.216051 44210 solver.cpp:244]     Train net output #1: loss = 0.031938 (* 1 = 0.031938 loss)
I0824 23:25:55.216060 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988283
I0824 23:25:55.216068 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989467
I0824 23:25:55.216076 44210 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0824 23:26:11.907795 44210 solver.cpp:228] Iteration 1260, loss = 0.0253499
I0824 23:26:11.907897 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990291
I0824 23:26:11.907922 44210 solver.cpp:244]     Train net output #1: loss = 0.0253499 (* 1 = 0.0253499 loss)
I0824 23:26:11.907937 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.9892
I0824 23:26:11.907948 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992726
I0824 23:26:11.907964 44210 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0824 23:26:28.583065 44210 solver.cpp:228] Iteration 1280, loss = 0.0321991
I0824 23:26:28.583192 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986816
I0824 23:26:28.583217 44210 solver.cpp:244]     Train net output #1: loss = 0.032199 (* 1 = 0.032199 loss)
I0824 23:26:28.583226 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.984404
I0824 23:26:28.583236 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991219
I0824 23:26:28.583245 44210 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0824 23:26:45.275967 44210 solver.cpp:228] Iteration 1300, loss = 0.026284
I0824 23:26:45.276021 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991098
I0824 23:26:45.276041 44210 solver.cpp:244]     Train net output #1: loss = 0.0262839 (* 1 = 0.0262839 loss)
I0824 23:26:45.276051 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993376
I0824 23:26:45.276057 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.985405
I0824 23:26:45.276067 44210 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0824 23:27:01.929201 44210 solver.cpp:228] Iteration 1320, loss = 0.0216623
I0824 23:27:01.929378 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990758
I0824 23:27:01.929395 44210 solver.cpp:244]     Train net output #1: loss = 0.0216622 (* 1 = 0.0216622 loss)
I0824 23:27:01.929402 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989395
I0824 23:27:01.929407 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99382
I0824 23:27:01.929417 44210 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0824 23:27:18.546473 44210 solver.cpp:228] Iteration 1340, loss = 0.025499
I0824 23:27:18.546519 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991168
I0824 23:27:18.546535 44210 solver.cpp:244]     Train net output #1: loss = 0.0254989 (* 1 = 0.0254989 loss)
I0824 23:27:18.546541 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994256
I0824 23:27:18.546546 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9795
I0824 23:27:18.546555 44210 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0824 23:27:35.163913 44210 solver.cpp:228] Iteration 1360, loss = 0.0235846
I0824 23:27:35.164059 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990955
I0824 23:27:35.164077 44210 solver.cpp:244]     Train net output #1: loss = 0.0235845 (* 1 = 0.0235845 loss)
I0824 23:27:35.164084 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989768
I0824 23:27:35.164091 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99309
I0824 23:27:35.164106 44210 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0824 23:27:51.769114 44210 solver.cpp:228] Iteration 1380, loss = 0.0211887
I0824 23:27:51.769155 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990891
I0824 23:27:51.769166 44210 solver.cpp:244]     Train net output #1: loss = 0.0211886 (* 1 = 0.0211886 loss)
I0824 23:27:51.769172 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988025
I0824 23:27:51.769177 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996058
I0824 23:27:51.769184 44210 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0824 23:28:08.394165 44210 solver.cpp:228] Iteration 1400, loss = 0.0211976
I0824 23:28:08.394284 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991615
I0824 23:28:08.394299 44210 solver.cpp:244]     Train net output #1: loss = 0.0211975 (* 1 = 0.0211975 loss)
I0824 23:28:08.394305 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989973
I0824 23:28:08.394311 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994406
I0824 23:28:08.394320 44210 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0824 23:28:25.002918 44210 solver.cpp:228] Iteration 1420, loss = 0.0212734
I0824 23:28:25.002959 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991098
I0824 23:28:25.002972 44210 solver.cpp:244]     Train net output #1: loss = 0.0212733 (* 1 = 0.0212733 loss)
I0824 23:28:25.002979 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991677
I0824 23:28:25.002984 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988864
I0824 23:28:25.002990 44210 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0824 23:28:41.617089 44210 solver.cpp:228] Iteration 1440, loss = 0.0243787
I0824 23:28:41.617229 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989343
I0824 23:28:41.617269 44210 solver.cpp:244]     Train net output #1: loss = 0.0243786 (* 1 = 0.0243786 loss)
I0824 23:28:41.617278 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986209
I0824 23:28:41.617290 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995384
I0824 23:28:41.617300 44210 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0824 23:28:58.287729 44210 solver.cpp:228] Iteration 1460, loss = 0.0111283
I0824 23:28:58.287776 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995129
I0824 23:28:58.287807 44210 solver.cpp:244]     Train net output #1: loss = 0.0111282 (* 1 = 0.0111282 loss)
I0824 23:28:58.287822 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994534
I0824 23:28:58.287833 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997073
I0824 23:28:58.287840 44210 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0824 23:29:14.918570 44210 solver.cpp:228] Iteration 1480, loss = 0.0152597
I0824 23:29:14.918730 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995373
I0824 23:29:14.918748 44210 solver.cpp:244]     Train net output #1: loss = 0.0152596 (* 1 = 0.0152596 loss)
I0824 23:29:14.918759 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997268
I0824 23:29:14.918771 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986134
I0824 23:29:14.918779 44210 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0824 23:29:31.535383 44210 solver.cpp:228] Iteration 1500, loss = 0.0182475
I0824 23:29:31.535428 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993844
I0824 23:29:31.535441 44210 solver.cpp:244]     Train net output #1: loss = 0.0182474 (* 1 = 0.0182474 loss)
I0824 23:29:31.535449 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99517
I0824 23:29:31.535454 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990377
I0824 23:29:31.535460 44210 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0824 23:29:48.164643 44210 solver.cpp:228] Iteration 1520, loss = 0.0268044
I0824 23:29:48.164765 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989706
I0824 23:29:48.164783 44210 solver.cpp:244]     Train net output #1: loss = 0.0268044 (* 1 = 0.0268044 loss)
I0824 23:29:48.164790 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99119
I0824 23:29:48.164798 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984019
I0824 23:29:48.164806 44210 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0824 23:30:04.807322 44210 solver.cpp:228] Iteration 1540, loss = 0.0221507
I0824 23:30:04.807366 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993346
I0824 23:30:04.807381 44210 solver.cpp:244]     Train net output #1: loss = 0.0221506 (* 1 = 0.0221506 loss)
I0824 23:30:04.807387 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994363
I0824 23:30:04.807394 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.982855
I0824 23:30:04.807401 44210 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0824 23:30:21.451104 44210 solver.cpp:228] Iteration 1560, loss = 0.0264825
I0824 23:30:21.451239 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990216
I0824 23:30:21.451257 44210 solver.cpp:244]     Train net output #1: loss = 0.0264824 (* 1 = 0.0264824 loss)
I0824 23:30:21.451267 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991451
I0824 23:30:21.451280 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98567
I0824 23:30:21.451290 44210 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0824 23:30:38.055479 44210 solver.cpp:228] Iteration 1580, loss = 0.0174983
I0824 23:30:38.055519 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993416
I0824 23:30:38.055534 44210 solver.cpp:244]     Train net output #1: loss = 0.0174983 (* 1 = 0.0174983 loss)
I0824 23:30:38.055541 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992914
I0824 23:30:38.055546 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994569
I0824 23:30:38.055553 44210 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0824 23:30:54.696007 44210 solver.cpp:228] Iteration 1600, loss = 0.0172436
I0824 23:30:54.696136 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993553
I0824 23:30:54.696151 44210 solver.cpp:244]     Train net output #1: loss = 0.0172435 (* 1 = 0.0172435 loss)
I0824 23:30:54.696163 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995178
I0824 23:30:54.696169 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98404
I0824 23:30:54.696178 44210 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0824 23:31:11.312546 44210 solver.cpp:228] Iteration 1620, loss = 0.0204264
I0824 23:31:11.312594 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991288
I0824 23:31:11.312609 44210 solver.cpp:244]     Train net output #1: loss = 0.0204263 (* 1 = 0.0204263 loss)
I0824 23:31:11.312618 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990517
I0824 23:31:11.312623 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992857
I0824 23:31:11.312631 44210 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0824 23:31:27.941830 44210 solver.cpp:228] Iteration 1640, loss = 0.0154647
I0824 23:31:27.941994 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994
I0824 23:31:27.942013 44210 solver.cpp:244]     Train net output #1: loss = 0.0154646 (* 1 = 0.0154646 loss)
I0824 23:31:27.942021 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993333
I0824 23:31:27.942026 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995812
I0824 23:31:27.942034 44210 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0824 23:31:44.572067 44210 solver.cpp:228] Iteration 1660, loss = 0.0146359
I0824 23:31:44.572114 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993721
I0824 23:31:44.572131 44210 solver.cpp:244]     Train net output #1: loss = 0.0146358 (* 1 = 0.0146358 loss)
I0824 23:31:44.572139 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993263
I0824 23:31:44.572144 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995134
I0824 23:31:44.572154 44210 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0824 23:32:01.203583 44210 solver.cpp:228] Iteration 1680, loss = 0.018441
I0824 23:32:01.203711 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992795
I0824 23:32:01.203728 44210 solver.cpp:244]     Train net output #1: loss = 0.018441 (* 1 = 0.018441 loss)
I0824 23:32:01.203735 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994373
I0824 23:32:01.203740 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.986533
I0824 23:32:01.203747 44210 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0824 23:32:17.828239 44210 solver.cpp:228] Iteration 1700, loss = 0.0224454
I0824 23:32:17.828279 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991411
I0824 23:32:17.828294 44210 solver.cpp:244]     Train net output #1: loss = 0.0224453 (* 1 = 0.0224453 loss)
I0824 23:32:17.828310 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990568
I0824 23:32:17.828315 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994093
I0824 23:32:17.828322 44210 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0824 23:32:34.459281 44210 solver.cpp:228] Iteration 1720, loss = 0.0189551
I0824 23:32:34.459444 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992603
I0824 23:32:34.459486 44210 solver.cpp:244]     Train net output #1: loss = 0.0189551 (* 1 = 0.0189551 loss)
I0824 23:32:34.459496 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993352
I0824 23:32:34.459506 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990359
I0824 23:32:34.459517 44210 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0824 23:32:51.076565 44210 solver.cpp:228] Iteration 1740, loss = 0.019478
I0824 23:32:51.076613 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991969
I0824 23:32:51.076628 44210 solver.cpp:244]     Train net output #1: loss = 0.019478 (* 1 = 0.019478 loss)
I0824 23:32:51.076635 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990664
I0824 23:32:51.076642 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994926
I0824 23:32:51.076653 44210 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0824 23:33:07.710259 44210 solver.cpp:228] Iteration 1760, loss = 0.0201775
I0824 23:33:07.710455 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991039
I0824 23:33:07.710489 44210 solver.cpp:244]     Train net output #1: loss = 0.0201774 (* 1 = 0.0201774 loss)
I0824 23:33:07.710497 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988681
I0824 23:33:07.710510 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996087
I0824 23:33:07.710520 44210 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0824 23:33:24.335863 44210 solver.cpp:228] Iteration 1780, loss = 0.0168014
I0824 23:33:24.335909 44210 solver.cpp:244]     Train net output #0: accuracy = 0.9923
I0824 23:33:24.335924 44210 solver.cpp:244]     Train net output #1: loss = 0.0168013 (* 1 = 0.0168013 loss)
I0824 23:33:24.335938 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990415
I0824 23:33:24.335944 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996534
I0824 23:33:24.335953 44210 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0824 23:33:40.951401 44210 solver.cpp:228] Iteration 1800, loss = 0.0170099
I0824 23:33:40.951529 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995441
I0824 23:33:40.951546 44210 solver.cpp:244]     Train net output #1: loss = 0.0170098 (* 1 = 0.0170098 loss)
I0824 23:33:40.951555 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99663
I0824 23:33:40.951566 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.981517
I0824 23:33:40.951575 44210 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0824 23:33:57.636580 44210 solver.cpp:228] Iteration 1820, loss = 0.0171111
I0824 23:33:57.636637 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992843
I0824 23:33:57.636654 44210 solver.cpp:244]     Train net output #1: loss = 0.017111 (* 1 = 0.017111 loss)
I0824 23:33:57.636662 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991285
I0824 23:33:57.636668 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995793
I0824 23:33:57.636678 44210 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0824 23:34:14.302930 44210 solver.cpp:228] Iteration 1840, loss = 0.0197009
I0824 23:34:14.303061 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989981
I0824 23:34:14.303081 44210 solver.cpp:244]     Train net output #1: loss = 0.0197008 (* 1 = 0.0197008 loss)
I0824 23:34:14.303088 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987587
I0824 23:34:14.303094 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995758
I0824 23:34:14.303104 44210 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0824 23:34:30.915393 44210 solver.cpp:228] Iteration 1860, loss = 0.218776
I0824 23:34:30.915443 44210 solver.cpp:244]     Train net output #0: accuracy = 0.960236
I0824 23:34:30.915459 44210 solver.cpp:244]     Train net output #1: loss = 0.218776 (* 1 = 0.218776 loss)
I0824 23:34:30.915472 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.986042
I0824 23:34:30.915483 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.909551
I0824 23:34:30.915499 44210 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0824 23:34:47.533144 44210 solver.cpp:228] Iteration 1880, loss = 0.0441052
I0824 23:34:47.533258 44210 solver.cpp:244]     Train net output #0: accuracy = 0.978828
I0824 23:34:47.533277 44210 solver.cpp:244]     Train net output #1: loss = 0.0441052 (* 1 = 0.0441052 loss)
I0824 23:34:47.533285 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.974748
I0824 23:34:47.533298 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995031
I0824 23:34:47.533308 44210 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0824 23:35:04.162652 44210 solver.cpp:228] Iteration 1900, loss = 0.031316
I0824 23:35:04.162703 44210 solver.cpp:244]     Train net output #0: accuracy = 0.984769
I0824 23:35:04.162717 44210 solver.cpp:244]     Train net output #1: loss = 0.0313159 (* 1 = 0.0313159 loss)
I0824 23:35:04.162730 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.979028
I0824 23:35:04.162736 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995856
I0824 23:35:04.162744 44210 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0824 23:35:20.809658 44210 solver.cpp:228] Iteration 1920, loss = 0.0234641
I0824 23:35:20.809834 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989685
I0824 23:35:20.809857 44210 solver.cpp:244]     Train net output #1: loss = 0.0234641 (* 1 = 0.0234641 loss)
I0824 23:35:20.809865 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985321
I0824 23:35:20.809871 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996993
I0824 23:35:20.809880 44210 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0824 23:35:37.429160 44210 solver.cpp:228] Iteration 1940, loss = 0.0259383
I0824 23:35:37.429208 44210 solver.cpp:244]     Train net output #0: accuracy = 0.987593
I0824 23:35:37.429222 44210 solver.cpp:244]     Train net output #1: loss = 0.0259383 (* 1 = 0.0259383 loss)
I0824 23:35:37.429231 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.983545
I0824 23:35:37.429245 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997702
I0824 23:35:37.429253 44210 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0824 23:35:54.025171 44210 solver.cpp:228] Iteration 1960, loss = 0.0167758
I0824 23:35:54.025292 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992503
I0824 23:35:54.025310 44210 solver.cpp:244]     Train net output #1: loss = 0.0167758 (* 1 = 0.0167758 loss)
I0824 23:35:54.025317 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991736
I0824 23:35:54.025323 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994954
I0824 23:35:54.025331 44210 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0824 23:36:10.665845 44210 solver.cpp:228] Iteration 1980, loss = 0.0186211
I0824 23:36:10.665908 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99226
I0824 23:36:10.665926 44210 solver.cpp:244]     Train net output #1: loss = 0.0186211 (* 1 = 0.0186211 loss)
I0824 23:36:10.665935 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989112
I0824 23:36:10.665946 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997057
I0824 23:36:10.665956 44210 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0824 23:36:27.287782 44210 solver.cpp:228] Iteration 2000, loss = 0.022923
I0824 23:36:27.287935 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993385
I0824 23:36:27.287977 44210 solver.cpp:244]     Train net output #1: loss = 0.0229229 (* 1 = 0.0229229 loss)
I0824 23:36:27.287988 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994598
I0824 23:36:27.287999 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980306
I0824 23:36:27.288009 44210 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0824 23:36:43.927870 44210 solver.cpp:228] Iteration 2020, loss = 0.0314188
I0824 23:36:43.927913 44210 solver.cpp:244]     Train net output #0: accuracy = 0.986655
I0824 23:36:43.927928 44210 solver.cpp:244]     Train net output #1: loss = 0.0314187 (* 1 = 0.0314187 loss)
I0824 23:36:43.927935 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.985883
I0824 23:36:43.927942 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989213
I0824 23:36:43.927952 44210 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0824 23:37:00.560354 44210 solver.cpp:228] Iteration 2040, loss = 0.0282555
I0824 23:37:00.560467 44210 solver.cpp:244]     Train net output #0: accuracy = 0.989771
I0824 23:37:00.560483 44210 solver.cpp:244]     Train net output #1: loss = 0.0282555 (* 1 = 0.0282555 loss)
I0824 23:37:00.560492 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988753
I0824 23:37:00.560499 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991382
I0824 23:37:00.560508 44210 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0824 23:37:17.199318 44210 solver.cpp:228] Iteration 2060, loss = 0.0230043
I0824 23:37:17.199367 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991612
I0824 23:37:17.199381 44210 solver.cpp:244]     Train net output #1: loss = 0.0230043 (* 1 = 0.0230043 loss)
I0824 23:37:17.199389 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988768
I0824 23:37:17.199395 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995341
I0824 23:37:17.199404 44210 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0824 23:37:33.848731 44210 solver.cpp:228] Iteration 2080, loss = 0.0222064
I0824 23:37:33.848896 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0824 23:37:33.848914 44210 solver.cpp:244]     Train net output #1: loss = 0.0222064 (* 1 = 0.0222064 loss)
I0824 23:37:33.848922 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988805
I0824 23:37:33.848928 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993454
I0824 23:37:33.848937 44210 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0824 23:37:50.464208 44210 solver.cpp:228] Iteration 2100, loss = 0.0183166
I0824 23:37:50.464256 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991861
I0824 23:37:50.464270 44210 solver.cpp:244]     Train net output #1: loss = 0.0183165 (* 1 = 0.0183165 loss)
I0824 23:37:50.464278 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990105
I0824 23:37:50.464287 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99567
I0824 23:37:50.464294 44210 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0824 23:38:07.095500 44210 solver.cpp:228] Iteration 2120, loss = 0.0173663
I0824 23:38:07.095634 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994287
I0824 23:38:07.095651 44210 solver.cpp:244]     Train net output #1: loss = 0.0173662 (* 1 = 0.0173662 loss)
I0824 23:38:07.095659 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997027
I0824 23:38:07.095664 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.97668
I0824 23:38:07.095674 44210 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0824 23:38:23.742595 44210 solver.cpp:228] Iteration 2140, loss = 0.0202452
I0824 23:38:23.742642 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993355
I0824 23:38:23.742658 44210 solver.cpp:244]     Train net output #1: loss = 0.0202451 (* 1 = 0.0202451 loss)
I0824 23:38:23.742666 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994478
I0824 23:38:23.742672 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98958
I0824 23:38:23.742681 44210 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0824 23:38:40.376785 44210 solver.cpp:228] Iteration 2160, loss = 0.0182581
I0824 23:38:40.376899 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992122
I0824 23:38:40.376915 44210 solver.cpp:244]     Train net output #1: loss = 0.018258 (* 1 = 0.018258 loss)
I0824 23:38:40.376924 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989527
I0824 23:38:40.376931 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997091
I0824 23:38:40.376955 44210 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0824 23:38:56.999311 44210 solver.cpp:228] Iteration 2180, loss = 0.0204598
I0824 23:38:56.999358 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991233
I0824 23:38:56.999374 44210 solver.cpp:244]     Train net output #1: loss = 0.0204597 (* 1 = 0.0204597 loss)
I0824 23:38:56.999382 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.987102
I0824 23:38:56.999388 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997507
I0824 23:38:56.999397 44210 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0824 23:39:13.633877 44210 solver.cpp:228] Iteration 2200, loss = 0.0207641
I0824 23:39:13.634040 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992111
I0824 23:39:13.634058 44210 solver.cpp:244]     Train net output #1: loss = 0.0207641 (* 1 = 0.0207641 loss)
I0824 23:39:13.634070 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992349
I0824 23:39:13.634076 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991509
I0824 23:39:13.634084 44210 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0824 23:39:30.263490 44210 solver.cpp:228] Iteration 2220, loss = 0.0187907
I0824 23:39:30.263532 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992922
I0824 23:39:30.263547 44210 solver.cpp:244]     Train net output #1: loss = 0.0187907 (* 1 = 0.0187907 loss)
I0824 23:39:30.263556 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993834
I0824 23:39:30.263566 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990478
I0824 23:39:30.263576 44210 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0824 23:39:46.897997 44210 solver.cpp:228] Iteration 2240, loss = 0.0101135
I0824 23:39:46.898125 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995407
I0824 23:39:46.898144 44210 solver.cpp:244]     Train net output #1: loss = 0.0101134 (* 1 = 0.0101134 loss)
I0824 23:39:46.898151 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994842
I0824 23:39:46.898164 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997304
I0824 23:39:46.898175 44210 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0824 23:40:03.596340 44210 solver.cpp:228] Iteration 2260, loss = 0.0182024
I0824 23:40:03.596391 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993019
I0824 23:40:03.596406 44210 solver.cpp:244]     Train net output #1: loss = 0.0182023 (* 1 = 0.0182023 loss)
I0824 23:40:03.596413 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993361
I0824 23:40:03.596424 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992099
I0824 23:40:03.596446 44210 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0824 23:40:20.224213 44210 solver.cpp:228] Iteration 2280, loss = 0.0139612
I0824 23:40:20.224328 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994414
I0824 23:40:20.224345 44210 solver.cpp:244]     Train net output #1: loss = 0.0139612 (* 1 = 0.0139612 loss)
I0824 23:40:20.224352 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993932
I0824 23:40:20.224364 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995749
I0824 23:40:20.224371 44210 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0824 23:40:36.838527 44210 solver.cpp:228] Iteration 2300, loss = 0.0169057
I0824 23:40:36.838568 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992645
I0824 23:40:36.838580 44210 solver.cpp:244]     Train net output #1: loss = 0.0169056 (* 1 = 0.0169056 loss)
I0824 23:40:36.838587 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991489
I0824 23:40:36.838594 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995146
I0824 23:40:36.838603 44210 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0824 23:40:53.455530 44210 solver.cpp:228] Iteration 2320, loss = 0.0136313
I0824 23:40:53.455673 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993876
I0824 23:40:53.455689 44210 solver.cpp:244]     Train net output #1: loss = 0.0136313 (* 1 = 0.0136313 loss)
I0824 23:40:53.455698 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99341
I0824 23:40:53.455703 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995262
I0824 23:40:53.455711 44210 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0824 23:41:10.085271 44210 solver.cpp:228] Iteration 2340, loss = 0.0191444
I0824 23:41:10.085310 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990864
I0824 23:41:10.085324 44210 solver.cpp:244]     Train net output #1: loss = 0.0191443 (* 1 = 0.0191443 loss)
I0824 23:41:10.085330 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988481
I0824 23:41:10.085336 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997396
I0824 23:41:10.085345 44210 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0824 23:41:26.700229 44210 solver.cpp:228] Iteration 2360, loss = 0.0105395
I0824 23:41:26.700423 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99547
I0824 23:41:26.700439 44210 solver.cpp:244]     Train net output #1: loss = 0.0105394 (* 1 = 0.0105394 loss)
I0824 23:41:26.700448 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995069
I0824 23:41:26.700459 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996945
I0824 23:41:26.700467 44210 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0824 23:41:43.316846 44210 solver.cpp:228] Iteration 2380, loss = 0.0137649
I0824 23:41:43.316890 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995059
I0824 23:41:43.316905 44210 solver.cpp:244]     Train net output #1: loss = 0.0137648 (* 1 = 0.0137648 loss)
I0824 23:41:43.316910 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995872
I0824 23:41:43.316916 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992601
I0824 23:41:43.316926 44210 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0824 23:41:59.914974 44210 solver.cpp:228] Iteration 2400, loss = 0.0139514
I0824 23:41:59.915112 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994559
I0824 23:41:59.915127 44210 solver.cpp:244]     Train net output #1: loss = 0.0139513 (* 1 = 0.0139513 loss)
I0824 23:41:59.915136 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993479
I0824 23:41:59.915146 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996477
I0824 23:41:59.915154 44210 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0824 23:42:16.532629 44210 solver.cpp:228] Iteration 2420, loss = 0.0156456
I0824 23:42:16.532675 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995815
I0824 23:42:16.532690 44210 solver.cpp:244]     Train net output #1: loss = 0.0156456 (* 1 = 0.0156456 loss)
I0824 23:42:16.532696 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996456
I0824 23:42:16.532701 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987213
I0824 23:42:16.532709 44210 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0824 23:42:33.139057 44210 solver.cpp:228] Iteration 2440, loss = 0.0182445
I0824 23:42:33.139219 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992701
I0824 23:42:33.139261 44210 solver.cpp:244]     Train net output #1: loss = 0.0182445 (* 1 = 0.0182445 loss)
I0824 23:42:33.139269 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991994
I0824 23:42:33.139297 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995174
I0824 23:42:33.139308 44210 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0824 23:42:49.810771 44210 solver.cpp:228] Iteration 2460, loss = 0.0164549
I0824 23:42:49.810817 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992999
I0824 23:42:49.810832 44210 solver.cpp:244]     Train net output #1: loss = 0.0164549 (* 1 = 0.0164549 loss)
I0824 23:42:49.810839 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991404
I0824 23:42:49.810845 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996342
I0824 23:42:49.810854 44210 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0824 23:43:06.438225 44210 solver.cpp:228] Iteration 2480, loss = 0.0167321
I0824 23:43:06.438374 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993954
I0824 23:43:06.438391 44210 solver.cpp:244]     Train net output #1: loss = 0.0167321 (* 1 = 0.0167321 loss)
I0824 23:43:06.438403 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994913
I0824 23:43:06.438416 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990506
I0824 23:43:06.438424 44210 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0824 23:43:23.067754 44210 solver.cpp:228] Iteration 2500, loss = 0.0161652
I0824 23:43:23.067803 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993087
I0824 23:43:23.067818 44210 solver.cpp:244]     Train net output #1: loss = 0.0161651 (* 1 = 0.0161651 loss)
I0824 23:43:23.067826 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992367
I0824 23:43:23.067832 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994901
I0824 23:43:23.067842 44210 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0824 23:43:39.742179 44210 solver.cpp:228] Iteration 2520, loss = 0.0119218
I0824 23:43:39.742393 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995381
I0824 23:43:39.742413 44210 solver.cpp:244]     Train net output #1: loss = 0.0119218 (* 1 = 0.0119218 loss)
I0824 23:43:39.742424 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994878
I0824 23:43:39.742430 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996469
I0824 23:43:39.742439 44210 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0824 23:43:56.345242 44210 solver.cpp:228] Iteration 2540, loss = 0.0187443
I0824 23:43:56.345288 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992423
I0824 23:43:56.345304 44210 solver.cpp:244]     Train net output #1: loss = 0.0187443 (* 1 = 0.0187443 loss)
I0824 23:43:56.345311 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992276
I0824 23:43:56.345317 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992787
I0824 23:43:56.345325 44210 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0824 23:44:12.966444 44210 solver.cpp:228] Iteration 2560, loss = 0.0134636
I0824 23:44:12.966601 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994109
I0824 23:44:12.966640 44210 solver.cpp:244]     Train net output #1: loss = 0.0134636 (* 1 = 0.0134636 loss)
I0824 23:44:12.966650 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992964
I0824 23:44:12.966660 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996935
I0824 23:44:12.966671 44210 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0824 23:44:29.618353 44210 solver.cpp:228] Iteration 2580, loss = 0.0165184
I0824 23:44:29.618409 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992834
I0824 23:44:29.618430 44210 solver.cpp:244]     Train net output #1: loss = 0.0165184 (* 1 = 0.0165184 loss)
I0824 23:44:29.618440 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990061
I0824 23:44:29.618453 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997316
I0824 23:44:29.618463 44210 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0824 23:44:46.244170 44210 solver.cpp:228] Iteration 2600, loss = 0.0139681
I0824 23:44:46.244302 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995178
I0824 23:44:46.244318 44210 solver.cpp:244]     Train net output #1: loss = 0.013968 (* 1 = 0.013968 loss)
I0824 23:44:46.244325 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996868
I0824 23:44:46.244331 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.980809
I0824 23:44:46.244340 44210 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0824 23:45:02.869328 44210 solver.cpp:228] Iteration 2620, loss = 0.0157734
I0824 23:45:02.869400 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993225
I0824 23:45:02.869423 44210 solver.cpp:244]     Train net output #1: loss = 0.0157733 (* 1 = 0.0157733 loss)
I0824 23:45:02.869431 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991691
I0824 23:45:02.869438 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996074
I0824 23:45:02.869446 44210 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0824 23:45:19.515380 44210 solver.cpp:228] Iteration 2640, loss = 0.0130183
I0824 23:45:19.515511 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994799
I0824 23:45:19.515527 44210 solver.cpp:244]     Train net output #1: loss = 0.0130182 (* 1 = 0.0130182 loss)
I0824 23:45:19.515535 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994326
I0824 23:45:19.515542 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995705
I0824 23:45:19.515549 44210 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0824 23:45:36.132690 44210 solver.cpp:228] Iteration 2660, loss = 0.0171952
I0824 23:45:36.132740 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992497
I0824 23:45:36.132755 44210 solver.cpp:244]     Train net output #1: loss = 0.0171951 (* 1 = 0.0171951 loss)
I0824 23:45:36.132761 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.990809
I0824 23:45:36.132767 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99583
I0824 23:45:36.132776 44210 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0824 23:45:52.743999 44210 solver.cpp:228] Iteration 2680, loss = 0.0130923
I0824 23:45:52.744210 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994686
I0824 23:45:52.744247 44210 solver.cpp:244]     Train net output #1: loss = 0.0130923 (* 1 = 0.0130923 loss)
I0824 23:45:52.744257 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994112
I0824 23:45:52.744268 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995847
I0824 23:45:52.744277 44210 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0824 23:46:09.367292 44210 solver.cpp:228] Iteration 2700, loss = 0.0114065
I0824 23:46:09.367337 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995336
I0824 23:46:09.367354 44210 solver.cpp:244]     Train net output #1: loss = 0.0114064 (* 1 = 0.0114064 loss)
I0824 23:46:09.367362 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99563
I0824 23:46:09.367368 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994394
I0824 23:46:09.367377 44210 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0824 23:46:26.001672 44210 solver.cpp:228] Iteration 2720, loss = 0.0124813
I0824 23:46:26.001844 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994967
I0824 23:46:26.001884 44210 solver.cpp:244]     Train net output #1: loss = 0.0124812 (* 1 = 0.0124812 loss)
I0824 23:46:26.001894 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99501
I0824 23:46:26.001904 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994871
I0824 23:46:26.001911 44210 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0824 23:46:42.637245 44210 solver.cpp:228] Iteration 2740, loss = 0.0134878
I0824 23:46:42.637295 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99468
I0824 23:46:42.637312 44210 solver.cpp:244]     Train net output #1: loss = 0.0134878 (* 1 = 0.0134878 loss)
I0824 23:46:42.637320 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995237
I0824 23:46:42.637326 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99299
I0824 23:46:42.637334 44210 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0824 23:46:59.280522 44210 solver.cpp:228] Iteration 2760, loss = 0.0139167
I0824 23:46:59.280653 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995185
I0824 23:46:59.280674 44210 solver.cpp:244]     Train net output #1: loss = 0.0139166 (* 1 = 0.0139166 loss)
I0824 23:46:59.280683 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996251
I0824 23:46:59.280694 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991517
I0824 23:46:59.280709 44210 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0824 23:47:15.898339 44210 solver.cpp:228] Iteration 2780, loss = 0.013473
I0824 23:47:15.898380 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995733
I0824 23:47:15.898392 44210 solver.cpp:244]     Train net output #1: loss = 0.013473 (* 1 = 0.013473 loss)
I0824 23:47:15.898401 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996208
I0824 23:47:15.898416 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994037
I0824 23:47:15.898423 44210 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0824 23:47:32.535254 44210 solver.cpp:228] Iteration 2800, loss = 0.0110556
I0824 23:47:32.535460 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995168
I0824 23:47:32.535496 44210 solver.cpp:244]     Train net output #1: loss = 0.0110555 (* 1 = 0.0110555 loss)
I0824 23:47:32.535509 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99504
I0824 23:47:32.535521 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995613
I0824 23:47:32.535528 44210 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0824 23:47:49.174679 44210 solver.cpp:228] Iteration 2820, loss = 0.0189417
I0824 23:47:49.174723 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992582
I0824 23:47:49.174736 44210 solver.cpp:244]     Train net output #1: loss = 0.0189416 (* 1 = 0.0189416 loss)
I0824 23:47:49.174744 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991628
I0824 23:47:49.174758 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994178
I0824 23:47:49.174767 44210 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0824 23:48:05.795286 44210 solver.cpp:228] Iteration 2840, loss = 0.0161476
I0824 23:48:05.795428 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992496
I0824 23:48:05.795445 44210 solver.cpp:244]     Train net output #1: loss = 0.0161475 (* 1 = 0.0161475 loss)
I0824 23:48:05.795454 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991694
I0824 23:48:05.795459 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994672
I0824 23:48:05.795469 44210 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0824 23:48:22.417244 44210 solver.cpp:228] Iteration 2860, loss = 0.0162191
I0824 23:48:22.417290 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993322
I0824 23:48:22.417305 44210 solver.cpp:244]     Train net output #1: loss = 0.016219 (* 1 = 0.016219 loss)
I0824 23:48:22.417311 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992381
I0824 23:48:22.417317 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995939
I0824 23:48:22.417325 44210 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0824 23:48:39.099236 44210 solver.cpp:228] Iteration 2880, loss = 0.00870753
I0824 23:48:39.099380 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996573
I0824 23:48:39.099412 44210 solver.cpp:244]     Train net output #1: loss = 0.00870747 (* 1 = 0.00870747 loss)
I0824 23:48:39.099421 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997062
I0824 23:48:39.099433 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994611
I0824 23:48:39.099440 44210 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0824 23:48:55.777693 44210 solver.cpp:228] Iteration 2900, loss = 0.0128165
I0824 23:48:55.777742 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994965
I0824 23:48:55.777756 44210 solver.cpp:244]     Train net output #1: loss = 0.0128164 (* 1 = 0.0128164 loss)
I0824 23:48:55.777765 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994093
I0824 23:48:55.777770 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997629
I0824 23:48:55.777781 44210 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0824 23:49:12.476083 44210 solver.cpp:228] Iteration 2920, loss = 0.0127674
I0824 23:49:12.476200 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995172
I0824 23:49:12.476223 44210 solver.cpp:244]     Train net output #1: loss = 0.0127673 (* 1 = 0.0127673 loss)
I0824 23:49:12.476233 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994764
I0824 23:49:12.476245 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995837
I0824 23:49:12.476256 44210 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0824 23:49:29.145076 44210 solver.cpp:228] Iteration 2940, loss = 0.0147365
I0824 23:49:29.145123 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994498
I0824 23:49:29.145138 44210 solver.cpp:244]     Train net output #1: loss = 0.0147364 (* 1 = 0.0147364 loss)
I0824 23:49:29.145145 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995581
I0824 23:49:29.145153 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989741
I0824 23:49:29.145162 44210 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0824 23:49:45.785993 44210 solver.cpp:228] Iteration 2960, loss = 0.0193045
I0824 23:49:45.786180 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992296
I0824 23:49:45.786198 44210 solver.cpp:244]     Train net output #1: loss = 0.0193044 (* 1 = 0.0193044 loss)
I0824 23:49:45.786211 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993153
I0824 23:49:45.786216 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.988561
I0824 23:49:45.786226 44210 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0824 23:50:02.454741 44210 solver.cpp:228] Iteration 2980, loss = 0.00960248
I0824 23:50:02.454787 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996422
I0824 23:50:02.454802 44210 solver.cpp:244]     Train net output #1: loss = 0.00960242 (* 1 = 0.00960242 loss)
I0824 23:50:02.454808 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996491
I0824 23:50:02.454816 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99628
I0824 23:50:02.454833 44210 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0824 23:50:19.116631 44210 solver.cpp:228] Iteration 3000, loss = 0.0107485
I0824 23:50:19.116758 44210 solver.cpp:244]     Train net output #0: accuracy = 0.9958
I0824 23:50:19.116776 44210 solver.cpp:244]     Train net output #1: loss = 0.0107484 (* 1 = 0.0107484 loss)
I0824 23:50:19.116786 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996536
I0824 23:50:19.116797 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992476
I0824 23:50:19.116806 44210 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0824 23:50:35.767957 44210 solver.cpp:228] Iteration 3020, loss = 0.0130986
I0824 23:50:35.768002 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995833
I0824 23:50:35.768015 44210 solver.cpp:244]     Train net output #1: loss = 0.0130985 (* 1 = 0.0130985 loss)
I0824 23:50:35.768023 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997198
I0824 23:50:35.768029 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990985
I0824 23:50:35.768038 44210 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0824 23:50:52.385893 44210 solver.cpp:228] Iteration 3040, loss = 0.0157575
I0824 23:50:52.386093 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994271
I0824 23:50:52.386111 44210 solver.cpp:244]     Train net output #1: loss = 0.0157575 (* 1 = 0.0157575 loss)
I0824 23:50:52.386119 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994479
I0824 23:50:52.386131 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993928
I0824 23:50:52.386145 44210 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0824 23:51:09.017282 44210 solver.cpp:228] Iteration 3060, loss = 0.0141707
I0824 23:51:09.017320 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993916
I0824 23:51:09.017334 44210 solver.cpp:244]     Train net output #1: loss = 0.0141707 (* 1 = 0.0141707 loss)
I0824 23:51:09.017343 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992836
I0824 23:51:09.017359 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996133
I0824 23:51:09.017381 44210 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0824 23:51:25.672667 44210 solver.cpp:228] Iteration 3080, loss = 0.0170467
I0824 23:51:25.672788 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992894
I0824 23:51:25.672806 44210 solver.cpp:244]     Train net output #1: loss = 0.0170466 (* 1 = 0.0170466 loss)
I0824 23:51:25.672812 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992848
I0824 23:51:25.672818 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993014
I0824 23:51:25.672828 44210 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0824 23:51:42.338363 44210 solver.cpp:228] Iteration 3100, loss = 0.0134283
I0824 23:51:42.338412 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996152
I0824 23:51:42.338428 44210 solver.cpp:244]     Train net output #1: loss = 0.0134283 (* 1 = 0.0134283 loss)
I0824 23:51:42.338434 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996902
I0824 23:51:42.338440 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.98329
I0824 23:51:42.338449 44210 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0824 23:51:58.963001 44210 solver.cpp:228] Iteration 3120, loss = 0.0109416
I0824 23:51:58.963172 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994792
I0824 23:51:58.963202 44210 solver.cpp:244]     Train net output #1: loss = 0.0109415 (* 1 = 0.0109415 loss)
I0824 23:51:58.963210 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993464
I0824 23:51:58.963217 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9981
I0824 23:51:58.963227 44210 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0824 23:52:15.631975 44210 solver.cpp:228] Iteration 3140, loss = 0.0126158
I0824 23:52:15.632030 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994964
I0824 23:52:15.632047 44210 solver.cpp:244]     Train net output #1: loss = 0.0126158 (* 1 = 0.0126158 loss)
I0824 23:52:15.632055 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995373
I0824 23:52:15.632068 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993216
I0824 23:52:15.632091 44210 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0824 23:52:32.322751 44210 solver.cpp:228] Iteration 3160, loss = 0.0081887
I0824 23:52:32.322882 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996804
I0824 23:52:32.322917 44210 solver.cpp:244]     Train net output #1: loss = 0.00818864 (* 1 = 0.00818864 loss)
I0824 23:52:32.322927 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99675
I0824 23:52:32.322933 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99693
I0824 23:52:32.322942 44210 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0824 23:52:49.016162 44210 solver.cpp:228] Iteration 3180, loss = 0.015018
I0824 23:52:49.016211 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994009
I0824 23:52:49.016227 44210 solver.cpp:244]     Train net output #1: loss = 0.0150179 (* 1 = 0.0150179 loss)
I0824 23:52:49.016243 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994361
I0824 23:52:49.016255 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992955
I0824 23:52:49.016269 44210 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0824 23:53:05.680248 44210 solver.cpp:228] Iteration 3200, loss = 0.00955751
I0824 23:53:05.680366 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996587
I0824 23:53:05.680383 44210 solver.cpp:244]     Train net output #1: loss = 0.00955745 (* 1 = 0.00955745 loss)
I0824 23:53:05.680394 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997548
I0824 23:53:05.680404 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993504
I0824 23:53:05.680414 44210 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0824 23:53:22.334949 44210 solver.cpp:228] Iteration 3220, loss = 0.0154608
I0824 23:53:22.334991 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994761
I0824 23:53:22.335006 44210 solver.cpp:244]     Train net output #1: loss = 0.0154607 (* 1 = 0.0154607 loss)
I0824 23:53:22.335021 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995635
I0824 23:53:22.335033 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993357
I0824 23:53:22.335048 44210 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0824 23:53:39.006803 44210 solver.cpp:228] Iteration 3240, loss = 0.0193756
I0824 23:53:39.006914 44210 solver.cpp:244]     Train net output #0: accuracy = 0.990823
I0824 23:53:39.006932 44210 solver.cpp:244]     Train net output #1: loss = 0.0193755 (* 1 = 0.0193755 loss)
I0824 23:53:39.006942 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.988974
I0824 23:53:39.006954 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99592
I0824 23:53:39.006963 44210 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0824 23:53:55.634511 44210 solver.cpp:228] Iteration 3260, loss = 0.0139765
I0824 23:53:55.634555 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994473
I0824 23:53:55.634569 44210 solver.cpp:244]     Train net output #1: loss = 0.0139764 (* 1 = 0.0139764 loss)
I0824 23:53:55.634577 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993015
I0824 23:53:55.634583 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997241
I0824 23:53:55.634593 44210 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0824 23:54:12.310577 44210 solver.cpp:228] Iteration 3280, loss = 0.011157
I0824 23:54:12.310719 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996162
I0824 23:54:12.310739 44210 solver.cpp:244]     Train net output #1: loss = 0.0111569 (* 1 = 0.0111569 loss)
I0824 23:54:12.310746 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99766
I0824 23:54:12.310752 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.987002
I0824 23:54:12.310761 44210 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0824 23:54:28.978652 44210 solver.cpp:228] Iteration 3300, loss = 0.0223687
I0824 23:54:28.978703 44210 solver.cpp:244]     Train net output #0: accuracy = 0.991539
I0824 23:54:28.978718 44210 solver.cpp:244]     Train net output #1: loss = 0.0223687 (* 1 = 0.0223687 loss)
I0824 23:54:28.978725 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992309
I0824 23:54:28.978746 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989981
I0824 23:54:28.978757 44210 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0824 23:54:45.676442 44210 solver.cpp:228] Iteration 3320, loss = 0.0131353
I0824 23:54:45.676589 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995013
I0824 23:54:45.676617 44210 solver.cpp:244]     Train net output #1: loss = 0.0131352 (* 1 = 0.0131352 loss)
I0824 23:54:45.676630 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994904
I0824 23:54:45.676637 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995414
I0824 23:54:45.676647 44210 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0824 23:55:02.362066 44210 solver.cpp:228] Iteration 3340, loss = 0.011238
I0824 23:55:02.362125 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995702
I0824 23:55:02.362145 44210 solver.cpp:244]     Train net output #1: loss = 0.0112379 (* 1 = 0.0112379 loss)
I0824 23:55:02.362155 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995128
I0824 23:55:02.362169 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996775
I0824 23:55:02.362185 44210 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0824 23:55:19.003125 44210 solver.cpp:228] Iteration 3360, loss = 0.0180335
I0824 23:55:19.003237 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993608
I0824 23:55:19.003255 44210 solver.cpp:244]     Train net output #1: loss = 0.0180335 (* 1 = 0.0180335 loss)
I0824 23:55:19.003262 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994407
I0824 23:55:19.003269 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992275
I0824 23:55:19.003279 44210 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0824 23:55:35.653348 44210 solver.cpp:228] Iteration 3380, loss = 0.0167471
I0824 23:55:35.653403 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993349
I0824 23:55:35.653419 44210 solver.cpp:244]     Train net output #1: loss = 0.016747 (* 1 = 0.016747 loss)
I0824 23:55:35.653427 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994586
I0824 23:55:35.653434 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989581
I0824 23:55:35.653443 44210 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0824 23:55:52.288391 44210 solver.cpp:228] Iteration 3400, loss = 0.0177166
I0824 23:55:52.288578 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994132
I0824 23:55:52.288616 44210 solver.cpp:244]     Train net output #1: loss = 0.0177165 (* 1 = 0.0177165 loss)
I0824 23:55:52.288624 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996385
I0824 23:55:52.288630 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.984469
I0824 23:55:52.288640 44210 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0824 23:56:08.948026 44210 solver.cpp:228] Iteration 3420, loss = 0.0135599
I0824 23:56:08.948104 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993639
I0824 23:56:08.948122 44210 solver.cpp:244]     Train net output #1: loss = 0.0135599 (* 1 = 0.0135599 loss)
I0824 23:56:08.948133 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.991607
I0824 23:56:08.948144 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997726
I0824 23:56:08.948154 44210 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0824 23:56:25.602674 44210 solver.cpp:228] Iteration 3440, loss = 0.0146404
I0824 23:56:25.602793 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993394
I0824 23:56:25.602811 44210 solver.cpp:244]     Train net output #1: loss = 0.0146403 (* 1 = 0.0146403 loss)
I0824 23:56:25.602820 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992126
I0824 23:56:25.602846 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99619
I0824 23:56:25.602857 44210 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0824 23:56:42.231704 44210 solver.cpp:228] Iteration 3460, loss = 0.0132811
I0824 23:56:42.231752 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994928
I0824 23:56:42.231770 44210 solver.cpp:244]     Train net output #1: loss = 0.013281 (* 1 = 0.013281 loss)
I0824 23:56:42.231778 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995858
I0824 23:56:42.231792 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.989172
I0824 23:56:42.231808 44210 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0824 23:56:58.851938 44210 solver.cpp:228] Iteration 3480, loss = 0.0147309
I0824 23:56:58.852066 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994646
I0824 23:56:58.852087 44210 solver.cpp:244]     Train net output #1: loss = 0.0147309 (* 1 = 0.0147309 loss)
I0824 23:56:58.852095 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993532
I0824 23:56:58.852107 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99641
I0824 23:56:58.852116 44210 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0824 23:57:15.494138 44210 solver.cpp:228] Iteration 3500, loss = 0.0100217
I0824 23:57:15.494180 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996036
I0824 23:57:15.494195 44210 solver.cpp:244]     Train net output #1: loss = 0.0100217 (* 1 = 0.0100217 loss)
I0824 23:57:15.494209 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996735
I0824 23:57:15.494221 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993063
I0824 23:57:15.494237 44210 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0824 23:57:32.111408 44210 solver.cpp:228] Iteration 3520, loss = 0.0104255
I0824 23:57:32.111519 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995441
I0824 23:57:32.111537 44210 solver.cpp:244]     Train net output #1: loss = 0.0104254 (* 1 = 0.0104254 loss)
I0824 23:57:32.111546 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994897
I0824 23:57:32.111558 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.9968
I0824 23:57:32.111569 44210 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0824 23:57:48.759994 44210 solver.cpp:228] Iteration 3540, loss = 0.0146048
I0824 23:57:48.760038 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993659
I0824 23:57:48.760053 44210 solver.cpp:244]     Train net output #1: loss = 0.0146048 (* 1 = 0.0146048 loss)
I0824 23:57:48.760066 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992142
I0824 23:57:48.760079 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996498
I0824 23:57:48.760102 44210 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0824 23:58:05.540427 44210 solver.cpp:228] Iteration 3560, loss = 0.00917226
I0824 23:58:05.540598 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996047
I0824 23:58:05.540617 44210 solver.cpp:244]     Train net output #1: loss = 0.0091722 (* 1 = 0.0091722 loss)
I0824 23:58:05.540626 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995966
I0824 23:58:05.540632 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996324
I0824 23:58:05.540648 44210 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0824 23:58:22.191563 44210 solver.cpp:228] Iteration 3580, loss = 0.0143743
I0824 23:58:22.191612 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994379
I0824 23:58:22.191627 44210 solver.cpp:244]     Train net output #1: loss = 0.0143743 (* 1 = 0.0143743 loss)
I0824 23:58:22.191635 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994131
I0824 23:58:22.191642 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995018
I0824 23:58:22.191651 44210 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0824 23:58:38.842159 44210 solver.cpp:228] Iteration 3600, loss = 0.00986229
I0824 23:58:38.842281 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996309
I0824 23:58:38.842308 44210 solver.cpp:244]     Train net output #1: loss = 0.00986223 (* 1 = 0.00986223 loss)
I0824 23:58:38.842319 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997176
I0824 23:58:38.842329 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.990988
I0824 23:58:38.842345 44210 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0824 23:58:55.482363 44210 solver.cpp:228] Iteration 3620, loss = 0.0104085
I0824 23:58:55.482405 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994935
I0824 23:58:55.482420 44210 solver.cpp:244]     Train net output #1: loss = 0.0104084 (* 1 = 0.0104084 loss)
I0824 23:58:55.482427 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993185
I0824 23:58:55.482434 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.999041
I0824 23:58:55.482444 44210 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0824 23:59:12.172096 44210 solver.cpp:228] Iteration 3640, loss = 0.0124777
I0824 23:59:12.172224 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994696
I0824 23:59:12.172250 44210 solver.cpp:244]     Train net output #1: loss = 0.0124777 (* 1 = 0.0124777 loss)
I0824 23:59:12.172263 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993797
I0824 23:59:12.172276 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996777
I0824 23:59:12.172291 44210 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0824 23:59:28.858438 44210 solver.cpp:228] Iteration 3660, loss = 0.0100087
I0824 23:59:28.858494 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995968
I0824 23:59:28.858516 44210 solver.cpp:244]     Train net output #1: loss = 0.0100086 (* 1 = 0.0100086 loss)
I0824 23:59:28.858526 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996551
I0824 23:59:28.858537 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993949
I0824 23:59:28.858547 44210 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0824 23:59:45.510223 44210 solver.cpp:228] Iteration 3680, loss = 0.0111126
I0824 23:59:45.510337 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995404
I0824 23:59:45.510354 44210 solver.cpp:244]     Train net output #1: loss = 0.0111125 (* 1 = 0.0111125 loss)
I0824 23:59:45.510360 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995791
I0824 23:59:45.510367 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994229
I0824 23:59:45.510375 44210 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0825 00:00:02.131686 44210 solver.cpp:228] Iteration 3700, loss = 0.0116478
I0825 00:00:02.131734 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995893
I0825 00:00:02.131747 44210 solver.cpp:244]     Train net output #1: loss = 0.0116477 (* 1 = 0.0116477 loss)
I0825 00:00:02.131755 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996265
I0825 00:00:02.131762 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995132
I0825 00:00:02.131770 44210 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0825 00:00:18.772122 44210 solver.cpp:228] Iteration 3720, loss = 0.0119031
I0825 00:00:18.772282 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995632
I0825 00:00:18.772305 44210 solver.cpp:244]     Train net output #1: loss = 0.011903 (* 1 = 0.011903 loss)
I0825 00:00:18.772315 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995919
I0825 00:00:18.772325 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99432
I0825 00:00:18.772334 44210 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0825 00:00:35.412678 44210 solver.cpp:228] Iteration 3740, loss = 0.014692
I0825 00:00:35.412731 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994359
I0825 00:00:35.412746 44210 solver.cpp:244]     Train net output #1: loss = 0.0146919 (* 1 = 0.0146919 loss)
I0825 00:00:35.412760 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992925
I0825 00:00:35.412768 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996377
I0825 00:00:35.412781 44210 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0825 00:00:52.041842 44210 solver.cpp:228] Iteration 3760, loss = 0.00825344
I0825 00:00:52.041960 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996586
I0825 00:00:52.041978 44210 solver.cpp:244]     Train net output #1: loss = 0.00825338 (* 1 = 0.00825338 loss)
I0825 00:00:52.041986 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99592
I0825 00:00:52.041992 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997908
I0825 00:00:52.042002 44210 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0825 00:01:08.715395 44210 solver.cpp:228] Iteration 3780, loss = 0.0105645
I0825 00:01:08.715448 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995108
I0825 00:01:08.715466 44210 solver.cpp:244]     Train net output #1: loss = 0.0105644 (* 1 = 0.0105644 loss)
I0825 00:01:08.715488 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994245
I0825 00:01:08.715497 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997132
I0825 00:01:08.715512 44210 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0825 00:01:25.355970 44210 solver.cpp:228] Iteration 3800, loss = 0.012873
I0825 00:01:25.356096 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993999
I0825 00:01:25.356114 44210 solver.cpp:244]     Train net output #1: loss = 0.0128729 (* 1 = 0.0128729 loss)
I0825 00:01:25.356122 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992598
I0825 00:01:25.356127 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997218
I0825 00:01:25.356135 44210 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0825 00:01:42.135231 44210 solver.cpp:228] Iteration 3820, loss = 0.0103235
I0825 00:01:42.135283 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995605
I0825 00:01:42.135313 44210 solver.cpp:244]     Train net output #1: loss = 0.0103234 (* 1 = 0.0103234 loss)
I0825 00:01:42.135323 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994243
I0825 00:01:42.135334 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998037
I0825 00:01:42.135344 44210 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0825 00:01:58.782471 44210 solver.cpp:228] Iteration 3840, loss = 0.0123186
I0825 00:01:58.782625 44210 solver.cpp:244]     Train net output #0: accuracy = 0.9951
I0825 00:01:58.782644 44210 solver.cpp:244]     Train net output #1: loss = 0.0123185 (* 1 = 0.0123185 loss)
I0825 00:01:58.782654 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99587
I0825 00:01:58.782665 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992555
I0825 00:01:58.782673 44210 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0825 00:02:15.412324 44210 solver.cpp:228] Iteration 3860, loss = 0.0114466
I0825 00:02:15.412384 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995511
I0825 00:02:15.412400 44210 solver.cpp:244]     Train net output #1: loss = 0.0114465 (* 1 = 0.0114465 loss)
I0825 00:02:15.412408 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996012
I0825 00:02:15.412420 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991485
I0825 00:02:15.412436 44210 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0825 00:02:32.081571 44210 solver.cpp:228] Iteration 3880, loss = 0.0150309
I0825 00:02:32.081814 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993407
I0825 00:02:32.081848 44210 solver.cpp:244]     Train net output #1: loss = 0.0150308 (* 1 = 0.0150308 loss)
I0825 00:02:32.081857 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992782
I0825 00:02:32.081869 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99548
I0825 00:02:32.081883 44210 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0825 00:02:48.733160 44210 solver.cpp:228] Iteration 3900, loss = 0.0117767
I0825 00:02:48.733211 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995518
I0825 00:02:48.733227 44210 solver.cpp:244]     Train net output #1: loss = 0.0117767 (* 1 = 0.0117767 loss)
I0825 00:02:48.733233 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994566
I0825 00:02:48.733243 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997027
I0825 00:02:48.733258 44210 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0825 00:03:05.363159 44210 solver.cpp:228] Iteration 3920, loss = 0.00794775
I0825 00:03:05.363308 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996995
I0825 00:03:05.363327 44210 solver.cpp:244]     Train net output #1: loss = 0.00794769 (* 1 = 0.00794769 loss)
I0825 00:03:05.363342 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99687
I0825 00:03:05.363353 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997257
I0825 00:03:05.363364 44210 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0825 00:03:22.002248 44210 solver.cpp:228] Iteration 3940, loss = 0.00931249
I0825 00:03:22.002300 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996198
I0825 00:03:22.002316 44210 solver.cpp:244]     Train net output #1: loss = 0.00931243 (* 1 = 0.00931243 loss)
I0825 00:03:22.002324 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996408
I0825 00:03:22.002331 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995433
I0825 00:03:22.002338 44210 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0825 00:03:38.637451 44210 solver.cpp:228] Iteration 3960, loss = 0.0103464
I0825 00:03:38.637627 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996379
I0825 00:03:38.637645 44210 solver.cpp:244]     Train net output #1: loss = 0.0103463 (* 1 = 0.0103463 loss)
I0825 00:03:38.637652 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996224
I0825 00:03:38.637658 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996652
I0825 00:03:38.637672 44210 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0825 00:03:55.326215 44210 solver.cpp:228] Iteration 3980, loss = 0.0148593
I0825 00:03:55.326273 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994446
I0825 00:03:55.326289 44210 solver.cpp:244]     Train net output #1: loss = 0.0148592 (* 1 = 0.0148592 loss)
I0825 00:03:55.326297 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995402
I0825 00:03:55.326303 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.991185
I0825 00:03:55.326328 44210 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0825 00:04:12.023468 44210 solver.cpp:228] Iteration 4000, loss = 0.0123074
I0825 00:04:12.023695 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995363
I0825 00:04:12.023718 44210 solver.cpp:244]     Train net output #1: loss = 0.0123073 (* 1 = 0.0123073 loss)
I0825 00:04:12.023730 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995098
I0825 00:04:12.023746 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996008
I0825 00:04:12.023756 44210 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0825 00:04:28.705780 44210 solver.cpp:228] Iteration 4020, loss = 0.00854097
I0825 00:04:28.705835 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996262
I0825 00:04:28.705855 44210 solver.cpp:244]     Train net output #1: loss = 0.00854091 (* 1 = 0.00854091 loss)
I0825 00:04:28.705871 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995857
I0825 00:04:28.705881 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997501
I0825 00:04:28.705890 44210 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0825 00:04:45.394196 44210 solver.cpp:228] Iteration 4040, loss = 0.00976265
I0825 00:04:45.394342 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995655
I0825 00:04:45.394378 44210 solver.cpp:244]     Train net output #1: loss = 0.00976259 (* 1 = 0.00976259 loss)
I0825 00:04:45.394387 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995411
I0825 00:04:45.394395 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996386
I0825 00:04:45.394405 44210 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0825 00:05:02.028503 44210 solver.cpp:228] Iteration 4060, loss = 0.011938
I0825 00:05:02.028565 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995032
I0825 00:05:02.028589 44210 solver.cpp:244]     Train net output #1: loss = 0.011938 (* 1 = 0.011938 loss)
I0825 00:05:02.028597 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995713
I0825 00:05:02.028614 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992225
I0825 00:05:02.028625 44210 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0825 00:05:18.657277 44210 solver.cpp:228] Iteration 4080, loss = 0.0149611
I0825 00:05:18.657433 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994
I0825 00:05:18.657452 44210 solver.cpp:244]     Train net output #1: loss = 0.014961 (* 1 = 0.014961 loss)
I0825 00:05:18.657461 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992825
I0825 00:05:18.657471 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996717
I0825 00:05:18.657480 44210 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0825 00:05:35.286447 44210 solver.cpp:228] Iteration 4100, loss = 0.0156217
I0825 00:05:35.286512 44210 solver.cpp:244]     Train net output #0: accuracy = 0.992494
I0825 00:05:35.286527 44210 solver.cpp:244]     Train net output #1: loss = 0.0156216 (* 1 = 0.0156216 loss)
I0825 00:05:35.286535 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.989577
I0825 00:05:35.286540 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997459
I0825 00:05:35.286556 44210 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0825 00:05:51.915185 44210 solver.cpp:228] Iteration 4120, loss = 0.0137807
I0825 00:05:51.915320 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994958
I0825 00:05:51.915345 44210 solver.cpp:244]     Train net output #1: loss = 0.0137807 (* 1 = 0.0137807 loss)
I0825 00:05:51.915354 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99496
I0825 00:05:51.915364 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994946
I0825 00:05:51.915372 44210 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0825 00:06:08.548678 44210 solver.cpp:228] Iteration 4140, loss = 0.00839587
I0825 00:06:08.548722 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996803
I0825 00:06:08.548737 44210 solver.cpp:244]     Train net output #1: loss = 0.00839581 (* 1 = 0.00839581 loss)
I0825 00:06:08.548743 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997544
I0825 00:06:08.548748 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993781
I0825 00:06:08.548756 44210 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0825 00:06:25.178393 44210 solver.cpp:228] Iteration 4160, loss = 0.00753506
I0825 00:06:25.178562 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996555
I0825 00:06:25.178586 44210 solver.cpp:244]     Train net output #1: loss = 0.007535 (* 1 = 0.007535 loss)
I0825 00:06:25.178594 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995592
I0825 00:06:25.178606 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998525
I0825 00:06:25.178614 44210 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0825 00:06:41.823285 44210 solver.cpp:228] Iteration 4180, loss = 0.00705538
I0825 00:06:41.823333 44210 solver.cpp:244]     Train net output #0: accuracy = 0.997238
I0825 00:06:41.823348 44210 solver.cpp:244]     Train net output #1: loss = 0.00705532 (* 1 = 0.00705532 loss)
I0825 00:06:41.823360 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997034
I0825 00:06:41.823372 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997669
I0825 00:06:41.823386 44210 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0825 00:06:58.452567 44210 solver.cpp:228] Iteration 4200, loss = 0.012767
I0825 00:06:58.452667 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994813
I0825 00:06:58.452684 44210 solver.cpp:244]     Train net output #1: loss = 0.012767 (* 1 = 0.012767 loss)
I0825 00:06:58.452695 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994569
I0825 00:06:58.452706 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995394
I0825 00:06:58.452715 44210 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0825 00:07:15.080700 44210 solver.cpp:228] Iteration 4220, loss = 0.0102869
I0825 00:07:15.080749 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996227
I0825 00:07:15.080771 44210 solver.cpp:244]     Train net output #1: loss = 0.0102868 (* 1 = 0.0102868 loss)
I0825 00:07:15.080781 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996798
I0825 00:07:15.080791 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993585
I0825 00:07:15.080801 44210 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0825 00:07:31.722236 44210 solver.cpp:228] Iteration 4240, loss = 0.00942908
I0825 00:07:31.722340 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996425
I0825 00:07:31.722357 44210 solver.cpp:244]     Train net output #1: loss = 0.00942902 (* 1 = 0.00942902 loss)
I0825 00:07:31.722363 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996808
I0825 00:07:31.722369 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995117
I0825 00:07:31.722378 44210 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0825 00:07:48.389572 44210 solver.cpp:228] Iteration 4260, loss = 0.0152269
I0825 00:07:48.389631 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99418
I0825 00:07:48.389647 44210 solver.cpp:244]     Train net output #1: loss = 0.0152268 (* 1 = 0.0152268 loss)
I0825 00:07:48.389654 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994605
I0825 00:07:48.389660 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993342
I0825 00:07:48.389670 44210 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0825 00:08:05.058140 44210 solver.cpp:228] Iteration 4280, loss = 0.0127928
I0825 00:08:05.058267 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994637
I0825 00:08:05.058286 44210 solver.cpp:244]     Train net output #1: loss = 0.0127928 (* 1 = 0.0127928 loss)
I0825 00:08:05.058295 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994366
I0825 00:08:05.058302 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995473
I0825 00:08:05.058311 44210 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0825 00:08:21.686748 44210 solver.cpp:228] Iteration 4300, loss = 0.0127392
I0825 00:08:21.686797 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994894
I0825 00:08:21.686812 44210 solver.cpp:244]     Train net output #1: loss = 0.0127391 (* 1 = 0.0127391 loss)
I0825 00:08:21.686820 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995541
I0825 00:08:21.686825 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99033
I0825 00:08:21.686836 44210 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0825 00:08:38.324429 44210 solver.cpp:228] Iteration 4320, loss = 0.00998814
I0825 00:08:38.324599 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99583
I0825 00:08:38.324616 44210 solver.cpp:244]     Train net output #1: loss = 0.00998808 (* 1 = 0.00998808 loss)
I0825 00:08:38.324626 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994855
I0825 00:08:38.324638 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997461
I0825 00:08:38.324648 44210 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0825 00:08:54.960732 44210 solver.cpp:228] Iteration 4340, loss = 0.00740889
I0825 00:08:54.960783 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996725
I0825 00:08:54.960798 44210 solver.cpp:244]     Train net output #1: loss = 0.00740883 (* 1 = 0.00740883 loss)
I0825 00:08:54.960811 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99676
I0825 00:08:54.960824 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996568
I0825 00:08:54.960832 44210 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0825 00:09:11.588676 44210 solver.cpp:228] Iteration 4360, loss = 0.0115052
I0825 00:09:11.588791 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995537
I0825 00:09:11.588810 44210 solver.cpp:244]     Train net output #1: loss = 0.0115052 (* 1 = 0.0115052 loss)
I0825 00:09:11.588819 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99505
I0825 00:09:11.588825 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996371
I0825 00:09:11.588835 44210 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0825 00:09:28.221493 44210 solver.cpp:228] Iteration 4380, loss = 0.0100458
I0825 00:09:28.221542 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996081
I0825 00:09:28.221559 44210 solver.cpp:244]     Train net output #1: loss = 0.0100457 (* 1 = 0.0100457 loss)
I0825 00:09:28.221572 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995063
I0825 00:09:28.221578 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997606
I0825 00:09:28.221588 44210 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0825 00:09:44.862992 44210 solver.cpp:228] Iteration 4400, loss = 0.0137773
I0825 00:09:44.863097 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994089
I0825 00:09:44.863122 44210 solver.cpp:244]     Train net output #1: loss = 0.0137773 (* 1 = 0.0137773 loss)
I0825 00:09:44.863131 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993066
I0825 00:09:44.863143 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996396
I0825 00:09:44.863152 44210 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0825 00:10:01.525729 44210 solver.cpp:228] Iteration 4420, loss = 0.00753954
I0825 00:10:01.525786 44210 solver.cpp:244]     Train net output #0: accuracy = 0.9968
I0825 00:10:01.525802 44210 solver.cpp:244]     Train net output #1: loss = 0.00753948 (* 1 = 0.00753948 loss)
I0825 00:10:01.525811 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996797
I0825 00:10:01.525817 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996813
I0825 00:10:01.525827 44210 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0825 00:10:18.168720 44210 solver.cpp:228] Iteration 4440, loss = 0.00990264
I0825 00:10:18.168833 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996091
I0825 00:10:18.168851 44210 solver.cpp:244]     Train net output #1: loss = 0.00990258 (* 1 = 0.00990258 loss)
I0825 00:10:18.168864 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995828
I0825 00:10:18.168874 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996745
I0825 00:10:18.168882 44210 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0825 00:10:34.794258 44210 solver.cpp:228] Iteration 4460, loss = 0.0117779
I0825 00:10:34.794301 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996497
I0825 00:10:34.794332 44210 solver.cpp:244]     Train net output #1: loss = 0.0117779 (* 1 = 0.0117779 loss)
I0825 00:10:34.794340 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996584
I0825 00:10:34.794353 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996048
I0825 00:10:34.794363 44210 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0825 00:10:51.431442 44210 solver.cpp:228] Iteration 4480, loss = 0.0159644
I0825 00:10:51.431612 44210 solver.cpp:244]     Train net output #0: accuracy = 0.993176
I0825 00:10:51.431637 44210 solver.cpp:244]     Train net output #1: loss = 0.0159644 (* 1 = 0.0159644 loss)
I0825 00:10:51.431645 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.992227
I0825 00:10:51.431658 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994793
I0825 00:10:51.431668 44210 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0825 00:11:08.059521 44210 solver.cpp:228] Iteration 4500, loss = 0.011012
I0825 00:11:08.059563 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996118
I0825 00:11:08.059578 44210 solver.cpp:244]     Train net output #1: loss = 0.0110119 (* 1 = 0.0110119 loss)
I0825 00:11:08.059587 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997133
I0825 00:11:08.059592 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992697
I0825 00:11:08.059602 44210 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0825 00:11:24.701416 44210 solver.cpp:228] Iteration 4520, loss = 0.00930764
I0825 00:11:24.701541 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99639
I0825 00:11:24.701562 44210 solver.cpp:244]     Train net output #1: loss = 0.00930758 (* 1 = 0.00930758 loss)
I0825 00:11:24.701576 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996566
I0825 00:11:24.701584 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995562
I0825 00:11:24.701594 44210 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0825 00:11:41.355514 44210 solver.cpp:228] Iteration 4540, loss = 0.00990297
I0825 00:11:41.355557 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995932
I0825 00:11:41.355572 44210 solver.cpp:244]     Train net output #1: loss = 0.00990291 (* 1 = 0.00990291 loss)
I0825 00:11:41.355581 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995959
I0825 00:11:41.355587 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995839
I0825 00:11:41.355597 44210 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0825 00:11:57.982750 44210 solver.cpp:228] Iteration 4560, loss = 0.00764508
I0825 00:11:57.982864 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996984
I0825 00:11:57.982882 44210 solver.cpp:244]     Train net output #1: loss = 0.00764502 (* 1 = 0.00764502 loss)
I0825 00:11:57.982894 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99683
I0825 00:11:57.982906 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997283
I0825 00:11:57.982928 44210 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0825 00:12:14.628748 44210 solver.cpp:228] Iteration 4580, loss = 0.0125272
I0825 00:12:14.628799 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995537
I0825 00:12:14.628815 44210 solver.cpp:244]     Train net output #1: loss = 0.0125271 (* 1 = 0.0125271 loss)
I0825 00:12:14.628823 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995357
I0825 00:12:14.628829 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995966
I0825 00:12:14.628849 44210 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0825 00:12:31.258584 44210 solver.cpp:228] Iteration 4600, loss = 0.00664431
I0825 00:12:31.258757 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99695
I0825 00:12:31.258798 44210 solver.cpp:244]     Train net output #1: loss = 0.00664425 (* 1 = 0.00664425 loss)
I0825 00:12:31.258810 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996326
I0825 00:12:31.258821 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998475
I0825 00:12:31.258831 44210 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0825 00:12:47.883461 44210 solver.cpp:228] Iteration 4620, loss = 0.00952722
I0825 00:12:47.883524 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996497
I0825 00:12:47.883551 44210 solver.cpp:244]     Train net output #1: loss = 0.00952716 (* 1 = 0.00952716 loss)
I0825 00:12:47.883561 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995884
I0825 00:12:47.883574 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997459
I0825 00:12:47.883582 44210 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0825 00:13:04.508499 44210 solver.cpp:228] Iteration 4640, loss = 0.0123039
I0825 00:13:04.508628 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995383
I0825 00:13:04.508648 44210 solver.cpp:244]     Train net output #1: loss = 0.0123038 (* 1 = 0.0123038 loss)
I0825 00:13:04.508657 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995524
I0825 00:13:04.508668 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995131
I0825 00:13:04.508678 44210 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0825 00:13:21.141808 44210 solver.cpp:228] Iteration 4660, loss = 0.0108275
I0825 00:13:21.141855 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995385
I0825 00:13:21.141883 44210 solver.cpp:244]     Train net output #1: loss = 0.0108275 (* 1 = 0.0108275 loss)
I0825 00:13:21.141893 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995648
I0825 00:13:21.141906 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.994495
I0825 00:13:21.141914 44210 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0825 00:13:37.803234 44210 solver.cpp:228] Iteration 4680, loss = 0.0121174
I0825 00:13:37.803357 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995443
I0825 00:13:37.803380 44210 solver.cpp:244]     Train net output #1: loss = 0.0121174 (* 1 = 0.0121174 loss)
I0825 00:13:37.803392 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994825
I0825 00:13:37.803400 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996796
I0825 00:13:37.803411 44210 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0825 00:13:54.459533 44210 solver.cpp:228] Iteration 4700, loss = 0.00796839
I0825 00:13:54.459584 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996646
I0825 00:13:54.459617 44210 solver.cpp:244]     Train net output #1: loss = 0.00796833 (* 1 = 0.00796833 loss)
I0825 00:13:54.459627 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996447
I0825 00:13:54.459645 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997079
I0825 00:13:54.459656 44210 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0825 00:14:11.099803 44210 solver.cpp:228] Iteration 4720, loss = 0.00871636
I0825 00:14:11.099937 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996461
I0825 00:14:11.099975 44210 solver.cpp:244]     Train net output #1: loss = 0.0087163 (* 1 = 0.0087163 loss)
I0825 00:14:11.099984 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996772
I0825 00:14:11.099995 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995023
I0825 00:14:11.100003 44210 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0825 00:14:27.795017 44210 solver.cpp:228] Iteration 4740, loss = 0.0113413
I0825 00:14:27.795058 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995007
I0825 00:14:27.795075 44210 solver.cpp:244]     Train net output #1: loss = 0.0113412 (* 1 = 0.0113412 loss)
I0825 00:14:27.795084 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994413
I0825 00:14:27.795094 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996505
I0825 00:14:27.795102 44210 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0825 00:14:44.446575 44210 solver.cpp:228] Iteration 4760, loss = 0.00795587
I0825 00:14:44.446722 44210 solver.cpp:244]     Train net output #0: accuracy = 0.997118
I0825 00:14:44.446756 44210 solver.cpp:244]     Train net output #1: loss = 0.00795581 (* 1 = 0.00795581 loss)
I0825 00:14:44.446766 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997734
I0825 00:14:44.446777 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.992503
I0825 00:14:44.446786 44210 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0825 00:15:01.092177 44210 solver.cpp:228] Iteration 4780, loss = 0.00642779
I0825 00:15:01.092228 44210 solver.cpp:244]     Train net output #0: accuracy = 0.997598
I0825 00:15:01.092243 44210 solver.cpp:244]     Train net output #1: loss = 0.00642773 (* 1 = 0.00642773 loss)
I0825 00:15:01.092250 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.998029
I0825 00:15:01.092257 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.993946
I0825 00:15:01.092267 44210 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0825 00:15:17.757066 44210 solver.cpp:228] Iteration 4800, loss = 0.00996151
I0825 00:15:17.757197 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995955
I0825 00:15:17.757215 44210 solver.cpp:244]     Train net output #1: loss = 0.00996145 (* 1 = 0.00996145 loss)
I0825 00:15:17.757228 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995736
I0825 00:15:17.757239 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996843
I0825 00:15:17.757247 44210 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0825 00:15:34.419960 44210 solver.cpp:228] Iteration 4820, loss = 0.0116361
I0825 00:15:34.420007 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994967
I0825 00:15:34.420027 44210 solver.cpp:244]     Train net output #1: loss = 0.011636 (* 1 = 0.011636 loss)
I0825 00:15:34.420035 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.993665
I0825 00:15:34.420040 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997116
I0825 00:15:34.420050 44210 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0825 00:15:51.087286 44210 solver.cpp:228] Iteration 4840, loss = 0.00689715
I0825 00:15:51.087426 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99716
I0825 00:15:51.087445 44210 solver.cpp:244]     Train net output #1: loss = 0.00689709 (* 1 = 0.00689709 loss)
I0825 00:15:51.087451 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996791
I0825 00:15:51.087457 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997971
I0825 00:15:51.087467 44210 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0825 00:16:07.752904 44210 solver.cpp:228] Iteration 4860, loss = 0.00704802
I0825 00:16:07.752955 44210 solver.cpp:244]     Train net output #0: accuracy = 0.996963
I0825 00:16:07.752971 44210 solver.cpp:244]     Train net output #1: loss = 0.00704796 (* 1 = 0.00704796 loss)
I0825 00:16:07.752979 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996259
I0825 00:16:07.752985 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.998451
I0825 00:16:07.753005 44210 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0825 00:16:24.395186 44210 solver.cpp:228] Iteration 4880, loss = 0.00805526
I0825 00:16:24.395308 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99717
I0825 00:16:24.395330 44210 solver.cpp:244]     Train net output #1: loss = 0.0080552 (* 1 = 0.0080552 loss)
I0825 00:16:24.395342 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.996673
I0825 00:16:24.395354 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.997886
I0825 00:16:24.395364 44210 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0825 00:16:41.072188 44210 solver.cpp:228] Iteration 4900, loss = 0.0118023
I0825 00:16:41.072249 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995764
I0825 00:16:41.072265 44210 solver.cpp:244]     Train net output #1: loss = 0.0118022 (* 1 = 0.0118022 loss)
I0825 00:16:41.072273 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995532
I0825 00:16:41.072280 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996134
I0825 00:16:41.072299 44210 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0825 00:16:57.718226 44210 solver.cpp:228] Iteration 4920, loss = 0.00741615
I0825 00:16:57.718423 44210 solver.cpp:244]     Train net output #0: accuracy = 0.997193
I0825 00:16:57.718448 44210 solver.cpp:244]     Train net output #1: loss = 0.00741609 (* 1 = 0.00741609 loss)
I0825 00:16:57.718459 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.997952
I0825 00:16:57.718474 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.99418
I0825 00:16:57.718489 44210 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0825 00:17:14.360810 44210 solver.cpp:228] Iteration 4940, loss = 0.00716554
I0825 00:17:14.360860 44210 solver.cpp:244]     Train net output #0: accuracy = 0.99697
I0825 00:17:14.360883 44210 solver.cpp:244]     Train net output #1: loss = 0.00716548 (* 1 = 0.00716548 loss)
I0825 00:17:14.360891 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.99704
I0825 00:17:14.360898 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996749
I0825 00:17:14.360908 44210 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0825 00:17:31.071704 44210 solver.cpp:228] Iteration 4960, loss = 0.012866
I0825 00:17:31.071871 44210 solver.cpp:244]     Train net output #0: accuracy = 0.994991
I0825 00:17:31.071919 44210 solver.cpp:244]     Train net output #1: loss = 0.0128659 (* 1 = 0.0128659 loss)
I0825 00:17:31.071930 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.994961
I0825 00:17:31.071940 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.995059
I0825 00:17:31.071949 44210 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0825 00:17:47.776046 44210 solver.cpp:228] Iteration 4980, loss = 0.00913234
I0825 00:17:47.776134 44210 solver.cpp:244]     Train net output #0: accuracy = 0.995966
I0825 00:17:47.776151 44210 solver.cpp:244]     Train net output #1: loss = 0.00913228 (* 1 = 0.00913228 loss)
I0825 00:17:47.776160 44210 solver.cpp:244]     Train net output #2: per_class_accuracy = 0.995742
I0825 00:17:47.776172 44210 solver.cpp:244]     Train net output #3: per_class_accuracy = 0.996634
I0825 00:17:47.776181 44210 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0825 00:18:04.096411 44210 solver.cpp:454] Snapshotting to binary proto file pocwisc7/training_iter_5000.caffemodel
I0825 00:18:05.182621 44210 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pocwisc7/training_iter_5000.solverstate
I0825 00:18:05.782177 44210 solver.cpp:317] Iteration 5000, loss = 0.00609329
I0825 00:18:05.782230 44210 solver.cpp:322] Optimization Done.
I0825 00:18:05.782244 44210 caffe.cpp:254] Optimization Done.

2017-08-25 00:18:06,218 log.framework MainThread  INFO       caffe models found
pocwisc7/training_iter_5000.caffemodel
2017-08-25 00:18:06,218 log.framework MainThread  INFO       Caffe model found: pocwisc7/training_iter_5000.caffemodel
2017-08-25 00:18:07,887 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-25 00:18:08,102 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-25 00:18:08,299 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-25 00:18:08,515 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-25 00:18:08,733 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-25 00:18:08,935 log.framework MainThread  INFO       uniques of label [0 1]
2017-08-25 00:18:09,152 log.framework MainThread  INFO       uniques of label [0 1]
